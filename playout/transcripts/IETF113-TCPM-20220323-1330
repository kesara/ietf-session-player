[
  {
    "startTime": "00:00:07",
    "text": "so foreign it's almost time but um let's see okay number of people is getting increased i can wait one two minutes uh okay okay looks like we can start right okay so the decision hey hello everyone um i hear some items somewhere"
  },
  {
    "startTime": "00:02:06",
    "text": "okay hello everyone uh i think i can hear you you can hear me um so this is our dcpm working group meeting tcp maintenance under my neck station working group and this working group has three co-chairs my name is yoshi nishida and we have ian here and michael here everyone in remote and just in case uh this session is being recorded so it will be published eventually so here in the remote make sure you have already cleaned the room otherwise it will be published okay and this is i use a node well i think you have already seen this several times already so in a nutshell this basically describes how to participate how to contribute to the idf and which point you should be available and if you have any concerns about participating or contributing the idea please read this slide very carefully and then if you you know you can find the same content on the idf webpage you can search and you can find it very easily and then so this is a special tips for this idea meeting so if you are on site please make sure to sign in the session by using media go and also when you speak up please use medical to join the mic you and please keep audio and the video off while you know you unless you are using uh on sidebar mid ago and if you are remote if you remote participant uh"
  },
  {
    "startTime": "00:04:00",
    "text": "please make sure your audio and the video of undersea and ask unless you're speaking and then use your headset as much as possible okay and then this is a resource for this itf meeting you can find the entire agenda on this first url and they if you want to get more information about mid echo weather information you can use the second url and if you have any you know technical issues or other reports other issues you want to report please use the third link moving beyond logistics um so richard will be in charge of not taking thank you so much richard and michael will take care of javascript thank you so much michael and this is short reminder so when you submit your internet draft to this working group please include tcpm as the name of your draft otherwise we cannot track the status of the draft so please keep this in your mind and then this is agenda for the today's meeting so we are starting from working group status and then after that we have uh three presentation for working group document um at first probing we'll talk about i start draft and then bd will talk about the cubic draft after that bob will talk about acura dcn updates and after working group documents presentation we have three presentation for non-working group document first chorus will talk about tcp accurate request and then after that peng will talk about"
  },
  {
    "startTime": "00:06:00",
    "text": "update for mbtcp lobby and then after that maxim will talk about tgprs modern transport service based tcp and trs so this is the agenda for today any question or comment or suggestion on this agenda okay then we'll be on to the working group status so as you might already notice there are some personal updates in the working group and very unfortunately uh michael decided to step down as a chair but we really really appreciate his long-term contribution dedication to the idea and to this working group i really really appreciate it i i learned him a lot he learned from him a lot and then um we have a new concierge ian and thank you so much for taking this role here you have some words thank you um yeah i'm really excited obviously i'm extremely familiar with with quick and um to you know congestion control work like ppr and and such and i'm excited to um kind of get a better visibility into the innovations in tcp and um you know help wherever i can to to make sure that tcp is awesome is quick so that's kind of how i think about it thank you okay moving on so working group documents so we have several working group documents um so ao test vector draft the current status of this draft is rfc in exaq so this draft will be published very soon so young pcb draft"
  },
  {
    "startTime": "00:08:01",
    "text": "this draft is under is ies review 793 bits draft this is this draft is currently under isc evaluation and ad3 12 bits draft and this graph will be discussed in the meeting and so hopefully we can finalize this draft and high star star high start plus press draft and this draft will also be discussed in the meeting and then accurate edition and draft this draft will also be discussed in the meeting and then we believe with all three this draft uh getting close to be finalized that's expectation and then um generalized issue and draft this draft has been on hold for a while and the reason why it has been on hold is that this truck depends on accurate dcn but we have very long discussion on accuracy and draft that's why you know this general edition drought has been suspended for a long time but uh i think the current status of our tradition is you know getting mature it's getting close to be finalized so i think we can start proceeding generally each and drop very soon that is expectation and for idio draft joe sometimes updates the draft some sometimes send a message to the mailing list but the problem of this uh draft is we don't have many feedback on this draft so it's very difficult for chairs to think about how to proceed this draft so i would like to talk about this traffic a little bit more in my final slide so i will you know talk about this"
  },
  {
    "startTime": "00:10:01",
    "text": "later and then the final one is 69 37 bits drafts and this draft has been inactive for a while but uh as far as we exchange email with the authors they also is planning to publish new version very soon and so once they have published the new version we can think about how to proceed the draft so that's a plan so that's you know current status of the working document any questions or comments on the working group documents so this is a richard just the general observation i don't think we need to wait with generous ecn on any of the other stuff really quite the opposite so i would really appreciate it if generalized ecn would proceed perhaps we can start thinking about even going working group last call because quite frankly there's no i don't see any technical discussion going on around that while there is also technical merit to be had from generalized ecm okay that's fine okay then uh richard now you can initiate mail send the email to the mailing list and the initial discussion and then we can think about you know if we can it's ready for working lupus core or not yeah that would be fine um it has a normative reference to equity again so it could go through um the isg waiting director eastern if it went first but that might be better to get it out of the way um rather than really admit"
  },
  {
    "startTime": "00:12:00",
    "text": "can you not hear me it's a little difficult to hear you sorry so if you can if i can improve your settings before the presentation that would be great so what's the problem just volume no it's not volume like heading out i think at least that's what it was for me [Music] okay okay so you hear what i said about what richard said if you can repeat it for this okay i i just said there's a normative reference from um in generalized vcn so would be fine you know at least it would be out of the working group but it um and that that okay yeah basically i got it it's a little tricky so oh sorry yes that's okay okay let's move on to the next slide so this is my final slide so i like to talk about idio draft a little bit more and as i mentioned the problem of this draft is we have very little feedback on this draft so"
  },
  {
    "startTime": "00:14:00",
    "text": "what i'm thinking right now is you know we can you know have some kind of specific reviewer for this draft and then if we can get very detailed feedback on this trust from the reviewers we can have a very good idea about how to proceed draft so if you are interested in living draft this is a very good chance for you to speak up so anyone interested in leaving this draft please speak up right now um i think i could at least um read it and see whether i can offer any anything okay great thank you so much jonathan it will be good if i can have one more review if possible okay yeah if not no after some discussion among cheers we might contact some of you asked for asking you know reviewing but that's a plan and then also if you have some implementation experience for idio draft or if you are planned if you plan to implement idio draft please uh the information such kind of information will also be very useful for us to think about how to proceed this draft so we appreciate your cooperation and then in the meantime i also like to think about how to you know proceed scene option extension and joe has a one proposal to about slashing option space extension and this program the program of this draft is also we don't we have very little feedback on this draft and then joe is saying that's no"
  },
  {
    "startTime": "00:16:00",
    "text": "he is thinking about you know submitting this draft as an independent stream but uh um i'm not sure this is a great idea the one reason for that is uh option extension is very fundamental for this respect so having this kind of proposal in as in as an independent stream is a great idea or not but we still have a don't have don't have a specific feedback on this point so we don't know if this is okay or if this is not okay well we should adapt it as this is a great idea so and then we also would like to think about uh how to extend option space in general not only specifically those proposals if you have any you know idea or opinions sold please share so we really appreciate your feedback any comments or thoughts wait uh yeah i would say the options extension in general and the sin especially is uh something i've been interested in for a long time and ideally i think the working group would handle this and arrive at a consensus solution uh i think the independent stream path is a last resort if the working group doesn't have the interest or energy to do anything i think it makes sense to me because it comes up enough that something is needed that the independent path is a way to get something published that other people can use and experiment with but"
  },
  {
    "startTime": "00:18:01",
    "text": "i think it's a last resort and it's not the ideal path at all thank you martin hi uh martin duke google um yeah i agree with wes it would be nice to get this done and if it's a question of bandwidth it just people want to review it but there's too many other things in tcpm right now then maybe we can make a commitment to like i don't know adopt it and then clear some space that people have the time or if people just aren't interested that's it that's maybe a different issue so i'm not sure what the nature of the of the reluctance is yeah so i also need my at least i need my feedback otherwise so this is so this is richard so i so from my ex observations over the last couple of years we've had a couple of years ago we had this push to get more option space and it was quite a high high on the agenda but since then um we didn't really find anything that had an immediate need for extended options right away however i would support what martin just said i think we should discuss adopting this and having it on the on the working groups agenda because eventually it will be coming up again and then it will be more urgent than ever probably at least in the beginning um at least at that time i would expect people will have some bandwidth to contribute and review so you are saying we should wait a little bit more we should start discussion very soon i think i think we should we should uh adopt i think we should adopt this but"
  },
  {
    "startTime": "00:20:02",
    "text": "um and give it cons consideration just as much imagination and to see that we can work on this even not at a very high priority right now but eventually it should be a working group document i don't think that i i also believe what mentioned having as an independent stream is should only be the very last resort and i would personally i wouldn't really like that so i do want to clarify that um i was making a question not a statement like if the if the lack of reviews is is like indifference or bandwidth and if the question is bandwidth then i think we can make time for this and just maybe reduce our document intake or or whatever and then put it as like the last milestone um they're the furthest up milestone whereas if people just like don't care then then we shouldn't string along joe thanks okay thank you so if there is no more comments now we are moving on to the presentation i would like to ask the presenters to stay in the time they got for the presentations yeah okay let's move on to the presentation so probing it's your turn come here and you should share yours you can control your slide uh i sent uh thank you i just approved it for me okay great uh hello everyone i'm here to talk about uh high start plus plus uh so the"
  },
  {
    "startTime": "00:22:01",
    "text": "current draft version is a draft version four um so uh this is a recap of the original idea when we first brought this to the tcpm working group so the problem we're trying to solve is the slow start overshoot problem so because we effectively double the window every round of time we can overshoot the ideal send rate and that causes massive packet losses uh which means you know more time spent in in recovery uh as well as increased packet retransmissions and sometimes we end up uh taking rto even with algorithms like rack so uh hyzer plus plus originally when we proposed it was a very simple modification and the idea was there to uh use delay inquiries to detect that um the um the queues are filling up and we basically exit slow start early before causing the packet loss and then we included a compensation for any premature slow start exit so in cases where the the delay increase was due to jitter or a temporary burst of packets we basically uh introduced usage of limited slow start so uh effectively we would use the max of limited slow start and the condition avoidance window uh thereby mitigating some of the impact of experience exit at that point we uh got some feedback and we started looking into jitter resiliency and we ended up simplifying the algorithm a lot so instead of trying to compensate for early exit from slow start we added detection of spurious exits to be able to resume slow start so imagine a network where there is a lot of jitter a delay increase algorithm would kick in sometimes spuriously and cause us to exit slow start at that point we enter something called as the conservative slow start phase so what is conservative slow start is basically a series of rounds where we"
  },
  {
    "startTime": "00:24:01",
    "text": "are trying to determine if the exit was spurious due to a delay spike and the way we do that is we when we enter css we capture the the current rounds main rdt at that point and then for a series of rounds we see if any of the delay samples are going to be lower than the captured rdt that tells us whether the uh delay increase was spurious or not and if we think that the if if we determine that the exit was indeed spurious we basically resume high start plus plus so which means you know regular slow start resumes as well as uh the direction of uh delay increase and in the entire algorithm is basically reset and and it restarts and the advantage of this is that if the network does have jitter that you know slow start will still give you you know good performance and an exponential window increase so that's the gist of it that you know instead of trying to compensate for early exit we are detecting uh spurious exists and we are resuming slow start uh sorry for the small font size here but this is the summary of the current algorithm in draft version 4. uh so basically in slow start we we adjust the condition window according to five six eight one uh but uh we take rtt samples so uh each round is approximately an rtt and we remember the last round's minority and we compute the current round's minority and we use a threshold basically there's a lower clamp and an upper clamp but basically if um the current rounds minority is greater than the last round's minority plus the threshold uh then we exit slow start uh we also capture something called a css baseline rtd so that's the rgd i was talking about that will help us determine if the exit was spurious or not and then the conservative slow start phase lasts a few rounds currently the draft recommends five rounds based on"
  },
  {
    "startTime": "00:26:00",
    "text": "experimentation uh and then uh for each ack in css again we repeat the procedure where we continue to measure the current round's minority and we compare that against the captured um css baseline rdd and if at any point during css we see that the current rounds minority t goes lower than the than the css baseline or rtt at that point we can determine that the exit was actually spurious and we just resume slow start and high start plus plus but if we complete all of css if we complete all those rounds and we don't see the minority go lower and then our captured rtt then we basically enter conditional maintenance so that is actually a correct exit and there is a consistent delay increase we do exit i start plus plus on any congestion signals and currently the draft recommends that we only use this for the initial slow start for subsequent slow starts after rto we do have a value of captured ss thresh and we say that you may use this after i do uh so we did make a few changes in in draft i want to bring up a couple of things that were brought up in the mailing list uh randall had proposed that uh instead of you know setting css baseline rtt to the current rounds minority that it instead be set to last one minority plus rtt thresh we did experiment with the idea but it showed poor performance when jitter was present um so i think it was an optimization for when there's no jitter but in in presence of jeter it did not work well and i think neil uh had suggested that we use a different mechanism for determining window and basically instead of using greater than or equal to you strictly greater than uh i think his comments were going towards uh you know cases where uh we could be app limited uh but we found that this is also uh inaccurate uh computation of an end of"
  },
  {
    "startTime": "00:28:00",
    "text": "round in many cases so we did not make this change so the only sort of logic change that we made in draft zero four was uh removing uh dependency on uh low ss thresh so basically at this point uh the only trigger for computing and measuring the rtt values and looking at delay increases basically enough number of rtt samples have been taken in the round which currently the draft recommends that the implementation at least take eight measurements of rtt so that was the only change so that simplified things a little bit more and removed one magic constant and then we made a bunch of editorial improvements based on all the discussions in the mailing list so at this point we have addressed all the outstanding reviews i think we got one from bob jeremy and neil so far and we answered questions on the mailing list as well that came in from randall and neil and to our awareness there are at least three implementations uh in in production use uh the windows tcp cubic implementation has been using this for more than two years i think maybe three or more than three years at this point uh cloudflare's quick library quiche uses it in production and then uh freebsd has also added this to their tcp cubic implementation so uh in the author's eyes i think the draft is ready for working group last call and i'm happy to take any questions corey would you like to go first so corey fergus thank you for doing this um i've seen this in action it can be good my question is which of the implementations use the latest version of the spec is there one i could actually go and try over my awkward paths that i don't know about and"
  },
  {
    "startTime": "00:30:00",
    "text": "interestingly you have some small voice in interference for me in this direction so um i i'm looking for a a point to which pers which version of the code i should test and then uh offer to try and test it and see how well it works over some really awkward links as a useful feedback perhaps yeah uh gauri so uh the the latest versions of the windows os both windows 10 and windows 11 have the latest uh algorithm implemented and i think the free psd tcp implementation also uses the latest draft so both of these include for example all the conservative flow start phase and all of that at the cloudflare's quick library i'm not sure if it has been updated to the latest draft that's what i wanted to know thank you ever so much i'll give you a feedback thank you any other comments so i think you know this stuff has been stable for a long time and then i think you know we are almost getting ready well i can rascal that's what's currently child thinking but uh if you have any opinions sold on this one and this is a good chance for you to speak up any comments silence understands there is no objection am i correct okay and same is to be at reason there is no objection i think we can confirm if this relative working group will have to go right on the mailing list okay thank you praveen okay sounds good thank you thank you"
  },
  {
    "startTime": "00:32:03",
    "text": "okay so we'll be on to the next presentation bd can you hear me now yeah you want this you want to make some comments no no i just want to check my audio okay i think it's getting better okay yeah can you hear me okay yeah um so sorry so i always forget the slide request um i think you you know you already grunted okay could you tell me where was it on the left or the right uh has to okay got it okay sure all right can you see the slice now awesome um so today i'll talk a little bit about um you know the changes that have been made and then the discussion that was happening on the mailing list to publish cubic base as uh proposed standard or or something else um so i have captured some of the updates in these slides but there are many more um these are just some of the updates that i thought would be interesting to just combine in the slides and this includes everything"
  },
  {
    "startTime": "00:34:02",
    "text": "that has been changed plus the ones that i have not added here so they're all present on the github um i'm not gonna go through each one of them because we have gone through these in the past uh presentations um so i'll give just a couple of minutes on each slides if you have any questions uh just in case if you haven't seen these updates so far um same here these were also done and discussed in the previous previous presentations give a couple of seconds here um so since the last meeting um we made some changes and these i would like to discuss um the spurious congestion uh detecting spurious congestion event and reacting to them uh there there's now we have categorized into them into two events um one is boris timeouts and the other is spurious loss detected by acknowledgements the first one is kind of relevant for tcp and there's already a standards track rc that specifies the response for restoring the congestion window and um for adapting the timer uh so that there's to avoid any future spurious timeouts so there's this rc 4015 that specifies all of that and then we have the spurious losses detected by acknowledgments so this is relevant for both tcp and quick and in tcp you can use timestamps and duplicate sex to detect these"
  },
  {
    "startTime": "00:36:02",
    "text": "um excuse me for quick it's uh quite easy you can detect it by seeing any new packets sorry sorry you can see this by detecting any packets that were marked lost but they were acknowledged after they were marked lost so that's kind of a spurious loss and then for these events uh right now we have suggested doing a undo of the condition window of the slow start threshold and a few more parameters for cubic um so and this this one is kind of a has a precaution caution written in the text to be careful when uh you're using this because you know it might cause you to set condition window to a higher value if the link capacity has changed from the previous state to the now state so you just have to be a little careful with that um and then we have uh neil actually made the next update about clarifying the meaning of application limited uh there was some question about what is application limited means and we have added text for clarifying that and then uh there was a request or question by yushi about why is rfc 7661 um okay to use uh you know when rfc 5681 has a specific test text about uh congestion window growing beyond receipt window and then it shouldn't grow beyond receive window so the 7661 basically is monitoring bytes acknowledged uh in rtt uh you know like the pipe back value that it's computing it's like it's doing how many bytes are acknowledged in rta in consecutive rtts one two or three"
  },
  {
    "startTime": "00:38:02",
    "text": "rounds so because it's based on the pipe value which is why it's acknowledged in rtt it kind of includes the validates the receive window because you always check the receive window before sending the data so we have added text to make it a little bit more clear why it is safe to use um even when this condition window grows beyond receive window so these are the latest updates um in the draft and this is probably the topic for main topic for today um i i will this is um i will leave leave the rest of the time for questions discussions and comments on whether we should publish 83 12 business uh you know standard strike or not uh great yeah gory first i was going to talk to the previous slide and just say i'll read the text again i think i was happy with what was done so the 7661 thing i think they did the right thing for this document so i don't see that as an issue and i'll read the text carefully i promise and give feedback if i see anything so i from my point of view let's look at the last slide okay any comments for ps4 experimenter michael uh michael uh just a quick question about this last statement here this uh separate draft on cubic evaluation improvements is that uh supposed to be"
  },
  {
    "startTime": "00:40:01",
    "text": "the home for the things that marco has brought up that's supposed to be okay i'm just curious i think it's a good idea probably and if anyone else has any other improvements that they wish to talk about right hi yeah lars eggert um i saw a bunch of emails from marco on the list that i haven't fully had the time to read yet but glancing at it i'm not sure if he's okay with publishing this sps even if we did this other document i would like to hear that validated from him i think what i saw him say is that because cubic was deployed on the internet without this not not following the process that that we did back when i was in magnus and we were ad and then we had sally and i think was it wes work on this considerations thing means that that the ietf cannot do this before cubic undergoes all of this you know evaluation and then while i sort of i was instrumental in establishing this process and so i wish that deployment would have happened that way it didn't right people deployed cubic and it worked well enough and more people deployed cubic and now it's basically ubiquitous and i thought of c2 two ways forward right either we can acknowledge that and say well you know this didn't happen in the way we ideally would have envisioned it to play out but the reality is that it is running the traffic on the internet and therefore maybe it should be ps or we can say you know we're not willing to do that we're going to stick with new reno um and i personally obviously i'm very biased here because i think this should be a published center but i think it would be good to sort of that seems to be the fundamental sort of objection right that it's it didn't do what we expect"
  },
  {
    "startTime": "00:42:01",
    "text": "specifically new congestion control algorithms which is arguably isn't really either but the process that we expect the stuff to undergo and it didn't follow that right i will point out i i made the comment in the bar the other night that maybe i'll write another document that says we should declare a new reno historic because we don't have any deployment experience on the running internet anymore and we haven't had it for 10 years but that's a discussion for another day so this is great it's gory fair hust again and i get to agree with lars really positively on the first one um which basically i think we should we should write a paragraph of texting we didn't do it the way the ietf should do it and this isn't this is not totally consistent with other rfcs but it is running code it is out there it is the consensus of what to do and that's what this document is and if we have a process to doing that then i think we should go that way if we don't then i think we need to invent one because we need to get this document published so that's my own take and that's just an individual idea the second thing is i don't agree with lars on the um on reno so we can fight that one out later michael so lars brought up a statement that there is a process how to deal with new um congestion controls and uh so obviously cubic didn't follow that procedure considering another congestion control algorithm which is being deployed called bvr is also not following this procedure so um i'm um i'm wondering whether this how how important should it be to follow"
  },
  {
    "startTime": "00:44:01",
    "text": "this procedure and just to answer martin's questions on the chat netflix uses neorino into the queue and i saw there's other yellow things in front of me so i mean the history of this process right this is when um i don't want to call it the high-speed congestion control wars but it was basically we had lots i think four or five different uh proposals many of them from academia on you know how you can improve tcp specifically for what's called high speed links back then which are just normal links now but back then they were high speed because they were like a gig fast or something like that and we felt that on the itf side we needed to give this some guidance and some structure because um it was sort of quite confusing how people went about sort of motivating why their scheme was better than somebody else's scheme and all of that and that sort of that's not how congestion control is being done or brought to the idf anymore but we're now in a situation where the people who work on new congestion control schemes actually are in control of of end points directly which wasn't the case back then which is mostly academic work that smart people did but they didn't have the the ability to deploy at scale which we now have right and so it's a very different world now 15 years later where um we actually have the ability to do a b testing over the real internet and and get data back and all of that so when we've seen this when we did iw10 for example and other things right so the the process we outlined is probably not useless in the sense that it still gives you good guidance for what the itf would like to see but"
  },
  {
    "startTime": "00:46:02",
    "text": "maybe like requiring that to be followed isn't hasn't aged very well okay can i say something so yeah i think you know basically i agree what michael says so so bvr is the internet draft so i it's not it might be experimental so i don't know the status but uh for example lfc 9002 this is proposed standard and then i also think this is some kind of aggressiveness in the draft the algorithm described in the draft so i think i'm not i don't find a particular reason that we are attacking cubic specifically so there are several drafts and the old draft should be treated equally and then otherwise you know it's not very fair and so i just know if you know we in the space we set very high set high bar on the cubic drug i think there we should set all other kind of transition control draft should be has a symbol that's my personal opinion probing yeah so um i tend to agree that this should be a proposed standard just because of how widely it is deployed and i think if i were writing a new tcp implementation or even a quick implementation like having cubic as the standard to implement would make sense because we know know the limitations of neurano right so it doesn't make sense for new implementers new implementers to not find this as a as a proposed standard rc uh that's my take on it as an implementer um if i was uh looking for guidance from the ietf right uh i"
  },
  {
    "startTime": "00:48:01",
    "text": "agree about the part about the process i think we should we should revisit that process i think iccrg or other places could define what that process should be but cubic given that it's already so widely deployed i think in my opinion i would be very supportive of publishing it as a proper standard martin just very quickly i i i feel like we're getting maybe away from the 80-12 discussion a bit but um uh regarding like the gates for congestion control the bar that we are setting it feels like that bar is now essentially high enough that the correct way to deploy new congestion control is to go work for one of those companies that ours mentioned deployed at scale and then come to idf and say see it works which maybe is not it is kind of defeating the purpose of having this body or a related idf body like provide review before things get deployed at scale so um i think we need to rethink it basically without without making specific proposals thanks [Music] okay there's okay colleen uh yeah i think i just want to plus one then i don't see that anything this group is ever going to do would meet that bar so i think we should we should have published this as proposed standard years ago [Music] okay so do you think this is counting number here is a good idea all right this is too early or to control basha"
  },
  {
    "startTime": "00:50:10",
    "text": "and your opinion i think the general sense is that uh going uh going on to propose standards is uh justified okay so this is not uh how can i say uh finalize no number uh but uh you know to think about you know how to proceed this route i just would like to come the number so it will be so if you agree with publishing cubic to graph as a proper standard please raise your hand okay 25 26 27 okay let's pretend here okay then i can also get another information"
  },
  {
    "startTime": "00:52:04",
    "text": "if you disagree with publishing cubic as a purple standard please raise your hand okay okay good i think 28 so can i just ask a clarification on the poll by jumping in okay did the last current include those people who want to publish it as exp rather than just not publish because i think some people want to publish it as exp okay then i can add more one more question a publish cubic as an experimental how many people agree with this idea one hmm okay number has changed pure pressure at work democracy and publishing interim results"
  },
  {
    "startTime": "00:54:01",
    "text": "okay it's coming back i can see some fluctuations please make a decision i will cross the ball very soon it's okay to cross the station i will cross okay gross okay but at least no i think we can get good statistics for this session and but still this is not the final call i think we still we should still continue the discussion and but i think i got a good data point and oh okay calling you want to make something make a comment oh hey this is large story i i'm concerned now that i started looking like gory it's no offensive [Laughter] it's the mask but it's the it's the mask oh colin sorry and now i disappeared okay sorry i forgot to take myself out of the queue yeah um i i just wanted before so for the author's team ask that if people because we had the second working group call now right if people are okay with publishing the version as is that would be useful to know and if the answer there is no it would be very good to know what exactly should be added to the document i know that gory suggested earlier that we add a paragraph that said this document didn't follow the process outlet in whatever the rfc was um but the uh you know the itf discussed this and and i want to say proof but at least"
  },
  {
    "startTime": "00:56:00",
    "text": "acknowledge that it's not standing in the way of this publication or something like that if there's other things that people want to add that would be also good to know i would like to ask the chairs for these suggested edits to a bit more actively asked whether there's consensus for this edition otherwise we are sort of again in a situation where this grab back of things that people want to add we don't really know what has consensus and what hasn't thank you okay um if i recall the discussion if unless i missed something in a discussion the only person who came to the mic and said it should be experimental was lars attempting to be a sock puppet for for makuu like you're kind of trying to like express his opinion without him being here so if if either of the one or two people who support experimental rather than proposed standard could actually like say something about it i think that's sort of customary um at least to give them an opportunity to state their position thanks okay and so okay then i can i'd like to do final you know both so publish to because it is why not this is last four you put a comment oh it's some point okay this is really interesting okay"
  },
  {
    "startTime": "00:58:00",
    "text": "there are several okay michael you want to make a comment yeah michael now i'm i'm afraid to say that because i'm not going to make myself friends with that but i think the statement that corey wanted if that doesn't elaborate on what specifically is wrong about the document or what specifically these points were that marco brought up that i think are important in in some way at least then that text is confusing to anybody reading it right so you have a ps rfc that says something's fishy here but we're not telling you what so i i think that this text should actually elaborate a little bit on on the specific issues that marco brought up could be just an appendix but i believe that text would probably be important to have okay and now i'm hiding okay let's stop reporting here and vidi you want to make some comments um yeah so um i just want to reply to michael that we have been making changes based on marco's comments and writing those uh if there are some open issues where writing or putting them in the draft for the reader to be aware of um at this point it isn't clear exactly like if there are suggestive texts that marku or anyone else would like to add would be really happy to add it and um that would require some participation um and you know some that commitment to make that to to get that done um and um so so you know there are lots of emails that marco has sent but what we have been asking again and again is if there is something you have a specific suggestion that we could add to"
  },
  {
    "startTime": "01:00:00",
    "text": "the draft that would be great um so just you know it would be good to hear that okay so i i did not want to make this complicated and i haven't followed the last emails from marco anymore but i remember that there were things about having to update uh probably 3168 about something and and some procedural things right that that he had heavy disagreement about now i don't remember if that was all resolved or not and i mean okay i'm fine with publishing without having that thing in i don't want to make it complicated you really don't but if it's possible to state why there is a procedural problem here and why that thing gets published nevertheless other than just saying okay it's published because there is code and is deployed i mean if we could be a bit more elaborate than just something something saying something's fishy about this rfc then i think this would be valuable if we cannot i'm not going to make a point about that i mean it's okay i still want i think the primary thing is that this should be a bs okay thank you so much i think we have lots of discussion and that we can get a lot of good data point and then we are running out of them so um i think we can you know so cheers can discuss a little bit more about how to proceed with this draft and so thanks so much billy now yeah let's move on to the next presentation bob so we are short in time please if you can be faster than clan that would be great that would be great all right um do i i've asked for a slide request i don't know what happens"
  },
  {
    "startTime": "01:02:02",
    "text": "you should mix strider requests i have really i don't see okay screen or yes yes oh screen okay to be honest i've never done that before okay can you now say it not yet i can see a shared screen request open isn't it asked to share slides yeah that's what i thought that's what i did and then yoshi said share screen so can you try ask to share slides and then you will no no yes right sorry yes yes right yeah no screen yep cancel screen request hang on it's responding very slowly sorry um we will get there time is running yeah i know yeah okay we'll i'll talk while while we're waiting for this um this is um sorry it's it's saying do you really want to share your screen i've said no and it's just hanging um okay um this is going to be a talk about accuracy and feedback it's draft 18. go away there you go right now try that is are the slides coming up"
  },
  {
    "startTime": "01:04:02",
    "text": "not yet yeah but yes finally yes okay um oh no it's gone again a new slide deck is being shared it's saying okay name is here let me celebrate him okay we can see it right so am i controlling this or are you you are yeah can you move on yeah yeah so skip the next slide uh as well which is a recap of that there's a three bit ace field and some 24 bit option or with 24 bits plus headers next okay so recent draft history um there was a long hiatus after july 21 but then um like all good buses they come in threes um and so february march time we've had three there's links there to the summaries of the diffs in each of them which i'm not going to go through in these slides but there are spare slides at the end that do and thanks to ilpo vidi gory richard and myself actually for noticing some unclear parts but um i will go through um most of those contributions and also just to mention that there has been some conversation between quick authors and the um accuracy and authors about how to deal with um act frequency so next uh just really news on implementation there are two main implementations one in linux one and three bsd uh the linux one is reasonably up to date but it's a couple of um"
  },
  {
    "startTime": "01:06:01",
    "text": "draft versions out of date but um there aren't that many things to do rich has been implementing in freebsd there's link to his implementation there it currently emits handling arriving tcp options but it sends them and i'm going to talk about that more later next um so this is about the main activity that's been going on recently on the list um based on a review comments from vidi asking about how you deal with any congestion feedback coming in when you're not sending using capable packets so um there are a number of cases where you might not send incapable packets because there's um a handshake at the start that checks whether there's a mangling going on if there is mangling you you still remain in actual etn mode but you don't set ec and not uh acn capable on your packets that you send out but then video wondered well even if you're not sending ecn capable packets what if you get um congestion marking feedback coming back and there are four possible three possible ways we can think of doing this a b and c here the um in all cases you would turn off sending ecn capable packets but it there's a difference in how we think you should respond to congestion if it comes in as shown in the right hand column and we'd like some discussion either now or on the list of whether these um the rationales for these make sense so the first one is if during the handshake"
  },
  {
    "startTime": "01:08:01",
    "text": "you see um some sort of illegal transition going on like either you send a non-easy packet and you get get back feedback that said that at the other end it was received with ecn capable or you said 18k on the other end it says it was non-sync when it comes back etc etc um then the you you might think well it's not going to have any congestion response but it might if the mangling is turning on ecm capability and then later on there is um some congestion that is um doing normal congestion marking so the idea idea there is that you you respond to congestion if you um see any feedback even though you wouldn't expect to see it right um in the in the b case um if you see continuous congestion feedback then you don't respond to it especially if you're if you're not sending um ect but even if you are that probably implies there's mangling going on that's that's asserting um congestion experienced all the time and the third case c if you get a zeroed um ace field which is this three bit field um you shouldn't see that at the start so that probably means a broken receiver or something's wrong um and therefore it's probably best not to respond to congestion and just um if you know just solely rely on loss so um we've written that all up in the drafts we went through a stage of having must and must knots for all those things and then it was suggested that we should make them all advisory rather than normative because with deployment experience there may be"
  },
  {
    "startTime": "01:10:01",
    "text": "unexpected things going on that we need to deal with so we didn't want to tie things down too much okay so that was quite a complex slide but um please respond on the list about any of that next slide please so um in the process um of these latest edits i did a review of all the lowercase mustang shoulds and mays and recommended things and changed them all to needs to or ought to or might um so that they were not um and had no potential of being red and red ambiguously as potentially meant to be in capitals there were just two cases where i changed lowercase recommended to uppercase um and i think they were justified one is it said already in the introduction it's recommended to implement sac and ecm plus plus with accurate ecn and um made that um uppercase and similarly there was one saying it strongly recommended to test the path traversal of the accuracy and option and given it already said strongly i figured that was quite reasonable to put normative there but if anyone wants to object to that please do so on the list or now at the mic um next slide um there are um as i said spare slides with all the detailed changes and i've also posted um each one to the list there are only really three technical changes all the other changes are just trying to clarify normative text usually the three technical changes are all that stuff i just mentioned about congestion response if not sending ect then there's a change where um we've allowed seven um packets to go by before you um have to send some feedback rather than six um because the rap is at eight and we couldn't really think why we'd"
  },
  {
    "startTime": "01:12:01",
    "text": "said six so we changed it to seven um we've just been conservative and the third case um is a bit of a fallout from when we changed the um tcp option accurate ecm tcp option so we had two different tcp option orders if you remember we went through that episode of changing it and you noticed that we hadn't um changed the initialization of the two um fields from how it was originally when we only had one option or one type of option so we'll change that okay um next slide a couple of upcoming changes um this slide the first one um gauri's recently very recently been talking on the list about how he's not happy with this um accurate ecn draft updating or 3449 which is about network path asymmetry um and originally i thought it should update it because it said oh three three three four four nine said that act filtering middle boxes ought to make sure that 3168 feedback works and so i thought well as we're changing 3168 feedback we ought to update that advice as well um but there is an argument that that advice in 3449 isn't normative so maybe we're not updating it so i don't mind going with what gory says but maybe other people want to chip in on that point but whatever we're going to try and change the text to outline the problem and discuss possible ways forward without recommending any changes and without updating 3-4-9 but if people feel strongly we should"
  },
  {
    "startTime": "01:14:00",
    "text": "update three four four nine then please say um next second upcoming change and i think just one more slide um through the experience of richard's implementation and ill pose um found that actually sending it accurately an option is the easy part of the code and handling the receipt of it is the difficult part and so whereas it currently says if you don't want to implement the um accurate ecn option at least consider implementing um if you don't want to send it at least consider receiving it we want to change that round too if you don't want to implement receiving it at least consider sending it and then that means that the other end if they implement it at least it will work um even if you're ignoring what they're seeing so it gives a little immediate gratification of the um other than dealing with the um upcoming changes one of which is still working through that um filtering section with um with gauri and then writing text for that um please could the people who asked for the recent changes just confirmed they're okay on the list or not and otherwise i think we're ready for working group last call and as i mentioned earlier generalized ecn depends on this one [Music] okay thank you bob"
  },
  {
    "startTime": "01:16:01",
    "text": "so jonathan please be quick okay two quick things uh previous slide number nine um this proposed change would be the opposite of the interoperability principle i.e be uh conservative in what you emit and generous in what you accept um the other thing i would note and i've put this on the list in the past couple of hours is that i think um the accurate request which i think will be seen uh shortly or talked about shortly offers an alternative way of getting generalized eats the end on so we'll talk about that in more detail elsewhere okay um i can i respond to both those the first one i don't think this is about liberal and in what you receive or send these two cases um they're um in either case one end is is not doing something and the other end is doing something so i i definitely don't think this contravenes that principle but if you've said this on the list i can respond there when i've fully understood what you mean and the other case i don't also see how um the act create requesting makes um generalized ecn or does it realize this year and it seems that generalization is a different thing it's trying to make control packets um he's incapable which i don't see how that relates directly to the outbreak but um"
  },
  {
    "startTime": "01:18:00",
    "text": "okay um thanks for the rit 349 proposal on the list i'm very happy with the direction that's going i'm sure the rest of the documents pretty ready the one thing i objected to reading which you did not pick up on was the strongly recommend i'm not sure our ad would be that happy having a strongly recommend can you can you just replace that by recommend and say why it's so important because it is important yep okay i can do that yeah okay so they'll still need more updates i think um okay yes let's continue the discussion a little bit more and then we can think about you know if it's ready for working group restaurant or not sounds good park thank you okay thanks so much so okay so moving on to the next presentation chorus so if you can be a bit faster than planned that would be really great yeah i'll try it so should i ask to share slides or yeah if you want if you want to control your stride yes i think we also need to get lost lights off i think quite yeah because i'm seeing like i can control bob's slides white okay maybe i think it shows me that yoshi is sharing the"
  },
  {
    "startTime": "01:20:01",
    "text": "slides why is he wearing i just stopped sharing slides yeah [Music] car should i ask again two shares yeah and we have some small voices in ian's background again i think okay i don't see my slides here coming up maybe the new deck is being shared no again i didn't find my slides on the list maybe if you can control them uh yoshi or perhaps i can also share my screen whatever you prefer okay it might be easier to share your screen if you have it open it's probably the fastest option you're working okay sorry okay can you see the slides now okay thank you my name is carlos gomez and i'm going to present the last update of the draft entitled tcp a great request star option my co-author is john cochran from the university of cambridge first of all let's take a look at the motivation for this draft delay dax is a widely used mechanism which is intended to reduce protocol overhead however in some cases it may also contribute to suboptimal performance we can identify two types of scenarios"
  },
  {
    "startTime": "01:22:01",
    "text": "here the first is so-called large congestion window scenarios that means when the congestion window size is much greater than the mss where saving up to one of every two acts may be insufficient for example in some cases there might be performance limitations due to a symmetric path capacity and also in some cases we might want to reduce further the computational cost and network load then there's also so-called small congestion window scenarios that means with the congestion window size up to the order of around one mss for example this would be in data centers where the bandwidth delay product is up to the order of one mss and in this case the led x will incur a delay much greater than the rtd and also in transactional data exchanges or when the congestion window has decreased the ability of requesting immediate acts may help avoid idle times long faster congestion window growth so about the status of the draft perhaps if you may recall before creating the draft there was some prior discussion on sender control of tcpx which appeared at least to me to convert to defining a new tcp option serving two purposes the ability of requesting a given upgrade and the ability of requesting immediate acts so today i'm presenting version zero three which aims to address comments from yoshi michael jonathan and bob many thanks for the very useful and helpful feedback so let's go through the updates in zero three the first one is in the main format of the option uh previously we had a six byte format and now it's just five bytes basically we have remove the field called n uh here this was intended so that when r was set to zero the sender could"
  },
  {
    "startTime": "01:24:01",
    "text": "request immediate acts for the next n segments however it was found that this was mostly redundant so it's possible to produce the same effect without an explicit field called n and then also in the new format the size of the r field which corresponds to the ack raid requested has a size of six bits and also there's one new bit which would be at the moment reserved this is called v so for the r field there there are like two possible encodings on the table the first one would be like the straightforward approach which is the binary encoding of the requested ack rate by the maximum value of r since we have 64. sorry well six bits is the maximum value 63 and then the second option is one of those which were suggested by bob where there would be four beats dedicated to represent a mantissa m two bits for representing an exponent e and then the requested act rate would be computed as you can see on the slide and in this case the range of possible requested values for r is greater although there's better granularity for the lower values of r um well i don't know if there are comments on this or perhaps we can discuss at the end by the way since i'm sharing my screen i cannot see at all uh the queue okay so um okay so then we also have updates in section three which describes the behavior of the sender the receiver first we state that a direction capable receiving tcp should modify its aggregate to one and every r receive data segments from the sender and this used to be a must in previous versions however it's been modified to"
  },
  {
    "startTime": "01:26:00",
    "text": "shoot because actually there may be several reasons why a receiver might not be able to satisfy the request for example lack of resources also security as i will mention later also we've clarified that r equal to 1 means that the receiving tcp should send an arc immediately but r equal to 0 is not defined at the moment maybe pending how we finally represent r in the field before then we've completed a bit the description of announcing support of the tar option and here by the way there was a suggestion by bob about well considering due to the the lack of space in scene package that perhaps we might want to include the support of tar option only in response to a synagogue so i don't know if there may be comments on this also there was another suggestion to aggregate this option with others as in yoshi's draft and another clarification is that a tcp segment carrying retransmitted data is not required to include at our options so if the original segment carry the tar option uh the retransmission is not required to to also carry the same star option and then uh there have been several comments about the ignore order feature uh here this was suggested once in a previous tcpm meeting the idea behind the future would be to allow a sender tell the receiver that it has some tolerance of our data packets so then it's not necessary for the receiver to uh to send immediate acts when there are like ignore uh well reordered uh data packets however it seems like uh the benefit that is seen from this feature is not so clear or not so significant so the proposal that we have like on the"
  },
  {
    "startTime": "01:28:01",
    "text": "table for the next update of the draft would be to just remove the feature so i don't know if there's comments on that as an individual so on the mantissa thing um am i correct in saying there's no way to express zero without encoding sorry could you repeat on the mantissa formula you have on the previous slide yeah there's no way to express zero in that encoding i'm not mistaken yeah but isn't zero a part of the doesn't zero have a meaning well it used to have but now it doesn't have yeah say no more all right next slide please um so if you send the tar with in response to senec that is not sent reliably so isn't that a concern yeah so that's that's one point and well i understand this was a suggestion to to try to somehow deal with the lack of syn space but also perhaps we can just not consider this this approach yeah great thanks thanks for the comment yeah okay so if there are no other comments then perhaps hi uh one question so i yeah so in case of option two the maximum value of r is 124 which is very big i don't know which what kind of use case to have such kind of large value for r yeah i don't know if maybe bob would like to reply himself but uh it seemed"
  },
  {
    "startTime": "01:30:02",
    "text": "like some people mentioned that the maximum value of 63 could be fine however bob considered like the future so when this option might be used several years from now and perhaps the capacity of links change and so on so i don't know if maybe bob would like to also add something um or put it on the mailing list since we are really short of time gory no no sorry sorry we can't get it to the mailing list please yeah gauri gori fergus i favor option one and i don't know any method which is safe at 63 we currently have iw10 so how how bigger than how is bigger than 10 safe it might be but i don't understand how big in the 63 would be safe by our current safety requirements yeah thanks for the consideration so perhaps the the point that bob had was considering maybe not today's scenarios but maybe future scenarios so the idea was being able to"
  },
  {
    "startTime": "01:32:00",
    "text": "support like larger values but yeah that may be of course something to take into account that also a very large value may have issues as you just explained thank you yeah okay thank you so much i think no this is you know good one i think we got lots of feedback seems to be people seems to be supportive so let's continue the discussion and then update the draft thank you so much okay and next presentation bang what is my screen available yep yes song is good but no not the green i i'm starting showing it somehow it hasn't started yet but you should be granted okay [Music] okay right i think it works right okay uh hello this is pony from china mobile and i'd like to pre present the multiple tcp robust session establishment and since this work has been presented in the past years i'd like to have a recap of it first this document want to solve the problem of connection setup failure that is essentially caused by establishing a connection only on default paths with unknown path letters"
  },
  {
    "startTime": "01:34:00",
    "text": "when we use multiple multipath protocol the session will be established in a sequence and the default bus is selected as the first one by default ule maybe wi-fi if there is no wi-fi signal 405 gxs will be selected however when the wi-fi signal is bad and the delay is large the default path can't be established which will also affect the link of the second connection so this problem is a real one and has been occurring during modified protocol deployment and implementation i believe some people have met this problem pay attention to it moreover even if the current document has a focus on btcp we think it could be expanded towards antique and btc support with which has a similar initial path grant and [Music] here's the definition for a robust decision establishment it is a set of extensions to regular mvtcp and btw version one is designed to provide provide a more robust establishment of mptsb sessions it has four methods including 1 theme and e3 and ips it also presents a design and the protocol procedure of the combination scenario in addition to these standard alarm solutions for example the combination of the same and ips and combination of timer and rps so a very short solution recap of those methods first is a timer one uh"
  },
  {
    "startTime": "01:36:00",
    "text": "result let's say again to network voltage is achieved by modifying the thing uh retransmission type timer if one path is defective another path is used and for the same one provides the ability to simultaneously use multipath for connection setup and rst is used to terminate connection setup on other paths when connection has been established on the first path and there's also the ethereum provides ability to simultaneously use multiple paths and i mean joint cap is used for decreasing overhead merging all simultaneous established path without a joint process so the ism can be used for negotiation between both sides and the final one is ibs provides a huge risk to select proper property and initial paths for connection establishment with a remote host based on empirical data derived from previous connection information so this draft has been presented several times from itaf16 and the last presentation was in idf for the iso is negotiating with shares the possibility for getting rid of the ipr blocking issue towards adoption of it so the uh criteria is something that authors can work on by taking to the other people who need the publication of the unwanted the update for instance a presentation"
  },
  {
    "startTime": "01:38:00",
    "text": "from the network operator rather than dealing with test results of the suggested mechanism would be interested input to the working group so in this case i found this work was really valuable and also planned for the joint testing work but due to the coverage uh it is too hard for us to find a place to do it so i checked the test before and it showed the obvious effect efficiency of this method and there's also the three start forms one or six you can see the demo and the hexane will be done into uh i can one seven and one eight so i just reviewed the overall work um the draft check them demo and the ipr disclosures with the license this draft has major enough and completed i wish my joining without ipr issue could help to promote this work so i'd like to ask if we could call for adoption of this draft thanks and any comments hey that's you yoshi will you go first we can hear you here she is still muted yeah [Music] so can you show the slide of recap zero one zero this one okay and then so it says that i i would like to talk about criteria one so it says you have"
  },
  {
    "startTime": "01:40:00",
    "text": "presentation from a network operators and which dragon and then after that with testing result of the suggestion makers will be interesting so what's we expect not only showing support this is yeah good things having support is very good thing but uh um what we really expect is you know showing some experience or operational experience by implementation experience and then um you can demonstrate that this is a great idea and then at the same time um since you are not also we can know how you deal with the ipr issues and that kind of information will be very useful for us to think about how to proceed around but just supporting is just one step but we need more steps that's my comment yeah okay uh in fact we we plan the test and other more things but haven't been successful so you mentioned that the idea can also be applied to mpdccp and be quick sending doing connection setups simultaneously or wire timers is something which is done in sctp though so there's prior art for other protocols do your does your ipr cover also mp quick and mpdccp are is your ipr specific to mp or tcp uh i think it only cover a btc but maybe the others could clarify this question because normally you write iprs in a very wide scope that's why i'm asking and the other question is for this stuff being deployed is it"
  },
  {
    "startTime": "01:42:00",
    "text": "needed to be implemented in an open source operating system or is it um okay if it's only implemented in proprietary systems okay thanks okay any more comments um okay yeah i think as i mentioned that you know showing support from you is very good and for the draft but it's still a little difficult for you know we can think this is ready for working group adaption because as i mentioned no i want to see more broad support or you can show some more solid test results or implementation experiment then you can convince people that this is not good item for this parking group right now it just was just one support so i think we need more supports or more experiments that's my take yes i think we will unvoice so should i stop to share the screen yeah okay thank you thank you peng so then so next action yes can you hear me yes i can hear you okay you have the 17 minutes we have left okay we'll try to make it a bit faster than planned to leave some room for a discussion because that's really the intent of presenting our work here in the tcpm um so yeah first i would like to to thank tcpm for giving us the opportunity to to"
  },
  {
    "startTime": "01:44:01",
    "text": "present this track for the first time within itf so this strap is called tcps modern transport services with tcp and tls and you might be wondering whether tcpls is an acronym it's actually not an acronym but it conveys the idea that we can bring tcp and tls closer and this has benefits and we can bring new transport services with this combination um so i will not detail the content of the preset presentation we will look at that just just now um so um first as an introduction i would like to go back to uh two important uh protocol that have been designed um within the itf and that extended the transports the transport services provided so the first one is mptcp which started in 2009 and the first specification shipped into 2013 and enabled bandwidth aggregation with several subflows fade over in case of network failure with a make before break or break before make um mechanism and it was made in a way that was backward compatible with tcp so so those were the main benefits of of mptcp but it also had some issues so the address exchange mechanism was not really secure although it improved it improved in v1 and it used tcp and the tcp options um which are prone to middle box interference and so that really drive the design of mptcp and made the design um a bit more difficult to to make so um mptp also proved to be maybe difficult to implement and i think we can take the seven year journey from this v0 specification to mainline linux as an example as an example of that of course many things happen in that time frame but still it's a long time"
  },
  {
    "startTime": "01:46:01",
    "text": "so another important protocol that was more recently designed is quick which started in 2016 with the goal of designing an udp based transport protocol and which the first version of the protocol was shipped into in last year actually and it enabled stream multiplexing without head offline docking and connection migration and failover as well and one of the the key elements i see of the success of quick is the use of tls to secure most of the quick header and the quick payloads because that's really what enabled an innovation to be brought back and effectively deployed in the transport layer and quick can also be implemented in user space and ship with application which has a number of benefits so i think an important point um that we we need to look at today is that we know that tls is the most used uh protocol at tcp and the latest version uh is even expanding the the use of encryption to extend the tls protocol with encrypted tls records and encrypted extension um and and together with the fact that tcp supports in the network and in operating system and kernel remains wider tcp is also the fallback of quick currently still so tcp will remain for a long time and given the ubiquity of tls and the lesson we learned when designing quick um the question i would like to to ask is or it's a rhetorical question of course but the question is can we provide new transfer services with tcp and tls and and the answer in this presentation is is of course a positive one uh we believe that by using those two elements we can build an encrypted transport protocol um that brings"
  },
  {
    "startTime": "01:48:00",
    "text": "modern transport services to those those services are stream multiplexing where the app can choose the degree of resilience from stream to others resilience to head offline blocking it can also offer connection migration and failover and multi-path by scheduling at the tls record levels this is something we will look of course in the details of the protocol so having this combined approach we believe that the protocol can be more efficient than http 2 tls and mptcp because those protocols were designed on a strict layering assumption and so it makes hard it makes it hard for an application on top of http 2 to influence the mptcp scheduling but also taking into account the record level of tls so let's go over the protocol and and put the focus on how we brought the services that we mentioned in this protocol so let's start first with the session establishment the tcpls session establishment so one of the key facts is that tcpls does not modify the ttp or tls handshake what it does is is introducing a new tls extension that indicates the support of tcpls so here this extension is exchanged um in the the sequence diagram in the client hello extension and in the server hello extended extension and at the end of the tls and shake both end points know they use tcpls so the the sequence diagram shows a regular tcp connection opening and a regular tls handshake but this our proposal is compatible with tcp tfo and tls xero tt as well so the first service i would like to introduce is stream multiplexing and streams provides concurrent byte streams to apply to application and and tcps manage those streams and"
  },
  {
    "startTime": "01:50:01",
    "text": "enables multiplexing over a single connection so this is reminiscent of what http 2 brought to to the internet so if we look back at our diagram and see how it is implemented we added a framing layer inside tls application data records which is called tcps frames and frames compose the the record and so if we look really closely at what happens on the wire when tcpls receiver receives a tls record well it first sees the header which is in clear text which indicates that it's a tls application data records for the given tls version and then when it removes the protection it has another tls record here which is the clear text record and this record contains the series of tcps frame here it's a single stream frame we will not go over the details of the fields i think all of you can recognize very strong similarities to what have been done in http 2 and in quick so obviously um as you probably wondering now um those streams put in a single connection are subject to edifying blocking this is equivalent to what have been achieved with http 2. so what we propose is also a way to for tcp allies to manage several tcp connection in a single session and schedule the records across those tcp connections and then by giving the possibility for the application to map the streams to connections the application can can choose the stream it wants to protect uh from other flight blocking from others so here in our example we have stream a and stream b on a single connection and then stream"
  },
  {
    "startTime": "01:52:02",
    "text": "c and stream d on this on another connection of the session and so stream c and stream d will be protected from that offline blocking happening on the first connection and uh involving string stream a and stream b so this brings the question of how can we add tcp connection to a cpls session the mechanism we have designed involves the server giving tokens to the clients and the clients using those tokens to open a new connection so here we have the server giving a token inside a frame so this token has the value abc and it has the sequence number uh one by controlling the number of tokens given to the client and the server controls the number of connection what the client can do is then open a new tcp connection and then use another tls extension which is called tcplus join using this token value and the server use this token value to identify and join the tcp connection to the tls session and then at the end of the of the token exchange the connection is open and it has a given connection id which we will detail uh what it is used for in in the coming slides so the question uh now is what kind of crypto material is used in this additional connection so if we look at tls uh tls encrypt each nonce using each record sorry using a unique nonce and this is the the non-derivation that is specified in tls 1.3 um so this nonce use the record sequence um to to get the the the nonce of the of the record and the record sequence is implicit in ts 1.3 um it is implicit because tcp delivers"
  },
  {
    "startTime": "01:54:02",
    "text": "data in sequence and so the sequence can be kept implicit so as is we cannot share this sequence among tcp connections of a tcpl session because then the receiver has no way to to know which uh record sequence uh the the incoming records are and so um in in the sequence diagram i've shown you i've shown you some tls message that resembles a tls handshake but actually we do not want to do a full tls handshake and then and derive a new initial vector for instance because that's this is costly and so what we propose is to change the initial vector uh non-script construction sorry and add the connection id so the id of the tcp connection part of the tcpl session and claw it to the upper bits of the iv and by doing that and keeping a per connection record sequence we now have back a unique nonce for each of the records sent in this tcpls session so it's really a way to share the tls session among several tcp connections another service we would like to um to provide with our protocol is a failover and so in failover um the the idea is that when a client has here an example a client has opened a connection to the server and sends two chunks of stream stream a and string b and something bad happened to string b it never reaches the server and actually the wall tcp connection is disrupted either by the middle box or by a network failure for instance so what failure failover enables the sender to do is to retransmit the frames that were lost onto a new tcp connection it could have been established before the fader or even after"
  },
  {
    "startTime": "01:56:01",
    "text": "so how does this work on the wire if we go back to our sequence diagram and and look at what happens in this particular example so we have the client sending um to connection id we have the the client sending sorry two tls application data records over connection id 0 and the second never reaches as i explained and the connection gets disrupted the question becomes how can the client know which one never reached the server and retransmits uh the one needed and so for that we introduce tcpls acknowledgements and so those acknowledgements enable the sender to know which are the tls records that were effectively received um we cannot rely on on tcp acknowledgements because they just mean that the byte stream reached the receiver but we do not know whether it was read by the application whether it was stuck in the kernel buffers or whether the decryption was successful and so that's why we need those acknowledgements so those acknowledgements identify records by stating their sequence number in the given connection so it states the connection id and the mo the highest tls record sequence that was received over this connection so it only needs cumulative acknowledgements so here in our example the server could send a knack to the client sorry it states server cid on on the right hand side is supposed to state client cid so the server sends back to the client a knack and indicates that on cid 0 it has received up to sequence number 3 and then the client can make the right decision and retransmit the loss frames and eventually those last frame get acknowledged as part of the the records containing the two acts on the bottom"
  },
  {
    "startTime": "01:58:02",
    "text": "so using all that we are also able to do bandwidth aggregation simply by chunking a stream in uh some stream frame and then send them over different tls records over the two connections so i've tried to quickly present the protocol here uh it's more it's more uh explained in detail in the in the draft we're very welcoming any feedback and comment on the draft either on the protocol or the use cases the services we we presented we will continue working on this protocol there are obviously some part that needs to be discussed and designed you probably didn't mind congestion control and flow control we also do of course but also maybe looking at further ways to use the tls extension to to to enable new services in ntc pls or even some how to make the receiver um zero copy as in tls 1.3 and all those kinds of stuff we're really interested in looking in the future um so the draft follow the prel preliminary version of the tcps protocol that was presented in a paper at conex21 that you can read if you're interested in more details on our approach we got also some early implementation feedback as we have implemented the last the latest draft we've implemented it on top of a tls 1.3 implementation in c called fico tls this required us to modify 50 lines of the pico tls library so to um to implement the the iv nonce construction i've presented and we were able to implement stream multiplexing failover and multipath in about 2.5 k lines of c codes um and this product this prototype will"
  },
  {
    "startTime": "02:00:01",
    "text": "be released under an open source license in the in the coming weeks um so there is not much to say left in the conclusion except that we're really welcoming any uh feedback and comments on our approach and maybe one way to start discussing this work because we're not looking for tcpm adoption would be to to start a mailing list to discuss with interested people so that concludes my discussion my presentation i hope we have time for discussion now okay okay i want to make a very quick comment so this is uh basically application protocol it doesn't require any modification tcp so that means the focus of the draft is slightly different from focus of tcp and working group yeah i think it's interesting for tcpm people because uh also people that participated in mptcp um are have joined the group and here we're touching on services that are addressed by mptcp and we believe tls opens a new way to address those services so that's why we think the presentation was fit here yeah it's certainly a transport topic but i'm not sure this should be the venue of the working group but we can discuss later jonathan jonathan hoyland's club so first obviously it would be really nice to see this in the tls working group i feel like this is messing around with tls in a way that we haven't seen before um"
  },
  {
    "startTime": "02:02:00",
    "text": "but my my question which i've put in chat is is is there a reason why you're you're doing something special with new tls sessions rather than just using new session ticket and resumption to split out one tls connection into multiple ones um so so this is also something we've briefly uh imagined but we never really looked into that actually the the way we changed the nonce construction is quite simple and doesn't require the server to issue those but issue a bit simpler uh values which are those tokens i presented but this is something we could look at whether using this um is is more fit and requires less uh stuff to invent than the normal proposition yeah yeah because with tls it's seen lots of formal analysis and lots of like security work yeah so inventing new bits and hoping they work is very scary yeah but the the the change in the iv that we propose is very reminiscent of of many discussion i i've i've seen at the atf so this is stuff that they're considering for mp quick for instance and i think i've seen some discussion in that part for dtls although i don't remember um for which mechanism it was maybe key recognition negotiation or something yeah uh crypt analysis by intuition is generally not recommended i get your comment i get your comment [Music] okay we are running out of time any more comments okay yeah this is interesting idea but yeah we are still not sure if this is a topic for tcpm so let's continue the"
  },
  {
    "startTime": "02:04:01",
    "text": "discussion on the tcpm mailing list of course yeah thanks so much thank you okay thank you so this is uh we have our presentation thanks so much for your participation thanks for very thanks so much for very productive discussion so see you next itf thanks so much yes yoshi will you copy the notes yeah but uh i'm going to go back right now okay bye bye"
  }
]
