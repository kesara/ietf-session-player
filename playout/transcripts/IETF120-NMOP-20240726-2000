[
  {
    "startTime": "00:00:16",
    "text": "Good afternoon and welcome to the NMOP's working group It's 1 p.m. and we've got a lot of cover, so we propose to start now So again, welcome to NMOP. I'm Bono Claes. The co-chair Matt, is not able to make it physically, but is on online. I met. And to help us, we've got thomas graf next to me, who's a secretary for Enma So let's start with the first series of slides, the chairs slides Note well, it's Friday afternoon I hope that you noted well the during the week. So basically whenever you attend this meeting, you agree to follow the IETF person policies etc really well that we're going to behave professional in this working group and that if you believe that you are harassed or victim or witness of something there are procedures for that so they are described in this slide slide So make sure that you lock into the Datatracker. This is required for asking question and to go in the queue If you are removed, feel free to sorry, make sure your audio and video are off unless you're speaking the agenda we have like four different projects in this working group So we're going to cover all of them"
  },
  {
    "startTime": "00:02:02",
    "text": "Young Push, Network and Nom and incident management digital map and update the operator requirements. There is one example session on knowledge graph is there any agenda bashing Okay, hearing numb By the way, thank you, Jean, for having, for being the note taker. I cut and pasted the link to the meeting with notes in the chat. Feel free to help on that front We have like three working documents. This is the second time we meet physically and two of them will be present this time The Yang message broker and the NMAP technology for network analysis anomaly anomaly We, if we look at the milestones, we have two milestones coming adopt a document on updated opportunities and adopt a document on network anomaly management and we're going to discuss those two during the meeting Regarding liaisons, we send three liaisons out We received a reply from TMF with a detailed analysis and a copy of two TMF specifications And we have some actions to follow up Authors, please help There are two great points at the bottom So, interim meetings we had an interim meeting in June regarding the digital map"
  },
  {
    "startTime": "00:04:02",
    "text": "and we have one schedule for September 11th on network anomaly and we are considering having an extra interim meeting between sorry before i IETF 121 on digital map us any comment suggestion about interims I want to hire highlight one specific point. This is refresh that out of the three projects we have in this working group that have code, the last one being the update of requirements, all of them are covered in a hackathon with actually a lot of people involved. I've been the IETF for long time. This is actually refreshing to me that we've got code already at the second physical meeting. Thank you okay open mic if I permit Okay, so let's start with the project number one which is about NetConf, Young Push integration Maybe one last thing Matt, is there anything that I miss that you want to add to what I see? No, no I think that we can just proceed. Thanks. Thank you So the presenter is Thomas thomas Hello, everybody. So we want to present some updates on the architecture for Yang push to make So we want to present some updates on the architecture for Yang Push to Message Broker Integration We go in the beginning some just refresh on the document introduction. What's the why?"
  },
  {
    "startTime": "00:06:02",
    "text": "the reasoning behind this architecture, what we try to achieve, and then some status and next steps, what has changed recently And then I would like also to take the opportunity to give some explanations to the current ongoing notification documents we're having in netcom NetConvent, how they are relating to this document So to look at the big picture, so we have with RFC in 79 seen 7950 Yang defined, which is machine and human readable but looking a bit in the industry and seeing basically how data is being organized in so-called data lakes or data mess we see that the network operators are facing challenges to deal with that data So we see in most of the cases that message brokers are being facilitated, especially we see notably Apache coffee there, but we see that there is a lot of manual labor needed to make the data accessible, or in other words, if I ask a network operator how long it takes from subscribing the data in the network to make it access in a data to the network engineers, the answers are never in minutes. It's either hours days or weeks, so there is manual labor involved and that's what we're trying to address here So at the end, our goal are there is manual labor involved, and that's what we're trying to address here. So at the end, our goal, our aim is we want to have an automated data processing line weeks so there is manual labor involved and that's what we're trying to address here. So at the end, our goal, our aim is we want to have an automated data processing pipeline, IETF should define the semantics of the operational matrix and network operators can gain actionable insights. And therefore, there are certain requirements on what are not notification message needs to contain and how this needs to be integrated"
  },
  {
    "startTime": "00:08:02",
    "text": "into the end-to-end data processing chain So just to give an overview on the different elements on the architecture, it's and I highlight a little bit in red what was changed in the recent revisions of the document. So we have at the down, let me try, yep, at the down here, we have the Manage Yang subscription, where we have first a so-called discovery phase that's RFC 9196, where the capabilities of the Yang Push publisher are being discovered, and then depending on the capacity and the intent of the subscription, then in step number two, the subscription is being done. And once the subscription of the Yankee push notification has been done, there will be a first, that's number three a so-called subscription start message being sent from the Young Push publisher to the Young Push Receiver, so that's the data collection And from there, through the Young Library all the dependencies are being observed that Through Get schema, the schemas are being op obtained and then registered towards the Young Schema registry where then for each schema a schema ID is being obtained. And when the first push-up, they then is being received from the Young Push Publisher and forwarded towards the message broker, that message can be prefixed augmented with that schema ID and then either at the message broker producer or the consumer, the message can be validated so we have now integrity. We know that the schema and the message are in line And out of the schema, we can also then"
  },
  {
    "startTime": "00:10:02",
    "text": "in the data consumer create in the data storage the table the schema there and ingest the data and make it available then to the network operation operator So what changed recently on the document is it got adopted at NMO Thanks a lot for your support and also thanks a lot for the review from Drouf, Andy, Feng, Queen Christ and Nacho. We addressed them all in the latest release in 04, which I just submitted a few days ago and there were some changes And so we have now let's say the biggest changes are in the introduction section we go a little bit more into the reasoning like why manual neighbor is currently needed and how basically this document is addressing it. Then in have in the, let's say, in the beginning added the RFC 9196 discovery phase. So before configuring the Yang push subscription, there is now a possibility to discover the couple capabilities and according to the capability and intent the subscription is being established Then we added for completeness also the message broker elements in the overall picture from the architecture and also added in section 3 message broker elements in the overall picture from the architecture and also added in section 3.8 a description how the observation type stamping is being used in indexing the matrix in the time series data and some I'll say, overall change on the boilerplate,"
  },
  {
    "startTime": "00:12:02",
    "text": "on security considerations, and also what was the concern, that we are more detailing the differences between how the dynamic and configured young push subscription are being applied to the architecture where are the difference in the two cases and last one at least, and it was the last update on 04. There were some concerns about to make the terminology a bit more agnostics so going away from the terms time series date and time series database ingestion towards data storage and data consumer So here, we are looking forward for your review and also your comments. We want to improve and push forward the document any further Any questions before I'm moving on or comment before I move on to the next slides Sorry, does you speak louder into the microphone, please? Absolutely, sorry Now better. Okay, sorry for that Now I come to the second part of the presentation so here we want to, I want to describe a little bit the relationship of the different Yang Push or Yang Push enhancements and also some addressing some of the Yang specification gaps or so which are implementation related and related also to the document itself. So the first one is on the NetConf event notification So this document is basically describing the Yang module for the netcon event notification had a part which is currently defined in"
  },
  {
    "startTime": "00:14:02",
    "text": "XST in RFC 527 the aim here is that all the different components from the young push message is now implemented in yang and can also then down the data processing chain being validated in Yang At the bottom, I briefly highlight the changes in the later revision. If you want to know more the details on the changes of the draft, at the very end of the slide deck, I added the details but I won't present them here then the second document is also related to the notification header and here we are adding to besides the already existing event time, which is described when the message is being serialized Also the CISNAM, the so-called host name of the device and the sequence number of the message itself. So the two elements are needed. First, of all, when the message is being received on the Yang push receiver and then forwarded down the data processing chain to the data consumer without having that information the data consumer is no longer able to add in from which network node this message has been published from Today, network operators mostly, I mean I don't, I think, without any accept need to augment that information at the data collection and uh have to look into the transport protocol to understand from which IP address the message is pushed from and then need to do a look up to find out what is the host name of the device and add it on top of the message. And with this, we add adding already the information at the source"
  },
  {
    "startTime": "00:16:02",
    "text": "and the data collection does not need to do that lookup anymore. The sequence number is become relevant to detect loss and reording throughout the data process chain, and is also very helpful when messages being replicated among multiple message brokers Then the next exam extension, and this is not related to the event notification header, this is now to the Yang Push subscription header Here we are adding the so-called observation time timestamp. You recall from before we already have a timestamp in the message that times describes when the message is being serialized to the via we already have a timestamp in the message. That timestamp describes when the message is being serialized to the wire. But the observations of when the data is being observed or when being pulled on the Yang data so this is being described here in the observation time stamping And depending on subscription type, that observation time is either in at the start of the polling process so when we are starting to poll that information from the Yang data store or in case of unchanged subscription, at the point in time when the state change happened in the Young Data Store This one is also targeting the Yang Push subscription header, but this time not the push update or push change update message This is targeting the so-called subscription started message You recall that when a subscription is being created on the young Push Publisher, the Young Push Publisher in four the Yang Push Receiver that there is a new"
  },
  {
    "startTime": "00:18:02",
    "text": "subscription and define or explains what kind of subscription has been established, what's current missing is we have a next part but behind that ex-pass, we do not understand which Yang module name and also which revision has been subscribed That's one aspect on the notification. There is a second aspect on this document which is target to the subscription. And in the sub subscription today, there is no way of selecting a specific Yang module and revision in the X-Paths The problem here is it's quite a typical on a network operator that when the young publishers or the network node is being upgraded to a newer software release, that the young push receiver is not aware of that the Yang module revisions have changed Now we have two possibilities, one in the subscription to ensure that the revision cannot change, so in case it would have changed, then the message is not being published and the second one is through the additions in the notification in the Young Push subscription state change notifications we're now able to observe that such a revision change has a occurred Another part is we saw before in the overall picture there is a yang library The Yang library describes us the dependencies and also the dependencies on the different yang modules and also the revisions of the Yang models. But here, we only know which sub-modules are there. We do not know from which other Yang modules is"
  },
  {
    "startTime": "00:20:02",
    "text": "these yang modules have been augmented by and we are adding that here as a leaf then in the when data is being subscribed and being popped, in the notification, the reference to the subscribed data is done in the so-called data store contents with any data And there are already existing texts in RFC 17 15 section 710 which is describing in such a case what we should do with any data but that text is not very conclusive So this document is actually describing how that any data subscribed content can be validated with the young library So in all, these are the six documents, four below what we are, so that extensions are the notification and also on the Yang Library on the top, some specifications gap, so motivated explanation how any data can be validated and the Yang module for the notifications Any questions? I see Mahesh Nothing could like me thank you for fault for finally putting all the dependency our the integration gaps that you define in one presentation because I guess we're starting to lose a little bit of track and I"
  },
  {
    "startTime": "00:22:02",
    "text": "appreciate the fact that I think from an author's perspective you're trying to get the over the hurdle of not getting and not doing it in one document to begin with. So one suggestion and it's up to netcon chair ultimately how they want to modulate this is once this general agreement, that these updates are needed and there's work group agreement that maybe at a later stage you bring all the changes into a single document rather than having everyone revealed four or five different documents for each one or two lines of augmentations. But that's just a suggestion I think that makes perfectly sense Any other comments or? remarks as he can't? Sorry, I'll jump into the queue after. So as NETCOM chair, when would that happen? Some of these documents they're all individual drafts at the moment. Should that? come, should that happen before they become? adopted by the working group? Or could it be after the adoption when it goes to Alaska? So, okay. Yeah, maybe I should have clarified in my comment My idea was that once the work group agrees that these changes are needed and adopt them as a work group document and maybe even go through some discussion at some point in time you say okay you seem to agree that these changes are needed just at that point just consolidated thank you So these are currently the open points which we are working on and addressing and verifying in the in the hackathon"
  },
  {
    "startTime": "00:24:02",
    "text": "hackathons Here just some brief histories where we are coming from and our end goal is that by September 2025 that we can submit the final architecture document into I IESG Here, some status report on Yang push implementations, which we verify during the hackathon, so that already started at IETF 19 that's the current status of the different vendor implement and also different draft documents they have already implemented there is a hacker slide if you want to go into details There is a repository describing the test cases and also the outputs we achieved and we are looking forward to make further progress towards the next IETF 120 And thanks a lot, everybody at the hackathon who contributed on that that's really I think, a very good thing we want to make sure that the implementations we are doing here and also the suggestion we're making in the documents at the end. They should be perfect work and especially they should be interoperable That's the companies who are currently on board and collaborating with us, the cake, so we want to marry the two things, Young Push and Kafka And yeah, that's the last slide All right, very good. Any comments? Questions? All right. Knowing the number of time Yang Push was mentioned during this week, I'm supposed there is not a long line of people in the mic here but this is fine. Thank you I had a comment at night"
  },
  {
    "startTime": "00:26:02",
    "text": "NetConv, but there was no time Olga Harald for research So I just want to kind of mention that for cis name, I really think it's very important to have it. And if you look at that standards, they all have it in the notification and events. So I can't see how it could work without it. I would see it as a hack if you do it without it. I also think it could be useful to start considering it at the nodebound interface from the controllers. Absolutely Both comments very valid and the host name we took it from SNMP, RFC 12 so i think that's really common standard and I agree on other standards for DVC that as well. Yeah, thanks Thank you I think there's this pair So Paranation is Cisco as a contribute So I wonder how that would work with backwards compatibility when you introduce them because now we have RFC 86, 39 and 41 and they are not present there So how would you cater to if they're are existing infrastructure that has these that uses subscribe notifications or Yang push? Right. So we described that us aspect in the documents. So we have RFC 9196, which are describing the system capabilities also the notification capabilities, and we did the extensions in there. And also we believe that since the Yang push header so the IDF Yang push in from 86 for there and also we believe that since the yang push header so the IDF yang push in from 8641 you have a revision number on on that you have the augmentations on that we can do those changes and we also think that for the notification header which is currently from 5277 specified as an excess scene, we are different"
  },
  {
    "startTime": "00:28:02",
    "text": "a yang model this might be open in the future for four more extensions in there as well if the community agrees and wants those extensions Okay, I'll review those documents. Thank you. Thanks Yeah this is Alex. You just want to make one one comment from remote regarding the sequence number and the system name and so forth Actually, well, and why they are not included, actually in the original discussions and it's a little bit blurry and so all. It's been a while back but I believe we had actually explicit discussions at the time and decided not to include them simply by virtue of the fact that we're assuming that there's a reliable transport and basically the system well receiving systems that would be interested in that could of course do whatever stamping and something and basically the system, well, receiving systems that would be interested in that could of course do whatever stamping and so all they wanted, but they know basically over which subscription and association or our connection is associated with plus you have the basically the reliable transport property which made it not required to include the sequence numbers for gap detection and so far something which you have mentioned here is the as the as the law so this is just as a clarification maybe one question first from this is, do you foresee? in the future that to use this over unreliable transport? Because that of course, if you have unreliable transport, that would of course change the need for secrets now because otherwise it's it's a luxury that you can have but i which i which would presumably not be necessary to build a working system Thanks a lot Alex and by the way exactly the same question we had at NetConv. And I think what's really important here to point out is there are OSI layers and we should not mix the layers"
  },
  {
    "startTime": "00:30:02",
    "text": "together so the sequence number we are describing in the document are related to the messaging layer So in transport layer, it doesn't matter which transport currently we have we have net NetConv, we have ResConf, we have HDVS Notive, we have UDP Notive, all those trends mechanism has their own sequencing number. And you have to look at the entire data processing chain where the mess is being sent for the Young Push publisher over the receiver, over the message program towards at the very end And in the industry, it's very common to put in the messaging, on the messaging layer sequence number in the messages and that will help facilitating the find out across the data processing chain wherever there are loss reordering also helps in the replication of the messages okay so I'm minimizing the amount of post-processing people loss, reordering, also helps in the replication of the messages. Okay. Well, I'm minimizing the amount of post-processing, if you will, that needs to be received. Maybe that's something I need to reread or reread the latest revision of the draft but I think if this argument should just make explicitly just to document this and explain why it is here now versus let's take it to the list Alex if you don't mind yes sure. Thanks. Can you be very quick? Kent tagging on the purse comment, so I agree that it's possible that augmentation to um the end module for 8639 or 41 can allow the client to discover that these extra modules are implemented but no such is possible for 5277 headers in both cases however a Keep capability could be expressed where it's stated that the server supports. But still, it doesn't mean that client wants, right? The legacy clients, they don't know necessarily to even look for it, so they might be surprised if extra things show. So"
  },
  {
    "startTime": "00:32:02",
    "text": "recommendation is to allow the client to opt into it like through in this description request to have a parameter that says I wish to receive extra and so that's it, thank you. Perfect input on the capability side I think on the notification drive, we tried to put all the possibilities how this could be discovered we recover them. And on the configurable aspect, I think what would be interesting is we have later also the rfc 35 35 bs to discussion. I think it would be good to have feedback from the audience, whatever certain elements in a notification message or in general when you're receiving network telemetry data, what should be something basic we can count on is always present, yeah, and which one should be optional? Thank you. So, uh thanks. So the next one is on Network Anomily So feel free to come in, Adrian So we want to get first the report, report the outcome of the side meeting on the terminology from Adrian Adrian The slides are coming there is an anomaly well here we go So, yeah there's a draft it's adopted uh it's on, it's currently named network incident terminology. It's based on something Nigel and I put together and then we bought it thomas eichinger and Chowder to help us and keep us sane sane The origins are that way back actually before we"
  },
  {
    "startTime": "00:34:02",
    "text": "even formed the working group, I think, it was, clear that we were all using similar terms, but not necessarily meaning the same thing and actually I think we were all quite happy with the way we were using the terms until we started talking to somebody else So Nigel and I agreed to put something together as a rough first step. This turned out to be harder than we thought and we spent a large number of hours on the phone to each other waving PowerPoint and getting confused Eventually, this got adopted in May and in June I spank a new version to adopt some of to include some of the easier issues from the adoption poll, but that still left a big raft Could you move your mouse over the You just need to be on the context of the That'll do. So, what is in the draft, a long list of terms here I don't propose that we go through them at all now. And in fact, this is a real good example of read the draft The definition are somewhat interdependent We have tried to put them in a logical type of order so that on the whole, you can read through an each term will build on previous terms so that there's no looping or whatever the definitions are a little bit terse We wanted them to be under understandable and robust, but we didn't"
  },
  {
    "startTime": "00:36:02",
    "text": "want to write a 50-page document So there's a trade-off there and I think inevitably as the discussion progress, we will be required to add more text to when people say, yeah, but does it mean this? So we'll have to just boost it a bit the second half of the document is is title of explanatory workflows and these are here to help but they are not normative. So the definition are normative. The workflows are designed to help you understand we actually have a PowerPoint that collapses all of this ASCII art onto one screen, and if you have a very good optician, it's possible to actually see what's going on. So I spend time breaking it up into pieces of the ASCII art. There is some sort of overlap between a lot of the figures, so a term may appear and multiple figures and you have to understand that it's the same term just in different places Their figures do two things They capture this workflow, so what might happen and then what might happen next, but they also show the dependencies between the concepts and that has caused some debate already about, but the dependencies on the workflow and the workflow on the dependencies so bigger issue We had a side meeting on Tuesday evening. There were 12 in the room and Brad and Watson online And we worked through, I think, most of the large open issues we converged on some and reached a degree on others we got a bit closer to"
  },
  {
    "startTime": "00:38:02",
    "text": "agreement, and then we discovered some new issues so it was actually a relatively fun meeting but afterwards I had to go back to my room and reboot reboot So I've got some of those remaining open issues on these slides I propose that we actually look at two of them specifically during this meeting The first one is what is the intended scope of this document probably quite fundamental. The possible possibilities are just the network layer everything in the internet or everything in the internet and the customer sort of facing part of it in the meeting on Tuesday we had a possible conclusion on this which is that we are dealing with things that happen inside the network. And what? we're describing the terminology for is a component of the final top to top-to-bottom monitoring management system with the understanding that there's a policy blob that consumes information from the network and converts it to customer information and and and how information from the network and converts it to customer information and handles that side of it, the business side and the customer side And that's out of scope of our work That's a possible conclusion that I would like to hear whether that is right, wrong or in fact I should be in a different working group I won't answer the last question, but I assume that if we scope this down now, then it will likely get consensus and finish sooner I would tend to"
  },
  {
    "startTime": "00:40:02",
    "text": "agree that the more compact this is, the easier it is to to reach consensus Additionally, I'd add to that, the bigger it is the more it overlaps with work in other standards bodies and becomes a multi-dimensional problem So in that case, I think, I think it'd be great the other documents we're working on will be able to refer to this and use this as a base document and I don't want this document to end up holding up what the other work. So I think it's better to scope this down to that network layer. That's what we're aiming on thinking about Hopefully with the ability to extend or write more documents covering these other things if we need them I see some nodding going on, but nobody in the line chairs Do you think that's what our do you think that's what our charter tells? us we can do or must do or should do? I think that you're about right with your conclusion but what I was thinking and trying to get a quick thing with Matt is maybe that's something that you want to poll people in the room, telling, should we, do we agree with the conclusion? which is their network network we're dealing with network incidents and your conclusion there. I would appreciate because maybe some people will have different views okay so when you set up a poll uh laurel yeah so question is why is it the intention that this becomes an area C to be valid or to be, let's say, a snapshot in time? Why not keep it as? I don't know, a reference on the wiki page that we can keep updating? The reference is still there Because I think the question you're asking is also subject to"
  },
  {
    "startTime": "00:42:02",
    "text": "why we want to make it, how we make it stable And will there be update? So just uh yeah the the wiki page question is really interesting. My personal view is it's really hard to understand when you have consensus on a wiki page But you're right, it's much more flexible for fixing things and adding things So, Mahesh, as a contributor I would agree with Rob's comment I think it would be better to scope it down keep it into that tight scope so that the rest of the documents are not blocked And of course, as a area I was going to suggest that you have a poll, which is already on the screen so I'll go poll All right so I don't see anybody else in the queue I see like a strong support with your conclusion. I was expected that if there was a no, someone would not support this who would like to hear the reason. But I don't see any no in the list. So it seemed that you've got your conclusion, Ken, unless you want to start something Yeah, this is Kent. I try to respond to the poll, but I didn't understand the question so I did not respond to the cold poll Okay Well, since it's phrased as, uh, you agree with Adrian's conclusion, perhaps I should state what I think my conclusion is was Yes, exactly that. Okay, I was thinking the one on the slide. Yeah, it's the one on the slide, which, of course nobody can see. There's a poll on front of it That we should scope down to network related terminology"
  },
  {
    "startTime": "00:44:02",
    "text": "I have to say I'm extremely relieved with that poll. I don't know if you need to take it to the list as well or not, but until I hear otherwise, I will go on that assumption Thank you Number two who is the consumer of this work? So we could be developing and reaching consensus on terms. I haven't even listed it for use only within this work group. It could be developed terms for consistent use within the whole of the IETF, we hope and then we might add into that a hope and desire that other bodies would pick up and use those terms and then a possibility, a different view of this is that we should be attempting to harmonize terms already used across other bodies So the meeting on Tuesday reached a possible conclusion that the principal time is that IETF wide use, remembering that this is scoped down to network, so bits of the IETF that are off in La La security land might not see these as relevant or they might have different terms, but we're trying to push everything network related these terms We'd be okay probably delighted if other bodies pick up the terms, but we're not marketing them we're not pushing them that way we would only use terms in other bodies if we found them and found that the language and the term was useful and consistent and then we point or in include"
  },
  {
    "startTime": "00:46:02",
    "text": "But we also picked up an additional, excuse me, an addition useful and consistent, and then we point or include. But we also picked up an additional step, which is that we should look carefully at existing RFCs especially ones with widespread use and try to pick up those terms by reference and alarm was one that was particularly noticed So if there was a poll, the question would be are you typing? a poll or not? No, no, you're allowed to Right, okay. Let's see if we let's see if we converge on the question question well hold on if we don't even know what the question is Go on, Mahash. There are people in the queue anyway. Dick us out Alex is there before me, sir Yes and oh yeah, I do have one comment regarding C. I think actually it is necessarily to harmonize it with terms in other body and specifically what comes to mind is ITIL infrastructure library This talks extensively about incident incident management of course a little bit be a bit the network incidents, but there's a rich body of all of standards terminology that I think this should this work should look at and potentially adopt adopt So look at, I agree completely I have to confess that I ordered these questions, question one and question two, deliberately because ITEL is substantially up there at the service interface Nevertheless, nevertheless, service interface. Nevertheless, what you say, if we find a term that's already used, and we like it, then harmonize, sure If we find two bodies that use the same term"
  },
  {
    "startTime": "00:48:02",
    "text": "in two different ways, then I don't know. Sure. Yeah clearly, I feel, is it a somewhat different layer, however they do talk about incident management So at least as far as incidents and the related terminology is concerned, I think there's definitely some alignment to be hard alignment to be harvested i guess Mahesh So, and this is more, I'm thinking from a process perspective, wondering how you would do this across the IETF, A, which groups would you target to try to figure out the kind of terms that you're trying to look at And more also to the last point about reusing term definitions that are already in other RFCs and those definitions actually will line up with what this working group thinks is our incidents So I'm process-wise, I think we need to get closer to consensus and then start involving other people in reviewing it and seeing whether they think it's appropriate I suppose ultimately we have an IETF last call Okay I quite like the idea of doing the poll first and then figuring out the question after quite like the idea of doing the poll first and then figuring out the question afterwards. But, so one of the comments, I basically agree what you're proposing here. This looks pragmatic and it goes back to the original previous question of, can we get this done number of reasonable time? frame in terms the one comment i would have is in terms of referencing definitions and other RFCs it's good it depends how many of those are it's a few it'd be nice to sort to be able to copy the definition here and say we're taking it from there and so this is this is an informative copy of it, go and look here, but"
  },
  {
    "startTime": "00:50:02",
    "text": "still not have to go and chase lots of references and things like, maybe i know there's a risk i'd way yeah so swings and roundabouts on that, but yes Sir Hans still a little confused by the question Proposed possible conclusion. Because you clearly have three options there there Well, no, the possible conclusion is a bit halfway down the slide yes oh okay which is basically saying we're task is a bit halfway down the slide yes oh okay which is basically saying we're we're targeting the first option as our principal thing other things may come along, but that's not our main thing thrust My name is Joseph Nicholson. I'm with NTT I want to follow on Alexander's pre- NTT. I want to follow on Alexander's previous comments about looking at other standards bodies like ITIL. Currently from an operation or operator standpoint, a lot of our ticketing systems and monitoring systems are based off of those standards and use those terminologies And if we don't take those into consideration, you could run into the same situation again that you started out with where you're talking about different definitions for the same topics from that perspective down the line Yeah, no too noted So one more time, it seems that you've got your own answer Adrian right looking good although I actually hear there's a little bit of caution on this one. Exactly"
  },
  {
    "startTime": "00:52:02",
    "text": "Exactly Right. Rest of the slides, I will whizthrow, because I don't think we discuss them now I would be bringing these a specific threads to the list. So we've all begen talking about what the document currently says, network insecurity, we have discovered that incident is massively critically overloaded in everybody's documents and they don't always mean the same thing and even if you buy it software package, it's not necessarily the same thing it's talking about. So a possible conclusion is fault, but we'll come back to that root cause we've got in the current document, we basically discovered in discussion root causes is kind of me meaningless it's it's a maybe a possible root cause or a, I hope this is the only root cause, and we can do without that and just go with cause Alert and alarm, we've got both 8632 is very good on alarm, and we think we've collapsed the two are we going to do? As was mentioned earlier, this seems to be kind of urgent to get this stable so everybody can converge on using it so um new revision soon to pick up some of the agreement A lot of iterations And just because it's in the draft, it doesn't mean you can't talk about it. So keep that going on the list separate threads for each thing and hopefully we get there All right. Thank you. So we just close the queue You're perfectly on time. So thank you for doing this Adrian. As you mentioned, it was an interesting meeting side meeting, but at least you've got some answers today Interesting Yes, I remember you told me at the end, I wish I could say twice wasn't a fun meeting, and I arrived a simple"
  },
  {
    "startTime": "00:54:02",
    "text": "conclusion Okay so now we've got the architecture for net network animation framework Let's get started So I will be presenting with Vincenzo together So it's a new document, so that reason for this document is it should, it the motivation and the extent, generic and extension architecture of network analog detection framework, and it anchors the two documents which we already previously at IETF 119 showed regarding the anomaly detection semantics so describing that the symptoms which are detected and the anomaly like cycle, so how to refine the system to have their two references And also at the very end of the documentation we started already by describing some of the applications where this architecture has been applied and will be in the future continuously updating that section as well So from a high level perspective,"
  },
  {
    "startTime": "00:56:02",
    "text": "there are different analytical use cases which needs to be covered at the network operator. The focus is on anomaly detection The data which is being consumed from the network is net the network operator. The focus is on anomaly detection. The data which is being consumed from the network is network telemetry data, so we are looking from different network plane perspectives architecture is overall, it integrates into so so-called the data mesh architecture where we are consuming operation data and producing analytical data and the semantics and the life cycle are targeting the analytical data we have RFC 8632 regarding the alarms. I should change that from alert And basically the life cycle is part on the post post-mortem process So what we care, we are more monitoring connectivity services from all the different, all the three network planes So we are constantly monitoring basically whatever changes in the network are negative impacting the forwarding of the packets of the customers And if it is that we are raising all negatively impacting the forwarding of the packets of the customers. And if it is that we are raising alerts and describing the symptoms which the network anomaly detection system has been observed Take over for me on the number for me or no. So motivation, he on the on the post-mortem side is that we need to improve the anomaly detection system won't be worked perfectly in the beginning So there is a refinement process needed So once an anomaly is detected and also data is"
  },
  {
    "startTime": "00:58:02",
    "text": "being labeled, afterwards those layers those annotations needs to be refined And then it's an iterative process And what's also quite important is one single network operator does have enough incident. We need a lot of incidents data to improve the system So there is a wish of having a lot of incidents and in order to do that we want to collaborate and exchange labeled incidents data These are the elements of the architecture. I don't go into the different details, but you will see that there are many elements of the architecture. I don't go into the different details, but you will see that there are message broker components. So basically the network telemetry data is consumable from the message broker. There is a layer of data aggregation and also the data is being network model so we have relationship among the different data among the different planes There is a streaming part where this is being observed in real time and then possible impact is being detected, and then consoling into one single hour message where in this alert message all the different perspectives from the network are being consolidated and then that consolidated message is then going towards the alert and problem management system where it's being handled by the network operator but also towards the post-morting system where then the refinement process is starting Hi everyone, Vincenzo here working for"
  },
  {
    "startTime": "01:00:02",
    "text": "Huawei. So thomas haynes been talking about the first draft, which is describing the overall arc architecture of the network anomaly detection system There are other two documents which are under the same umbrella and under the same project substantially one is called anomaly semantic network anomalies a moment This is really about so this is trying to solve a very specific problem in the context of the network anomaly detection, which is can we find a way to build labeled datasets for network operators to share their data with vendors and academia? And this tends to work in the direction of improving the quality of the detection system so exchanging knowledge exchanging understanding and improving systems overall and as a result of the effort that we've been doing basically is the definition of these young model, which is trying to define what is a symptom, substantially, referring also to the draft that the arian was was discussing before So the symptom here has been described with a set of fields where we substantially describe what a symptom is and high level set of fields and we provide tags which are quite important to define the semantic metadata and then we also specify some information about the annotator you will you will get in a couple of slides why this is important the other document is called Network Anomaly lifecycle. Here the objective is a slightly different but again it's trying to provide a way to improve the quality and the accuracy of your network anomaly detection system. So working on the problem of network anomaly detection system independently at the beginning, we all realize the need of kind of improving the network anomaly detection over time. So when we set together and we started to look at this problem, we we understand"
  },
  {
    "startTime": "01:02:02",
    "text": "that this is something that many people which will jump into the network anomaly detection or all the people that are currently working on it are actually facing. And this is about the fact that it's really difficult to get a network anomaly detection system either rule-based or machine learning based to work properly the first time So you have to have in place some kind of cycle where you learn from the mistakes and you try to incorporate knowledge back into the detection system so we identify these three stages of the life lifecycle, which are the detection. So basically, the system, receives the telemetry and decides if something is anomalous or not. There is the validation, which is where a network engineer can jump in and say, what's right? what's wrong, how to fix it, how to improve it and so forth And there's the refinement part, which is where, for example, a data scientist might come in and say, oh, I have my machine learning model doing the detection, I have my new set of labels now I can improve my model, I can retrain my model and come up with a better detection system So this is where we're, where this life cycle fits in. As a result, of this work, we also defined a state machine in the context of the lifecycle and a young data model which describes a network anomaly as a list as a collection of symptoms substantial And again, you have the unnoticed information here now you understand why this is important because basically at each stage of the life cycle, you have different annotators. By annotators, we mean what's the end? that actually produces the label if something is anomalous or not and all the different fields And it's quite important, this, because these would would let you see if this is a network engineer saying that this is an anomaly or if it's a machine learning system and so forth, right? These work"
  },
  {
    "startTime": "01:04:02",
    "text": "so actually last year, November, I started playing with this antagonist thing, which was kind of a toy thing and then slowly became a bit of a bigger project. So we started to kind of expand the scope And eventually we realized that there is kind of a gap in the MLOP tooling system at the moment and I haven't seen anything like a label store Why do we need a label store? If you want to implement that life cycle, you need a place where you have to store and share your labels, and you need a structure, a standard format for exchanging that information, which is semantically appropriate and correct and fully understood. So you kind of need to have a shared understanding of this so in the in the hackathon this year this um um information, which is semantically appropriate and correct and fully understood. So you kind of need to have a shared understanding of this. So in the in the hackathon this year, this, this IETF, we actually valid we've been like we've been doing a little bit of work here. The goal for the hackathon is a the goal set of goals for the hackathon are actually just to try and see if the models that we have in the in the drafts are containing all the necessary information and we want to validate those across a wide range of use cases and show that there is interoperability between the different stages of the life cycle. So let's say, for the hackathon, the main focus was the lifecycle draft. There's a little bit of work that we will need to do in the future for the metadata semantic draft for the validation. But basically, we've been validated this with real operational data from the cloud monitoring domain We've been validating this system actually also internally in Huawei with an implementation that we are currently providing on the RFC 947-91418 We've been able to validate this full lifecycle with the real machine learning model on the cloud domain we've been using an auto encoder and for that we actually implemented a few notebooks that you can see up there for the provisioning of the detector and refiner And we also have a GUI"
  },
  {
    "startTime": "01:06:02",
    "text": "for the validation where like a network engineer can easily validate the labels and yeah, so I guess so far the work on the on the for the lifecycle draft is is very much in a very good shape I think I think major changes to the young models and it's I have the feeling that is almost ready for evaluation of adoption for what can concerned, the roadmap and the future time frame I will let Thomas address this in the next couple of slides So I move forward real quick So at Swisscom we already have approximately two years experience, half a year in the lab, 18 months in production network. I just put some key figures together The system is being developed in several phases So we started with a limited POC in production network and now moving forward more to a higher deployment where we have a broader coverage of the amount of layer 3 VPN which we are monitoring and these two slides should be just give some insights on how many changes how many verifications in which network incident applied and how affecting the system was So coming to the status of the draft so the anomaly architecture document is new, we just published that a few weeks ago. And the semantics and the lifecycle document have been updated. So they are now both references the anomaly detection architecture document and all the documents have now proper references on the terminology, which is being defined in the NEMOP terminology And we moved some of the sections"
  },
  {
    "startTime": "01:08:02",
    "text": "which we had previously in the semantic draft, describing the integration aspect and also the types of outliers detection are architecture possibilities we have and moved it over the integration aspect and also the types of outlier detection are architecture possibilities we have and moved it towards the architecture document our recommendation is to move forward from here, starting the adoption with the architecture document and from there, subsequently going towards the Semester and the lifecycle document Very good Any question answer feedback on this one? Okay so maybe what we could be doing is a can of a quick poll on who read the draft We speak about here the architecture discussing with Matt, we tend to agree that the architecture is the main document and the other were going to be linked to it. So maybe if we have to adopt one, that's maybe the one that we need to start with. Exactly Yeah. And another point is that we would really like to have more experience and not only the same group, I would say, participating in this area. So this is not against what Toma mentioned that also Bichenezo, but really would like to have a the same group, I would say, participating in this area. So this is not against what Toma mentioned, that also Bichenezo, but really would like to have, I would say, more contributors. And so this is something we should the same group, I would say, participating in this area. So this is not against what Toma mentioned that also Vichenezo, but really would like to have, I would say, more contributors. And so this is something which is not closed. So um we would really like that that that that more i eyes be put on the encore document with the architecture so that we make sure that this is something that will be open for for additional other framework so that's why we are just starting considering the architecture one for the other specific documents We will discuss them during the next interim meeting. Excellent. Thanks And maybe"
  },
  {
    "startTime": "01:10:02",
    "text": "like there is an interim meeting coming up right on September 11th and there we want to bring a bit more insight more on some examples on incident post-mortems from Swisscom and also from Bell and also detailing some of the hackathon experiments we did and also some document updates where the document is progressing very good thank you so maybe a next poll would be that whether you support adopting this working documents as a anchor to the anomaly detection work in the working group And Matt is super fast typing All right, very good. So it seems that we've got Paul Yes no opinion and there is zero no Thank you very much thanks a lot So now this is like a the digital map issues related to deployment usage of the young topology module So Olga, you've got like 10 minutes plus 5 of Q&A, right?"
  },
  {
    "startTime": "01:12:02",
    "text": "so it depends how you want you to do that Yeah, I'll present on behalf of the author's digital map IETF and MOP status, but focus on the digital map concept draft. Can you rotate? the microphone? Sorry, I'll be focusing on the digital map concept draft because we don't have enough time and then maybe depending if there is any time left, I'll go into the status of the other drafts So I'll talk about the updates since last Digital Map Interim meeting that we had and I'll propose an action plan for Digital Map Activity and we'll share some open questions we have So this is the summary of dual activities around digital map. As you can see, we have three drafts, NMOP drafts that are generic ones. Then there are two IGP drafts, Oscars drafts for ID ISIS, SPF. Then we did RFC RFCA 345 augmentation analysis and got a contribution for substitutes or SPF. Then we did the RFCA-345 augmentation analysis and got a contribution for some of the authors. There was a hackathon that Bena talked about and we started looking into doing RFC A345 BIS. We had a side meeting with this team and started looking at the potential changes needed. But this presentation will focus on the Digital Map Concept Draft and for all the others, I sent an email prior to this meeting with links to the documentation and these set of slides also has more information and the help slides if you are interested interested so this draft defines the concept of the digital map explains how it's related to the digital twin, and identifies the same of the requirements and use cases"
  },
  {
    "startTime": "01:14:02",
    "text": "We spend some time collecting those from the operators and we communicated that in this job draft. And based on the recommendation from the NMO, co-chair, this document was extended from the main draft digital map document. And then reasons for that is because there is a lot of interest about the digital document the main draft digital map document and the reasons for that is because there is a lot of interest about the digital map and how it relates to the digital twin So we want to kind of bring it to those who I need interested in those aspects but maybe separate from the experiments that we did and gaps that we identified and then also to separate it from any controversial topics like potentially what are the right approaches, etc so this would allow maybe some to divide and con right approaches etc so this would allow maybe some to divide and conquer approach and we want to make some concrete progress in this area. So what we are expecting from this, we are expecting to have a resolution document for the concept of digital map independent of which approaches or which gap we then identified, you know, so that we can all agree. So that all the other activities could have a shared terminology document and the concept document that we can refer to. The goal would be that in the working group we agree key terms and their definitions and then that we go wider and we want to have inventory of use cases and requirements for the digital model in this document we have terminology digital twin was taken from NMRG For topology, believe it or not, we could not find it anywhere so we add the definition here so any feedback would be really welcome. Topology layer digital map, digital map modeling, digital map model, digital map data, plus use cases and requirements requirements So we believe this document is ready for adoption It went, although you can see zero zero version,"
  },
  {
    "startTime": "01:16:02",
    "text": "there it has been going through the multiple revisions from the Ops, AWG to the digital map draft and now this is the part that is taken to this job but it's going through several reviews. We believe it's ready for adoption and we believe it's really important to agree terminology for all other digital map activities Matt Yes, if you can just please go back to the slide in which you show, I would say, the rationale for the splitting and why it is interesting to have the draft. Yeah, so while you are showing this one, I think us, we can suggest to the working or to consider the um there's interest to um we say to start a bed adopting this this this document and so we'll be just starting that poll and then we'll let you um continue your research of the presentation while we that poll is there So the poll is started. So there is some in the QMet. Do you want to do the polls before or after the feedback? yeah we can we can Yes, and Thaloo? Yes, I, okay idea to split the concept from the solution because that's more where we are And I agree with you that there is a lot of interest on this topic About the maturity for working group document, I look at it looks like there are some requirements many need to be some polishing because it looks a little bit too of interest on this topic. About the Maturity for Working Group document, I'll quick look at, it looks like there are some requirements may need to be some polishing because it looks a little bit toward biases toward a solution. And one of the big elephant room is the interaction between these use cases and other use cases are they going to be isolated or they can be coexisted so i think this is issue can be also addressed during working group process so I don't"
  },
  {
    "startTime": "01:18:02",
    "text": "see those blocking but I let you and it shares the side whether they are blocking or not for the adoption But these are major issues that we need to address on this current version of the document. Yeah, thanks for your field feedback. I would really appreciate any comments We have a document on the GitHub and we have the document kind of email sends so any feedback is really appreciated Hi, Nacho from Telefonica I just wanted to make two comments One of things, I told you one of our chats that we had, I think the document should elaborate more on the connection with the digital twin architecture proposed in NMR I know the terminology is used, but I think it could be better described And the other comment is the, after the site meeting, that we had this week, I have the impression that the current document is too much focus on the topology modeling. And I think this is a limit in the scope of the document. I would say the digital map should tackle other use cases, like for example, how do we connect the network topology with other kinds of data like saying for several assurance, the connection of the topology or with the inventory so there are other use cases apart from the network topology these two comments Okay, thanks Well, when I, when I'm Diego here, when I first had Nacho talking about the GITZR twing, etc I was saying that I was going to this disagree with him, but then the point is that I fully agree with the second comment and I will go, even in the introductory and the justification for it,"
  },
  {
    "startTime": "01:20:02",
    "text": "I mean, for the idea the idea and the concept of the digital map I can agree that this has originated on the digital twin, but I would say that it's bigger than satisfying the digital twin And probably this is something that we have to remark This idea of the other use cases and how to build the links between different data that this can be relevant for the network model is something that probably, I mean, the digital twing is very important and we are working on that, etc., but it's a particular tool. While this is much more oriented into a general conceptual model of the network and I think that's very important, we should remark it in the document. Yeah, thanks Diego. Thanks everybody Like we would really appreciate a few feedback and engagement on the email, on the working group email and we want to address all of the comments and enhance and add more terminology needed and add additional things that you think are needed then then back in there so on the comment on two much focus on topology for digital map we're not saying to not focus on topology. I think it's need Yeah, just to clear Thanks, Dan. Yeah, the approach here is well why it's focused on topology, because in a know the main I think topology is the core that can that brings everything else together and we have so many use cases that I need there Therefore, the map and therefore, topology is something that we are focusing here but we would add the additional things if needed to be mentioned in terminology. Thanks andrew stone I apologize I kind of went through the document relatively quickly so I might have missed it. I understand that the document basically tries to describe the concept of the map and multiple layers"
  },
  {
    "startTime": "01:22:02",
    "text": "and the topologies within those layers, but it was clear to me if there was also an intention to show the binding between resources that are used between those layers So for example, you might have a topology in one layer, and that itself projects itself to another layer for consumption by that layer Is that intended to be captured in here or is that something that's still to be looked at outside? That would be captured definitely in the modeling part and in the solutions part, but if you believe that some of those concepts are needed to be defined here because add additional definitions yeah definitely because i think from what I've seen in the past, there's one of the challenges is about mapping, especially identifiers to say, for example, this this resource the CVPN service this this SRV6 tunnel whatever it might be how does that map to that underlying IP topology optical topology and so on and create those pointers, you know, in a many-to-many kind of relation manner So I'd be curious to see more in the document to cover that interlayer aspect of things What we wanted with this document is to take out from the other document the concepts and definitions and some use cases and high-level requirements but we can add a specific requirement there is a requirement for relationships and so we can review that requirement and maybe if you can send your comment and we can include it Thank you. Thank you very much Yes, so just for the record, I guess we have an fair amount of support to at one of the document best still we we have two um two folks who indicated that they are objecting to uh to the document i have a fair amount of support to add the document, but still we have two folks who indicated that they are objecting to the document. I wonder whether the folks who indicated that they are objecting to adoption, if they can go to the mic and accept indicated that they are objecting to the document. I wonder whether the folks who indicated that they are objecting to adoption, if they can go to the mic and explain the irrational, if it is possible possible Nach Telefonica, I was one of the ones that said no, but I explained you the reasons. I think the document"
  },
  {
    "startTime": "01:24:02",
    "text": "could be a bit more let's say, elaborated, no? on the connection with architecture and clearly explain that, for example, the topology is one of the use cases of the Zidtel map to clearly state that Thanks, that's right that's fair. Yeah, just natural for, yeah, for the information, this is just a start, I would say, the initial version of the document, this is not working with classical, so the document is not frozen And please feel free to send contribution or text or can comments to the list, and then we can work together with the video authors, and then the next time it will be addressing all the all the comments so thank you anyway Nacho for sharing your comments. Thank you. And also I just want to say i was talking with Oscar now I fully agree with this work. This is something that it's much needed at an IETF but this is opening something that we could have here enough work or creating our new working group even. There's a lot of things to do here here so i didn't object to it not being i i didn't object to it but um so i did vote notes but I noticed that the way that poll was phrased this is question of the chairs, was phrased in a negative way, is it doing what? working a positive one to see the support side as well as that your plan otherwise how do you read it but When I saw the question on the screen, I realized that people might be confused and you saw people say, yes, I support, but the question is, do I object? and then I will let met answer how we came up with that question because I'm an offer in that document. So Matt, do you want to address this one? Yeah, I think we can just run again the poll, I would say, with the positive one and see how we can take it from just to confirm the president one"
  },
  {
    "startTime": "01:26:01",
    "text": "And the rationale for the question, Rob was to say, it seemed that we need to have that document anyway for the concept before going further. That's why we're asking is there like strong objection on program? this? It was the rationale of the question do you object in the first poll and the goal also was to engage the audience with the feedbacks because we didn't get too many comments on the NMOP mailing list I think that we are getting the same result as the previous one I think if you can just close it right now. So thank you. Thank you all guys for presenting So I think I have 12 seconds so i will not really have time to talk through another status of all of these things but maybe just to go to the next steps after adoption we want to submit in of these things but maybe just to go to the next steps after adoption we want to submit the initial version of RFCA 345b more feed for augmentation analysis from the authors, I did engage with lots of you in terms of emails and discussions, but anyway please, who I didn't engage with, please contact me. We want to do new versions of others draft. For the next hackathon, we want to add more layers as IPv6 is priority more operator labs more vendors. And there are some different opinions in terms of modeling we had a side meeting please read the email that I have. Italo, please reply if you don't agree with any of my conclusions. So we are proposed to go ahead for the next hackathon and show different approaches. Thank you very much so just because i was in the side meeting and I was somewhat watching as an observer between the different"
  },
  {
    "startTime": "01:28:02",
    "text": "people who had different opinions on this because I haven't read the different drafts It wasn't clear to me that 80s the side meeting I was somewhat watching as an observer between the different people who had different opinions on this because I haven't read the different drafts. It wasn't clear to me that that 8345 BIS was necessarily the right way forward or if it did go that way and you added in these properties into the base model, I think that also needs to be an analysis of do you have to update all the other models that were? these definitions have moved from because it felt like this potentially quite a wide impact on existing RFCs and other drafts if you go to that model because I think the one thing we want to avoid in my mind is I don't think you want to have the same properties being modeled in two places and I felt like that's where you could end up here so I think we need to need to go tread this one careful I think so based on the another that we currently have out of 52 active ones which are augmenting, I think majority of them do not need to be changed but as the things saw, we won't be able to do the proper generic digital map like for different silos because they are using different approaches. So that is our opinion They are all okay for their functional domain and all the data is needed there in all of those, but there is a problem with 11 or 15 out of 52 that have topological concepts defined in their own way or gaps which are today their specific function or specific technology Okay, because that's different interpretation I took up at me because I thought it was possible to do the district map using the other models but the complexity of doing that was very, very high as in putting the T topology that one had a lot of elements I think that was my understanding, but maybe it was a misunderstanding. Yeah, the mind and changes in the core are needed and mine changes to the others. We are not proposing moving attributes moving, you know, traffic engineering or assurance or saying. We are just saying if you have made some topology entity defined outside of the core model which was the initial intention of the core model maybe we align and see if it could be moved"
  },
  {
    "startTime": "01:30:02",
    "text": "But does that mean that those properties in TE topology? that are relating to the, defining the relationship? are they now in two places do you know which to use? How do you map? those? There are ways to align it so we can go further into the discussions, like how to do it potentially with the least impact. But the goal is backward compatible solution definitely if you change the other RFCs and drafts, yes. Thanks All right. Thank you So what we want to do now, it's the last part of the charter which is about an update to the RFC 35 we want to do now, it's the last part of the Charter, which is about an update to the RFC 3545, which is the requirements from operators And we want to explain what has been happening lately so there is like an IA workshop called Nemops next era of network management's operation so is there anybody in, so I presented this in the ops area and also in MRG. Is there anybody in the room who had no clue what this workshop is? And it's perfectly fine I'm going to cover it. Show off hands Okay, very good so this is a workshop and the goal, as you see in the net map chart, we have to find a way to update RFC-35 and to collect new requirements for operators So with the IAB and a couple of us so Matt, myself, Mahesh as an AD and the IAB member I see Chin Wu in the room we arrived to a proposal to do this workshop. This workshop, there are tentative dates in December. If you go somewhere at the bottom, you will see it. This is going to be a virtual a set of virtual meetings I think, three times three hours"
  },
  {
    "startTime": "01:32:02",
    "text": "and consecutive days the goal is to collect the new requirements for operators to look at the state of what happened since that RFC 3545 in 2002, which by the way was the trigger to create NetConf and as a consequence, NetMod, and as a consequence, of the feature that are described as requirements in that RFC 4545 in that rc as well there is recommendations what should the IETF and the IESG do? One of the was like, don't do any longer read, right? NIF modules. So it became an IESG statement later on so this is the type of things that we want to have in this workshop Since it's a fact that we had, somehow less operators that back then, we're going to have an effort to out to do outreach to places where operators go this is like nanok this is ripe in Europe this is apricot in Asia This is like autocon. So the idea there is to collect feedback of these operators and try to document this So this is a high-level description of what we want to do And if there are no questions on this, we might be moving to the last note sorry, to the next presentation, which is about the operator requirement requirements Hello, everyone, this is Luis. I will present the status of the draft on behalf of my co-authors met, Oscar, Thomas and Rashad. So as you can see on the timeline, so we have just released in this week a new version of the draft, so we will go quickly through that that"
  },
  {
    "startTime": "01:34:02",
    "text": "so as Penavo was commenting there was an initial work some time ago that produced on a result we produce an RFC, this RFC 3535 that somehow has been the catalyst of all the world being developed in IETF for NetCon and Jan After that, RFC, so 20 years ago has said, the point is that, well, there are no total adoption or let's say partial adoption of the, of the, has said, the point is that, well, there are no total adoption or, let's say, partial adoption of the models that have been developed, there are yet operations working with CLI S&P maybe on the legacy install base or maybe even in new install base. There is all yeah, new changes, new needs on the service on the management of the network. So basically we the situation has changed from the city was the situation 20 years ago So with that, we realize that there is a need for the performing a reality check. What is this? status in comparison with the expectation 20 years ago refreshing the deployment assumptions, so it is now needed, check if new requirements are emerging that is actually the case. And also, and also assessing the blocking points and what can be improved what can be done from IETF basically So we started to report all this view in the document for this new version from Brisbane to up to now we have included some some new let's say, observation the point that there is too much time between the publication of a new networking functionality up to the point that the associated jam model is developed we drop an example there about that time lapse five years. So there will be for sure different cases, but also we find these kind of situations. Also, the availability of open source tools and in some cases we"
  },
  {
    "startTime": "01:36:02",
    "text": "for other of the deployments let's say that are not related to the NECO and young there are more availability of open source in the case of NECONJAM Nekongyang, in some cases we have some limitations on this Also, the fact that the transition to all trend to network application, we refer here as an example the working growth for the PID API that could be a case, even though there are young capabilities or young models as well that could be used for that fact So how we need to find the proper link between all the efforts the fact of having new service approaches, all this which is around the expectations, computing, the cloud native approach, the Kubernetes, these kind of things so there are interactions from those services in the network but somehow we, the way of linking that with the reality of the the work on modeling with Jan is not yet there another fact is like the the case that the network becomes consumable and this relates with the effort about the slicing for instance and also somehow can also bridge with the application that we have mentioned before apart from that we also has started to state some individual assessments of what were well, what went wrong, and what can be improved as well. So this is somehow you can check on the document and we are trying to collect an overall view so that we can identify the points i said but so this is somehow you can check on the document and we are trying to collect an overall view so that we can identify the points as well as part of the milestones well, this is part of the milestones defined and work items defined in MOP. So the original milestone was dated for September this year. We are probably far from having all the that ready. So we will keep continuing on that. But the important thing is also what to do with the workshop that Benoa has commented before so here um So we will keep continuing on that. But the important thing is also what to do with the workshop that Benoa has commented before. So here, we can consider to submit this draft as well as a kind of input for this workshop"
  },
  {
    "startTime": "01:38:02",
    "text": "So yeah, some individual contributions that can be the discussed and be put in common with other participants in the way workshop but also there will be the idea of idea would be to keep an MMOC document reflecting all the work that we are collecting. The reason for that is that the outcome from the workshop could be published and an NFAC from the AIIB but will not reflect the IDF consensus. So keeping the document here could help us to collect that consensus and generate an outcome from an ATF with the same all the inputs from the different interested parties. So, uh, here what we would like to bring into the discussion is if we go for option one, for Microsoft 2 two, or for both of them Our view would be that it's appropriate to keep the work in MOP, even though we can for sure deliver it as an input for the workshop And that's basically the presentation. I made it sort Very good. Thank you, Louis. So what is at stake here? whenever there is an iB workshop the IAB is going to publish an RFC with the observation conclusions of the workshop Now we have also in this working group that we could accept the working document. The thing is that we don't know yet what's going to, what will be the content of the iab workshop if it's a one-to-one mapping with what we have, what you have, then actually we don't need to publish anything, but we don't know. So any views on what we should be doing, we accept this working document here and we keep working on this and then we'll see what the outcome will be but it might not be published. Or we say we don't accept and we it's input to the IAB workshop as individual contributor the aim input to the workshop will anyway happen one way or the other individual or"
  },
  {
    "startTime": "01:40:02",
    "text": "a document. Rob I would suggest that we keep as an individual draft at this point in time, because otherwise I think it sort of biases the input into that process if it looks like it's an adopted document into that workshop So basically I think we should be waiting for the workshop to happen and see whether the dust settles from that and then we'll have a better idea as to what we want to publish after the iB is published i don't know that depends how long it takes them to publish the conclusions, a good three or four months at least normally okay thank you rob and what would you say to the AD, who did this, who did this I don't know, it depends how long it takes them to publish the conclusions, a good, like three or four months at least, normally. Okay, thank you, Rob. And what would you say to the AD who did this charter and put the milestone of September? don't answer that's fine right Mahesh so did this charter and put the milestone of September, don't answer, that's fine. Right, Mahesh. So, I think even that the previous workshop that happened in 2000, what RFC 3535 has I understand it, captured was the requirements with or without whether IETF would work on all of the items some of the items on none of the items. So if the question if I understand the question is, do we accept RFC 3535 biz? of whatever you call it 20 years later that still can be an input to NMOP? And it's up to the individual work groups to decide whether they want to pick it up or not is that is that a input to NMOP. And it's up to the individual working groups to decide whether they want to pick it up or not. Is that a fair understanding at least of what you're asking for? Yeah I don't know an opinion on one or two, but for me, the IAB workshop will happen. I think we should try to avoid to give the impression that whatever are the input and the discussion in the workshop, this group or in the individual through these documents try to jump to all the conclusions So I think lets the workshop happen That will give us, I think, some guidance about what could be"
  },
  {
    "startTime": "01:42:02",
    "text": "the future of this document but really try to avoid to say, irrespective of what happens, we already have our ideas and we will pursue them. So that's could be a bad impression, but I understand it's just a general comment. So Laura, question to you please. So do you agree that anyway this? feedback whether it is individual or working group, should be given to the IAB workshop? Yes I think as an input to the workshop, that's the best step of today As an individual opinion, not for that that Okay. Paul poll, okay, we'll do a poll, okay yeah can you prepare a poll mad Matt? So, really go. Okay. Really good polls Okay, we'll do a poll, okay. And you people are a poll, Matt? So, Riddiger. Okay, really, folk. Okay I think number one and number two are not mute you people are a poll, Matt. So, Riddiger. Okay, Reriga folk. Okay, I think number one and number two are not mutually exclusive Though kind of change to figure out a working group consensus before input to the workshop does not seem to make a lot of sense I'm not completely sure whether at the end of the workshop the conclusion will be yes, it makes sense to continue work on this draft and what are the ideas that need to be enhanced or well, okay this was a valuable input like others as well All right, thank you Niels Yeah, now. Now, I would also support that. Let's not jump to a consensus that might be contradictory to what comes out of the workshop. I mean, that's for my point of view the worst or one of at least a bad result"
  },
  {
    "startTime": "01:44:02",
    "text": "for that. So let's be open. I do think it's a good idea to have this draft and i totally support that but i would support or prefer to have it as an individual one Thank you Rob And I guess just to reinforce my point is, if we do adopt this and if we do send it into that workshop as it's coming from this working group, I'd ideally like to see a consensus call, a working group last call done on that document and achieve and pass working at last call before we say this is the input from the working group to this IAB program. Otherwise, I think it's going to misre misrepresent that's uh that's a fair point and I don't think there's time to do our I iab program otherwise i think it's going to misrepresent that's uh that's a fair point and i don't think there's time to do well i i doubt you get time to that but all right Thank you So the result is like Chenyan Q. Please go So it's Qing Wu, and I think a problem the IB workshop will happen, actually also will produce this IB workshop reporter So we need to figure out a relation actually, probably, I think this work could be the input to the IB workshop And if I.V. also produce the workshop report, how this relate to this document So it's need to be cautious. I think there is unless someone says otherwise, I think there is no objection and actually we should give this feedback to the IB workshop The only question was individual draft or kind of concern telling the working group believes that this is the question, but the input is obviously valid so what was the result of the poll?"
  },
  {
    "startTime": "01:46:02",
    "text": "it's eight yes and 12 no all right thank you Thank you So next one we have So next we have Nacho Knowledge Graph for Yang Basin network management Thank you I'll try to be quick We'll have much time. So in this presentation, I want to introduce this new draft which is about using knowledge graphs for network management We focus on Yang Yang. So first of all, why? m-mop? So just a reminder of the scope of M-M-M-M-M The idea of M-M-P is to discuss operational issues facing the deployment of network networks based on short-time experiments in this couple for one, two years, and in particular discussing the use case and requirements for solving anticipated problems in the management of the networks So this said, what's the problem that we need to tackle in the work? Well, we see that the network is full of heterogeneous silos of data and this is limiting the AI applications to unlock new use cases. So what we're trying to do here is to find new ways for these applications to find these data silos under cases. So what we're trying to do here is to find new ways for these applications to find these data silos, understand them, access them, and especially combine"
  },
  {
    "startTime": "01:48:02",
    "text": "them for these new use cases This heterogeneity is well described in the network telemetry framework in NADOCE NADOC-92 9232, which describes this variety of protocols like SNMP, IPFix, all these protocols based on yang, format also levels or planes like the forward plane, the control plane, and so on So if we just take a look at the Yang ecosystem, we see that this is already a big challenge There has been a tsunami of data models, as we all are aware of with standard data models proprietary, open source, also at different levels of traction at the device level, network, service level We see a variety of protocols as well like NetConf, ResConf, now Jam Push, Genome so it's always there, and many formats So what we propose is to you leverage this new paradigm of the knowledge process to enable the integration of all the heterogeneous data silos And knowledge graphs allows us to do this by building a semantic layer based on formal knowledge representation And this is commonly known as ontologists, taxonomies, and the like so in this document we provide guidelines for building knowledge graphs, in particular for, from young data. And these guidelines cover three main aspects. First, graphs standards. Here we have the commonly known standards from the semantic Web, RDF, old, and more recently, labor property graphs with popular solutions like uniform commonly known standards from the Semantic Web, RDF, old, and more recently labor property graphs with popular solutions like New 4J. The second aspect is the development of ontologies in this sense, we are exploring standard methodologies, but also now there are options to extract automatic"
  },
  {
    "startTime": "01:50:02",
    "text": "extract knowledge from the sources And the third aspect is also very important, which is, the construction of the knowledge graph itself. This is the data pipeline for collecting the data from our network and integrating it in the knowledge graph And this work is the to give you more context, is the result of an ongoing research a telephonic that we call account candle. And here I posted our latest paper that can give you more, more details details so potential applications for knowledge graph in the IT. So the first that comes to nine is service assurance Here, if you have a look at the sign, this is basically a graph of dependence between services and symptoms And the idea here is that by integrating the service assurance graph data in the knowledge graph, we could combine it with all our data like topology, inventory Another potential application is network digital twin here the knowledge graph aligns well with with the proposed architecture in NRG and also with all the work that it's been done in the digital map, because precisely the work in the digital map is about finding these common concepts between different young modules And in this sense, the knowledge graph could be the technology to realize that no to essentially integrate these silos of data And another potential application is the data manifest This is a typical example of metadata management where in the notice graph we could have the data and the metadata explicitly connected so we could have a contextualized understanding of the data, like how the frequency"
  },
  {
    "startTime": "01:52:02",
    "text": "which I'm collecting data from my network Some challenges should be addressed in order to improve the adoption of knowledge crafts for naval management Well, here I have listed a few in the in the there are more. One of them is of course, the development of ontologies. Ontologies are one of the pillars of knowledge graphs and this is a big challenge because skills on semantic modeling are required And this is a mostly manual procedure also scalability The knowledge graph must cope with the scale of the networks So in this sense, distributive and federate architectures could be explored. Also, the scale of the networks so in this sense distributor and federated architectures could be could be explored also has to cope with all the volume collected of data collected from the network and support real time use cases and additionally not limit the application of knowledge grass for network monitoring but also explore the application for network configuration configuration And to conclude, some pending issues and next steps the first one is the document should focus, keep the focus on, on, or broaden the scope with other data sources like IPFix or S&MMP And the other question is to confirm whether this work fits within NMOP or maybe in other groups like NMR where I've also introduced this draft And for the next steps, well, I know all this story sounds very abstract so in order to help people better understand what we are trying to"
  },
  {
    "startTime": "01:54:02",
    "text": "do here, the goal is to implement a prototype In particular, based on the augmented island library work, and build a knowledge graph collecting this giant library data and the plan is to have this prototype ready by the next hackathon in zabling ensure a knowledge craft collecting this giant library data and the plan is to have this prototype ready by the next hackathon in Zabling and share some some results and also the as part of the next steps they idea is to explore integration with our works in IETF like integrating the knowledge graphs with the Jan Kafka architecture Here, there are several pieces that could be levered to build the knowledge graphs. And of course, well, keep collecting feedback from the working group and looking for interested contributors That's it. Thank you. Thank you Nacho So sorry, I'm not a chance reader of your presentation, I think it's a really interesting idea So I think I look forward to looking for what you present in IETF 121 Thank you. Any more questions? Thank you We are perfect on time for the five minutes discussion as mentioned the agenda So, at least one topic to address So there is like in September 11 an interim meeting on network anomaly, right? So feel free to we'll do a call for an agenda"
  },
  {
    "startTime": "01:56:02",
    "text": "And we've got a question with Matt, it's like, do we want to have other interests? meetings so in one of the slides, I think it was at the beginning of chair do we need one interim on the digital map? Do we want to have other intermeetings? Do we want to have like, you know, monthly interim thing like this? Tell us what do you think? Envoyable Canada. Sorry, I closed my laptop I think yes, because it's a lot to digest in a single meeting every three months So having interrupted, interim meeting will help us to understand a little bit more and socialize more before the meeting So there is one another minute animal detection. So the other two topics we have is digital map and incident network anomaly so we have one on networkedony already So what, Young Push, Digital Map Young Push and Digital Map makes sense because I think they are close to one another I mean, the vision behind So was Dan saying two, having one combined? for two of those or not, I don't know, but if you do want a digital map, I think there's two aspects to it. One is the digital map, is the concept and the technology what's been trying to be so solved there. And I think the other one is the same kind I made earlier in terms of working out how we update the RFCs or extend the RCs that set. I think it's a knotty problem there. Certainly in that side meeting, it looked like there was a few different views and trying to resolve those I think will take some efforts and maybe having an interim meeting to try and progress that would be helpful. I'm not sure thank you All right, Italy from Norway"
  },
  {
    "startTime": "01:58:02",
    "text": "I definitely need to have more discussion on digital maps It's clear that we have started and we are working on it I'm not sure whether the interim meeting is more effective versus maybe the weekly WebEx that we do in other working groups I will think about that So the weekly meetings should be work Where people can be informal and discuss different opinions and then try our outline a list what do we agree, what we don't agree, what can be the question that we asked the working group to get forward so what you have in mind is like the type of IV weekly meetings? Something similar, yes, yes And it's not a design team, it's a weekly meeting open to everybody Of course, open to everybody, yes, yes hi oscaron salete Telefonica, in this last month it was very useful to have a joint end-mobtis meeting for the digital map and the topology also getting the experts that developed the topology and that have developed, I say it the models of the topology. So I think it's very useful also to keep that relationship ongoing because also it might imply also some words in this and work here so I suggest also that the activity on digital machines especially the topology, we keep also the alignment with this Thank you. Adrian farrel, I very much expect that it will be useful to have interim meetings to talk about terminology, but I'm not ready to say put one in the diary because that's going to force my hand on doing the work So what I'd like to do is spin it a bit and see if I can advance some of the issues and then collect ones that need discussion and then come to you and say, can we have an interim in however much warning? you have to give right"
  },
  {
    "startTime": "02:00:02",
    "text": "On that specific one, in the end there are you had like 12 people in the room plus two and I think that maybe these are the key contributor to and they need to sort it out maybe them themselves Sure, if you're saying go away and self-organize with your own design team or whatever, then I can do that. I just don't want to exclude the working group. That was my next point, yes So whatever works for you, Edrie? oh right we're gonna call everything a thing, okay so we'll have the network thin detection And what happens is you see a thing in the network and you report it as a thing. And that goes up as a thing and then we just have one definitely and everything's done. Would that be a problem? No, you see. Or false? No, no, it's a thing We'll just call it a thing, yeah And that makes things work really easily for me All right Hi Olga. Let's close the I think we need to continue discussions, definitely and to address whether we want to go with two hackathons in IETF 121 and whether that's the right approach. So from traffic engineering guys, maybe we need to get the feedback about that and agreement. In the case that that go ahead with that, we need to agree the use case we need to agree the most specific things so I think intermeeting would be great and to show the progress in in regards to state weekly statuses yeah, I think it may be a little bit too often, but because there are a lot of topics you know, it will end up being you know, maybe monthly meeting for"
  },
  {
    "startTime": "02:02:02",
    "text": "the digital map. Thank you so just one last thing is that the weekly meetings they work i maybe monthly meeting for the digital map. Thank you. So just one last thing is that the weekly meetings, they work, I think, well in Ivy because there is one focus Here we have got different interests in Yang push and digital map is in network anomaly. Yeah, right Done and you are okay. We last in the queue This whole work, we've talked about this during this week it's taking way too long over the last five, ten years five-ish years So having regular meetings is a very much needed because of those reasons to debunk or review address definitions, which I would welcome as well so we move the work a bit faster we change the beat. That's my last comment since it's closed And we'll end with that statement Thank you very much, everybody everybody Thank you, Matt as I'm losing my car"
  }
]
