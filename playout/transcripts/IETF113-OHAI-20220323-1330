[
  {
    "startTime": "00:00:22",
    "text": "today i think we can get started sound good francesca okay cool well hi everyone welcome to the ohio session at ietf113 i'm siobhan and i'm joined by richard bronze and francesca is our eyes and ears on the ground thank you for that um and we are still looking for a note taker so if anyone would be willing to volunteer that would be fantastic anyone anyone face for the link i think yeah i think richard also said that you can keep an eye on the minutes as well so worst case we could do that but it would be really nice if someone could just volunteer fantastic thank you so we have a note taker um yeah and if you have anything that um you would like to say the mic just prepend that with mike and you can get that sorted out this is the itf note well please go"
  },
  {
    "startTime": "00:02:02",
    "text": "through this whether it's your first idf meeting or your 113th it's always good to refresh your memory um iatf 113 is hybrid so if you're in person please please make sure to sign into the session using meet echo online tool um and please please use uh we are going to join the queue um it is important for queueing and all queueing is done through medico um all right i think we can get started we uh we do have quite a bit of time um so i'm hoping we can get some good discussion on and first up we'll have martin and then there will be um some discussion about issues and updates since last meeting and then we have two brand new drafts being presented by tommy and hero so if martin i think you have some sites mine's coming up perfect i think i have to let's see how this works i'm going to do the uh hall of mirrors thing for a moment because i'm going to be jumping in to uh yes i want to share my screen that's the crazy crazy thing uh yeah okay all the mirrors and now slides so um this is uh just a brief update on what we're doing and i'm going to go through some of the issues here that we've got um since the last meeting there have been a few issues raised in the last hour or so obviously i won't"
  },
  {
    "startTime": "00:04:00",
    "text": "go into those ones but i will hopefully get through all of the important things that we identified this is every open issue that existed as of a week ago so option one changes in version one uh we've moved the padding to the binary messages draft that is something that i think simplifies the overall design uh and it makes the binary messages stuff more useful generally we've also made uh changes to the the labels that we're using for generating to extend the exports those are now um based on the the content type of the um of the the content that's enclosed and there's some text about repurposing the design that we have here for other purposes not that this is a primary goal for us but it's something that makes a little bit easier for us to manage there's some new text on resource mappings i think one of our new issues is about that and some draft texts on anti-replay that i'll go through as part of the issues here so the first one of the issues that we're talking about is what information the proxy is able to provide to it to a server when it um relays messages obviously we want the proxy to hide a lot of information about what the client is who they are and where their requests are coming from but there are certain use cases where um it might be useful perhaps to have a proxy um provides just a tiny amount of information at the moment we're considering one bit that would allow proxies to to do shadow banning for instance that is"
  },
  {
    "startTime": "00:06:00",
    "text": "identify abusive clients and allow the request to pass and appear to be handled correctly but give the server a sort of side channel signal that says hey this this guy's probably a bad actor you might want to de-prioritize or or respond in a different fashion there's a pull request uh we're discussing that i don't know if we want to talk about that one just just now it's kind of in flight right right now there's a number of comments so um i will probably just stick to this uh one here are there any comments about this one i'm going to bring this off full screen where did you want to go it's just waiting to be to be called on um yeah so i guess i think my take on this is that actually like this entire restriction is kind of misguided um and that there's a number of things that you might want the proxy to say um um one one of them is this bit as you indicate um one of them um i've heard floated is a um a token of some kind indicating um you know um uh you know that there's been some sort of dial service reputation kind of stuff on it um you know one thing i've heard of is geo is rough geo um i certainly heard suggestions of you know um of short term uh short term linkages for um for ip address you know this is the same person over or cover a couple of a couple less messages um yeah i'm not like a huge fan of these but i guess my my thermal thesis is these are all out of scope for this protocol and that we should simply not say anything about what you should say and um and and leave that to applications um"
  },
  {
    "startTime": "00:08:00",
    "text": "fundamentally that's i don't know exactly what what messages are what what crap is conveyed in that metadata is really like for um the uh the client and the um the client in the proxy to like work out for themselves um so um and i understand like certainly like you know that that allows you to bypass any possible protections being offered here but like but like you know this is just like this is like this is like a 6919 don't do it so i just think it's like rather than trying to like put that in the number of language we should like talk about what um um well uh nick asks we don't know it's being out of them yeah the point the point is that like the point is that there would be an understood policy of what of what the proxy was doing and not doing and the user be aware of that at the point they chose it just entered we're still aware of anything issues anything here right um um i mean like you know the proxy and the process can just be side channeling all the information to the server for once right and so the only question here is like um um so i think you know your fundamental trust in the process yeah so that speaks to to potentially saying um as long as the the potential uh range of things that a proxy could communicate to a server is is known to the client then the client can use that as part of this decision to use a proxy that's what i just said that's my name and in general maybe we could just make some have some waffley words about you know don't include too much uh chris yeah yeah i think that's what the the text in 96 tries to do right now in particular tries to say that any of this of this public metadata that the client and proxy agree upon uh as being revealed during the course of using this proxy um is known to the client uh whereas in contrast what i call private metadata like this this shadow banning bit where the client does not necessarily agree to the presence of that metadata um that must be strictly bounded the proxy just shouldn't"
  },
  {
    "startTime": "00:10:01",
    "text": "add things to the you know client forward of requests without the client being aware of it so the sort of intent here uh in my mental model has been that the any sort of public metadata is agreed upon between client proxy and and factored into the decision to use a particular proxy or not um and private metadata must be uh strictly bounded it is sort of like a you know a must but we know you won't in a way uh um but at the end of the day you kind of have to trust the proxy to to not do bad things like forward your ip address or whatever so i i'm not i'm not too concerned with the language there but that's the tent that's my mental model so i think that aligns with ecker as well so so chris i want to pull on something there a little bit there's there's two things that we're sort of conflating perhaps one is the uh spectrum of possible things that the proxy might say so the type of information that it might pass to a server and the other is the specific values that those types take now are you suggesting that most things fit in the you know the precise value that's being communicated or um it is that just all of them just you know the type of the thing that's being communicated about you um can you repeat it one more time i'm i'm sorry i just spoke so so understandable um so in the shadow banning case the client might know that the so that the proxy might pass a bit along but it won't know the value of that bit yeah in the geocache do we expect that the client will know the precise value of a geolocation that's being provided along or it will just know that geolocation of a certain type yeah my uh thank you my my um"
  },
  {
    "startTime": "00:12:01",
    "text": "my thing is that the client does not necessarily know the precise value it will just know that the value is being communicated um faithfully by the proxy um like it would be the right geo mapping or whatever it would compute the right token it would send the right bit um but the client is explicitly made aware of it yeah i i do wonder whether some of these examples can be made to work i mean geolocation is pretty dangerous to do these sorts of things with so yeah i think there's a lot of sharp edges within that any more metadata you're adding that's why like with the 96 pr in particular um i tried to punt any anything more than a single bit to a separate you know discussion down the road um uh and because to your point uh any any any more information you're adding is uh it's a slippery slope so to speak okay thank you hi tell me all right hello um so i agree with ecker that it's difficult or impossible to try to make this normative maybe one thing we could do is have a normative statement about future standardization of protocols between a proxy and a target of saying like we really shouldn't approve things that give away you know lots of information but otherwise we can't really enforce this and to echo what people have been saying i think this really comes down to how much the client trusts the proxy and the like the implicit thing whenever we're using oblivious proxy is that trust relationship and so anytime we try to talk about untrusted proxies or proxies doing things that the client don't doesn't want we're kind of missing the entire deployment model um and i think even for the shadow banning case like i could as a client once i learned that a proxy"
  },
  {
    "startTime": "00:14:00",
    "text": "does shadow banning bits i could choose not to use it and say i don't trust you anymore because i don't want that in my contract so i don't know if the shadow banning is really unique or if it's just one more thing the client could decide not to trust you about yeah i i think the the the general shape of the things that chris has described is is what we're aiming for i'm not sure that we're there yet on the pull request but this is good input shivan yeah i think um i kind of mentioned something similar on the pull request but yeah i kind of agree i think that um well i think that we should just keep it to be assured and you can describe the many ways in which this can go really badly and like why a proxy shouldn't just add you know everything under the sun and it communicates with the server but i think applications will have things that they want to do um so there's i don't know if there's much point being like this is the exact amount of amount of information that should be uh given out david david kanasi privacy proxy enthusiast um hey martin i want to really echo what folks before i've been saying like this must is completely unenforceable and we will probably have uses for this later which all we'll have to do is by the way that must just ignore it in that previous document so having some text about well duh don't put the name of the user in there uh sounds i would have should sounds good and some like implementation guidance says we have more implementations is good but i wouldn't i would prefer no no must i'm suggesting that at this point perhaps it's time to um"
  },
  {
    "startTime": "00:16:00",
    "text": "to to go back to the the the separate work on the poor request and maybe we can try to like um go back um and like rather than try to like i think i'm generally like obviously when i'm generally hearing of course if people agree with me but what i think they think agreement is like that we should try to talk about the positive the space here and like give some guidance but not actually tell people to do anything and then we can work out the exact importance of the thing around that later offline this is also my issue 100 so i think this is like clearly this is clearly like a hot issue in this document yeah this is one of the more difficult ones uh we will take this to the pull request i have probably one final point here in and that is that um some of the things that people are requesting here are probably generic http features that don't exist currently and they might be something that uh we would would benefit from standardization with and so if we we took those things to say the http working group we could define new header fields for say the shadow band bit or no i'm not i'm not going to say that we're going to do the geolocation thing but um other things those lines okay so i'm going to move to the next one this one's a little more technically complicated so um i think a number of people have pointed out that this isn't particularly good at carrying all of the different http semantics at the moment uh we sort of have a an atomic request and an atomic response and if we want to do things like have large request bodies or large response bodies that stream and are processed in a streaming fashion it's not very well set up for doing that in fact it would be a very bad idea to use the current thing for doing uh very large requests that are processed incrementally"
  },
  {
    "startTime": "00:18:00",
    "text": "and it also means that we can't do things like encapsulate uh 1xx responses um which is a little bit awkward so um i have a slide uh ben if you have a question i might answer it as we're coming up so jump in if i'm so um this is just a sketch of a design i'm part the way through writing this up it turns out that writing this up is awkward and time consuming so the couple of hours i've had to spend on this has not been enough to do it cleanly but the basic idea is that rather than having a single aad invocation either via hpke or just directly itself we invoke it multiple times and send the message in chunks so this is easy for hpke because it maintains its internal counter uh for the aead we need to maintain a counter in a nods and which we can follow the pattern that we have in tls for that sort of thing for each chunk we can prefix each of them with a length which if we use say for instance the quick variant encoding it might cost one extra byte if you send a single chunk and then the only other consideration here is that we need something to seal off the end of the message so when you have a series of chunks you need to know that the chunk that you're processing is the very last one otherwise you're exposed to potential truncation attacks so use something to distinguish the last chunk and if there's any number of things that you can use the the simplest thing in in many respects is is just use a zero length for the last one because then you have a distinguishing thing and you ensure that the um ensure that it's uh you rely on the the outer encapsulation"
  },
  {
    "startTime": "00:20:01",
    "text": "to to manage the length of the remaining things uh richard's going to complain about that probably um and that's all i have so comments folks hi ben schwartz i first wanted to ask can you just confirm that i understand correctly that the proxy already can stream requests and responses yes the proxy can stream everything it receives it's the it's the client and the server on either end of the hpk thing okay yeah so that doesn't seem as important to me um i understand the the interest here but i would uh i would ideally prefer for this to go in a separate document possibly as an extension to hpke or you know as essentially an addendum to hpke because this is a very general purpose thing that you're describing here has really very little to do with uh http it seems like it seems like an expansion of hpke itself i'd love to hear what richard has to say about that so hp hpke has a notion of doing a single key exchange that you then use for multiple ads now it's up to the application of hpk to like provide sequence numbers to make sure that you process them in the right order um etc but um but that that's there we could use that it'd be pretty straightforward what i was wondering is whether we need to invent something new to signal end of stream here or whether like we could lean on the http chunked content encoding or something like that to you know which if i recall correctly has end to stream signal um and so you would just basically just"
  },
  {
    "startTime": "00:22:00",
    "text": "have the the encrypted thing be you know here's some some chunks and [Music] uh and you can encrypt them and then the interior thing would signal when you got the last shot i don't think we can rely on chunked encoding for this i don't think coupling the the chunk boundaries that you use for the aead with either the chunk encoding thing or http 2 data frames is a good idea i think there's any number of reasons why you might want to be doing things like rechunking at intermediaries for instance so i don't think that's going to work particularly well um this design that i have here is going yeah so what i was going to say is like if you're going to do the hpke uh multiple aud thing you're going to need a framing a little bit of framing anyway so you might as well just put a bit there that's exactly what i'm suggesting might happen here yep tommy um so one question because i was waiting to see kind of the proposal i understand that that's not ready yet does supporting this streaming chain do the streaming does that change the wire format for the encapsulated request for requests that don't want chunked or streaming yeah the the way that i've got it at the moment uh there's a single zero byte at the at the start of the message but otherwise it's exactly the same so exactly the same code that you have today you put a zero byte in and if you're unwilling to support chunking on receipt then you just simply read a zero byte off and then run exact same code that you have today right so okay and that makes sense i don't"
  },
  {
    "startTime": "00:24:01",
    "text": "love it so i guess the other question is like you know what are the use cases for oblivious http that currently would use this like are who is going to benefit from this uh bite and the potential complexity of implementing like is anyone going to actually use this and test it out and exercise this um as we're developing the protocol because i have a couple use cases that i'm currently using this for and they're not needing this right so there's a there's a lot of use cases that we have that are very small requests very small responses and that would be kind of this would be a waste on those um those things now the question is whether there's anything that you might use this for that has much larger requests or responses there are some of the things that i've been looking at for um the npc related submission of you know advertising related things for instance that might use larger payloads it's uncertain and sufficiently large that they couldn't just create i mean couldn't just essentially stream it to the proxy and then have that be one large request that's forwarded well it's it's more about being able to stream it into the in the encryption or description okay yeah david sknozzy this time mask enthusiast um so similar to tommy i'm not entirely sure we need this because like in my view most of the use cases are for like short things and like if you're starting to get into things that are much longer i mean i know i'm the math guy but you know at some point you can use mask like if you're really want to stream that's we have another protocol for that that"
  },
  {
    "startTime": "00:26:01",
    "text": "might be a better fit uh so at first i was like oh yeah this makes sense but now that i'm seeing um crypto foot guns i'm kind of concerned that solving those might delay the rest of uh this effort and unless we have a real use case that's not solved i'd like to understand more why that one can be solved by something like mask right so i suspect that the right thing to do here would be to uh put out a pull request see what people think about the concrete implementation of it i suspect that the feedback that i've gotten here will remain unchanged but since i'm 90 of the way through work i'll probably go ahead and ship a pr circulate on list and see see what comes out of that ben schwartz uh just one quick note you you could consider separating this by mime type effectively um and that would that would make an extension so in effect that would mean using an extension which isn't completely unreasonable a number of ways to cut this one okay so um this is one of the more interesting technical problems that exists here i think it might have been david benjamin who has sort of reminded us that um anti-replay is kind of a thing when you're doing this when you seal something up in hpke uh there's nothing in it that ensures that their connection is live and so a malicious proxy that gets their hands on a request can replay that request any number of times and the server that has no defenses against those sorts of things might just process the request"
  },
  {
    "startTime": "00:28:01",
    "text": "multiple multiple times so uh what we have at the moment and this is going to require a little bit of coordination perhaps to address is we've got some text in the draft that that looks at the general problem and surveys the space and there's a call out to a new draft that i've proposed to the http api working group that talks about how you put timestamps in requests and how you deal with the problems in there um i will go on to the next slide to show you the sort of problem so um if you're doing anti-replay there's um sort of two broad ways that you can deal with it first is you can just not care this is often the case for things like dns even though perhaps maybe they should care in certain circumstances a lot of dns servers won't care about replays and the other one is you take all the requests you receive and you remem remember them and if you see a request that's played out twice you reject the second one all subsequent ones for something like oh gdp you just look at the a slice of the the request that the encapsulated key is a good thing to use in that case you don't need to remember the entire request in order to recognize that something's coming again you just need enough of that ink value to to ensure that it's unique probably 16 bytes would do so the problem with this is that you even with as little as 16 bytes per request that you've processed that's an infinite amount of state if you're a long running server so um a practice that we've used in a number of other settings is to include uh some sort of timestamp in the request"
  },
  {
    "startTime": "00:30:00",
    "text": "and the http date header field is not a bad choice for this one even though the date is not used particularly often and then you only need to remember requests over a short span of time anything outside of that span is rejected because it's too old it's probably a replay or too far into the future someone's got a wacky clock for those requests that you remember as they get too old you just stop remembering them it sort of keeps the amount of the state that you maintain finite that leads to the next problem which is that client clocks are bad and in some cases really really bad there's a paper that we cite that talks about just how bad it is but um it's not unusual to find clocks that are years bad some of them like centuries into the future that sort of thing um completely weird stuff so um the solution there i think is to just let the client retry so you have a the service send a signal saying that you'll collap your clock is wacky and the server response will include a date header field conveniently and the client can just retry using the date that the server has provided you should turn the value around in most cases there's a number of ways in which this can go really really badly wrong you don't want to use the service date for things other than an immediate retry but there's a you can use it for this one retry so there's a there's a bunch of stuff in the in the date request draft that covers the security risks of taking random clocks from random servers um but in general this this works"
  },
  {
    "startTime": "00:32:02",
    "text": "between the original attempt and the retry but if the retry is essentially the same request tried again then it's not particularly bad and here there's not there's acne answers as well in the chat i don't think that allows you to do the time windowing thing although it may be uh possible in that case because the server is the one that's generating the noises it seems like the server generated date here because the server comes indeed yep so it's essentially a token so um this is more or less in uh for your information um i think this is probably a reasonable thing here i think the challenge here is that we're citing a draft that's an individual draft in another working group so i just wanted to make people aware of that that possibility we could probably break that dependency uh by folding some of the content in but um we haven't yet had the conversation in http api about what to do with that draft so um there's a little uncertainty there thankfully we have some other problems to solve so we this doesn't become urgent any input on this one okay so first let me just like state what i think is the case um which is um that this is about replay by the proxy correct so the proxy is pretty much the only one that ever gets to see these messages so yeah right are you good just making sure i'm the same page as you um i think i mean i i guess i wonder like i mean i know i know as you say clocks are like terrible um um um but i wonder if the answer is just don't do that um you know uh we're talking we're talking a new protocol definition and um i i wonder if like maybe the answer is just like"
  },
  {
    "startTime": "00:34:01",
    "text": "it is say well like like have an accurate clock or it's not gonna work um and uh um i guess i just like like i know we talked about i mean you alluded to some of these things but it's just like that the like just just just like you know naively accepting whatever date the server gives you has like all kinds of other problems um and um um and and if if um um you know i think well i guess i guess there are the other two there are two flavors of this right one is where you don't know or you know you accept it but only for the purpose of this message at which point you mess measures or not because it's basically nuts or the other is where you persist it at which point now you have a tracking problem i'm not sure how to do what and so it seems like and it seems like maybe like the answer is just like um it's just like fisher clocks so um i don't know but um i think um i guess i guess if i'm i i think i think my i guess maybe my my my bottom line is like either we should do not try to correct the clock at all and just do what you have this in this thing or have send a correct clock or you're gonna have to absorb around trip for knots i think it's probably my take on this i don't think i don't think trying to crack the clock is going to like this is a great idea so you you're thinking of having having the server respond with the nonce and then you have to make another request with that nonce well the mechanics and the mechanics obviously or if your clock is wrong then you're going to send a request and either it's going to be dropped or they're going to tell you to try again with some other new information and and and and the version and the version you have here uh the version of the next slide effectively is try again with a correct clock but i'm just saying that unless you're that if you're not going to store that clock information for very long then you might as well just try the knots and you can skip the clock part and then and then the way you think about this is the clock is the clock is a shortcut around the around the knots right um is going to think about this anyway i'm i'm not sure if i i guess i i'm just trying to avoid having this like having to like define the privacy rules around precision o'clock"
  },
  {
    "startTime": "00:36:00",
    "text": "yeah i mean i i went through it in the other draft i think it's probably probably tractable but um yeah you you essentially if you have a bad clock you end up with with a round trip an extra round trip for every request that you you send which is unpleasant then uh so i i looked just briefly at the i guess two drafts involved here um neither of them seems to mention the problem of distinctive skew linkability so if you're the only client who's 11 seconds behind then all of your requests become thinkable you lose the oblivious property so including a date header in the inner request is a little scary unless it's i guess fuzzed rather than quantized anyway something to think about yeah i did talk about fuzzing but uh i should probably have brought that out a little bit more maybe ecker's idea is much much better tell me all right one high level comment on this is like i would suggest that the normative bits should be a bit more generalized that they should be around the fact that the client and the target should ensure that the protocol that is encapsulated isn't going to be vulnerable to replay attacks and then drill down more specifically for the binary htb case and say okay here's the date field or we talk about the technique and then yeah i mean calling out to your draft makes sense but i think probably be a pretty soft reference because other protocols like if i'm doing just dns message wrong here or something new in the future like that will have their own considerations and those don't need to be a fundamental dependency"
  },
  {
    "startTime": "00:38:00",
    "text": "from the main ohtp draft yeah that's um this is really only http at this point so i don't think we need to make it particularly generic but it does i think i think we do a text on the generic protections that are necessary if we don't then let me know fix we'll fix it up eric yeah similar to the to tommy's comment a moment ago i think this is enough of a case that a lot of the uses of oblivious won't care about this to the point where i don't know if this really belongs in the main oblivious draft at all this i think this should either be either something generalized or maybe just a a quick informational draft of if you care about replayability attacks and your oblivious usage here's what you do about it and then the main draft can just be nothing other than a citation of hey replay is a concern for it here's the draft to look at if you do care but overall since i think the majority of usage won't care i don't think this should be polluting the main draft um okay let's take this to the list because i think this is a little bit more challenging than i had anticipated let's see where we're up to and the queue is trained great so we'll take the take that to list there's some ideas floating around here that we can probably take up uh i'm not convinced that we can ship something like this without some replay protection but we'll see so um final final issues a couple of small things uh issue number 58 uh and and 19 are things that i think we can dispense with relatively quickly here i just wanted to test"
  },
  {
    "startTime": "00:40:00",
    "text": "since the room on two of these things the first one 58 asks whether this work should be experimental i'm going to suggest no does anyone disagree with me please come to the like if you have an opinion on this whether this document should be experimental or standards track i've implemented this i think we plan to ship this and there are others so it doesn't seem to make much sense to make it a grand experiment but uh i'd like to hear reasons why there's feedback on the in the chat that says not experimental wouldn't it be great if medieca would scroll the chat all right so uh issue 19 uh is um talking about discovery and there's a number of things that we could talk about in discovery um i think i'd just like to reaffirm that we're not going to do it in this draft we may do it in this working group i think tommy has a document that's talking about discovery or at least some aspects of the discovery related to this there may be other things that we need to discuss about discovery i suspect this is a very long topic and we should we should continue having those discussions does anyone think that we need to address more of the discovery problem in this in this document now i've got a couple of notes"
  },
  {
    "startTime": "00:42:00",
    "text": "but those people are sensible [Music] because i don't know how to do discovery in this document uh because yeah i can imagine the service b config stuff um is is going to be enough of a challenge for the what is it ddr so i would note that the charter text on this says that the working group may work on other use cases or deployment models including those involved discovery so this is at best secondary in the charter so with that feedback i think we're good to close that issue off and move on that's me done thanks martin i think next through hello hello uh theory did you wanna uh [Music] you want to share a screen or um i think it might be easier to do sharing of pre-loaded slides yeah that would be great yeah wait do i have to okay can you try controlling that yeah"
  },
  {
    "startTime": "00:44:02",
    "text": "hey um good afternoon everyone i'll be i'm through from i will be presenting the obvious proxy feedback draft we published this rap a few weeks back and we got some feedback on this stuff so we worked on that so i'll share the feedback as well as what this draft is trying to propose the problem is quite straightforward that uh uh because we have there's an obvious proxy which is basically uh masking all the clients behind it and sending the traffic there's a good chance that uh the traffic that's coming from the proxy could exceed the uh capabilities of the target server and that would cause it to start rate limiting the traffic from the process this is something that we have seen in various deployments today with regard to various types of rate limiting that gets applied uh but this is quite different that because there's a proxy involved typically the rate limiting is usually applied for clients but in this case the right lifting would get applied to the proxy and if the rate clipping gets applied to the proxy then it would start harming all the clients that are behind the proxy that's the problem that we are trying to solve by this draft the proposal is to signal the overload from the server to the ws proxy and the proxy uses this feedback to rate limit uh any http request from uh like offending clients or misbehaving clients or botnets which are trying to overwhelm the server uh one of the feedback that we got was uh there's already a draft in http api working group with regard to use of rate limit headers which basically is publishing the quotas or service limits to clients uh we updated the proposal that we have to align with this draft to basically send those quotas or service limits only to the proxy and not to these offending clients so what we did was uh we introduced a new uh proxy header earlier in the zero zero version we had just a feedback editor and the feedback was not to pick a very"
  },
  {
    "startTime": "00:46:01",
    "text": "generic header so we changed it to ohi proxy feedback header which provides feedback from either the request resource or target resource to the proxy and the whole idea is the proxy would remove the header before sending the http response to the client a simple uh workflow would be like the client gets sent in that's in a crafted packet just to target the server and the target resource identifies that it's an uh malicious request and it sends in 400 response along with the ohio proxy feedback back to the request resource which which again forwards it to the proxy proxy basically takes it out from the foreign response puts it in uh the request resource takes it out and puts it in the 200 response only for the consumption of the proxy and sends the encapsulated 400 response without this feedback header and then the proxy applies this rate limiting rules that if it believes is the right remitting rules that the target resource has given it and the 400 response would hit the client back so what we did was uh all these parameters that we have would be part of this uh proxy feedback header uh so we have picked the various uh fields that are there in the rate limit headers to be part of this header which would be sent back to the proxy for enforcing this rate limits either for the proxy to enforce late remits or for if it's an offending client which is trying to attack the server then the target server can ask to the proxy to uh rate limit this uh offending client and uh and the server obviously in this case would not have any information about the client all right do could i ask you a clarifying question please sorry to interrupt yeah could you go one slide to slide five please sure so when you were first explaining this i"
  },
  {
    "startTime": "00:48:00",
    "text": "was assuming that the request resource was getting too many requests from the proxy resource but now i'm kind of thinking that the target resource is getting too many from the request resource so can you clarify in which which server is being overwhelmed or receiving malicious requests here so so in this example we have just targeted the target resource getting an offending packet for example assuming it's getting an abnormal header the attack could be even on the request resource that it's getting let's say and garbled encapsulated request and it tries to decrypt it and it just fails so the attack could happen the draft currently talks about attacks uh encapsulated malformed uh request or higher rate of request coming and hitting the request resource or it could be hitting the target resource with crafted packets okay thank you i'm gonna need to think about this some more thank you hi um eric scroll um i guess i'm a little unclear on how this is supposed to work so um you know the um you give the example of um of a uh undergraduate message but like it's perfectly easy to make a decrepit robust critical message right so i guess like so i guess like what i'm trying to understand i mean it's like there's there's like like so there's like one very specific set of veg cases where somehow there's a particular kind of like message i send that like has abuse like has abusively high single message consumption of resources on the server um like i do something that requires you like making a normal secret powerful big computation right and then no legitimate client would ask for but the way that dots and act like frequently work is i send legitimate appearing requests and um and they're indistinguishable from illegitimate requests and their problems the volume of those requests and so given so i don't understand like which give it if you're getting if you get you know if you're if you're able to channel a thousand requests a second and you're getting five thousand requests a second like to which ones do you send the throttling messages"
  },
  {
    "startTime": "00:50:00",
    "text": "yeah there are two types of attacks when i was referring to either it could be a simple http flood or it could be a flash cloud scenario and it's quite undiscontinual in which case the target resource is getting over and branded want to handle those the other one is basically an attack where it could be a slow loris or it could be a malformed request or a garbled request kind of an attack okay but we agree this does not work for the ones where it's just a lot it was just a lot of legitimate looking traffic right sorry i didn't get that we agree this does not work for ones where the traffic is legitimate working right yeah yeah the malicious request is not for the legitimate tracking but for if the target resource is getting really overwhelmed with let's say black millions of requests coming from the proxy and it wants to rate limit then it can basically signal that the rate limit is not just specific for a client it could be for the proxy as well i guess i'm still not like i hear you're saying but i don't i don't see how this works because you're just now you're just rate limiting everybody like you got you got i mean for this to work properly to discriminate between the valid traffic and invalid traffic and um you know if you just don't like how much bandwidth you're getting likes like you know slow down your tcp stack or something i mean like it just seems like you know i mean i i guess i mean it seems like i mean i i guess if you're just trying to like like narrow the amount of bandwidth being assumed but you're not like actually writing any any better service right yeah narrowing the bandwidth to to basically give an equal share to all the clients both the legitimate and uh i don't understand how that works what i'm saying is is that like the the nature of the proxy is to transparently send the data coming into the data coming out and so in order to and so like and it will like naturally attempt to share between those clients right and so if you want to like do less you've got to somehow tell it give these clients less and these other clients more i don't understand how you're saying that well but ecker the the whole"
  },
  {
    "startTime": "00:52:01",
    "text": "concept here is that the resource server can't or the request server can't distinguish the clients i think the idea here is to say dear proxy server figure it out because you can see the clients by uh okay but i guess like sure okay i guess but like um i mean i would hope the processor would always do that i guess one might think so we have a bit of a cue here um tommy hey all right um thank you teru um so actually to this point that you have on the slide right here about aligning with the rate limiting um it doesn't really seem to be quite aligned i see that you're using some of the same terms as like the values of your http fields but in the right limit document those are the actual field names the header name so i would really suggest like just use the rate limit headers i i don't see really what we're getting from these additional ones um and overall the reason why we didn't pick the fields as is as what is there in the rate limit header was we didn't want this uh signal to go back to the client if it goes back to the client then probably the client would know that hey it's attack strategy is being identified and that's being mitigated so we wanted the signal only to reach the proxy so how do you distinguish other fields that are i guess i would say um overall for ohtp if it's not already said the proxy should not just be relaying arbitrary headers between the target and the client or the client and the target um i i if that's not said it should be said by i wouldn't expect that the proxy would just say oh yeah the target just can just include whatever random data it wants and then we'll send it"
  },
  {
    "startTime": "00:54:00",
    "text": "kind of as clear text not inside the actual encrypted payload right and with the current rate limit header i believe it will be in the encapsulated response so the proxy wouldn't even know what is there in that right yeah um and then overall this seems like it's like what we should have here is just normal rate limiting between the target and the proxy saying hey proxy you're sending me too much and then the proxy should just figure out on its own what it needs to do about that and it can identify its own clients that are overwhelming it right but that's it we should just leave it very very simple this is just two layers of normal rate limit headers and we don't need another header field here i think okay so sure yes we can restrict that quick point of order um did you have more uh presentation content you wanted to get through because we have a queue here we can put that off so you're done sure uh just one more slide so basically uh if i wanted to have a discussion whether this header needs to be only conveyed to trusted proxies and if an attacking proxy which is colluding with attacking clients would leak this feedback to change the attack strategy so is this something that needs to be only conveyed to proxies which authenticate back to the target reso target and resource servers or could this be used with any any any proxy that was one of the questions i wanted to discuss with the working all right going back to the queue eric mr escort law all right reggie from piconets uh just wanted to say you know um"
  },
  {
    "startTime": "00:56:00",
    "text": "i have only personally reviewed the draft but um at least based on heroes description if we can go back a couple of slides um i am still unconvinced whether this uh rate limit based approach is the right uh approach to take to try and mitigate these challenges so i i i see clearly that there are two types of challenges here that uh you know like eric mentioned one type which is where there is a obviously uh individual request that is likely to be malicious in nature either because of of the scope of that individual request or how it is structured uh it may contain junk or it may contain the kind of content which will is designed to overload the server okay so there the challenge is the fact that it's a malicious or uh you know overloading style request which you want to restrict the second uh condition that we are looking at is like eric mentioned a large amount of legitimate looking requests but just at a scale designed to disrupt the target server okay now in scenario one where it's an individual request that is malicious by nature of its content okay fill rate limiting are you going to send back a rate limit of zero because that's the only way you can guarantee that the next request does not come through right because here it's not the volume of the request that is a problem for the server it's the nature of the request so i have three clients each sending one request per minute but if those requests are designed to bring my server down and and the only way for me to stop them from coming is to send a rate limit of zero because these kind of malicious"
  },
  {
    "startTime": "00:58:00",
    "text": "requests are not designed to be limited by a rate limit type of mechanism so in the first in the first case rate limit is obviously the wrong approach to take to try and uh you know mitigate or block that particular traffic hey rajiv i'll answer the first question i think uh if you look at the rate limit headers graph right it allows a rate limit uh uh option where you set it to zero basically that means to say that the server is not willing to accept any any further client so the rate limit is typically a block action correct but then in this particular scenario because of the fact that you have two levels of intermediation with anonymization happening in between what you have effectively done by allowing rate limit zero to be said is you have dosed your entire proxy infrastructure no uh so if you see the headers that we have defined we have defined multiple headers one is rate limit p limit which is for the proxy and one is rate limit uh uh rate limit hyphen limit which is for the client basis which then brings into the picture the fact that now the now the dependence is on the target server somehow knowing that this is coming through a proxy infrastructure and i need to have separate headers for that or you are talking of putting intelligence at the request resource level to identify that when i get a rate limit zero okay i am now supposed to be uh setting the rate limit p limit and sending that onwards to the proxy but in in most cases the expectation from the target resource will be hey i am talking to the requester resource that's that's all i know okay i am the whole point of being oblivious is that the target resource should not have to know that it's coming through a proxy infrastructure anonymization intermediation is all a black box to it all it knows is i've received a malicious request from request"
  },
  {
    "startTime": "01:00:00",
    "text": "resource so i'm sending a rate limit zero to that request resource which means anyone any other traffic coming through that request resource has effectively now been dosed yeah it all depends on if the request resource and target resource writer requests because all this can share that it's coming by a client or a proxy right otherwise if it's let's say if it's a direct communication for example in case the target server could be attacked by both the client directly talking to the server or it could be coming by an oblivious uh path right yeah in both the cases the server needs to have that context right if you see what we have proposed is there has to be some uh communication that's happening between the request resource and the target to identify whether this was this request actually originated because it was obvious or or a direct communication so that way uh obvious basically so that the target can actually set the right kind of headers there yeah so this kind of goes against the text at least in the first section of the draft where it clearly says that the whole purpose of oblivious one of the use cases that should be supported is the fact where the fact that traffic is coming through an oblivious proxy channel is masked and not visible to the target resource the target resource should not not know nor care that this is traffic coming in from an oblivious reason yeah it doesn't it doesn't care about the client identity right i mean that's the purpose of ws is my understanding but whether it knows that it's coming because obvious protocol is being used it's not going to invade the client privacy in any way right okay so so on on on the one hand then you're saying that yes uh you know you will have some sort of uh probably header level communication between the requester and the target saying that hey oh oh by the way this isn't a request directly from me it's from it's for a downstream client of mine but it's anonymized so therefore i'm not sharing that with"
  },
  {
    "startTime": "01:02:00",
    "text": "you so and and then you're talking of uh the target server then having intelligence in it to understand this communication from the requester and know that if i see a malicious request of type one i need to send back headers specifically allowing the requester resource to continue to come to me but also to communicate downstream to its clients saying that you you specific client are no longer allowed to come right okay now i think you should move on congratulations yeah let's check the discussion on the list but the good questions thank you thanks for all the questions here okay can i very quickly address my second point uh which is the volumetric actual volumetric attack that date limit was designed to counter against uh i tried to keep it down to 30 seconds so um again in a case of a rate limit the same you know limitation applies the target resource has to be aware that this is a volumetric traffic coming through a proxy infrastructure of some kind so that right you do not land up in a scenario where the rate limit basically doses your proxy infrastructure itself correct and secondly there's a even bigger problem if you come back to the previous site on the proxy resource side when you're dealing with a volumetric proxy the minute you start having to maintain state of saying okay these are the list of clients who are blocked or these are the list of clients for whom these rate limits are set up especially in a volumetric attack that effectively becomes a toss on your proxy resource because your state table is going to grow to a point where it probably is going to land up becoming unmanageable right so that's also it all depends on the way that yeah it all depends on the way that you enforce these rate limits if you're if the proxy is authenticating the client then it's a different way of"
  },
  {
    "startTime": "01:04:00",
    "text": "enforcement if it is not authenticating then how do you put acls for example we have we have been implementing rate limits for ddos attacks all the while and we could even program millions of such ip addresses to be blocked or rate limited so uh i can share more details on how it could be done okay but i'm i just point out that that should be something that should be addressed in the draft specifically because it is a it is a non-trivial problem i i'm pretty sure you are good that you you have a lot of data you have a lot of years of engineering behind being able to do what you're saying you're doing now right thanks rajiv let's move on eric yeah sort of quick mental exercise to sort of decide if this is a worthy thing to pursue or not if we ignore your specific proposal and just focus on what's the simplest thing to solve the issue i i limit the issue down to saying this specific thing that this request was doing something's bad in it and the proxy needs to know that to either ban or limit or act on that specific client if they have more requests of that sort i think the simplest thing we can do is proxies i mean the the server sends a bit to the proxy saying something was bad about this request and then that's one bit going from the survey prox and this immediately something hey this sounds very very very very similar to that whole shadow banning conversation we just had 45 minutes or so ago now so from that perspective maybe we should essentially shelve this until the debate is settled on the proxy banning thing and if it's decided yes sending one bit or similar information from the proxy to the server makes sense okay then we should go back okay this makes sense to send similar information from the server to proxy because that's in my opinion exactly what this is and if it is then then we can discuss okay what's the exact stuff that makes sense to be able to send and pick this back up again okay"
  },
  {
    "startTime": "01:06:12",
    "text": "hi ben schwartz so i think this issue is real i think it's it's worth solving i think that you're i understand the concern that you raised about using the unmodified rate limit headers directly and i think the solution is to use the unmodified rate limit headers and work with that draft and the http draft to make sure that they actually work in the way that you that you want it to work here so i don't think we can i already reached out to the authors of their draft to help us out so yeah we'll work with them so yeah i don't think we need a new header here but i do think there's there's some work to be done yeah the whole challenge was how do you make sure that the proxy strips it also if there is a way we can the the target resource can put these headers but the but how does it from from the http response and how does it get percolated back in a way that uh it's it's it's it's not being sent to the client field we can discuss that yeah that can be specified either as an aspect of the header itself or as an aspect of http proxies so eric had a fairly good in it that i think probably works in this case um it requires communication between the request resource and the proxy not the target result and i'll get i'll get to that but um just like in the in the issue 66 discussion we were talking about sending a a single bit that says this this client is suspicious um in the direction of the proxy to the request resource not the target or the request resource"
  },
  {
    "startTime": "01:08:01",
    "text": "accordingly the same applies for in the direction from the request resource back to the proxy and and that single bit with the same sort of standing uh would work uh it does require there is a private communication um that the proxy resource understands this message or that the proxy resource is not it's not generic and doesn't blindly pass uh header fields alone but i think both of those things are quite reasonable in this heading for the target resource communicating this state there's a lot of cases where you'll have the request resource and the target resource collocated in which case none of this coordination problem really needs to occur over the wire in the other case i think that the the rate limit stuff doesn't work in this case because of the way that it depends on understanding who the client is but some there may be some ways in which we can signal um those sorts of things i think there are two different solutions there though and um the more important is the is the signal that is private between the request resource and the proxy resource okay and it is just that one bit this request was potentially suspicious and then you potentially have to have the volumetric things as well sure see since martin you're suggesting that for malicious requests we just say that it's a malicious one rather than uh providing any rate limit uh parameters but for proxy continue to have the right limit uh parameters being pushed on to the proxy yeah i i think in a lot of cases though as as ekka pointed out the individual request won't be problematic it will you will need some other ch or perhaps a separate type of signal"
  },
  {
    "startTime": "01:10:01",
    "text": "that says hey by the way uh the number of requests or the rate of request that i'm receiving is too high proxies start looking for for individual clients that are acting badly and and try to eliminate or slow them down in some way that i think requires probably a richer outer band communication than what the individual request headers can provide us with okay uh why do you think that uh the inline one is bad and we need an out of band a new communication channel sorry i'm going off then you ask me a question um for exactly the reason ecker stated which is that individual request in a denial of service state will generally be genuine or appear to be genuine so um it will be from the perspective of the server that's operating here it will be unable to distinguish between the the requests that are coming from bad actors and good actors and all it needs is try to push further out toward the edge the responsibility for filtering those down got it one additional point that just came uh you know into my way or achieve here uh was the fact that in uh cases of most target resource servers um while they may implement things like sending out rate limit headers and stuff like that many times when there is detection of any sort of malicious traffic there may also be other security measures that kick in um i like an application level firewall that starts uh blacklisting stuff like that so um having some text in the draft specifically saying that"
  },
  {
    "startTime": "01:12:00",
    "text": "hey uh you know any traffic that's going towards a target resource from a request resource must contain some header or some indication that it's coming from a proxy which then allows the target resource to say hey um yes i'm seeing a malicious request that would under normal conditions lead to an immediate fan on that ip but because it's coming from a proxy infrastructure of some kind i don't do that ban right now because i may end up impacting legitimate users which again kind of to me it's a bit of a disconnect between the text of what the draft is intending saying that you don't want a mechanism where target resources have to be necessarily aware of the oblivious framework in order to be able to support the traffic so i just thought this was also something since we're discussing security implications that should be part of the draft and uh you know it's a problem that needs to be addressed even if we don't have a solution for it at least say that this is a potential problem that we need to look at yeah that's a good point rajiv i think we can add some text to address that okay great i think we've drained the queue um yeah so it seems like my sense is that um the is that there is a need for something like this but um maybe that should go in the http api range limiting draft um in a section over there or sounds like like more fundamental work is needed in the contract yeah especially we'll work on the feedback and i think we'll get a new version and then we'll take the discussion on the mailing list to see which working group fits us okay perfect thanks a lot"
  },
  {
    "startTime": "01:14:00",
    "text": "great um tommy you up next thank you let me show the slides and i'm going to forgo sharing video for the moment apologies all right so um we recently posted a draft about how to do some discovery of oblivious target configurations via dns using service plan service binding records and this is what martin was referring to earlier as one of the directions for discovery this is certainly not the only mechanism that could be used for discovery it is a particular model that works for a particular deployment scenario there are other aspects of discovery that we would want to get into but this may be a good starting point to the conversation so what does this document do it's relatively simple it sends the oblivious configurations as well as when needed the http pads for targets and is specifically for the oblivious targets and it sends these through dns records and these are defined using the service binding slash https rr types which allow definition of new parameters and i explains how you can use these for discovering the configuration for a generic oblivious http target and essentially learning that a server that you would normally access not obliviously also does offer an oblivious target but then it also talks about how to use this specifically in the dns case for doing oblivious dns over https"
  },
  {
    "startTime": "01:16:02",
    "text": "and this is the part where at least for my end we have a lot of experience deploying it now and this is where this becomes interesting this allows us to integrate with um work that's going on in the add working group to discover uh encrypted resolvers either via a dns query to a well-known resolver.arpa name or as something that can come in dhcp or ra messages and this also um explains the similar use for the previous version of odo which is the experimental version that pre was the precursor to a lot of the oblivious http work what this document does not do at least in its current form is talk about anything for oblivious proxy discovery that's one thing that i think martin brought up an issue and the draft could probably be more clear and emphasize this more strongly that it does not cover this the proxy discovery case could be added but i believe it's something that's quite different as we discussed earlier the relationship between a client and a proxy and that trust about what it's doing what it's potentially adding or not adding really matters and i don't see as much of a use case for that being arbitrarily discoverable in a mechanism like dns maybe there could be a registry of known and trusted proxies but what we're talking about here is discovering targets now there will be a little bit more on this later so as an example um the we have two cases here we can have"
  },
  {
    "startTime": "01:18:00",
    "text": "oblivious dns um being advertised for essentially the discovery of encrypted resolvers case ddr so we would have a record for dns.resolver.arpa amongst other things it could say that it supports an odo server this would include within it the fact that this is an http target it would have the path to use for do on this query along with the list of o http configs this is quite similar to how the encrypted client hello tls configs can be communicated in the same way and you can imagine this then works also for a generic oblivious http case where i could learn that metricsupload.example.net supports oblivious http as a target and i could learn what its config is there so to walk through a very specific example and this is kind of the real life case that we would have i have a client that has an oblivious proxy that it goes through that it trusts that has a strong relationship with and it currently would be by default talking to one or more oblivious dns targets that it knows about this is how icloud private relay works today and in this scenario i can imagine that i join a network and i connect to the isp dns resolver just for my normal maintenance traffic i can query it for dns.resolv.arpa and i learn that the isp has designated a specific oblivious dns target and the reason that this could be interesting is maybe there is some in country or in isp policy about the type of responses i get from a server there are you know various regulations"
  },
  {
    "startTime": "01:20:01",
    "text": "in places about what content someone may be accessing and so the case of maybe my isp knows that this is a child's device and it wants to have some filtering for particular content i do not want to when i'm using this privacy system disclose my kind of full browsing history to that isp dns infrastructure but i would be happy to go through a proxy and use oblivious dns if that is safe and so if we learn that configuration we can essentially bootstrap this and the client is now able to access that isp selected oblivious doe target if that target is known and trusted by the proxy so there is a transitive trust relationship here in which the client has to trust the proxy in the proxy or some other mechanism that the client can check against validates that this is not a unique per-client target but is something that is more widely known and registered so to be very clear about the deployment model for which this works this is a case where the client knows one or more proxies that it already trusts it's not trying to discover that the client wants to be able to access oblivious targets that are published by their local dns or public dns the client needs a way to know that this target is supported by a proxy and what path to use because oblivious http does require that there's a mapping between the request to a proxy and what the target is um this i'll point out and there's actually an issue on the main ohtp draft that ecker raised about the flexibility of these mappings while ohttp does require that you have a one-to-one mapping that one-to-one"
  },
  {
    "startTime": "01:22:00",
    "text": "mapping could be something that is also expressed as a uri template so it is possible to have this be a bit more generic as long as the proxy is doing the correct access control checking i think that having an unknown or untrusted proxy that i need to discover that's not a very clear use case from what i can see right now if someone does have a use case for it let's definitely talk about it i'd love to hear it but at this point i'm not aware of that so the question is you know do we want to adopt something in this direction um certainly you know there could be more refinement and changes but you know do we want to be able to communicate these types of configs in service binding records if so it seems like it should be in scope for the charter as one of these secondary items and as part of that we'd like to get these um service binding parameters allocated because we are planning on using them for our olivia's dns deployments and that's all i have hi tommy um thanks for raising this um i'm a little um i i understand what you're saying and i think this is like a reasonable thing to think about um i'm trying to think through some of the privacy implications and it's not like entirely clear to me that the price implications are straightforward as one might imagine and so let me give you a concrete example supposing i have um two and i have two endpoints um i i have two you know dns endpoints a and b right and they're otherwise identical and um i'm the isp right and um i've two there's end points a and b are identical and so to everybody but you i give a"
  },
  {
    "startTime": "01:24:01",
    "text": "and to you i give b and yes um and that they're specified by by path or whatever right and so yes now and so now as another proxy like faithfully does this it hides everything but it doesn't matter because i okay because i've i've now i've not linked up the dns publication in that and so i'm like i'm like i'm just really worried that like actually this will be quite easy to attack um and i can imagine like i can imagine a bunch of other like variants of this well i give like really short dhcp lifetimes and then i like i encourage your identity and like in single bits or i have multiple things i mean i can imagine a lot of ways to attack this directly and so i i i guess like i want to persuade myself if this actually is going to work um right exactly and i think that's so the approach you know we are thinking of here is again relying on this relationship between the client and the proxy and that there is trust there the proxy is in a place where it can ensure that the volume of traffic of essentially different clients to a given target path as well as like the the key ids of the configurations is sufficiently large the proxy can definitely recognize or clients could all report to some other entity for transparency you know what are the paths and stuff they're seeing so you could detect oh this is a unique client and they're the only ones who get this um and that that's part of why i think there is a there is i think a case where this discovery makes sense and is useful but it's it has a lot of constraints on it and it doesn't make sense oh sorry i i don't know what to do about that you're better now okay sorry um anyway yeah i i think it depends a lot on how the client can trust the proxy or work with other clients to detect"
  },
  {
    "startTime": "01:26:00",
    "text": "um unique configurations and i think we have a call out to some of the work that chris and mt we're doing for key consistency right well i i i think i guess so i i think well i guess i perhaps feel differently about this in the sense that like i feel like we kind of we kind of like hand weight this away when we when we started privacy pass and now we're like having to fight it because we haven't waved it away and we didn't have a solution so i guess like i'm a little reluctant to take that bet again um without having like some a more clearly worked example of how to make this one how to actually make this work but um um but i agree it's a problem worth trying to solve thank you hey ben schwartz so uh maybe some people didn't see the the comments on the the ohio mailing list about this but so i read through this and i conclude this is this arrangement is um first of all not secure like above all this arrangement uh essentially hands over root ca powers to the proxy server who can now arbitrarily invisibly impersonate any um any website on the internet uh it doesn't even have to be a website that actually supports oblivious http um so i am seriously concerned i do not support the draft as as written i do think that there's i i do disagree about that model i think it'd be good to explore that a bit more right sure so there is a trust relationship between the client and the proxy already and i don't think that it's going to be able to just grab tell the client whatever keys it wants that's not where the keys are coming from uh right the keys are coming for over an insecure channel they're coming through the dns which is assumed insecure unless stated otherwise so uh in our in all our threat modeling"
  },
  {
    "startTime": "01:28:00",
    "text": "for the web we always assume that a dns attacker could be swapping in arbitrary things we don't trust you know we don't rely on the ip addresses coming back from dns or anything else uh to be secure in order to in order to authenticate the domains that we're visiting uh this this would change that this would say that if the proxy can poison a dns cache if the if the entity that operates the proxy can also execute a dns cache poisoning attack or just operates the dns resolver which seems entirely reasonable or happens to be near the path between the user and an insecure dns server which also seems highly plausible for a lot of these proxy deployments then the proxy can swap out the or or even inject a synthetic ohttp config for whatever domain the the user is attempting to resolve and then act as the origin so to me that makes this really a serious problem i also have some other concerns with the design i think the use of a path here is basically wrong the dope the path the doe path parameter in the dough service b mapping is not a good thing it's there as a compatibility hack to be able to work with pre-existing dns over https servers but the the dns service beam mapping has a long long multiple paragraphs of caveats trying to explain the dangers that this creates because that path again is attacker-controlled so uh so you can't assume anything about it there's some problem like pat multiple paths on the same server can interfere uh so i think that we shouldn't have a path here right there should only be um that should somehow be a fixed value effectively you know through the dot well known mechanism"
  },
  {
    "startTime": "01:30:02",
    "text": "is required to be known i understand but we don't need it to be flexible um given that there is no install base that we're trying to maintain compatibility with we can set that we can say in the case where you are trying to upgrade a a standard http connection in this in the case where you're trying to bootstrap ohttp off of a dns name where all you have is the dns name then we can say there's a fixed default path for that or there's a fixed inbound mechanism for learning that path by again querying to something in dot well known i do think that there's a version of this that can be made secure and and workable and it's actually much simpler and that is to just set a flag here that says i do http or i require ohtttp and then let the client actually contact that origin directly and you know through an authenticated channel learn the ohtttp config learn the preferred path and then use them alright ted uh ted hardy speaking um can you go back to slides seven and eight please start on seven uh so if i understand this correctly um once the client has gotten information that the isp dns resolver is accessible through the isp doh target it tells this information it starts to use this information through its proxy and i want to make sure i understand this correctly because is it your presumption here that if the isp dns resolver presents an isp odo target it must always be accessible"
  },
  {
    "startTime": "01:32:00",
    "text": "to all parts of the network in order to work with any proxy because typically isp dns resolvers aren't globally accessible and this makes them so and i want to make sure i understand that that's your presumption here that that is correct it doesn't necessarily need to be open to anybody in the world it could certainly have an allow list of known proxy deployments that it is willing to work with but yes it does need to be reachable via the proxies and that means it's not isolated within the isp network okay so i i think this is worth unpacking a little bit more as you think about how this goes because there are a couple of consequences to that one is you if you say there's an allow list um you you either can pay a penalty um by checking each one of the proxies that you have access to to find out if any of them are on the allow list and that that's perhaps not a very serious latency penalty but it definitely would occur if the only way to discover whether it's on the allow list is by experimentation or you can publish the allow list in some way and i think if you publish the allow list you actually have changed the scope of what you were talking about from changing how do i find a a target to also how do i find a proxy because what you're in effect doing is using the the information uh from the the information carrying that the target list to also carry uh the the permitted uh proxy list so i think if if you're gonna go down that path and use that allow list as something that's published you're you're in effect whether that's generic or not you are providing discovery for for proxies i don't necessarily think that's a bad thing as was pointed out on the list this is this is sort of a twinned problem here a proxy is useless without targets and the target is useless"
  },
  {
    "startTime": "01:34:01",
    "text": "without proxies they don't without knowing both of them you you actually can't get this oblivious service but i think if you are going to do that you have to kind of rethink architecturally that that's the scope now and is this the best way to do it um and maybe maybe that does need some more thought thanks all right thank you um and just to respond quickly to that so yes you certainly could have an approach where along with the target information and target configuration you get a list of associated or trusted proxies the other way that this can work is again the client has to know with its proxy what the mapping is of paths so if the client does have multiple proxies it essentially needs to be able to ask its proxy have you heard of this target do you know how to access it and so it's not like we will have to actually have to create and just try random requests it can have its own communication with proxies to say do you already have an established relationship with this target uh so i agree with that thank you and um there are other ways you could do it as well right the the dns resolver target could tell you uh what uh its reachability limits are and say basically give you a reachability limit that's only within the isp um or only within some region etc and so you could do it in a bunch of different ways but i think it it may be important that you work out in a little bit more detail which one you expect to be the standard davidskenazi hey tommy um so overall i think there's definitely value in having a way to um for a target to be able to say hey if you want to talk to me here's a way of"
  },
  {
    "startTime": "01:36:00",
    "text": "doing it that improves your privacy so i i like that i think there's a problem worth solving here um however uh and i think you know some of the deployment concerns uh are somewhat orthogonal uh some of them not all of them but the the point that ben made where uh because of the way we have odo sorry oblivious http today um you don't have a step or you verify ownership of the private key for the tls certificate um that breaks kind of the security model of a lot of things so i would say totally agree with the problem to be solved here um i think we should refine the solution to make sure that that gap is fixed because otherwise this sounds like a giant foot gun thanks all right thank you martin you're in front of me i wasn't sure if it was me so i'm sort of wondering whether there is something here that's a little little different in terms of the design that might be might be able to work so i i think the large open problem that you have here is that there's there's a target and you've described a way of discovering the target which i think generally works um there but the discovery proxy and finding the intersection of the set of proxies that the client will trust and the set of proxies that the target will trust is challenging um and because there's no discovery mechanism for the proxy pieces the information the client has is insufficient based on your your current design i think we did a little bit more about that to ted's point earlier so um i think we probably need something more"
  },
  {
    "startTime": "01:38:01",
    "text": "i found that the draft to be quite confusing on that front because thinking as a client i i saw a url but that's not the url that i i can use i need two of them in order to make a request with the oblivious http and you only gave me one of them so um i think there's probably around before we would go there yeah i mean to respond to that i think the existing model without discovery for either proxy or target is essentially you need some proprietary mechanism for learning the configurations and learning what your proxy is and what the paths are that map to your target so a lot of this is managed to clarify it assuming that you still have that proprietary mechanism to communicate uh what the config of the proxy is to the client and that essentially the client and proxy can learn you can negotiate what they support and what the paths are etc and learn whether or not this target is supported and a new mechanism have that relationship between a client and a proxy that is generic um i think is a larger scope and is less clear to me yeah so probably the uh other idea that i had here was if you get a url for the target resource there's a bunch of things you can do by talking to that target resource in terms of learning what proxies it trusts and learning what it's uh its config is that of course creates some interesting issues when it comes to consistency but um those are the issues that i think we need to be we need to be thinking through here"
  },
  {
    "startTime": "01:40:02",
    "text": "chris hi yeah chris box uh i work with bt um i just wanted to say i think this is a really interesting idea it it allows an isp to offer dns based services in a way that doesn't require exposing the client's identity so for example an isp could offer malware filtering you know for that service we don't get to know who make the request so i don't yeah i take the point of of others about yeah we need to explore all the implications of it but uh i think it's a it's a good idea and uh i'd like to see it adopted all right thank you yeah yeah definitely let's work work on the problem is right here and fix the solution yes eric yeah very very similar to the last comment actually i i think this is a very good problem i like the overall i like the overall solution i like the overall area solve i think this is something we should be adopting i think the only question is do we solve the very big security issues that i agree with almost everything ever said in those areas already do we solve those before we adopted or do we adopt and write the solutions for them and i don't think they're too hard of security issues to solve we've had a lot of talk in the chat about hey signings of all this the draft r discussed a little bit linking the consistency draft for stuff about the the other one that echo was discussing earlier so i i think if we if we beef up the handling for security implications this is a very good draft to have so i mean i'd say let's adopt it and do that beefing up great um and what i would say is besides stuff on the list there is a github for this and so eric and ben and egger"
  },
  {
    "startTime": "01:42:01",
    "text": "if people have ideas let's work on them and try to revise this we can turn out another version of the draft quickly and if that's something that people like the solution on more then that would be a good adoption target all right i think that's the cue oh ben ben did you have any last comment there if there's time i'll say uh i do think that that to step back one more step i think that we need a little bit more of an integrated architecture approach here that figuring out what makes sense here really does depend on how we decide to handle key consistency for example it depends a little bit as some some other folks are saying on how uh how users are learning the initial url that that got them to this query so i think i would like to see us step back a little bit and see if we can get put together you know a set of puzzle pieces that really fit fit together into a into a clean overall solution jigsaw puzzle one might say yeah so i've been chatting with with my co-chair in the background here it seems like where we're ending up here is that there's you know some energy behind this being a problem that is useful to solve um but it sounds like this the draft is not yet in a state where it's it's kind of adoptable and there's enough energy around the draft in particular so i i think the investors there is to kind of keep refining the um problem statement and especially around the security requirements and um i think we can look at uh you know whether a future draft would align with that better"
  },
  {
    "startTime": "01:44:02",
    "text": "all right i think that brings us to the end of our agenda siobhan is that correct yes um we do have about 15 minutes left i think um you can just let everyone go early unless anyone has anything they'd like to say or we do have like buffer time um i don't know if anyone has any comments uh i guess something that we didn't want to ask uh which was that like it seemed like there were at least a few issues that were pretty i guess like hotly discuss so we were wondering if folks would be interested in having virtual interims well the shadow band case i think was the specific one you were thinking about but maybe for some of the other ones as well so if folks would be interested in that um i mean please let us know yeah go ahead martin i don't know i think given the feedback that we got on the shannon banning case here i i have a pretty good sense that we can come to a conclusion on some text that will work for it in the next i would say weeks uh the anti-replay stuff uh is maybe less settled but i i suspect we can make some good progress on that uh on on the list the discovery issue does seem to be something that is is worth um spending a bit of in person high bandwidth time on so if there's any topic that rises to that level i think that's the one that makes sense so it sounds like we maybe don't need to schedule a virtual inum right now but um if we get to a point where we're ready to have some deeper dives on those latter two topics"
  },
  {
    "startTime": "01:46:05",
    "text": "yep that sounds right um francesca anything you want to say no sounds good okay perfect all right then thanks all for coming and see you all on the list thanks for watching thanks again francesca for helping us thank you and thank you the minutes take care as well the three big rooms are closed because they were reshuffling them to prepare for the final well i mean just you can't you can't say"
  }
]
