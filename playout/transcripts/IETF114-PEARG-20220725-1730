[
  {
    "startTime": "00:00:06",
    "text": "okay thanks for the feedback yeah is anyone here willing to take notes for us it's a very simple job"
  },
  {
    "startTime": "00:02:04",
    "text": "okay we have chris off nice thank you can you repeat that sarah sorry so christopher patton has offered in the chat to take notes thank you thank you hey all welcome to the perigee session um we are your chairs um i'm siobhan we have chris and sarah joining remotely i guess sarah you're sharing the slides anyway do you want to go to the next one sure thanks this is the note well please note it well also please note that according to ietf policy we do have to wear masks inside all meeting rooms so just be aware of that and let's move on to the next slide yeah so this is the agenda we have three presentations and a quick update on um draft safe measurement i believe that mallory will be giving so we have i guess we can the chairs can do jabbers keeping an eye on jabber and we have a minute taker thank you chris patton and i think we can start so if sophia is online yes i am here do you want to present your slides yeah uh do i have to share them oh there you go okay it's me i'll wait"
  },
  {
    "startTime": "00:04:00",
    "text": "okay i see this light now and i see on the screen also that they are shown on person um let me stop my video okay okay uh should i just go ahead shivan sorry sorry was the question sophia should i just go ahead with the presentation yes yes please okay okay thanks um hi everyone thank you so much for having me here um my name is sofia celia and i work at brave software and today i was just going to present a very informal note or an informal presentation on privacy per se measurement techniques and as i said if this is just an informal comparison next slide please okay sofia do you see a slide selection at the bottom of your screen that you can drive uh no okay that's no problem we'll move the slides along okay thank you sir well thank you very much sir um okay uh suppress a little bit of a disclosure uh again this is not a complete overview but rather an initial note around the different techniques that one can use for indeed trying to try to attain privacy preserving measurement techniques and what it really wants to i aim is to answer the question if i want to execute measurements with privacy which scheme should i use and well in general that seems this likely seems like a simple answer in reality it's a very complex one because there's a big array of different techniques that one can use in different schemes um so it's difficult as a user of the system administrator or just a user who is a system administrator to actually choose the correct scheme or the scheme that best suits your need the other problem is also that as we'll see we have different techniques and different schemes and the majority of them really attain a level of privacy and security but it's difficult to correctly pinpoint and attest which specific level of privacy or security they are providing"
  },
  {
    "startTime": "00:06:01",
    "text": "there's also some clear expectations of the efficiency of monetary costs that indeed this these schemes provide and if you are interested for some furthermore some further notes i have put online displaying for my pdf that is going to be developed into some of something more formal eventually through the months nexus live please okay so let's just start from the beginning which one is the main notion the main notion is of course that you as a provider or whatever system or whatever application you want to indeed know something about your users and the reason why you want to know something about the uses is mainly because um you want to improve the usability of the system by understanding how indeed users use that system and while that this seems great in practice at the downside it has a big but consequence which means that we are learning certain private things from yourself that we are not supposed to learn and in the light of this the idea was to actually provide a privacy a private and secure way to actually attain to actually be able to collect these aggregate measurements um because of course as i said these aggregate measurements correspond to a centralized leakage of private user data currently the ietf actually has a working group devoted to this that is called ppm that precisely has been trying to standardize certain of the techniques that i'm going to talk about to provide privacy and security for aggregate measurements i think i now can do that yeah you should have companies yourself now perfect thank you um so a little bit of a wishful thinking so the first also question that one uh must pose themselves when actually thinking about it is what level of security and privacy won't want to attend and the first main definition that one one find is this web by the linus which is not a specific to taking aggregate measurements on the digital world but rather in general for a statistical disclosure control mainly the privacy and security that it aims to provide is something similar to"
  },
  {
    "startTime": "00:08:01",
    "text": "semantic security meaning that access to a statistical database should not enable anyone to learn anything about the user that would could not be learned without access and this is a very strong privacy notion that we will see that is achieved to a degree by the different techniques that this service works so let's start with the actual techniques and scheme and as i said there's many so i've tried to categorize in general by the specific technique that they use the first one is the techniques of differential privacy and the reason why i'm talking about this in the first place is because it's one of the oldest schemes there are out there to actually preserve privacy for aggregate um measurements and the idea in the differential privacy techniques is that some local randomness some kind of nose is added at some points when you're actually performing the aggregate functionality it could be to the data collector it could be to the output of the statistical function or it could be to the mechanism itself and what in general differentiation privacy wants to attain is a notion that is called epsilon differential privacy you will see here a mathematical notation just don't worry about it this is just for reference but mainly if you ever read the papers of differential privacy this is the notion that they want to attest and without any mathematics the meaning is that the output of the function of the statistical function is similar on both data state if you change or remove the one element so any kind of operation that you take in different data sets can someone looking from the side cannot differentiate there's two basic schemes that uh support differential privacy that he have been actually deployed in the real world the first one is rapport from 2014 until 2019 it was kind of supported um and basically what it is it uses the same idea of acting of adding local random noise into the statistics that is taken from users and also using memoization the problem with this scheme is that it is very costly"
  },
  {
    "startTime": "00:10:01",
    "text": "because locally you have to add all of this randomness and therefore it is very costly in the light of these this very costly another system was devel developed which is called proflow and it's much more efficient and also uses a different architecture the architecture that it uses is called encode shuffle and analyze it is an esa architecture and mainly the idea is that you also add this local randomness but this one in turn is augmented by a private channel that randomly permutes a set of user supplied data so you have the local one that you add and in the encoding section then you have a shuffle path that permits the different user data and then you have the analyze one that it just performs the statistical function that you need to perform what is the problem with this one is that is more efficient in a way but it also requires trusted architecture because you indeed have to trust the shuffler in order to be in order to be secure to be assured that indeed the mechanism is work so there you have a little bit of a downside of problem in the light of this all of these schemes of differential privacy i just touched two very lightly but there are many many more as you see um all of them could have a lot of drawbacks and in face of this another system was developed that was called prio and nowadays the ppm working group and the itf is also trying to standardize some preo based uh like schemes not specifically the original prio as it was first written in the original paper but kind of similar schemes what does basically prior 1.10 basically what we started on the first slide private aggregation and also they specifically specified three properties that they wanted to have privacy of course robustness and scalability so this is skin indeed tries to be a little bit more efficient and the way it works is that it works with a small number of servers and a large amount of clients and as long as one of the servers is honest the system leaks nearly nothing about the user's data except for what the aggregate statistic itself reveals so as you see here we have already a"
  },
  {
    "startTime": "00:12:00",
    "text": "little bit of a leakage of the of the privacy that the system provides because it's not completely privacy private as the first slide that i showed you wanted but rather than there is a specific amount of leakage so for example let's say that you are using a mean function you are trying to compute a mean functionality therefore something is leaked meaning the number of uses that have submitted some user data because you divide by the number of users so that is leaked by the aggregate function there's other variations of these schemes that as i said has been proposed to be standardized by atf you have prior plus but it's a little bit more efficient because it uses boolean circuits instead of arimatic circuits there's 302 which is not going to be standardized as far as i know um priya 3 which is the one that is going to be a sundares um as far as i understand and that one is more efficient into the client to server communication to give you a little bit of a specific pinpoint of the specific privacy that priyo provides it uses a specific privacy that's called privacy in which an adversary he controls any number of clients and all but one server there's nothing about the honest client's values except what they can learn from the aggregation function itself and this is just repeated why i already show you in the previous slide of what kind of privacy it provides it's kind of a bounded privacy in the sense that there's some amount of leakage um yes i'll take the questions at the end i see that there's some in the sulu but i will take them on the at the end okay so a little bit of a diagram for what uh does and know exactly how prio works this is just a really high level explanation how prio works but in general let's say for example that you are an user who is um who is going to a park and indeed is in the park and then the system actually wants to know if you are in the pack because the mobile clients for some reason want to know that um what amount of users are actually going to this park and if you are in the park then the mobile phone says one and if you are not in the park the mobile phone stay in steer and sends this data to a"
  },
  {
    "startTime": "00:14:01",
    "text": "collection of an amount of service so instead of sending the one meaning the yes i am in the top arc what it does is that it splits this one into shares in the shares for example of 15 plus minus 12 plus minus 2 which all sum up to 1 and sends the individual value to each server that uh that belongs to the system and as you see here each individual server will not be able to pinpoint which is the private value that the user is submitting because it's just a secret share that the user has been submitting to the server now it's important here of course that the user is honest in that the range value that they are sending should correspond indeed to that range meaning that they send either a zero or a one meaning a yes or a no sorry a no on a yes um but for example let's say that a client sends a two uh in this case um in general if you're only using secret shares then that's indeed possible that the user could be sending a tool so what you indeed also add in the prior system is that you add a serial knowledge proof that is a specifically called a secret shared non-interactive proof in the prior language and basically this is a proof attesting that indeed the user is sending the correct value in whatever range so in an example is the correct value is either a zero or a one and that is sent once that is sent to the different servers they each go between each other and attest to the validity or not and if indeed is valid they indeed aggregate whatever shares were shared with the servers and eventually they will be able to compute whatever aggregate function they were trying to do and as you see this is preserved in the face of a malicious client but then there's some efficiencies robust here mainly server to um sorry server-to-server communication is sufficient but server-to-client communication is inefficient because computing sometimes the serial knowledge proves well efficient than the previous zero knowledge proofs um it's still much more costly okay and also a thing to note is that pre-orbase systems uh only work on"
  },
  {
    "startTime": "00:16:00",
    "text": "numeric values meaning that you can only send numeric values but if you want to send something like a strings then the system does not completely cover that in the face of this there's another kind of problem that one can solve indeed when we're when someone is trying to have all types of data to be a part of an aggregate function and in this case we call it the private the heavy heaters problem one of the schemes on this is the scheme of the star that has been recently been um announced in a paper and also proposed to the itf not so recently i think a year ago it doesn't again focus on the specific f privacy problem that is that belongs to the previous system but rather in another privacy concept which is called the threshold k anonymity and basically the idea is that the server only learns any data from a client any private values from user if there's at least k minus one or the clients that are submitting this data and what it prevents is the preventative collateral from from being specific from specifically learning uniquely identifying information or uniquely co-occurring patterns of data from a unique line how does it work mainly what it happens is that a client constructs a ciphertext of the data using an encryption key derived from some randomness this random name is usually taken from a randomness server that uses an opr functionality to actually have this data then the client once it has the ciphertext sends the ciphertext to the service and also a k out of end secret share of randomness and tax these these shares within a specific task so the server will know which one to combine and at the end the aggregation server organizes the shares into subsets depending on the tax that was just submitted by the client and recovers encryption keys from those subsets of size uh bigger or equal to k and if you want that more a little bit more of a beautiful diagram it is here as you see here you have three entities the first one is only to actually gather the randomness in order to be able to derive the key that is going to be used"
  },
  {
    "startTime": "00:18:01",
    "text": "to group the ciphertext and then the other ones is actually the client sending the ciphertext to the aggregation server who will take the auxiliary tags that the client actually define will be able to reconstruct the specific for the ciphertext and we'll be able also to decrypt it one of the things that is important to note here in a specifically of the system is that is the first system that takes into account not only about efficiency but also the monetary costs that are associated with running all of these kind of ppn techniques mainly the system for example one of the aims was actually to have low monetary costs another system that is seem very similar to peop to prio is the popular system which also allows for finding the most popular string among a collection of clients as well as client as counting the number of clients that hold up giving a stream the only difference with prior is that in prior you will require only one on a server in this case you have a two no you have to have two non-colluding uh data collection service and it indeed also presents the same amount of privacy as free okay so um that's a little bit of a really brief overview of the different schemes but if you are a little bit more interested in how actually you compare to each other which was the core of the question when actually having this note um i kind of created two tables for this on the first time for example it's good to consider the type of data that you need one to use when you're actually thinking about choosing some schemes so as i already said the prior-based functionality somehow some numeric and then the star wars has some a string uh other kinds of types of data that can indeed be accepting there's also some types of robustness notion for example when i say that uh in some systems for example the trust assumptions are different in the sense that at least one server has to be trusted and on others they don't actually require any kind of trusting entity also as i said uh while all of them provide certain kind of privacy notion none of them actually attain the in original privacy notion that i just put"
  },
  {
    "startTime": "00:20:01",
    "text": "you in the second slide but rather all of them some have some kind of leakage in the case of pre-assistance for example i already mentioned that the leakage that they have is whatever that the aggregate function leaks itself that's leaked in the case of a star for example the server learns which clients share the same measurements in the same popular there's a leakage of all heavy heating prefix prefix sorry um all of them also have different efficiencies so we already saw that in the previous prior base systems you have an inefficient client to serve a communication that is improved in the iterations of the original video paper so you have a better efficiency in pre-ordering and i only added the monetary cost of the two last schemes of star and poplar because those are the only ones that i have seen analyzed for the monetary cause perhaps uh what is missing in this table is properly inputting for the other schemes but i didn't have a lot of time to actually analyzing them from the monetary cost okay so that's a little comparison and if a user wants to at least choose between all of these schemes you see there's a lot of values to actually compare and a test if indeed it works for your system or not something that is also interesting to note is that the user needs and most of the times absent from any of these kind of studies or even in the original designs in the sense that the voice of the user is notably absent and while it's great that these kind of schemes are advancing the privacy of the user at the same time sometimes users will not be wanting to participate in different aggregate functions service or in different kind of service in general and the reason why they will not be wanting to actually be part of the systems is because while maybe this system if they provide some privacy and not going against individual privacy they might go against the whole group privacy for example let's say that you have a survey about women and um about the number of abortions that women have i will not would like to participate in that kind of functionality even though even if the system says to me that it's private because the output of that functionality"
  },
  {
    "startTime": "00:22:02",
    "text": "of the function might be used to harm me as a woman that belongs to the woman group or as an individual that belongs to the woman group so the point here is that while it's important to provide privacy it is not enough it also has to take into account user consent and also yes i also have to take into account uh user consent we should be really noted and really important into the different design system and with that uh thank you very much sorry i'm running out of time um so yes sorry thank you very much all right thank you sophia unfortunately we don't have time for questions so we'll have to move on to the next presentation sophie there's a number of questions for you and chat i'm sure you could engage with those folks further there yes thank you all right so next up we have bharath can you request to share the slides okay can you hear me yes we can hear you okay one more time okay okay take it away okay thanks for having me so um i'm bar throgfin uh faculty at usc and uh co-founder and visit with paul schmidt um one of my colleagues um and thanks uh in this to to jana and chris and tommy for um a lot of the discussions uh that went into this so i'm gonna give a very high level talk very different type of talk um really trying to step back about this question that some of us have been noodling over for a while which is there are all these interesting privacy preservation network protocols systems architectures that have been come up with by a lot of you"
  },
  {
    "startTime": "00:24:01",
    "text": "in this group and folks in the ietf community in the network systems and privacy community for years decades really and we're trying to figure out what is uh in common among all of these the ones that we think actually achieve some sort of meaningful and practical privacy preservation and it seemed like there may be a sort of a common principle that doesn't uh satisf uh sort of address all of the questions that we care about but one of the core sort of design principles that may be underlying them and so that's what this talks about uh what we're calling the decoupling principle so at a high level uh basically the decoupling principle is for internet privacy you want to decouple who you are from what you do that's that's the nutshell of this talk this is an old idea is nothing new that we've come up with here uh chom introduced this in 10 different ways in a classic series of papers back in the 80s and then in the 90s um but it's been inconsistently applied over the decades for some reason this principle sort of gets rediscovered over and over again and then it gets forgotten and it gets rediscovered it seems like right now we're in a phase an era over the last several years where people have rediscovered this principle and are using it to good effect um and a lot of the proposals that have come out from many of you again have used this principle and so what we thought we would do is just step back for a second and think about what what's going on in a lot of these systems uh that enables internet privacy by decoupling who you are from what you do um and it seems like decoupling is easiest when we split uh by entity so meaning who are the different parties in the network that are participating to achieve some internet service and the mechanism that's being used so the mechanism might be a mechanism for authentication or mechanism for connectivity or um for"
  },
  {
    "startTime": "00:26:01",
    "text": "achieve um the decoupling is always going to be protocol and context specific so you have to look at the specific service that you're trying to provide of course um so we can go through that for a few examples and very sort of at a high level trying to understand what kind of decoupling is being achieved so the context here before we go into that is ordinary data confidentiality is nearly solved this is sort of a broad statement i'm making here but we're at a point where tls is everywhere data is encrypted at rest and if it's not we know that we need to do those things there are some hurdles in some contexts where you can't use tls or you can't encrypt data at raster you can't do some of the very well-known uh steps for data confidentiality but we know we need to do those things so the solution is there it's about implementation but what remains is this a little bit more complex layered metadata privacy problem and this is in many different contexts at different layers of the network stack everything from the mobile layer to various types of internet protocols to applications um and so you need many different overlapping solutions and so it's not that you would apply the decoupling principle for a single user in a single context in a single protocol then be done but rather that you want to decouple all the things effectively um and really the privacy challenges that we're dealing with here are fundamental to the internet maybe in a unique way versus all other sort of computing contexts because we rely upon others to carry our traffic and process our requests this is sort of a fundamental thing with networking that's not true in other domains and so you know a lot of computer science now is focusing on privacy and security but they don't have the same degree of challenge for privacy as i think we do so a little bit of terminology trying not to make it super terminological but"
  },
  {
    "startTime": "00:28:02",
    "text": "you know just to be a little bit more clear about what we're talking about so we're going to have a very crude uh binary distinction between sensitive and non-sensitive information that's the level we're going to stay at a very high level this filled triangle is going to be sensitive user identity so this is you know my my name or maybe in some context my home router ip address and the uh the hollow triangle is a non-sensitive user identity some sort of temporary identifier a random identifier um and then sensitive user data again is going to be context specific but it could be everything from the actual contents of a request that i make to some service um or the response that comes back um and non-sensitive user data would be uh for example the fact that i did make a request but no content of that request so then we can describe using we just have sort of a tuple which will say there is some party in some context that has some knowledge about the user and we're going to talk from a single user standpoint from the moment so if i write it like this sort of a filled triangle and a hollow circle then we're talking about somebody knows sensitive user identity and non-sensitive user data so how do we apply this so we'll go through a couple of examples using just existing systems and think about what the decoupling going on is but first there are some caveats obviously identity and data are always shades of gray the idea that we can say this is sensitive user identity and this is not it's really difficult to cleanly categorize that um but you know that's uh we're going to sort of use these generally understood categories for the analysis and then we can complicate it through thinking about side channels and you know all the shades of gray that also"
  },
  {
    "startTime": "00:30:00",
    "text": "come about for our user identity the same thing of course is true with data the data itself there's shades of gray of what counts as uh sensitive and non-sensitive and maybe even contextual some data might be sensitive in one context and not sensitive in another the user is ultimately gonna be the judge of that um and then of course further still identity and data are sometimes mixed and conflated and so there too this is going to be complicated so i'm going to just sort of put those caveats out there but also um we're going to ignore them for the moment and think about the the simple case first so let's just look at something we all know something like mixnets or tor and in this context we have some sender trying to send a message some request or data to some receiver over this network and they're trying to achieve some data or metadata privacy for their identifier their personal identifier and uh the message that they're sending the mixes are some third parties that are relaying the data and then the receiver is a partially trusted party who will receive and respond to the message so that's the setting that we have uh we don't have to go into the specifics of a specific design for this analysis so in this context the sender of course has all the sensitive information i'm the sender i'm the user and i know of course my identity so the triangle and the data that i'm requesting so that's the filled circle now the first mix here knows my identity in some form in the sense that i have to talk to them so they know my ip address or they know some sort of network identity of me for me um and then the subsequent hops know less and less so they don't even know who i am they just know that they got a message from somebody um and there's the uh the request itself which they don't know now there's also the context in which"
  },
  {
    "startTime": "00:32:00",
    "text": "uh it's i could pretend to be mix number one so mix number one actually thinks that i'm sending on somebody else's request right there's that design and in some systems um so mix one may not know even my identity so let's but let's leave that out for a second for a second um and then finally the receiver uh is gonna get a message from somebody they don't know who uh unless i specifically conveyed to them and that's going to be sort of non-sensitive user identity and sensitive user data potentially because i am sending a specific request which they are capable of decrypting so that they can then give me a response or maybe i'm just sending them data for their sake so if you look through this you see that only the sender knew both sensitive identity and sensitive data and so the basic idea the decoupling principle is really simple third parties should know at most one of sensitive user identity and sensitive user data and so some of them might know the identity piece but not the data piece some of them might know the data piece but not the identity piece and it's not always simply there's one type of identity and one type of data in some systems there are multiple types of identity one of the systems i'll briefly mention is gonna be it has a mobile identity piece and a non-mobile identity piece there's lots of other similar kinds of systems so this has been used all over the place there's all of the classic designs from chom and all the systems that have built upon choms designs they all exhibit the decoupling principle privacy pass and private private access tokens exhibit the decoupling principle in that context you have a client an issuer and an origin the issue or an origin neither of them know both uh the identity and the data uh in the context of oblivious dns and"
  },
  {
    "startTime": "00:34:00",
    "text": "odo the resolver and the oblivious resolver also they know either the identity or the data but not both same with the origin um in the context of pretty good phone privacy which is one of our systems we this is one where we have a mobile identifier and so you have sort of a user's human identity and their mobile identity and no system knows both of those uh in the context of private relay you have the same decoupling across the multiple relays that the first relay knows the user's ip the second relay knows the origin that's being requested but neither knows both and then private aggregate statistics you have an aggregator and a collector but neither knows both the private identity and the private data so there's a lot of these and these are just this is a very incomplete list of examples of systems that have used this principle and so really the idea in this talk is to sort of point out this the similarity across of these and so why does this seem to work why do people keep using it why does it seem to work um and it seems like this is an incomplete reason for why this works users often care about hiding their true identity from semi-trusted services and hiding the data or metadata of the requests from untrusted parties but they don't care about that often but sometimes they do whether they reveal that they are a user some user of a public or popular service so i don't mind revealing that i'm using such and such service i just don't want that service to know too much about me and i don't want others to know too much about me um and users often don't care about whether they can hide a request from the service who is actually providing it if i'm requesting something from a website and i have to reveal a little bit to get that information then i'm willing to do that because they are providing me a useful service"
  },
  {
    "startTime": "00:36:01",
    "text": "there are some cautionary tales and sort of examples of where this doesn't work and why and then we can use the principle to sort of see what maybe went wrong it's somewhat obvious in retrospect uh so if you take the popular architecture really not popular anymore but you know was it really common architecture i'd say 15 years ago um which is to improve security of some network or some system x let's just drop in a security gateway a middle box somewhere and that security gateway is going to do all the all the things we wanted to do to improve our privacy improve our security whatever it may be um and so in that context the sender of course has all sensitive info but the gateway also has all sensitive info that gateway is doing you often was and still sometimes is doing uh all processing for that user and so that means it's seeing decrypted traffic it's seeing uh requests that are going out uh it's seeing uh user identity and so you have to put all your trust in that and we kind of we've always known that um but this is just sort of a way of analyzing it to immediately flag the problem and then again the receiver doesn't have all that information so the value that we get here is that we can quickly identify problems that might arise by doing this quick analysis this sort of decoupling analysis this isn't to say that if we show that we've decoupled we've solved all problems obviously we need to be able to have consider lots of other things non-collusion between different parties that are providing a service um sometimes you get benefits by using hardware enclaves or trusted execution environments so you can shift trust and therefore shift who knows what um and then of course their side channels even if you decoupled there are tons of side channels the side channels are going to be context and protocol specific they'll still be a problem and will still change the nature of this"
  },
  {
    "startTime": "00:38:00",
    "text": "analysis so i'm almost out of time so i'll stop there um thanks for inviting me all right thanks broth time for a couple quick questions if there are any should i read from chat or what should i do here there was some chatter in the in the in the chat um uh some of it was carry over from the last presentation though yeah let's see here okay hearing no questions thank you broth um and uh we'll move on to the next presenter which is mike it's mike if you request to share your slides there's like a little button near the top left it looks like a piece of paper okay and then you should be able to drive all right perfect take it away yes we can hear you fine okay um so my name is mike rosalek i'm a faculty member at oregon state university i also happen to be on sabbatical at cloudflare research these days and i'm going to be talking about this paper that's going to appear next next month that usenix and i just want to thank the chairs for the opportunity to present here let's see if i can figure out how to drive the slides uh so this is a talk about ssh authentication and specifically authentication using public keys so i want to review how things currently work in ssh so when i connect to an ssh server my client offers a public key and says hey do you want me to authenticate under this public key and the server might say no in which case my client will"
  },
  {
    "startTime": "00:40:00",
    "text": "offer another public key and ideally eventually the server finds a public key that it likes and it says yes and in that case i authenticate by uh by doing a standard kind of signature of some of some random nots that's how public key authentication works in ssh and i'm here because i want to point out some privacy and security issues with this with this approach i think one of the most well-known problems with this is that the server can fingerprint the client and what i mean is that the server can just say no to all of the clients advertisements and actually by default the ssh client will send all of the public keys that it knows about that are currently loaded into the ssh agent so the server can see your public keys even your keys that are um you know presumably not uh not generated for this particular server um so i want to point out a cool uh application of this or maybe it's creepy i don't know if it's cool but maybe creepy and this is what first uh got me aware of this problem so back in uh 2015 ben cox had this blog post pointing out that on github uh everyone's public keys are truly public like you can just look up anybody's public keys in some cases that's a nice feature but he points out that if somebody cared enough they could collect a massive database of everyone's ssh keys and so that's exactly what he did and he did some analytics on these ssh keys and then a few months later uh filippo valsorta um had this cryptic blog post where he says uh he invites the readers to ssh to this server uh the server is still up i i encourage you to ssh to this server when i ssh to the server this is the message that i get and in particular um i didn't type anything and i just type ssh to this domain name and it knew"
  },
  {
    "startTime": "00:42:01",
    "text": "my my full name and it knew my username on github um so that's kind of creepy and the reason this works is that my github public my my public key for github ssh is loaded into my ssh agent all the time because i'm always using github and so my ssj my ssh client offers it to this uh the philippo's ssh server and he has a database of public keys he knows that this public key belongs to this user on github so this problem can be resolved you can configure your client to only send keys to the servers that you expect um so this can be resolved with some configuration changes uh and so if this was the only problem with ssh then i would wouldn't really have much to say um so i'm going to mention a few other issues with uh this ssh authentication another one is that the client can probe the server so the ssh client can offer a public key that belongs to somebody else suppose somebody else knows my public key then they can offer that key to the ssh server and if the server says yes they can conclude that i have an account on that server now the ssh protocol does support a preemptive signature so the client can provide a signature along with the public key in the offering you know in the hopes that this might save a round but as far as i know there's no ssh server that that has any has a configuration option that enforces these preemptive signatures uh to be given so that's a bit of a problem uh another issue is that the server obviously sees which of the keys was used so if if several keys are authorized to perform an operation on the ssh server then the server observes which of the keys was actually used this is kind of fundamental um to the protocol"
  },
  {
    "startTime": "00:44:01",
    "text": "and it's even a little bit worse because the ssh server can prove to anybody that you know somebody authenticated under this specific key so authentication is not uh deniable um and last this is a little bit esoteric i probably won't have time to get into it too much but the server can say no to all the advertisements but i can also just say yes to all the advertisements and it can let everybody in and it can let people in that it could not have predicted uh in advance and that's pretty fundamental to the protocol all four of these are things that we can sort of improve uh with our new protocol so i'll give you the big picture of this new authentication method that we have designed for ssh it kind of works like this the client has several secret keys that it knows and the server has several public keys that are that are authorized those are the inputs to the protocol and you can see in this case sk1 is supposed to go with pk1 and sk4 is supposed to go with pk4 for example these keys can be a mixture of rsa ecdsa and so on um so for example sk the first public key could be rsa the second public key could be dsa for example all of these can be used together in one attempt what does the server learn from the interaction the server learns that the number of keys the client has and the server learns that at least one of this client's keys is authorized so it doesn't in particular it doesn't learn um in this case we can see that key number one and key number four are authorized but the server doesn't learn that information it just knows that at least one of the authorized keys was being used but it doesn't learn which one and the client learns the number of keys that the server has and it learns which of its keys were authorized so it learns that pk1 and pk4"
  },
  {
    "startTime": "00:46:00",
    "text": "were authorized keys but in particular the client cannot learn whether public key pk2 is authorized by the server because the client doesn't know the corresponding secret key so the client can't offer somebody else's public key and learn whether the server recognizes it it can only learn that the server recognizes a key by also holding the corresponding secret key so this just works without any uh site-specific configuration so it's safe for everybody to just put all the keys they know about into this protocol um and you get pretty good uh privacy guarantees um and then regarding this kind of strange attack that i mentioned on the previous slide the server can't convince the client that a connection was successful unless the server no knows an advanced public key that's going to be used and it explicitly includes that key in the protocol so the server can't just say yes to everybody so this offers a little bit of a protection against some sort of attacks let's see so uh hopefully i have time to give a bit of a very high level technical overview uh of how the protocol works it just has two main components so the first component is what we call an anonymous multi-chem so basically you can think that the server generates a ciphertext and it's addressed to a set of public keys and the ciphertext is c and while generating that ciphertext the server knows that okay somebody who has uh secret key j will decrypt this message to message mj so the server learns all these mj messages um and we need the property that the ciphertext c hides the identity of these public key recipients so that means that anybody can decrypt this cipher text and they might get a dummy value but if they happen to have one of the"
  },
  {
    "startTime": "00:48:01",
    "text": "one of these record recognized secret keys they'll get one of the plain text that the server has predicted here so the server sends that cipher text over to the client the client can decrypt with all of its secret keys and so now some of these decryptions are equal to the values that the server already knows and so to tell whether they have any in common they use a private set intersection protocol so in private set intersection each party has a set of items and we use a variant where the client learns the intersection of the items and the server only learns whether the intersection was empty so in this case if the server learns that the intersection was not empty it means that the client must have been able to decrypt under one of these good secret keys and that's all that's all the server needs to know in order to decide on whether to authorize this connection so from our technical contributions of the paper maybe that's less interesting to this audience but we show how to generate this multichem that simultaneously supports the different key flavors that are supported by ssh um and we uh we do this new modification of private set intersection um this this way of proving that the intersection was not empty is kind of a new thing and we show how to add that to the state-of-the-art uh psi protocol and in the paper we have a full uc security proof so this is a composable security kind of the best the best kind of security that we know how to prove um for an interactive protocol like this okay so finally i want to just mention uh the performance of this protocol we implemented this as a extension of"
  },
  {
    "startTime": "00:50:00",
    "text": "open ssh and it's quite practical so i mentioned that the protocol supports rsi keys and elliptic curve keys simultaneously but the rsa keys are much more expensive so for the worst case let's look at if all the keys are only rsa keys that'll be the the worst case in terms of performance and the best case in terms of performance is if all of the keys are just these elliptic curve keys and there's really we didn't find any difference between ec dsa and dsa there's very little difference there so i just lump them into one category as elliptic curve keys so in a realistic setting where the client has five keys and the server has ten keys i think that's a realistic setting for a kind of a small github repository let's say um even with rsa keys 60 milliseconds and with elliptic curve keys it's like instantaneous nine milliseconds um i mean nine milliseconds is not instantaneous but for uh authenticating a connection that's that's pretty good um a more extreme example would be the server has 100 keys and the client has 20 keys that's like you know a github power user connecting to a really popular github repository with 100 maintainers even that is is still i believe within the realm of uh reasonableness for uh authenticating a connection even with rsa keys we try to take this to the extreme and imagine a server with 1000 keys so that's a server that authorizes 1 000 different public keys to be able to connect so with rsa keys that's a little slow it's over a second but even with elliptic curve keys less than a quarter of a second so again i think it's pretty reasonable um so that's that's all i have this is my last slide it's just a summary of uh of what we provide in this new protocol"
  },
  {
    "startTime": "00:52:01",
    "text": "the protocol basically gives the the minimal amount of information to the server the server learns only one bit of information that it learns that the client has some authorized key so if you want more information i have a link at the bottom it's the papers on eprint and uh i'll be happy to take time for questions um i see a question in the chat from uh from chris p um concrete performance this was like total round trip time um so from the from the client's perspective from the time you say i want to connect to the server um it includes the tcp setup as well i think but these were two two servers on the same lan um so the time from saying connect to the time that we can send the first uh application command to the ssh server might not be on yeah if there's a question when when in doubt turn the microphone on uh this is daniel kahn gilmore from the aclu thanks for this presentation thanks for working on this um this has been a long-standing feature of the ssh protocol or or bug depending on your perspective have you thought about how you would apply this to um common patterns right now like the git based forges github git lab etc that have everyone using one account everyone you know if you if you configure ssh to get github it's git at github yes and then your ssh key is what does the split so they need to know what it is to make that work have you thought about how to apply this there or do you have to change your pattern yeah that's a great observation um we do have a section in the paper where we talk about github as the most obvious application of ssh so it's true that uh at the time that you"
  },
  {
    "startTime": "00:54:02",
    "text": "run the protocol um let's see if i can illustrate with the picture it's easier for me at the time you run the authentication protocol the server has to know which keys are authorized and if the server only knows that some github user is connecting to some repository that's not quite enough information so it turns out in the in the ssh flow um the client says i want to authenticate to this user so in github it's i want to authenticate as git at github.com and then the authentication begins so so there is a place in the ssh flow where you can say maybe it's i want to authenticate as repository name at github.com the server sees repository name and it goes to see which of the keys are authorized so it would work if you could make that change to the github flow and of course if if you wanted to support this as a optional thing you could it would be like repositoryname new.github.com or something so by connecting to new.github.com you would signal that you want to use this new authentication protocol and then the username would be the repository name um and that that's how we envision it's working but yeah it would require some changes for sure all right and there's one more quick question in chat um if it's would you like me to take one's a quick answer uh if it's a quick answer we can answer it now if not then we can take it offline uh different configuration and constraints server side i don't i don't think i completely understand um what this person means by configuration constraints maybe we'll take that offline and i'll ask for a clarification okay sounds great thank you mike thanks all right i guess the last presentation is from mallory"
  },
  {
    "startTime": "00:56:12",
    "text": "all right this will be really quick this is a draft that is has been adopted by the working group um and so i'm here to give you a really short presentation about why i think we should keep working on it but i'd like some help so next slide um this is just a draft of what this um this sorry this is just a summary of the table of contents for what this draft does um so in trying to define what is safe internet measurement um i think the focus on consent is good i did a bit of a rework on the table of contents so rather than um putting case studies for each of these um versions of consent they're now just kind of subsumed into their sub sections on informed consent proxy consent and implied consent and then there's a long but maybe not exhaustive list of safety considerations because it is about safe internet measurement um and i'm pretty happy with that list as it is right now um but always there could be things that are missing from it um and then there's a final section on risk analysis uh so next slide please um there are quite a few open issues uh mostly because the original author ian um leermath who has done the vast majority of the work um already put those issues in there they have not all been solved but mostly they're quite low-hanging fruit in terms of he's identified some really good citations that are within scope of the document they just need to be elaborated within the structure and um here's a sort of short list of those six open issues you can see right"
  },
  {
    "startTime": "00:58:01",
    "text": "there there they're pretty obvious next slide please then i think so um yeah there's a really basic update to this which i think makes the structure a little bit more straightforward um i'm going to also plan to send a message to the perigee list for those that aren't here or participating online in this meeting to get more feedback on folks who might be interested in suggesting text for the open issues or reviewing the current version to make sure i think i have two questions about review at this stage one is the table of contents um complete so far and then two if there are definitely missing sections um that we already know about um but the one the last thing i'll say before maybe people have comments or want to volunteer to help um it's just that you might have seen the iab announce a workshop coming up um like q4 i guess it's it's slated for late october and submissions for papers are due i think at the end of august or early september but it's on measurement techniques in encrypted networks which i think is um a place where we could present this draft and whatever version it's in and get a bit more feedback from folks who are also thinking about these issues it's the workshop i think turns the concept on its head a little bit because what it's trying to do is um you know make uh network measurement a little bit easier or try to solve some of the sticky issues with network management and encrypted environments um and this draft is sort of coming at it from like from a safety and privacy perspective you want to make that measurement safe if that makes sense anyone have any questions or so my plan is to continue to work on this submit a paper to this workshop and then"
  },
  {
    "startTime": "01:00:01",
    "text": "get feedback from there as well as on the list from all of you folks comments or questions it doesn't look like there's any questions but one recommendation now that the ietf is working on privacy preserving measurement um that's certainly a group that will probably need some guidance in terms of how to use the systems they're developing uh adap specifically so i wonder uh to what extent you know either this document would benefit from the work that that group's doing or that would benefit from the work that's being developed here but it seems like there's some cross-pollination that should be happening um as we move forward i think you're making a really good point and if there's anybody who actually has a viewpoint on how this draft should fit in with that work especially those who are involved in ppm i really love to know that now or we can talk in the hallway or at some point in the future but because i think the idea is that this would maybe be um this this draft because it's in the irtf especially would kind of be making a broader um sort of um approach to the issue and then ppm would maybe then yeah as you say sort of take advice from it okay thanks yeah no go ahead i think we're good to wrap up just one i guess note that draft censorship just cleared last call so we will finally have an rfc soon maybe hopefully after seven years but yeah thanks all for coming and see you next time"
  },
  {
    "startTime": "01:02:05",
    "text": "okay foreign okay thank you [Music]"
  },
  {
    "startTime": "01:04:38",
    "text": "we'll know very quickly"
  }
]
