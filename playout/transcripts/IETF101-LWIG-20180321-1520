[
  {
    "startTime": "00:02:00",
    "text": "good afternoon this is L week so if you are not here for a week you may leave the room sorry for the delay we were looking for adapter yeah all right so note well the new note well so I I guess by now you are already familiar with the note where we can just move ahead Olaf has kindly agreed to be the jab escribe we need a note taker is someone willing to take notes anyone willing to take take notes okay Rahul thanks so here\u0027s the working group status we had two drafts that cleared the isg ITF last call and all the ESG comments and they are now with in the RFC queue and the third draft is also in the RFC tuber has a missing ref reference to sin ml so it will also move ahead at some point we have a packed agenda for today and now it\u0027s the time for if you don\u0027t agree with this agenda I want to add something remove something if not we can start with the first presentation okay good afternoon everyone my name is Carlos Gomez I\u0027m going to present the last update of the draft and title DCP usage guidance in the internet of things other authors of the document are John Krueger from the University of Cambridge and Michael sharp from Nokia so first of all let\u0027s take a look at the status of the draft so the draft became a working group document after ATF 99 and since the last IDF meeting in Singapore we have revised the document so the last revision is 0-2 and this last revision is intended to address the feedback that we received in Singapore and in addition we\u0027ve also tried to better organize the sections that provide the actual guidance in this "
  },
  {
    "startTime": "00:05:00",
    "text": "document which correspond to current sections four and five so basically this part is mostly a reorganization of content and only just the small new subsection for this sections four and five okay so let\u0027s go through the updates in this last revision so a first update is in section one introduction which is a new paragraph some text intended to address a comment by Hanna\u0027s in in Singapore on which are the reasons for Hawaii TCP is perceived as a not so good or a bad protocol for IOT scenarios and we\u0027ve also added a reference to a more detailed document on this topic so among the reasons that we include in this short summary we can find that some of them are possibly valid however we believe that some others basically the stronger ones are possibly invalid reasons so valid reasons for criticizing TCP as a protocol for IOT comprise at least the following first of all TCP has a relatively long heather size at least if you compare this for example with the head the size of other protocols such as UDP and in fact in some scenarios the situation is a bit worse for TCP because there is no for example 6lowpan style header compression defined for TCP then TCP being a unicast protocol is not suitable for multicast well multicast is important in some IOT applications and also TCP provides and always confirmed it a delivery service so for example you may compare with what happens in co-op where you may well a sender may determine may choose whether an acknowledgment is required for a message or not and this is some flexibility that can be useful for some scenarios and applications especially for applications where you can tolerate some loss ratio and you can just skip waiting for an acknowledgment and by that you can get some energy savings for energy constrained devices however for TCP this flexibility does not exist and on the other hand they have been many typical reasons for criticizing TCP which we believe are invalid or are not fair one of the most typical ones is the complexity of TCP so it is true that there are many mechanisms defined for TCP however it\u0027s true also that much of the functionality is optional so it is not really required all that functionality for interoperability and "
  },
  {
    "startTime": "00:08:02",
    "text": "in fact it\u0027s possible to implement TCP in a quite simple way for example by having single MSS window size oriented implementation then secondly another claim that appears sometimes in the literature is that the connection oriented approach of TCP is incompatible with Radio duty cycle so the latter is a technique that\u0027s quite typically used in wireless low-power technologies for devices that are energy constrained and it is based on having the constraint device in sleep mode during some intervals or maybe by default and waking up sometimes for communication and the point is that there is not any actual problem with having the constraint device in sleep mode for some intervals ok well the device is in a TCP connection so the consequence that there will be when there is ready to die cycling in place is that sometimes to deliver data to the sleepy device there will be some additional delay however if Radio duty cycling is suitably configure there is not any further problem than that so for example when the device goes to sleep it does not necessarily break the connection and another claim or another reason for criticizing TCP is actually a bit more general and well known for quite some time about and the performance of TCP in wireless links for example so it is true that TCP activates congestion control mechanisms whenever there\u0027s a packet loss and the problem is that sometimes packet losses will happen not due to congestion but due to corruption in for example high baterry rings which are quite typical in IOT scenarios so the problem here is that TCP behaves quite conservatively assuming that any loss is due to congestion and therefore there will be these under performance however the main point here is that this problem is not specific of TCP so the actual problem is the fact that the transport layer protocol doesn\u0027t know which is the reason for a packet loss so this is a problem that will happen also in in other protocols for example in co-op this is the same issue however I am not aware of any claim against coop being a bad protocol for the IOT so we believe these are some of the main typical claims against the DCP for IOT which however we believe are not valid or not fair okay then we have a quite major update in former section 4 which was entitled TCP of a constrained node "
  },
  {
    "startTime": "00:11:03",
    "text": "networks the update is mostly editorial and relates with how we organize the content so basically now the content is split in two sections the first one is now entitled TCP implementation and configuration in constrain node networks well the section 5 which is entitled TCP usage recommendations in constraint on network so the last section deals with how an application will use where handle connections in constraint mode Network environments and the previous one section 4 is divided in three sub sections the first one for that one is focuses on path properties so it focuses on parameters and mechanisms that are related with both properties then for the two focuses on guidance for implementations which are based on single MSS window size and for the three provides guidance for implementations for devices that can afford somewhat more somewhat larger window sizes by the way there is the only actual update in terms of content here is the small subsection 5.3 entitled number of parallel connections so basically we just say that device that has limited resources needs to keep a low number of parallel connections since each one of them each connection will consume some resources then we have some other updates in the annals of the document which is the part where we collect details on TCP implementations for constrain devices so first couple of updates is in the subsection on the TCP employment asian for tiny OS so we now have added that this implementation provides a subset of the socket interface so there was a comment by Rahul in Singapore on this and also we found that it appears that this implementation supports also multiple TCP connections in parallel then we\u0027ve also added details for two additional TCP implementations for constrained devices this is basically after some comments by Hanna\u0027s in Singapore that well we\u0027ve added the implementations for free rtos and for micro CE OS so these two are real-time operating systems for embedded devices which are supported by up to 32 bit micro processors so now we are covering implementations for a bit more powerful platforms than the ones we are covering in the previous version of the document and both basically are based on a multiple MSS window size although free rtos has some readily available option called tiny TCP to quickly or easily configure it as a "
  },
  {
    "startTime": "00:14:05",
    "text": "single MSS implementation also both implementations support delayed acknowledgments and there\u0027s one particular detail in free rtos implementation because the threshold of the delayed acknowledgments mechanism is set to 20 milliseconds instead of the typical value of 200 milliseconds and this is intended to gain performance by reducing delay in interactions that just require a single segment in order to transfer some payload then we\u0027ve also updated the summary table that collects the different features of these different TCP implementations that we have considered in the document so first of all we can say that there are two rows that have been deleted from the table those were the rows for DFO and ecn because actually there was a no everywhere so now the same information is provided as one sent in the table caption and on the other hand we have added two rows one for whether there is support for the socket interface and another one on the number of well whether it\u0027s possible to have number of concurrent connections then also we have added the two columns that correspond to the details of the implementations for free our TRS and micro C OS and basically the part of the table that deals with TCP features is almost complete although as you can see there are still few details that need to be filled in however we we are struggling a bit more with details numbers on memory consumption so especially data size is something that appears to be not so easy to find and for the code size part we we have found some numbers and by the way now in this last day we\u0027ve also added it for each of these numbers whether they correspond to just the TCP part or to the whole protocol stack there was a comment by Mohit on this and I\u0027d like to take the opportunity to also make a call so that if anyone has details on these especially for memory consumption and data size for the different disapear implementations please let us know this would be much appreciated so then those were all the dates or the main updates in this last revision and we have identified a number of potential additions for 0-3 for example we plan to add some discussion on the support or lack of support of ecn in the internet and also in for specifically IOT scenarios then with regard to the security consideration section we\u0027d like to possibly expand it and one thing we "
  },
  {
    "startTime": "00:17:08",
    "text": "are interested would be to know if there are any known code vulnerabilities due to implementing TCP in a constrained way so this is something that that\u0027s a question that we also would like to make to the working group right now for example and also we plan to to maybe post an email on the mailing list this and then Indiana\u0027s we also plan to maybe separate which are the TCP implementations that appear to be updated and maintained recently from those that have not been updated or maintained since some time ago and well and again it would be great to try to complete the summary table however we believe we may need some help in terms of data and code size details so any input in this regard is very much welcome and yeah that was last slide so I don\u0027t know if there may be any comment or questions I had a specific question about the appendix like I think it\u0027s 8 section 8 right one other thing that worries me is like that\u0027s like highly dynamic content and I had a thought like just like chronic I want to run it by the working group see what they think right so usually this kind of stuff is tracked in something called an implementation status section that\u0027s removed before publication as an RFC ok so that\u0027s like RFC 79 32 or something that it describes how we do it and that\u0027s how it\u0027s usually been done so I want to understand if the working group thing there\u0027s like long term archival value for keeping this or is something we just do this now and be done with it so that would deter mind like whether you want to put it in an implementation status section or keep it in the RFC because I think an RFC giving wrong information is worse than not having the information but maybe people may feel otherwise is maybe just a snapshot or something but I think Hannes wants to say something but yeah just think about it like what you want to do so sure you specifically referring to the EC end support or the table that was previously shown or to some of the performance data of course these things change but I thought that this table was at least it could be a snapshot in tiny but I think this is quite valuable I saw that it\u0027s really useful of course it is a fair comment on like how do we actually maintain use could this be updated in the future I understand that it\u0027s very difficult to get the data about data size and code size but since there are lots of people in the room who always focus on on code size DRAM utilization over the wire transmission size I think it would be a good exercise to actually get some real data um if you get the data from some papers um I expect that "
  },
  {
    "startTime": "00:20:10",
    "text": "this will be tricky because they will probably measure it differently they will probably include different values and so you will have a not very representative figure in yen so that could be if I understand that you are also sort of the document you\u0027re probably not super thrilled about the idea that you have to get all these things running and then do a comparison for the date for the code size it may not be the the item at issue but would still take you some time but for the RAM size in measuring that would be will be tricky I\u0027m sure you have noticed that yeah this is more so I think I agree with Hannah said it makes sense to have have these numbers and not remove them our before publication yeah once it is RFC so we then we just updated we don\u0027t remove it but like if we keep updating the curves right so today\u0027s this elliptic or tomorrow it\u0027s some other curve and things will change but it it makes sense to have like at this point of time this is what we know these are these are the numbers and of course measuring Ram is is much harder because you either run the code or you use analyzer and both of them don\u0027t give you accurate values and they use so many different languages that it\u0027s it\u0027s hard to do that so there\u0027s there\u0027s actually there are ways to measure the RAM utilization of and to get some some real data without being overly intrusive but it it will require a sophisticated setup so I\u0027ve seen tools i in fact i wanted to use a tool myself without making advertisement it\u0027s actually not a nun product and so it\u0027s a it\u0027s a company an Austrian company a CEO who provides her and analyzer and they basically give all sorts of data you increment the code and you can retrieve it from from the board then but it I haven\u0027t used it myself I want to play with it to see how easy it is maybe that maybe that could help um thank you I don\u0027t know if you say that already but maybe you want to at the beginning of this section you just want to indicate that like a such just a disclaimer that this was what I\u0027ve done work done at the time of writing of this document yes and maybe incorrect at the time when the people read it and then later on I don\u0027t expect these implementations to change like on a daily basis or maybe in a few years then things could be revisited and like like you guys do or constant us at least try to redefine their classes and pretty be more descriptive of a couple of years of experience I could see that following similar lines or as we do for crypto as well thank you rahu each other well so "
  },
  {
    "startTime": "00:23:10",
    "text": "regarding regarding the question of implementation is getting changed so one point is that the I think these are all the design aspects so the implementations might change at a different level but these things will remain same for example I don\u0027t see why you IP or riot will support slow start or any congestion control algorithm in the future and WI if you\u0027ve already supports it so so these are something fundamentally different so I feel this table and some of the information which is already there in the draft should definitely be there thank you so I I\u0027m not sure I agree right like so the thing is like lot of these nodes could change into a s at some point right like so that that\u0027s the part I\u0027m concerned about that we are giving misleading information right but the core number probably won\u0027t change by March all yeses are probably not going to become notes at some point right but there\u0027s some stuff we say like no but at some point people are implemented like if something becomes important like you know delay tax for example right if somebody could just do it like they just haven\u0027t done it and so as long as there\u0027s some kind of disclaimer which is it\u0027s like a snapshot which doesn\u0027t exist by now right now but you can put it something saying like okay like just like not a section just actually moved into an actual appendix even though it\u0027s just appendix it\u0027s in a actual body of the document so push it somewhere further down and say like this is a snapshot at the time of writing and may or may not be accurate and probably like put in a link to a URL where it\u0027s getting flat okay that that could probably give you some kind of so this is the information you are kind of trying to push into a working group wiki rather than a RFC because it\u0027s so a lot of the times we think like this is gonna be valid in five years that\u0027s the kind of like test we do to see what goes in a wiki and what goes in an RFC and I think something here is gonna be wrong in five years like just that feel yeah I might be wrong you might be wrong right but that\u0027s that\u0027s the thinking so just put it somewhere and say like you know may not be up to date and like you know the current status for this is track that wherever and then somebody maintains it like would be a lot no biggie yeah just moment I\u0027m not sure if I heard you suggest what I was going to say that\u0027s half the cake and either true so this will be in the document the same table will be on the wiki and the cable on the wiki will live and the for volunteer all right Thank You Carlos Raul I guess you\u0027re next ravage other so I\u0027m going to just present the update for this particular draft I\u0027m not going to go into the details of what this draft is about but at a very high level the draft talks about how to manage neighbor cash in trees when the density of the network or the density of the nodes in a specific "
  },
  {
    "startTime": "00:26:10",
    "text": "area is much higher than what cash table is the cash table sizes so the only update that has been done since the past revision is the security consideration so there had been one discussion in the six stage which talked about maintaining untrusted neighbor entries for some time while the pledge joins the network or in case of an AGG authentication where the panaka client joins the network so this this specific security consideration has been added into the document thanks to Melissa for citing this in context two six dish and today there again there was some discussion tomorrow there is some more discussion in rule which is going to happen in this context in this context but not exactly the same so this the draft is not a standard stack document it\u0027s informational RFC so we are not aiming to change anything in the signaling or messaging in this particular document so the inputs from this document might in turn go to I\u0027m hoping it will result in some changes in the role it might result in some changes in the role as well as in maybe 600 so some update about the implementation so quantity already has some part of the implementation of this which allows the 6lr know to manage neighbor cash entries in a way such that you know even if it gets even if the 6lr gets bombarded with more and more number of entries it will still be able to manage it right does not have this implementation as of now and other operating systems also don\u0027t have this implementation so what quantity doesn\u0027t have currently so we already have this implementation it\u0027s appropriate implementation we are planning to add this support to quantity and hopefully to write as well as a pull request so what what we have what quantity currently doesn\u0027t have is it doesn\u0027t have any key management protocol once it doesn\u0027t have any if it doesn\u0027t have any key management protocol I\u0027m talking about not the quantity ng but the quantity operating system which is which is the older version so it cannot distinguish between a neighbor cash entry which is authenticated and unauthenticated so there is a difference there so it doesn\u0027t handle that currently so there is no time so the abit that we had done in the security concentration is that you have a different timer you manage a reservation for unauthenticated entries in a certain way you have timers for those are not n ticketed entries in a certain way so that it can it will read it will reduce the impact of an attack it will reduce an impact to the attack but it might not be able to totally avoid it so what are the next steps so we plan to do this implementation in Kentucky we are we plan to align the quantity implementation with the drafts proposition and do some performance tests so the performance test would be in terms of like how many times the network had to change is routing adjacencies and how soon how was the "
  },
  {
    "startTime": "00:29:11",
    "text": "connector convergence time impacted because of such an implementation that\u0027s all any questions next steps we definitely require some removals of this before this document ok so have you spoken to the quantity folks like one thing is editing the core code in the forked implementation but maybe they are also interested to then use useless in in future they are co-authors then we had lot of discussions they are also co-authors in this particular draft and we had a lot of discussions before hello so in six days this wagon will get seven years old and yeah I cannot regulate because it\u0027s six days away but I wish this moment would have been around 11 or 12 years ago because I wouldn\u0027t have to stand here now so this is really a blast from the past I on the insistence of Thomas to attain document it\u0027s something that I thought had been common knowledge for more than a decade now but apparently had so it came up when the again when the sixth of our group build sixth of fragmentation design team and one of the objectives was to finally document this so this is about memory fission fragment forwarding with virture reassembly but first let me quickly talk about the standards this is based on from the standard number this is really about something that\u0027s that\u0027s a decade more than a decade old why we are doing this how they work and what we\u0027re going to do about this so you know that I\u0027ve seen it for 944 defines a link layer fragmentation or adaptation layer fragmentation as as I usually call it mechanism so we are able to take an IP package turn it into a multiple adaptation layer fragments and then hand them over to 802 15 for and the fragmentation format is this inspired from ipv4 so we have a Datagram size and a Datagram tag and for any data room that is not the first one we also have a Datagram offset as a unit of eight bytes so basically you can think about this as a form of IP fragmentation that is undone at the place where the fragment "
  },
  {
    "startTime": "00:32:13",
    "text": "I received so that when at the packet leaves the the 6lowpan domain it\u0027s a whole packet still and not a lot of IP fragments which would be much larger now how do you implement fragmentation you do it by providing reassembly buffers so you build reassembly buffer when you get the first fragment then you have something like a time out while you are waiting for additional fragments to come in and then either you reassemble it completely then you can drop the reassembly buffers because you have processed it all when you have a timeout you drop it and these timeouts have to be pretty long for a number of reasons so usually there are dozens of seconds 60 seconds and in some cases so we\u0027re talking about buffers that that are about a kilobyte that are reserved for 60 seconds and that are living on a constrained note so this is this is really a bit of the hard proposition RFC six to a two which define a refined header compression did not change anything about the fragmentation mechanism so we as they\u0027re using the same mechanism as in 4/4 now what\u0027s the problem well first of all because our links are not particularly fast and media access may take some time the the the idea of reassembling everything at every hop and then fragmenting it out again that increases the latency it essentially can can double latency or more and also the reliability where fragmentation is bad for reliability in the first place don\u0027t do fragmentation but we have to but the the bad thing is that the real I well their reliability is further negatively impacted by the fact that the forwarding nodes have limited memory so if somebody starts to send the fragmented packet and so many eighths starts to send a five-minute packet and it should say nurse that\u0027s the same Defragmenter packet we might run out of buffers and then the packet is gone so it\u0027s much harder to actually deliver a fragmented package then so basically what what we need to find is a way to actually get rid of the fragment in the forwarding node as quickly as possible and that\u0027s known as fragment forwarding so we actually want to send fragments onwards before we have received the whole package and that of course relieves the intermediate nodes of "
  },
  {
    "startTime": "00:35:14",
    "text": "memory requirements and the only one that really reassembly reassembles things is the final destination or the ABR for instance when the package is supposed to leave the 6lowpan domain okay so this is what we want to do and again I thought this had been common knowledge because it were also had been documented in a book that is dated 2009 so that that is getting 10 in a couple of months we can actually emulate the function of a reassembly buffer so we don\u0027t actually implement the reassembly buffer we just act as if we had one and that\u0027s called a virtual reassembly buffer so real reassembly buffer is going to sit there and and put the fragments together and then only when it\u0027s full actually starting to burst out packets fragments again and the idea about the virtual reassembly buffer is that you should just don\u0027t let the data sit here you send them on as soon as you have enough information to actually do that so in a virtual reassembly buffer environment you essentially reduce the reassembly buffer to information that you need to identify the packet that you are working on which is the layer 2 sauce and the Datagram keg and all the other information you just don\u0027t keep you you just send them out immediately when you get of course there\u0027s a little catch here you have to have media access to send something and while you\u0027re waiting for media access you submit receiving packets so you you cannot count on getting rid of your fragments at the same speed that you receive them so the reliability problem and the requirement for buffer space remains but in many cases nodes will be able to actually get the media access in about the same speed in which they are receiving things so the the virtual reassembly buffer never actually stores actual data and that\u0027s good because now suddenly we might keep twenty of them or something like that it\u0027s no longer as costly because it\u0027s just a couple of fights so this figure by the way is from Thomas who wrote another draft in documenting that you race in your books so as I said it\u0027s not always trivial to do this for instance you might have a situation in which the first fragment does not contain enough information to forward the packet if you have a very long sauce world in your packet you might have to wait for the first two fragments to come in before you know where where that goes on all there might "
  },
  {
    "startTime": "00:38:14",
    "text": "be out of order fragments I think that that\u0027s something that is to be discussed how how real these are in networks but it might happen and there\u0027s also a third problem but that\u0027s a general problem about fragmentation you do header compression hop-by-hop and of course the Pickett looks different on on every hop and the the layer to information that goes into the header compression with the packet also looks different on everyone so the header compression will be slightly differently efficient on every hop and if you do this naively then you might get a packet that has a 180 by at 108 page fragment and 50 byte fragment and then you notice oh I need 129 bytes to represent the first fragment now because yeah it\u0027s something about the header compression became less efficient in this topic for instance the the TTS changes and there are there only a few TTA sizes that we compress efficiently so what do you do in that case you actually send three fragments 128 one and fifty and that doesn\u0027t make a lot of sense so there\u0027s a well enough to trick the original fragmented doesn\u0027t send 128 at 50 it sends 50 and 128 so you have all the slack in the first fragment and this means if you have to go from 50 to 51 or 55 that\u0027s not a problem yeah security considerations this is pretty much the same it doesn\u0027t really change very much so getting getting a node who sought reassembly buffer is as easy but it\u0027s at least not as severe because we can have very more of these but you reassembly and finally we are not serving all the problems this is just an implementation trick it\u0027s not a new protocol so it kind of cannot help us with a packet drop probability it doesn\u0027t provide fragment recovery it doesn\u0027t provide things like per fragment routing which you may want to have you you cannot do situation sending fragments multiple times where you can do it but it doesn\u0027t really help as much as if you have a real special protocol for fragment recovery so this is a completely different item and this is out of scope for this group and is being looked at by six law so six law has a fragmentation design team that was charged to produce two documents one giving all of you of what we have and originally the idea was to have "
  },
  {
    "startTime": "00:41:15",
    "text": "Mitch the information about the battery assembly buffer implementation technique in that document but more importantly this is also supposed to discuss it analyze it tell us how far does that take us so it\u0027s supposed to have some numbers in it some some actual a summary of research so that\u0027s one thing that design team wants to do and the other thing is get a standard strike document out with a new protocol that adds fragment recovery okay so how do we do this as I said Thomas wrote another document that also documented but you reassembly buffers and a few other things and that might become this document here and yeah small section here about the VRB itself it also has a section discussing it so what are the limitations and so on and we would add numbers there and so on and that may continue to be a good topic for 6lo because it\u0027s the forward-looking part is the backward-looking part documenting things that happened more than a decade ago so yeah the this the the the description was first published as as a draft a week Thomas wrote another description and after some back-and-forth and discussion we came up with the idea to keep a document about the implementation technique in eric and put analysis and some some analysis also of new protocol proposals how they can avoid the limitations of the limitation technique into a sixth order humans which will then be accompanied by one fragmentation recovery technique that has chosen by sixth oh so that\u0027s where we want to go questions questions or comments well we have the six low cure here we have the 80 here I think this split make sense so sounds good to us as I chaired the design team so we had the discussion this morning I think we\u0027ve had this like L wick 6lo question because it turns out we published the same draft essentially within 24 hours so you didn\u0027t know of each other writing it so there\u0027s no you "
  },
  {
    "startTime": "00:44:15",
    "text": "know just there\u0027s no conspiracy there\u0027s no conspiracy there\u0027s no so so what what Carson\u0027s made exactly the plan I think if that works so the pure implementation details VRB L wig six low discusses that and the limits we have some judge is working on simulation results where we show how the thing diverges and how for you know tenth of the price and random or you actually get a hundred percent reliability stuff like this and then the second six low draft is about a new protocol so makes perfect sense suresh krisshnan so make sense to me so and yeah talk to Gibbon summit as well just so that they are like fully aware of it as well and I don\u0027t see an issue and at at some point we might probably do a giant class call for both of what the documents that\u0027s probably it I just want to say that early in the Karsten and Thomas spoke with us six low chairs and we are okay with the plan and also sued us just reminded that it will be last called and revealed by both working groups so it\u0027s fine thanks thank you any taking her comments on this whole thing I mean is there anything else that should be documented about this who has implemented this all right Thank You Carson next we have a remote presentation from Renee Renee can you can you hear us if did you register him as a remote presenter for mythical yes okay so they he should just be able to - yeah anyways if you request the line sorry yes otherwise you can just request the line and then you press the red button Rani can you request the line "
  },
  {
    "startTime": "00:47:42",
    "text": "then you can start with the last one you come back Rena you need to request access so there\u0027s nothing we can do from here maybe we can go on to the next presentation and then come back to Renee ready please send us a email or something hi I\u0027m Francesca pardon beanie I\u0027m gonna present an update to the comparison of coop security protocols so this document was started last year March it was first presented in court and then at last idea they were presented in L week so the update for this document so we removed the roster six low compressed DTLS from the document as suggested by harness we aligned to update it to DTLS 1.3 so it\u0027s now version 26 we so it\u0027s much more it\u0027s much smaller header in detail s 1 2 3 and also we added this short header format we corrected some errors wearing in the document such as the legacy version number that was 0 3 0 1 and the correct number is 0 3 0 3 that doesn\u0027t change the overhead but it mistake so that\u0027s fixed we add the encrypted content type in both for T less one two three and DT less one two three we remove the nuns from TLS one two three and we added the consideration about GHC which increases the overhead for TLS 1 2 3 and DTLS 1 2 3 so all these changes you can you can check the examples are very detailed and then they implement these changes so we also added a table with the overhead without Mac as Garson suggested during last meeting and finally we updated all the tables according to the updates and the summary so this is the main body table of content so we have now a section for DTLS 102 with and without GHC and "
  },
  {
    "startTime": "00:50:45",
    "text": "connect connection ID and a combination of those same for DTS 103 including short header format then TLS 1.2 till s 1 2 3 version 27 we think without JC again and then oscar version 11 she\u0027s the last one this is a summary so this is the table from the front document with update in numbers so in green are numbers that are lower than the last version of the document then in like blue are the new numbers so the numbers that we added for this version and in red those that are higher than the last document this is the new table that we opted so this is just for the overhead without the Mac well the table before is a function of yeah how long the sequence unbraced and it includes a ok I\u0027m going to finish and it includes the the Mac so this is without the Mac for all the protocols with and without GHz again Green is for lower number than before and this is because of we updated according to update seeing the document and fixed a few mistakes so we are wondering what are the next steps for this document it got support that IETF 100 and got support before when he was presented in core as well so we think this document is ready to be adopted by the working group so this will be a point where we ask how many have read the document is there any objection to adopting this there was clear interest at the last ITF unless there is someone who thinks otherwise I think we have yeah we love course confirm it on the mailing list but let\u0027s do a hum so those who are for adoption of this draft please hum now those who object to adoption of this stuff please hum now it\u0027s pretty clear we will confirm it on the list thanks Francisca let\u0027s hope it works with Renaye now yes "
  },
  {
    "startTime": "00:53:47",
    "text": "just run it just keep saying next slide and I will switch the slides ok well thanks very much and things gave me the opportunity to be remote so this draft is submitted I think in November or something like that after email discuss you know it and it\u0027s about how to squeeze as much script on small device as possible there are some simple suggestions and those are on these flights so so one remark the the draft is like 12 pages of it\u0027s probably 11 pages our appendix and the zoning home page is just a description but sniffle I suppose Minister will make 15 slides but most of these slides are just things to glimpse over and just to get the appreciation for some problems and hopefully your solution direction next slide please can you me yes go ahead okay sorry so so currently in in ITF we have quite some interest in implementing Ecco mall kind of devices it\u0027s until at one point three and it\u0027s a lot of IT style devices and I will discuss the the kind of the algorithms ooh that has evolved over time and what to do with it if we all the cram as much so among the guys as possible so I will go over the the Dinesh curves which have been there for at least one hour decade I think and some more recent curves suggested certify the see of our key process both for key agreement and for signature schemes and then I will zoom in a little bit so I have a few slides with mathematical detail but you don\u0027t have to learn it by heart then I will just do compare some very implementation pitfalls lie and then I would suggest an approach on how to actually still cram as much on one device as possible suppose you want to implement more than one out business but that\u0027s the the precursor is we have to implement that for whatever reason let\u0027s say you do obviously use government you have to interview implement the PT 56 surface ECB is a but you also want to use all this and nice things that came out of everything and then I will also sketch once I\u0027ve suggested how to reuse some code to implement all of these schemes on basically environment implementation just like how can we evolve from here and can we make potentially our sanitization process somewhat easier so so why my kind of hidden claim is that lots of documents that have been produced in crypto lamp in ITF the last few years they could be mounted documents if they had the document that "
  },
  {
    "startTime": "00:56:47",
    "text": "I submitted in November and then I would glue to some final remarks next slide please okay so this is the finished curves and the most important thing is there\u0027s lots of dqo only slides but there is an overview um and a few slides down the road these are widely implemented source of hardware implementations for this it\u0027s all over the place the important thing to notice is that they use a particular shape of elliptic curves this is so called the bias trust model and you see this equation the curved equation is the mod p and x and y parameters on there and this particular shape of equation its triggers all kind of other design decisions including how do you do circle group operations on this curve how do you represent points how and so on so lots of standardization bodies have picked some choices for so long I just want to highlight is that the points are always submitted in most significant bit an octet order and that these objects that are on this curve are always in so called non compressed form so it means you have all any information that you need to run a calculation is not something that you have to mentally reconstruct I then we have ECB\u0027s a it\u0027s all over the place as well it\u0027s a signature scheme there we we use the same elliptic curve as for example expect we specified the NIST we use a hash function and then we pop out a signature of in this case 512 bits again in a particular format so this is this is just basically legacy curves has been around since probably around 2000 okay next slide please so now comes Co AG and they have introduced some some new curves or not that new anymore but at most two years old in terms of spec work one of them is a Mongolia curve and a settlement curve to 5500 online that has been heavily promoted by a burst in and some others and that curve has been taken in a particular way both to to make the calculation as little bit speedier and because of at least lately suspicions that the nice numbers were cooked up so one important remark there is that some of these speed ups actually may work less well in iit setting so for "
  },
  {
    "startTime": "00:59:50",
    "text": "example atmega328 device to treatment the 8p device most multiplications is devoir on a bit level and all the papers that are written academia about speeds or records are all about 32-bit or 64-bit architectures which is nice to TLS but maybe not nice for every iit in application so one thing to note here would be that the calculations are done on only one of the X\u0026Y coordinates of the points there so you basically saw way information so you don\u0027t really reconstruct the entire thing that you would otherwise need in the BIOS transform in the nice curve case but it still is enough for lots of tea brewing protocols next slide please okay so then we have another type of curve which is being used in C of the t\u0027s back for a new signature scheme called II D D is a and that users yet another form of elliptical physical the twisted adverse curve and there is yet another set of formulas to to hit speed records and to be the fastest in the world right and that particular reputation has been used in the paper that later on form the basis for our seat32 for a circle snore signature scheme and it\u0027s operated in a deterministic fashion using open of HR 5512 and in other cases even more exotic in his fractions but you see there\u0027s lots of flavors of girls so let me just give an overview of them and that\u0027s on the next slide Chemical next fight okay so I just walked over these three different curve models so bombed in this curve is trust model the curve to 509 is Montgomery curve FS curve they all have different on the line formulas on the route of file to do group operations they have different representations of how the points are represented internally and also how they are sent over the wire and they even have different bit and byte orderings so for example if you look at the left column is on the NIST P 256 you see that the authors are sent let\u0027s say normal Elementary School order and saying this bits and this curve 25.9 then doctors are least significant byte first but on the on octet level is the other way around and abscess curve does something yet completely different so "
  },
  {
    "startTime": "01:02:52",
    "text": "what are we going to do now if you want to implement or have to implement for example list curves and NIST signature schemes and we also want to use the C over C stuff for almost mobile guys so there seems to be quite a pain right because all the even the formatting is different like the bit or Couture ring the underlying formulas are different arithmetic is different so it seems like oh we need to have triple the implementation size or some of the implementation size of the individual components this is bad news for IOT devices so let\u0027s see how I can make sense of this maybe you can actually do better so that\u0027s the next slide for next six slides I think let me go to the next slide we are on the next slide oh sorry can we go back down I didn\u0027t see the my screen okay so I just recopy the comparison of all these curves and for now I want to ignore the bit byte ordering because it\u0027s kind of a mess but it\u0027s only a slim layer to convert along to the other so let\u0027s focus on the elliptic curve cryptography so to make the the exposition level clearer I assume that all the information is there we don\u0027t do anything compressed so we have all the x and y corners of all these different shapes of curves and then we\u0027ll try to see where we can actually measure we turn it into something that looks like NIST curves implementation next slide please okay so you see that I have a blue item there where it used to say NIST P 256 and what is that so we have this curve 255 online and this adverse curve if you look at all these facts you will you think that all these curves are completely different mathematical animals but they\u0027re not the just different ways of representing the same mathematical objects and it turns out that you\u0027re able to with all these three curve models once you actually have something like curve to 5009 you can easily convert the points to something on different weekly space like metros curve or the curve that I specified in my draft which is something in the traditional Weierstrass format and just for the for the record like every curve cut can can always be represented in biased as firm up but it\u0027s not always representable in memory or at this form so you see this little diagram on the bottom essentially we we we have a way to to move between different representations of the same objects so these seemingly different "
  },
  {
    "startTime": "01:05:52",
    "text": "things are this just different way if we present in the same mathematical objects and these mappings between for example the curve to five thousand nine and this new thing that I introduced in the in the spec in the draft is very easy to implement so let\u0027s look at it on the next slide so here I just for first focus on on the bottom so we have a curve two five five one nine points which is people are using it and in IOT applications it has two coordinates U and V actually X\u0026Y I have to look at the red arrow going to the left how do you move toward something that looks like a missed Weierstrass format you you just add some number to the x coordinates that\u0027s it same thing if you want to move the other way around you just subtract the number that\u0027s it so the computational workload of moving from one to the other direction is 0.1 percent at most maybe even far let\u0027s write some similar happens if you move between this adverse curve and the curve to five 509 so that means for example if you can do this very efficiently you can have a single implementation for the signature scheme that came out of CLG and the this extra 255 wrong nine implementation as long as you convert it to the other fall out and then the end of computation just converted that and the reason why this works is that it\u0027s a so-called isomorphism which means that you maintain the same mathematical structure so now we have essentially three repeats less representation of the same mathematical objects one of the domestic curve to 509 the address curve that\u0027s in the EDD is a scheme and the thing I specified in the draft and they all have the same parameters at the same prime number so you can just borrow all the arithmetic for it and same group size the only thing is like the the rip station the XY corners are morphed a little bit so for example in curve two 55.9 you have an x coordinate nine is the circle base point but it\u0027s nine plus the fixed number that is a little bit long to write a new slide but it\u0027s never less simply add in your head and that transforms it to the other format so the important lesson from this slide and the previous few slides is that we have all these million different objects that essentially are the same except they are representing their coordinates slightly differently we won\u0027t exploit that to essentially stick it into an existing air transportation for example the miss curves next slide please so now I have I condensed all these different new improved curves to the "
  },
  {
    "startTime": "01:08:54",
    "text": "justice volume right various fast format I mean now see that if we compare this the miss curves that has been around forever and it\u0027s like probably owners of hardware invitations for that already available we have the same curve normally if the same base point now we have the same internal ripest a/c the same foreign and the same wire format a same auditory and by embed ordering so that means that if suppose you are kind of late in the game and only won\u0027t start implementing the move Emery curve or the FS curve now maybe you can just just just format the various formats just of an old hardware implementation for the Miss curves and you\u0027re done the only thing you need to do is you you represent it in and if way and you use outer circle domain parameters so if the the NIST NIST curfews another prime number than the other curves and a few other parameters but these are constant and they are easily loaded into memory okay next slide please so I keep it a little bit because we also actually had all these encoding problems because the bit and byte ordering and in all these different models has been picked kind of badly because they\u0027re all like incompatible so if you really want to implement all these different models in the same way we need to at least solve this encoding mess so if the octet ordering was least significant byte first instead of most significant byte first we have to have a little translation layer there so apart from that issue you\u0027re basically we can implement all these things in the same way and we can if we for whatever reason we already have and I kind of a classical virus perfect implementation you can implement all these things in also insanely next type is some efficiency so what is the efficiency of of this whole exercise so one attempts of course is oh we we only need one implementation of instead of all these flavors except for a little bit byte ordering a mess the conversion is really low cost as I said in the first bullet it\u0027s like really negative negligible and there\u0027s one caveat though is that if you look for example TLS I saw today that TLS 1.3 was just approved until at one point three uses this curve to 55.9 and for reasons that I really don\u0027t understand they only at format the x coordinate of the point instead of both coordinates its handicaps my mapping between this curve formats because now 7b has only "
  },
  {
    "startTime": "01:11:54",
    "text": "computer sets so if TLS 1.3 has solved a little bit more of our the reputation issues then this point one percent would be the final cost but because they didn\u0027t do that now we have a very expensive call calculation we have to add to transfer to this virus format or a Swiss format which adds roughly one seventh of the total scalar multiplication time and then all the bit and byte or rings they they cost a little bit of complication but it\u0027s only it\u0027s only in ordering of octet so it\u0027s been a pain that should have been avoided if we look back now but it\u0027s there and it\u0027s at least computation of scale oh okay so next slide I only have like two slides so how to reuse existing steps right so suppose we have to implement the NIST curve with key agreement and curve to 55.9 in TLS 1.3 and we want to do it on a small device then on the root we can just do the Fionan this this curve as specified in the draft and then we even compliant this existing specification we get all the compliance stamps we can all like CEPS approved and so on the iranian ounce that they would give you the stand November last year if you want to do pyramid and sign in using the CID curves then we can also were if we want to for whatever reason to devise that model we can already do that and I actually checked all the specs if we look at v 186 days for it allows specifications of all kind of cursor does allow introduction of a new virus curve which for example the one is specified in a draft and then we have ECDSA styling this curve that\u0027s on route you can just do the calculation with Mohammed ladder-like CVT as we promoting and it\u0027s compliant and this doesn\u0027t have to do there a three-year rear it and it can all be done if you want to implement the snorer a signature scheme this is essentially EDD is a we can dust off the beers ice pack of 2010 and it also allows new curves although it recommends their own slow one so we can do a fast one instead and then we done same with a combination of of any mist and any CoV flavor curves as long as we keep the same encoding so most people in Python bits first then we don\u0027t have to do is change any line of code aligned with any existing specifications there\u0027s one note in the "
  },
  {
    "startTime": "01:14:54",
    "text": "bottom of the page is that if we want to reuse the ECB\u0027s a and suppose you have an existing easy design implementation with NIST and you want to use to implement the address EDD is a scheme then part of its possible because all the lot a paraphyletic road work just fine the only thing is C of G has implemented shot 512 so there\u0027s a mismatch on there as Frances we have two implements to hash functions now and the other thing is some of the formula on the route is slightly different computer this so-called s component of the of the signature and you can still do it but if you cannot do it easily in a secure way so you have to in that way you have to you cannot exactly reuse existing implementation bits of Springs on my whole presentation so next slide okay now suppose you want to do value instead of rapid prototyping we would like to do rapid thermalization development and so I think you see of a deep process to pick the new curves perform all the infighting it also took two years to do it and there\u0027s like 50 different drafts that are all about to do a new curve miss HTTP do a new curve miss josei and and whatever right if he actually would use the Vice trust model we only had had to define a new object ID for the curve and we would have been done we could have introduced MTV we could have introduced a new certificate formats with long line drafts instead of like you know 60 pages we could have used implicit Sara Stefan I used for autonomous vehicles in the US Department of Transport all by just swapping to old-fashioned Reaper station that has been around in all kind of specs for 15 years next slide please not slide so the bottom line is first of all mathematically different curve models they look different than our to understand but they can all be seen as one with wave representing or the other way of representing the same virus past model if you use that model then you can use all the existing implementations of NIST type code but also if you represented that ready even if I\u0027m going to use a kind of a fancy over like normally letter and so on you can your starid development becomes vom page if you just specify the parameters any dot then the the search and force things are take away that the encoding formats like TLS I think has done the kind of a nine side kind of a bad choice but you know someone one gives off the trying about representing "
  },
  {
    "startTime": "01:17:54",
    "text": "points which effectively makes it harder to switch from one location to the next which i think is detrimental for algorithm and reality and for implementation security because essentially it has v picked a favorite which in this case would be the Montgomery curve and made it harder to shift to an our way of representing object so I think in future IDs you to be more careful about the representation of Isis and rather they kind of dig a moat around the solution instead of make it agnostic and yeah so the there\u0027s one question I have that I didn\u0027t put on the slide is essentially if for small for low-cost devices we really want to have one implementation maybe we should define some of these things in a very presented in document and it could be beneficial for IOT type settings so that\u0027s the question mark for me and the question is whether people think it\u0027s of interests to them she\u0027s a partner draft people think that would be of interest implemented as a and so forth yours suresh krisshnan okay suresh krisshnan so i read the draft it it had like three pages but i couldn\u0027t figure out what was implementation guidance in there and i have a hard time seeing how this fits in Elway right like it\u0027s and if you look at the appendix it\u0027s like very crypto heavy for batteries you mean the slicer crypto heavy order the draft most probably right right the slights are and I\u0027m just worried that like we don\u0027t have the expertise in this group to review the crypto and better right like so if your strategy is gonna be grow bit stuff somewhere I would like a different content in the draft it says like how this can be used in constrained implementations right and that\u0027s not the direction the draft is taking today right it says like super me if you look at security consideration section it\u0027s a it says oh we we essentially define a mapping that transform on Ruby station into another one which is public information so there\u0027s no security impacts there\u0027s no need for in our crypto people to do their own pick their favorite things this is for like fatigue limitations people can define different way of representing "
  },
  {
    "startTime": "01:20:54",
    "text": "things and may be able to reuse for example the older list related code to define something where under the hood you would actually implement the C over T here curves and the signature schemes right so that\u0027s the only point is like if you if you only have to make it so right now everything that TLS have been doing all rightie last idea is is creating as much of a strong divide between the different curves types and what I think would have been better 9 side would be so like I said essentially we give all these flexibility if under what you want to do murmuring let her go ahead if you want to do necklace curve go ahead if you want to use nice hardware that has been all fit certified because you need it for your customers or whatever go ahead i reproduce the same ordering as also essentially if you want to do a lightweight implementation then this would be wrong approach to doing it right right like all the finishes to the 10 10 pages of finishes in a draft are essentially tutorial for people who may not be into some of the crypto stuff but the only thing is essentially defined is in annex D which is the the parameter sets and hobby of late right like I think the part that\u0027s like kind of lacking in the draft is like you know what to do really right so I think we can probably take this up on the list right but for me just reading like the content of the draft it wasn\u0027t clear what its ass is for the implementers of these like is what\u0027s the guidance it\u0027s it\u0027s not clear so maybe that maybe we can I trade on the list to figure out what that is but I think that\u0027s the part that requires development okay Yamato um Erikson first great slides I think this is a excellent reference for summarizing up all these standards then you said that talked about governments nice dead now stated that they plan to standardize curve to four five one nine you in the future we might need to have a different terminology than least curves then one of the one of the benefits with curve two point five one nine and and Edwards to prefer one nine is performance what I\u0027m lacking this dot is what what performance do you get when you use the bias dress version of too far by one nine what performance do you get when you do key generation diffie-hellman function and ECDSA with bias to perform one nine compared to EDD essay or "
  },
  {
    "startTime": "01:23:55",
    "text": "occurred two four five one nine I can give first I did some calculation and it depends on details so so are we so we talked about we can talk about naive implementations and then I think the the BIOS has curves they have roughly to take fifteen to twenty percent eight compared to curve two five five one nine and it could be more but not online T devices so my IT devices you cannot exploit all these fancy tricks that have been done with this like a Malini a new cars have been generated in a template last ten years and they all do something like notification without carry right but all these things don\u0027t really fit too much on on lots of small platforms maybe on a 32-bit websites but if it less than that it doesn\u0027t fit so the only thing you can really get is that you you form like events if you fewer notifications so if that\u0027s the case then the ratio is roughly you may run a lot slower but not much that\u0027s in 20 percent if we talk about secure implementations it depends a lot on what you\u0027re interested in so I look at the world is like HTC for extremely nasty environments in mind in my case that\u0027s a devices then all these models have no Ivan has not seen any real implementation that actually meets those implementation security crimes so it\u0027s it\u0027s hard to do a comparison and but the touted advantages of different curveballs is far less than sometimes advertised at least in in the in in highly hostile environments where you can do with implementation attacks thank you so many permission this would be welcome in the new version of the door unless it\u0027s already yeah it\u0027s hard it\u0027s hard to give the implementation security-related the information but I could definitely I could give some numbers about let\u0027s say the number of multipliers required in the Weierstrass first move only and so on right yeah hi the name is honest things for that great work I was in the way of it previously so I forwarded it to my co-workers who and sort of have that crypto expertise we have obviously been facing that challenge with the implementations of the different different curves and so I think it\u0027s we at the moment we haven\u0027t implemented all of them yet so that\u0027s definitely a useful approach happy to work with you on on sort of the performance characteristics and and "
  },
  {
    "startTime": "01:26:55",
    "text": "those things but we\u0027re definitely get in touch with you once I get there from my co-workers for this place scoots HTT consulting thank you Renee for this presentation and and going through it I really appreciate all I\u0027ve learned from you over the years on the math behind much of the are crypto algorithms and I recognize your expertise in this area but there are other things to optimize then code use and also if some code is better than other code there\u0027s been much discussion of the aspects of the current P 256 Kobus some is good some is not good on what it takes do there\u0027s discussion on on the easy to 519 code base comparing them but there\u0027s also the difference as you pointed out in the XY representation of P 2 5 6 vs EC to 519 being only just on the one axis and I have specifically worked with one vendor an 8-bit processor and a 32k memory of allowance and they just could not have done P 2 5 6 the storage requirements and whatever they\u0027re doing the third 32 byte made the difference for them plus them the other processing that I was able to get them to do the easy for ec2 519 implementation and they tried they could not do PG 5 6 so Isis if we\u0027ve done this with with one implementation of course it varies across the map and so when you\u0027re talking about optimization there are many factors to consider on it on this is definitely want to consider and and how you maybe would do things but the best that L wig can do is to as you point out is is to tell until s1 3 can you please give a representation so that easy for 19 maps to same as as P 256 whether that has value or not we let\u0027s we can run down their path but I really don\u0027t think when you take all the different optimization considerations in that this is a we\u0027ll get legs but it\u0027s definitely very educational and I really think your name yes there\u0027s not about be attorneys right hi Rena so my name is in town and getting out of math I think there\u0027s some points that might be useful for many implementing implementers of the the IOT world I also I also come back to ask our implementers to check if that\u0027s useful to came we use some code and to break down the memory usage by speaking us the code one the "
  },
  {
    "startTime": "01:29:57",
    "text": "coach of this walking group I really want to dis document we focus on the detail guidance for four things that in scope that will make I think this document more impactful and the useful a clear mmm-hmm and also I think the for the last item on the screen which is some criticisms about the IETF I see that\u0027s okay I mean that\u0027s a happening every day and but I think that\u0027s probably issue talked is topic for this point maybe that\u0027s useful for the larger audience as out of scope of I err week for me the Securities Patterson I\u0027m not sure right now but I see yes yeah I think this would definitely be useful to have more eyeballs on this more than more than L week pretty much but especially for this one because this one we need all the crypto experts to have some say on this but I think we are almost out of time so maybe we look forward to your next portion one comment from Hondas so I guess the type of expertise that you need here this is someone who implements a crypto library and also specifically obviously elliptic curve cryptography of course it\u0027s not that the person you typically run into so so there may be in general like a limited number of people and and so we have to do some extra effort to reach out to those probably if we look around in a room most of us are probably not the target audience for it and so you could forget it right away but that doesn\u0027t by itself make this document useless I think it\u0027s in on the other way it\u0027s just a very complicated problem and complicated topic and so so I know within my company on who to talk to and I\u0027m sure you have similar guys in a company so but they are they typically don\u0027t sit around here so I think if we forward that this presentation and the document to those people I think we could get some some useful input this much appreciated all right so we are adjourned for today thank you everyone "
  }
]