[
  {
    "startTime": "00:00:21",
    "text": "good to see you on pam you are our our official note taker but we need a second one if we can get a second one please then we can go ahead and get started describe just who says what right so uh conversation style does that work for you yes okay great so can i get a second one i just posted the link to the notes janelle i hit hate to pick on you but when you're not presenting can you also help to speak up where did you post that link i'm sorry i'm not seeing it right now oh i posted it on the chat it is also on um your meet echo view it's the little pencil icon notepad"
  },
  {
    "startTime": "00:02:00",
    "text": "on the top right right here thanks yes so i tried to preload the agenda there okay in the interest of time um if if i could get a second one that would be great please um we've got a full agenda today so i want to welcome you to our our first official uh continuation of the skim working group the session is being recorded and why is it not advancing there we go okay so there may be a few of you who this is the first skim meeting so just to provide you the note well um there are some notes uh to take um here with respect to privacy um we will be following the iatc ietf privacy processes as well as the ietf processes sorry um i'm not going to read them through but um there is the note well to be considered okay uh some meeting tips uh please stay muted it is recommended although for me the headset doesn't work we usually track attendance through the blue sheet but now that we're meeting virtually um it's being tracked automatically there are chat rooms and the meet echo some of you are already on there and if you need further assistance there are a couple of links there to help you the other thing that was noted um that we should highlight is the code of conduct so a reminder of some of those points"
  },
  {
    "startTime": "00:04:01",
    "text": "here is that um as we participate we should extend um respect and courtesy we all bring in different perspectives we are a diverse group so just be respectful of that keep our discussions professional um and uh to stay on point all right so with that in mind uh thank you pam again for being our our jabber we definitely could use a second or third one um it is a live note set of notes so i encourage everyone to help um especially as pam will be presenting um on the third slot so with that i want to get to the first order of business which is to bash the agenda and i forgot to introduce my co-chair barry who is also with me and will be helping me run the session um okay so we have a full agenda there we go hey barry um so i'll i'm just gonna spend a few minutes to remind everyone of what we said we would do in the charter the milestones are there to be [Music] as markers and we can update as we go along um but getting to the agenda so first step we've got janelle and danny to help provide an introduction of what we did in the first when skin first chartered and why we rechartered meaning they'll go through the current original rfcs with highlights of the new work that we may want to tackle there that will then be followed by pam who'll cover the"
  },
  {
    "startTime": "00:06:00",
    "text": "the use cases and concepts that we want to focus on now based on the rechartering i am hoping phil will join i don't see him here but he is um on the dock here to present um his current draft on uh on multi-value filtering and then danny will be talking about a couple of of proposals that he put together in ietf drafts um that go to the skip extensions and then at the end i just wanted to cover our next steps and the types of tools that we may want to use i've got a proposal um that i'll put up a couple of polls for how we want to proceed and that kind of brings us to the end of the session so with that in mind any comments or feedback going once going twice if not okay i'm already one minute behind so i know this is an eye chart um but i did put in the link to our tour actually to our actual charter but again just to recap um what we agreed to do was to revisit and review and augment to the use cases that will help drive the work that we need to do vis-a-vis updating both the schema and the protocol rfcs followed by some of the other extensions so again i'm not going to read through the charter this is just to provide you that high level um overview i saw somebody come up on video so if you want to get on the queue then i suspect um i would like for you to come in and um sorry i'm not awake yet"
  },
  {
    "startTime": "00:08:00",
    "text": "to put yourself on the queue um through the participants you don't need to turn your video on okay so with that um being said what we also provided was just a stake in the ground for the kinds of documents that we may want to do besides the revisions to the base schema and protocol and we just laid out some what i'm calling markers or milestones of rough targets of where we want to be that doesn't mean that this is the final thing it is up to the working group for us to decide how we want to break the work um and move forward on things so okay that being said i left myself with a minute for questions or comments if not i know we have a full um full agenda so if not what we can do is move forward to the intro and we can have janelle so janelle i figured and danny i could run the slides for you unless you want to but i just shared them for you welcome everybody um nancy are you ready for for danny and i to take it away okay please go welcome everybody uh i'm janelle allen and uh i'd also like to introduce you to danny zulner we both have something in common we are product managers uh for"
  },
  {
    "startTime": "00:10:01",
    "text": "for danny's at microsoft and i'm at cisco anyway nancy could you uh flip to the next slide please um we just like to start with what is skim you know this standard has come about over the last 10 years i think yeah when did it get uh released danny the the rfc do you remember um but danny uh okay uh about 2015 i believe yeah 2015. and so it's been it's been around for a while and really what was it designed to do it was designed for sharing identity data across contexts and it really uh was normalizing this data you know normalizing maybe is a tricky word to use um but it was abstracting away this data from its existing where it was residing in its data source to be to be shared between um different you know different organizations identity context domains is what we call it in the standard it consists of a communication protocol and the core schema and this you know it allows for extensibility it wasn't you know a net new standard it was building upon a lot of work that had come before us in in previous waves of deploying and handling identity data and uh it was designed to be fast and cheap and easy to to use nancy next slide please so again why skim it it abstracts away this underlying data structure um if the data is stored in a database such as sql or in in a directory such as about app directory or ad or elsewhere um you know"
  },
  {
    "startTime": "00:12:00",
    "text": "it takes away the notion of of that specific data storage mechanism and it it abstracts that away and it treats every site the same and that enables scale and it's very helpful in that way nancy next slide please to show you an example just at a very very um conceptual level we have an example of an identity here her name is jane smith and her data is stored in a database we don't go into great details of the databases as a suggestion um the format of that data might be stored with the last you know last underscore name jane smith but uh this example is showing that there's a there's a service a skim service that's sharing that data um you know to an app that's running in the cloud you know somewhere and that that app wants to store that same user in a different data structure in the data structure being suggested here as a directory structure and we can see that the the skim service transforms the data from its original data store into this standardized json format that skim takes the data through and then the client can decide how to interpret that data and then store it on the other side next slide please the skim protocol r is defined in rfc 7644 and it had a restful approach in design and it's a set of apis they follow you know they use the http methods you know the verbs for get post push patch and delete which is very convenient for identity data which follows you know the create read update and delete methods so we can map"
  },
  {
    "startTime": "00:14:02",
    "text": "those quite easily to these http methods and you know we can standard uh send the the standard skim json payloads to the resource endpoints which can be users groups as defined in the standard and other resources which are definable by the standard it standardizes these methods for communication with the servers in skim these servers are called service providers and a service what is a service provider in in the sensuality it's an hdb server which exposes standard cm apis for for the traditional create read update bleed operations uh for skin claim um all of the endpoints provide well there are three endpoints i should say that provide discoverability for for understanding how to to interact with the server or the skim providers and danny will take over the next slides uh hi uh so yeah we wanted to go over uh just what are the the standard endpoints included in the uh the original skim 2.0 spec uh so up at the top of the list we've got slash users and slash groups uh those represent shockingly users and groups uh which are you know mainstays of uh identity really regardless of how your you know where the identity data is uh stored uh those endpoints allow for sort of the full gamut of the rest verbs get post put patch and delete um and uh both i guess uh users and groups they come with a core set of attributes uh and then uh the users also have uh in their schema there is an enterprise uh schema that is uh you know"
  },
  {
    "startTime": "00:16:02",
    "text": "an extension of a couple extra attributes that is included uh in the the game 2.0 standard uh groups has a simpler schema compared to users uh the only group specific attributes uh that aren't part of a common pool would be uh display name and members uh but part of our charter is to uh look into that and make it uh expanded uh there's next uh on the list we have uh slash me uh slash me is a method to find the standard to allow uh an authenticated uh user to read uh data about themselves or interact with themselves so you know examples being uh maybe uh you've got some an internal application and it's going to update uh it's gonna allow the user to update their password using the skim standard uh so they can send a post or a patch or whatnot to uh well find out a post because how are you gonna create yourself but um uh it allows them to you know manipulate themselves specifically um next on the list we have three that all have that check mark next to them uh and these are what we refer to as the discovery endpoints uh so slash schemas allows you to retrieve available schemas and the themes are just you know representations of a set of available attributes for a resource type so uh the user's resource has two schemas the core and the enterprise groups just has core um and you know it's very extensible um moving on to the next one uh resource types uh that's a way to discover what resources are available so um in in the you know the core standard implementation resource types would return uh users and groups uh and then uh servicewriter config allows you to read uh configuration details uh specific to that skim server or service provider such as you know it is such and such"
  },
  {
    "startTime": "00:18:01",
    "text": "feature enabled and if it is you know what are the parameters of it um so there's a handful of uh of like configuration options in defined in the core schema but some of the uh draft extensions that have been written also they all propose using servicewriter config to advertise whether or not they are implemented on the service provider and down at the bottom list we have uh two that are um i think a little less frequently implemented but i i've seen instances of both i believe um bulk especially so there's uh dot search uh which uh you would uh it's essentially an alternative to the http uh getrest method um it allows you to define a query uh and you submit that career using post in order to serious uh set of results and then uh the bulk endpoint uh you'll submit your request using a post and inside of the body of that request will be uh one or more uh separated sets of actions so you'll include not only the resource that you're that you're hitting but also the uh the rest method and the body of that request so it allows you um to sort of scale and hit efficiency more easily because you can submit uh you know 20 or 100 or higher uh amounts of uh accommodation of get post patch foot delete um so danny and janelle i don't know if you're taking questions in the middle but phil hunt is in the queue you might have a comment help phil you're in the queue did you have a comment or question the size microphone thing light up"
  },
  {
    "startTime": "00:20:05",
    "text": "okay just keep going daniel i'll ping phil okay um yeah he's having my problems uh next slide please and then uh on this page we have uh a not exhaustive uh okay uh so phil had a comment uh the post on dot search is for security because a get query can reveal pii okay uh so yeah i i did not have the context on that so it was very much appreciated uh and to expand on that we could actually use uh what we have right here on on this slide to go into the details of that so um on this slide we have a set of uh examples uh not exhaustive obviously of uh things that can be done with the skim protocol uh so the third example we'll just jump straight to that uh in the resource url so https you know whatever slash users filter equals uh you can see there we're saying users filter equals username equals user domain.com and so the dot search uh option allows to perform a search without uh having sort of a plain text url with pii in it uh so now rewinding a little bit we'll just talk to some of the other ones uh so a post against slash users will let you create a new resource and this is you know all the i'm using users as the examples for all of these but this scales out to any uh data resource representing objects that can be manipulated uh so if you send a post with a body containing adequate information to slash users slash groups uh you know flash anything uh assuming it's been implemented uh in this in the the relevant skim server uh you should be able to create a resource uh get against the the root resource like slash users will return all resources"
  },
  {
    "startTime": "00:22:00",
    "text": "uh then the third example you can define attribute based filters um they can be fairly simple like this or they can be uh multiple sets in parentheses uh you know you have a full set of operators and or um so uh you you can only return users where department equals sales or uh you know it matches they match a specific username uh and then we also have another method of retrieving a user that doesn't use a filter uh which is the fourth line and i'll just be getting them using uh their id value which is a sort of a core component of skim and that will return just the resource matching that id value and the standard states that id needs to be unique across all resources um next two are two different methods to update objects uh so if you do a put on a on a resource uh you will define the full set of attribute values that uh that it has and if you omit anything uh it is expected that the the attributes that have been omitted will be set to null or you know blank uh and then patch allows you to do a selective uh set of modifications without clobbering all the other things so if you send up a patch for user and only modify active from true to false you're leaving all the other information away are alone rather and not modifying it um another option for updating you can actually use filters to select a group of objects or resources and update all of them uh based you know anything that comes back on the filter will get the same update applied so if you need to change the name of the department you know sales gets turned into you know the organizational rebranding or whatever you can do that you know at scale pretty easily and then delete self-explanatory allows you to delete the resource"
  },
  {
    "startTime": "00:24:00",
    "text": "next slide please uh so now to talk about the schema a little more so the schema defines a minimal common set of attributes that represent the user in group data along with the enterprise extension we talked about this uh it's also very extensible uh so you can extend schemas uh you can you know add existing uh or you can add attributes to existing resource types uh you know users groups uh but you can also extend resource types uh so if the content you know if the the concepts of users and groups aren't adequate for the usage situation uh your service provider can implement others and they can be advertised uh with that slash resource types endpoint uh that we discussed a few slides ago um so it may be slash contacts slash uh you know uh conference rooms but the sky's the limit essentially uh and then uh the skin standard uh says that custom schemas may be permanently registered with ayanna um from our research we're not actually sure if anybody has done this yet although there are plenty of custom schemas out there um so far the the only ones that we were able to notice there uh were the ones directly assigned to the the standard uh next slide please uh and so now we wanted to take uh sort of a little snippet of the uh the rfe uh and show how it's represented in the body of of an object in in skim format uh so the the skim uh schema rfc which is 7643 uh has two different spots where it uh describes attributes uh the first section which is uh it's either in the in the section three or four uh sorry i can't remember uh is more a more descriptive manner of talking about attributes and that's what we see on the left um and so it um it's a short set of you know one or two sentences per attribute sometimes longer talking about the"
  },
  {
    "startTime": "00:26:00",
    "text": "properties that it has um and then down in i believe it's section eight there's uh a full json representation of the schema uh that's shown and that gives you uh all of the the nitty gritty uh the mutability state is it read uh is it read only is it read write uh is it multi-valued what's the data type uh all those things um and in the current standard there's been a couple uh there's been a couple instances where uh some confusion gets drawn between the the two sections uh the like sort of uh expository description part versus the the json representation uh but and that's something we're hoping to touch on moving forward uh but on this slide uh we can see uh name is described as a single value complex attribute it's the components of a user's name and then if we look over on the right in that section of name we can see its name and then the squiggly brackets which are indicative that it's a complex attribute and a complex attribute is then made up of uh one or more uh simple valid attributes so that could be you know string integer uh what not uh boolean uh so name has several sub-attributes formatted family name given name um and then you know phone numbers is similar except it's a multi-valued complex attribute and we can tell that because it's the the square brackets and then uh it'll be one or more sets of squiggly brackets uh each set of squiggly brackets uh enclosing a single like complex result or object uh of that value i guess a complex value would be the right word and uh yeah we can see phone numbers uh in this representation has value and type uh i believe there's one or two other uh sub-attributes as well uh and same thing for emails uh it's"
  },
  {
    "startTime": "00:28:02",
    "text": "multi-valued complex so it's an array of one or more complex uh values uh typically with uh the the type value is used to differentiate between uh different purposes for email because if you have more than one email it may be that uh you know one is a personal email or a secondary versus uh you know a primary like work related one uh certain attributes in the schema such as username uh are required uh id is also required um and then there's in whenever uh results are recreated from a server uh there are also some attributes that are returned back that are read-only so there there's this whole uh complex uh meta attribute with some metadata about the object um [Music] and then uh you can see up at the top uh the schemas returned tells what schemas are being uh used for this object so you can see in this example uh the core 2.0 user schema and the extension enterprise 2.0 user uh which are you know the two different user schemas in the in the standard uh next slide please uh and here's just a quick list of the data types uh you got you know your old favorites uh strings booleans decimal integer date time uh binary and then the the two that are you know worth talking about a little bit here are reference and complex uh complex we just uh saw a couple examples of uh again it's just a collection of one or more simple valued attributes grouped together um and then reference is a pointer to a resource somewhere so for example the standard defines uh a an attribute for photos for uh like a profile picture type concept and uh a url will be included"
  },
  {
    "startTime": "00:30:02",
    "text": "you know https console whatever.jpg and so the the reference attribute is a reference to a uri pointing to a resource uh and with that uh next slide please and back to janelle skim has been widely successful it's been widely adopted by many many companies around the world um it it's why we are here is that there have been some wrinkles in in skim and we seek to address them and some of these are related to usability um sometimes the spec isn't 100 clear in certain areas and this leads to some interoperability challenges and then you may have a client side skim client that customer that's interacting with the server and they come into well having arguments over how they're implementing the spec and then they realize that actually it's not clear sometimes in the spec there is limited guidance on certain certain aspects such as groups and roles how you handle entitlements and some of the attributes are not clearly defined in in 7643 so we seek to improve the usability of the spec in general we are looking to make improvements uh some uh some companies have noticed some problems with the bulk operations and and how they operate pagination uh has some limitations some people would like to extend the core schema and then you know there are some new and emerging concepts that happen in draft that are actually in use in draft such as limited uh privileged access management we seek to to move that from draft to standardize and address whatever issues it has so"
  },
  {
    "startTime": "00:32:00",
    "text": "these are the types of papercuts the paper cuts we have a link to and we welcome other organizations to share their experiences uh with skim as well and uh and and show that with the working group so we can address any other issues that may not have been already documented in the papercuts nancy next slide please so what are our goals for the next generation of skim and really we seek to improve these overall best practices and guidances and clearing up the specification in areas of ambiguity um there is some notion of that had been in previous drafts regarding soft delete and how to handle that in skim as well and then also looking to enhance the schema in certain areas for for data that's handled by hr systems enterprise group data as well as privileged access management advanced automation scenarios there are several of those that we could wax and lean on for quite some time and then enhance data handling for larger sets this could be the pagination this could be other things um these are sub articles you can read the full list in our charter of what we're seeking to do in the link below and answer shared as well thanks everybody are there any questions yeah you're doing great on time well nancy it seems that uh we can move on to the next agenda person and then there'll be more time and questions on something meatier than the intro how we can proceed well i mean at some point um the group will need to decide on the"
  },
  {
    "startTime": "00:34:02",
    "text": "content of how we want to go about updating both the schema and the protocol specs right but in the meantime yes we can move on to pam all right kevin we've had some micro shoes can you hear me yes we i can hear you fine i can see you fine that's awesome great and i just shared your slides perfect um and you're willing to place a slide adventure for me of course okay that's fantastic thank you for all your work and we really appreciate it hi everybody my name is pam dingle i work for microsoft as well i get to work with danny and what we want to cover today is in fact we want to dig more into rfc 7642 if you haven't heard of 7642 i wouldn't be terribly surprised if you want to advance to the next spec so there are actually three specifications that were published as a family um in that 2015 time frame 76 43 and 44 were the the core schema and the core protocol um this document 7642 is has the title of definitions overview concepts and requirements uh so it's a non you know to use what i think is the right spec terms it's a non-normative uh document it doesn't um exactly instruct you how to use how to use things but it is meant to you know the goal of it as i understand it is for someone to be"
  },
  {
    "startTime": "00:36:01",
    "text": "able to read this and then have an easier time understanding what to do with uh the actual core specifications does anyone want to add any color around the creation of 7642 now i know we have a few people who are there for the actual process it's too bad phil has make problems because uh i know right he was there from the beginning yeah yeah um so i guess that means that i can um you know take his name in vain for the next 30 minutes and there's really nothing okay don't put that in the scribing all right so uh so what we want to do today is just look at what the fit for purpose um has been for 76.42 and at the end of it my goal here is to ask whether people have interest in participating in an effort to revise this document so just keep that in mind as we speak uh informational status sorry roman in the chat added the official correct terms um so it is an informational status versus a proposed standard which is what 76 43 and 44 are okay great so let's dig then into what what does 7642 talk about so one of the major things that 7642 talks about is it tries to um create um the names of actors that have relationships to each other in um in the skim specification or you know or that could um com comprise use cases that use the skim specification and so they just describe three different actors a cloud service provider an enterprise cloud subscriber and a cloud service user now this of course is now slightly dated terminology"
  },
  {
    "startTime": "00:38:00",
    "text": "in that um you know the the a lot of the implications in the document are that enterprise cloud subscribers always um have certain patterns of usage and i think those patterns of usage are slightly have proven you to not pass the test of time but essentially what you're seeing here you know this sort of diagram that's been provided is this idea of a cloud service provider as essentially a multi-tenant platform with many ecs's or enterprise cloud subscribers of subscribing and then in turn those enterprise cloud subscribers have um users attached now the interesting thing about this is that um that you know there is no exact correlation here to a subscriber versus a provider in the actual 76 43 and 44 language so the word subscriber is not a term in the protocol at all as far as i know it's certainly not in the definitions in rfc 7643 and so there's some confusion and ambiguity here now the other thing is that the cloud service provider the term service provider is in fact an important term in 7643 but as you'll see as we go on there are times when cloud service providers talk to cloud service providers and in that case the term service provider has zero protocol specific meaning and so we have a we have a collision in terms just in the basic terminology that's used in 7642 let's keep going if you want to advance this um so here's where the real confusion comes in so the you know we define in 7642 triggers modes and use cases so the triggers um are sort of the major obvious triggers that would happen in a"
  },
  {
    "startTime": "00:40:01",
    "text": "restful um a restful service endpoint right creation update deletion and then there's a trigger called single sign-on which is an interesting one so it's really meant i think to talk about just-in-time use cases but the interesting thing nowadays is that just-in-time use cases occur for reasons other than just sso they occur for things like privilege elevation for example and so that term is slightly outdated now as well it was perfectly fine in the day at least in in my opinion and by the way i'm making um what might be provocative statements in the hopes that you care to to correct me so um you know if you feel like i'm being overblown here i would love to hear it and i you know i'm doing so kind of on purpose to to see if i can enrage you all enough to come join me in making this work so so you can see the use cases uh in the document for example we have a ton of these cloud service provider to cloud service provider interactions that's perfectly fine we certainly have cloud service provider interactions today in 2021 however what the document doesn't do today is translate the use case of a cloud service provider trying to um create an identity at another cloud service provider with any kind of protocol terms so you know we all we really get is this very coarse understanding that data is being pushed from one cloud service provider to another and i think all of us here can agree that for someone to really understand how skim works they have to understand more nuance than that right they they you know the data flow the direction of data flow is important but there are a ton of concepts that an actual implementer of the specification has to understand and"
  },
  {
    "startTime": "00:42:00",
    "text": "we'll go through some of those concepts um a little bit farther along but the you know the big one here is there is the confusion over service provider because in 7643 um you know service provider is generally defined as as being an entity that runs a service endpoint the restful endpoint right and a client is defined as the entity that is accessing that endpoint and so you know when you when you talk about pushes and pulls uh we uh you know there's an implication here that is the client pushing to the service provider or the client pulling from the service provider but none of that is is explicitly defined it's left sort of um for you know for the reader to you know peruse both you know you really have to read all three documents before you can come to any conclusions which i believe is makes this document slightly yes less useful um you know the the next question is you know that again with subscriber our is a subscriber a client we don't know we don't think so uh you know just based on this list if you look at it um you know if an es if if an ecs is pushing to a csp then great that yes you know ecs would likely be the client and the csp would likely be the the service provider um but what about the other options you know what if what if we want the opposite to happen right we what if we want the ecs to be the service provider and the csp to be the client those things are also possible and they're not described here um just stopping anyone want to comment on these use cases has anyone had experience in reading this doc i'm guessing people don't because i don't think it's a you know i don't think um it's a useful aid at this time and so we're sort of in this situation where no one's read it no one knows it"
  },
  {
    "startTime": "00:44:01",
    "text": "exists and um hopefully people will feel the need to be able to come help me improve it if you want to go ahead and see so here's the other question to contemplate right how has identity management changed in the 10 years since 7642 was started and where we are now um you know and how many of those concepts are actually important for implementers as they look at the skim specification so uh you know you look at the sso trigger as an example of of how the world has changed right privileged access management um is now in 2021 an absolutely critical part of of most enterprise security regimes governance regimes and that idea of a real-time ability to create to quickly create an account it existed in 2011 but it existed primarily as a a federation concept where you know you when you arrive at a relying party the relying party would take the data from us from an sso assertion and push it into a database right create the user on demand at that time there's a whole bunch of on-demand capabilities and and um use cases that exist now um you know we have a ton of workflow around privilege elevation that's super important as well so you know cross domain um you know not not just access but elevation those two concepts are are one example of this um another interesting thing to note and this is more to 76 43 and 44 is that um web hooks didn't exist as i understand it they did not exist before skin was created so you know do we have to think about uh those kinds of um"
  },
  {
    "startTime": "00:46:00",
    "text": "you know industry changes that have occurred around us proof of possession is another example you know we um we have some basic requirements right now in um 76 43 and 44 around oauth but we don't have like strong security recommendations for skin because those those didn't exist we didn't have things like um depop at the time that this document was being created and so the question then becomes are are these kinds of concepts and use cases things that we do want a skim implementer to be aware of um you know we have a lot of issues right now with folks taking what i would call the hello world path to implementing specifications where they implement it until it succeeds right they implement it until the user gains access but what they don't do is check whether users that shouldn't have access don't and you know this is this is a big problem industry-wide in my opinion and it's something that we should be more what's the word we should be better able to advise now especially as folks who who are writing clients are trying to understand the bounds of of what they should implement anything does anyone else have a list or is there anything others would want to bring up around you know changes in the way identity management has changed um the other one that i want to bring up here is maybe the simplest one which is in 2011 it was almost a given that enterprises on premises would be the heart of any kind of provisioning regime i don't know if anyone wants to challenge me on that but having been there myself that that's my you know that's my my memory right was"
  },
  {
    "startTime": "00:48:00",
    "text": "that people loved the cloud in limited doses and really never thought that a cloud an entire cloud native uh regime was anywhere near coming true but we are here we are 10 years down the line and so the idea of a pure cloud native enterprise is starting to be true there are cloud native enterprises today and so that idea of you know all every cloud element is is trying to now negotiate their service provider-ness versus their clientness and that stuff is all uh just changing right yep you have janelle in the queue she might want to comment as well excellent go ahead janelle um yeah pam just to add on to some of your observations in the last 10 years and how identity has changed um you know i think when we were looking at skim back then it was really between you know maybe you know within an organization to another organization but not this kind of explosion of the propagation of the cloud and all the service providers that are out there and all the funnels of all the data that's uh that's floating around and so i think that there's kind of a narrow view just really based on the existing implementations of how people were implementing locally within their organizations say provisioning services or identity services for their enterprise but then that expanded reach now globally i think there were notions of how that might work but we didn't have that practical experience as we do now that makes perfect sense and you know probably the last big change is uh that governance has become a security imperative and that you know i would say in 2011 governance was primarily an accounting measure you know you would count all your users you would make sure you had the right users"
  },
  {
    "startTime": "00:50:00",
    "text": "you might sign a quarterly affidavit and what we're seeing now is this huge push for real-time understanding of who has access to what system and you know with uh an expectation that if attackers are in the system there is a detection that can occur and a remediation that can occur so instead of every quarter looking at your user list for for a financial resource and saying hey john smith is dead we should really remove him right we're now in a situation where attackers are you know gaining access creating a user with administrative privileges executing five commands deleting that user and those kinds of activities now um make provisioning far far more important right it's not just a case now of having to deal with that with users who might get terminated and then try to sabotage the company you're really looking at using provisioning using user an understanding of who's and what systems to keep the entire company safe all right so if you want to go ahead so what 7642 doesn't do today which i think it should is it should talk about how clients today implement bi-directionality because the truth is there is you know we're not purely pushing and we're not purely pulling in almost every circumstance we are you know generally speaking there's a flow a data flow right where we are you know the creation of accounts occur in one direction and it may occur from skim client to skin provider or it may occur from service from you know um from the you know the flow may run from service provider to skim client but the skim it's because the skim client is pulling data so understanding this diagram to me is a big part of what we can do with 7642 right if you think about"
  },
  {
    "startTime": "00:52:02",
    "text": "how a push pull works um when the data flow is moving from skim client to skin to service provider generally speaking what it means is the skim client is making those create delete um you know patch post or patch pull you know uh put types of commands but they're also using get commands constantly right to make sure that they have the right idea of what the service provider knows to be able to check whether an incremental push is even needed right so it isn't just a case of of the data flow it's a case of the skim client having to be sophisticated enough to know what it can search for when to make for uh you know to make their queries efficient so you know giving a better more nuanced view to folks who want to be a skim client and who want to be able to update service providers would be very very useful if you look at the second piece down here um in the same way if you are a skim client who has to pull data from a service provider there may absolutely be pushes that occur and that is you know that comes to this idea of multiple starts of authority which i think is another place where in the last 10 years we've gotten a lot more sophisticated so it's absolutely possible for example in an hr system that the hr system is the service provider that you know a cloud platform might be pulling data from the service provider um and might even be responsible for the existence of the user um but is going to push back and you know is going to play the authority for an email address for example and so uh you know so it just isn't as simplistic now as it might have used to be and so we absolutely have to understand how the user is moving right how the accounts are being being created through the system but we need to give more"
  },
  {
    "startTime": "00:54:00",
    "text": "nuanced advice on how you know how a you know a user with a specific business goal can actually deploy these tools all right if you want to go to the next one so the two patterns you see here combine right and this is the other piece that is not addressed in 7642 um you you end up with these chains of provisioning where uh you know you might have a cloud platform in the middle right as a service provider and you might have clients looking to both push and pull data so you know in this case another you know this could be workday on the left-hand side and it could be salesforce on the right-hand side and it could be google in the middle as an example so understanding where you are in this hierarchy and you know related to your start of authority becomes important because it changes you know just because you're a client attaching to the service provider does not mean that's enough data for you to understand what you should do next and you know this is also where the pagination and synchronization discussions come in we have given you know there's no guidance at all for folks as to how they should be thinking about reconciling data keeping data in sync and i think we can better prepare our users in this case i'm just going to do a quick time check nancy um do you want me to be done by 5 a.m um you you have 15 more minutes okay all right and i think and dan uh janelle and danny for that but yeah you have 15 minutes left okay cool um all right so in that case so so in this case i've defined this term of provisioning hub i"
  },
  {
    "startTime": "00:56:00",
    "text": "don't know that this is the right term it's not a term that's used in the specifications today but you know if if it's the case that we want these kinds of relationships to be communicated then i think terms like provisioning hub might be more valuable right that show that data is you know sort of ingressing and egressing so to speak compared to talking about a cloud service provider because essentially everyone's a cloud service provider today so it's not super valuable to call them that um you know i'm open obviously you know we can propose any set of terms we want but i do believe that some terms to help understand the difference here are important and so you know if you're a for example if you're an implementer who is you know who has a a sas application and wants to be able to pull data from let's say you know three major cloud service platforms right pick any three they may actually have to you know they they may not be able to play the client in all three situations and so having them understand that and understand that they're essentially that you know the final stop on a train is super valuable uh if you want to go to the next slide right this is so this is one common pattern right where the service provider is the provisioning hub the second common pattern is the case where the skim client is a provisioning hub and in case you think that that there are no examples of this in the wild microsoft azure is an example of this pattern right whereas i believe that amazon and google are both examples of the service provider pattern so in this case um you know the the you know if you're that same person that same implementer trying to set up your sas app to receive data you're going to have to implement an endpoint versus implementing a client right and and ultimately the decision you make there depends a ton on what your downstream partner"
  },
  {
    "startTime": "00:58:01",
    "text": "already has set up and that's i think a useful thing to also communicate here um and again it has to be bi-directional right the the um the pattern that that was brought up in this case of you know if you're on the right-hand side here is the as a service provider on the right is that um you may be absolutely oh i just realized my errors are backwards but anyways you may be pulling data from that or the skim data you know the skim client is going to be looking at you all the time right in order to push data to you because they're going to be looking at whether they need to push in the first place right so those patterns of push-pull become more and more important for implementers to understand uh oh i got a comment in the chat since skim is an http protocol the terms all originate from http yes that's that's fair enough but i do think that an overlay um in this case is is useful i don't i don't know if there is a there isn't really a concept of chaining i don't think right and that on the http front if there is let me know and we can always adopt it all right so let's look at yes perfect thanks nancy so again these things compose right so the chains start to compose as well and we start to get maps of how account creations right and account updates ripple through a company right or through a system or you know through a network and so what you can see here is i've you know i've got notation to denote where the start of authority is so in this case the top left skim client is sort of the origination of the account and as um as you know the skim client there pushes to the service provider what happens is you may have a provisioning hub that in fact can handle both service provider and skim client operations right so in this case you've"
  },
  {
    "startTime": "01:00:01",
    "text": "got a full fan out effect right so you you know data gets pushed from the original skim client into the service provider and then what hap what's happening is some clients are pulling that data in order for them to be updated um but the cloud platform may also be pushing that data to other service providers right so now you've got a full-on ecosystem of pushes and pulls and ripples of data the one thing to note here is if the on the you know the service provider on the bottom left although it's drawn with a data flow that implies that it's um that it's a downstream application it's not right if you look at the pattern the pattern for that service provider is identical to the pattern for the service provider on the right so essentially uh you know the patterns start to collapse at some point right depending on the on the um the direction and the directions matter far more about where this big dotted line is than about any kind of overall direction right things start to um to blend and if you go to the next one so that you know so that's one case the case where the skin client is kicking off the avalanche you know the second use case is where the service provider is kicking off the avalanche right so a database gets updated the data passively sits at the service provider waiting and the cloud platform as the client then actively goes and pulls that data from the service provider and kicks off the whole ripple effect again right whether that whether there are entities passively fetching or entities that are actively being pushed to you so to me this is this this understanding of how all of it works right as this much more complex set of pulls and pushes are far more important um than just understanding there's such a thing as an overall push or an overall pull all right you want to hit the next one and we're getting to the end here so then the question becomes what can we do right what should we do we don't have"
  },
  {
    "startTime": "01:02:02",
    "text": "to write an entire opus on how skim works right so i think what we want is a minimal amount of data that is going to make it easier to read the specification right um and so for me there's some basics here first of all we have to align the taxonomy we have to talk about service providers and clients in ways that are helpful to understand how they work in the specification this as it exists today 7642 never never talks about service providers or clients never talks about resources or resource types it never talks about extensibility it it never uses the term provisioning domain which is defined in 7643 um you know it none of that is even in the document and i think that's uh something we can address um and then you know the the from a use case perspective now we have much more nuanced use cases that we can discuss right we can discuss for example you know the 7642 doesn't talk about groups at all it literally only talks about users right so just that you know you think of the um the difficulty that exists um in understanding what to do with large groups right million user or million member groups um talking about those use cases i think can be very very helpful have people understand what they need right um the slash me endpoint is never discussed search is never discussed uh so you know some number of things we don't have to exhaustively drain it but finding the set of use cases that actually give people the whole picture of the specification is valuable you know custom setting up custom resources for example would be a very good use case in my opinion um and then you know and then there are some of these more advanced concepts which we can decide whether to include or not um this the idea of incremental attribute exchange"
  },
  {
    "startTime": "01:04:00",
    "text": "never discussed and that's super useful um the you know that like put and post to read the spec and understand the difference between a put and a patch is is pretty hard work but we could very easily make it uh better with a use case that describes it um and then of course synchronization is the other one that's a heavily discussed part of this new skin 3.0 world um so let's see oh phil you've got a comment in the chat about looking at things from an information perspective i would love to know what you're thinking there if you want to jump on the cube please do um yeah pam that comment was um well before okay yeah i'm sorry i didn't see it soon enough um no no no that's fine sorry phil if you do if you do want to come on and make a comment we of course would love it um but at the end of the day you know here's what we i think we need right we need something that's easy to read and um that is going to be time well spent for anyone who takes the time to look at it and then something that in fact is going to change how people read the specification in a positive way right and then the last thing is just to make sure that there is nuance that that can be gleaned out of this document that helps them understand complexities as they look at the spec and i think that's it i will i will leave it there hopefully this is useful for folks but i i would like to ask for volunteers so you know i am committed to trying to put a draft together as soon as i can um and submit it to this working group for consideration is uh you know if there's anyone who's interested in being part of this you can respond on the email list i'm assuming you could contact nancy or barry you can speak up now"
  },
  {
    "startTime": "01:06:00",
    "text": "anything like that would be greatly appreciated well so this is a little uh disconcerting so phil if you have no audio um pam you've got four minutes left so if anybody has comments or feedback or additions or a different perspective to what pam presented um we can discuss it in the next four minutes uh pam you have a volunteer in janelle yes she's been on the channel she's happy to join you um so next on the agenda phil if you have no audio you had mentioned that there was potentially somebody else who could also present yeah i couldn't remember his name so there isn't a way we can call phil in or anything like that is sir with me deco ah greg wilson um yeah alessandra i don't know if you have any other suggestions to have phil be able to present because he's up next we could try um getting me on the phone with phil and seeing if it will play through my microphone let me see if that can work okay thanks barry so pam i think this is a really good"
  },
  {
    "startTime": "01:08:01",
    "text": "start at the modernization um it looks like you're introducing some new terms as well that could help um help provide a guide i guess as we modernize the protocols as well um yeah i'm hoping i'm hoping to for guidance i mean i think what we can do now is revive seventies you know revise um this use cases and definitions document to point to the current skim document so that they're a pair and then in theory there's a possible revision that has to happen at the point where we where 76 43 and 44 are subtly changed right if we if we decide to subtly change them right so i you know i feel like this work there will be an initial piece of work to align to existing skin 2.0 specs and then a follow-up addendum possibly you know prior to us trying to go to any kind of you know get any kind of rfc number to be sure that nothing's changed out from under us okay well i suspect that you know once you put a a proposed draft in place we can evolve it over time um perfect typically yeah in in the other working groups the use cases help guide how we shape the updates to both the scheme and the protocol as well and potentially other drafts as well that makes sense i think i mean i think what the you know the group can do in general is also keep us from boiling the ocean right um there's definitely a line that has to be drawn as to what's useful for people to know and what's too much information"
  },
  {
    "startTime": "01:10:00",
    "text": "so i think that'll be yeah yeah sorry i forgot to protect your your last slide that's right and it was so pretty well my bad um but literally anyone is free hey i see phil can you hear me now yes awesome and we are in perfect timing browser number four okay i presume i should go ahead and share your slides now so thank you pam and um so just to close on the use cases you can also contact pam directly as she's volunteering to put the proposal for updating the use cases draft feel free to contact me as well but also as she is taking on the pen um feel free to contact her directly to get more involved okay with that phil so happy you are now on i can't tell you how horrified i was i'm sorry for all the messing around here yeah danny was kind of sweating too because he was volunteering you know as a last resort so glad to have you on apparently safari latest doesn't work and uh firefox isn't even talking with my os so who knows uh so chrome's working okay um yeah so this draft um came out essentially after skim was published uh and the problem that came up was that uh initially uh when you have very large groups sometimes you just want a sample of the"
  },
  {
    "startTime": "01:12:01",
    "text": "data uh and the idea was hey phil how can we page uh multi-value attributes and and i was a little confused that i noticed people on the email list are confused um we want we want to page the values or say i want a range of values by index rather than paging resources which is the normal what the skim protocol does it lets you page through a set of resources that might be returned from a query in this case the intent is i want to select a set of rows from a multi-value attribute to return so this spec provides two types of ways to select those values either by filter or by index essentially and to help avoid some confusion i've changed the name to multi-value filtering because this spec kept getting rolled up into the stateful page discussion which really is a separate thing um so uh i think we can go to the next slide so this this this draft was submitted after the group finished its charter and that's why it sat around for a few years really hasn't had any discussion um so in skim when we have a filter um we have something called a value i believe it's called a value path and really what it is is normally you might say emails equals phil dot hunt yahoo.com um but really what you're trying to say is if if uh if you want a way to say if the emails.type equals work and emails.value ends with yahoo.com i want to return the value"
  },
  {
    "startTime": "01:14:00",
    "text": "and we introduced in the skim protocol spec the value path notation which is to put square brackets uh after an attribute so that you could execute the filter within the context of that multi-value complex multi-valued attribute so i can say email square bracket type equals work and value ends with yahoo.com would select a particular row from that um attribute um and the thinking here was why don't we use that notation on the attributes list so that i can tell skim that when it returns that attribute i just want a particular row of data or a particular sub-attribute of data from that table uh sorry table it's from that json object that we have the we also then thought as well as doing a value path filter we want to do ranging much like we do with paging so we just use the start index and count parameters to specify if i'm got a group with a million members and i just want the first page of data i can say start index is one but i only want 10 rows and that saves a lot of data being returned unnecessarily so the extension defines this and it also defines two more things the first question that came up in the discussion we did have is how do i know how many values are available um the first time you execute this query the service provider can add a mata attribute meta.attribute.count to indicate what the number of rows are for that attribute um you can decide my thinking was is it"
  },
  {
    "startTime": "01:16:01",
    "text": "would be returned only when you invoke this type of request but that we can discuss i don't know that you need to add it for every single request that comes in we'll see the example request coming up because this is going to be an enhancement to skim and it's its own rfc then you need some method to know that has the server implemented this rfc so we describe a discovery parameter in the service provider config as well in spec so next slide so this would be a get request and in this case the parameter attributes is normally used to say this is the list of attributes that i want returned but what we're doing is we're saying i want asterisks which is i want all the attributes but for emails i only want the rows for type equals work so that would be the get request go to the next slide and you can see that that emails is returned and there's only one value returned and it's the one that corresponds to type equals work as requested and uh the email stock count this is probably a bad example i should have said two or more because the example would be that it assumes that there's two or three email addresses and the count would reflect the number of actual email addresses available uh so the client knows that there is more um that's not meant to reflect uh uh the count of of items returned that wouldn't be that useful um so bad example on my part but the intent here is that emails.count"
  },
  {
    "startTime": "01:18:00",
    "text": "would would indicate the number of values that are actually available so next slide so if i wanted to do multi-value paging uh and as i mentioned the term might not be the best uh because we're confusing it with resource results paging in this case we're doing members type equals group and count equals five and start index is one so if i had a type of group in other words a group within a group i want to know the first five members where the type equals group and we return that value so i don't have an example for this but that would be how you would specify a range in this case and it just follows the same pattern we've used for resource paging we can now use in the attributes parameter next slide so um the spec is fairly straightforward um some things to clean up is whether you want to have that count of values that are actually available i have to update and revise security and privacy considerations because privacy considerations is now a new thing so of course those have to be added and so if it became a working group document i would actually put that in as the uh in the draft uh as the as it gets adopted i do however think it's just it's since you're further restricting information um within the skim protocol spec you're actually narrowing uh the exposure information so i do think that these will be relatively straightforward and they'll follow the same security and privacy considerations"
  },
  {
    "startTime": "01:20:02",
    "text": "that rfc 7644 has we're not introducing any new exposures here pam you're in the queue question when you say awaiting tentative agreement on extension mechanism is that agreement from this group or agreement from someone else you know i was just looking at that or going i don't remember what was referring to so um were you thinking maybe that it would get folded into an extension draft oh yes um yes uh i think that was yeah that's where i was going was uh depending on where the working group is going with if you if we're doing a skim v2 bis or something like that then there's no need for this to be a separate rfc i would support rolling it in with uh an enhanced skin draft um if we're just uh moving skim as it is 7644 um if we're moving 7644 on to its next phase of formalization uh then we couldn't really add this new feature indirectly it would have to remain an extension draft so that's probably uh the biggest discussion is what's the process for moving this forward do we roll it into the core spec somehow because we're updating the course back or do we leave it as a separate enhancement so i may be hearing you volunteering to be an editor for the core spec as well"
  },
  {
    "startTime": "01:22:00",
    "text": "phil just putting it out there i'll contribute this part sounds good i don't think we had volunteers for for the course next yet so that's still under discussion so danny on the chat says he's interested in this work um so what we can do phil is communicate over the main list and check on interest on this body of work and then also then discuss where we include this body of work how's that yeah yeah yeah and that's another reason why i didn't want to do all the final uh the final security consideration stuff because it really depends on where we roll it next so um and i'm flexible as the author i um i don't know if it's useful to just say um for the process wise for the group to adopt it knowing that its final disposition is not known um but i i'm wondering if it helps engage i would like to see enough people show interest in it before we take it further and be sure of that which is the normal process so right right so um so so i can say uh my colleague at oracle greg wilson who who i was hoping could be here today"
  },
  {
    "startTime": "01:24:00",
    "text": "did say that oracle intends to to implement it shortly okay i'm just writing down as an action item for myself to to put that call for interest already well you guys are doing great and sticking to the the time allocations if there's no other comments or feedback we can switch over to danny thank you fellain i'm glad that you're you're back with your weekend video thanks me too i was not wanting to talk about that stuff you're interested all right i mean but i i uh i haven't read the draft actually so uh there's a strong difference between the two um uh yeah so i i've written two different uh drafts uh the drafts themselves are sort of rough this is my first go around writing uh you know internet draft but um there's some like problems or you know opportunities for betterment of uh of the standard that i've seen working in the sort of the the sas like skim space the cloud skin space um that i i thought could be solved with uh some fairly simple extensions to add new resources uh next five please uh so the first draft is on a concept that i've tried to title uh verified domains um and in the cloud there's uh you know a lot of different services particularly you know like email providers anything with"
  },
  {
    "startTime": "01:26:01",
    "text": "like a hint of security to it um they uh they they like to require that ownership of uh domain name so you know at contoso.com uh is uh verified before you can add it to your uh your sas tenant uh and that's to you know obviously for uh prevent impersonation that sort of thing like me as an individual um without proper proof i shouldn't be able to go and register you know with uh with google and set up mail for them uh so uh obviously you know there's other things dns stop a lot of these things but um like you know mail routing but uh so the the problem that comes into play here is when a skim client is uh in you know the cloud world is trying to uh provision a large set of users to uh into a uh into the the skim service so let's say it's an email provider or something of that sort um or uh any collaboration platform uh the username in many cases ends up following that userat domain.com format um and what is currently undetectable based on the skim standard is hey what format of name does the skim service require because some just do a simple you know it might be danny and some might be you know danny domain.com um and so being able to determine that is helpful but then also knowing uh for any instances where that you know user domain.com format is being used uh is the the right-hand side of that the domain.com part is there some sort of"
  },
  {
    "startTime": "01:28:00",
    "text": "verification mechanism in place uh because if there is then what happens is if the client has uh you know data coming into it that doesn't align with what's allowed on the uh on this given service provider the client will send uh requests that fail uh if i try to you know create a user using a domain suffix that i have not proven ownership of in that collaboration platform uh it will fail and that's a it's an unnecessary use of resources for both the client and the service provider uh and it's something that's easily you know detectable and avoidable or it should be um so the the the entire idea of this draft is to add a slash verified domains endpoint so that uh so that any sort of skim client interacting with the service writer can read the list of allowed domains as well as some service writer config stuff to see whether or not uh you know this whole uh draft has been implemented um and that will allow the client to act intelligently and uh avoid sending requests that will obviously fail uh next slide please uh so yeah the two key components uh we have the verified domains resource i just mentioned that uh so i've written this uh with it only being read only so only http get uh there's some interest out there uh with parties that i've talked to about uh certain sas platforms uh having an option to trust domain verification from uh major idps that are connected to them uh i left that completely to the side i think that's probably a separate problem to be solved or aiming you know an extension to an extension or just a completely you know separate draft uh because there's a lot of security considerations there uh how do you stop a bad actor from uh trying to impersonate the you know a"
  },
  {
    "startTime": "01:30:01",
    "text": "trusted uh skim client uh from the you know trusted from the perspective of the the service provider and i don't have the security background to write that so um and then we have the service writer config extension just to advertise uh is it available and a couple of uh key you know things of is this specific thing uh you know enabled or not uh next slide please uh so a quick run through the schema of the verified domain object uh so we have a domain name so fairly straightforward it's a string containing uh at least the second level domain and top level domain so that would be you know domain.com of the verified domain uh subdomains uh are supported as well so that would be you know x dot domain.com uh and you know uh recursively i think it's the right word uh down as well so if you don't want you know a.b.domain.com that would also be allowed uh there's then a boolean that says allow subdomains uh which is to really just advertise actually um about that piece uh that we just that i was just uh talking about the of sub domains uh there are instances where um there's uh a single organization may have many instances of a uh like a cloud platform in play it may be split by you know region by uh organization inside of the company uh there's you know a whole bunch of different ways that you can split up your user base right um and so ownership of the top level domain let's say domain.com doesn't necessarily mean that all possible subdomains you know infinitely under that should be allowed as well um at least you know at least it should be an option to say uh you know owning having domain.com verified on your tenant does not allow you to also have you know"
  },
  {
    "startTime": "01:32:01",
    "text": "a.domain.com it only gives you that top down you know that top level or whatever is explicitly returned rather than anything under it as well uh that way if you have uh you know north america in in one sas environment europe and another apac and another um you they're all separated uh and ownership of the top level domain doesn't you know create problems uh if it doesn't actually grant the full set of uh subdomains under it uh and then the the last attribute in the schema um at least outside of some core attributes like id would be uh the verified date uh this one's optional uh it's you know an informational piece to know how long or you know when was the domain verified in this service um so yeah for use cases where it's uh where it's valuable uh next slide please uh here's a quick run through of the service router config so there's a like a top level boolean of just supported uh is is the verified domains extension uh implemented uh there's then a uh complex uh attribute of uh username properties and it has two sub attributes uh and i'm not sure if rfc 5321 is the right one to call so you know anybody want to correct me go for it um but one is to say does the username follow that userat domain.com format uh and then the second one is if it accepts that domain.com format rather if it requires that it is the domain suffix required to be verified so uh this is to allow a skim client to sort of programmatically or automatically figure out that it needs to act intelligently here and not and you know any possible value for username isn't acceptable uh and then uh the last attribute and service data config is emails verified domain required and that's essentially the same as that second sub bullet point on username"
  },
  {
    "startTime": "01:34:00",
    "text": "properties uh this game standard says that uh you know like 76 43 and 44 already calls out that the emails dot value attribute uh needs to be in that rsc 5321 format so it didn't make sense to to make it complex and have advertised because it should always be true um but the other those two are essentially to say both for username and for emails uh you know two separate attributes uh do these require that the domain suffix on the username or email value do they need to be verified with the service writer next slide please um so here are some open questions one i just mentioned is 5321 the correct rc 2.2 for that format um i you know took a stab at it um i'm sure there'll be more revisions of this draft before we try to you know if we ever try to uh move it towards adoption um if i'm wrong please let me know um for the last subdomains thing uh is the purpose of it clear uh should that be moved to optional and then guidance provided uh specifying that the value if not provided is assumed to be true so if you don't say that sub-domains are not allowed just it's assumed that they are um i already sort of walked through the use case of that uh verbally uh and then i had a little bit of trouble when i was writing the draft trying to get like clear concise language defining things like uh a domain uh i was i think i used the term like dns domain something like that um anybody who reviews this if you have feedback on how i can make uh any of the wording clear please i would love to talk with you um yeah and uh that that's i think about it for for this uh draft if you could uh move to the next slide please and uh if anybody has questions at any time just join the queue um pam just joined the queue"
  },
  {
    "startTime": "01:36:01",
    "text": "um do you see a need for a use case where um infected the domain or the you know the owner would want to define say three allowed subdomains the boolean in this case basically says all or none do you see a case where you would want to actually specify yes but i think that's achievable with the current draft uh so the the boolean would be if if i have uh you know can uh i guess uh and and maybe the wording in the draft needs to be refined but uh the the idea at least was that uh that it's to say are subdomains of the values returned allowed uh so if uh you know domain.com is what's returned uh and you know all sub domains are not allowed then you should only you know you would say no allow subdomains uh false and this is on a per resource return so every domain return would have its own value of for allow sub-domains but the uh the service writers are good uh the the service writer um could alternatively just uh return the three subdomains so if it was you know a.domain.com b dot domain c dot domain it could return the three sub domains and uh explicitly just these are the subdomains that are allowed i uh so essentially what that does is allows uh or prevents cascading subdomain assumptions right okay i get it yeah so if if it's everything you can just do like domain.com and say allow subdomains and they get everything underneath uh if it's specific subdomains then uh rather than listing the topleveldomain.com you can"
  },
  {
    "startTime": "01:38:00",
    "text": "just list or return back uh the subdomain.top you know uh.whatever.com uh in a list of whatever the the allowed ones are okay um and so yeah the the second draft um sort of aims to solve that same general like sassy problem of uh clients interacting with skim service providers want to know uh like they want to be able to act intelligently and not waste time calculating requests that are going to fail and so the discoverability of information uh relevant to whether or not a request fails is important in my opinion um and so in this case uh i'm i wrote a a draft jointly covering uh adding two new resources uh for roles and entitlements and these are meant to mirror uh acceptable values for uh the user resource object for the the roles and entitlements attributes in the the core schema um so discovery of the acceptable values uh allows us to not send uh as as the client it allows the client to not send uh an invalid request and by you know pulling that list back you can know okay these are the accepted values anything else won't work um and then the ability to discover uh roles and entitlements uh and what values are allowed um because they're um this draft is going to uh go into uh returning them as complex objects so you know both value and display it also then gives the clients a little more flexibility uh in helping the uh like whatever whoever's configuring it to uh assign the the roles or entitlements inside of the client so that uh they can get the correct values on the correct objects in the service provider uh so the the end state of that being a client could go and read"
  },
  {
    "startTime": "01:40:00",
    "text": "uh you know they could do a get on just the base of slash roles or flash entitlements get a full list of uh the available values back and then represent them in a ui somewhere and allow them to be uh assigned to uh other resources as appropriate uh just so there could be like a direct mapping of uh you know of you know these objects get this role or what not uh next slide please um yeah so the key components slash roles slash entitlements and a servicewriter config to announce uh what is available uh next slide please uh the schema i designed it to mostly mimic the sub-attributes of the user resources uh like roles or entitlements attributes so for both roles and entitlements since they share the same complex sub-attributes um the the resources proposed here would have value display and type which all originate from the sub attributes on the user object uh as well as one new attribute uh specific to this uh draft which is enabled uh which allows the the service writer to announce that this role or entitlement exists but is not currently in a state that can be used uh next slide please uh so here is an example of service writer uh this is mirrored for entitlements so you can just sort of uh you know replace all for the word roles with entitlements and i i think it applies um so uh it's a complex value for uh you know for roles inside the service config uh enabled is this uh is this uh feature added so we have an enabled for roles and enabled for entitlements uh are multiple roles supported uh some service providers only allow a single"
  },
  {
    "startTime": "01:42:01",
    "text": "value for roles uh whereas some allow multiple so uh since the standard uh today doesn't have an easy way to determine that that i'm aware of uh why not include it here um and then additional just advertisement of what does the service writer support uh the the 7643 uh says that uh these sub attributes on roles are uh optional so primary and type we um we're allowing the service provider to advertise whether or not they support them and all this is just sort of adding discoverability around these for the client uh to know how best to interact with the service writer that way if they don't support type or they don't support primary there's no sense in calculating them and including them in the request next slide please so open questions on these uh how widely adopted is the type sub attribute for roles and entitlements um i in my own experience which is only one person uh i've seen implementation of primary of value and of display i i'm not sure if i've seen implementation of type used for roles or entitlements uh so i'm very curious just on uh what implementations are out there uh and this raises questions uh should be considered uh like if we were to include discoverability of available types because the uh 7643 does not list any canonical values for uh for type for uh roles or entitlements should type be advertised uh should the values that are allowed for type be advertised uh at sort of a a global level so perhaps in servicewriter config or should the available types be advertised on a per role or entitlement value level um and then adding just sort of extra questions here even though they're not all relevant to"
  },
  {
    "startTime": "01:44:01",
    "text": "this draft specifically has there been any implementation of type for roles or entitlements uh should it be should it remain in the core theme adopt if uh and this goes back to the question that uh that phil had raised earlier uh if we're just sort of you know uh giving a once-over on 76.40 to 43-44 and uh sort of uh trying to push it forward to like a a real standard versus proposed um then we probably can't make that change but if we're going towards a new rfc with some major changes you know that sort of thing it i think it's a worthwhile question of has there been any implementation of this and as you know like is there a value in it being there um and then uh there's a question that uh i i now have floating around uh based on a previous conversation i had with phil uh should this be a standalone extension or get merged in the course fema docs uh this again falls to are we just you know tidying up the existing ones or going uh hard on you know making a new one um i i think from sort of an ease of like access thing and the timelines of how soon can we improve this the standalone draft makes sense in my opinion uh and potentially it could always be obsoleted later and moved into uh if we have you know a new rfc for skim 3.0 or whatever uh it could be absolutely didn't move into that into uh into it then but um i'm interested to hear any other perspectives as well uh i believe that is the last slide it is so we have time for one question no comments or feedback"
  },
  {
    "startTime": "01:46:03",
    "text": "right i'm glad you put the uh the question at the end danny because that's what i was gonna ask so it seems again much to what we did with phil's draft what we can do is on the mail list ask for interest um on the actual topics of the two drafts before we can sort out whether they become stand-alone drafts or they become part of the core schema right right okay well uh without any questions i believe it's back to you nancy yes i'm just making notes for myself all right thank you danny all right so we're back to procedural stuff um let me worry there for a moment all right so thank you everyone for putting forward draft proposed concepts i will say so with that in mind we talked about um you know putting proposals together that can serve as documents that we can adopt um to move forward so there was a question on the list about how we could move forward with some of the tools we talked about it at the virtual interim um informal session a couple of weeks ago and i brought up the notion of using github a lot of the working groups at the ietf um use that as a way of openly sharing the work um that the"
  },
  {
    "startTime": "01:48:01",
    "text": "working group the documents that the working group is is focused on um it also allows us to have that version control but more importantly for myself and the authors and editors of the drafts is that we can interactively and on at live um do the issue tracking issue tracking suggestions and pull requests if you will um the itf has provided guidance i've put the link in here rfc 8874 there's a tutorial there as well and so as chairs what we can do is provide a skim working group repository there um typically what we do there though is that we only include the documents that are adopted not the ones that are proposed potentially i could create a sub-repo um that are for proposed um but i wanted to to bring that up to you guys as we work through consensus so my proposal is going to be that we use github the other comment i wanted to make here is for communication channels and that was the other thing that we discussed and i was going to note details here in slack but as it turns out the ietf doesn't really have an official account for slack that we could use so we'd have to ask the question there for a more interactive communication style there so that said independent of the interactive communication channel that being slack we officially will run we meaning the chairs we'll officially"
  },
  {
    "startTime": "01:50:00",
    "text": "run the consensus calls if you will through the skim mail list so i still encourage everyone to use that mail list for any issues questions topics that we want to raise and also pay attention there as whatever decisions we may make even in these plenary sessions they will get confirmed on the mail list so i will give a minute or two uh to see if there are any comments or feedback first on the github you guys are very quiet danny not github uh would it just be like people submit drafts to the itf or is it all just like decentralized well you you still have to submit the working group well all the drafts whether proposal or working groups they do have to be submitted through the ietf process but as you're working on the drafts and as we provide comments and create issues that we want to address in the drafts those we can track through github so the ietf does have an issue tracker but i think most everyone today uses other mechanisms in the other working groups that i chair we we use github and that's where we track the issues a combination of um of the github as well as on the mail list um so what i'm doing right now as i'm seeing people put votes on the chat"
  },
  {
    "startTime": "01:52:01",
    "text": "um i've put so on the um on the meet echo you'll see i've started a poll to see if we can get consensus on using github as our repo so there's a [Music] raise your hand for yes don't raise your hand for no oh i have all right i think we have unanimous consensus i'll give it 10 more seconds so danny does that answer your question yeah like it was already clear that um the like final steps would be submitting but uh it's more like it answered the question i was more talking just about the uh like before their their fully baked uh like you know collaborative review and yes a way to have a uh decentralized uh a more centralized way to uh to collect all these drafts before they're fully baked correct yeah and thank you roman he you put in the link oh go ahead barry i just said that when you use when when a working group uses github it also has to figure out what the uh pace for posting internet drafts to the data tracker is and so you use github for the development of the document but still periodically post drafts throughout the process when you get to a point where you think it's solid enough that um a wider community might want to be looking at it surprising thank you"
  },
  {
    "startTime": "01:54:01",
    "text": "yeah all right so we we seem to have unanimous consensus everybody's voted for github so thank you everyone for that um come back to no i didn't want to stop okay so coming back okay so we've already um put the question for the repo so i'll go ahead and and create the github whenever i can get my laptop back and running um the second question is prior to us becoming a working group thank you pam for running the bi-weekly um informal meetings and i would still encourage that now it gets to the question of whether as a working group we want to have virtual interims at all and if we do whether we want to run them informally meaning as we need it or whether we want to run it to a cadence of either every two weeks or every four weeks so while i create the poll um if anybody has comments or feedback please do so now okay i've done the poll before but um i thought i could do multiple choice"
  },
  {
    "startTime": "01:56:05",
    "text": "so i guess we'll we'll first ask the question go ahead pam i can't change the question so um the first question is yeah i'm trying to describe the question too so i'm sorry um i think i would love to see us do virtuals just because a it helps us get everybody's point of view into the dock and i think it also just raises engagement okay yeah so far i've got eight people responding to the poll positively to yes we want to continue with virtual interims and so my next question rather than me having a poll since i can't do multiple um does the group feel um so honestly from my being chair perspective i could probably commit to doing them on a monthly cadence um but want to hear feedback as to whether there would be objections to monthly pam i didn't take you off the cue so don't know if you have um i would love i think that's fine plus one for me and i'm and i'm really glad that you can run them i think it's better for for the official chair to run them for sure i don't know about that pam but thank you also i'm going to add my vote to the last poll because i had to dismiss it to get on the to unmute my mic so i couldn't respond no okay um that's right i mean we we've got you know um a good amount of interest there"
  },
  {
    "startTime": "01:58:02",
    "text": "so rather than me running a poll i'll just have people speak up if there are any objections for us to start running a monthly cadence and i can do a doodle poll to see times for those as well okay this actually went faster than i thought it would um are there any orders other orders of business that we need to discuss we actually have two minutes left okay so i will raise one um janelle and danny talked about the paper cuts and the things that we want to address as we evolve the use we've already covered the use cases the schema and the protocol um and danny and phil you provided some of the work that you'd like to see get addressed can i get someone i mean phil i was kind of volunteering you to take the pen on a proposal but perhaps i'll take it up to the working group mail list as well it would be good if we can start discussing the content which we have a start of but also getting volunteers to take the pen basically to be editors for these drafts thanks danny so are you volunteering for both the scheme and the protocol uh yes okay thanks all right"
  },
  {
    "startTime": "02:00:00",
    "text": "all right danny and janelle thank you for that um anything else that we need to cover pam thank you so much so much for for being our note taker i think we are now out of time i thank you everyone um let's continue the dialogue sorry go ahead nope just was also going to say thanks everybody ah yes and uh i'll probably start a doodle poll to find a day in time recurring day and time in which we can do the virtual oh and thank you paul as well i just wanted to jump in here to congratulate everyone on a successful launch here i think we had a smooth charting process i appreciate kind of everyone's kind of feedback and uh big thank you to barry and nancy kind of with their leadership to get us here to our first working group meeting and it sounds like we have a good plan to kick off the work excellent thank you roman thank you everyone until our next session bye everyone"
  },
  {
    "startTime": "02:02:35",
    "text": "you"
  }
]
