[
  {
    "startTime": "00:00:19",
    "text": "[Music] [Laughter] okay so can you please take your seats so this is the call backing group i\u0027m karsten bowman this is from reminisce yeah this one is a bit low so this is an IDF meeting we are on a Monday so I probably showed you do a little bit on this there are some idea rules that we are working under so if you talk about technology and know about a patent claim affecting the technology you have to tell us or you can decide to just not talk about the technology and yeah the whole point is about making progress on drafts where we hope most people have read those and they\u0027re weird views here are because Apple has destroyed the you know to a little bit so I had to convert the slides to PowerPoint and back to Kino to be able to show them so the brew sheets are going around good and we do have scribes so those people who ascribe can they raise the hand take notes nobody take notes but yes does Alex does Marco does okay good thank you so so the note well "
  },
  {
    "startTime": "00:03:30",
    "text": "applies I think I already said what\u0027s on them let\u0027s talk about the agenda we have two meetings one now and one tomorrow at the same time so today we will hover around work new blast calls are the ones that have already been done or once that will happen soon and at the end we will have a quick look at payment over cuerpos Adrian here thank you and tomorrow we will have another one of those that are done with work new class called another one that maybe is up to forward new brass code and then we will wander into less charted territory any comments on the agenda anything which are clicks okay so let\u0027s go right into the first item new which is called over TCP now this has been a neverending story we completed work last call she can March or something like that and we had a lot of brouhaha about the URI schemes so we reached an agreement finally how to handle the URI scheme problem and the current draft reflects that and also should be clearing all IES three discusses can you have a quick look where the major th well okay okay so maybe somebody else can can ever look whether yes she discusses are gone on that draft so a B approval assuming we will be in the RFC editor queue soon Omega hasn\u0027t cleared us yet okay maybe mock tomorrow there is also a dependency on a small housekeeping document hi bye WebSockets we\u0027re known because this document is assuming that the slash start well-known mechanism is defined for WebSockets but it wasn\u0027t so this document defines that and we will see we are aware that housekeeping document goes but forth over TCP itself we are pretty much done and we also spend a little bit of time on Saturday getting a few implementations together there is a pretty well cooked "
  },
  {
    "startTime": "00:06:30",
    "text": "implementation now in lip co-op so that that was a little bit our reference implementation on Saturday and there are two implementations that are in the process of being created one from Jim and one from me and we managed to go to the place where we could do a get on slash that went on at call which because of the fact that there are a few things mandatory you have to really foil you can get a get over TCP a connection is already quite some achievement so Jim wrote up the issues that we found there there is one example that isn\u0027t quite right I think - is missing on an option name and I think the only place where we probably want to think about it a little bit is what does it mean to send a request after you have sent release income over TCP we have an explicit release mechanism so one side can shut down the connection without disrupting things that the other side is trying to do at this point in time and we didn\u0027t really say very much about what it means to have sent that release and we might be more explicit about the idea that after having sent release you are not supposed to continue to use the connection as it was so that that\u0027s maybe something that the author\u0027s took for granted that is kind of obvious but it could be made explicit and also the text could be made a little bit clearer on the situation where you do a ping pong and you have a custody option in the ping but the the other side doesn\u0027t want to do a custody option in the return and there is currently no language that discusses this case and the point here is of course that the delay language that is there for the case where the custody option is present doesn\u0027t apply to this case so this is the level of issues that we have had at the hackathon we probably could address this in in a - 11 and of course the we are still waiting for the discusses to clear and Alexei has to do with evaluation whether we did the end of the comments right so maybe there are a few more small editorial things but apart from that I think we are done with it and at the "
  },
  {
    "startTime": "00:09:31",
    "text": "start of this segment I should have said that I\u0027m changing hats because I\u0027m not saying this as a chair because I\u0027m a co-author on this document sorry for not pointing this out so whether this is the original chair on this side okay any questions on discussion items on poverty\u0027s of you Tim Kari Nokia I just got a question on this I\u0027m trying to get an understanding of just timeframes right are we talking about this do we think that this is going to go into the editors queue this year yes so there is an interesting gauge that we should be working to which is the Consumer Electronics Show in Las Vegas and by that time it should be in the RFC editor queue or we get some problems so that\u0027s really the ultimate deadline and we want to have it in the queue we follow and that\u0027s what February right for what we know it\u0027s January in January okay all right thanks so it should it should be the Christmas tree okay next item okay good afternoon everyone my name is Carlos Gomez and I\u0027m going to present the last update of the draft entitled coop simple congestion control advanced also known as cocoa next please so first of all let\u0027s take a look at the status of the document so the last revision is 0-2 and the motivation for this last version is that a few months ago highness and heads up on 0-1 before initiating a working group last call so the the word the heads up was sent to the core and eCPM working groups and also to the ICC research group so after that we received two reviews one by three oh you\u0027re right just continue talking okay yeah so version two so the last update of the draft is actually aimed at addressing the comments that we received "
  },
  {
    "startTime": "00:12:31",
    "text": "in those couple of reviews and so yeah so also we expect 0-2 to be the version that would possibly be intended for working group last call so let\u0027s go through the updates in this last revision so we have one technical update which is that the impact of strong and weak estimators is now tunable that\u0027s the impact of these two estimators on the computation of the RTO as a result and it is that in the previous version of the document we we used some fixed constant weights for the contribution of the weak and strong estimators as you can see those weights were 0.25 and 0.5 however in the new revision we have two neural parameters for those weights which are the ones highlighted in red W weak and W strong which by the way have 0.25 and 0.5 as default values next please so we also have quite a number of material updates actually most of the work in this last revision has been editorial so first of all we have extended the abstract in order to explicitly indicate that the core of this specification is an RTO algorithm then in section 1 now we have a proper introduction whereas in the previous version the section was almost empty then section 3 describes the area of applicability of the document and now we explained we have added that the algorithm define being adaptive is actually intended for a wide range of network conditions in terms of different aspects such as network topology traffic load different link technologies and so on so related with that in section 4 which focuses on RTO estimation now we explained that we expect this algorithm to run in in different conditions and we expect a wide spectrum of our titties ranging from few orders of magnitude below the default RTO estimating go up which is between 2 \u0026 3 seconds and greater values than that then also in the same section we have added some some content to the discussion we had on our TT variability so previously we explained that in coop we have application processing times that contribute to the coop party T which in addition may be variable with different distributions and we explained in "
  },
  {
    "startTime": "00:15:31",
    "text": "version 0 1 that this is something that doesn\u0027t happen in TCP however now we have also added that if TCP is using the latest knowledge means there\u0027s also some contribution in that case to the RTT which also may be variable with additional delays that may be up to 200 milliseconds typically or in theory up to 500 milliseconds then another update is in the subsection that needs a discussion when we describe the measure RTO estimate that\u0027s for the 2.2 and in order to better motivate the need for the weak estimator which is quite unusual in the IDF we now explicitly explain that the weak estimator allows to update the RTO estimator when our T DS are mostly weak so recall that we carta T\u0027s are those for which the sender has run into the transmissions so this may happen for example when we have really low ceilings or when there is some congestion event that induces losses as well and we also explained that in the latter if losses are due to congestion then the the week estimator allows to update the RTO actually increase the RTO as well and this helps avoiding spears time outs reducing the rate of retries and decreasing congestion so we have also added references to the base co-op specification this is intended for readers that might not be so familiar with co-op and we have provided pointers to specific sections and also to specific parameters in several cases and on the other hand we have also extended section 7 which is it provides the security considerations and we now explain that an attack that manages to prevent packet delivery will lead to an RTO increase which may lead to a performance decrease however well this attack is not specific for cocoa or even for co-op but anyway this might be mitigated by means of network access control and if the attack is performed by means of radio jamming we are that recovery from that situation can happen in reasonable time when cocoa is used because the the week estimator increases the chances of obtaining RTD samples even when there may be a large amount of losses leading to almost only allowing to get weak RTDs finally we have also quite a number of updates regarding appendices so first of all the old appendix which was entitled aggregate congestion control has been removed from the document this was suggested by the two reviewers mentioned at the beginning "
  },
  {
    "startTime": "00:18:31",
    "text": "of the presentation and this also matches the actual intention of the authors so this has been removed and however we have added three new appendices and this is b c and d the first one appendix b provides pseudocode on how the RTO estimator date works also on how the RTO aging mechanism works and also for the variable back off factor on another appendix we have added some examples where we provide numbers on the calculations for the week our titties for the variable back of factor for aging and we also provide some explanations which try to clarify a little bit the properties of these mechanisms and finally we have added the last appendix which provides some analysis on which may be the difference of the values the difference between the values with the strong and the weak estimator well so that\u0027s all for this presentation any comments or questions I did this honest thanks for the update was really useful one question that wasn\u0027t answered from my review is when as a developer if I care about so the reason why I would want to take your document into consideration is because I don\u0027t want to have this stop-and-wait behavior that co-op over TCP provides me with the in star equal to one so Biff the advanced congestion control mechanism I can actually change that and have a value higher than one is that is that correct so customer and the congestion control doesn\u0027t take away the stop and wait behavior so it\u0027s you still have lockstep so in the request get a response and request get a response can I now have more than one an outstanding request re-imagining response no this document doesn\u0027t modify and start for example so what this document does is instead of having the static setting for the RTO in the base co-op which is between two and three seconds now we compute the RTO on the basis of RTD samples okay so um that leads to my real question is I think it would be nice to indicate on at what point a developer shoe should actually move away from co-op plus that type of extension took over UDP to a model a co-op over TCP like co-op over DCP was motivated by a fired rubber or firewall "
  },
  {
    "startTime": "00:21:31",
    "text": "traversal but there may be other motivations as well that relate to the congestion control or specifically to this behavior of sending multiple requests which is sometimes also annoying just does that make sense what I\u0027m saying actually you you have written the text for that so the introduction for Cordova TCP ya know provides information to this question it provides background for the coop of a DCP but it yes provide the information on at what point should I consider not going for this document but then for something more like I don\u0027t understand what the complexity differences neither the albick document on DCP implementation guidance nor this document nor any other document provides me that type of judgment I think the complexity in the complex city versus the benefits isn\u0027t an too obvious to me and maybe not to developers either maybe it\u0027s obvious to you but yeah so I don\u0027t remember the details but I think we put some text in the Coco draft that discusses what what the incremental complexity is with respect to the base congestion control but this is the coatrack yes yeah and I\u0027ve read the Coco draft and it wasn\u0027t India but maybe we got stripped out let\u0027s check that okay and the next question is when do you actually go through TCP which is a bigger step and that of course depends on on the complexity that your specific platform needs to run TCP it also depends on your application whether that actually benefits from an aggressive transport protocol so in some sense or environments it\u0027s actually a benefit to not have an aggressive transport protocol yeah fully understand that but and that big TCP guidance document gives me the impression that TCP is also highly tuneable and there\u0027s there\u0027s a lower pond as a higher bar and so I don\u0027t see what the overlap is between what is going on here - what is going on in the elevator with returns terms of users of a transport for the call and I think there could be some additional clarification of it specifically if you\u0027re not like working full-time in a transport area and I maybe you have that information written down somewhere already it would be good to add it we happen to have the author of the Eric physically document very close so maybe that\u0027s actually useful thing to add yeah yeah maybe it needs to be added there I don\u0027t know what the best place is but it would be nice to have the information somewhere yeah sounds good now what what we don\u0027t have is numbers "
  },
  {
    "startTime": "00:24:33",
    "text": "where we can say by the way implementing TCP takes you this amount of ROM space and so on oh yeah there\u0027s only at the moment ideal week document we have those numbers but however only for a subset of the implementations we are considering so let\u0027s hope we can complete the information at some point so the advice that should be in the cocoa document is that that if you have space to keep two or three variables per year plus vary where two or three formulas for every packet to send appear then you should do cocoa and not the basic congestion control help then no takers have that and we will consider now so the next step of course is doing the working class call so I managed to decide when when to do that and the idea is to make sure that\u0027s working last call is done in a way that the the transport working groups that have indicated interest and also the convention control resource a research group is in the loop of that working across coil and I think Alexei has something to say about how his end wants to handle the history process you mean my idea of asking another ID yeah I tend to ask birria to as you know person more familiar with this stuff to be the responsible lady and she did ask recently what the status of the document it was expired I said well it will be renewed and so I\u0027ll talk to her again thank you okay so barring any other comments I think we should check the the conversation we just had with Sunnis and then go forward in Glasgow okay so next one is resource directory and we have a remote presenter for that you just have to hello do you hear me yes we do thank you um my name is Christina Moses and I\u0027d like to present "
  },
  {
    "startTime": "00:27:34",
    "text": "the current status of the resource directory document and the associated resource directory DNS SD linking parts I go I\u0027ll go through the through the recent changes briefly and use them as a set up of to show where we are with the document and to ask some questions about how we can proceed there there will be a part about DNS St 2 which will be after the actual rd text a slide please one change we did since version 11 was to introduce the introduced a number of statements about what we think the RT should do which basically amounts to storing statement and storing links with the same semantics they have when they are when they are retrieved from well-known core documents and allow clients to fetch those links and query those queries that information was the same mechanisms they use when they are doing regular multicast or well-known core-based discovery an RD can also come into play when when multicast is unavailable or when there are other reasons why you don\u0027t want to get that information directly from the node dns SD is not directly here in the motivation because I\u0027ll show later that we can do everything we need for exporting to DNS st from what an RT can do if it is designed without particular consideration for our DD n SSD next slide please so what is an inner resource directory and we flashed out how this looks textually now as well the ERT contains links and the top line shows how they look like in an unco file they have a link target at the left which is evaluated to a full URI they have a link link source which is usually the the well-known core document or the the device itself and in most Katyn most common cases it\u0027s implied and has a relation or some other link attributes and attributes that describe the target so for example resource type we transfer we take those links up in the resource directory and Express and replicate them semantically which means that the serialization might look a little different for example the anchor as in the bottom line needs to be explicitly stated because the document comes from somewhere where this is not obvious but some of some things like the rail relate like the rel equals hosts can still be implied by default so Christie that they quickly mentioned because the predictor is not very sure oh great well this is great here and so "
  },
  {
    "startTime": "00:30:37",
    "text": "these are default values of the target attribute so the actual well-known core entry would just say this part here and this is default it\u0027s on the with link relation hosts and the empty anchor those are the default they use and at the point that Christian is trying to make is that this can stay at its default value but the anchor where you actually has to change because in this case it\u0027s the when on call environment that provides the device itself but in this case it\u0027s the resource directory so this has to provide the other end of the link the place where the link emanates from all right Thank You cousin if you go to the next slide please there are some other entities in the resource directory which is endpoints and groups and points is mainly what using to manage that a particular device registered there and can have some additional properties that are available for querying and groups which are aggregates of endpoints that typically share a multicast address the next slide please all these entities can be used in queries across the resource directories so you can look for as in the first example query look for groups which contain a particular node and then you get a link to that group resource to the place where the group is registered with some additional data about the group like what is its multicast address what is it is its group name is it in a particular domain you can so this is a in this image this is a this users information this queries down the the stack you can also query APIs in the next example where we are looking for and for all endpoints that are in the rooms group so this again gives us a link to one registration resource which is not particularly useful as well as a link to a courier but contains additional information in the metadata for example this has an endpoint type or what is the where is this registered from from and most importantly it contains the links which can be queried not only by querying their their attributes so for example you could have a lookup slash rest query RT is temp and get all temperature resources but you can also query all resources that reside on say n pound endpoints that are wall-mounted as in this example next slide please we we did some more changes to I won\u0027t go through every single of them but some are particularly noteworthy we\u0027ve added an information "
  },
  {
    "startTime": "00:33:37",
    "text": "model that that kind of provides the whole set up we as I\u0027ve shown on on the first slide we\u0027ve nailed down how the resolution of your eyes work so what is what is result what does need to be resolved when how our relative references are evaluated and we removed sections about how those registrations can be changed because we don\u0027t have suitable content formats for that yet so we can\u0027t we can\u0027t specify how this works anyway and we prefer to specify how the general thing works and if account if and when a content format gets along that allows simple modification or observation of collections of links which everything in the resource directory basically is then this can be added to the resource directory without further changes on the of the information model and lookup and next slide please so what are what are the the next steps we\u0027ve published version 12 document a few weeks ago next slide please we do have some changes we know about that we\u0027d like to have in a version 13 document for example registering a multicast address and fixing something about that you can actually go up and down and the in the image I have shown before in the queries but there are also slightly from some open questions especially about how next slide please especially about whether a group an endpoint registration can be included in a group even if it is not registered on the same end on the same resource directory which is really kind of doing the icing because resource directory is not originally specified to be federated but it looks like it can be without doing much on the specification side and we\u0027d also like to have some idea of how this how the specification or how this interface can evolve without breaking older implementations we invite you to join us on the issue tracker all the those open issues and also the pending ones are described there and it would be very good to have input from the working group on on those and next slide please we\u0027ve really received comprehensive reviews from Jim shot and Hannah\u0027s about the 11 document thanks for that but I think given that we\u0027d like to go for working group last foursome um it would be good to have more reviews and also to "
  },
  {
    "startTime": "00:36:37",
    "text": "get input from people who are actually implementing the resource directory so as to expound on that now is a good time to implement this stuff because we have really cleaned up the document a lot and at least for me as a co-author the situation has started that they understand what the resource directory is about and how it works so I that implement dusts can now be in the same situation and of course there are partial implementations in various environments for instance like radium terrarium uses the resource directory but only a certain subset and doing the the whole thing now seems possible and it would be nice to get more feedback honest I have a question on on the slide on a changes like there was one note about removed all methods that modify links in existing registration and I was following but this also means that if I do an initial registration if I do it in a registration would that prevent me from changing the links there or is did I misread you know you can you can do a link registration and re registration and this is currently the only way to do it and the read registration is semantically almost equivalent to dropping your registration and registering in you and this is what you can do even without explicitly dropping your registration so you can just pull to the to the directory resource again as you would do for example after a reboot when you\u0027ve forgotten that you\u0027re registered and then the Rd will accept that registration and now have an updated set of set of links and this Lea registration would that require me to resend everything again with the modified words so if I want to remove one link would have to resend everything or what I indicate that one thing yes you will have to run resend everything in that region re registration because we don\u0027t have the content formats yet that would allow you to say this is a this is a patch on that on that linked list and please remove that particular link okay so that\u0027s maybe it\u0027s something that we may need to look into a little bit because in unlikely there them at least registration interface we were hoping that we don\u0027t have to send everything again when we do every registration when the when the life time expires oh no you don\u0027t wanna live time expires um you can you can always keep your registration alive so you can just post to the to the registration resource you\u0027ve obtained but it will need to be an empty post and it can\u0027t change the links can\u0027t it can\u0027t change the links now but you can register a new with a new set of links so the important observation is that "
  },
  {
    "startTime": "00:39:39",
    "text": "right now we don\u0027t have a media type to fetch a registration so we can hold a replace it yeah we can refresh the registration registration yeah but we cannot say change the third star on the top I was hoping that in earlier versions of the document that might be presented at that time patch wasn\u0027t available so my hope was that once the patch was available never actually do different versions in their brief and without patch that we would once patches available would actually switch over to pageant allow that patch to be used also for a registration interface that sounded like obvious to me but maybe it\u0027s not so the decision was to define that patch media-type in a separate document because we don\u0027t have to hold up this for defining that media type okay I miss and and we had a pretty interesting discussion at the OCF meeting on Friday how to do that because the the the current March page document is geared up for having maps of things and and you essentially replace things in there by giving their keys but those links it\u0027s on our maps they\u0027re arrays so we we need a variation of merge patch that that grabs into an array finds an element of the array based on one of the keys in the map that is the element of the and replaces that and we have to write that that must have been a discussion after a ocf meeting it was at the gym shot I vaguely thought I actually saw that that that the map stuff existed but I wasn\u0027t paying that much attention at the time because I was having a hard time fitting either a patch but that\u0027s not actually why I stood out there one of the things that really worries me and I\u0027m not too sure I want to see the are deep actually progress until we figure out how it\u0027s supposed to interact with the new URL schemes so that we because I\u0027m not too sure you want to you if something is reachable by multiple schemes I don\u0027t know that means you end up with multiple endpoints and so forth and what that means in terms of anchors um if if you\u0027re registered um the current idea is that if you\u0027re registering with multiple your a schemes you will still have only one registration and the pending protocol negotiation document will describe how you how you add your alternative transports and how you can query them in the resource look up so that you finally get a resolved link "
  },
  {
    "startTime": "00:42:39",
    "text": "based on your preferred transport when you\u0027re querying the resource directory is that gonna make mi gonna have to heavily modify my resource directory implementation when that gets done or pretty um you will need some modification because you will need to interpret the information that is now provided in in whatever attributes that came along but the changes should be very minor they favor what\u0027s the current state of the protocol negotiation document no there was how close is it to being done because I what I hear Jim saying is that you have to treat them together and that if you haven\u0027t reviewed them both at the same time then you\u0027re skeptical that this one came whereas before that one right I think that\u0027s what you\u0027re saying Jim and so the real question is is the other one also ready for working request call here Jim are youing to put him through at the same time as I\u0027m not arguing for or against but it\u0027s how I understand you it\u0027s coming yeah so we know how ocf does this we have an existence proof edit can\u0027t be done but it still has to be done so maybe we can copy as much as possible from from the ocf solution of the ER that would be my personal preference but that discussion needs needs to be here yes and I take from the input that that\u0027s really a blocking point for finishing Rd because we need to understand that now there are two kinds of alternative transport situations there are situations where you have transports that are mostly equivalent in most of their technical parameters so one may go through a firewall the other one may not but but once it works it doesn\u0027t really make a big difference which one you use and we have other situations where we for instance combine UDP access with SMS access that\u0027s a very different situation and I think we have to make sure that we actually address both cases it might name is empty so then I go back to you to your reviews slide and yeah I think we could just proceed to the to the next slide which is which starts the part about our ddns SD before we do that a quick question who has an implementation of a resource directory at this point I mean yes "
  },
  {
    "startTime": "00:45:40",
    "text": "I mean it\u0027s partial but it\u0027s does something so who has such an implementation kind of kind of so we have two implementations that do something in the same space and californium does have one Jim has one I have an old one a student that probably needs to be fixed and I have a current one and Christian has a current one so yeah so did what I get from this is that we have enough substance here that we actually could start doing some intro plus testing we didn\u0027t get this into place in time for this hackathon but we might want to use the time between now and the next ITF to actually do a little bit of virtual interrupt testing between our implementations so how we do that we have to find out but I think it would be a good thing to start with that now okay just yes yes um so I promised that we would that I chose that DNS SD works from vrd what what what exports to DNS SD unconditional needs is some support from from the origin server so from the from the endpoint that is providing the resources to say that it wants to be exported and to provide instance names because they can\u0027t be derived from anything that is that is present in the resource directory otherwise the current document that is that that should be published about today describes this as happening from a resource directory but actually it can equivalently work from the well-known core data as well so while an exporting agent would typically piggyback on an RD it can could just as well do multicast discovery and export whatever it finds from there to DNS st how this works has not really changed since DNS st was a part of the resource directory I\u0027m showing next slide please I\u0027m showing here on the top a typical example of what it could what a resource look look up could look like in the in the Rd and the bottom half represents that information in Indian SSD so our next slide please leave the information gets gets moved around a bit but what is what is in the in the DNS SD record is you DNS SD type "
  },
  {
    "startTime": "00:48:46",
    "text": "that is derived from the resource type it is registered in the domain which is shown in green it uses the instance from from the from the link form a document as an instance name if there is a if there\u0027s a sub type to the resource type that can also be exported to the to the to DNS SD which is the proper part this is the first on half of the day of the dynasty continent the second is the mapping to the actual address which happens in a server and a text record to form the complete URL again if the if the link is not formed from from a DNS name as the authority which is shown in red here it could also be derived from data in the resource directory but then again could be derived in in any other way just as well because there just needs to be a or quad a record for the thing that the server record points to next slide please before we go so a question on the part in blue which is the Sto and so this example uses an RT value with only one dot in it there exist plenty of RT values that are registered with IANA that I have two or even three dots in them so the question is when going to DNS is there any problem because you have the underscore sto mm-hmm is there a problem if that has dots in the middle of it funny fun thing is it isn\u0027t because the way T and s SD works is it doesn\u0027t work on the on the serialization of the DNS record which usually uses a dot to separate the segment but it works on the on the actual DNS messages which have fields that are not dots delimited so there can be a dot for example in the instance name or the resource type so it sounds like no there\u0027s not a problem it can work when there\u0027s when multiple dots in the RT that comes whatever here\u0027s all right yes sounds brittle to you um I don\u0027t personally I don\u0027t like it very much but given that there already can be thoughts in the in the instance names and implementations largely support that but there is and this now brings us to the next slide still the open question of how those things should be mapped exactly because um what the issue we are having here is that for resource types there is a registry so you could register the sto dot anything resource type and there is a registry for DNS as these service types which is "
  },
  {
    "startTime": "00:51:46",
    "text": "not the same registry and which is not coordinated and most entries or many entries will not need to be in both so the question question yeah I realize I may have phrased my question slightly differently than I should have but you probably answered the question I was asking what I should have said was there exist RT values with multiple dots and here it into a sto plus a temp piece and I should have asked how do you know which dot discipline just boils down to the same thing we have an open issue about that one proposal is to say that can you go to the previous slide please if resource.type is unknown to the dns SD exporter it should not be split by any dot but it should be exported as some type coop UDP with the whole resource type of the subtype and particular as a particular s do so whoever registers a resource type can say can also register a DNS SD type and their sub types and along with those registrations provide a pattern in which by which those resource types can be converted to DNS SD types so then the DNS SD converter needs to be aware that this RT scheme is handled like this Indian Indian SSD but this information needs to come from somewhere and providing a simple pattern with the registration would be one way of handling that so Dave knowledge several times three thank you said okay I\u0027m Vic for the question slide um yeah so if we\u0027re expecting a server to know the instance name and we\u0027re trying to have the exporter make assumptions on how to derive the service name why wouldn\u0027t we just expect the server to be able to drive or state what the service name should be since we already expect it to state what the instance name would be um that\u0027s a viable suggestion and would be an alternative to having that registry I figured this might look like having not an X but an X in s with the particular service name could be done I think and might be a better option so the the objective when this was designed was to have the the expansion\u0027s attributes kind of generic so the the node that exports "
  },
  {
    "startTime": "00:54:46",
    "text": "these attributes doesn\u0027t really have to think in DNS SD terms they might be other lookup schemes that I use that generality is not needed so I think that\u0027s a good discussion Trevor yeah because it sounds like you know your resource types particularly as they start getting you know hierarchical you know sto dot whatever you may be your exporters might not know that but your server should if they if they particularly if they have to know the instance name we know that there is a strong argument that the evolution of the various parts of the system can go on and in parallel so if the device already knows about the resource drive that the exporter doesn\u0027t know about that should work the device should be forced into a weird situation there so there I think that\u0027s a good idea okay nobody else is running to the microphone so let me just as an author comment on the pace in which this document has gone on for a long time we have had essentially a little bit of progress at each eye each EF but nothing in between and if you look at the commits that on the github repository now it really has taken off and we have significant progress and we want to keep up that pace and and finish this work so again comments like like those from from tamiya that\u0027s really useful input and that would be good if you could provide us with that input so timeline to preempt a question that Jim is perfect to have not another Christmas tree but we shouldn\u0027t go on with this much longer than the London ITF I think ok thank you thank you Christian you on the engine room screen you have this really weird look because your glasses reflect the light and you have these blue glowing [Music] presentation from outer space okay Thank You Kristin so we had a video and I\u0027m sure the comic people will squander that "
  },
  {
    "startTime": "00:57:46",
    "text": "thanks and now for a presentation down to earth let\u0027s say that we\u0027ll take a little bit more time so we are going to be talking about carmine and so I\u0027m going to be giving a couple of updates since the last time so on a very macro level you can see the main drafts that are part of this package here it\u0027s a little bit offset so basically so here we have the tree main draft documents that are the yang to see bro mapping this draft and come by itself so we had some actions from the last time which were riveted drafts perform interrupts deployed asset registry like down to the straight to the point so on the update and on the review of The Drifter different drafts the yang to seaboard draft hasn\u0027t moved because one of the things that we said is these three drafts basically they\u0027re moving in as a package right the moment that we have some inter up and and that we see that everything is working weld and we do the working group last call for all the three of them so basically here we are ready for working group my last call since IGF 97 which was not three years ago unfortunately or fortunately then we have the courseid that is stable for two IDF\u0027s now and the comma which is the one that is mostly evolving for the moment so and then there are some new drafts that that have been added that are allow the whole system to be working very nicely but these are like just some extras so where are we and this is the point that we actually start talking this one works okay thanks this way I\u0027m not going to be able to I don\u0027t need to turn around always so we have existing implementations as I said since the last time we had some and right now we are really improving our implementations so we have two implementations that are proprietary implementations one is go line when you see we have two partial implementations that we had some knowledge from the last IDF and one of the goals was for this IDF to have an interrupt with at least two implementations of them and to have a hackathon so in order to produce an open-source implementation or at least put the basis of an open-source implementation because it always goes through the open source so we needed to scale back a little bit on our initial expectations because some of most of the key people that are were not able to come here to Singapore and so we needed to scale back on this "
  },
  {
    "startTime": "01:00:47",
    "text": "but we did our best so I\u0027m here to present what is our best at this point well after several changes and many many discussions we actually managed to do a virtual Interop over the internet between two implementations so the first point here is that one of the implementations actually manages to run a full calm eye with a subset of the functions that are fetch patch and post for our pcs running on ipv6 the other one is full but you know can interoperate with itself so it\u0027s not much enough interoperability between two different implementations so the point that we really did was to say okay we need to have at least these implementations to be able to show that they are running so we have fetch which is the basic of everything where you can go and can really retrieve information from the server so here the client and you can retrieve information from the server so the type of request that was so we needed to have a use case a test case so we was using the module ITF system and more specifically we were just trying to get the system date right what is the current time so we have the seat file that is generated for this with the seed allocation that allows you to actually build the whole kamae system up and through this these are the the first results that we have so we are able to okay do this so I we are able to fetch single values fetch a container fetch two values in one single request that are announced two separate values whenever we try so we found some issues with some of the implementation so we are now it\u0027s like minor bugs we are fixing this and with this we actually managed to validate the yang to see bor string mapping derive types container representations and we have also validated the delta encoding and having Delta euro like Delta compared to the URI that is given in the fetch request so this is a first result of a first interoperability like an a basic use case that is out there from two implementations independently mutations and that is pretty good given the time that we had to you know to do this since the last IGF we are quite happy about this of course our goal is to go and to do much more until the next idea next point so yeah but before I go to this I would like to share some of the lessons learned through this through this interrupt so the first thing is that ITF system may may not may not be the may not be the easiest module to use as an interoperability basis and one of the "
  },
  {
    "startTime": "01:03:48",
    "text": "things is basically you know we want to test everything we want to say okay is there this is an integer this is a string this is slow this is you know we want to be able to have like a basics all the things that can be presented present in a yang module we want to be able to but to go there and do like fetches and patches and and have all these nice stuff that we can have with them and gets and puts so and just so that we have like this unitary tests and that we can do one against the other so one of the things that we are starting to do and this is starting again right now so we are ramping up we had so to give you a short idea of the timeline that we had until the past IGF we had be weekly meetings so we were managed to advance pretty well from since the last IDF to this one it was like summer and all these kind of different issues that that happened so we were less we didn\u0027t manage to have this beautiful virtuous meetings and right now we are restarting them again so we are restarting two weeks from now in order to define this interoperability suit and to be able to have it ready for the hackathon in ITF 101 so that\u0027s the first issue that we would like to address is to have this basic young modules in order to test this functionality on the protocol level and here this is a question also to have maybe net mod have already established such a baseline yang modules for testing I\u0027m not aware but now I see Eric saying no so no so maybe it is something that we could contribute also to the network community so that\u0027s the first point the second point is that you know these famous Delta encodings that are super efficient and are really really nice and we really do like them and one of the things is that and with Andy we were he was also saying this in the past it could be a little bit tedious when we are trying to debug complex requests and complex queries that have different you know you have several sub trees and and you could get a little bit lost in case you you\u0027re just so lonely watching that watching the payload and of course with with the right tools this is not a problem but we are not there yet having the full tools that we have all the you know the burgers that keep everything in place so one of the things is that we are really would like to propose is to have this option in the server and or the client that can say okay well you know I would like to disable for this session this the Delta encodings and then we go and tag the sits with seaport actor 39 that has been allocated it\u0027s an identifier and it\u0027s to just to indicate hey this is the sit it is not the Delta said it is it is "
  },
  {
    "startTime": "01:06:49",
    "text": "directly to sit and the same the simplest thing in this is that you know you in your code you just need to whenever the code is parsing it you know they don\u0027t need to do anything special they are just doing Delta Delta oh that\u0027s not a delta so I\u0027ll just take the value as it is and I continue so it is a pretty straightforward solution it helps debugging and you know you run your server in advance in the bug environment you debug and then whenever you decide that it\u0027s good well it is able it by reaction to this is you can do that but don\u0027t kill anyone I mean you really should fix up your to it store handle this it\u0027s not that hard and I think doing this this take 39 heck is about the same amount of work as fixing up those two is so why don\u0027t just fix up those two it\u0027s and do the right thing so I think one of the things is good when we want to have an interrupt is to I mean we can say okay we\u0027re going to do this dirty hack but if you can have it on your interrupts that would be really cool so please everyone hack you\u0027re good and then you know just the hack it so yeah somehow III agree with this but it\u0027s it is a very neat solution I don\u0027t see any back and any any any problem with it like you a long-term problem that could appear but the long-term problem is that this stuff is in production systems don\u0027t do that okay even if it appears in production system it C it is going to waste - let\u0027s say bandwidth from although it\u0027s going to jeopardize interoperability because I will never implement it I mean it\u0027s way too easy to fix that words to show the right values I mean you don\u0027t really want to see the city anyway you want to see the actual identifier so you need to have a tool to do that anyway so I think that that\u0027s yeah you you\u0027re trying to run a marathon on crutches and and that that\u0027s not going to work very well I honest probably agrees with me so Peter meet the famous cock I won\u0027t be very original I support Carson\u0027s remark fully I don\u0027t think he should add complexity to reduce complexity sorry ok so that\u0027s a point point taken that\u0027s improved so another point that we had from this first interrupt was that actually we have this minimal set that is pretty straight forward and that allows us to have the full functionality "
  },
  {
    "startTime": "01:09:49",
    "text": "of comma and the one of the points that we\u0027d like to do to just state there is that it is possible to have coming minimal plus comma extended and let\u0027s say call my minimum is fetch patch and post for the are pieces and then we can have a very simplified document and you have a second document or like two sections where the second section builds up upon on the first one and then we say okay you know if you want to do a get put post in all these nice operations then you know this gets transferred to patch this or fetch this so this way we can like really go with that with comma minimal come I extend it and you know we basically it boils down to this like we have these implementations and we will be very happy to have other people having different implementations but until we have this is the only thing that we\u0027ll be able to interrupt so that\u0027s about the implementation part and the lessons taken now on the hackathon well on the hackathon we do we did start an implementation so we started with with a specific specific module in mind because we wanted to have a specific use case so in this case we started with the shake context compression so we expressed shake in yang and then we started you know like building the whole the whole system around it I can declare partial success so yeah we started it we have the yang module and everything is working and then a partial failure because actually I made some maybe not the best choices in the use of the in the choice of the Python tools that were out there and so we reached or yeah we reach to some point where we understood that the the choices of the basic libraries that we chose for Yang actually makes it super difficult to make the Seabourn encoding well so I need to go back a step this was after discussion with the medmont team and basically rebase the development of the of this part with ydk which is the yang development kit which based on your yang file produces Python code so this is the only thing that needs to be done so I was really hoping that we\u0027ll be able today to come and say hey we have this working baseline implementation it needs you know it\u0027s interrupts with these other parts but I think that we should like step back a little bit and prepare for for the next for the official hackathon that will take place at the ITF 101 and where most of the people that are actually quite active and which and who are working a lot at in come on come I will be there "
  },
  {
    "startTime": "01:12:51",
    "text": "so then will be will be really around the table and really really be able to advance with this so that\u0027s about the hackathon and so as I said next steps be weekly meetings from now on that will ensure that we have the full interrupts in London with the fetchin patch so something like as I said to call my minimum and have the hackathon also and prepared the open-source implementation from their own so these are the next steps and on the yang to see board documents I get the feeling that we will not be introducing the option 39 it looks so cool it\u0027s off some problems and the option worst was there so okay so that one is done and on the Kamiya documents what we could what we propose to do so this is like an option and this is something I would like to hear the working group if you have any opinion on this would you like to see how my minimal and come I extended if this will give come I minimal like it\u0027s just going to be like removing a lot of text of the current document simplifying some stuff and having three basic operations and then having like maybe a second section that does this or a second document that that does the firt that that you is the first the current document proudly shows all those best verbs that we have get until e8 and post and in my chest it shows how to to use them with comai so this is all wonderful but it\u0027s a lot of complexity I don\u0027t know how many media types we are generating there and it\u0027s not really solving a big problem so maybe this minimal form is a good thing but maybe another way to look at this is it might make sense to edge catch as as a third message that we want to support but that\u0027s it so we don\u0027t really want to do the other things if you want to modify something it\u0027s not really a very onerous to do a batch and only if you just want to get at a single item may be supporting get as the third message might make sense and we wouldn\u0027t have two different versions two different he said which was always an apology so I really yeah that that\u0027s something that "
  },
  {
    "startTime": "01:15:52",
    "text": "we really looked at it and we discussed about it and the thing is that in get you have a URI so if it\u0027s simply having a gear to sit so you can forget and you want to get one item that is identified by one sit it\u0027s super easy there\u0027s no problem with this the question is if you want to do a get on an item that is part of a list okay but then what\u0027s I mean the then the problem is that your get is super partial like you can only get some some items like a super subset of the thing so you need to say okay did part of the things in my yang module I can do it I can obtain I can get through a get and parts I cannot maybe it could make sense if you want to say okay you know I can only get like the first level of the things like if I have a first level element like if it\u0027s a container I can do a get and I\u0027ll get the whole stuff if it\u0027s an item I can get a single leaf I can get this leaf but if I want to get like the first item of a container maybe now this one I could get also but you know if I have a list then I cannot I will do a get and I will get the whole list I cannot say okay I want this item of this list the examples actually they get so I just wanted to throw this in the room that maybe we don\u0027t want to do a minimal and an extended but we won\u0027t simply do the right thing and that may be exactly fetch and match odd may be fetching fetch plus more method like hmm but looks let\u0027s look through the examples and see what actually makes sense we don\u0027t have to support all of risk just because it\u0027s there okay sounds reasonable I try to do this to do the to do the exercise to provide how would it look like without the other methods and if we only have the get method some I mean we have it working even now so first it\u0027s a it\u0027s a question of text editing so that\u0027s on Carmi and now on Sid so cities the identifiers that are used income I and here just a short reminder so ass it is simply a 64-bit number that\u0027s of course it is a 64-bit but in because it\u0027s expressed in C bar it can be on one byte to buy it\u0027s four bytes and and so forth so it\u0027s pretty dynamic it is a file so you have like a young schema that represents the reason that that map\u0027s the reason or C bar if you want and then you have the lifecycle of a model and you have allocation policies so you have a two-tire allocation policy that you have the first one is managed by Ayana it\u0027s called the mega range registry and you know Ayana allocates chunks of 1 million sits and then we have a second "
  },
  {
    "startTime": "01:18:52",
    "text": "level registry that people go and you know can much more actively allocate range sub-ranges so since the last time we have these three that are solved and this one that was somehow you know we were not here is it really solved are there any problems so we discussed again and again with with I Anna we discussed also it so many people and I said ok you know we should not be just keeping the working group last call for this these are things that could be solved when it comes to Ayana and then we say ok well there is this detail or this detail that should be will be changed but generally the document is good so that\u0027s that it\u0027s good we have not have not changed anything so right now the next thing is okay so what about it yeah Peter the founder stock a very simple question bomb of the sheet generation tool for the moment it\u0027s difficult to know where it is will be part of the ITF useful tools really help yes thank you Peter so that\u0027s actually an excellent question so you know so whenever you have a yank file you have a tool to generate the seed files of the correspondence it\u0027s a tool that\u0027s like a plugin for PN so it\u0027s like it\u0027s the super standard thing that people use for yang and it\u0027s just like a plugin it is not yet in the main branch but it has been stable for a long time now so what we did was basically we put it we made a web interface to around it we wrapped it up and it works and since this weekend so this was like the partial hackathon that we had around some several virtual places we have also set up the seed registry so this is the first seed registry that is that is out there that is in some kind of a minimum value of MVP Mode minimum well protected so we will start operating it a little bit illegally just to see how it goes right in the second million of the of the sit registry because there is for the moment there is no megasuck mega range its registry Ayana has not created this so we cannot legally obtain like 1 million blocks to start to play with so what we are going to do is we are going to say hey we pretend as if we have this thing by the time the last were the working group last call passes and Ayana goes all through the whole process and the mega range registry is created but in the meantime we will get the feeling and people will start using it and hopefully you know it will just get translated at the moment everything is in place we will just say ok yeah it\u0027s there so we have this too but the single context that\u0027s the normal thing to do when you write a document in "
  },
  {
    "startTime": "01:21:52",
    "text": "creating our in a registry you provide an initial population of that registry so in this case you would say the the 1 M 2 to M range is taking up by this okay yeah so so doesn\u0027t know what\u0027s going to do and so this is the DCT interface so we have so this is the best the basic the login page so this was this has been existing for like a couple of months now so you can come and then you can click on login all this stuff so you come in you register so you fill in some information about yourself like from which country and so forth we have a super secure way of actually the thinking is your computer or not so we\u0027re using reCAPTCHA and then once you have signed up you can log in and then if when you have logged in you can see all the modules that are available on the system yeah there was a question yeah yeah there\u0027s a comment by Michael is up just a second I don\u0027t if he happen he thinks that the minimum is a select merge format where the select user links attribute values of merge works under I think he\u0027s going to make a proposal on the select merge but I think it was also finish line so sorry ok ok so you have this welcome page and here if you if you go to and you see so this could be sensors Peters question here you have the tools right away you have seat file generation sit validate and sit consistency check so if you click on these links you don\u0027t need to go on to login to do this you just provide your rank file on a web interface and then it produces you to sit visit so what you need to do is you need to login request a seat range so for example your the 10 C user you go there and use the 10th company and you\u0027ll get the range from 1 million ten thousand to 1 million 11 so these are your 1000 seats and then you go here on this file generation you click and you say okay I have these thousand seats this is my yang file and then the tool populates the produces the seat file that corresponds to it and puts the correct seat files and then you can go up and upload the seat file to the to the to the to the registry and then it gets fixed and locked in this is my tears for the minutes so where did you set this up sorry where did you set this up so I see these nice screenshots but how do I get there okay so so actually actually so yeah so you see so these are all the nice the nice things here so you have to hear the when you when you log in you have the the seat ranges that are there so your account the cedar ages that are mapped to different idea to different link from "
  },
  {
    "startTime": "01:24:55",
    "text": "ways so there is a big there is a small problem here but I tried it no it\u0027s not working now no it was it was working yesterday even so I think that we had some update program during the night you know people working in some other time zones were updating stuff and right now it\u0027s not working but it will be working by the in the next two or three days like you can we can just go and and and and lock it and you can just go and log in and try it and as I said so this one this one these two these three points were actually addressed by what Carson said so this is like the first place that we\u0027ll be testing the whole thing the most important thing is also to get feedback on the the behavior of how things are behaving like people can say hey this is really not working for me I would like you to see the the process in this way around this way it\u0027s not the important part like this we can change this process the most important part is that we have the registry that people register there sits and that we have this nice process where we avoid land grabbing and you know we and we flee defy this this process so and we we don\u0027t overburden Ayana with every small module someone can want to register somewhere around the world so these are the design these are the the design constraints that we put to ourselves so right now the question is do we do a skull on it or do we wait more we would like to see some cross validation with net mod and you know that that we started getting all these discussions but what is the right time to do what is right thing to do as a next step so the last IDF we said document is pretty much ready for a group but we wanted to see an interim so maybe you can actually continue what you started at this weekend couple more days and write up a little bit of report about that and then send a message to the palest explaining what you did and what your experiences were and of course you should do this in a way that other people who want to participate in that so I think that\u0027s what we said last time you want to have that interrupt and we are halfway through I think that\u0027s the the yangtze border cured and maybe the yangtze border human also is the first one we actually want to Lascaux because this is one where we need very close coordination with net mod and so that\u0027s "
  },
  {
    "startTime": "01:27:57",
    "text": "something that you really need to look at the the other documents are more core specific and I think we don\u0027t have such a high coordination requirement there so we can do our normal two week working last part so we can probably do those a little bit later and use the time to continue on the intro okay so I agree on this point on the go with you at this point about the sit so draft course it will actually you use a yang file to our yang module to define the structure of the file or I mean the structure of the CID file so the the way this the way these information is stored for all the citizens oh sorry the way this information is stored is actually described as a yang file it\u0027s a young schema and moreover we are basically saying okay well they are so these are some useful things to know about about a yang module so we have this basic M module and then we have these like correspondence when we say they did well there is this link there is this URI and this is the city that is allocated so it\u0027s some kind of a meta information about the it\u0027s superlight meta information about the initial yang module so the question is maybe you guys from that mod would like to at least take a look at it and say well you know well I mean we started talking to them and they say okay that\u0027s pretty interesting we\u0027ll we\u0027ll review it but just just saying that at some point you know we may also try to to to offer their opinion okay I\u0027m going I\u0027m going to take this in this one I think it\u0027s better and so with this I have finished Alex yeah Michael Richards means asking if you can use comai to allocate seat ranges to use command to allocate see what\u0027s it ranges that\u0027s an excellent idea I think that I will invite him on the next Interop to come and decode the the part into the citric history code but yes that could be really cool that would be yeah it\u0027s possible and so now I\u0027m going to pass the word but before passing the word to the mic to to Hank who on hankies okay so during this hackathon there was something really interesting that happened and that was that people on the next table were really really busy bringing this new great feature to the world of yeah that is push so yank push that is used for telemetry and that\u0027s that what\u0027s really interesting is that this is actually a cross working group work so you have sockem net conf and core that "
  },
  {
    "startTime": "01:30:57",
    "text": "are working on this and you have a very interesting way to to see how you you have like a whole process so basically for the moment it\u0027s using XMPP you have a process to to see how a collector or something that is observing like like an observer can go and can discover devices can see what is happening in real time can hack and have update streaming events from what\u0027s happening from the configuration and operational data and so this thing okay so it will each one the best cross working group of collaboration work and what is really important is that for the moment it is using so there is this new technology that\u0027s called yank push and it is based on that content Resco for the moment and right now it\u0027s actually the moment to go and and go to deeper into the car my world into the world of IOT into the world of very efficient tallip telemetry and Hank and Eric in a couple of other people have actually wrote and they have written draft on this that is the problem statement and now Hank is going to to say in much better way what it\u0027s all about thank you yeah hi I\u0027m Hank um next slide so yeah young pushes build and designed in Netcom for group leading parties are for example co-authors of this problem statement about the there a lot more people involved in that it\u0027s called the yang push design team essentially written with a Z I think that\u0027s a tradition so we created a problem statement that basically tried to actually effectively identifying gaps in the co-op realm and the Kumaran in order to create Akamai datastore that would support the same push operations that are already be able to be conducted via net conf and rest conf so the natural order of things would be to now make this happen komai first of all telemetry means in this context that the data store contains state and that state is a kind of subscription to change its configuration operational data so in essence if you think back a few 10s of years SNMP traps we\u0027re doing the same thing and they\u0027re now reached yang so to speak and our faciliate hid in extra "
  },
  {
    "startTime": "01:33:57",
    "text": "quota calls that a net conf and restaurants so the streaming of continuous changes happens on the device without further interaction coming from the client we have a lot of things to do here for example we sometimes want to have a subset of things from the module we do not want to subscribe to everything like as a thousand leaves in the module so we have a filter expression in this subscription which is for example differentiating it from the pub sub that is already existing in coop and in the end it will enable data motion that is way more safe descriptive than it is now using standard modules I think about 800 in audio is already defined in the IDF and therefore the principle of not reinventing the wheel is being applied here also using coop and the binary representation via of course in the future enable far better scalability I mean this is an overused term but it effectively really will enable a lot of more telemetry on the wire especially if composite devices start to have their own data stores inside them so a device might be a set of multiple data stores so how are we planning to do this um fetch is not only able to do then observe operation to basically establish a subscription but also is able to convey a filter expression due to its capability of containing a body so we are creating media types that will be enabling XPath expression for example all as we just heard a specific get on a subtree to get everything from that set down if it\u0027s a leaf it\u0027s just one value copy or container so you can also do subtree subscriptions with the gates basically without the filter expression I think all right so I have to think about this is what\u0027s coming up just before my report here so we\u0027re going to do right at least two drafts I\u0027m not highlighting here that there\u0027s something called call home I\u0027m just mentioning that now so the data store sometimes wants to yeah find a suitable client that it\u0027s supposed to subscribe to it and this can be triggered by just initiating the ETS or DTS connection and then say peer allowed to send and then the rules change the client then starts the dynamic subscription for example and then we go into the realm of it on whirring bootstrapping and such result that might be a little bit complicated for today we\u0027re starting with the fetch "
  },
  {
    "startTime": "01:36:58",
    "text": "and get operations with the observe to get the subscriptions on Akamai ah data store the one thing here is that um komai is not really very visible in that confer group so we are trying to remediate that situation by bringing all more net conf people looking into a specific this new draft it would be the subscription to the kamae datastore and my rough educated guesses that will be about 45 fine 7% experts from coal mine and a little bit more experts from I come very to make this a feasible document and a feasible approach so I think this is my little report yes it is and the first questions from Hannah\u0027s Hank when you say XPath do you really mean X bar is it kind of my staff is that it\u0027s a very powerful mechanism and maybe maybe that\u0027s intentional or maybe I\u0027m not sure in what the functionality that is very true so we have the sub-tree concept which is basically done by getting a specific city and everything below it this is also this is the other alternative that is existing in yang 1.1 RFC and Eric has a I think sophisticated answer to the rest of the XPath question yeah basically we intentionally with the egg push did not limit the XPath elements that can be used we leave not to implementation and anybody at this point can choose what subset they want to support because it\u0027s very difficult to choose which subsets you want that we certainly didn\u0027t want to do it generically across all kind of technologies so we\u0027re a lot of the the standard allows XPath implementations will choose which things are why that probably doesn\u0027t work like from an intra bility point of view you can because it\u0027s almost like a scripting language XPath is it so you can\u0027t just send at the end and assume but what is the what is the anticipated interoperability then like it\u0027s a minimum set that you need to abort and if you provide something else then you bounce back and say error we formulate your question or English has a RPC mechanism where if something\u0027s not supported it provides back a look and a pointer to what is the current error with the or the current non-supported element so we do have a great response mechanism in the RPCs for the filter so let me have it before the next question comes in that we are targeting two sides of the same coin here first of all we are targeting less volume on the wire and more self "
  },
  {
    "startTime": "01:39:59",
    "text": "descriptiveness of today basically raw values that are pushed around so that\u0027s supporting unsolicited push those informations and we actually know what\u0027s happening what\u0027s pushed to you this is not a IOT this is just another and one at enhancement and natural progression of how to make better use of your resources then on the other hand we have constrained devices and they might not really like the complexity of XPath expressions and answering our pcs all the time so you can fall back of course to the most simple way to do just a sub-tree subscription this is to be CDs hider this is will be stuff we have to discuss when we divide the drop in progress or offer now Eric has a comment yeah to follow up on the other answer because this is related the yang push does allow filters and we have transport drafts for Netcom HP to comité so it\u0027s possible to put for transport what specific filters or what elements you want to support so there\u0027s no reason you cannot apply additional constraints by transport if that\u0027s the way you choose to do in limit what\u0027s there while the overall mechanism is in place so there are definitely by transport additional technology selections which are allowed as we expand past the base implementation that we used in the hackathon which was Netcom true so Tim carry no key idea but question as I was trying to figure this out because you know I won for look telemetry when we look at you know normal notes not IOT constrained notes I mean it does a very nice job of giving a general framework for for pushing data right limitary in in an IOT rolled with with constrain devices you know originally we had this thing called observe that kind of did that right so I\u0027m trying to understand how we\u0027re going to get this if you ever look at the push framework it\u0027s a well it\u0027s a rather heavy framework when you compare it to something that\u0027s constrained and so I\u0027m trying to figure out exactly what this means to constrain devices that you know observed was was all they really needed and and then what what does push really look like in that context I I\u0027m very concerned that you know as we start bringing the stuff over from net mod and net conf and we get all the things that go around you know more expectations that you would have on on routers then you would I have on on IOT device that you know this this framework working really working a it might work on a constrained Network but it would be difficult to justify in a constrained node and I\u0027m just trying to understand you know what you guys are thinking about in terms of observe vs. push in telemetry this is this is touching the "
  },
  {
    "startTime": "01:43:01",
    "text": "topic of a call home or finding a home to call home to if your boot strapping or if your drop ship or if you\u0027re imprinted or if you enrolled at some point you want to send out data as an Alex II device a lot of mechanisms how to bring the things into the field and this here allows for a very slim down semantics well-defined output that is interoperable with everything else it\u0027s already out there which is a big benefit if you have a lot of other devices that are already data stores a lot of post processing infrastructure that can handle all that information it is kind of practical if the things it\u0027s just appear in your domain and then push information to you can be processed and just like the exactly same way there is a homogeneity to the complete process that in simplified interoperability drastically also what you are getting it is it is a hazard huge overhead so but an IOT device can have some hard-coded someone I wish the video would see that one other item there is a parallel structure you might guys might have heard of DDS service the same mechanisms are shown to work on IOT devices there\u0027s our proof points that if you don\u0027t require deep filtering there are implementations which do similar stuff except it\u0027s not using yang it\u0027s using you know whatever the language is there so customer the underlying question here is is yang good for you and I think that that\u0027s a complex question and not everybody will answer this question with yes but for those areas where where yang is actually useful technology to work with the next question is can we make that scalable and scalable not upwards but as we are always interested in downwards so okay can we define a version of this this yang push environment that actually makes sense on a limited device that is probably not going to be your light switch it\u0027s probably going to be a little bit more powerful device so I don\u0027t think we are targeting class one devices here but still can can we make this work in a way that it\u0027s not dominating the the actual application that is running on the node but it\u0027s available for making these event streams available for for telemetry purposes and "
  },
  {
    "startTime": "01:46:04",
    "text": "right now I wouldn\u0027t say yes sure we\u0027re trip still trying to do that but I\u0027m pretty optimistic yet to add to that comment that\u0027s that\u0027s what the problem statement which is published has really highlighted the first section most of the building blocks are there and they\u0027re actually quite feasible to build something way more static then the typical data store if you\u0027re required to do so if you do not have the resources to react in a RPC interactive error detecting way and now I - Hank I was waiting to hear the answer to Tim\u0027s question about how does this relate to observed mechanism is it it is using the observed mechanism that\u0027s how it related it it is a fetch observe the body there is a filter expression or okay because maybe you have an example in the in the problem statement document which I didn\u0027t need to look at but my understanding of the observe was and some of the other work that was done they were filters separately defined for observe and then you use the observe mechanism to send the notifications but what we heard earlier I believe I heard was you use a different filter expression mechanism and maybe the answer that you get is also different so maybe maybe just an example in in the slides or in there in the document withheld through the document understand the unfortunately the this is this is bad conduct I think the problem statement has a lot of approaches as for suggestions to make it better understandable so it\u0027s not only a problem statement but it\u0027s also a set of proposed solutions unfortunately which is bad conduct we should have done this in two documents but the bias now are the problem statement by providing for every solution area a set of proposals how to solve this and we already in this it is already outdated so we had a few days to talk about this and we already advanced those but there are examples in there yes so I asked for this presentation mainly so that the group has the heads up that that this stuff is happening again I\u0027m I don\u0027t think we\u0027re in a situation yet where we can say oh this has been proven to work it\u0027s obvious that we want to go there there still is a need for for additional work but then it\u0027s good for the working group to know that this work is going on and and some people may want to take part in that so I\u0027m not I don\u0027t think we are asking the working group to take on this work today yeah please do not adopt a problem statement "
  },
  {
    "startTime": "01:49:05",
    "text": "this is Mattias I try to make sense out of this for the minutes so in the beginning I saw there is this push framework using XMPP and you use XPath and so on okay when so so what I understood is that you said hey this overall mechanism could be good also for constrained environments so you\u0027re looking for the equivalent over what whom I does already in this space is that\u0027s kind of a good summary ignore the slide there\u0027s nothing to do with core fact is that yes core and core can be used here and that\u0027s it ignore the slide this slide shows how pushed information can be post processed in a security automation domain that a second and can be used to create apology pictures by unchanged subscriptions for neighborhoods discovery between devices and or whatever if your USB serial connector just was connected and your switches now many really locally configured these are change events in operational State that can be pushed to a second collector and then be further distributed in security automation domain that is able to detect anomalies does machine learning or something else so this is basically a application of young push and we want this to be bolder than that conformist community we see a lot of applications that are already trying to create multiple data stores per device and the number of telemetry streams will increase drastically if this process of this trend continuous so please ignore this light in the context of cohab it\u0027s quite appstats here these are just the results from decathlon okay but you\u0027re still looking for something that kind of fits the overall ecosystem using yang using the push mechanism and so on but you\u0027re looking for this blue part that was at the bottom going to the devices it should use kind of the same how we model data how you transmit it but you\u0027re using for a good transport that uses coop the coop observe and some some optimized futures and not the experiment and heavyweight stuff we are still on not unsure how to deal with a very complicated XPath stuff I think they have to be a bit compromises this is the interest most interesting thing that\u0027s not been discussed yet it\u0027s about the media types of emissions we have to do but in general you\u0027re correct there as the fact is there\u0027s so many yang modules out there and and most of them are actually kinda useful I mean despite the 800 done by ITF that about I think 2000 then in total by the industry so there\u0027s a lot of good stuff out there and and not making use of that it\u0027s "
  },
  {
    "startTime": "01:52:05",
    "text": "kinda redundant and probably not the best idea so that that\u0027s that\u0027s one of the more drivers for using yang again I know people are kind of fed up with that term at some point I know and some other stos use something else entirely which is not necessarily better other ways to express models and this is just another way to ensure long-lasting interoperability and reducing redundancy and defining models for data that has been transported for years already again I\u0027m waved from the square thank you so as I come he has managed to time advantage completely and we will move the pub/sub part two to a Tuesday so we have a chance to get Adrian who is only here today to quickly talk about a payment of our couette and thank you for other questions and so this was a last-minute decision to come to this session based on interactions I had last week at w3c TPACK with wave of things working group and and some people there so I chair the payments working group at WC and there\u0027s a note there\u0027s a number of API is rolling into browsers today for payments the way they work is that the website constructs a payment request which it submits to the API and in that request is a set of accepted payment methods so the API itself and the data model is quite generic and you could put anything in there what has emerged as a desire from part of that working group as well as the web things working group to look for ways to bind that same data model to alternative transport so not a browser API but the the initial proposal was HTTP the the people I spoke with in San Francisco interested in exploring if bindings would also be with digging into so the the expected interaction would be some thing makes a request and instead of getting a response to that request it gets a request to pay the payments made some other way and then the request is retried so it\u0027s it\u0027s it\u0027s likely the work will continue within a w3c group for some time but making you aware of it in case you\u0027re interested in getting involved they double through see I\u0027ve created a mailing list so if you are interested just join that Public IOT palest and the work will probably get moving in the next few weeks and that\u0027s it yeah so if you look "
  },
  {
    "startTime": "01:55:16",
    "text": "at the way this payment required the stuff works that that is really reminiscent of the way ace handles the case where you access a resource server and and are not authorized to do it yet so probably the the right group to present this in would have been the ACE group but there is only happening tomorrow here today so I think that that\u0027s a useful thing to keep in mind there there is a payment infrastructure being defined and that will need some ways to reach down to constrained devices and my present example is is always a coffeemaker I want to be able to instruct the coffeemaker to make a career for me but if that coffeemaker requires payment how do I do this with co-op today and so probably the ACE framework is actually already quite useful for doing that so it probably makes sense to bring these things together in some form and it may be interesting to look at so the way their data model works is it\u0027s quite possible that the response can be very static so your coffeemaker could be pre-configured or have a very static so it could work very well in a very constrained device as well it doesn\u0027t need to do any payment processing itself it would need to be able to do something like produce the payment request information which could be very static and then validate maybe a token later that proves payment happened somewhere else so it\u0027s I think the model would be applicable in constrained space then constrained devices but I\u0027m yeah leave that to the experts out of my wheelhouse a little bit this one is I just open the document scanned true but it doesn\u0027t it sounds like related to the AIDS framework but it does actually use the x-ray book it doesn\u0027t use access token he doesn\u0027t use OS in at least from a quick glance so you seem to be defining something that is somewhat similar but if your own header format and everything else it may be ace is the right way to do it in card like I say I\u0027m out of my wheelhouse in that curve sort of world so I would in my participation from anyone who\u0027s interested in this yeah arrow scroller what are you assuming the client for this activity is what what am i assuming the client to be yes no assumption is the payment today the current API binding is is divined for browsers of the client but the the data model makes no assumption the data model is somebody says give me a set of payment methods that you support I\u0027m familiar with other word limits API works but my question is like what said of what\u0027s interactions "
  },
  {
    "startTime": "01:58:16",
    "text": "between the device and the arm and the client depends on what you see they keep those the client or if you think evils the client are basically generic web browsers and one sort of idiom is appropriate if you assume it is a something we know the standardized protocol another should it be is really sure and so given that given that the it the interaction from um I mean so in the in the web browser puns this problem by basically paying a JavaScript API and having stuff behind the covers and so if you\u0027re on given that the pay actual payment operation here is a miracle occurs behind the scenes it\u0027s important understand what you think the capabilities that device are of the client may get a request and then and subsequently initiating the payment yes I think it\u0027s very determined by the payment methods that are used so some payment methods could be an exchange of tokens that are understood to be valid for a prepaid arrangement that that could be perfectly valid or or it can be much more sophisticated that the client actually has to go online to a payment service and execute upon human tissue the the purpose here is to try any couple those two no I again I\u0027m not asking the question of what the payment mechanism is I\u0027m asking the question if we think the device is that is doing this work I\u0027m failing to see why that\u0027s irrelevant because the capabilities that device-dependent dictate what kind of API or interaction mechanism is appropriate again if the device is not capable of doing a sophisticated payment method then it would it would not be able to interact with it with a a server that requests that payment method there\u0027s a it\u0027s an agreement between the two devices or payment methods that they can both do so your misalliance is understanding me but I don\u0027t actually I am yeah everything is with you right nothing so we will meet again tomorrow H wanted "
  }
]