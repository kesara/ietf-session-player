[
  {
    "startTime": "00:00:13",
    "text": "Yes. Hey. Hello? Hi. Alright. It is time. We are we are at 9:30, and I think it is time to start the meeting. Could we have quiet, please? In the back of the room. Thank you. That we we will have open bike time as well. Not Alright. Welcome to, IETF 119. We are, we are so, kicked off in, DTN Working Groups. We have, Rick, who is joining us remotely. We have Adam, who is joining us remotely. But otherwise, Rick, why don't you, take it away with our chair slides to kick us off. Okay then. So, good morning, everybody. Or or good evening depending on where you are in your time zones, but good morning everyone in the room. Next slide, please. Just for confirmation, this is the DTN working group meeting. If you're you're not expecting that, you're in the wrong room and this is your chance to leave. As ever, this is an ATF meeting. It is covered under the note well given is now Friday local time. I'm assuming you've attended previous meetings and are familiar with the, the note well. Not gonna attempt to summarize it better than Tony Lee did earlier in TBR when he said, yes, just be a grown up, behave sensibly. Otherwise, you will be in by of leave, and there are circumstances in the Roberts team in order to act as a as a as a referee"
  },
  {
    "startTime": "00:02:00",
    "text": "if things get out of hand, but please just Be a grown up and remember, although the subject is exciting, we do need all to, to get along The other important part of the note well is to do with IPR disclosure. Anything you say at the mic, you are putting into the public domain, So, the onus is upon yourself to make sure you don't breach any corporate or a national security guidelines. Nick slide, please, there is not detail on this you can find by following those links. Notes really well. This is the anti harassment. Please behave It's that simple. Next slide, please. So meeting tips, we don't have blue sheets anymore. It's 2020 4. It's all done through Meteco. I'm assuming those in the room are signing into the on site tools so that we can record how many attendees we have those of you online. Hello. Assuming you're using Meteco and not some weird audio stream unless you're watching this in the future on YouTube, which is, hello, YouTube viewers. Remote participants, the dreaded echo is always the stand thing please, mute your speaker if you're trying talk or use a headset. It does work much better. I know in these post COVID times, we but with a lot of people clamoring and, latency involved. Please just be a little bit aware with your audio. Next slide, please. And So these are the general resources. These are the slides which are provided by the IETF to make sure that chairs have useful information in their slides, and this is the general information. Given it's Friday, if you've got this far and still need help, I feel for you, but it's getting a bit late in the day to try and fix your variants, Next slide, please. So more importantly, for this meeting, the agenda, we have quite a packed agenda So we've got a lot of topics to go through, but most of them we will spin through pretty quickly,"
  },
  {
    "startTime": "00:04:02",
    "text": "the two big subjects which are almost new work the co app of a bundle protocol, which we've left a 25 minutes slot for. And we've got a 20 minute slot in there for quality of service extension and Scott birdie and Alberto Montia are doing an update on whether got to with bundling bundling encapsulation. The rest of it, although Brian Seapos, has, short segments, they they sum up to 25 minutes in total to cover the 3 seeing us in flight. So quite a lot to get through, but we have left 10 minutes at the end for open mic. The one piece of agenda bashing I wrote these slides based off the agenda that Adam published the 3gppsaone store and forward use cases, Ed, I've I assume that was you. There was no name attached to it. Oh, yeah. Yes. That was me. And I, I can present those at at the end. Okay. Perfect. Only other thing to to add on the agenda no, let's let's keep going. Actually, no, I'll do it now. We are changing area directors. So we have to say a big thank you to Sahed who has done, and I can see Magnus's in the room who's are AD minus 1. So, well done for AD-1 still attending the working group, but on a serious note, thank you so much for us ahead. Who I'm not sure quite understood how much he was getting into when he said, oh, sure. I can cover CTN as well. He's done a fantastic job, and he will be sorely missed. And we're looking forward to welcoming our new AD who I believe is officially confirmed to be Eric Klein. He may be in the room. I can't see my monitor isn't that high resolution. Welcome Eric if he's there. And we look forward to more productive work"
  },
  {
    "startTime": "00:06:01",
    "text": "So, so, 2, 2 things in that. One is we do have, both Eric and in the room. Before we go into the AD updates, I I do think it'll be appropriate to both just take a moment say thank you. She's ahead for all of the work that he has done for DTN. And, a deep apologies to Eric for all that he's about to get into, for DPN. But but thank yous ahead, and welcome, Eric, So, there's there's one other, item, to agenda bash, and that is, Brian Cipos is having a scheduling issue in getting here. Nope. He is here now on time, so we do not need to change, the agenda So will I will bash my agenda bash, and we will stick to I it. Okay. Brilliant. Next slide, please. So, as usual, we need a notetaker, Adam, take profuse notes, which is great, but, we can't just leave him to do all the work. Critically, can you please check the shared notepad so that if you step to the mic, can you just check that your name was captured correctly and things like that and that your point was actually captured. Because people speak fast, people get excited, and transcribing is a professional job and it's not Adam's day job. So there is a fantastic job it's the onus is on all of us to confirm what was captured was actually what we meant. So, that's that. And the other thing is here is the reference to 2 mailing lists. Please subscribe to the mailing list. It is actually the workhorse of the working group despite fact we have meetings and Webex and virtual interims as required, the mailing list is the critical place for work. So Ed, let me pause and breathe. Do you wanna take over? So, these are the documents that we, we currently have, in, in various dates. Just as a reminder, the IPN URI scheme, is waiting for the 80 go ahead. Of the DTNMA, the DTN Management Architecture"
  },
  {
    "startTime": "00:08:02",
    "text": "is is also, scheduled for follow-up, and we might hear about that in a moment. We have finished, the working group last call. I I believe we're now out of working group last call for both the cozy contacts and the Bpb7, admin record types. And I believe Brian will be speaking to those in a moment, and then we have most recently adopted the, follow on, specifications to DTNMA, which is the management model, and the resource identifier, and we will speak a little, briefly about that in just a few minutes. So, pretty active set, and we have more that are coming, And that is in sort of working with, where we are in our milestones. Our milestones are behind. We have too many that are not in 2024, and yet we are here in 2024. So we will have to do a a rev of this, but the good news is that for the majority of the work that we did take on in the working group we are actively progressing almost all of these areas. And that is a good thing. And where we are not progressing, we are working well with other standards organizations, who are also progressing in some of these areas. Like in, some of the signaling work. That's where we are. Alright. So with that, what I'd like to do is invite it's a head up, to do some, outgoing AD updates. And Eric, following that, anything that you would like to say Up is fine. here Mister Okay. Hello. This is. I used to edit this Working group. Until last Wednesday. So I have some updates. Like, I am I think it's good to have some record of that one. Like, acquired this is, working group stands on different kind of, things that we are doing. And then definitely it's basically a equals Ticarapel, all of the things that we have been working here. Thanks for giving me the opportunity."
  },
  {
    "startTime": "00:10:01",
    "text": "For doing work, and she has been really great. On the working group update, I think the most important thing here, like, now we have been discussing quite a lot is DTMMA. DJMA went really well in the working group. We want to work with definitely, if the the document is pretty good, We also have follow-up documents to take on some more 1. It was in the ISG Evolution where some got some common like this needs some some broader kind of attention. So that's what exactly what we're doing. I think Ed has been doing a really good job on trying to incorporate all the comments and also now been this in this I take meeting. We have been actually talking with different working groups like networks. I think the network session went really well. And there was, like, general sense, like, and this is this is kind of something good. But the other sense of the of those thing was like, okay. Let's let's talk about this DTMMA about, like, what we are doing then when when describe the best practices that we're doing and try to see, like, later on what we to be extended. So I think this is in a good shape. I hope it goes well. I I think I don't think, like, We have a serious hurdles to cover right now. So that's it. IPN update. I wanted to send it send it, but then I thought, like, Eric can do that. So he just finished his last call. There has been a lot of discussions, So, Eric, you need some more information, just reach out to me or, I think, yeah, then has all the information about IP and update. And that is basically a, It should it should go go well, unless and we have been communicating in Ayana on this what we're gonna do, I wanna do. I think Diana just told us, like, yeah, tell us what to do. So that should be IAG approval. Of this document would, like, sell that thing."
  },
  {
    "startTime": "00:12:03",
    "text": "So that's it. I think the rest of the thing will I think I I'm really happy to see some work coming on. Estimated and MA. Maybe some way, young extension. But I also got the feeling that this work need to be done here in this detailed working group. So that's it from my side. Alright. Thank you so much. Okay? Eric, would you like to come up and say anything? I think I'll just say, oh, hello. I knew many people I know and thank you to zohed and to the chairs for including me and any conversations this week as we hand over various documents in various states. I think data tracker is mostly should be completely up to date, I think, with, action holders and, All the other administrifia. I look forward to, try to do my best to carry these things forward and make sure we get the current documents over the lines and the next ones, into the queue. Alright. So thank you. Hey. Thank you so much. Alright. Our our first presentation is, Brian Cepos, who will be going over, 3 topics that are that are all, sort of related to the work that he is doing. Brian, are you online and and able to share your audio and video. We'll take that as a no. He's definitely showing up as there. Yeah. So Brian, your audio is not working if you're talking Alright. So, why don't we, take a moment and be, delay tolerant and, move on with the next set of presentations, and then maybe a little bit later when Brian is"
  },
  {
    "startTime": "00:14:00",
    "text": "is, better connected, we can go back to his slides if if that is the case and if it is okay, then if we jump over this, the next thing that we would talk about would be the constrained application protocol coapp, over BP. So Give me give me a moment to switch those slides. K. Will this, this is not working with my laptop. So I will just me tell when to Okay. Hello, everyone. My name is Carlos Gomez. I'm going to present the initial version of draft and title constraint application protocol co app over a bundle protocol. My co author is Anna Calviddas. We are both from UPC. Next, please. So this is the introduction, which also provides the motivation for the draft. The first half is pretty much well known by this working group. But, anyway, the DTN Architecture enables communication in challenged or stressed networks are characterized by intermittent connectivity, high delays, high error rates, low energy, low bid rates in some cases. These are features, which may be encountered in deep space or temporarily disconnected areas among others. And then the bundle protocol is the fundamental component of DTM, which provides this store carry forward, hopefully. End, there's the application functionality, which runs atop BP. Then the constrained application protocol co app is an application layer article, which has been design and standardized by the ATF for IoT environments. Many of them are characterized by features like low energy availability which often leads to intermittent connectivity because, the network interfaces and wireless have to be duty cycled. End, this, leads also contributes to high delays There's also low bandwidth, high error rates among other constraints, And as you may have noticed, these features are somewhat similar to those"
  },
  {
    "startTime": "00:16:03",
    "text": "in DTM environments, and COB has been designed on purpose for this kind of scenarios. So accordingly, CoAP supports features like a lightweight operation. For instance, the message Heather alone, when, not using options, has a size of only 4 bytes. There's also synchronous message exchanges. Significant amount of flexibility as you will see. And a club has been designed based on the rest architecture, which is used in the world wide web. Yes, please. So, the main goal for this draft is to specify how can be carried over BP, today I'm presenting the initial version intended status would be a standard track, One related, goal is also to explore interest, collect feedback. By the way, there has been already quite some feedback, provided. So thanks to all for that. And also another point is that, there's a question, which is if there's interest in the document that needs progresses, then, which is the target working group because there will need to be probably 2 working groups involved. The core working group, which specifies CoApp, and it's related ecosystem and the which specifies BP and it's related environment. So, in any case, the aim is to keep both working groups in the loop if the document progresses. Next please. So back to the content of the document section 3 provides the architecture. This is the protocol stack model actually based on figure 1 of RC, 9171. So here we can see the co op endpoints, are running in the actual points of the communication, the source bundle node, the destination bundle note on top of the BP overlay on top of a number of constituent networks, from the source to the destination. Next place. So, section followed 1 provides the messaging model"
  },
  {
    "startTime": "00:18:04",
    "text": "and the abstract layering for COB over BP. Cop was originally designed to operate over UDP. And we understand that the same co app messaging model would apply also, over BP. Because both UDP and BP are message oriented protocols that do not support Britain's mission. Was subsequently extended to to operate also over reliable transports, such as TCP DLS and WebSockets, However, for that, there's a different messaging model which we understand is not so suitable. Next, please So, co op can be viewed as comprising 2 sub layers. The uppermost one, handles requests and responses. The request ascend by clients, which aim to manipulate resources on servers and then the servers bring responses back to the clients in some cases, including a representation of the intended resource. And these requests and responses are then encapsulated as messages which are handled by the lower supplier called messages here. Which offers, broadly speaking optional reliability simple congestion control. So there are 2 main message types. The first is confirmable con messages which must be acknowledged by the receiver. Lead by default to a stop and wait pattern. And there is timer based mission with exponential back office single congestion control measure, for these con messages. Then there's also non confirmable messages which do not elicit acknowledgements from the receiver. There is acknowledgements themselves and also the special case of reset messages, which are sent when a receiver gets a message that it doesn't know how to process. And Next please. So also in this section, 4.1 We have attempted to, provide some perhaps minor optimization. The idea here is"
  },
  {
    "startTime": "00:20:01",
    "text": "when a source bundle note, has to transmit go up con message, then it may set the request reporting of bundle delivery flag in the encapsulating bundle. And then the receiver may opt to only send the corresponding bundle delivery status report. Instead of sending a bundle encapsulating the Cop Act message. This is only for the case where the go up back doesn't carry a payload. This can happen when a request, doesn't well, there's not a response ready when a request arrives, but still the confirmation needs to be sent or when there's a con message which does not elicit an actual response. So here, then the status report that would be sent in response to this, bundle encapsulated con message. Would serve as a GAAP act for the Gong message. So the assumption is that the status report size would be bit shorter than the size of that bundle encapsulating the quack app message with no payload. So there was some comments by, Brian in this regard. So we expect that Here, this, saving a few bytes would compensate the, perhaps, additional complexity of handling the the situation, perhaps Well, there are some additional things to to discuss here. Please. So, folder 2 provides the message format. First of all, regarding how the web message is carried over BP, We state that the co op message must be carried as the block specific data field of the the bundled payload block block type 1 of the corresponding encapsulating vendor then regarding the quote message format itself, each quad message, has a field called the message ID. And then, we are considering extending the message ID size from 16 bits, which is the the fold 1, 224 bids. This is intended to avoid a have severe limitation on the maximum message rate for a sender."
  },
  {
    "startTime": "00:22:03",
    "text": "This is because, RFC 7252, which is the base co op specification states that the same message ID must not be reused within the exchange lifetime which, is the time that with the full card settings is equal to 247 seconds. And, however, in other environments like for in, say, deep space environments, this time should be at least in the order of 1000 to perhaps tens of 1000 or perhaps even more. So then it means that with the full settings, the maximum message read, would be 265 messages per second However, if we consider communication from Jupiter to Earth this would decrease down to 3 messages per second assuming only one try for con messages, which is a favorable setting. So This is why we want to avoid at least this, maybe too constrained, on the, maximum message rate for a sender. Next, please. Section 5 discuss the scope parameter I think, which may be relevant. And start is the maximum number of outstanding interactions between a client and a server. Extending interaction being request and it's corresponding response or a con message and its corresponding subsequent act. By default, the the setting for this parameter is 1. Which leads often to the stop and wait pattern in in Guam. Then, the base curve specification explains that greater values are possible if there's some mechanism that ensures a congestion safety. So it's an open question which should be the right setting for this parameter. In DTM environments. Then there are 2 parameters, act time out, and act random factor, which are both relevant because, they determine the initial value for the transmission time out. This is, randomly chosen from the interval from act time out"
  },
  {
    "startTime": "00:24:00",
    "text": "up to act time multiplied by the random factor. The default values are for act time out. It's 2 seconds. However, for example, the RTT between Earth and Mars is up to 45 minutes considering only propagation delay. Component. So, of course, this parameter would need to be set to at least the RTD in the particular scenario. An acronym factor is by default equal to 1.5. This is intended in the original COB specification, the base box specification, to avoid synchronization effects, which may occur when there's like a group of sensors which may be transmitting sensor readings periodically. They may be close to each other. And when the scale of the latencies is relatively low, it is somewhat likely that several devices might end up, colliding repeatedly all the time. So this parameter is intended to avoid to decouple that, effect And, however, when we are dealing with much greater latencies, then perhaps it's very unlikely that synchronization will happen. So, therefore, in that case, perhaps it may be better to reduce the random factor to just one. Do you wanna take questions in line or wait till the end? As you prepare. We we have, Rodney in the queue. Oh, go ahead. Hi, Rod Van Meter. Can you go back to page 8 for for just a second? I'm I'm only a diletton here, so this this has you guys have probably talked about this. You covered this already, but the exchange lifetime says deep space, up to 10 to 4th seconds That's only 3 hours which is, which is plenty for the actual time of flight, but but in my limited understanding, you know, when when you, when you have to wait for, like, orbits to coordinate for relay, that's enough for end to end. So so"
  },
  {
    "startTime": "00:26:01",
    "text": "Is that is that the right time time value, or or does it only have to be the time flight, flight, flight, flight, flight, flight, flight, flight, flight, flight, flight, flight, flight, flight, flight, number. Yeah. So, you are correct. Probably we need to incorporate as well because here we were rather considering a sort of idealized scenario kind of referring to to what we have in appendix a, which only considers propagation delay, but definitely, we need to also include, like, you said, other delayed components, So, yeah, perhaps these numbers need to be just increased. And make it clear that, well, this is like, in the best case, let's say, like, considering only propagation delay. Yeah. My my first reaction on things like the message ID is is just don't use such a small, small number, but but I know that that in in for for your application use that actually every bit kind of matters, but Yeah. So that's the the trade off. Actually, in the design of club, there was this concern of, providing some very lightweight message format. So increasing one by this is somewhat relevant, at least in in that area. Should maybe try to see globally whether, this is, the issue or not. Maybe it's kind of negligible somehow. But, yeah, any way if On the other hand, if we might be constrained, in terms of the message rates might need to increase the message ID. So, Thank you. yeah, we have a bit of yeah. Thank you. And we have, one more. Rick is in the queue. I just wait for my order to wake up. Is there any reason given that a bundle does actually have a unique message ID and it's made of the concatenation of source the ID and the timestamps very and it has a sequence number built in to the primary block of a bundle. Could you delegate the the the message ID field and say, actually, it's 0 bits"
  },
  {
    "startTime": "00:28:01",
    "text": "use this other thing that's already in the bundle given you've got a mapping of a message a one to one mapping of a message to a bundle. Do you you need a secondary message ID is my question. Thank you. That that's something we had actually thought about. Perhaps One thing to consider is when we have con messages. Which, might lead to retries from the source. Then, understand that the Perhaps that message ID would be the same, but then it might be encapsulated Oh, Bundle. I see. Yeah. Yeah. I see. So it's it's the it's the sequence of the message within some longer conversation fire off the bundle. Got it. Thank you. You. Okay. So, the next parameter was max Regionsmid this is the maximum number of retries for con messengers It has a default value of 4. However, perhaps, due to the exponential back off that there is with retries, maybe a lower setting, a lower value than the default one might be suitable. And, related question is an person actually, whether we might need congestion control at all in the environments where BP is used. Next, please. Then still in section 5, there are some related times one is max latency, which is the maximum time since the datagram is sent until it is received at the destination, it is defined as 100 seconds. Which is close to the 2 minutes maximum segment lifetime defined in the original TCP application, then, another one is change lifetime, which is the maximum time since the first transmission attempt of account message until the arrival of its corresponding act. By default, this would be with the full settings 247 seconds."
  },
  {
    "startTime": "00:30:02",
    "text": "received. Which is, by default, defined as max latency, which is 100 seconds. So, Again, align with, what has been mentioned before. Yeah, we may need to extend the values for these times by at least maybe 2 orders magnitude, greater than than those by default. When, using Cop over BP. And one note is that caught implementations using AB timers to compute these related times may need to be adapted to operate over BP, perhaps using larger variables to account for the greater latencies. So section 6 discusses a co op option called observe which, is very useful because it allows a server to send notifications carrying, representation of the current state of some resource to interested clients which are called observers. The latter only need to initially register their interest in some particular resource. And then whenever the resource is the resource state changes, then the server will transmit the notification, carrying the current state of the resource to the client that is without the need from the client to send a a specific request for that. So this is, of course, beneficial in scenarios with high latency and or low energy or bandwidth. There is one detail in the original observe specification, which is that If the time between the two last notifications that a client has received is greater than 128 seconds, then the last one received is or can be considered the latest one sent. However, this time, 128 seconds, is chosen, as a value greater than the fault max latency, but when Co op is used to the VP, probably this amount of time, maybe in sufficient in many cases. So the duration here would need to be chosen"
  },
  {
    "startTime": "00:32:00",
    "text": "a value greater than the max latency of the particular scenario. And, well, there are some related details in in appendix a. Next, please. So section 7, focuses on blockwise transfers. Co ops supports functionality that allows carrying large payloads by means of called blockwise transfers. It's a sort of fragmentation and reassembly on the application layer. So, on the other hand, BP also supported its own mechanism for mentation reassembly. There is one statement in the original block wise specification for co op, which is 7959. Which is that the fragmentation reassembly process burdens the lower layers with composition state that is better managed in the application layer. Well, there is one implicit assumption there, which is that details on the data unit sizes that can be carried along the path over the different links, are known in advance However, well, perhaps it's open for discussion whether these statements still holds when running coop of a BP. Anyway, in the draft, we have currently added that for co op over BP as an option. Clockwise transfers may be used if the source knows in advance the duration and type of expected contacts, And this does not preclude because of BD fragmentation and resampling whenever necessary. And there are 2 specifications that define go up blockwise transfers. And we understand that the second one, which is our 9177 is more suitable because the original one in principle leads to stop and wait, pattern. And, also the last one supports efficient loss recovery. So we understand that it's more suitable for, the environments where BP is used. Also, there are several parameters for this articular specification, which may need to be, fine tuned to each scenario. Yes, please. So in section 8, we focus on a co op over BP URI scheme."
  },
  {
    "startTime": "00:34:02",
    "text": "So there are several UI schemes that exist already. The original co op specification defines co op and co op s schemes. Then RFC A 323 also defines the schemes to support go up over DCP over DLS and WebSockets. And, here we attempted to, define a new URI scheme for COAP over BP which would have this name called plus BP. The syntax would be the one shown on the slide and here, the the syntax that would apply would be similar to the one in in the original club specification. Except for the endpoint ID part, However, we received some comments on Wednesday in the co working group meeting that perhaps it might not be necessary to register a new co op, over BP scheme. Perhaps it might be enough to user coop scheme. As long as there is some way to tell unambiguously that well, whatever should be the endpoint ID is not confused with maybe something else. There is also some draft some working progress document in the co working group. Which is trying to provide, some guidance in this regard for coop over alternative transports. BP is one of those So, yeah, this is something we have to double check and perhaps update for the next revision of the draft. And I see Rick in the queue? Yeah. So just touching on the comment about point IDs, it's important to remember with bundle protocol, we have 2 different schemes for endpoint IDs. We've got, a numeric scheme, and we've got the DTN team which is text based both of those already have a URI representation. So whoever commented in the core working group that Just coep."
  },
  {
    "startTime": "00:36:00",
    "text": "And then understanding that the endpoint ID part could be discriminated correctly is correct. I don't think you need to co up plus BP. You might need a co app plus DTN or a co app plus IPN. But I think just having co op is the right way to go. Happy to continue that conversation on the mailing list. Okay. Thank you. Thank you very much. Yeah. So, well, a section 9 is the IANA considerations. However, this contained the request to register the RA scheme, which perhaps will not be present in the next version of the draft. If if this is confirmed. So next, please. Yeah. So, finally, There are also a couple of appendixes, in the draft the first one appendix a tries to provide some sort of reference parameter values. Regarding delays and related times, in this case, for the examples for interplanetary communication. For times between 2 celestial bodies, of the solar system. Here, these are idealized scenarios. Latency here only comprises propagation delay. Anyway, the aim is to to provide some reference to show what are the orders of magnitude we are dealing with here. Because, these are quite different from the default ones, for example, in Coab. So these times may be, something more are more common for DTN, but maybe not so much for core working group. And for example, this table provides RTT values which, also would be something like the minimum act time out to be used in that specific case or the equivalent exchange lifetime for, max regions meet equal to 0. And as you can see, the the orders of magnitude are 1000 or tens of 1000 of seconds. Yeah. That's right. Just a comment while you're coming to the mic, from the chat, and as a member of the new horizons team, where's pluto?"
  },
  {
    "startTime": "00:38:04",
    "text": "Rodney. I was just going to point out that that I just checked and Voyager 1 is currently 22 and half hours, one way latency. So so I would suggest we we have we have protocols that that are capable of going out a little farther. It's it's sir. Thank you. Magnus. Thank you. My name is Weslana. Want to comment on, I think, the whole congesting control flow control repair schemes. It seems like we need to think a little bit because I mean, Convergence layer is supposed to take care of the congestion. So I think what comes down for COAP is the question saying, your endpoint, how many concurrent requests can it handle? How many total message are you willing to burden the the paths with, etcetera. It's that's more the, like, kind of limitations you have. So, I mean, Sending as much data towards abundant protocol here should be fine. And, I mean, from that perspective. So I think it's it's you need to think about, okay, how much can you commit and and what can I deal with? Also, when it comes to the repair, etcetera, I mean, would guess you have to scale it to what in relation to what, bundled protocol lifetimes you sent. So that's, okay, what's the maximum lifetime And when do I need to retransmit based if I haven't received the response? So the Yeah. Yeah. Thank you. There there were some comments on the list, I think, regarding bundle lifetime. So, yeah, definitely something to look at as well. Thank you. Then we do have, Joshua, the kit, and the kit, and the kit, Hey. Can you guys hear me? Yes. So I may have missed it or I might have a bad assumption here. But has there been any consideration towards the possibility of aggregating"
  },
  {
    "startTime": "00:40:01",
    "text": "co app, multiple co app messages into a single bundle, to try and increase efficiency across BP? Yeah. So that's a good suggestion. So the draft, we are not, currently considering that, but perhaps It might be something to look at for efficiency. Yeah. Thank you. And and Rick, chair hat off. I really support this work I think this is really good stuff. call. I'm very happy to I'm gonna go back deep into this document after after the session. I'm gonna come back with a lot more comments. Because I want it to to work. I think the guiding principle is to to look at the information unable protocol primary block or available through extension blocks. And try and avoid duplication, semantic duplication with in the co app headers, but think this should work. I think this really should work. So I really support it, and, I'm I'm offering to help and and I will contribute to this. Thank you. Thanks a lot. And, Scott, I'm seventy 1. I Hi. I had 2 thoughts. One was just to suggest that maybe contact people at Antara Technic, a little company in Northern California who have a an implementation of beep of, co app over BP it is not open source, but there may be some experience that can, you can build on from from what they've built. But my main comment is on On the use of, confirmed messages. And I will suggest that it might actually be"
  },
  {
    "startTime": "00:42:05",
    "text": "simpler avoiding a lot of, configuration problems to use non confirmed messages instead and rely on bundle protocol, being reliable and congestion aware substrate, not in Italy, but by virtue of the converting slayer protocols that it runs over. I think that, the, there's some likelihood of of a, status report message is being used as an acknowledgement. Being lost because it's not 7. Reliably itself, I think the likelihood of of that happening is, is, at least as great as, the likelihood of, a failure in reliable transmission, at the end of the well hang layer underneath the bumper protocol. And that would would save, problems with, trying to estimate around trip time and and and time out intervals. And, the limits on, the different, message numbers that you use to identify the messages. I think a lot of problems go away. Okay. Thank you. Yeah. Perhaps, it it may be good to to discuss further whether that would mean like to completely, descart, like, the option of using con messages or maybe perhaps in some cases, they may they might be used but, yeah, definitely, we we may position a bit the the text in in the lines of of the comments that you just made. Thanks. Thank you. Okay. So finally, this appendix be It's just"
  },
  {
    "startTime": "00:44:02",
    "text": "some numbers try to to illustrate a bit, why we might be interested in increasing the message ID size in the go up header. The column on the left is a series of exchange lifetime values. One in the middle is the maximum message rate for a message ID of 16 bits And the one on the right is the maximum message rate for a message ID of 24 bids. So as it can be seen with different values, if we want to avoid quite significant decrease in the maximum message rate then it may be good to use, 24 bit message IDs. So that's my last slide. So I I a quick question, out to the working group, and that is I know that this is not a a call for adoption, 5. Are there any while we are here together, both in the room and online, are there any concerns about, the approach of standardizing coop over BP Alright. You. Eric. I'm speaking only as the AD, I think the only concern is that we maintain communication with, I guess, core working group. Is that where? Yeah. Yeah. sure we have Just be their review at critical junctures everything should be fine. Alright. Thank you, and thank you very much. Thank you. Brian, if you are able to, talk over audio, can you Can you let us know that? Alright. I've Let us, continue on with the bundle and bundle encapsulation updates, updates, updates, Here. Thanks, Ed, and and folks."
  },
  {
    "startTime": "00:46:03",
    "text": "Give me a moment to set your Alright. timer. And we can Can you hear me now? Oh, yes. We we can hear you. Oh, thank you. Thank you. The encapsulation, wanted to provide, you with some updates together with Scott and, and Joshua who are on the call as well. So let's go to an SSLite motivation, as many of you know, the existing draft for a vibe, as a Convergence layer expired, in August 2020. We have resumed, the work on a vibe, on the draft. A new proposed version is expected soon. We're working on it don't have an exact date, but, moving forward, the original motivation of by what's what's primarily extent about extending security enabling defense, against traffic analysis, as well as allow things such as, cross domain security, source source path for wording and things of that nature. As a way to support, you know, interim security destinations We're adding 2 additional, or 3 additional aspects to this motivation. And the first one is that, we at this party and believe that, buy this key to service provider DTM Networks, we're gonna be demonstrating by being, the ISS, later this year. There's also a use case, related migration from BPV6 to BPV7 and CSDS is working on a knowledge book to describe the TME implementation of BIP for carrying over over a bpv7network. To basically, migrating the network to 7 while keeping the payload, bonded protocol or DTM notes on the PB6."
  },
  {
    "startTime": "00:48:04",
    "text": "And, last but not least, is basically driving the requirement convergence for the initial 3 implementations of I only see any and micro, VPN. So I'm gonna go and talk on the next slide, talk about the first motivation, which is our new motivation, which is by within the context provider and works. And what you see on screen is basically a division in which you have the end user domain and then in between the service provider domain and domain here is useful loosely is that has no direct relationship to the, on the protocol specification or to the bio specification by any instance, this is more related us. Know, how we see as service provider networks and, things such as, using the vibe as a way to the service provider to apply their own security policies so at the end of the day, the service provider, is responsible for their own network but all that also applies to their routing, routing policies, to the collective service policies, under lights. That vibe offers at the possibility to hide the topologies, especially the networks that are inside the service provider domain so that it simplifies routing configuration and also provides just there's there's there's of of its own. So the whole idea is that the end user domains they basically see the entry and the exit, gateways they don't have to see their routing path because that belongs to the, vibe, this example, route, node, 11 would, basically communicate, let's say, with node 21 to the service router network. And all they know is that Exit, gateway, which is an old one. And then then node 11 could have their own quality of service and security"
  },
  {
    "startTime": "00:50:01",
    "text": "and this can be encapsulated on Biden. By itself would have its its own port or they buy one that would have its own, policies as well. So, we're gonna be demonstrating, part of it in the upcoming economic demonstration. And we do believe it is an important to consider. So, who's gonna be, next is gonna talk about a 1 or how that some of this is implemented currently implemented in ion. Scott, Yeah. Thanks, thanks, Alberto. Here's just a a brief overview of some, changes in the implementation of 5 in the ion in implementation of, upon the protocol. The the motivation here is that, in particular, looking into the the service provider network use case and and this security use case where the you might have a a particular security domain that needs to be operated in a significantly different way from the the, edge, domains where, information in Flow is more secure. The order to make those things work, what we've determined is that it's important to to give the 5 bundle source that is the encapsulating nodes, real control over all the parameters that that condition of the forwarding of the Vibe encapsulating bundles. And and so what we've done in the 5 implementation ION is enhanced the, by the administration function there there's always been this, notion about a a BCLA, by a convergent cellular adapter. A configuration object that is managed using the, Bob admin"
  },
  {
    "startTime": "00:52:01",
    "text": "utility, to, set up some parameters governing the transmission of the encapsulated bundles. That's expanded now to include values that would be used for all of the parameter, values, in, in the outgoing encapsulating bundles. Those are things like, the requests for status reports, a report to endpoint ID, a flow label for the encapsulating bundles sort of in, in addition to the of of of other, quality of service, parameters, that are providing for transmitting bundles, for me out of ion nodes. There is a pro right? Provision of RFC-9171 that prohibits the issuance of status reports for bundles whose payloads are administrative records, and that was intended to board the the kind of hailstorm of, of status reports that you could get from generating status reports, office status reports, office status reports, this is, a little bit of a problem here because the structure of the the, Bob implementation, and the original specification that in the now defunct, and interim and internet draft. For Bob was that the payloads of the encapsulating bundles be administrative records, and the administrative records content would be incapsulated bundles. Well, that would make it impossible to"
  },
  {
    "startTime": "00:54:00",
    "text": "to provide status reports 4 of those encapsulating bundles, which is an important capability if you're if you're doing a service provider network, And so what we're proposing, along with the the change to the implementation is, an additional bundle processing flag that indicates that the payload is by, and and where that is the case, that, that is intended to introduce an exception to the that rule in 9171. Next slide. Before we go on, we we do have, Rick and Oh, yeah. Rick. Hi. Hey, Scott. Very quick question about the admin records for for bundling, bundling encapsulation, your your 3rd bullet. In my mind, bundling bundling encapsulation, the Although the halo happens to be an admin record that's traveling effect through your tunnel because bundling bundle is tunneling. Yeah. Surely, you even though the payload is an admin record that you are bun that you are tunneling, surely, you wouldn't send set the the bundle, the bundle flag in the primary to say this is an admin record. Because it's not an admin record. When it's inside the bundle to you, do you need to to to change 9171 here. I'm it it's still an admin record because the the the when it when it is received at its destination when the encapsulating bundles receive you this destination the payload of the, of the encapsulating bundle needs to be delivered to the bundled protocol agent, not to anything else that is in the, the the user area."
  },
  {
    "startTime": "00:56:00",
    "text": "So the the bundled protocol agent is gonna sees this thing. And the only thing that the protocol agent receives in its capacity as a destination administrative records. We can introduce, like, I This is like the simplest I think that's right. way to do it, I think. Yeah. I just I just get wary about changing 9171. I think it does. I think a diagram would really I've I've got lost in what's help. it being promoted and what's not and when it's end capped and when it's decapped. It is it is totally the case that the diagrams are very helpful of bundling bottle encapsulation. Your mind just breaks. But I I think this is a, and we we do sort of have the ability to introduce new processing flags and so forth. That's the speed of inspect. And, and I I don't think it's departing too far from the the the the the intent of the specification to, allow an exception in this case. But that's that's absolutely fine. I suppose we're my my challenges, and I understand this is work in progress, and I need to do a bit more reading. Was that with, once encapsulated, the content of the payload is opaque until the the the decap point, and that was the point that Alberto made about transiting through, of your environments. And hence, the less you flag into the outer payload to say the more transparent you make that allegedly opaque payload, the more worried I get, but I'll leave it for now. This is something I I've made a note. I need to to review this. Right. We we do have a flag that says that the payload is an administrative record. So we do say something about it. Matter what already. this is this is, I I understand your And your reluctance"
  },
  {
    "startTime": "00:58:00",
    "text": "And if we can find another way to do it, that's fine. This was the simplest way I could think of it. Fine. That's it. Oh, let's let's take this to the I'll I'll I'll wait for a bit more information. Sure. Next slide then. And I I believe this is our last slide. It's just a a summary of the the work that, Josh Deaton folks at at atmarsh pretty much centered doing with, and, Josh, would you like to speak to that slide? Yeah. I will, please. Talk to this. And, thanks, Alberto and Scott for, diverting up a small amount of time for me to talk about this part. So for DTNV, we incorporated by, particularly for our use case was the encapsulation of the different versions as that was one of the main hurdles of trying to and, deal with deploying B7 on, the ISS, while also still maintaining legacy support for our already existing payloads. And we do agree that the the current standard does allow for the encapsulation of V6 bundles by V7 bundles. But one of the things that, would need to be updated, if we wanted to maintain both directions would be that, a definition of a pseudo BPV 6 5 administration record would need to be defined potentially in an annex just to make sure that that could actually be covered under the standard as that that could be used properly. And that's that's really the main thing. We did implemented as, that intermediate convergence layer type concept. As Scott was talking about, And the only other, special things that we particularly did, was we added some redirect options to our current convergence layers instead of having to"
  },
  {
    "startTime": "01:00:00",
    "text": "directly point out the buy convergence layer. And I'll give it back to Alberta. Thanks, folks. And that's, basically, that the we wanted to provide, what is next is that we will be basically delivering the draft, once, ready. Thank you. Alright. Thank you so much. And looking forward to the, the updated draft. Right. Next, on the agenda, we will have a quality of service extension, for bundle protocol. And I believe that Teresa, you will share your screen. Yes. I will be sharing my screen. I already see my screen. No. There's a permission thing that I need to like, what I'm not seeing. Me a moment. Rick, do you see where where the permission to share screen is? Let me try and find it. So video is published in order is published and slides published. are It should be there. Oh, I can share directly from it's all within me, Deco. You don't need here. Yeah. Oh, great. The share your screen. It's not It's it's way ahead of Zoom. Thank you, Mejekker. Yeah. This works very well. Okay. So Good night from Germany. I am my name is Theresa Agara, and I'm working on, quality of service for bundled protocol. This is my, PhD. I'm a secondary PhD student, and I am working on, like, on implementing this into an extension block. So I am going to go over, My proposal."
  },
  {
    "startTime": "01:02:00",
    "text": "Yes. So I am working on quality of service over VPN in general, but I am mostly focusing the scenario of Earth Moon Communication on since a very present scenario. And the truth is in the near future, we're going to have congestion since we will have for an extended period of time, only one relay link. When relay satellite in the middle, we expect to have many different types of interconnected devices as well as many types trucks. And in the future, we will also have several networks that have to interact with each other somehow. So with using call, we also need have a need for quality of service management, and that is why I am proposing an extension block that does this for bundled protocol. So, This would go into an extension block, but not only one extension my proposal is baby having 2 extension blocks. This arises from many comments that I have received previously in CCSDS is since this work is currently being carried out. The CCSTS, and I am, working on an orange book that will be proposed soon so there would be 2 extension blocks one that is called user quality of service extension block. That can be present only one time, and this would be defined by the source. Including parameters such as traffic required reliability and so on. So this is what the note says. This is my bundle. This is these are my parameters. And then we would have the network quality of service extension block, that can be present more than once, and it is always served as local values, meaning the networks get to decide to append, a block, saying this is maybe network prioritization or some other parameters that they see relevant for for it"
  },
  {
    "startTime": "01:04:01",
    "text": "According to their priorities, So Oh my sides are a bit okay. Okay. Okay. Can work with it. So help both of this, blocks with the structure, they would be very similar. The only difference being the user quality of service extension block would have only the canonical block extension information because the, inserting, I note is the source already. So that's already in the in the header, whereas the network quality of service extension block have to include also the inserting note ID because this can be added and removed along the way. It is, the dynamic part of this information. And Both of these are going to be using seabormups to have The type of quality of service parameter that we're currently defining and the value. So for example, there would be a map saying traffic participation is critical and then required reliability is blah blah blah. Using supermobs takes the exact same amount or same space as using CBRA arrays and it is very useful in the sense that we would always have the pairs matched up with each other. Eliminate in a possible error. Yep. So Moving on to the definition of both blocks, we would start with user quality of service extension blocks since this is the one that is the most defined. As of now, there are 3 parameters that we have identified us relevant. We are aware that these are not all these are, however, the ones that are currently being defined for the CCSTS, orange book Starting with traffic prioritization, for which there are 3 main types"
  },
  {
    "startTime": "01:06:00",
    "text": "defined one is critical, which would be, I I believe some people call it a 911, type of information. And then following some of the guidelines, there would be a distinction between quasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasquasrealtimeandforward. Both of them have a range of numbers, meaning that there could be subpriorities within these types, And they can be managed. The values have been assigned 0 to 23, meaning 24 values because then then this would only take one bite. With this, CBOR encoding, with a map but the rest are left as unassigned but they could. Be used, in an extension in the future. So how would this queuing work? Which is the the always the big question. So as I said, there are 3 used to be, defined. The first one is critical. 2nd one is real time, meaning if there are any bundles that are consider critical in the queue, they must be served before moving on to quasi real time, then if there are any bundles that are real time they must deserve before moving to strong forward and strong forward would only served if there are no other types of bundles in the queue. However, since there are some priorities within HQ, it's it's within each queue, there would have to be weighted queuing to avoid that aspiration. So if there are critical bundles, no quasi real time bundles are going to go through. Until there are no more critical bundles. However, if there are 3 types of quasi real time bundles, there would be some kind of weighted queue in to make sure that the was with the lowest priorities he gets sent even if it says at a slower rate than the higher priority ones. So, yes, we would have, an importance or urgency, decrease in this table."
  },
  {
    "startTime": "01:08:04",
    "text": "The second parameter would be the required reliability that is if the bundle needs to be sent over a reliable or an unreliable link, has been previously defined as a binary flags sort of either reliable or unreliable. We thought it was also interesting to add not only strict reliable or strictly unreliable, but also reliable possible and unreliable, if possible, So if there is the chance of trusting it reliable, reliably. It should be done that way. If not, it can be done and reliably long as it is sent. So now it's a little bit more complex. However, this is still, only four values that are being used. And the rest of reserve for future use, since there might be the need to, Do a little bit more granularity first for some specific scenarios. And the last one is latest only. Believe this was attached or mentioned before if, if we have, for example, an series of bundles that come, there might be the chance that only the last one is valid. With this flag, this would be a binary flag. Either it's up or not. Only the last one would be valid and the rest would be chopped from the queue. This is also work in progress. So there is, someone else that is working on this latest only only concept. So there are, the rest of the values that are not from the viral flag are reserved for future use, but there is also the chance that this may change change if the system gets more complex or if we can need more granularity. Okay. Yeah. So as an example of execution, if we have a source in yellow, and a destination in blue that has to go through a node in green we have 3 bundles. 1,"
  },
  {
    "startTime": "01:10:00",
    "text": "bundled one would be quasi real time and need to be sent reliably, bundled to a strong forward and needs to be sent reliably. And bundle 3 is quasi real time again, but can be sent reliably. Then in the queue given that there's only one link 1 and 3 would be sent before 2 since 2 is thrown forward. And then in the chance of having 2 possible links, reliable reliable or reliable or sorry, 2 manners of transmitting the, information over the link. B 1 and b 2 would be sent over the reliable link. MB 3 would be sent over the unreliable Yes. The other part of the proposal is the quality of service extension block. This part is really short because It is really reserved for local use and for network to define the quality of service parameters or the parameters, in general, there are important or relevant according to the priorities and to assign values to them. And what this would mean is that this block could translate. The user quality of service extension block into internal policy, Therefore, optimizing the decision process for the intermediate blocks of a network. So it's just an addition to the other one. And, yes, all values are reserved for local use to give the individual network's maximum flexibility. What this means is that we would have one block that immutable, and it would be, It would be authenticated, with the primary Heather, primary bundle block. And then we would have this network quality of thir this extension block, which is dynamic. An example of use would be here a similar example. We have one source that is in one network and the destination that is in another network, and we have to trust first a second network here in green. So if we were trying to send a bundle with a certain, traffic prioritization requirements and relay"
  },
  {
    "startTime": "01:12:02",
    "text": "required reliability, and we went on to network 2 this would append, Another blog that would say, okay, I am gateway of network too, and I say on top of this, this also has this network priority, for example, this bundle or this extension block would be kept along the second network, and the moment it would exit the network, It would be deleted because it's not relevant anymore towards outside of the network. And then the bundle would be needed only with the user quality of of service extension block, on to the destination. So, just to recap, would have and, of course, any extension blocks that might already exist, and on top 2 extension blocks, the user equality of service 1. And the optional network quality of service extension block, the user quality of service extension plug. Would be within the, integrity check, And the network 1 couldn't be. So, That is my proposal, and I am very open to questions and comments. Alright. Thank you very much. And we do have a couple of people in you. First, Alberto. Thank you for, the presentation. I'm I'm wondering if if, you had considered or validated or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or compared, this, option We an option in which you don't have a network extension blog, but just have a policy on the note. I'm I'm curious about why been"
  },
  {
    "startTime": "01:14:00",
    "text": "why why carrying a new extension block within the network? Because at the end of the day, it might be a mapping the mapping might be pretty static along the way. From, derive either derive from the user you know, a collective service block or extension or just simply you know, based on whatever policy the, you know, the network have for that type of quality of service. I'm I'm wondering about the motivation of including the network extension block. Yes. So my initial proposal was without the network blog. I added that, because of the feedback I received during the CCS TS meetings in which, policy Would either be incredibly complex and not scalable or would miss some of the cases So this policy would not only have to include how the network treats asserts in, for example, traffic prioritization or required reliability, but also the source, the network where it comes from, and, a lot of other A lot of other characteristics, that would mean policy and in the it would work in the case where we have very at no amount of devices, but the moment that we have a growing network that it's, growing it's going to grow exponentially at some point. Or it's going to grow much more at some point than it would be really not scalable. Okay. Oh, okay. I understand. Thank you. And, Joshua? You may have mentioned it but I'll go ahead and ask anyways. Did you discuss the reasoning for putting the node or inserting node ID on the network block versus just depending on the"
  },
  {
    "startTime": "01:16:00",
    "text": "a bib to identify that fact So that was nearly chosen because, to avoid for example, one network block going into another network, maybe. So to so it would be clear to identify, okay, this is, belonging to our network or this is from another network and this part part part part this block can be dropped. So so I guess, kinda, again, the the question would be, why couldn't you just simply use a a bib to identify that fact and drop both, when you need to throw it away. And then the user and network lock both have the same primary park, and even to that extent, the extra piece that you had for the network extension block, could just do as an optional element to the user block, and now you just one definition for an extension block and you're done. I'm sorry. So the part about this using the BIP, that's something that I haven't considered, and I will look into thinking about very much for the idea. The second part about just having 1, you mean having the network part inside of the You said broke. And just drop in that parts, you mean? Yes. So, the network specific pieces that are only in the network extension block right now. Just make it as an optional element to the, other extension block. And then now you're not defining 2 separate blocks. It's one block with an option. So the problem that I saw with that is that then v block would have to be dynamic, and there would be no way of checking that the original content has not been modified Along the way,"
  },
  {
    "startTime": "01:18:03",
    "text": "we we we can take this offline. Yeah. Thank Thanks for the discussion. you. And Rick first off, great work. I really like this. I'm I'm also going to say thank you for splitting the user block from the network block because when you have big heterogeneous interoperable DTNs, which I know I'm trying to build and sometimes very to get focused on where we just have a simple network at the moment. We know from DSCP, based QOS in in on the internet, that as soon as packets leave a an administrative domain, people immediately take off the QOS because what's important to you is not important to me, So I really like the fact, and this is kinda going back to Joshua's point. If the application, which is the user in this case, can say, I considered this data important to me in the following manner, and that can be using a bundle integrity block that can be secured, authenticated, and placed in an way for the lifetime of that bundle. And then the second block can be added and removed as their decisions about how they wish to treat it without losing the original. That is spot on that is such a good way of doing it, and it's bothered me. That we have avoided this before and said, oh, we'll have 4 bits. It will be fine. It was never going to be. So I really support this, and I really support that split in two blocks, and I understand why you're doing it. Thank you. Thank you. Alright. Thank you. Thank you very much. Yeah, thank you. Alright. Next"
  },
  {
    "startTime": "01:20:04",
    "text": "The next presentation is going to be, the block of presentations for Brian. And we will give just one more chance on that. If not, I will walk through the slides, having having some familiarity with them, and, we can we can take questions to the mailing list, or otherwise. Make sure that things go into the chat itself. Alright. So, I am not Brian Cipos. But I will be for the next few minutes. And I wanted to talk about three different things. The first one is just sort of the status of the VP version 7 administrative record, updates registry. So if, if we recall this, this was a document to update, such that registry, we have Done the last call, 8 well, we are still in the working group last call state. I believe we we have probably finished the last call. And we need to, update that document. It technically expired, last month. But we have no comments that have received. No comments were received during the last call. Edits are expected to be needed, and it is starting to hold up a work that's happening in acne. So, here having gone through the working group last call, we're ready to call that. Although since we are in the room here and, one line, Are there any concerns with this document Speak now. thing I'm gonna add one which is we're gonna I'm not sure, and I'm looking at our 2 previous and one current AD for advice here. Can we proceed the ISG review phase with an expired document. There was talk about, changing the data tracker so that things just really don't ever expire because in fact, they don't expire. The data tracker keeps them around forever."
  },
  {
    "startTime": "01:22:01",
    "text": "So what is a draft that's kept forever versus a draft that hasn't hasn't hasn't arbitrary tag that says expires on it. That said, shouldn't be too difficult to just, I guess I guess. Yes. But, I I would I wouldn't necessarily have a problem with it. So, actually. Thank you. In working with GlassCall State, Yeah. It has to go to AD eval. There might be some updates for that, and then IETF calls. So it'll it'll need to be ripped before it gets to the ISG anyway. Okay. I think the last call expired. I think we ran that as chairs. I just never clicked the button in the data tracker. So my apologies Yeah. Well, and and one thing that we are still, actively looking for either from DTM Working Group or or maybe acne is a shepherd for this document. So if you are interested in being a shepherd, if you have read it, if you are tracking it, please let us know. Otherwise, we will we will go find one. K. Right. The the next, is another document that had gone through working group last call, and this were the cozy context for BPsec. So as a as a reminder, BPsec, 9172, is the overall description of security blocks for bundle protocol but it relies on security context to determine how information is put into and pulled out of various Cypress suites and how cryptographic materials are captured, captured so the 9173, documents, default security contacts. And they are intentionally limited in scope. They are symmetric key encryption and Mac algorithm and the the way in which AAD is handled is also intentionally a very narrow focus. Because they are they are meant to be a sort of a least common denominator, default And importantly, the default security context do not have, any sort of concept of asymmetric key or TKIintegrated security."
  },
  {
    "startTime": "01:24:04",
    "text": "And, that is something that that needs to be present security contacts that can support that. And rather than try and reinvent that wheel, in DTN, working group, we decided that the adoption of, seabor object signing encryption, Koci, already provides all of the syntax and semantics that we need. And so the work being done here was to create a security context that maps cozy into this ecosystem. So, to that end, there were some final updated changes or the the last changes as as was in working group last call. We added a scope parameter to allow the use of, indirect block references, as we do a binding across different blocks We added the mention of, kid context header parameters for identifying, keys. And and there are, a couple of of small, sort of open issues related to to this on the GitHub project, although all honesty, I I'm not familiar with these. So if you have questions about them, take them to the mailing list, or or ping Brian on the the important point is the last bullet, which is that none of these issues change. The actual context definition or processing so we don't think it has a significant impact or any impact on the document itself. So from that perspective, we have also done implementations of There are other implementations of this going on. And that seems to be, not problematic and good from an implementer's perspective. And so at at this point, we have the BPsec, cozy contacts, they, are not meant to replace or supersede the default ones. The default one is called the default because it presumes that there will be other ones coming in. It gives us, you know, BPsec in a PKX environment. Particularly in in the near term. And it does not address policy and what is required"
  },
  {
    "startTime": "01:26:00",
    "text": "from a policy perspective, there's other work from that. And it is currently through, working group last call with no additional comments. I think just like the original, or the, ACME document This one is is meant to Go forward. So having gone through a working group last call, we are also looking for a shepherd for this document. If you are interested in being a please let us know here or on the mailing list. And I will pause and say, while we are all here together, if there are any additional questions or concerns on security contacts that were not brought up in the working group last call, please take a moment and, let us know now, or please take a moment and put them on the mailing list. Can I add one point about Shepherding, It is not difficult? I believe I did the shepherd write up for 1 of the DTN I think, TTMMA document. I did it in the airport what I sent up between security and the and and the actual plane. It does not take long to do if you've read the document beforehand. And your and you've had relevant conversations with people. So please it's just really useful to have an independent shepherd to, to perform the right up and make sure that due diligence has happened. So so don't think it's going to take months of your time. Indeed. Thank you. And then the the last, presentation here is on the concept of the early and emerging concept of bundle protocol endpoint ID patterns, patterns, And the the background on this, is that, you know, the use cases that that are coming in motivate the need for some way of identifying sets of endpoint identifier. As we have looked at policy for security, policy for matching, policy for policy, for quality of service. The question becomes how do you not do direct matches to endpoint identifiers but how do we how do we glob them in some particular way? And what are the regular expressions they're in?"
  },
  {
    "startTime": "01:28:00",
    "text": "How do we make sure that the definition of an DID pattern is is not simply something that looks so close to an EID itself that could ever be confusion of of pattern and and identifier. So, that is essentially what we are doing here or what Brian is doing here. These are purely text based and pattern matching syntax has sort of a network effect. This proposal has been put together this prism is compatible with the IPN scheme update. Which is good. And these are the various it's certainly something that's useful when we're doing security identities. Route blocks and author authorization, but then also the configuration and policy, that we've talked I'll leave this up here just for a moment. The the other thing I will mention on this slide is that that there is a difficulty here when we want to match between the different URI scheme. In particular at the top, first bullet under security identities where we talk about DTN colon, or we talk about IPN colon, and how would we make sure that, if a node is known by 2 different identities, say a DTN or an IPN URI. How do we match or apply similar policies in those cases. So in in Brian's proposed drafts, then he he has started putting together a couple of these individual capabilities. With patterns, IPN scheme patterns and DTN scheme patterns. Where, you know, you can do, match all syntaxes of ipncolonca Stars or below DTN's game pattern matches with DTN colon and stars, But then separately, you know, separate for IPN, the ID into single integer parts and each part can be exact match match all or one part wildcard or range expressions."
  },
  {
    "startTime": "01:30:01",
    "text": "And, deal with and use the compressed seaborne coating, for integers and then essentially just try and build out a simple set of logic. Pattern a contains b or pattern a overlaps with b. For the DTAN scheme, it it is a little different, separating it into name and service path segments. And then each of those can also similarly be exact match or match all or match parts. But the, And then I, again, set logic related to the regular pressions, And here are some or or an IBM perspective. Singleton patterns still look like singleton instances, and then all services We can have dotstars or one service on any node pointing specifically to the IPN star.star.say5. Then also getting into complex wildcarding patterns And ranges. And the mix patterns. So the an important consideration here particularly if we go back and look at singleton patterns looking, a lot like the identifiers themselves, it we need to understand that an EID pattern is not an EID. They cannot and should not be used interchangeably. This is clearly a security risk, such as the wildcard DNS names in the early PKX certificates. The syntax has been designed that a range or an expression is specifically not a valid EID pattern for ABNF. More importantly, the EID pattern is a superset of EIDs. It design goal. Is that an EID is a singleton matching pattern for itself. And then the patterns are conceptually simple as we just saw in the examples. But they can become more complicated, in practice. The IPN pattern special considerations has 3 logical parts. So the patterns always have exactly 3 components."
  },
  {
    "startTime": "01:32:02",
    "text": "So at this point, the the question that that we have, is is Well, at this point, there are 2 things. Number 1 is, whether whether, Brian will will be angry at me for for murdering his slides, as I've tried to present them for But second, when we talk about the idea of patterns and EID patternings and the URI patterns therein. Is this valuable? Do we see the concept of patterning of patterning as relevant to the use cases for which they have been proposed. And And are there any issues with the syntax and the pattern syntax that are proposed? I think that the question, first off is, conceptually, do we think that this style of patterning is the useful style for the purposes to which putting this document together. Any any questions or comments on on the utility of patterning from that perspective? Right. Alberto. You're in the queue. I just, want wanted to, say that that I do support And these, I think there is value in a grouping and the the formatting it's a common, it's a common standard when you are playing with, dealing with numbers. It's heavily using the telephony industry. So I think both useful and the style seems to be the right one. Thank you. And Rick. I'm gonna say pretty much the same as Alberto. I think it's it's useful. I I think what helped it make make sense to me was the understanding that the the patterns really are for users and user tooling to interact with the textual representation all the IDs. So this is not specifying the internal implementation that that needs to happen within fast lockups within"
  },
  {
    "startTime": "01:34:01",
    "text": "agent or anything like this. I assume that was based on my under standing, and I I kind of need to take that to Brian. So My concern is where this interacts with routing. Where people suddenly start trying to do path root aggregation and and try and use the pattern syntax as part of some sort of within a routing protocol. That's where I will become concerned. But defining a common textual representation to describe EIDs that match the following pattern I fully support. I I I do see under the use cases, the, routed blocks and all authorization the same purpose as, IP set of notation and and slashing. So that is something Not worries me. That that worries me simply because if, you know, I've been working on IPN quite extensively and and you've got a 32 bit space for your note numbers within a single allocator ID. And And we know from the public internet that ipv4 addresses had to introduce structure in order to manage aggregation I'm not sure patents solve it without sort of some kind of Bitmask, or as there's some sort of logical operation stuff that needs to happen in there, particularly for IPM And DTN, the regex. Yeah. Sure. I it's a good first start. I do support. I do support this work. But 8 I think having published this, it will open more questions, which is a good thing. So, agreed. And and observation being that the the fact of pattern is different from whether it is a appropriate for a particular use case. Since we did go through these slides a little bit, quickly. I I would just keep this on the slide on the on the screen and presenting just for a moment as the examples of the proposed patterns I've And while this is up, are are there any"
  },
  {
    "startTime": "01:36:01",
    "text": "concerns about this as a at, you know, at Well, this as the pattern approach or any any concerns with these as examples of what is Dane proposed. Scott, Scott, not a concern. I think this good. is very I, I think it's, nicely compressed and potentially very useful. Excellent. I do see that, Brian, your connection is working now. Is there anything, you would like to add? I don't know how much you've it looks like this is kind of the end but This, this doesn't have a lot of implementation experience yet. And there are some other things that that are being worked and the, Get hub repository that's associated with this Drafted, has, an issue tracker and has some item is already in there. But people are welcome to provide feedback and And, Especially the the aspects that haven't been, looked at in much detail yet are kind of related to one of the things that I had posted on the mailing list, which was How to handled unknown schemes, if that's something that that that that we want to deal with in in this kind of situation just as well. With With a a BPA shouldn't, catch fire and explode if it sees an EID with an unknown scheme. There are possible possibilities to handle Arbitrary schemes, in patterns using the, like, the double asterisk and and we can talk about it on mailing this, but That's the kind of thing that hasn't been really looked at yet. So it's not a matter of If, but how?"
  },
  {
    "startTime": "01:38:00",
    "text": "And, Brian, one of the questions that was asked, before you came in was, what is the proposed use of patterning in in routing, here because they're they're there were questions as to as to the use of that Yeah. That's an interesting point. And that it's almost the way that sitter notation Now is used as configuration Seems like it was probably not the original intent? But it was a mechanism that was Common enough? In tools, that that Although sitter started out being This is a a routing block, what it now is is When a tool needs configuration of IP address space, Well, we use sitter notation because we understand how to read that as a human, and we understand how to handle that with tools, And this is kind of the opposite direction, which is that that u. Could use these patterns in configuration or in protocols for routing, But the intent here is not to it's it's the opposite direction of how Sitter evolved. It's saying, here's a mechanism for doing patterning. Use it how you will. And one of those ways of using it Probably Canon will be for configuring forwarding and and routing. And and also authorization because that's one other thing that has been evolved over the years in in the IP world. Related to, resource PKI and authorizing my router is allowed to forward this kind of traffic, to these addresses. I am the authoritative holder of of these hosts. These hosts live behind my router. And these kind of patterns would be suitable for doing that same kind of work. Excellent. Thank you. And and one other, element that just came up in the presentation of this was"
  },
  {
    "startTime": "01:40:01",
    "text": "could you explain a little bit more about for the DTN scheme patterns complex or unavailable set logic. So this is something that definitely is gonna have to be worked out in the drafted And what it amounts to is that When I'm dealing with numbers and number ranges, it's very easy to say range a, is shorter is smaller than range b or range a contains range be or overlaps with, when it comes to Because the DTN, authority part is really Not not specified fully what it does it have structure? What is the structure right now? The mechanism proposed is to say, Well, we can either match all we can use a regular expression. And that's a large jump. And when you start dealing with regular expressions, what that means is that you can't really say Easily, At least as far as I know, in a closed form, is regular expression a, a subset of b. It's not a close warm thing. Now Regular expressions, Aren't the only way to pattern matches string. And If the DTN Authority part had a known structure if if we were to say In the same way as the IPN scheme is been kind of updated and refined. If we were to say for the DTN scheme, There is a structure. It it follows the same Approach as DNS names. It is not a DNS name. It it has the same kind of kind of hierarchy to it, Then we could do some specific pattern logic. Related to that hierarchy, but it doesn't exist right now. And as far as this is concerned. One thing that might fall out of it for the sake of expediency is to say We're not gonna deal with DTN scheme patterns right now. We're just gonna say, Match all. Match all within a scheme, and an IPN specific pattern, and and that will go pretty far to start with."
  },
  {
    "startTime": "01:42:01",
    "text": "Okay. Thank you. And then lastly, because you did come online right at the end at next steps would you like to speak to the next step slide, Sure. Yeah. I think feedback is the most important thing. And and one piece of feedback might be we don't know enough about the DTN Authority component To dig down into this level of detail, and we should just say, focus on the IPN scheme, focus on what has usefulness right now And, and, deal with other schemes later on. And that would include potentially IMC or any other scheme in the future. Alright. Thank you. Thank you very much. Alright. Josh, quick question. Yeah. Can you bring up the, IP and pattern, real quick? So in relation to that, I could have missed it because I was kinda talking over on the chat a little bit. So Do you, is there any reason to have any patterning in relation to the service number, or are you just particularly trying to play with the the main segments. Oh, so they're actually inches, Each of the three parts are handled symmetrically. So the examples are really focused more on the node numbers, but it it applies to the same to the service numbers. Okay. Copy. Thank you. And and that is something that hasn't I don't think it was mentioned in these slides, but these kind of patterns would also be useful from an application perspective to say, register me for these Endpoints. Because there are some use cases where an application, might need to have more than one endpoint On the same note? Yeah. I was gonna say the this patterning is basically"
  },
  {
    "startTime": "01:44:01",
    "text": "we use internally for DT and me as well. So Definitely like the kudos. Thank you. Alright. Thank you so much. And then, our last topic is me, talking a little bit about a summary of use cases, related to store and forward, coming out of, 3 g t So we'll go through these, somewhat quickly. I've There is a, in in the 3 g p p, there is a, several working groups. One of them is SA 1. SA 1 focuses on requirements. The, essay 1, group, published a requirements document that included among other things. Use cases and aspects related to store and forward satellite operations for a delay tolerant communication services. And that will be the focus of what I wanted to present. Here. And the the reason for that is, when I was at 3gpp, a few, weeks or maybe a month and a half ago and was talking with members there, they were not aware of the the work that was being done in IETF in this specific area for store and forward. And so it would be good to to understand whether we feel these use cases, from this community things that are relevant to the work we do so in that, the doc has an overview, and it in the specific store and forward operations are are overview is presented here, and then that is a wall of text. But the point I wanted to to pull out is this last bit. This is particularly relevant for delay tolerant IoT services, via the non geostationary, space segment And and so this is not something that they're looking at from a I think, a real time voice or screaming perspective, but the idea of messages and other IoT based traffic, To that end, if you were to go into, that doc which is publicly, available and"
  },
  {
    "startTime": "01:46:01",
    "text": "all the way at at the front. The document can be found by looking up TR22, 865, There are many versions of that. The most recent version is 19.2.0. So everything that is in this presentation is pulled from that document. They they talk about, many use cases the ones that are particularly related to store and forward, are summarized here. Mobile originated and mobile terminated messages. The store and forward service between a u e with satellite access end an application server for a delayed tolerant, non real time IoT service. So, in each of the use cases, they they have preconditions. They have examples. They have post post conditions. And and sometimes graphics that go through, the data flow and and sort of some of the justification for them, and then additionally requirements associated with what it means to go into those use cases. There is additionally intersatellite use cases, to its and and the the text and the bullets here is also pulled directly from the document. To expand the market of delay tolerant IoT devices, storm forward operations are necessary. Be developed to sustain the user data playing during the feeder link disconnectivity, there's another for data transfer, for IIT devices in remote areas where it is the thing communicating up and through and back down again because of the or the remote area that is the cause of the disconnection and then some emergency support I've scenarios. Again, because each of these use cases comes with a series of requirements here some examples of the kinds of requirements that are in the document. The document is not tremendously long, but it's about 45 pages and and of things like this. And so we talk about, or we see in the requirements support for store and forward operation. Support forwarding of stored data from one satellite to another satellite. Support for a store and forward data retention period"
  },
  {
    "startTime": "01:48:02",
    "text": "and dated stores quotas, configuration and provisioning specifically required Qs and policies related to how these things would work. And then in addition, the document, has you know, for purposes, one of them is the store and forward operation. But there are other use cases, that come in that also have some level of interaction with you know, satellite communications that are otherwise supporting the store and forward use cases like land access over satellites or information exchanges between ships at sea. And things of of that nature. And there are a couple of of use cases associated with that. So the the the presentation here and why we wanted to bring it up was really informationally to make sure that the delayed tolerant networking working group was looking at and trying to understand the statements of need for a delayed, tolerant communication service coming out of, the 3 gpp. The SA 1 are requirements, there is another working group in 3gpp called SA 2, which is architectures. There are a series of architectures, being proposed, for this by the the various partners in the consortium. I think there were last I checked 20 to 25 different architectural proposals to this. But one of the one of the questions that we have at large is how do we make sure that that community is understanding and aware of standards that we are producing here. So this is a simply an informational brief for that effect. But if there are those who have more in additional details, to this, I I'm I'm would love to hear them and invite anyone up to the queue to comment, comment, or to comment. See, Charles in the queue. Yeah. Charles Eckl, and thanks Ed for and, and Eric also for bringing this to my attention. For those of you who don't know I'm the"
  },
  {
    "startTime": "01:50:00",
    "text": "the liaison manager and I, you have to to 3gppp So, you know, now this this is at least on on my radar. Actually, the I think at this point, everything seems to be pretty good. I looked at the essay 2 documents and they reference a lot of the the DTN work and have, you know, kind of placeholders in there for certain things. I don't know specifically about store and forward, though, they've done anything. But at least they have kinda you know, the basic stuff in place using, the work that's been done in this group. What we could do is, have an actual lays on to them saying, hey. We've looked at your use cases, and this is how we think it could you know, you could leverage the work we've done. I just noticed this this document that you were referencing, the TR that's, that's kind of at the output of a study it's not actually the normative specification. So the next I wanted to do was go and look and see if this made it into a TS. One of their normative specifications. And at that point, That's when SA 2, when the other groups would start looking at, hey, They'll they'll be looking at how to address these requirements. And so from I think probably the, the interaction would be more at SA 2 and the other groups than with SA 1. And and any any help in understanding exactly who those points of context would be and and how we look at the the most appropriate set of data would be Much appreciated. Okay. Yep. I'll, definitely be communicating with you on that. And like in many cases, people interacting across both groups is often, you know, even better than than a formal liaison, so we won't do that unless it really seems appropriate. Yeah. Thanks, sir. You very much. Abby. I see, Jim in the queue. Thanks. My name is Jim"
  },
  {
    "startTime": "01:52:01",
    "text": "I'm sorry. I've got my newcomer to this, walking group Specifically studied up to 13, and there are various people there, mainly for China that are trying to advance the cause of satellite communication quality of service type activities. Now the work that's going on there is very poorly specified and the documents are almost incomprehensible. It's just in my view, very low quality, but we need to be aware of what going either at least to try and stop on doing bad things Yep. Much appreciated. And and follow on links to that either, directly to chairs or to the mailing list would be appreciated. Ads Jenny in the queue. Just want to make a comment. I know you were at the TBR meeting, but there's so the presentation, they were talking about, you know, the use case, of the intersatellite links, how they recognize that 3 GPP that It was a very important thing to consider but it they considered out of scope at this moment. So I think it'd be interesting you know, when we're communicating with them, the use case they're interested in, but especially the ones that they wanna on near term versus what they consider we recognize it's important, but we don't wanna work on it. Right now, right now, So, That's fair enough. Yes. In in the TBR working group, the the observation was that Oh, TVR would be interesting in in schedule annotation. But that some of the work the 3 GPP is investigating here would be out of scope for that working group. I do think the store in forward would be considered relevant in scope to this working Rick. I just I I have it with storing forward means means so many things to so many different people. So many different things. I think the use case is Fannie timed it,"
  },
  {
    "startTime": "01:54:00",
    "text": "it's it's store and forward during satellite handover or during a lack of coverage, and they're really talking about 3 hops. BP may be considered overkill by them. And, a certain element of not invented here. I'm old for liaison. I'm all for suggesting that we're we are solving broader problems than than their use case, but we do have a solution I'm interested to see I'm interested to see where they I I'm interested in maintaining this and and staying impressive. Sorry. There's a ramble, not a comment. I'll I'll excuse myself from the from from the list. It's getting late here. But but to Jim's earlier point, I I think that the communication and the conversation is how we come to the conclusions as to whether something would be too much little two little two little two little two little two little I think that was my point. Thank you, And and there is an additional topic which is not currently covered by these use cases, but is one of these very relevant to the work that we are doing and it has to do with, lunar surface 3 EPP systems in the lunar surface. So there is a store there is gonna be a store and forward no matter what in that context And those, you know, those, that specific use case is not considered in into a NTN But technologies might be the same. So it's something to also bring up as part of the conversation. That that is an excellent point. And and part of the the conversations, the early conversations that we've had to date with members of SA 2 were if there is a solution that works for the smaller use cases today, but would then for severe to solve the coming use cases that we see then that is, probably a good thing. Yeah. Right. We have 5 minutes of open mic And in the"
  },
  {
    "startTime": "01:56:02",
    "text": "In case we don't have something to discuss specifically in an open mic, I will share a a walk on set of slides, which is just an update to, where we are with some of the network management work as the head mentioned, at the start of the of of this session, the DTNMA is is progressing forward. We have presented it with, Net Mod and from that background perspective, we are now it actually version, 13 of the DTNMA. Which incorporated, discusses and other comments and AD reviews. We have just recently adopted, the, data model and the URI encodings for that model. And, there are, implementations of this, that are out in the wild in a variety of ways. Overall, the DTMA topic areas as we've talked through data models and operational data models and value exchanges continues to go through quite well. But the work is not complete. Are just now working group adopted. So we are working through additional open issues here relating to translating ARIs and semantic types and type matching and finishing up the work on, authorization, through access control and whether and how we do any additional seabor tagging, but what we do have is a fair bit of implementation experience, with this in in a variety of of, experimental systems and technology demonstration systems, with multiple implementations from independent parties, and that has gone well. And at this point, the work through the adopted documents AMM ADM and ARI is to, complete them complete the the various open source, implementations of them. And and proceed. So those are the most recently adopted, working group documents. Eric."
  },
  {
    "startTime": "01:58:01",
    "text": "As a as a matter, sort sort of related to sort of maybe related to AOB. I was wondering if you had any, thing to share about how your presentation and net mod went. Oh, indeed. So I think it went well, but I will also invite anyone else who is in Netmod, to to chime in on that. The the overall presentation was, was without, any concern. The questions that came up, were all supportive questions. The comments that came through were similarly supportive. Everyone seemed to understand, the goal of command based in the the environment that we are in. And then speaking, afterwards with Net Mod Shares, they affirmed that of of This was an appropriate thing to be doing. That this should be done here and not in Netmont. Just as other working groups would create their their models, and then we should be doing this with, Net Mod review to make sure that we are trying to capture the things that can be captured in Yang correctly. And then finally, and understanding of that Yang Next is coming, And so if we do see things that have been difficult, to model with Yang, that we are invited to create issues associated with that to be considered in the multi year effort that would be Yang Next. Interesting. Thank you. Alright. With that, we have 1 minute remaining Any final comments or walk on topics? Rick. I'm gonna jump in because having painfully gone through the experience of adding one extra integer to to the IPN scheme I'm wondering if anyone and I don't want to say Brian because Brian does so much need to look at the DTN scheme you know, there are there is there is a number of implementations out there. This stuff is is flying"
  },
  {
    "startTime": "02:00:01",
    "text": "we need to get a bit more maturity in how we specify EIDs Brian mentioned DNS form. DTN Registration. I don't know if there's a whole area there. Currently there's a lot of well, we do it this way and not a lot of, best practice So I would flag wave for somebody to look at what what on earth is a DTN URI? What does it mean? Fair. And and Scott's Okay. And Just to speak to Rick's point there, It makes sense, kind of, architecturally, that if we're gonna consider DNS like or DNS structured names. In the DPN scheme that perhaps we should also engage the DNS community, and see about maybe a record type for that. There was some talk of co opting the old CH record type chaos net record type. But I think it's not the cleaner if we if we're gonna be be giving them DNS names, to make a a combinations for that. Can I just clarify one thing? Yeah. But I meant I meant just the DNS textual representation format. Not actually tying them to some kind of record. That's a whole part too. Or parallel work. So yeah. Yeah. Interesting stuff. Agreed. Agreed. Yes. But so now The eventual unions are gonna function want that lookup on traditional Internet. I'm really sure if I agree with you, but some disagree. So let's let's have that discussion. Absolutely. Let me just have one more, with Jim. Yep. Thanks. I am one of those DNS people if you want to get a new DNS resource record type, there's a likely process for this. You don't need to write up an RFC"
  },
  {
    "startTime": "02:02:00",
    "text": "So getting a new resource record type is relatively simple and quick. Used to be done in a couple of weeks. Oh, that's terrific. So this is an excellent open top is something that we do need to start considering. And, please, let's see that considering done on the mailing list. Otherwise, we are we are 2 minutes over now. Thank you everyone who has joined, both in person, and remotely. And we will see you at 1:20 Thank you to everyone who remotely and who presented remotely. And thank you, Niteshka, for making it work. Super, really, really good. Yeah. I want me to go to take over the world. This has been the easiest secretary work I've done in a while. Everything's on one screen, not 4 screens, fantastic. Unfortunately, I learned today that Meetecho doesn't work Right? over Rizoncellular network. Well, caveats. Don't use Verizon. That's alright. Halfway through the Netmo to just before Ed was speaking yesterday, my entire broadband shutdowns attended. Oh, that's awesome. Yeah. It was it was great. 3:30 in the morning, someone thought no one will be using the internet. I'll just reach figure the exchange. Obviously structures and networks. Anyway, I'm gonna leave you all to it because getting late here, but thank you very much, guys, and I will see you in Toronto. Okay. See, interrupting Rick. Bye bye. Cheers, guys. Tears. Cheers."
  }
]
