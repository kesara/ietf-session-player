[
  {
    "startTime": "00:00:28",
    "text": "e e okay good morning good afternoon good evening wherever you might be um by my clock uh it's time to start uh so the first thing um we have to do is share the agenda uh Chris could you advance the slide yeah one second okay so here's the note well um remember everybody these are the UH responsibilities for iatf participants to make sure that we're all playing on a Level Playing Field next slide and please be respectful at all times and remember that"
  },
  {
    "startTime": "00:02:00",
    "text": "uh we're all here to improve routing security and please work together next slide uh for the virtual meeting just uh remind folks that uh we're it when you're not speaking turn your video uh and audio off or mute them and if you have a headset it seems to help the next slide is the draft agenda that was sent out yesterday uh which is was basically to continue doing the things that we didn't get finished at the last meetings because the agenda was too tight uh so we we know people want to speak to these three drafts and if there's uh any other time after that we can speak to other drafts uh when we're done with those is there any agenda bashing okay um um go ahead gear yep uh the only thing I will add here is Russ that on the last uh draft since we are Expediting it uh we just wanted we just wanted uh to get the working group feedback and see if they have any concerns okay thank you um I got a note earlier from sham that he wanted to speak to verification um did this I just got some slides um and so I will upload them while we're talking about the first one uh yob did you want to start with your slides or rudiger slides"
  },
  {
    "startTime": "00:04:13",
    "text": "which one of you guys who's provided slides want to go first yob or rudiger looks like yob is trying to get his slides sorted out uh well I posted them already so uh he should just be able to pull them down think yeah can you hear me yes I can now nice let me see yeah sorry the the the data tracker was super slow so it took me like multiple minutes to get into this meeting uh maybe other people were stuck as well okay well we're going to start with your slides then I I would say start with ruer he was first to submit and and his slides so I figured I just do him a favor by uh uploading into the system okay uh Chris can you pull up rudiger slides so let me see ah so does anybody hear me yes okay uh so next slide uh as you might have seen on the first slide that is actually something that w a and and I I mentioned that in in an email couple of hours ago uh done at the end of the prag uh meeting and um"
  },
  {
    "startTime": "00:06:01",
    "text": "uh since I only received the call for this draft uh this very morning on this side of the time zone range uh I did not get uh to quickly do a little bit more of uh what I have been looking at um in Prague uh the students of Matias valish uh asked me some questions about the verification draft and uh that made me look into it uh uh and detect a lot of uh nasty thing beginning with that I had not looked into it uh for a couple of years um and um so looking closer into it I found uh a lot of things that I think uh actually need some work uh simple things would be just terminology uh like well okay uh uh the draft title is uh talking Ops let me see the the uh yes draft title says verification but when you look in into the draft you find that it actually uh Maps uh uh in the decision um algorithm uh into the domain of the set of valid invalid and in fact I think validation would be"
  },
  {
    "startTime": "00:08:00",
    "text": "uh the correct thing to call this because verification uh should be reserved for bgp SEC where we unfortunately failed uh to uh do uh name the classification verification but well okay verification is something uh uh telling the truth and uh the bgp SEC is telling whether the path is uh figured out to be true while uh the aspa based thing is actually validating the path under certain criteria um uh looking into the text there is actually uh quite some stuff that is fairly badly structured like uh duplicate uh uh text or topics in uh very distant parts of a of a draft and um uh actually uh going very closely through the draft and trying to figure out which audience is actually addressed by the various parts of the draft and grouping stuff so that uh the topics uh come up uh with the different audiences in mind uh would make a lot of sense um uh the security consideration section looked uh quite lacking to me uh it starts with uh very broad benefit claims uh and I think"
  },
  {
    "startTime": "00:10:03",
    "text": "it looks very much like hand waving and then it goes uh into uh very technical discussions where uh I feel uh that kind that that kind of uh detail uh uh seems kind of a little bit uh interesting because uh uh it is not really clear how complete uh the explained set of vulnerabilities is um in Prague I did this one pager uh with this uh note that I wanted to be short and uh kind of uh the uh thing the thing that I was trying to skit in skip in the very short thing uh is essentially what I called in my male the elephant uh and that is the question uh about afy agnostic or ay differentiated and uh well uh in case in case of AR agnostic whether the explanations in this draft are actually sufficient to explain the necessary uh impli the relevant implications uh to in particular the operator um and uh of course uh if"
  },
  {
    "startTime": "00:12:01",
    "text": "such basic structural things are being questioned uh one would not be surprised if some rework uh may be necessary as consequence of uh What uh rework or or of other related drafts maybe required uh uh if there are actually uh substantial consequences to the questions that I ran into and uh uh actually the remark of apologies to the implementers I got the comment from one of the draft offers that uh H uh he was saying apologies to the premature implementers um so uh let me let me have uh well okay um I can run through some of the more detailed uh notes and questions I have it's not really that well structured else I would have submitted slides um but if there are questions or comments right now uh I would stop for that I have a comments job sniders fly open bgpd rpki clients open e see uh as"
  },
  {
    "startTime": "00:14:01",
    "text": "to API specific or API agnostic it is good to remind this group that there is a spectrum of granularity we can make mechanisms that are specific to a prefix specific to a BP session specific to a API and specific to as uh arcs and in June 2023 the working group came to consensus that API agnostic was to be the minimum viable product we saw benefits in the realm of the BEP implementations where it was easier to achieve good performance uh using an API agnostic approach but more importantly we saw benefits for operators because by removing buttons we make it harder to misconfigure aspa uh and indeed it is not as granular as it could be if we included API or if we included something specific to BEP sessions or even included something specific to individual prefixes so it is a trade-off choice now currently rpki clients Rotator forts rpki prover uh Krill ripe ncc's test uh B uh B medicines uh rpk mener Tom Harrison's uh aspa demo uh all are II agnostic and uh I fear that this is a choice we are going to live with because I don't think we're going to go back because none of the argumentation offered so far to make it API specific uh outweighs the benefits that we perceive from API agnostic now um as to your other comments about uh the"
  },
  {
    "startTime": "00:16:03",
    "text": "structure of the text uh I I think it would be very good to take a look at that and make the document as readable as possible and in that regard I think help is very welcome okay uh kind of my uh simple-minded understanding of uh uh a reasonable choice for uh actually being a uh doing uh AI specific aspar would be just at the as level and uh well uh if the if uh uh the community thinks that uh the argument we are not expecting like as it is documented we are not expecting major differences uh uh thinks that this is a prediction that is valid and will valid for the lifetime of the protocol uh well okay uh however uh the uh explanation the explanation uh and the guide lines that I would be looking for as an operator I was in the text is telling"
  },
  {
    "startTime": "00:18:00",
    "text": "somewhere well in the 92 chapter aspa issuers should be aware of the implications and somewhere Network operators must keep their aspa correct so kind of the interesting question is does the draft as we H as it stands expain what in congruent as topologies would mean for the operator to uh uh to deal with and uh as there is this well okay actually uh both uh statements should be aware of the implications sounds very much like a truism General very very general truism and uh must keep correct uh also sounds very much like coming from that that chapter but uh the the question for me comes up uh do I get an explanation what the consequences of having in congruent as topologies with with with aspa will be if if I may interject riger I I agree with you that the sentence you site uh with the truisms is is not optimal it's true because it's true and you must do it correctly um what I uh I'm happy to take on uh with with the other co-authors is uh either removing that"
  },
  {
    "startTime": "00:20:02",
    "text": "sentence uh or or making it useful and perhaps we can add an appendix that uh enumerates through a few exam few examples of potential in congruence and uh the effects that ASA validation would have or would not have because in my mind the approach of making it API agnostic means that in few Corner cases you do not get to enjoy the benefits of Asa protection like when you uh buy Transit from somebody but also have them as a appearing partner a sentiment free Port situation um and I think U it could be valuable to to to be more explicit like this this is the scenario where where espa helps you and these are scenarios that are essentially out of scope for espa protection so there's one to do item noted think sh's been waiting in the queue as well and now Randy go ahead sham then the then Randy may maybe sharm's mic is not working"
  },
  {
    "startTime": "00:22:03",
    "text": "skip on to Randy and come back to Shri Ram good morning and various other times um given that onethird of V6 enabled as's do not have the same neighbor set in V6 as they do in V4 I think the dis the discussion of the implications belongs in security consideration section okay go ahead k then Oliver can you hear hear me this is sham can you hear me yes we can hear you now okay thank you um so rudiger um regarding validation versus verification terminology um in different drafts uh like uh aspa SPL we are saying that validation pertains to x.509 validation um and verification is something that we are using with regard to using the the the validated uh aspa or Roa objects and making use of them uh in the form like a wh list uh what are the asss that can legit legitimately"
  },
  {
    "startTime": "00:24:00",
    "text": "announce a prefix what are the asss that are providers so when we make use of that kind of white list uh in the in for for the path verification we are using the term verification um so just wanted to mention that I don't know if uh you want to agree with that or or we need further discussion if I may continue um the um the other uh comment I have for rudiger is that um the security consideration section uh rudiger you and I met in Prague we met in a group with um mataya tesillo and others uh had a long meeting there in the evening I you and I spoke specifically about um security consideration section uh so what we have done in in the in the update that we have done on GitHub uh for the draft um I will speak about it soon in the next uh uh talk uh but just want to mention that um your concern was taken into consideration and um we have included other shortcomings of the aspa uh for with regard to path manipulations uh where it where it is not able to detect them so so you'll be able to see that um soon uh but I'm also going to talk about that in the next uh I mean in the talk that follows okay go ahead Kier and then Oliver okay can you hear me yeah super uh one comment that I and K"
  },
  {
    "startTime": "00:26:00",
    "text": "Patel speaking as a working group member not as a working group chair one comment I have had um and I made this um also few years back when we decided to remove ay out and make it ay agnostic since the point was brought up um I think the comment that I want to make is um anytime you take ay out of bgp it's quite dangerous you don't know what you're dealing with uh with new safis coming up uh or new offy sais coming up like Rift and lsvr soon you're going to have number of mechanisms through which you're going to distribute IP routes and connectivity that coupled with how the cloud is manifesting itself and the peerings that are happening in the cloud at least uh we should have um as you suggested your U some sort of an appendix that talks about um uh um how the peering has been T through uh in the appendix section um from an a agnostic Viewpoint and then we can attack should we figure out a need for AI um in future thank you okay can I can I or is yes please go ahead sham can you mute yourself please even with the danger that I don't make myself a lot of friends with this question when I hear these things like that onethird of IPv6 does not share the same path like ipv4 and IPv6 is still"
  },
  {
    "startTime": "00:28:01",
    "text": "growing is there a possibility that we go from one3 to one half to even more in the future and if this is the case isn't it relatively how can I say it doesn't it make this protocol then or not this mechanism a little or does it make a aspa useless that's what question number one question number two is I never really got all the arguments for moving to AI agnostic for me the main argument always looked like it's easier to implement it fits well with my implementation and designing protocols designing mechanisms based on implementations and how great it is to implement it like this and it's easier and not so complicated I think it's a very slippery slope and every time when I when I hear that one word what job at one point told me where he spoke about about his youth where he always thought yeah this is a great idea so we have to push it through and now this age the understanding that this might have been a bad idea I have a feeling we go down that route maybe I'm wrong and I know many people don't like to hear what I just said but I really have the feeling that we see already we we see already problems on the horizon and now we're"
  },
  {
    "startTime": "00:30:00",
    "text": "talking about we have to add it into the security discussion and and that there is a problem you have to be aware of and maybe by maybe one solution by just taking the sentences out to basically you know what let's just close our eyes and hope for the best I think is a really bad approach just my five cents Shri Ram you're still in the queue did you want to respond okay I guess you're not still in the queue uh yob then claudo then Tim thank you so we have to take into consideration that what we currently see in the default free zone the wasn't necessarily logically mapped to what people will actually use aspa for uh in other words I do not believe it is wise to extrapolate from what is observable through biased sources like route views into this protocols design so an example that is very hard to capture uh looking at data is a lot of network operators start out their ISP ip4 only they connect to a bunch of of upstreams and they' configure an aspa when it becomes available to them now over time they notice that ip4 price is going up or is higher than IPv6 and they enable IPv6 with one or more of the same Transit providers this usually takes a bit of time they'll start with one Transit provider then add a second one maybe some up equipment needs upgrading and the moment they Ena the second the the ip6 sessions alongside"
  },
  {
    "startTime": "00:32:01",
    "text": "the I4 sessions with an API specific aspat model they would need to go back to the RR provided web portals and add IPv6 alongside ip4 in an API agnostic model in which we assume that people want to do jeel stack over time um this is not necessary as a step so this is not something that can go wrong or yield surprises this is the major benefit and if we follow the argumentation line I need more granularity then I would say why stop at apis why not make a bgp session specific why not make it prefix specific so I would argue the slippery slope is how much triangularity do you want to add and what is the bare minimum of granularity that we can add uh to move the needle a little bit and I would argue the current model AI agnostic is could you m mute uh sorry I lost most of a session after talking uh maybe this is being recorded um so so what I'm arguing is that the current proposal is the bare minimum we can do to move the needle a little bit this will allow us to investigate whether more granularity is warranted in future extensions and what the shape of that granularity should be because it's not that API or not API are the only perations we can look at it's BP session specific even prefix session specific or even prefix session BP session specific like there's a lot of other options out there uh so what we currently have is the bare minimum and this is the path we should follow because this is what we"
  },
  {
    "startTime": "00:34:00",
    "text": "decided a year ago um then one point uh in response to K where K expressed concern about new safis coming and clouds starting to rain uh the ASA specification is very specific that it's only ip4 and I6 unicast that's it it doesn't do anything else uh and that's in both the ASA verification draft and the ASA profile draft so uh I hope that addresses the concern about uh the impact of Asa on future bgp extensions because we we narrowed the scope to just the internet use case can I cut through the mic Russ just to reply and then sorry that all right thank you speaking as a working group member again not as a working group chair two points y um there is a reason why we have aafi inside bgp um we started without aafi inside bgp in 1994 very quickly realized the need for AIS Safi and we inserted that in 1997 so uh there are reasons why we do things why uh for what it matters number one number two um Rift and lsvr as I stated in my comments carry the same exact V4 V6 routes it's not like they carry different routes what you are seeing now is a manifestation um where you have a need to carry um V4 V6 routes uh but using different softw for different reasons um that doesn't need we need to extend here I think the draft is very specific but what needs probably um to be looked at is do we need to yank out ay Safi or do we put it and if we yank out maybe some section that describes our justification so future if we need to put it back then at least for the set of folks who will be working in future we know the that's all I might yeah thank"
  },
  {
    "startTime": "00:36:02",
    "text": "you um so if I yeah can I go yes please thank you um sorry I was muted previously um so I wanted to uh I mean job already covered some of what I what I wanted to say quite nicely uh I do want to add a couple of things to that uh one is that one is that uh when um when an as declares um uh different providers um and even if it at at a point of time if one provider is specific to V6 and another provider is specific to V4 uh in the future traffic engineering May necess necessitate uh that uh you you kind of move some of the V6 traffic to the to the other provider who is doing V V4 currently or the other way around so for traffic engineering that that flexib many operators would like to have even though they may be having separate providers currently for V4 and V6 uh so that's that so in that sense it is conservative uh to to include both both V4 and V6 uh providers without the apid distinction in in the aspa um and and so that way for any kind of traffic traffic engineering which shifts traffic from V4 to V6 I mean V4 provider which shift traffic V4 V6 to between the two providers that that will not hinder their operation um in addition to that the other comment is that by including the the V the V4 V6 providers both of them without the apy uh in the aspa the other advant I mean the other point is that uh we would be making uh we would be ER aing on the safe side meaning that we would uh we May sometimes declare an invalid to be a valid but it is much"
  },
  {
    "startTime": "00:38:02",
    "text": "more harmful if we ever declare a valid to be invalid so it is better to be earing on the safe side uh in if by doing by by having it Affy independent um so those are my two points thank you claudo please yeah I I I realized that um f I'm just more or less mentioned what I I wanted at the end so the thing is that by being ay agnostic what we actually do is we actually um put path into a valid State when they would maybe not be valid but it's I think it's way more important for operators that this happens than the other way around where path that actually should be valid suddenly become invalid because they they they didn't properly set up the uh their aspa record and by that we're actually making it easier for people to actually start using aspa and I think that is one of the more important parts that we need to get right at the beginning go ahead rudiger I think you're muted rudiger yeah well let's see what what failure I run into this time um uh for Shri Ram's remarks about uh traffic engineering well if I have if I have actually distinguished uh between V4 and V6 up streams uh kind of uh obviously"
  },
  {
    "startTime": "00:40:02",
    "text": "obviously uh uh one would not traffic engineer shifting VX traffic to v y uh if v y is only uh uh set up for v um uh kind of uh that sounds not like uh a reasonable and expected use case but uh anyway uh I did not find explanations uh that when the operator uh uh lists uh uh single ay providers in the overall Cas what happens uh with uh the kind of uh um yeah with with these additional as's or paths uh thereof uh there are the remarks there is the text you should be correct and you should be aware of the implications please explain thanks go ahead yo um as I mentioned before um we can add an appendix to be explicit what implications we are uh uh ref referencing so for instance the on the"
  },
  {
    "startTime": "00:42:01",
    "text": "side of caution rather than uh the opposite is something I think we can articulate in a diagram um so the two items still stands and um I hope we can uh provide some text in the coming weeks okay uh Q's empty um I think uh we should move to the other aspa slides that yob provided uh we've spent 40 minutes on this topic and I think we really need to uh pick up the pace if we're going to not find ourselves in the same situation where we still didn't get through all the material thank you yo do you want to present your own slides or do you want me to uh yeah if you can put them up uh let's let's start with uh same origin or whatever you're you're going to put up okay profile um quick update on aspa profile uh yesterday I uploaded version 18 next slide please uh this is the overview of the current ASA profile this has been implemented by a good number and diverse set of implementers in various programming languages uh and I think this this profile um is is stable uh We've not seen changes to it in in multiple months next slide please the biggest difference or maybe the only difference between version 17 and version 18 of this draft is that we added a note uh and recommend rpki"
  },
  {
    "startTime": "00:44:02",
    "text": "validator implementers uh to be aware of a potential for dos attacks using uh aspa objects um the asn1 profile does not impose a limit on the number of uh provider asns that can be listed for a given uh customer asid so uh it according to the asm1 profile is possible to list a million providers um but if you list a million providers um uh we we'd run into issues so for instance um in the RTR uh RFC 8210 bis uh document there is a 16bit uh field for the the count of provider asns and obviously you you cannot fit a million in into uh uh that range um but the reason we didn't put a limit in the asm1 profile itself um is that you could also create multiple espot objects and they have to be merged by the validator that sees the multiple objects um which would would sort of nullify putting the Restriction in the asm1 profile Tech U profile itself so the suggested text is that uh validators collate all aspa objects for a given customer asid impose a reasonable limit somewhere between 4,000 and 10,000 seems uh reasonable to me and are also conscious that existing rpki validator implementations uh for instance impose file size limits um now in rpki client 9.1 we implemented a 10,000 provider as limit uh and I think this is the something we we need to sort of monitor over time like how"
  },
  {
    "startTime": "00:46:00",
    "text": "how does this uh uh is is this good or should it be adjusted so this is why we I I did not suggest to put in like a strict limit uh because the size and shape of the default free zone changes over time uh but they people should be conscious there they should make some kind of limits as to what's the maximum number of Transit providers um currently in use for a single ASM could be um the there's one CDM that I estimate has 300 uh Transit providers uh so that aspa object would have 300 uh provider ASN listed uh and that that's well well well below uh the limit of 10,000 that we imposed uh so I I think this type of limit is not controversial but maybe the text is not worth it in an ideal way so if you take a look at that diff and are like hey you're you should phrase it like this or maybe upgrade a should to a must or something I am all ears um that's it for this uh topic any questions uh okay I see Kier rudiger and Shri can you hear me again I can hear you loud and clear sweet speaking again as a working group member one question I have and it may not belong here um y feel free to push it aside uh but you're suggesting a limit for provider if I hear you correctly per customer as ID correct um but as number of providers grow uh do you think we need to worry about also pacing uh the uh data that goes into rpki router so that we avoid bgp flaps particularly because"
  },
  {
    "startTime": "00:48:01",
    "text": "inherently there is no play pacing inside protocols as we receive updates and maybe the answer is hey do it at bgp level which is an implementation dependent thing or maybe the answer is introduce some level of pacing in rpki to router I just don't know and that's one of the reasons why I'm asking in traditional bgp we have such pacing at a peer level at a route level so forth and so on and hence the question so in the RTR design um the the cumulative validated outcome of one or more aspa objects for a specific customer asid have to be packed into a single uh pdu uh so I'm not entirely sure how pacing could be uh introduced in the current RTR design but that's a fair question I think the point is um if you introduce an aspa object and it it contains an obscene amount of uh provider asms um that that will potentially cause a significant resource consumption on the BEP router site uh and and the goal of this draft update was to make people cognizant like hey you you can put in a crazy number and maybe we don't want crazy numbers maybe we need to cap it to something that that is super uh um accommodating to to what we know about the current Internet but also is well within uh tolerance levels of uh uh HP implementations fair enough that's one point and the second point is uh your you know as you said number of as is and imagine where the updates are coming towards outter where say number of as is minus one number of as is plus one so forth and so on a continuous update happening and what it means to CPU on the router side was the second question"
  },
  {
    "startTime": "00:50:00",
    "text": "I had but if that is something who we we think is something to watch out for I think we can put it on a to-do list and then see how we can Target that later on assuming that could be a potential issue sure ol ofer yes actually uh 88210 bit 12 with the two bytes as you said gives the maximum upper limit because I can't have two pdus for the same customer uh as because the second one would overwrite the first one right so the the the current limit in RTR is 65,535 which I think is unreasonably High and um um a few thousand in practice is probably a serer limit no I I I completely agree with you but the only the only comment what a basic because you mentioned something like one could have a second one and the second one basically would override the first one anyhow so there is already a natural limit for the router side that they cannot go beyond 65k anyhow right um and and I should clarify a little bit why I put this in the profile draft uh because RTR is not the only way to uh populate uh data in bgp routers RTR is one mechanism to to transport from cach to BP router uh but for instance uh our pki clients in conjunction with open BPD use a mechanism via the the file system and there no such limit of 65,000 exists uh hence also having a limit in the validators what they emit whether it's arar or Json or CSV or open beach PD format or birth format uh to me makes"
  },
  {
    "startTime": "00:52:02",
    "text": "sense so if we s if we lower the limit in RTR it doesn't lower the limmit in the whole ecosystem as it's currently deployed then maybe for compatibility reasons it would make sense to put into the profile a Marx limit that does not exceed the uh RTR because otherwise we have multiple mechanisms and and I cannot I cannot say for sure that everything gets transmitted because maybe one can the other can't but it would make sense then to really have an upper limit putting into the profile the challenge though with putting a limit in the profile is that a customer as ID holder can um issue multiple aspa objects that would be merged in the validator so limiting uh putting a limit in in a the for a single object would still allow people to introduce multiple objects to get beyond that limit so this is why I think um uh we we have to describe the concept of a limit on the validated payloads output side okay that sounds that sounds okay rudiger then uh Shri rudiger you're still in the queue did you want to be sorry I missed the mic button okay um okay yo uh I'd suggest to consider putting uh a note into the draft uh that suggests that validators actually should have a config configurable limits and uh issue"
  },
  {
    "startTime": "00:54:02",
    "text": "warnings if uh the validated complete aspa uh goes beyond the configured limit um seems to me much more valuable than setting some fixed uh uh fixed limit and uh it kind of Next Level question would be uh if an operator uh sees that for some as uh uh an obscene number of Provider as is listed uh can we explain how B how bad the consequences are for the uh uh if if that Operator just configures that this as uh uh will not be allowed to install vaspa um I in terms of whether it should be configurable or not that that might be more of of local implementation policy sure the current text uh says something like if this threshold is exceeded relying party implementations should treat all aspa objects related to the customer asid invelop EG not permit sorry not emit a partial list of Provider asns additionally an error should be loged in the local system indicating the customer asid for which the threshold was exceeded so yeah um logging errors is important is part of the text uh but most important I think we should really avoid uh emitting partially complete lists because I think a partial list is more harmful than uh no list"
  },
  {
    "startTime": "00:56:05",
    "text": "agreed sham yeah um just a logistics question regarding the time uh so logically like if we stay on the a aspa topic and move to the aspa verification uh if we do that I just want to know from Jo yob how much time he needs for his other presentation well let let's do them in order because I think we have them in priority order um in terms of time people did not get at previous sessions um and we have another uh 35 minutes left in this meeting should we go to the next topic we can uh which would be uh Shri Rams verification deck sure if you want to do the slides yourself I can stop sharing and you can share um you can do it it's it's fine uh so we don't have a problem so so um so y you still give me an idea how much is there is there only one more presentation after mine uh is that Ys one Ys can you give me an idea how much time we need for that two more so if you can keep it to like 10 minutes oh you need okay yeah 10 minutes would be short uh let me uh I mean I mean may need a little bit more than that but I I do my best to stick around that time so um so this is uh mean we've been working hard on the verification draft update over the last few months of course through last year if if I may just uh quick ly remind I mean recapitulate um in March uh April of"
  },
  {
    "startTime": "00:58:01",
    "text": "last year we had an extensive working group Last Call on the verification draft uh nearly 30 people participated lot of good discussion and uh all of the comments were satisfied uh at that time uh Al also subsequently um and um um I mean there were no objections there were there there was a lot of uh support and good very good interest uh in this verification draft um so so then uh then in November I mean some for some reason or the other the working group last call didn't get closed uh in November some new comments started to come uh at the Prague ietf some of them we heard from rudiger and uh and uh Matas and trilo trilo is on the call I think they had some comments to improve the writing of the of the algorithms making them more more clear U so better understand how valid invalid and unknown are determin rationale for separate Upstream Downstream algorithms things like that so we've been work we've been working on that and and that's there uh in the updated version that is on GitHub next slide please um so uh so r al already uh spoke about this so in response to riger's comments regarding the consideration regarding the security consideration section uh we previously had one um uh type of shortcoming that was explained and the rest was kind of hand waving but what now we have three types of shortcomings that are explained in detail and I'll talk about that later if we have time um and these are I think the three types that we should be concerned about uh aspa is promising us to to solve the"
  },
  {
    "startTime": "01:00:02",
    "text": "route leaks problem which it does very well but path manipulations is a different ball game uh bgpc needs to step in for that uh so we'll we'll look at that later uh but just to be honest and uh and and uh accommodative of rudiger's uh criticism comments on this section uh it has been uh expanded with more more details with the different types of shortcomings that are possible um Mutual Transit and complex peering uh uh so we had a good discussion in email with the authors um Claudio Alexander all participated uh cardio requested that uh we should make it clear if we are defining like roles additionally for Mutual Transit and complex which do not exist in the bgp roles and the OTC RFC um but but then we discussed it and we we came to the conclusion that we wouldn't bother about like defining those roles and updating the other RFC instead here we would just stick with the term bgp session types and that is adequate uh clao can talk speak to that more but we would just uh add these Mutual Transit and complex session types and that seems like is is adequate for from the implementation point of of you for clao and others we we can also talk about this in some more detail later next slide please uh so over the next like uh I should step back and say that uh back in 2021 uh we we found a bug in the uh existing algorithm at that time in aspa verification um myself Jacob Heights from Cisco um got involved and we we we made a presentation about correcting that bug so that bug is is accept I mean"
  },
  {
    "startTime": "01:02:00",
    "text": "is is overcome quite some time back of course uh but anyways starting from that the ASP algorithm is is in a correct and good shape only question is are we are are we describing it adequately like sufficiently for everybody to be able to understand it clearly um and we during the working group last call last year most people seem to be on board with it and they they approved the the draft at that time uh they had there was a lot of discussion and we continuously made improvements uh in the in the draft write up uh with regard to the algorithms as well as other sections uh so at this point of time uh the we we have all the right material for the algorithm uh we there's just a question about do we need like this detail I mean we have the detail so that so we can keep that detail and and hopefully everybody will be satisfied in including tasillo and Maas who most recently raised a question about that um and uh the only other choice is to to condense it Alexander is uh is on the side of like uh condensing it um so so it seems that the working group feeling uh during the during the working group last call discussions last year was that don't need to be so parsimonious with your words um explain it clearly and better and go with it so I'm I'm think I'm hope I'm thinking that is still true um so I need to be strategizing here properly to keep a track of time so I have a bunch of slides so we Define The Hop check function next slide please um we can I mean the Hop yeah we make use of the Hop check function to use the aspa to determine for each hop in the as"
  },
  {
    "startTime": "01:04:02",
    "text": "path whether the next as in the path is a provider or not um so so we can lay down the path in in this form here the prefix originates on the right and goes through as1 through ASN uh sequentially and these are unique asss in the path um as1 is the origin uh and ASN is the last uh as in the as path closest to the verifying or receiving as next slide please uh the key to detecting an invalid is that that uh that there should be two a hops in this path and these two hops facing each other facing towards each other for example from ASI to ASI + one and on the left from uh asj to asj minus one so facing in the opposite direction and these two hops should be determined as not Provider by the aspa and if that is the case we would have a route leak so that's the basic definition of a route leak if a if an update was received from a Transit provider or a lateral peer it should not be sent to another Transit provider or lateral peer uh so that's what this picture captures this is the basic definition of what an invalid is and this this is U how aspa detect an invalid it looks for two hops facing each other and the aspa tells us that these two hops are not provider facing each other and that results that's the basic methodology for determining a Dr leak next slide please so we have what I just talked about we have described that with that figure uh in the draft on GitHub quite carefully so so tasillo and others can read it and let us know if that that adequately meets what you were"
  },
  {
    "startTime": "01:06:00",
    "text": "requesting um so in the case of Upstream path verification we already know that the verif uh Upstream is applied Upstream path verification is applied uh when the um when the update is received from a customer or a lateral peer and in that case uh we already know that the Hop extreme hop on the left is already a not provider uh and therefore we just need to look for one single notot provider in the direction of the flow of the update uh and that would establish that the route is invalid in general so for Upstream there is the Simplicity that you just need to look at the uh path and think of it as going only up up up before receive it is received by the verifying as and if there is one single not provider ASI says ASI plus1 is not my provider then that is enough to declare the path invalid so that's the simplification with uh upstream and uh tasillo asked why do you separate upstream and downstream verification so this is the answer to that uh next slide please uh again when it is valid we only we already know that the Hop from ASN to the verifying as is a customer to provider or lateral peer so we only need to check the whole path to make make sure that there isn't any not provider hop and that again simplifies the Upstream algorithm for valid determination uh and and next slide please uh so unknown is when it is neither valid or invalid according to the previous slides next slide please so for the for the downstream it is different the the first top is as the The Hop from the verifying as to the most recent as on the left side that is"
  },
  {
    "startTime": "01:08:01",
    "text": "a downstream so that doesn't play in a ro play a role in determining invalid so we look for two NPS within the path from the path that is given to us in the bgp update and again if there are two not provider uh hops facing each other then it is invalid so in this sense the downstream algorithm is different uh the Upstream algorithm was simplified but the downstream algorithm needs to find two hops facing each other that are not provider then we call it invalid next slide please so I think many people know this well uh the for the downstream path verification uh we have a uh up ramp on the left and a down ramp on the left uh and the up ramp on the right down ramp on the left and it should form an inverted V structure based on the aspas so we have aspa validated up up up provider provider provider attestations on the right uh in the up ramp similarly up up up in the on the left side in the down ramp up up up each of each of the Hops is a tested Provider by the aspa only one hop at the top we don't need to know it uh it it's allowed in bgp to to go one hop across on lateral pier and the and the downstream path would be still valid uh so so this is how we determine valid for the uh Downstream and in the downstream if it's not invalid according to the previous slide and if it is not valid according to this slide then the next slide um then it basically is unknown next slide please um so we discussed between cloudo myself uh Alexander uh and the rest of the authors we discussed this carefully"
  },
  {
    "startTime": "01:10:00",
    "text": "um Mutual Transit relationship um we we required that they should register each other uh uh in the in the aspa as providers uh and we uh we we recognize in the latest draft that the RFC 9234 uh which is about uh about bgp roles uh and OTC those procedures are recommended uh to complement the aspa based path verification uh if the um if the procedures um uh I mean those procedures must not be applied on a mutual Transit relationship so again this is explained uh in the in the uh draft updated draft version next slide then we go to complex next uh so with complex um you have an as can have another as as a Transit provider for some prefixes and as a lateral peer for other prefixes um so what we have um uh what we have recommended is that the uh if any of these relationship if you have the other as as a provider then you should include the other as as um in the aspa even though there is another peing session on which it is not a provider that shouldn't matter if on one paing session it is a provider then go ahead and include the next the neighbor as in your aspa by doing this what happens is that it we are on the safe side uh sometimes the uh the update may be invalid but we would call it valid for example when it traveled on the lateral Pier hop and and then was received by another provider as3 Upstream uh it would be invalid valid but but we would call it valid that is earring on the safe side but when it is valid we would"
  },
  {
    "startTime": "01:12:01",
    "text": "never call it invalid so so that is more important next slide please um so let me at this point keeping that time in mind uh jump keep jumping like I can do this presentation in um in Vancouver for the benefit of the for the whole working group um so people can look at these slides and they would not have any I mean many of their questions would be answered so let's skip some slides skip this one um skip this one um so regarding um sorry uh yeah just one quick comment um we say that the RSC 9234 um OTC Pro procedure uh should be should not be performed uh on uh the mutual transition uh keep whatever existing OTC there is only to customer attribute keep whatever exists when when you have a mutual Transit relationship like between as2 and as3 but don't do any adding of the OTC Etc on this hog uh so that is important for for Mutual Transit and I can explain I mean the D the the slide explains and I can also explain it in Vancouver hopefully next slide we can jump ahead one more yeah now rigers next slide so this is already in the version 17 so this shortcoming of the aspa verification is already described in the um in the um version 17 itself so this is still included um here basically any as that is in the downstream path can lie to its customer and it shot it can shorten the path and the top hop uh at the epex of the of the of the vertical"
  },
  {
    "startTime": "01:14:01",
    "text": "like inverted V uh it can lie about the about that uh hop at the Apex even though it doesn't have a connection to two or three it can it can pretend it has and shorten the path so so this is one limitation of aspa it can a provider can fool its uh customer by offering lower uh paths with lower length um so that's one one shortcoming next one next slide uh so when a malicious removal or addition of as3 Pence is possible and aspa cannot detect that bgp SEC can next slide um so there's another uh sorry uh stay there previous oh uh there there is um there's another way the provider can also lie in the Upstream Direction U but but this attack may be too devious considering that it has to be at least a tier two ISP that that has to be engaging in this kind of uh deceit deceit um so anyway we described it so now we have these three and I think by and large these are the three types of shortcomings uh rud Ruder I'll make it available to you the the the the text file you can look at that next slide so there are two uh versions on the GitHub uh we are in the process of trying to discuss and converge uh PR pull request 24 is something that claudo Alexander myself discussed extensively and it it was made available on May 12 uh Alexander uh prefers to be uh to be brief on I mean to be to be sort of concise uh and June 14 he published a master in"
  },
  {
    "startTime": "01:16:02",
    "text": "which many of the things from the pr 24 are not included uh which in the process I'm a little bit afraid of we maybe losing the working group last call comment effects uh from last year uh so we need some help from few other people uh uh to to look at these two and compare and review them and compare and let us know uh and help with the fin convergence so please say thank you next one so for the working questions for the working group last uh uh for the working group folks is uh is the working group okay with a more detailed explanations about how the algorithms work uh working group okay with more detailed explanation illustration the types of path man manipulation aspa cannot detect for rudiger's request so this is another place where Alexander chose to eliminate much of the additional uh details and uh uh and the presentation of the um uh of the shortcomings um but I I think working working group perhaps would benefit by keeping that uh then the we want to Define in the complex as separate types of sessions um Alexander again has a uh has leaned towards making like complex one type of session and and uh and and put the mutual Transit under that as a special case but in reality I think claudo was requesting that we just separate them and call them two different types of sessions that makes it easier for the implementation um then um the fourth dot valid um yeah they we have a terminology WAP validated aspa payload Provider Plus uh Alexander again I mean those are like well understood by the working group they were very helpful during last year's working group last call so there's no point in changing the"
  },
  {
    "startTime": "01:18:00",
    "text": "terminology at that time at this time Alexander is again leaning towards like introducing new terminology here uh and finally the early adoption benefits has been moved to appendix but I would prefer to keep it that discussion was very interesting to the working group uh I would prefer to keep it in the main body uh of the draft rather then move it to the uh appendix so with that I I would stop and um let people ask questions if we have time claudo uh just from my side uh since my name was mentioned a few times um I for for me the important part is is that the algorithm in itself has been stable for more than a year so at least we're now talking mostly about how to properly document it and and should it be tur or should it be more explained or things like that and in the end I don't really care which one we take as long as we finally get to uh kind of the last call and make it a standard um a lot of the extra explanations could go into an appendix um if that helps to to make the this um the aspa draft to actually go forward um in my opinion um so whatever it takes I think we're at a at a point where we're just um yeah talking about different colors for the bike shed and but the bike shed actually stands already so uh we should we should be able to to get this out soon I hope uh clao uh yes uh good point um just take a look at uh I mean it would help if like tasillo had a lot of questions about this and Matas it would"
  },
  {
    "startTime": "01:20:02",
    "text": "be good to just for them to quickly look at the um the two versions and it's not a whole lot more maybe a page extra um uh so we can move it to appendix if people prefer that but uh leaving it where it is maybe maybe like coherent for the reader um so taso Matas others can take a look and offer their comments as well yeah maybe I think there there so I said there basically the meat doesn't change the question is how to present it and I think there's two distinct problems here the first problem being or two different audiences that we want to um explain the algorithm to um and or it's one audience but there's two goals and the first first one is give them an easy to implement version um and the other one is give them an intuition on why this implementation is correct and that was when we uh built the um aspa support and RT Li that was the really confusing part because we had something that was implementable but we really didn't understand what was happening and why some choices were made and I think personally I would split this algorithm section into two things one implementation and one does I think what we called semantics of valid invalid and unknown and yeah that's that's my take and I we we really should basically sit down and right now there those two diverging um versions of the document one goes into whatam says where we explained it in all detail and the one version from Alexander where he um basically had an Implement oriented"
  },
  {
    "startTime": "01:22:02",
    "text": "document which was really easy to implement but is also as a newcomer probably it's very hard to understand and we really should sit down maybe ask four or five people in one meeting and pick and choose from the different documents which parts are actually good and relevant so in response to your comments uh uh we we we separated the basic principles in section 7.1 uh so that is where you will find the uh explanations and then 7.2 and 7.3 uh in PR 24 are like clear Implement implementer oriented uh description thanks okay so the Q is empty um let's move to the uh our um r d rrdp same origin policy before we move there Russ uh note two chairs did we uh do the last call with IDR on that document on the r RDP document no not the one before verification uh I believe that we were waiting for the aspa profile to finish because the aspa verification right depends on it yeah so just just a note between the chairs that we should probably cross reference that indeed or call a call across IDE as well all right go ahead yob yeah I think it would be really good to Loop IDR in but but I would wait a"
  },
  {
    "startTime": "01:24:00",
    "text": "little bit um not just for profile I think that one is slightly less interesting to IDR but for the verification draft to to mature a little bit further yeah yeah my comments were specifically to verification track but that was more about a note to chairs um May I quickly interject uh so should we Target for uploading it looks difficult at this point uploading by the deadline for ITF 12 120 which is in 10 days um so is maybe people are okay if we we get take a little bit more time and maybe upload it just before the ITF starts minimally you should consider we should consider presenting it so that at least the IDE uh audience is aware of it oh I'll be happy to present it to a joh session or both in IDR and cider Ops if needed sorry r that was all go ahead yob um yo before you go ahead can I interject sure yep uh this draft is currently going through a working group last call uh post last call we want to accelerate this draft uh towards the publication uh of course there are other drafts I think I recall in post working group or last call also but considering that we're going to accelerate it we just want to know I mean it's pretty harmless uh it's uh non-controversial um it's needed uh and it's simple enough that we would like to push it the chairs would like to push it so uh if anybody has a concern uh feel free to air it here or on the mailing list that's all I had or do you all right same origin for the"
  },
  {
    "startTime": "01:26:05",
    "text": "rpki RDP um are you putting up my slides Chris I believe they are it's these right same origin I see my apologies I if I have to chat box open it won't show me the the slides um all right the problem in RP version one is that the the data structures the XML uh allow referencing resources such as Deltas or snapshots across different Origins so stuff hosted on different fqdn then the notification file is hosted this property can cause uh a tiny publication point to increase resource consumption on other people's publication points so for instance from a tiny experimental publication point I could reference ripen C's uh giant uh snapshot which is I don't know like 120 megabytes uh and in doing so I would increase the load on ripe NCC servers but also increased load on all relying parties that use the tow that through which my publication Point ultimately is reached uh so this is a bit of a a simple dos Factor um next slide please the solution is what is called uh a so-called same origin policy uh this is a concept from the the web world uh and it's it's well understood there uh cross origin problems are also better understood in in the web browser world than I think they initially were in in the design of RDP uh and the mechanism forbids you from following a reference to a resource when it's hosted on a different fqdn or and forbids you from following"
  },
  {
    "startTime": "01:28:03",
    "text": "HTTP redirects to resources hosted on different fqdns uh so this means that whoever is hosting the notification file also has to host the snapshots and Deltas on the same fqdn and the implication is that people have to host their own data and in doing so be the cost uh of whatever they produced in RDP themselves rather than um cheaply referencing uh someone else's uh rrdp resources uh prior to submitting this internet draft we uh had a discussion amongst rpki client rator rpki Prov and and Fort development teams and we were all in agreement that this is a reasonable easy solution uh I think the current status is that that RP K client and ruinator have released uh an official release in the last few days that implements uh same origin policy for RP uh and I assume RPG Pro and for will um follow in in the coming weeks uh next slide please um in terms of impact of this solution um to me it seemed easier to digest uh that that four or five implementation teams have to to add an extra check to when when parsing RDP data instead of so an alternative solution could have been to change RP protocol to use relative URLs instead of absolute URLs but that would require the cooperation of uh all publication Point operators uh currently deployed uh that's like 70 parties or so uh and collaboration and coordination with relying parties uh so that would be so much more work than U imposing a same"
  },
  {
    "startTime": "01:30:00",
    "text": "origin policy this is this fix is incrementally Deployable operators upgrade their relying party instances at their own Leisure uh it's backwards compatible in the sense that none of the publication Point operators rely on Cross origin uh um uh hosted resources so everybody uh that currently has something deployed in the RP I reachable through the five R trust anchors is already compliant uh with this Draft today uh and as more and more RPS upgrade to to versions that impose same origin policy uh the risk will uh subside uh last slide please currently we are in working group currently we are in working group uh last call uh this closes July 1st uh there was a lot of support like a lot of people that said hey this is uh this seems reasonable let's go um Alberto was one of the people that had more substantial comments and he uh pointed out that my attempt to describe how exactly uh you would uh take advantage of uh the absolute euros and and cross origin references uh it was confuted that's that's I guess my summary uh so I removed uh how to exploit it uh and and this change was uh confirmed to be beneficial by F buer and T uh if there are any more comments or things you'd like me to to restructure or rewrite uh I am all ears your feedback is most appreciated so at this point we're going to have to stop we're already one minute over I know we have one more set of slides but I think we made progress and uh we will carry that over to the Vancouver agenda so Russ I think yeah Randy had"
  },
  {
    "startTime": "01:32:03",
    "text": "had one comment I'm I'm super eager to hear it so maybe another 30 seconds go ahead Randy um documenting the threat that this is meant to amarate would be good so the current document says uh cross origin references could uh increase loads on third parties but it doesn't go into detail how exactly that works I read the you read it okay so you You' like a little bit more detail add it back in see you in Vancouver see you in Vancouver sounds good all right thank you so much and uh thank you to the note taker take care"
  }
]
