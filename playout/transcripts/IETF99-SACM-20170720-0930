[
  {
    "startTime": "00:00:21",
    "text": "[Music] can we get a 1 or 2 no takers anybody want to volunteer now you see one let me get one more note taker hey 1 1 okay Roman note taker Danny note taker Chris Jabbar scribe "
  },
  {
    "startTime": "00:03:46",
    "text": "are you really gonna sit all the way over there Peter [Music] all right please don\u0027t flicker all right it\u0027s an honor off are we on [Music] good morning welcome to the second working group if you\u0027re sitting behind the pillar we can\u0027t see you so if you\u0027re hardly I hope I see a hand somebody waved all right so uh welcome to the second working group yes this is the revised net well everybody has seen previously right excellent there is that we have jabber scribe Chris and we have Danny and Roman note takers excellent all right so this is the rest of the agenda agenda bashing sorry Dave altameyer is there a way to reorder the the agenda slightly I have to leave for the last half hour to attend another another meeting would it be possible to do the Charter discussion earlier and the and the agenda and as I would like to leave with Dave and maybe push 5-2 with the band because I know this okay any other agenda bashing requests all right so I would personally like to do to get through the hackathon stuff first so hackathon us okay so so what we\u0027ll do is "
  },
  {
    "startTime": "00:06:48",
    "text": "we\u0027ll we\u0027ll discuss we\u0027ll do items two and three the hackathon stuff first or yeah first then we\u0027ll do the Charter and then we\u0027ll move through the existing work items do we it becomes for well then the question is whether we move five down but maybe not it\u0027s okay with Charles we\u0027re doing one two three eight four six seven five and all my years of chairing I don\u0027t think I\u0027ve ever bashed an agenda quite this much bashing all right and a reminder to anybody on the other side of the pillar that\u0027s sitting down we can\u0027t see you and so I guess if you want to remain incognito that\u0027s a good place to sit so moving on hackathon results so he\u0027s gonna I I know where it is I just did a fast review yeah I just I just um I didn\u0027t want everybody to observe my process for actually finding oh no no I didn\u0027t want to do that that was I hit the wrong back button sweet perfect there isn\u0027t there isn\u0027t any slide so I\u0027m just gonna talk around this diagram and I\u0027ll keep my comments brief so I\u0027m good morning my name is is Dave Walter Meyer and what I\u0027m gonna give is a quick update on the sockem hackathon activity that we had earlier this this week where we built a "
  },
  {
    "startTime": "00:09:49",
    "text": "a proof of concept of an implementation of the vulnerability assessment scenario so our goal was to to work under the assumption that a vendor will release a security bulletins identifying a vulnerability in a product and that and then user organization who is a customer of that vendor would need to to be able to analyze the software inventory of their devices and then determine which of those devices would contain that software vulnerability so we designed over over the course of our planning activities for the hackathon we designed this this implementation architecture which incorporates a number of existing standardization efforts I\u0027m here at the IETF some some within Sock\u0027em and others within mile as well so quickly talking through the diagram which is no longer on the screen so so what we ended up doing was we ended up cobbling together a solution that that was comprised of a number of open-source projects as well as some some commercial products so if if you look at the right-hand side of this diagram we have the the target endpoint so this is the the end point where the vulnerable the potentially vulnerable software may be installed the the the grey box and just at the left of that represents the collector in this case which is which is orchestrating collection of the software load on the device using a swimmer one of the drafts that I will be talking about later in in the agenda swimmer allows two modes of collection the first is it allows the the collector to you know to to ask for the current software a load of the device and swimmer also allows for the collector to subscribe to change events relating to the software so in this case we implemented the first use case which is being able to pull the client on the the target endpoint to get the software load so strong Swan does that polling it it communicates with the PT TLS client on the device it looks at the package "
  },
  {
    "startTime": "00:12:50",
    "text": "database on Ubuntu system its generates whit tags out of the package database swimmers used to transport those sweet tags to the server and then those tags were made available to downstream consumers so to round out the assessment solution we built we enhanced the see the CIA a sis CAD tool to be able to to query the the sweet tags that were stored on the strong TNC server we use Deauville to to evaluate those sweet tags to look for sweet tags on on the strong TNC server that match a specific of honorable software version and then we used that to report whether the device was vulnerable The Oval definitions as well as other vulnerability management information was retrieved from the Roli server which is the leftmost box which is based on a specification for mile and the Roli server allowed us to dynamically serve up the oval content to the assessment server so we were able to to get this architecture working we we were able to do a complete run-through of the vulnerability assessment scenario and we were able to identify a ulnar --fill system using this method in doing so we\u0027ve learned a few different lessons out of out of this project so the first thing that we learned was that turning the vulnerability what we\u0027re calling vulnerability detection data or vdd knew a vulnerability bulletin into an oval definition is actually a rather difficult task it took us a number of hours during the hackathon to write a single local definition that could you know look for that vulnerability so the other the other challenge we had was it was it was kind of difficult to actually query for the the software that was of interest to us with with the strong TNC server now we weren\u0027t using any kind of standardized API we were using you know an existing capability that had it was strong TNC so we feel like there\u0027s probably some some work that\u0027s needed in order to you know to enhance "
  },
  {
    "startTime": "00:15:50",
    "text": "the usability of that kind of kind of service so one of the lessons learned we had was that we need some kind of API that will allow for you know for queries to be performed against the data store and I think there\u0027s a working group we might want to consider looking at what other existing work in the IETF or elsewhere that might be applicable in that case we also need to get back to the oval point we also need to find a way to better ask questions of an enterprise data store containing posture information such as s wood tags you know the the Oval querying capability that we were using you know was cumbersome there\u0027s there\u0027s got to be a better way to do that we\u0027ve actually proposed a work item to be added to the Charter to work on a new evaluation approach to try to you know work out some of those those issues and then the other thing is something that swimmer doesn\u0027t do today is suite tags contain file hash information so you can you can use that hash information to determine if a given corresponding file on the device has been modified really to determine whether our vulnerability is present or whether the integrity of software on a device has been changed or not you need to be able to use that you know golden measurement in that hash to be able to to check to see if the file has been tampered with we really have no mechanism in the current set of sockem specifications to be able to to collect file information to be able to do that that level of assessment which also means we can\u0027t verify that once the software is patched that the patched files are actually installed so that\u0027s another gap that we should you know consider closing and then lastly most of the orchestration activities that we did as part of this this demonstration the collecting of content from the Rolly server the gathering of software inventory from from the the collecting of the software inventory from the device this was all kind of manually orchestrated within within the solution and so having having a more standardized method of being able to support orchestration would also be be helpful because it would allow us to more dynamically orchestrate these kinds "
  },
  {
    "startTime": "00:18:51",
    "text": "of workflows yeah Roman janay to CMU Dave if you could just clarify the third lesson learned you were saying that you know Swedes have have file hash information and you can use that to look at end points to look at whether things were modified and then you were saying things about well we still have difficulty seeing what their patches were applied can you talk a little ego by is whether whether that the device sort of coarsely says yes I have this the software installed the next step of verification would be to actually look on the device to see if the software is installed so to be able to examine the file system to you know to verify that the software is actually there and that it\u0027s the you know the version of this software that you\u0027re looking for so I think what we were talking about is you know this this demonstrates the ability to take package database information and use that as part of the software inventory but if there\u0027s any Delta between what\u0027s what\u0027s included in the package database versus what\u0027s actually on the file system we have really no way of verifying that and that was one of the things that we talked about it part of the hackathon thanks for that clarity thank you any other questions hello Frank shall we uh possibly I like to say that I like this ho demo because it is a I did ambitions demo because it covers a lot of working group work Maya and the sacrum and I think there are some from Netcom because we need to collect the information for network so it is very good to test a triangle to do end-to-end network security information monitoring and I\u0027m interested about the lesson you learned in this in this end-to-end architecture because York our different work from different working group so so - you feel that currently the working this working group in your in your demo you\u0027ll find out that they are very clear differentiated and they can work work together where we are and is there some overlapping or some some some some conflicts among them something do you have this lesson kind of this lessons well I would actually say that we\u0027re probably we have more gaps so then we actually have overlap and and in this in this solution architecture Hank may have a different view but he\u0027s gonna give an update on the other hackers on activity and that he was involved in I mean we we had to use a lot of proprietary interfaces and protocols as part of this "
  },
  {
    "startTime": "00:21:51",
    "text": "solution so I think what we found was that there\u0027s a lot more standardization work you know that could be done in this space the collector that we used was you know kind of built to deal with more classical kinds of endpoint devices you know like servers and laptops and and and desktops and that sort of thing one of the things that we are interested in to you is incorporating you know more of the Metcalfe and and and yang activity into into this architecture as a way of maybe doing a similar kind of assessment scenario with with network devices you know like routers switches firewalls so I think there\u0027s there\u0027s lots of room for more integration of existing solutions and to into this architecture so I find more gaps than I do you know that I do overlap we didn\u0027t have a lot of different choices as far as you know the other standards that we were using so there I I can\u0027t really think of any any overlap yeah we ran into yeah okay thank you I understand yes it\u0027s a thought the time after so a lot of experiences it\u0027s learning shritha Cisco thank you for doing this this was really interesting work I think you touched about and what I was going to ask if you replace the endpoint with a router or a switch doing replacing Summa with with press conf to pull the single order data and and even the file hashes you are mentioning the I\u0027m a stuff that will also be very interesting to do if and I think that\u0027s that\u0027s important to get it done as well that\u0027s great then yeah so we\u0027ve been talking as a group and we would like to do that as part of the the next hackathon we would like to combine some of the work that\u0027s been done across the two hackathon projects and and that\u0027s one of the dimensions that we\u0027d like to incorporate and I would invite you to come help us yeah sure thank you thank you hi this is Hank and this is no my TCG head on there\u0027s a lot of I\u0027ma related work being conducted in the trusted computing group right at this moment so if we want to delve into it I\u0027m our solution space we most certainly should approach people in charge over there because they are really far ahead with that they are already talking about how do you deal with hibernation and Eimer and stuff so they have problems we haven\u0027t even seen yet right bring visibility into I\u0027m not using the the "
  },
  {
    "startTime": "00:24:52",
    "text": "network management protocols like net contrast count to get visibility of what what was measured on the box is important I think that should happen here creating telemetry what I\u0027m are measured boots secure boot stuff would create an insane amount of data it is not even comparable to what we do at the moment it is not even even its software venturi is tiny the initial person - ima yeah we should move on yes that\u0027s it for me thank you Thank You Hank does he have slides they were just uploaded perfect hi I\u0027m Hank from the Fraunhofer Institute of sexual information technology I sent the same slides you can Colton slides basically diagram again and it is also not readable it is it is the initial plan we distributed amongst engineers to create it\u0027s in your mailbox Adam okay talk so we took the laboratory we took the liberty to a start with um yang based collection which seemed rather unfeasible three years ago for this work group but but it was okay because it was always about queries curing a API for data addressed and current work basically Lia led by Eric white and Alexander Clem which is the yang push and the yang subscribe notification work in net conf we are now able to subscribe to a yang module using our sub trees or XPath expressions and we can do periodic like for example one a minute solicited posts or unchanged pushes um this here what you can read is that we have two locations in the second phone we had these alive machines running in the USA and the People\u0027s Republic of China we connected to the develops and had the second component cyber walks with the slides I will leave the box sorry so we created second components actually as described with the current terminology we have included function into those the standard function for yang push "
  },
  {
    "startTime": "00:27:52",
    "text": "notifications is written in Python and the available open source XMPP code client is written in Java so we of course faces with every haircut whenever interoperability within our components and used in this example only the Kafka bus I said no local cluster running on the um running on the component it is just a hackathon solution was a heck literally so every topic that had to be are filled to be a brokered content in the second domain reaction VP grid had an appropriate corresponding partition in the Kafka bus so we didn\u0027t have to take care of two great invites in Java Ruby and C code actually yeah the result is that we are basically caught address a lot of general requirements of the second requirements document could you just skip to the next slide please there\u0027s a second slide so we addressed this is an excerpt only requirements that were not really discussed before data partitioning of course important because data is coming from through different parts of the world and it is maybe confidential to both souls we retained partitioning until the broker allowed a subscriber to see both so there\u0027s content authorization in place we of course used now finally push mechanisms that can be used with literally every yang module that was having a small opens our discussions then were clear about this and Warren was also there and he was pretty much very happy that we used state of the art NC client library ah software to you it\u0027s basically about push o for implementations a little bit behind and graphed text which is at all seven at the moment I think but there we could do periodic and unchanged subscriptions with XPath and subtrees and it all worked excellent we got net conf notifications and wrap them into a experimental data second model which we also composed in X and V XML xst because net converse also X and XS T was the easiest way to do it I pushed a sub individual draft to the list it\u0027s as an FYI on the second list that explains how we did he use the second information model to broker the output of that yang push stuff yeah g13 is on this list because luckily labor "
  },
  {
    "startTime": "00:30:54",
    "text": "hot link layer link layer neighborhood discovery was one of the modules we could use as unchanged so we can now if we discover you can now do auto discovery due to that because one network equipment can maybe see its neighbors and then we know have a target endpoint discovery and then we can crawl through the topology and find each other piece of network equipment to then assess so this is actually an implicit discovery mechanism of target endpoints and that\u0027s why I listed g13 here I wanted to hide a deck explicitly then it was so kind to add information elements for that a few months ago thank you very much we made use of those so this is my short report on what we did and why we did it because yang modules are actually now in production we used products that are being sold on the market today on both sides of Huawei and Cisco Steven Bing heart NIST I worked on the other half on project just wanted to say really quick that it was really cool to see the applicability of Yang and yang related standards here in kind of the sockem space and that this was really good work I\u0027m glad it got done first of all thank you and then my quick discussion has been about today involved and this was planned with Dave the yang module about software inventory and we discussed semantic overlap or the complement semantic discrepancy between the same name or type of leaf nodes and Yang and I don\u0027t ask me how would you solve it and he after expended two miserable complicated we can do this offline his literal words were like yeah I would do the exactly same thing so he but they were planning for this problem they have no use case for that explicitly selected yet and they see software inventory as a use case to solve discrepancies and overlap vice versa with different yang modules which is a problem if you have two thousand yang modules there will be some redundancy there and mapping this redundancy is an interesting challenge by itself and they want to use metadata augments for that in a nutshell so that\u0027s my record okay thank you any other questions on the to hackathon I think they were very productive um thank everybody that put in all the time to do them so all right so we were going to move to agenda item 8 and our very bruised agenda do we have science for that "
  },
  {
    "startTime": "00:34:00",
    "text": "which ones I think all right so I think over the past couple of days after the hackathon we\u0027d we\u0027ve gotten together a bunch of us and talked about kind of what\u0027s the core the working group that what are the core work items that that we need to worry about in this working group and if you had to add one label each one of those things with one word it would be essentially collection and evaluation and messaging I think we have people who are interested in each of these areas which is positive which means that we should be able to parallel I as opposed to that work and there is gonna be some overlap I think like depending on who you talk to you might hear the word orchestration and messaging go together you might hear the word orchestration and collection go together and orchestration and evaluation go together so they\u0027ll have to be a little coordination between these things but in general we have some some language that we might start looking at as a working group for each one of these items and that\u0027s pretty much as far as I think we\u0027ve gotten so we can look at this language now I don\u0027t know next collection is a set of bullet points Danny and ill and Hank I think were the primary people putting this together is that right yes well but you talked about it didn\u0027t you yesterday okay thank you but you contributed all right sit again yeah I don\u0027t know what sentence that was [Music] so revisiting this the original agenda had this chartered discussion with all of these bullets in it the request at the beginning of the week was we needed to identify what the next steps were for us I think the phrase at the time I was using was three to five documents my understanding and I wasn\u0027t available for yesterday\u0027s meeting was that we\u0027ve come up with three categories we have a list "
  },
  {
    "startTime": "00:37:02",
    "text": "of what those things are I think the next step is the intention is that we\u0027re going to rewrite our charter and not rewrite our charter but refine our charter based on these three steps and those are three steps so I don\u0027t know given the so you do you want to do the one sentences or do you want I\u0027m not sure how easy it is to actually edit this level of charter change in a group setting like this I mean do we I\u0027d like to give what I would like is for people that the key proponents of each of these areas that are going to help us write this text if they could describe shortly at the microphone what each of these are would that work yes and then based on that we\u0027re gonna go off and work on refining the Charter text on the mailing list so collection you would propose Hank so Hank why don\u0027t you share these sentence that you mailed to us at some point in time you can say a few words whew so it\u0027s lesson learn if they would call them and it\u0027s a lot um we collected stuff and our young focused work and we found that getting filter expression to the collector of course seems to be important otherwise you will always get everything if and that the second lesson learned you know what target endpoint to query in which yang modules are available so we have to orchestrate collection with two sets of imperative guidance the first select the VDD how to get the information this would be the filter expressions and then where to target these subscription at which sounds kind of simpler because both are very collection rated but doing that manually will never scale at all first of all do two 800 plus ITF plus I know about two thousand modulates in general outside there and a lot of endpoints so um taking into account that call me and call me pops up might be a thing soon we were most certainly need to create as it\u0027s very lightweight way to orchestrate this is less overhead as possible so can you you said you had one sentence I would like you to tell us what that one sentence is yes we will try to find a way to provide two types of imperative guidance to the correct second collectors first which target endpoints to collect from and second what to collect from this target endpoints been classified a set of instructions such as VDD or en filter "
  },
  {
    "startTime": "00:40:02",
    "text": "expressions can be brokered to appropriate collectors LS detecting classifying beforehand might require orchestrating functions that go beyond the set of capabilities that second collector can provide manually configuration of targets and corresponding collection profiles do not scale and doesn\u0027t seem to be a viable option in the second space well you misled me you said one sentence okay that never mind so Hank just to clarify go ahead then yeah Hanks that just covers beyond uh seeing data models right as one of the examples is V DD yes this is a general collection problem yeah I just want to make it clear wasn\u0027t just yang and that it was other day tomorrow yes okay cool and sorry it just took the other two as examples now that that\u0027s fine I was just I lost track of the sentence yeah that\u0027s right that\u0027s why I didn\u0027t want to read it so so in the collection front Dave waltemeyer on the collection front it based on what we learned from the hackathon we have we already now have two methods of collection that we\u0027ve been that we\u0027ve been working with we\u0027ve got the you know the swimmer based you know software inventory collection we have arguably a much more robust yang you know based collection mechanism you know with with yang push net confer s Kampf would it make sense for us to look at how we can orchestrate across you know multiple collection methods because it seems like one of the things that is a a reality of the current marketplace is that there\u0027s a lots of lots of different kinds of devices that we\u0027re working with and that there are different management approaches that we can use with different kinds of devices different collection approaches and that we need to figure out some way to be able to orchestrate you know across across those yes one lightweight orchestration mechanism for to bind them all yes yeah something otherwise it would be not feasible anymore is that part of what you\u0027re thinking about doing cuz I didn\u0027t hear that and and what you like you just said okay I should have made it more clear yeah but doesn\u0027t mean okay site okay thank you and lightweight is a very important term here yes sir so that yeah we have lots of different ways of collecting right like we might prefer to collect on a Windows environment using WMI you might prefer to collect from "
  },
  {
    "startTime": "00:43:02",
    "text": "Network Devices using comp rest com yeah you know that kind of thing we might prefer Obul system characteristics generation for something else or for this technology over here that has a particular way of doing it we might prefer that I think we look at a couple of these different areas perhaps like individually and then try to extrapolate from those and how we make it generic that make sense no it makes sense in my mind but anyway cool so that was collection right how about evaluation Stephen thank you okay so Stephen bang Hart NIST so these three things that we\u0027re talking about really kind of came from the hackathon effort in the first place the original goal of kind of what the idea of the hackathon was to identify the actual specifications that we could write to fill in these gaps of course I do not have a sentence either I apologize and I\u0027m not going to read it aloud on the microphone I will learn lessons from from my predecessor so one of the things that we identified as a gap in the hackathon and Dave alluded to this when he talked about the results of the hackathon is a way of talking about evaluation in a way that is expressive but not horribly difficult to write and read so for the hackathon what we were using to fill in this gap kind of as a temporary solution was oval definitions and for several reasons we weren\u0027t quite happy with the way that oval definitions worked in the hackathon scenario and so we kind of identified this evaluation piece as a missing gap a place where we could actually write a specification a standard that could fill in that gap and actually work in the way that is most most beneficial to this use case you have to forgive me for my voice it\u0027s a little bit rough this morning but so this is the second thing that we identified as our work items that could potentially be added to or you know as part of the refining process for the Charter update we are thinking as a working group that we could write a standard that describes a language that allows us to describe the evaluation process kind of in the way that all the definitions do something that allows us to actually write out a kind of query almost a way of saying software version greater than this and this or this and construct a statement that we can for example store on a rolly server and be able to pass around different pieces of this system so this work item kind of represents putting together that "
  },
  {
    "startTime": "00:46:03",
    "text": "language that would allow us to describe that that evaluation in a way that\u0027s expressive machine readable but that\u0027s not horrible to read and write because we had some problems with that with with with ovale I\u0027m popular I don\u0027t know if that\u0027s good or bad shree that\u0027s the school how we get the the known good values to evaluate against or is that in in the messaging I think that would be a different part of this this is just writing the this is this this would be a standard for the language that allows you to kind of evaluate against those values but not a way of determining those values in the first place okay if I understood your question correctly but but is there something in the Charter in the collection evaluation messaging where we have specification to say how to get the known good values for an operational Network where which can then be evaluated against what is so you mean like determine what the non vulnerable versions of software are or something like that or process that is running that I want to run on the system and then compare against once I collected so minimally that would not yeah if Hank has an answer go ahead the coast wit spec for us there\u0027s a select draft of the S second book group it depresses exactly that thing we use the swift documents as a reference integrity Menace measurement manifests for every software package of an endpoint you can request the complete manifest and have reference values for every applied software and you for imma you can measure before start and then it would address exactly what you just said it would be a golden or very non measurements the idea is that these are vendor supplied and if they are not vendor supplied you can create evidence text with golden reference templates we have to create yourself in that inside their enterprise which is a huge complicated process but it was also be possible to do that thank you Dave Walter Meyer another way of looking at this is so so in my organization NIST we run something called the national vulnerability database and part of what the nvd does is we for a given vulnerability we analyze it we we try to map that to the vulnerable product versions that are impacted by that that that vulnerability and so as part of writing those kinds of mapping expressions we have to be able to say things like you know a piece of a system will be vulnerable if if software XYZ a version equal to or less than you "
  },
  {
    "startTime": "00:49:04",
    "text": "know version you know 1.2 is is present on the device and a specific operating system is also running on that device as an example because there\u0027s an interaction between the application and the operating system we need the ability to describe those kinds of statements in a standardized way this kind of language would potentially allow us to to do that to allow an enterprise to download that information which I think that we\u0027re calling vulnerability detection data in the vulnerability assessment scenario and then use that to compare with collected software inventory information that was done using the collection and messaging capabilities that we\u0027re talking about today to actually support a more full assessment approach so that\u0027s that\u0027s one way that we kind of envision this working the last sentence in this this text up here is also important because I think what this is trying to say is that the intent here is not to find one one collection method to rule them all but what we would like to try to do is to find a way to do an evaluation approach that can begin to unify various various various collected data from across across different approaches so maybe the point in which we can start to bring you know these disparate views of devices together is is through this evaluation language right and I did leave out that last sentence one of the important pieces of this is that it is kind of agnostic to the mechanism that collected that data in the first place so we don\u0027t have to define one of these for every single mechanism okay Thomas Connell so maybe it\u0027s a kind of confusion on my side because of the way the text is written but I have a slight concern about going into into the field of formal languages and evaluation and kind of I\u0027m concerned about the complexity of the words it is being done here and especially will be extensible enough to be applicable to the full range of collective posture attributes kind of rings are Bell to me and and all kind of triggers a warning signal and I would suggest that we are very very specific about what will be included and try to restrict ourselves because otherwise we can actually both get into into a field where there is a huge range of contributions and probably a lot of prior art on the other hand we may not have as a full knowledge or expertise to expand now that\u0027s right and you know you raise a good point that formal language "
  },
  {
    "startTime": "00:52:05",
    "text": "design is always going to be difficult and have lots of complications to it right right yeah just try and try and keep this keep the description of this as specific as possible what you need yeah Frank Shah from from your from the text written here I really cannot see what is I what work would standard our work we can do further inter interoperability because they are more like some assistant you know insistent design something you need to define some you can even do to the evaluation may be some policy some raw and that doesn\u0027t that might may be may be wrong but my my my initial feeling and the second question is that I\u0027m wondering or I want to know what do you really want to use this evaluation solution to cover how each scope just the cover the current a second walk for example we we already collected the software information and we do the evaluation on our current walk or you wanted to a more general you rather than should work for maybe for net future for the network information collection and attend to the evaluation so what is the scope of this work so honor to the the first question first which so there\u0027s languages out there that kind of approached this similar issue so I mean if you\u0027re familiar with oval for example oval is already kind of this evaluation language right and so that\u0027s the kind of standardization effort that I think I\u0027m referring to is something like that that it that more closely addresses the things that we actually want to do here in sac them which i think is a good tangent into your second question that I think sockem needs to identify things that will work for sockem if it works for other things through extensibility or something else then obviously that is very very good I think I think sockem needs to identify something that will work for sockem but we definitely have an eye on and that\u0027s kind of this last sentence here right is the extensibility the ability to it use this to address data regardless of where that data kind of came from so this is a sac of work item if it ends up usable elsewhere then that\u0027s something that we\u0027re not going to turn down as part of this process okay I see yeah thank you personally my opinion hi this is Hank and to check up on dense comment of oh my god red flag this can be very very complicated there is already a draft in existence in the ITF that it attempts this to simplify the solution it is the "
  },
  {
    "startTime": "00:55:07",
    "text": "I to NSF draft for a capability information model they introduced the ECA model and event condition action policy rule that can be cascaded and there\u0027s even a capability algebra for that that can deduct or add to the rule set an ambiguity in a hierarchy so this is a very simple and powerful tool it is John stress knows unfortunately not on site who is a really excellent expert on this domain had a hand in this so I would give him the benefit of dog that it is quite feasible because he\u0027s the scalable distribution system for like 20 years and so I would have a look at that and not reinvent the view if this is appropriate right yes so if it\u0027s appropriate then it\u0027s it\u0027s something that that would would be good I think that I would be curious to see how that fits into kind of the gap identified by the hackathon where we have some statements stored on a rolly server that we\u0027re dynamically discovering and pulling down a standalone statement with no other with nothing else and then evaluating that against a collected data store an arbitrary collected data store and I\u0027m not sure if that if that fills that gap maybe we should have a direct second interim including John and introducing him to our problem and maybe he is willing if he has the time to give us a simple example how this can be solved exploring existing work is an important part of this work item yeah Thomas come again so I very much agree it\u0027s a good idea to invite the altar and and have a session with him or them just my point to emphasize my point I understand what you are trying to do here and I believe that\u0027s variable and it\u0027s been identified as a gap and and we need kind of an interface that exposes the results and of the evaluation externally I believe that we need to be careful to make at the limitation between the interface it describes of the results can be provided and and read read in in a consistent manner and in the way to do it because there is a way to do it is actually quite a complex area and again we may not have also needed complex learners and needed expertise in this room so if I understand your comment correctly are you recommending that we produce multiple standardized efforts and perhaps one of those is no no actually what I\u0027m trying to say and it may not come very clear is that we need to start with the externals exposed layer and then see what we need to do before for the other layers behind below okay Sheila Frankel nest "
  },
  {
    "startTime": "00:58:12",
    "text": "I just wanted to reinforce what other people said I mean defining a language deciding how to represent it and maintaining that and writing an interpreter is is a huge effort so you know taking a language that exists and has a compiler or interpreter and extending it I think is much more manageable than starting from scratch so agree to one of the things that we actually talked about as a potential direction that this could go was actually looking at ovale and seeing if there\u0027s something that we could improve on and oval it work on top of an existing language and see where we can go with it I think perhaps there could be some some if that if this is a serious concern of the working group we could do some small edits to this text to make it more clear that what we\u0027re doing is identifying something that can fill this gap and if that means that we need to write something new if that means we need to update something so be it but I think as one of the gaps that was identified in the sockem hackathon it makes it clear that this is something that needs to get done regardless of how it gets done so I think we could maybe bash the text a little bit but this this idea of filling in this gap with an actual standard is pretty important for this group to approach in my in my opinion and it\u0027s so there\u0027s gonna be some difficulties and some challenges and we could probably edit this to better reflect what direction the working group wants to go in but I just think it\u0027s important that we get it done I don\u0027t think we need to bash the text now but I do think it\u0027s very important that we are very clear that we\u0027re not gonna reinvent we\u0027re gonna extend something or fill a gap but we\u0027re not gonna start from scratch well unless we need to I would be I just can\u0027t imagine that we would need to so III think you\u0027re gonna get serious pushback actually the serious pushback is moving to the mic as I speak [Laughter] [Music] Kathleen Moriarty ad you really have to do a lot of proving that we would need something new as opposed to working with Yang and all of the other tools we have ants and OVA was contributed and there\u0027s a large number of implementations of that and of course yes I know it\u0027s broken but fixing that is it\u0027s fine pretty you know I know you guys have plans and thoughts about that so something new I I don\u0027t know that\u0027s it it\u0027s not something I\u0027d like to see happen you\u0027d really have to prove that it\u0027s necessary okay all right so messaging [Music] "
  },
  {
    "startTime": "01:01:19",
    "text": "Nancy Kim wins it from Cisco so the titleist messaging but it\u0027s really about defining what I put up here as the control plane functionality as well as the transfer protocols that are needed to actually convey the information that sockem is interested in and I\u0027m leaving that abstract because we\u0027re talking about posture collection as well as posture evaluation as well as the very controlling configuration functions that are needed to orchestrate the flow of information in a secured function because after all we are security so from that perspective I think we\u0027ve already done sufficient work and buy-in to know that we need that control plane function and so putting it in terms of I think it\u0027s already been articulated in the requirements but I\u0027m open in to hearing other feedback so given that we have the role and the functionality already expressed in the requirements what I thought we would do is provide a document that shows the example for such an instance that could help us with that brokering with that orchestration as well as with the discovery so as you\u0027ve already heard ok I\u0027m not that short it\u0027s slowly falling so as you\u0027ve heard in the collection right we\u0027re gonna have many different methods in which we do the collection and so by methods to me that translates to potentially different data models and different transfer functions so how we discover that right and how we articulate the expressions for the actual assessment through the evaluation I\u0027ll say rules for now all needs to be orchestrated in some fashion as well as having the different means from and I\u0027ll say timeliness for now so don\u0027t bash the term Knology of publish/subscribe and query this is really falling so from a also yeah it\u0027s not working from a data plane functionality XMPP allows us to show the example of how we could do both the orchestration through the control plane as well as a transfer a unifying transfer mechanism by which we could do both the directed queries as well as the publish/subscribe and that was one of the exercises that we were trying to prove in the hackathon and I think we were successfully able to prove that point through using a yang as one such "
  },
  {
    "startTime": "01:04:20",
    "text": "example and putting that through the orchestration that orchestration being through XMPP and we\u0027ve got a draft for how that applies in mild the XMPP grid which we could do here as well per second okay let the comments and feedback flow is this gonna be the Charter text as now we gonna call out a specific example of XMPP in the Charter text would this would that limit other possibilities of protocols that we might want to use well so if you\u0027re familiar with XMPP you can allow different protocols in there and different data models if I want to use existing network topology discovery and that network devices become the point of evaluation would would would that work yes so what we showed in the hackathon was and and part of the reason so as Hank showed all the different requirements that we were trying to meet right out of the requirements draft beyond the the separation of data right we tried to show both the push model and the pull model if you will so with the Cisco switch we were using the asynchronous publish model where in that switch we were doing updates of the network topology that was one example the other example was using the hallway switch which I think we were pulling or querying no I can\u0027t remember but it was more static more of a query no it was still published okay but one was more dynamic than the other is my point right thanks so it was using the yank push sorry yeah the same is it so basically the there are typically orchestration yes you mentioned the same thing there\u0027s basically you had you had something already running and you wanted to just integrate this functionality into correctly something that\u0027s already running okay so as part of the messaging are you defining just the model and the message format or is it basically transport is it so my intent with the XMPP is just show how you apply the XMPP protocol to to apply and meet the second requirements and so while we could use yang as you\u0027ve heard in the collection yang is just one instance we\u0027re gonna have other methods and so I\u0027m thinking of sockem is that another level of orchestration for the different collection and evaluation methods right thanks justification yeah you mentioned "
  },
  {
    "startTime": "01:07:25",
    "text": "the data plan under the control plane yes CP but if we if we go back to the the first of our data collection I think of the collection apart already include data plan protocol for example we have a net count right we have not got some pub and the way you use that channel to get message and we have second prong protocol we have the Maya protocol so so I just want to make sure that III producing that HTTP were useful in the controller but I don\u0027t think the to it we are it need to to replace the other dental and I\u0027m not expecting us to have one Transfer Protocol yes yes I expect us to have several I\u0027m just suggesting here from an orchestration standpoint XMPP can offer even in the data plane right a common trends are the real another yes and under the overall control a from a control plane I think XMPP would be an overarching right and others are free to present others as well but we need something to help with the orchestration still on in Stockholm walk I I\u0027m still not clear what we can achieve because currently we just do we we do not deal with Network part country well that\u0027s not quite true right because we don\u0027t have the explicit documents to show you that but part of the hackathon exercise that we did was to show how we could use the network infrastructure to provide the attributes and so one of the drafts that Hank submitted I think was the extension in time we don\u0027t expect yet for you to have reviewed it yet but in the information model we have put in the draft the applicability and how the yang applies and and we expect it to be yes I like I like this way I think if I think the network is where were important the part for the Antoinette so if we miss that part I don\u0027t see that listen I\u0027m completely with you which is why were on and and we\u0027re now gonna put it into a formal draft yeah so would love to collaboration absolutely yep hi this is Hank and I just wanted to point out that is a the solutions are not compete competitive but they they are chained so the um perhaps uppers one two one and the XMPP girl is n 2 N and 2 n bar over and so so they\u0027re not they\u0027re not competitors we chained although right I mean man they maybe put them in the right place and made use of them and the best place so I was gonna "
  },
  {
    "startTime": "01:10:29",
    "text": "say some day voltar I was gonna say something very similar like an example of where we could use XMPP is to transmit a reference to a rolly repository resource which can then be downloaded using an HTTP request this example right yeah yeah and I should have said ok what they\u0027ve sent with Hank said write more explicitly we were using the yang pub right to have the switches publish into the XMPP that\u0027s orchestrating it for second that\u0027s what he means by Janie from jabber Jessica asks would part of messaging of the messaging effort include defining data model requirements for the message messaging data plane okay that\u0027s the messaging people but yes so part of the reason why we spent all of this time and hopefully we\u0027ve passed the iesg with the requirements draft No okay I I thought we had anyway different topic so for the messaging so I\u0027m my expectation and this is Nancy speaking as an individual not just for this is that for the documents that we put together we show the applicability and how it meets the specific requirements that we\u0027ve worked so hard in the requirements draft also this is Hank again hi Jess we they\u0027re the draft submitted today includes a very early experimental data model that might be a answer of multiple answers to your question man everybody got a long queue I\u0027m done all right thank you so so based on these three areas week back to refine the Charter and we will do that on the mailing list one last comment Rita I think Hank mentioned that there\u0027s some work happening for tying these pieces together for collecting evaluating against something that should be collected from somewhere else in IEEE to NSF but I I think in the Charter text at least we need to see how that will fit into this whole system so I don\u0027t see any charter text right now that points to how to collect the information that the known good values that we discussed a while ago that part is not reflected in the text right now we could probably I can bring it up on the mirror and we could yeah I\u0027d like you to bring it up in the mailing list we don\u0027t actually have any charter text right now what we have is the three areas that we\u0027ve identified so we have a little bit we\u0027ve got more work to do there but the other thing I would would also strongly encourage I mean part of the hope this whole exercise was to Hank so part of "
  },
  {
    "startTime": "01:13:29",
    "text": "part of the part of this exercise was to try and to get us to narrow our scope and make some incremental steps and so what I don\u0027t want it to see us do is to take the scope and expand it all the way back out again I\u0027d like to see us have a narrower scope move forward and then you know do the next steps all right that\u0027s just what I would like to see you guys get to decide I guess ultimately but all right so next so what do we so swim Oh what\u0027s next I should be able to so Charles do you know how to start them uh I was thinking can you guys present I\u0027ve only got three slides it seems really complicated so you didn\u0027t request to be a remote presenter I did request to be a remote presenter I can I can try to figure out the interface here okay no never mind we\u0027ll look at it let me find your slides here we come race I can see if I can do it yeah I know I did everybody watching all right yeah Mauro all right so this is just a quick update on the status of swimmer next slide please so a graphic sent out on June 28th it addressed all the known issues this was a combination of issues received during a normative requirements review and also for Monday as Stefan who as you saw implemented this as part of strongswan next slide very short overview of of the slides of the of the changes first I finally fixed the title to what it was intended to be it\u0027s now swim up PA T and C as opposed to Swit PA T and see the rest for a few optimizations instead of having to send unknown as a string if you don\u0027t know the location it\u0027s just an empty field provides some guidance on a couple of the edge cases if you need to report record that no longer is available such as if it was deleted no "
  },
  {
    "startTime": "01:16:30",
    "text": "longer have the deletion record ondrea\u0027s requested that we reorder fields I had changed things so that all the constant length fields proceeded on the variable like fields apparently this was not an innovation that was very useful so we switched the more standard length value length value format and then altered the software identifier algorithm for force wood tags so that when the sweet tag is just identified by its software identifier it\u0027s it doesn\u0027t start with a random number which is its length it starts with some actual descriptive information that\u0027s more indicative of the tag and and made a few other minor typo fixes and things like that so that\u0027s pretty much the extent of the edits you can go online and see the new draft next slide so far I have not received any comments didn\u0027t hear any specific changes technical changes with regard to the swimmer draft out of the hackathon that was certify you think that we were waiting for in terms of of may be seeking working group last call so that\u0027s so that\u0027s where we are are there any questions concerns comments or whatnot on the state of swimmer at this point Stephen Bankart NIST one of the things we did in the hackathon was to test swimmer and see if there were any gaps or things that did not work or needed work in swimmer and we really didn\u0027t find any swimmer worked quite well for what we needed so just wanted to put in my support for moving this draft forward Thank You Stephen any other questions all right Thank You Charles all right Dave altameyer is the plan to move this to working group last call I\u0027m sorry I asked him a question just as you started speaking at him I was just asking a question that the chairs is the plan to move this forward to working group last call I\u0027ve reviewed the draft it seems in pretty good shape how many people here read this draft excuse me oh one okay as Ronnie yeah you will read it okay excellent uh Nancy will read it Bo one just said that he would read it "
  },
  {
    "startTime": "01:19:32",
    "text": "on ever she has read that\u0027s about it okay all right I guess well is there anybody that does not think we should move this document to working group last call all right [Music] terminology Hank hi this is Hank again I\u0027m giving a shot of you or the state of a terminology draft with a lot of with a lot of help of coffers thank you and the next slide as always we do housekeeping we are entangled with the I tunas of terminology draft and so as this at this updated we had to hand a neck problem but we resolved a lot of interdependent definitions and I know way more consistent and by this text a little bit time it is actually a super nice thing to have it in a diamond we also increased alignment with improve the time with 49 49 unfortunately 49 49 has a completely different definition for subject and we were just a workaround for that it reads like oh my god hitting there and so yeah I don\u0027t know maybe not everybody\u0027s will be fond of doing what\u0027s the thing but in this case the subject and the context of circum we have to really make clear that people understand what we try to convey here it\u0027s an information element in second and it is of course a category of other specific terms in the 49 49 including objects and unfortunately also our semantics of an information event moving on target endpoint profile was improved we referenced that from 49 for 9 also targeting point basically for the 9 for 9 is only referencing common criteria here so it\u0027s in direct comment criteria reference and yeah well again remediation of subject was clumsy please help we have a we\u0027ve done the definition somehow I guess at the moment because two years ago we were talking about endpoint attributes and now with the Oval "
  },
  {
    "startTime": "01:22:33",
    "text": "terminology coming and and more aligning with 49:49 it\u0027s actually I think and foreign characteristics it\u0027s also the term that was took up by cheap charter yesterday they were talking about object characteristics an object could be an endpoint in this case so maybe we dropped the old lingo and go with characteristics from there because also attributes are something else I think maybe this is it\u0027s good other races as an issue on the on the github and I think it\u0027s pretty straightforward but I wanted to highlight it so we could be even incorporating teep cheapest a lot of interest in insecurity and talking to the right thing and I very ating it so ii might be one consumer or partner of that at some point also a virtual component was introduced into the terminology i had to talk with bill maher about this they dropped they coming from entity map version 4 and going with harper components there\u0027s a yang module for hardware components but not for virtual components anymore this is a problem benoit asked the second workgroup if we are going with virtual component at some point please do our yang module also we are missing that hard hi Kathy Kathleen we already area director uh chief is not yet a working group Joe do you suspect you know I am trying to help them to become one but um I wouldn\u0027t gate the work of sockem on teep you can reference definitions that they put in later um coordination is good but don\u0027t gate the work this is absolutely correct a gentle to make a smooth path here so if they become it actually that the Charter doesn\u0027t conflict with the other stuff that\u0027s the only thing yes so yeah you\u0027re absolutely right there\u0027s not a dependency it\u0027s it\u0027s just smoothing the way if it is a becoming a reality are you done with the housekeeping yes ok so my other question to the working group would be is there another document this could fit into it\u0027ll be received a lot better in the isg as part of another document I don\u0027t know if that would be architecture and it would get published later at the end of the working group so if you have terms that change then it would be represented there or if it would be in one of the initial documents like the information model or something along those lines and it could even be in as an appendix or as a terminology section every one is more normal than just a terminology document in terms of what I\u0027ve been seeing over the last few years I saw that one coming so I think from semantic point of view the architecture was a bit best play to do it because the old architecture actually had a list of terms just "
  },
  {
    "startTime": "01:25:33",
    "text": "iterated as itemized list and then said those are they find out somewhere else so this would literally be the place where we could put all of those there is one concern that create a 100 pages plus document which nobody would ever then read maybe also it might include terms that exceed the applicability of secure automation and is about well so I wouldn\u0027t be worried about nobody ever reading it because people um nobody reads I except for the people like me who have two terminology document right you you reference it so when you need a specific definition and another document points to it you\u0027ll go back to that specific definition and that\u0027s what you would read it doesn\u0027t matter where it says agreed okay and the the the most references will be from the architecture the second document would be the information what is the architecture unfortunately is not standard but informational I am not sure if this has to be the case so I don\u0027t think there\u0027s any problem with the definitions being informational the definitions by the architecture itself then is also always information I actually don\u0027t know if it is customary to have the architecture as an information yeah 49:49 is informational so and everybody\u0027s adhering to it anyways it\u0027s okay Steven bang heart yeah I\u0027d like to make the case for perhaps as an option moving the big chunk of this terminology either to the terminology section or to the appendix of the architecture I suspect that most of these terms are are used pretty much just in the architecture to help define the architecture and that they\u0027re not really most I feel like most of these terms are probably not used again a whole lot in the rest of the documents and that\u0027s what just yeah right right so so perhaps moving those either into the terminology or an appendix of the architecture will help us kind of reduce that down and then use the terminology sections of the other sockem documents to either I define there or reference out to the definitions that are shared I really much prefer the letter because if you spread definitions across documents you get angry at least I do when I have to always refer it is easier to have them have a one document autom and then used as a co dictionary then have to browse and link I feel like it\u0027s probably even easier to have all the definitions in the document you\u0027re reading anyway so you only have to have one document open always you can merge the architecture and information model I\u0027m afraid but yeah right so my only point was that the architecture is probably a good place to merge this okay thank you so Kathleen Moriarty so my advice would be to wait on publishing the architecture document then until later in the process yeah it could change anyway yeah but we have those "
  },
  {
    "startTime": "01:28:34",
    "text": "minds for the ultimate goal but at point x with your approval we merge architecture and terminology appendix basic oh you have my approval okay I was asking for the working group yeah okay if you\u0027re fine with us I think what are you with you I\u0027ll get your work through and give you guidance as to what successful you guys make decisions okay agreed thank you next slide sorry what is taking so long and there are a lot of new issues raised so we are actually having a discussion on making it better which is really great so chime in on that at the moment we have momentum we thought that we would drop a variation the term in favor of assessment yesterday there was again something basically the opposite so now we have a discussion on going over of that in the list sorry and it should track out please if you have an opinion and want something I want decision on this or if you see semantic difference between those terms write them up put them into the issue tracker and then we can include them if the agrees yeah I want to maybe point out that we will not cover attestation in the circum domain as it is a cross workgroup our terminology problem um so we created an individual draft about attestation terminology where we pulled in general electric\u0027s arm and they have another into a guy that almost says said yes I will also be there because into an arm other both of the companies that provide T\u0027s and in global electrics a global research is the office an expert in Harper of trusts i like 20 years you basically invented that so um all these people are very familiar with Edda station and so yeah I think that\u0027s that\u0027s that\u0027s way too big to get into the terminology drafts a second next slide ah yeah the same thing might happen with events not decided yet yeah I think that\u0027s it okay Thank You Hank Hank I think you\u0027re up next hi this is Hank short even concise our update on concise verse of identifiers it\u0027s moving well next slide we added our first extension point there is a reason for that there was strong demand on having parity between the originals with interoperable part and extensions to that so we have a first extension point in the resource collection type I will come to this "
  },
  {
    "startTime": "01:31:37",
    "text": "later there are now also explicit structures for file hashes and as I have learned from experts in the ISO space a file can have multiple hashes that express the same integrity statement because you use different algorithm to create the ashes I found this astonishing but this is the case so we have to do this like multi-value member now there is also an explicit appendix that will address a problem we just heard before the reference integrity measurements you can have them in single ones or manifests there are specific guidelines how to do this I forgot to put a normative language into there this will be remediated and the swift X cannot express the absolute position in a current instance age of an endpoint so this is a claim you could introduce into a concise with using a standard cut the concise we are talking which are not allows to add claims through other standards with structure XE both structures so these are now explicit appendices through the ice to the coast with draft next slide please yeah I leave a problem the XS T let\u0027s provide by so does not conform with its own normative text language and unfortunately my assumption is there most people download the xst and use it unfortunately it is not the ISO standard and now we have the problem do we adhere with what is probably common in practice like in production or do we adhere to the normative text and break interoperability but with an introduction and and I think that at the moment because the ISO standard is Karen we were here to the text and break interoperability with the current I saw exist e it cannot be avoided I think we understand what they try to express in the xst but they did not manage to do it unfortunately it\u0027s about cardinality most of the time so this is a decision I cannot make myself I will raise this as explicit question on the lists today I will give an example of what how the problem looks like typically and then yeah no answer I will also provide this in the may as a critical concentrate remedy to our if there is no answer assume consensus actually it\u0027s it\u0027s up to Adam and I to determine consent okay so then do do what I would like to see you been hidin but didn\u0027t do it then you have to answer we don\u0027t have to answer you all have to answer and we get to "
  },
  {
    "startTime": "01:34:38",
    "text": "determine the result based on your answers okay and this this one I I don\u0027t want to take no answer as consensus yeah so I think we need to have people to actually to actually answer it it\u0027s not a it\u0027s a big deal I\u0027m not saying it\u0027s not a big deal I\u0027m saying it\u0027s not a big ask okay it\u0027s not it\u0027s not a we\u0027re not asking you review a 200 page document here so I think I\u0027d like you to post your your summary and then we\u0027ll have a little discussion and then either Adam or I will construct a question for consensus okay but you\u0027re right we do need to decide because yeah I don\u0027t know where to start so yeah next slide so we\u0027re still missing a our own glossary of switch attribute definitions these will not go into the terminology because they are basically an equivalent but free weber version of the descriptions from isis so we will use our own words we will not use any are all freely available words that are included in the xst so we have to provide the own context and description of software identities yeah that\u0027s still missing at all there\u0027s nothing written yet yeah the claim stuff is fair still missing and we have to find a partial polish which is including the decision on which lead to follow the text all that exists yeah and that\u0027s where it\u0027d be it for my site a couple good questions how many people have read this draft hmm you haven\u0027t read the most recent version how many people have read a version of this document okay um I guess that\u0027s it you look forward to here I will run away no you\u0027re here oh no I know um we\u0027ll be asking the question again about how many people have read it before we try to move this to work from your last call I\u0027d really encourage people to start reading it this is Hank as a comment from the mic I know of a lot of people from from the ISO and the US government who read it yeah they\u0027re not in the room probably I mean what will get more feedback on the list but obviously ah Steven software I feel blind without my all my back channels Steven Bing heart NIST gonna be doing two things up at the mic right now one is providing a brief update on the actual draft that is "
  },
  {
    "startTime": "01:37:39",
    "text": "here submitted to sac them the software descriptor extension for Rowley and the second thing that I will be doing the chairs have asked me to give a brief overview of Rowley itself to talk about just kind of the basic overview why we have a Rowley extension here in sockem it\u0027s gonna be similar to the presentation I gave in sockem in Seoul but with a few updates to kind of bring it up to speed with the current state of the Rowley core draft so Rowley is a mile specification that I\u0027ve been working on in the Maya working group we\u0027ve just recently pushed an update - o8 hopefully it is more or less stable at this point we\u0027re working on getting it ready - to move forward out of there so next slide please so I\u0027m gonna be talking about and trying to do it succinctly although I have a pretty decent sized time block what what really is why we made rolling what Rolly is going to do here in sockem so we created we\u0027ve started working on Rolly because of this issue that we actually have here in sockem as well that information comes from many different sources for in many different formats and even in many different sea realisations and trying to keep track of all that stuff is often very difficult unless you already know beforehand what you want so if you\u0027re trying to distribute this information with this massive permutation space of all these different factors you have to negotiate beforehand or otherwise know what you\u0027re looking for to go and fetch it from from what you\u0027re looking at and then there\u0027s often this problem and not in all protocols but in many protocols the issue of retrieving historical information as well all these different formats are being pushed out potentially on some kind of publication system if I\u0027m a new subscriber I have no way often of going back and retrieving all this old information next slide this is just kind of an example of that of what I was talking about with historical information with a traditional pub sub model not all protocols have this problem but many do when a new subscriber joins the system they have a hard time going back and finding out all the things that had been published previously next slide I should be looking down here and again in a kind of traditional system where you\u0027re going to go and ask a server for a piece of information given the number of different formats and see realizations you need to know beforehand what you\u0027re getting or else it won\u0027t make any sense to you you have to know that your going and getting a file that\u0027s in is it\u0027s an oval and in XML and you have to know that before you get it otherwise it\u0027s meaningless bits to you next slide Roly hopefully can help address some of those things in the security automation "
  },
  {
    "startTime": "01:40:40",
    "text": "space so Roly is all about categorization characterization and discovery it\u0027s a way of putting information up in a server that can be characterized in a standardized way categorized in a standardized way so as somebody who has no idea what I actually want specifically I can come to the server and I can actually through a discovery process discover what the server has available what formats it has available what information types and categories it has available and start to pull those down and so it\u0027s really focused around this idea of information discovery and information information distribution some of the other important goals that we wanted to really do when we put together Roly was reduce round trips for data retrieval by reducing the bring me a rock problem where one person is just trying different things until they finally find what they want and there\u0027s a decently high number of round trips for a system like that and reducing it to the point where you have a discovery request and then you know exactly what you want and you get it hopefully reducing round trips as well as in the security automation space there\u0027s often particular authorization and authentication concerns in terms of who can access and who can see what information enrollee hopes to address that by granular access controls down to the resource level and ultimately this is a security automation system to help allow machines to talk to machines about security automation is kind of the end-all be-all goal of this next slide please so Roly is actually an extension on atom publication and atom syndication it is a profile of those atom syndication is a syndication format in XML it\u0027s not dissimilar to something like RSS if you\u0027re familiar with that as a syndication format and as an extension of atom pub at a publication in that of syndication Rolly builds on top of those features and can take advantage of things like existing atom implementations so Rolly the other part of the roller solution is really about this extensibility and that speaks to the issue I was talking about before with the amount of variation in the format\u0027s we can\u0027t list them all not reasonably we can\u0027t list all the serialization formats and you just know that as soon as you do someone\u0027s gonna make up a new one and suddenly there\u0027s the you know the new captain proto and the new Chaisson and who knows what else that\u0027s hip and cool and suddenly you\u0027re left in the dust so role is intended to be extensible so in the future you can just register new things in this space and be able to continue working next slide so this is the discovery round-trip system that Rolly tries to focus on instead of doing a bring me Iraq Rolly focuses on a discovery request that allows you to determine what categories and information is present and then ideally "
  },
  {
    "startTime": "01:43:42",
    "text": "your second request is a hit to that actual resource itself next slide same concept with with using this system in a pub stone next slide which is so actually this is what was being talked about with passing Roly over XMPP allows you to do something kind of like this roughly next slide so I\u0027m not going to go into too much detail here unless the chairs would like me to in terms of the actual in-depth anatomy of Roly no okay so instead give a brief overview there are service documents these are the top-level discovery mechanisms this is a structure from atom pub and this allows you to discover what collections of information are available on the Roli feed this service documents at an own look URL so if you have no idea if a host even has a rolly server there\u0027s a slash dot well known registration that allows you to discover this and see what information is present on there Rowley repository next slide the next step down is a feed feeds are just collections of entries which are effectively just information they provide a little bit of metadata about themselves and then a collection of entries next slide next slide the most the final level of Rowley is the entry the entry actually contains a link to the content itself and this is really the most important part of the process the entry contains all of the characterizing and categorizing information about the content so it\u0027s all metadata exposure property exposure this allows you to learn things about the content without having to download the content you instead download this Rowley entry which is never very long allows you to determine if you actually care about the content before you dedicate downloading what is potentially a rather large file next slide this speaks to our extension system and this is actually relevant here in sockem the Rowley extension system allows you to write new documents new standards track documents in the ietf to register new properties categories and information types and this allows you to standardize the way that we talk about different pieces of content so we currently have submitted a extension to sockem all the software descriptor extension and that normatively registers software descriptor information type what that means is it allows rolling repositories to in a normalized way say I\u0027m carrying a software descriptor something like coast wit or sweat so now if I\u0027m parsing through a rolly repository and I find this standardized scheme and value of software descriptor I know that what in that Rolly entry is one of those things which is very useful here in sockem and "
  },
  {
    "startTime": "01:46:43",
    "text": "it\u0027s actually something that we demoed using this extension in the hackathon we held switz in our Rolly repository and demoed using this extension to allow them to be in a standardized way exposed and talked about in Roley next slide oh right this is exactly what I was talking about sigh yeah I was off by a slide so yeah this is what I just talked about ultimately was wit tags next slide I wasn\u0027t trying to rush you along I just was was tapping on my lap no it\u0027s okay I don\u0027t want to dwell too much on this just wanted to give a brief overview so as I said at the beginning this presentation we\u0027ve just published the most recent version of Rolly which only contained minor edits from the version prior so if you\u0027ve read version o 7 version o 8 is not particularly different it\u0027s mostly editorial changes and small edits so if you\u0027re interested in learning more about the Rolly core draft then that is in mile Rolly draft o 8 the software descriptor extension is currently a personal draft in sockem I believe it\u0027s yes so the call for adoption went out for a software descriptor if I remember correctly the I believe that the email went out to lists for that and so just waiting for that adoption process to go through I might be wrong I can\u0027t oh you\u0027re on the presentation sorry regardless I have prepared - OH - version of the software descriptor that contains just really kind of basic updates to reflect the most recent core updates there\u0027s nothing significant so if you\u0027d like to understand this extension you can go and read the software descriptor extension in sockem it\u0027s a draft thing hard parolee software descriptor i think something like that and we\u0027re working on that so that is my overview of that there\u0027s no other updates to software descriptor right now to talk about so i have nothing to talk about there i believe that we\u0027re talking about the next another extension next I think right yeah so I\u0027ll pass over the mic to talk they\u0027ll talk about another rolling extension that we\u0027re doing here in sac while that\u0027s going on I\u0027m bill Munya and I\u0027m going to talk about very similar extension to Rolly that is that\u0027s kind of located here in sockem for configuration check lists no worries rere rere yeah there\u0027s nothing like "
  },
  {
    "startTime": "01:49:43",
    "text": "having everything yeah I know yeah I know this is why I hate being the one driving where the hell is it oh there goes there we go yes we have a zero-zero document there that\u0027s a that folks can review and that\u0027s what we\u0027d like people to do because there\u0027s still a fair amount of comments and things that we need to do you can go to the next slide so the purpose behind this really and this actually kind of speaks to a couple of the comments I think from previously about sort of the known good values that can be used in evaluation and stuff so a lot of enterprises again can evaporate against a control framework and it within those control frameworks is a kind of recommendation to have defined standard configurations for all of their machines in their environment network devices all that kind of good stuff we kind of term those as a configuration checklist for those standard configurations what that checklist defines is a set of recommendations for those endpoints and those recommendations really define the expression of the desired posture of those endpoints or those configuration items you know things like password length you know registry settings things of that nature you know that those recommendations also contain other kind of descriptive information what the recommendation is why it\u0027s there what\u0027s intended to secure expected state of those collected posture attributes could be published by an organization I can only speak personally from my own organization of publishing those checklists in numerous serialization formats a PDF Word docs Excel spreadsheets also automation content kind of XML using other standards oval XD CDF and things of that nature could be supported within the the applicable roli content elements and adding other properties to were kind of speaking towards maybe attribution for those who kind of developed those configuration checklists they could be developed by a consensus process or you know numerous folks it that are given attribution and can be added in and fit into some of those "
  },
  {
    "startTime": "01:52:43",
    "text": "Rolly property elements so again this kind of describes a separate information type for those configuration checklists you go to the next one so things that we want to do we\u0027ve got a lot of comments from Steven so far appreciate that that we need to kind of incorporate into the into the draft there\u0027s a a bunch of to do\u0027s really that we still need to kind of get to and you know finalize those I think before we can ask to officially incorporate it into the working group so please read please review please comment we\u0027ll take any sort of feedback that you want to get just out of just for timing and planning is it would it be reasonable to have the next version like in time for the next virtual interim I was wondering when we might be make trying to ask for it to be working god I definitely think so yeah no by the accident virtual no sure okay it\u0027s not that huge of a draft steven bang heart the myself and the other authors have also been thinking about with dave altameyer have been thinking about putting together a template that would allow for a more standardized form of the roli extension drafts themselves so we may or may not have that ready for the next virtual interim but once that template is ready it shouldn\u0027t be too hard to to put the checklist draft into that into that template format myself just sounds like a useful thing to have actually okay and I\u0027ve got no problems like converting it to a template if you know as a new numbered version if need be it should be pretty easy Dave altameyer I just want to head to that we would love to have your help with creating that template sure because I\u0027m sure you\u0027ve got some insights into what you think is working well what\u0027s not so definitely when I hear those two sure thing okay thanks thank you uh so it\u0027s Charles still on yes Charles is still there okay hold on a second Charles are you still there are you awake I must present heaven are you any more present I am in so native coffee all right go ahead Charles all right so I\u0027m between you guys and lunch so this is actually gonna be pretty quick just one to make you all aware Tristan that were communications architecture 2.0 is imminently out for publication maybe a "
  },
  {
    "startTime": "01:55:44",
    "text": "few weeks but I wanted to let people know that this was coming up so next slide slide two so why why are you interested so TNC trust network communication was the foundation of nieta the to specification suites are compatible with each other or are interoperable with each other and we\u0027ve been using Nia quite a bit in the sack of work so it\u0027s swimmer\u0027s it\u0027s an extension of some of the Nia specifications so basically this this is sort of an indirect but it does it does potentially impact activities of interest to us just because Nia and TNC share this link so next slide so it was we TNC decided that they needed to do a revision of the specification it was actually first published way back in 2005 it hasn\u0027t been updated for a long time and it had fallen out of sync with current use in practice so we wanted to to get that updated and also just do a better job of sort of explaining the utility of TNC the hope is that the way that this has been present presented will will get more people thinking about hey we can use TNC to solve some problems that we\u0027ve got next slide so TNC architecture itself is not a normative document in the sense that there is no in fact normative text within it so with regard to that yay no there\u0027s there\u0027s no normative alterations that are gonna causing compatibilities between the T and C and these specifications what what did change is how TNC was characterized primarily hence the original TNC was very complied to connect oriented about you know doing the evaluation prior to connection and that was that was it we wanted to emphasize the role of TNC is a ongoing ability to to scan an endpoint even after connection there was also some conflation of roles in the original document validation and enforcement roles were were one in the same and and there was a recognition that actually we should we should be breaking those apart we there was also a desire to add configuration management database roles so this there\u0027s already an orchestration capability within TNC and that that hasn\u0027t gone away but in terms of sort of longer-term storage of collected information making that available for for subsequent use that that was a role that god added and then finally we we changed how it was the specification "
  },
  {
    "startTime": "01:58:45",
    "text": "itself was described the original version and if you look at the NIA specification the Neo sophistication follows this was very specification based this is the use cases and here are the specifications that comprise Nia the TNC 2.0 specification looks a little more at okay these are the capabilities these are the sub elements and tries to emphasize that this is a composable set of things that you can use it\u0027s not a you have to comply with every single one of these specifications but in fact you can decide what rules you need what capabilities you need and pick the pieces that you that are applicable to your specific scenario so we try to make it a little more visibly flexible a the original TNC was this flexible but it was sort of hard to tease that out of the specification as it was so those are the main changes in terms of the actual text and structure of what\u0027s presented if you go on slide five so this is the this is the TNC 1.1 diagram and you\u0027ve it\u0027s it\u0027s the five column version you\u0027ve got your access requester that\u0027s your endpoint policy enforcement point then this policy decision point which is both the collection evaluation and enforcement arm of of TNC all rolled into one and then metadata access point as is the orchestration capability so that was that was how TNC one was presented but if you go to the next slide we\u0027ve broken out a number of things you\u0027ll you\u0027ll see on the far right side that now in addition to the metadata access point there\u0027s the CMDB configuration management database which is a separate sort of back-end capability for storage of information you\u0027ll also see that the policy decision point has been split into the policy decision point that\u0027s that\u0027s still the enforcement but then there\u0027s the compliance valuation point that is collection and validation but not necessarily triggering an enforcement action instead the CEP would be a feed to some other to both the CMDB and also to the metadata access point and allow other tools to take whatever action or or do whatever analytics are appropriate so it\u0027s it focuses on collection and potentially evaluation but not the enforcement action and you can see also on the bottom what used to be the network access requester has been split into the posture transport which would be the transportation of of the information but without the enforcement "
  },
  {
    "startTime": "02:01:45",
    "text": "activity going through the network access enforcer so basically a clearer segregation of roles and the addition of a few new roles within the TNC architecture with that moving onto slide 7 the the other sort of main conceptual idea is the breaking out of of TNC into three main capabilities there\u0027s the compliance capability access control capability and orchestration orchestrations metadata access point but also in in many regards to the CMDB the compliance capability that\u0027s that compliance enforcement point that\u0027s collection possibly validation but not necessarily going out and indirectly changing network state maybe leaving that to other tools that are hooked via the orchestration capability and then of course the access control capability that\u0027s that\u0027s our original policy enforcement point so all of these are interconnected but it we we really want to sort of emphasize that hey there\u0027s these three distinct capabilities and you can compose and and select the items that are appropriate to your use case it moves away from the impression not necessarily correct but certainly there that if you\u0027re implementing TNC you\u0027re implementing everything and and we wanted to emphasize that that was not the case so slide 8 so just just a emphasize you know TLC architecture tries to emphasize TNC as a composable solution with lots of capabilities that you can pick and choose from and put together the solution that you need I would argue that in in this regard it really aligns it makes it more clear how TNC aligns with sockem the versatility architecture flexibility topology flexibility these are all much more clearly visible in the TNC 2.0 architecture than I think they were in the in the wand ATO and by extension in the in the NIA specification so bottom line is that this is a fairly important update that TNC will be pushing out fairly soon but that despite the fact that we\u0027re revising this key specification it\u0027s not creating any ink compatibilities with the NIA specifications and and thus with what we\u0027re using in sockem we haven\u0027t bifurcated anything but hopefully we will make the these sort of capabilities that we\u0027re trying to make as a key statement within sockem the serf "
  },
  {
    "startTime": "02:04:47",
    "text": "flexible architecture more visible within the TNC architecture so with that are there any questions about the TNC architecture or TNC activities general any questions anybody where does everyone want to get to lunch sorry Bob I didn\u0027t hear you oh I see you\u0027re sitting in the section that I told people they were I\u0027m unable to see okay so it doesn\u0027t appear there\u0027s any questions thanks Charles it\u0027s a good update all right thank you all right so this brings us to the end of our agenda we have we we had talked at the last meeting about having a hackathon to help focus our deliverables I think we\u0027ve made some pretty good progress towards that I think what we need to have is a mailing list discussion to to hammer out the Charter the Charter update and I think we need to we need some more work to define what our work items are right so we\u0027ll be working on that in advance our next we will have at least one virtual interim maybe two maybe that\u0027s all part of our work item planning does anybody have any thoughts or thoughts are coming yeah yeah Kathleen Moriarty ad so the Charter update we have to do that as soon as possible the iesg has noticed that it has gone beyond its expiration date so unless you have real milestones tied to dates we should leave that out in an updated Charter there\u0027s always a trigger to close a working group so we don\u0027t necessarily need a trigger like that in the Charter right yeah so I think either leaving it out or tying it the only working group that has theirs tied to specific milestones is IPSec me and they do evaluate their Charter and update it annually and base it on adopted documents so if you\u0027d like to take that approach no I I personally would rather not take that up yeah obviously it\u0027s not my decision but it\u0027s "
  },
  {
    "startTime": "02:07:48",
    "text": "it\u0027s not a normal so I think these are the only two working groups that have such a date in their Charter and that one was received better than this one but not that great I mean I would prefer to see I mean I would like to see the Charter narrow it a bit but what I really want to see is that list of work items that my three to five documents which is going to turn into whatever we\u0027re going to end up doing but I really want to see what our next steps are so I agree and having it tied to priorities of the the working group and what you really want to accomplish and get out of this work effort right so to that end can we rely on the the folks who put together the collection the evaluation and the orchestration messaging work items that we discussed earlier today to continue working on those refining those sub part them out if you have to over the next couple weeks I mean you say soon like as soon as possible right Kathleen so like what does that mean does that mean a month from now or like we need to get it hammered out tonight over beer or something August is usually tough I don\u0027t know how many people are affected in this room by um or in this working group rather by August vacations but probably not well okay so yes like some like September yeah September is fine I think with the August slowdown that we usually see that gives you breathing room so that\u0027s our our deadline but there\u0027s a part of me that thinks that it this is not this is not a significant effort it\u0027s the Charter itself I think defining the milestones and that definition the work items is a little bit harder maybe but I think we can update the Charter and get the date out of it pretty quickly great yeah the sooner the better and we get set September as a last last possible date okay I\u0027d say like a week or two into September as the last possible alright so mid-september is when our ad will get grumpy if we haven\u0027t done it very grumpy not just grumpy but very grumpy okay so as jiminee closing remarks yeah closing remarks I just want to say thank you for everybody who participated in the hackathon and you know there wasn\u0027t just this weekend it was planning it and you know attending those weekly meetings that we have and everything I think it went really well thank you for your work somebody\u0027s water okay so I also wanted to thank everyone as well um it shows a lot of effort from "
  },
  {
    "startTime": "02:10:48",
    "text": "the working group in it um yeah it\u0027s a really positive thing to do this work so thanks for all the effort you guys put into it all right anything else well with that I give you an extra 20 minutes back in your day you "
  }
]