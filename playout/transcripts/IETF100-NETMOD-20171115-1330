[
  {
    "startTime": "00:00:04",
    "text": "are here for the net mod meeting then you probably have the wrong room as Lou just mentioned and we do have etherpad and there\u0027s the link on this on the slide or maybe not that thing okay Soph you\u0027re too late I\u0027ll be on the next slide so here\u0027s the note well this anything do you say or do you know contribute in the room it\u0027s considered an IETF contribution please be aware of that as mentioned there\u0027s audio Medeco streaming it is recorded will be posted to youtube later on so make sure you use microphones when you\u0027re speaking and be sure to say your name blue sheets are being passed around the room so please fill in a blue sheet and hand them to other people as they\u0027re walking in we do need note takers do and I will do something they\u0027re taking and our secretary Michael will do some note-taking yes okay if anyone else wants to do some know taking a be highly appreciated attendees should feel free to join in the etherpad I\u0027ll send it in the Lincoln Jabbar in a second and feel free to contribute okay so we have two sessions today back-to-back there\u0027s a break in between them same room fortunately we were able to rearrange or reschedule the room assignment to enable that the agenda for the first session is as follows essentially we\u0027ll go over schema mount and then the ACL drafts and then kick off a discussion on revisions or how we handle yang model revisions in session two we\u0027ll continue going over some post last call specifically the revised data store drafts and then we\u0027ll get into tree diagrams yang catalog module tags draft and then some other not yet working group charter drafts yang data extensions and modeling finance state sheens and the art being muddled okay so update since last meeting we do have a new RFC\u0027s 81 99 yang module classification so congratulations and thank you for that back from is G is the 60 87 biz currently pending an update Shepherd right up we do have a couple new working group documents 72 23 biz and 7277 biz and post last called ducts revised "
  },
  {
    "startTime": "00:03:04",
    "text": "datastore which will be discussed today in the syslog model which we\u0027re waiting for the author to provide an update on continuing with revised working group documents the the ones in green we\u0027re going up today the ones are not in green we\u0027re not reviewing today the only thing I guess to say about reviewing is the enemy mint model sorry the entity model was just updated and the author said it\u0027s ready for last call and 60 87 Biss we\u0027ve received a couple of comments and the implications of one of those comments is going to be discussed under the tree diagrams so that\u0027s gating the the republication of that okay so we do have some liaisons to our working group there\u0027s all right okay so there\u0027s one from the I Triple E which we received informally so it has not yet been formally submitted so we don\u0027t have yet the LEAs a number for it but essentially they\u0027re asking for an update on when we\u0027ll be able to complete our nmda related activities I did send an email to the working group asking for us to just proactively try to conclude on providing them a response even before receiving the official liaison we have not actually had any discussion on that yet but hopefully if nothing else else I\u0027ll make a proposal send it to list and hopefully we can provide them more response also it\u0027s we neglected to put a liaison on the screen from the BBF liaison 1544 yeah this liaison is I think the same thing is Tim in the room yeah did you want to say anything about this - yeah sure if you and all I\u0027d be lays on teeth or pad is Tim Keri Nokia yeah so it was just it\u0027s pretty probably pretty similar to the I Triple E you know with the fact that NMDA is now out there standards organizations are trying to figure out what to do right because they base their base their models like on 7223 and you know the the hardware model and they were all you know state based and they split it and they\u0027re now now you\u0027re bringing them back together again and there\u0027s some guidance in here about whether we\u0027re gonna create state models when we do the nmda models we\u0027ll keep the state models separate and we\u0027ll you know we\u0027ll prefix the module names and "
  },
  {
    "startTime": "00:06:06",
    "text": "so they kind of need guidance right because they\u0027re trying to figure out what to do with their modules because they\u0027ve created state modules as well right so do they just say hey hang on guys we\u0027re gonna go move everything over Tim nmda are we going to ignore you guys and base everything off the state models that were previously there or are we going to follow like the patterns that you\u0027re using for adoption and they\u0027re just looking for guidance to come back how you want to kind of handle that so it\u0027s the likely response once we put it together will be that you should follow the refactoring approach that we\u0027re taking on our existing RFC\u0027s including having the appendix the a stateful version in the appendix do you see that type of response causing being well or see to being causing any problems from the BB I think that if that\u0027s what the answer is I think they\u0027re willing to accept that right I think they\u0027ll be asking they would want to know in the interim you know how long would we be doing like the state model separation that when we produce a model will produce a state model type of thing and I think they\u0027ll also just kind of want to get some assurance that you know maybe this thing is is good enough that we can they could proceed and start converging their models right you know there\u0027s no no new big change coming down the pike the the current of recommendation for within the ietf I would I would be hard-pressed to see that it would be different outside the ietf but one of the nice thing about the recommendations with having this these module the models in sorry modules in the appendix is that sort of is good risk mitigation because you can go down that path while the other parts being developed without any concern about in long term incompatibilities or long term hiccups so we can certainly put together a response along those lines as always we hope that someone in the working group will draft the response we circulated in the working group look for ensure we have a consensus position and then we can send the formal liaison response but even though it comes from the chairs it\u0027s really from the working group and we want to make sure there\u0027s consensus on that okay all right thanks but I think you kind of understand what they\u0027re trying to get yeah absolutely it\u0027s completely reasonable as is on the screen the PDF conversion lost the font so that supposed to be a red arrow be great if we could have someone in the working group prepare a draft response can we see if there\u0027s any volunteers who will it someone willing to prepare a draft response for the working group to review one hand oh we got all right so Michael thank you for volunteering to look for a proposed response and perhaps we can use the same one for both the I Triple E and BB F binoculars so Tim the the problem you mentioned are there "
  },
  {
    "startTime": "00:09:06",
    "text": "valid for any SDO is right so yesterday or recall this week we had like a breakfast meeting with I Tripoli management team and we went the same thing the point is that we\u0027ve got multiple source of information we\u0027ve got like the tool that Rob wrote on converting things we\u0027ve got the freaking ask question as well that the Rob mentioned what we showed you yesterday in Tripoli is that from the catalog I could do select all yang modules were a Tripoli and cedar States so I think that what we need to do is be proactive and contact all the different SEOs in the most project that are dependencies on or yang module and explain what the guidelines are the tool that we have etc the only thing that will be missing in there at agreement is one would be complete in the working group they\u0027re kind of wondering what you mean in a little no I\u0027m sorry they\u0027re kind of wondering when that\u0027s gonna be complete was the other piece of it but then why I will say that that one of the things I know from the BBF perspective is it\u0027s important to them is that you know it\u0027s kind of like they want to make sure that the the state models will exist for a period of time because they\u0027ve got stuff that they just published and then you know they got to react right you know it\u0027s it\u0027s gonna go through the the value that the chain of you know people be doing dependencies and stuff like that so I mean you\u0027re asking about the state modules that we\u0027re publishing in the appendices of various RFC\u0027s yeah so so when we do an nmda we said that we would also do you know or - state version of the thing just long as we keep doing that for for you know a period of time until you know the the industry can get their stuff then reformed up I think we\u0027ll be fine I don\u0027t think we\u0027ve ever put a timeline as to how long we would continue doing that but I assume we would continue doing that for as long as the market needed it right and I think that\u0027s what they\u0027re that\u0027s exactly the answer that I think we that they would like for you to provide okay great thank you all right from a milestones perspective we did complete 60 87 biz but as we mentioned we may have to make a modification to four tree diagrams and model classification also has done the ACL model and into the and in purple these are the ones that are coming you know on track so ACO model into the scheme amount and revised datasource are all on track for milestones the syslog model unfortunately is a lacking I was supposed to be published back in April and I think we\u0027re right now just waiting for response from the author to the shepherd right up and then lastly interface extensions and sub interface VLAN are both they\u0027re a little bit behind but so it\u0027s just a warning I\u0027m not sure if we\u0027ll get them out in December but hope we will perhaps Rob Wilton if you\u0027re in the room if you "
  },
  {
    "startTime": "00:12:07",
    "text": "could give an updated estimate date where do you think the documents will be ready for last call so it\u0027s a revoltin to the interest extensions one I think actually it\u0027s just I need to add examples into that document and then that one I think is pretty much pretty ready to go to work we\u0027ve last call so that one\u0027s not far away the problem one actually is that second on the bottom on the layer the sub interface yang one I Triple E I changed the structure to simplify it and I Triple E had had some concerns with that so I need to follow up with them to check that they\u0027re happy with their with the current structure in terms of how the VR tags are represented so depending on how quickly that goes is is what\u0027s going to control they say is fine then then it\u0027s ready they say no then there be more discussion okay great thank you and with that I think we can begin the presentations can we get some mid takers in jabber to help because out of the discussion right now there are just four lines so I\u0027m trying to help there but we need more people doing the minutes otherwise we\u0027re losing the action items hi good afternoon my name is Harold Kahn I\u0027m going to talk about this schema of this scheme amount draft and actually since it is already past working group Lascaux I\u0027m only going to cover the the new issues that arose during the working group last call and they are these four so when the first one is about prefix and namespace declaration in the schema mounts specification we need it because we use XPath expressions in the specification of the so-called parent references if you remember what it is and so we can use of course namespaces prefixes in those XPath expressions so that\u0027s why we have this simple list declaring just the prefix and URI it was done so because it is really very close to the notion of how XML deals with namespaces that means a prefix and namespace URI but I think Rob proposed that maybe we should add module name because this is what what we have here of course we have a module and the names main name space is uniquely assigned to every module so that\u0027s of course possible on the other hand to have to have both URI and module names "
  },
  {
    "startTime": "00:15:07",
    "text": "it seems redundant to me so another option might be just to drop the URI and use module name actually in in the existing revision there was some mistake that the URI here was optional it it should be mandatory as it is indicated here but anyway the question now is whether our proposal we discussed this with Martin and our proposal is to leave it as it is because it\u0027s not really so important but of course as a second option I would propose maybe to use my new name because it\u0027s of course easier easier to read for human readers so other any opinions on this this is really minor Lu as both contributor and chair given that we have gone to the last call on this unless there\u0027s a specific issue that we\u0027re fixing we should make the change okay down you said their proposal is one yes but then you mentioned the option to you I mention it as my second preference so I would I would suggest to leave it as it is and as a second preference we might consider using the name but here there are no strong opinions I think that we could probably really because it\u0027s it\u0027s why if your main preference is no change then I wouldn\u0027t even go for two because the only place where I would change it would be essentially for the three because it gives me more flexibility for identifying you know as essentially the proper namespace so do suggest to use option number three here well I I would because I would say no change but if if we would agree all to change then I would say go with with option number three okay so so to be clear I think we\u0027ve just heard three comments that say no change is the first preference okay I think we can stick to it it shouldn\u0027t be a problem really second issue is about NMDA support that\u0027s a bit tricky we discuss it with Martin the problem of course is that we can have Oh an in fact we as you know we have the two methods of specifying the mounted schema and for the you schema method this method should just work because you can imagine it\u0027s just some kind of an augment where the target note is specified externally to the module so assuming that augments "
  },
  {
    "startTime": "00:18:09",
    "text": "work with with an amine da architecture they of course shoot then this use schema method should work as well whereas in the in line method there are some problems and some gaps because the mounted schema in this case is specified by some instance data and namely state data so this data is only present in the operational data store and since other data stores like intended can defer their contents it could also be that this state data with the Yang library is not present for example consider a mount point instance in intended that is a part of some pre provisioned configuration for non existing hardware at the moment but it can be in intended but since the resources don\u0027t exist yet this entry may not exist in operational and so we have no place to look for the yang library that that\u0027s that\u0027s supposed to specify the schema so in this case if we put something into intended as a part of the mounted schema for this mount point we cannot determine the schema and so we cannot validate the intended so the rule that Internet has always be valid cannot be enforced here so what it means maybe it\u0027s as Martin suggested in our discussion it\u0027s possible that the use cases for the in line method are so that this is not an shoo but in any case this is how it works and so if the inline method is used it has to be ensured that this simply cannot happen because otherwise you might have problems there are on your example I was really trying to figure out yes we\u0027re in the real life scenario I would have you know such a case yes this is a theoretical corner case yeah it is as I said it\u0027s possible that it will never happen but you know the you schema case is really general so you can use it as as you can use augments anywhere and don\u0027t care about anything in this case it is just this small catch I\u0027m not saying it\u0027s a big problem but we have to I care about this I really don\u0027t see to be it you know to be it as a real-life problem all right any more comments to this if not then I "
  },
  {
    "startTime": "00:21:10",
    "text": "can continue to and ACM considerations access control and the problem here is that of course we can have the an ACM module in the top-level schema but we can also have it mounted under a mount point but we did discuss this with Martin and again with the you schema method we cannot figure out any use case where this could be useful because every client in this case should be able to see the entire tree and so the top level and ACM rules should be used to cover the the entire instance treat to specify access rules and so in this use scheme um I thought this is not an issue whereas again for the inline method it very early use cases and I hope that will confirm where we can have a nation an ACN beta both in that parent three and in in the mounted three so the reasonable rules in this case could be that the top level and ICN rules apply to because in this case in most cases we will have these split management it means basically to that conference servers one further host management session as it is called in in the routing working group device draft and so in this case for the host management session the NAC M rules in at the top level could cover the entire tree both the parent and mounted data but the insane rules in the mounted tree should apply it only to the sort of embedded session which is called a lenny session in in the device draft so because in this case the client only sees this dismounted data tree and so it makes sense be an ACM moves to talk only about this data so in this case an ACM rules of course can only refer to the mounted beta tree and never to the parameter T even though we might have the option to use this parallel fences to somehow make pants data accessible to it but this should be this should be banned by the rules so we have two options here either specify such rules in this document or address these special rules elsewhere for example in the an ICM document or in the next revision of this document our "
  },
  {
    "startTime": "00:24:10",
    "text": "proposal here is to include some simple rules like this in in this document of course this may need some discussion in the mailing list so regard to the knock\u0027em rules from the LME perspective they are really important because you are separating the you know the administrative domains nurse and you are essentially defining who can read what data coming up with the rules in this document will just delay the schema mount and until we really learn what rules would we really need as a minimum I would you know essentially really say put it out in the in the napkin document of those rules will be specified in we can add them for use cases I wouldn\u0027t I wouldn\u0027t try to put them into this one I already know which one I\u0027m looking for but I want to see from some you know real-life experience you know validation or not or not getting validated okay it also make sense because this scheme amount mechanism is designed to work without an ACM so it\u0027s just the next kind of extension of yang so any more opinions and more comments Watson as a contributor and co-chair of the but as also has co-chair of the Netcom working group 6530 sorry 6536 biz is already in is G so if we were to try to put it in that document it would mean it have to be yet another biz that document to be much further down the road blueburger with whatever hat do you see this is an issue for in the NI case it\u0027s not an issue for any case where this you schema method is used which i assume is this case so so so matter it\u0027s good to establish for that the in the base case when you use you schema that\u0027s not an issue because that can inform what we can do here with Ellen II because Ellen E has two cases one case is identical to the NI case when managed equals true which means that that case is exactly the same so it\u0027s covered in the other case we\u0027re managed as false there is no access from the top level at all oh there\u0027s only access from within the context of the end of the lne and that will have its own maqam so it\u0027s a non-issue so I think the fact that this is being raised as an issue is actually a little confusion about how lne works "
  },
  {
    "startTime": "00:27:10",
    "text": "I\u0027m happy to work offline as long as as long as you think that the NI isn\u0027t a problem I don\u0027t think we have a problem here because we just stock them document that the two forms of the scheme amount that way okay so let\u0027s discuss it flying and we will see whether we can we can then come and I may be wrong I may be wrong I may be missing something it\u0027s just quite possible but in fact if in any case there is no access from the parent level to the mounted level it means that we basically do not need any scheme amount at all by right right in that case you\u0027re not when manage equals false you\u0027re actually not using scheme amount yeah so this really doesn\u0027t matter for L\u0026I now comes our note because once you mount actually once you create an Elleni whatever you do inside the elleny it\u0027s it\u0027s you know it\u0027s that one you know owner of the LA elleny so not come for Ellen I don\u0027t see any use case okay yes I just said this is only an issue for the case where we have some we want to have some access from the pantry to the Mountie tree if no such use case then we have no issue at all of course and the last issue that was raised by Rob I believe is about yang library and scheme amount integration and actually it it makes a lot of sense because these two basically define how the over betta model looks like young library gives you the collection of modules that we have and the schema mouth without schema monk they have to be used side by side by side or older all the yang beta models coming from the yang modules whereas with schema mount we can have some some hierarchical arrangement of the module trees and actually there have been already two concrete proposals the first one by myself several month ago and then recently Rob started a new threat which is I believe now in the net conf mailing list that discusses alternative proposal of course this is a bit difficult because it changes it might change young librarian in some way and it would certainly take some time so I\u0027m not proposing to do it now maybe we can just see how things work but in my opinion we have to strive for making things simple because for for a newcomer "
  },
  {
    "startTime": "00:30:10",
    "text": "wants to start with the egg it\u0027s in my view really important that the concepts are relatively simple and it doesn\u0027t help if such a newcomer is told that this was there is because of some some compatibility considerations and and backward compatibility and so on because if it is complex and hard to understand people will not use yang at all and that would be our problem Rob before Rob goes from the jabber room Martin makes the comment on the previous slide and I apologize them for getting too late is that this really must be done in this document and I think I think we\u0027ve established that we will cover knock\u0027em considerations in this document before it goes forward both because of this issue which Martin actually somebody raised Joe Clark raised and also Martin trees raising so I was just going to make the point that tomorrow I\u0027ll cover in the net comp session these different options effectively in terms of what we\u0027re proposing but I guess the families community in a little we can\u0027t hear you sorry that\u0027s but okay so I\u0027ll be covering this the different options for yang library that we\u0027re looking at tomorrow in the Netcom session as part of my slide set there I don\u0027t have an opinion as to whether we should wait or not but it is the case that effect the yang library is open at the moment to updates and we want to get that finished quite quickly as well so the timelines may align somewhere it slows down by a couple of months out of those and actually I made a high-level proposal I think so disclaimer I have to say that this is not necessarily Martin\u0027s opinion but I think it would make a lot of sense really to structure the specific vacations into the documents and document number one would cover some kind of really small metamodeling language meta meaning that the granularity here is at the level of yang modules so it means it would be a combination of yang library describing the collection of yang modules to use and this you schema structure that describe how the modules are combined into the schema hierarchy and second equipment could be the inline case of schema mount and possibly the name scheme amount could be used only for for this case that could yield with special use cases in order to fit to an MVA as we discussed with an ACM whatever but also with questions like configuration and provision of mount mounted data and these questions arise repeatedly on the mailing list because "
  },
  {
    "startTime": "00:33:11",
    "text": "somehow this inline method really invites the consideration of how instances mount mounted and so so and as you could see the inline method has a lot of exceptions we can quite often we cannot do in the inline method what we can do with the you schema method and vice versa so in in my view it would make a lot of sense to do it this way and in this first case this metamodeling language dealing with yang would use it would be a simple concept just how to describe the overall data model consisting of multiple yang modules so that\u0027s my proposal again as I said we can discuss it later and try to do something with it later but I would say this is really important to make things simple and easy to understand given the document is post last call a major reorganization is basically hitting reset do you three think that the problems are substantive enough that we need to do that yeah well I understand but I think that it\u0027s really important to get it right that should be the primary priority because if we don\u0027t do it right then we will have problems later and of course what I mean we\u0027ve talked over this reorganization and you\u0027ve raised this repeatedly over the document lifetime and each time we come back to keeping it sort of the way it is it\u0027s quite an interesting note we discussed this with Martin and it turned out that Martin is only interested in the inline case whereas I\u0027m only interested in the the you schema case so the reason why you have this these problems I\u0027m gonna repeat a comment from Jabbar for Martin and then in Dan will respond so this is Martin\u0027s comment not mine I don\u0027t want to split the document we\u0027ve discussed this before it\u0027s just a split of the content so please ban bogdanovich document as is in my opinion a is good enough to move forward and for us then to try to cover you know the multiple corner cases that are not you know being that I don\u0027t see them being like a real life issue and then to try to reorganize the document to postpone the in the publishing or the RFC I think it\u0027s a it\u0027s it\u0027s a wrong exercise to do and I am as an implementer of you know end up as depending on some of this stuff I would like to get it done because this is good enough for me to "
  },
  {
    "startTime": "00:36:11",
    "text": "use it okay so we will see how it works okay great thank you if you have comments please of course send them to the list I think we\u0027ll be trying to wrap up all the issues and move towards a shepherd write-up and publication which is by the way Kent\u0027s call because as I mentioned before I\u0027m also a contributor in this effort we are running over so just four speakers if we can move a little faster than be great um good afternoon so today I\u0027ll be presenting the updates my Haitian I made for the ACL yang model so the last time we presented draft number 11 and we\u0027ve had three updates since then okay so basically in graphs 12 13 and 14 we\u0027ve incorporated a lot of new match and action criteria we\u0027ve incorporated statistics and also the attachment of the ACL to the interface a list of ACL Stu interfaces and this data has been gathered by looking at several vendors namely the two big vendors that we looked at were juniper and Cisco and Arista so we took a lot of their matches and actions and put them into the ACL yang model okay so one big enhancement is the support for statistics on a per a spur interface basis this is needed because stats can be gathered on a as the packet enters the specific port on the line card we have stats that are collected so this change now gives us matched packets and match octet on a per ace per interface basis in both directions the previous draft did not have the support they had only stats on a per ace basis which meant that a vendor would have to aggregates stats for that ACL across all interfaces it was applied which is really not granular enough the next big change is the application of a excuse me yes the previous one so the stats collection and the Aces are highly dependent on the basic "
  },
  {
    "startTime": "00:39:12",
    "text": "implementation and on some of them you can do that only on the Egret ingress side and on some of them not on many of them you will have also on the egress so in this case you are then sent your trying to put onto something that will not always work on all the Asics so this is an option so what this is saying is that stats can be gathered either on the I mean so so wherever you have the ACL applied you can either gather stats on an ingress direction or the egress it doesn\u0027t mean you have to gather it on both its optional where you have your ACL attached Mahesh it hadn\u0027t done so I think to address a dance comment one of the comments of the Christian provided is that they be a separate egress interface and a increase interface defined that you can that you attach the interface to you speaker microphone please so you\u0027re saying that I would have for the flow one ingress in one aggress and then I\u0027m collecting the stats for this flow through the device what I\u0027m saying is that the attachment point could be either ingress or egress now for stat collection that\u0027s a good question I don\u0027t know the answer whether we can split in and the other issues here is that why didn\u0027t you just say this is a ACL with a counter in instead of separating it out as a as a separate ACL you\u0027re just using them as a you know a match contention just a match condition so in the standard ACL if you use the match condition sorry if use the action counter then you are counting you know essentially the package for that and this is a pretty standard way of it is implemented you know but just using the counters by having a separate statute a CL when when this is done what with the counters um probably we should so take this offline yeah okay okay so the next one is the application of the ACL on the interface so now we can support a list of ACLs on either in either or either an ingress and egress directions so the earlier model the earlier drafts did not "
  },
  {
    "startTime": "00:42:12",
    "text": "have this support okay now you said list of ACLs that means ACL typologies a list of ACLs I mean ACLs with their did your serial applying to one interface yeah so this thing has to be optional as well because not the basic vendor support that they don\u0027t support ACLs on the interface they don\u0027t support more than one ACL for interface yes that is fine so this this allows any number of ACL on the interface but strictly serial you you you you cannot be different apologist except serial ones that\u0027s that that is a pretty hard limitation on some of them you can put them I was just going to suggest that you can put max elements on the list keep speaking microphone please in say your name it\u0027s to say but max elements as a vendor constraint I\u0027m here a deviation max element so we can do that yeah we can\u0027t like that yeah I wouldn\u0027t put in the model I put it in the in a vendor model and augmentation yes yeah we can add that in okay there are also quite a few match and action statements that were added in so one action was logging then we also added the dscp and ecn leaves and we also added the operations to the source and destination port containers so that you can match on greater than less than not equal to and of course the default being equal some of the other matches are adding all the headers for tcp adding all the tcp flags adding the UDP header ICMP and also adding the input interface there after we publish draft number fourteen there was a lot of feedback given by Christiaan which were all mostly very valid comments which are in the process of being incorporated in the next version of the draft so those include so some of his comments deal with the usage of containers versus groupings the way that we do for the "
  },
  {
    "startTime": "00:45:13",
    "text": "input interface maybe we want to divide that into ingress and egress input interface and he had a few more comments on life statistics and the groupings of the different types of ACLs so those are changes that will be incorporated very soon so pardon me John easily a entity you were chasing into the mic really far we didn\u0027t hear anything is better yes so so will your name John with MTT you were saying the different types of ACS you\u0027re referring to ethernet v6 before right yes so there\u0027s v4 v6 l2 and there\u0027s also this concept of a mixed ACL so like v4 v6 together yeah so because because we saw that some vendors could actually support both in the same ACL I one last comment on on the ACL white as a this ACL model is getting fairly complicated and you know all the iterations that are trying to be put into a basic model well you know turn into such a mess with deviations from the vendors that it will be like oh you know what just forget it and you use whatever else there is from the vendor side so if you really want to cover those why not create a basic base model and then create then created the extended models that can cover you know those variations and then the vendors can say which of those variations they will have but it will be the same base model for everything if you will you you cannot cover all the vary all the variations in Asics that are out there even by the same vendor they there are significant differences it will make the implementation so complex and it will it will just be a nightmare quick follow-up point to that as well just jumping in Rick Tony the other end of the spectrum from doing ACLs and Asics is if you\u0027re doing ACLs in a full software stack so I want to look at any 16 bits anywhere in the packet for ACLs so how many young models do I have how many extra and all the officers I got I have four offset 23 offset 58 I think you need to break this down into a core model that can be extended over time or this is never going to be finished this is from jabber from Jeff Hass in order to do a base bottle and extensions you must first know what the expanded form would look like so I think that follows on very nicely with Rick\u0027s comment Mahesh it and I to address them your comment about the base model by the time "
  },
  {
    "startTime": "00:48:13",
    "text": "you actually declare the feature you can make it a fairly base model the way that we do that is you can just declare feature eat and all you will get is an each container and that\u0027s all nothing else in the model that is fine because right now today\u0027s vendors are calling a filter or ACL and they are being differently constructed and you always have to know to do all that parsing if you start with the base model and you say this isn\u0027t layer 2 and an IP and you know just having the very basic one that you can then start from there but if you try to cover all the variations I think you\u0027re getting into fairly complicated but you can should take this off the list in order to be on time ok we\u0027re gonna start with kickoff Maisie you\u0027re actually second alright we\u0027ve had some discussions on yang revisions and we\u0027ve run into a couple of real-world use cases that have ended up with some good discussions in the content of a bist that we\u0027ve planned 8220 to this there\u0027s some in discussions in l3 related to an STL 3sm documents and we\u0027ve also had examples of some solutions coming out in terms of drafts what we wanted to do is to sort of kick off a discussion here here what was the real world use what was the real world experience with 8022 through that adoption process and then go into Benoit\u0027s proposed handling of this in the revision document and then hopefully have some time left in the session to the first of open discussion but the the most important thing for the working group is to wreck it for us to communicate collectively and have some agreement on what the problem is and if we have agreement on that there\u0027s a problem then agree that we\u0027re going to go work on the solution we\u0027re not going to try to find the solution today what we are going to do is make sure we have some good understanding so that we can get some good discussions on current proposed solutions as well as get people thinking about what alternative solutions there should be so the first thing is is that with the current rules in in the in yang specification there\u0027s some very limited types of changes that can be made within the same module and the in order to affect other types of changes you have to replace that module if we replace a module we run into the next problem is that we don\u0027t have any "
  },
  {
    "startTime": "00:51:13",
    "text": "syntax in yang to support tooling to automatically understand what the relationships are between a module that replaces another module and there\u0027s a few other cases that are listed here so where it is our current situation started I want to call it problem but the current situation starts is it starts with number one what our rules are and the rules state very clearly that they any changes in a module any updates to a module must be backward compatible and that goes to both the definition of leaves and structure as well as the presence of those of leaves and structures you can\u0027t remove things you can deprecated but you can\u0027t remove if we want to make any other changes the what the document says what the rules say is we need a new module name the other thing is to keep in mind is is our process inside the IETF remember our resort\u0027 what we produce here are documents and those capturing models our documents allow us to have some metadata that says one document updates another or and that or one document replaces another we know missus we do them all the time right the problem is is that doesn\u0027t show up in the tooling sorry show up in the model to support tooling so what some of the implications we have the real world case of it the l3 s/m where we have basically a broken module that came out whether that was the right thing of the wrong thing doesn\u0027t matter it happened but we - according to a strict interpretation of our current rules we can\u0027t use the same name for the fix in the case of 8022 we wanted to remove some nodes but that\u0027s not allowed so that means we have to change the name but then we run into the linkage problem which is the third bullet if we wanted to support some more complex changes like you do in in source code for example you have a branch that becomes a maintenance branch and you want to make a modification in that maintenance branch we don\u0027t have semantics to do that not saying that is what we want to do but people have talked about using code source code models and apply them to yang modules and if we do that this is a very natural thing that happens with source code and we should think about it and I think we\u0027ve cover really the major points so the goal is we would like to find a solution that allows us to deal with all types of module revisions there\u0027s been some "
  },
  {
    "startTime": "00:54:14",
    "text": "change some some discussion in email there\u0027s been a proposed document we\u0027re gonna hear a little bit that in a moment other solutions as I mentioned before or possible we want to kick this as a kickoff of a discussion it\u0027s not a time we\u0027re not at the point saying we\u0027re saying we\u0027re ready to select an answer we\u0027re saying we need to focus it\u0027s time for the working group to focus on this come up with some good solutions discuss those here now to start and then sorry discuss the problem start in one solution this is a start and then moving forward particularly hopefully at the next meeting we\u0027ll have some documents that have solutions and we really want to try to push forward on selecting the right solution quickly so with that we\u0027re ready for AC and then we\u0027ll hit come back to discussion so as part of the ole NDMA effort where we decided we were going to re spin all the existing modules that followed the split tree with the config and state in separate containers and so one of those was the IETF routing model and it\u0027s augmenting IETF ipv4 a unicast an IP IETF ipv6 unicast modules as well and one for ipv6 router advertisements I\u0027m working on this Lada he was the original offer of IETF routing way back when we were all younger and yang sent he\u0027s also helping out on this I promised can\u0027t I\u0027d go really fast so after this slide I\u0027m gonna go straight to the end so we started out with doing this we wanted to minimize the disruption and the work and start with clean slate so we started out with new naming we had IETF routing to IETF ivb for unicast routing - - and so on just in the same vein as what was done with me of one in May - and back in the SNMP days well this proved to be you know our goal was a clean split this proved to be you know based on input received on the list this was much more disruptive and it was inconsistent what was done for RFC 72 23 bits and RSC 72 whatever the whatever the one is for IP IETF IP interface "
  },
  {
    "startTime": "00:57:15",
    "text": "routing so so and part of the reasons but in wasman has in detail and he\u0027s going to go through it the whole story of the IETF routing and why that broke tooling and everything else that\u0027s that\u0027s in I don\u0027t know how many of you got a chance to read the new yang module update but that\u0027s going to be in this whole thread of discussion on revisions he\u0027s going to talk about that later one thing we did differently because we wanted to limit the implementation cost of this and there weren\u0027t a lot of implementations and deployments of IETF routing we went straight with the that now redundant with revised datastore state trees we went straight to obsolete we didn\u0027t take the deprecated what this allows is it for new implementers of IETF routing and it\u0027s children it allows a much simpler implementation than having to implement all these deprecated notes and like you can look at the draft for this we\u0027re correct we\u0027re in the process of connecting and collecting comments we\u0027ve gotten some good input input from Valdemar and also rob has a pending comment I got to talk to him about one thing it\u0027s we\u0027re going to have to decide is whether or not we need on the imports whether we not need to specify a revision now that we have multiple versions of these modules and that doesn\u0027t that\u0027s all part of this discussion we also there\u0027s possibly also now that we\u0027ve moved along with RFC sixty eighty seven biz there might be some new changes we want to put in to be compliant with the latest version and that\u0027s it oh no it didn\u0027t like it for some reason some kids can ever send let\u0027s just see if this works I\u0027ll just have to it\u0027s not the right one oh it\u0027s the wrong one sorry so Kent how much time do I have I want "
  },
  {
    "startTime": "01:00:15",
    "text": "to make sure there\u0027s discussion after 16 minutes I reduce it okay so I\u0027ll make it ten okay right but I can reduce it I want I want to have discussions so okay anyway let me start talking thanks you for the intro it was well stated Thanks ac for the explanation what I want to do here is show you what\u0027s happening from a tooling point of view I won\u0027t be repeating what was you said Lou and there were things I will skip a lot of points now from a tooling point of view okay yes very good so okay if you get a next slide you know that I try to work from toolings right so if you look at this you would see that this is the idea of rounding in the middle and all the dependent yang modules right so what do you what does it mean it means that if you change this one there\u0027s a lot of impact now if you if you go to the next slide as soon as AC publisher draft is the ITF - routing - - well it showed up in the in the tool right now what it mean it means that someone is committing and I take the role for that as to contact every single document author of the depending draft on ITF routing to say hey there is a new version with a new name and you should be thinking about importing the ITF - routing - - right that\u0027s the manual process so if you look back at this slide it means a lot of people part of the tooling we\u0027ve been doing in the yang cataract we had to create a script to do that it\u0027s kind of automatic in the ITF right we extract from the dependent yang module draft name we extract the author now ITF "
  },
  {
    "startTime": "01:03:16",
    "text": "routing it\u0027s a ITF for your draft sorry for the other yang modules this is a cross as your issues if we look at something like the ITF interface yang module we have like dependencies in I Triple E BB F open config any F Vander etc so does it mean that now I would have to contact by a liaison or process all different SDOs or even the guys I don\u0027t know about to say well change your import because there\u0027s a new module name and and you see things that are even weird like some modules import both of them so from a tuning point of view from a automation point of view it\u0027s a mess alright it\u0027s not a new problem right the open config people came like some time ago and express the same thing now we could say well you know if you go from ITF routing to ITF routing - - well there is a way to do that it\u0027s an RFC header there is like an obsolete or update there but you know in this world of automation going via a level of indirection which is you go from a yang module to the RFC header tag to see if it\u0027s updates obsolete another one it\u0027s a non-starter alright now the source of the problem Lou mentioned updating module section rules this implies that we we have to make sure the yang modules are perfect at least the structure whenever they hit the door in the ITF it means delay now we had like two examples and that\u0027s not a new problem but it\u0027s the first time we see it with two occurrences in the ITF with the l3 VPN module and we\u0027ll ITF routing module the address M was something was somehow different because it was broken so not in implementable but we have to rethink the way we update our yang modules now this could be fine but what is the bigger problem or the angle the operators they want to automate their services so we have an issue of service composition right if we take an Orchestrator we\u0027ve got a service it maps to multiple yang modules potentially in different network elements and wikidot nothing so whenever an operator want to do a service creation it has to know which yang modules work together right this what some people call a release bundle or a package now typically an operator would look at some metadata it come from the same as the O or you know there is like in the yang catalog a metadata called three type if "
  },
  {
    "startTime": "01:06:16",
    "text": "it\u0027s nmda compatible as a value well they should be working together in the end he has to do some testing to create the services and to keep the mapping to the different yang module Network elements the biggest issue is the service maintenance or update am I doing this noise like let me move so the bigger issue is a service maintenance or the update if you for example update a device OS right again if you have dead device OS with new is this one okay if you update for the third time a device source then you might have new yang modules right so if for example you change from ITF - routing to ITF - rotting - - it mean that you have to change all the yang paths for your mapping every single time you have to change your service to update the yang pass this is the the big issue now whenever you get your device maybe because you want to upgrade your service so whenever you want to just upgrade for something different you you might have some non backward-compatible yang modules that\u0027s a fact of life right there are different is a shoe that works with non backward-compatible yang modules there are Native models in the wild so that\u0027s the fact that we have some backwards incompatible yang modules so whenever you update that device what\u0027s happening is that you break your services at least we want to be a that there is like an issue with semantic versioning right that if you would upgrade your device you would have a new yang module it\u0027s ID the same name but you would know that it\u0027s a lag not backward-compatible you would compare changes for your service it affected yes or no that\u0027s the end goal proposed solution is first of all we believe that we have to relax the rules to update yang modules right going from the ad VPN to Anthropy and - - just to fix okay a big issue but one issue it\u0027s an issue right for me turning point of view so we want to keep the same yang module name now we want to mention if a yang module that you produce is backward compatible with the previous version we propose to have something based on semver again proposed by open config some time ago right reuse is permission with major minor and patch I mean we know this in the open world "
  },
  {
    "startTime": "01:09:17",
    "text": "now what we have done in the catalog is an experiment as well right so there is code for that and then we\u0027ve got like two types of semantics there is one you know the open config people they have like semantic semantic versioning extension there we can get it directly and we have got upload the metadata but you know we\u0027ve got also the derive semantics so we use ping - check update from and we\u0027re about to check if there is like some semantics no sorry if there are some syntactic changes which is something different so it goes by comparing the the young trees and telling us if you think that there is something different now it is a perfect solution well not really we were just checking with Jo right now it would not check for example obsolete right it doesn\u0027t support yang one not one for now but we have plans to update the two sets now it\u0027s not semantic versioning right because it means that we have the same yang modules but the semantics behind it is different so it\u0027s not the ideal solution the ideal solution is that someone whenever it creates the gang module will tell us yes its semantics backward compatible or not with major minor and patch so with this approach what do we solve and I think it is the last slide oh no we solve the issue of the backward compatibility compatibility the tool chain works we experiment this with a catalog and most importantly it fits Wells into the service composition because whenever you want to update your service or update your your servers you check what would add what would happen if I would move from OS version X to X plus one you can pair a semantic versioning and we do this in the catalog you compare if the yang paths that you have in your mapping are affected if they are affected you get an issue with your service so as Lou mention it should be the beginning of discussion on which one we want to solve right I like the way that you phrased it with multiple bullets and we want to see which solution fits with those bullets and yes they are like open issues like for example if we go with semantic versioning what do we do with import right right now we don\u0027t use like import by revision or really maybe you want to say I\u0027m able to import everything which is like above major - for example so there are corner cases and maybe we want to have like new naming conventions like having the sender directly into the yang name and maybe you want to tackle a different problem which is modular "
  },
  {
    "startTime": "01:12:18",
    "text": "bundle or package so how the yang modules will work together so I think that we reach in the idea of the point where our modules are kind of used and we\u0027re hitting like the deployment issues so with this I want to leave to a chair to drive the discussion great Thank You Belong let me to stay here to answer questions okay okay I think I\u0027ll kick off with the first question or comment in yang I think currently we\u0027re only able to implement a single version of a module at a time and this works because of the backward compatibility support that we have but now who moved to actually allowing for breakage and backwards compatibility would we then need to for instance support multiple versions of module to enable both backwards compatible view of the legacy version and also the new version in a server on a typical router I\u0027m done think so but maybe in an Orchestrator or controller where there is like service composition coming from multiple network elements that might be the case yes as a follow-on is glue one of the things that we\u0027ve been trying really hard to fix with yang is the problem we have with CL is where when the version changes on the CLI on a router all of a sudden the user has to change their tooling I think we\u0027re at run a risk of repeating the same thing here if we don\u0027t allow a server to export both the old and the new and allow the user to choose what they use if we you follow what I\u0027m saying yes and no we could export multiple who wants library but only one could be implemented now you want to give the choice to say ok I\u0027m exporting new one and the old one you could you could advertise them and you expect that one controller or one Orchestrator will say which one to use but if you\u0027ve got multiple ones exactly you\u0027d want to support multiple so maybe this is it this is a consideration to think about is when we have to be careful here because if we\u0027re not careful we\u0027ll end up repeating the same problems or reintroducing the same problems we\u0027ve tried to get away from yang think about it you have a customer that has a deployment there they have some news that they have some old software and they have some new software they want to be able to keep the old software running and they upgrade your router but they also want to be able to use the new software yes maybe on a particular session you would only use one version and you know that might be "
  },
  {
    "startTime": "01:15:18",
    "text": "the compromise but you would want the server to be able to support both the old and the new understood is this an issue which is introduced by this proposal it is because in the current requirements you can\u0027t have it because you\u0027re always backward compatible it\u0027s just not okay so it it we\u0027re not trying to poke holes we\u0027re trying to say let\u0027s be careful and think about understood yeah good point first of all I would like to say that I support this effort it\u0027s it\u0027s been missing for long times and something like this you are proposing and second I believe it would be useful to move the update rules away from the specification of young the language and maybe define them in the in December draft just to say what what changes what updates are possible within one minor version and so on because I believe in the definition of that beta our modeling language such a policy really has no place because I can imagine that some groups may use yang even with slightly different meaning of the versioning rules so so I\u0027ve been arguing against these update rules in 7950 for a long time so that would be my proposal to really do it now and move it away so lada clarifying questions so actually assuming we we have this an extension you would like to have your bitch who\u0027s telling that are in such document telling with that extension that the rules are the follow I agree that we have to something with the import statement so this has to be done in in the yang specification certainly but I\u0027m talking of all the texts I think it\u0027s section 11 or something in 7950 that talks about an update of whom or you cannot do this and can do this so I think this is some kind of policy that different groups can use different policies perhaps and this really doesn\u0027t belong to the specification of the language itself by Daniel Erickson I have wrote a quite long mail about this yesterday just some of the main points from this first of all I strongly disagree that we can\u0027t make incompatible changes today when you obsolete or deprecated any data node then you are not mandated to implement it anymore so you are you even today we allow to remove complete sub trees and keep the model module name we are noting the roots already broken so the rules are already broken yes yes your "
  },
  {
    "startTime": "01:18:19",
    "text": "mischaracterizing the rules right what the first stage is and I get these backwards I had you deprecated first and there\u0027s an expectation that deprecated is used to support a transition period and then you end up with obsolete where it\u0027s removed but well during the deprecated you\u0027re not supposed to use it but you\u0027re supposed to implement it alright don\u0027t remember the exact phrasing but it\u0027s a transition period so you know we have the notion of a phase-out it\u0027s not an immediate removal and that\u0027s part of the reason for bringing up the 80/20 to comment is is that we went at to 80/20 through this is we went immediately to immediately to removal and that is was a sort of an exception and that\u0027s why we wanted to highlight it sorry I disagree if you read the exact text of the yang 1.1 standard it allows you to remove deprecated nodes don\u0027t have to implement deprecated yes okay you already allowed to remove those notes but even obsolete is allowed by the update rules which means that you can remove those notes completely so an OSS an Orchestrator cannot depend on these notes still being present second I think you\u0027re getting into what is strictly required and what is implied it says it permits new and continued implementation in order to foster interoperability you know so there\u0027s already a notion of a transition period in the rules it\u0027s not quite as kind it\u0027s strongly worded because I just read it I know but the strongly worded because it doesn\u0027t stay that you must still implement deprecated notes must keep the implementation you\u0027re allowed to remove it the other main point is that first of all I very strongly support this work we support it in Ericsson so strongly we implemented it ourselves for Ericsson this is also a big problem for OSS for any network management software so if I get the device with the newer model can I still work with it like I did with the old or is it dangerous because there are unknown changes said I just stopped my software here as well so this is absolutely needed there are some more details that I could be happy to support I also feel that this bondwoman package could handy handled separately but I don\u0027t object of being it here I would agree with your last point somehow we open this with a draft tooling we see this issue by the way we knew it for two "
  },
  {
    "startTime": "01:21:20",
    "text": "years right and now we start to just and we just got this also there with the yang doctors that we wanted to open discussion trying to see which four we solve so I I agree with you at the notion of bundle maybe it\u0027s not part of this also we with our own solution which is very similar to this one we had many cases where the model exactly didn\u0027t exactly change but the behavior expected by the model changes so manual assignment of these semantic version numbers is is needed sometimes and also I propose that for every yang revision statement a mandatory sub statement at least for new models to have these semantic versions and to come back to another point you made I know one of our own MSS I mean they just put instead of having the yang name in the OSS they put yang name and this revision next to it as a single new string tricking the the - it\u0027s a new it\u0027s a new yang module because we\u0027re not sure about some semantic versioning one more point is that prefixes are also very important we like to think that we have the namespace the module name who cares about the prefixes it can be exchanged any time no prefixes are stored both for instance I identifiers both and identity references and also in human conversation we very often refer to more use with their prefixes yang glib is common reference in emails and other places so if we update something to yang library - - will we keep the prefix or not if we change the prefix we have the item data migration problem because we have to go and find all the stored updates in the file system of the operator and change the prefix there as well I have two comments from jabber I\u0027m gonna actually go out of order because Martin is responding + us and the comment he has is that a server is always allowed to remove support for a module on a new software version so we have even a bigger compatibility issue with that are potential cab backwards compatibility problem thank you more coffee please yeah but of course an a vendor would be sort of foolish to remove something that\u0027s used by their customers that was comment number one now from Jeff Haas oh by the way the the commented that one at the end was mine not Martin\u0027s from Jeff Haas the issue is somewhat analogous to the issue of multiple modules managing similar information for example the BGP module which we have open config and one still working through IETF I\u0027m actually "
  },
  {
    "startTime": "01:24:20",
    "text": "trying to figure out how that relates but I have to it was a comment on your presentation earlier maybe did you get formed perhaps maybe about having multiple versions supported basically structural mapping okay Rob Wilson Cisco so I strongly support this unlike this idea of doing semantic versioning I think that change you how to change a modules name and the prefix whenever you ought to do a major version change is a real hassle for everyone involved saying don\u0027t think that\u0027s the right solution I also quite like to lose point that he made on earlier on about the fact that you use github develop these modules and want to put patch changes and things like that again the semantic version version here marries to that quite well in terms of how you naturally manage this um developers are also very used to using this sort of version scheme so it\u0027s not like it\u0027s a brand new scheme that people don\u0027t understand it\u0027s a scheme that\u0027s well use in the industry seems to work it seems to be well understood I also agree that the the suggestion that import by revision effect needs to be fixed I\u0027m not even sure that the one today is actually that useful it seems to constrain in the wrong way or where you can\u0027t necessarily actually use use it in the way you want so I think something along the lines of you need to say I want to only port this same major version number probably seems likely so I think that\u0027s useful one last comment I\u0027d like to make is that perhaps the issue that came up about having to support two versions of the same module in terms of upgrade ability could that perhaps solved by you configuring on the device which which virgin you want the device to provide I\u0027m meds allowed to different clients both to access the different versions but it does allow the some control of is to which version it\u0027s going to export the issue is always same one for an MS what about to a nemesis right yeah they are mocked on which the other thing what I would say I concur what Rob said and also what Lou said and I support this work he said everything well actually in generics on one more requirement we have on all this I want to have a Yank name and the simple statement like the semantic version just reduced those two lines and understand whether the module is really compatible or not so without a full check for the status statements so you want to have the same verb part of the yang name not necessarily just that reading the same way the very same where and the name that\u0027s two reading two lines I don\u0027t want to make a full comparison of the model to find out what is it right reading these just these two statements "
  },
  {
    "startTime": "01:27:20",
    "text": "that\u0027s fine right so let me understand this because I couldn\u0027t have multiple ways so you would like to have an extension not on in December but like the module name semver that could be one way which could solve a specific issue that you don\u0027t want to bring but maybe we want like let\u0027s pretend there is an ITF VLAN yang module right and we do this as a temp solution while yeah Triple E does that the real one so whenever you actually will do the real one was a different you are n was a different module name maybe you want to stress that point that I did I Triple E yang module update the idea that module seven eight now extension you are an module semver but maybe I\u0027m going too far because I think your solution what you have in the draft are just having a sandbar statements somewhere I think that\u0027s enough for me okay from jabber from Jeff Haas the issue isn\u0027t necessarily two versions of the same module it\u0027s the blast radius effect you update a major module you have to upgrade the entire ecosystem regarding to the prefix issue that Marsh mentioned I just checked the specification for the IANA yang module registry and it only says that module and sub module names and namespace here I have to be unique so I think not nothing prevents us from reusing the same prefix or modules with different name I don\u0027t know if it\u0027s but it in some cases it might really be useful and really I and I should accept such a registration without any problems and I think it\u0027s part of the you know I just want to clarify what you say you\u0027re saying it\u0027s okay to reuse a name okay and I think this is part of the the thing that we have to decide right we\u0027ve been listing multiple problems already like the update like the semantic versioning like the urin like the package it would be good to agree on what we want to solve right and maybe we do this in sequence but in the end what we\u0027re trying to solve is like the the deployment on those yang modules seriously good thing ro Bolton so I\u0027m one columnist earlier actually it was about packages and I think we need to be very careful with packages similar to Jeff has his comment that we don\u0027t want to type the couple lot of particular versions together such that you can\u0027t if y\u0027all have to upgrade one module you end up and upgrade the whole lot I mean you look at the Linux packaging system that it seems to work very well where you mostly can pull in particular packages "
  },
  {
    "startTime": "01:30:20",
    "text": "and upgrade some of them as you want so I think we need to be very careful with inside of this that gives us great more more flexibility and how about great things and I would agree with that because most of the packages I mean mine are service oriented and your service is of my service is not a different service so in the end whatever we\u0027re going to send yet yet that they work together this could be resolved with like metadata those are all the set of nmda compatible yang modules those are all the ones that are precious RFC\u0027s and and then depending on what you care about you will pick the right values in the set of metadata that we\u0027ve got as opposed to us telling for whatever service you could think of this set will work because after some time the services will evolve and it will not work any longer I think you\u0027ll find a way out today as soon as you\u0027ve published it there be maybe another module in updated as soon as it\u0027s done I mean yeah well enjoy Ericsson I think for me at least the two main root problems are one is that I need a small bit of information like the module name combined with the semantic version that tells me if this version of the module is compatible or not with the previous one we don\u0027t have this today this would provide us the other one is I want to be able to find out that it\u0027s compatible just without comparing the full modules and and also the other big problem is that we want to allow some level of incompatible changes the routing and some others stated yes they should be indicated clearly by December or some other way but sometimes keeping the name and the prefix and namespace and still doing incompatible changes is needed so find out easily what is compatible and sometimes allow limited incompatible changes these are two problems for me which could be described like in the minor of summer for example the rules would be different well if you\u0027ve got like major or minor or patch it\u0027s what you\u0027re talking about by a small backward comfortable changes I think we need to revisit what we mean by small and backward compatible I agree with other that yes--that\u0027s needs a full document and I would say that we need to revisit that so the end if it\u0027s okay can I okay thanks we actually are a little over so it would be good to try to wrap up this part of the conversation we actually could go 20 minutes into our break time "
  },
  {
    "startTime": "01:33:21",
    "text": "but some people may want cookies so I\u0027d like to we\u0027d like to try to wrap this up we think the most important thing is is that we agree on the problem rather than the specifics of one solution because we as a group really haven\u0027t spent enough time thinking about solutions to think this is the one solution we\u0027re going to follow or if after when we go back to go back home and have some time to think about it we come up with something different so it would be good to make sure we agree on the basic problem definition and like everyone take a look at the screen for a moment I\u0027m not going to say we spend a huge amount of time coming up with this so if we think that there\u0027s a better formulation we\u0027d be happy to change it but is this close enough to capture the problem space we\u0027ve talked about yes we know that on certain solutions that it we may have implications that are not captured here but that\u0027s that\u0027s a solution problem not that\u0027s not a problem definition I\u0027m uh microphone please was this a call for a vote or for a comment no comment is a call for comment so based on not hearing a lot of discussion on this while we had a lot of good discussion on a specific proposal I\u0027ll take it that we\u0027re close enough here to have some agreement that this is a problem that we as a working group need to solve there\u0027s no polling on this do we think it\u0027s a problem we\u0027re saying this is a problem and we must solve it at this stage we\u0027d like to ask the working group to think about solutions proposed alternative solutions if you have them discuss the solution that has already been documented and let\u0027s do this on list I would expect although we haven\u0027t figured out Tommy I would expect that given the importance of this discussion we\u0027re likely to have an interim on it before between now and 101 although we\u0027ll have to of course be sensitive to the holiday period that\u0027s coming up final comments we have three people come up this is just a problem Congress ooh excuse me Thank You Lou I appreciate you reminding me sue hair\u0027s in this hat properly are to us no not artis IDR I\u0027ll get those letters out i sat there and thought and so this is a clarification question but well we often have augmentations to models are you tracking the augmentations and how they go back to another module is that the catalog sue I\u0027m sorry I don\u0027t want to get into more on the specific solution here I would like to take that to the list that was a problem question not a solution I have no desire to "
  },
  {
    "startTime": "01:36:23",
    "text": "specify a solution for this okay I\u0027m sorry okay problem we have extensions to BGP functions which may themselves say if the base model and you have an augmentation model that reflects that may Rev itself do the is the catalog able to handle that portion or data log as a solution in terms of this problem that we have is he absolutely have to cover augmentations okay no commentation that tracks okay yeah we absolutely have to make sure that whatever we come up with covers augmentation I\u0027m sorry I missed Martin and Q so I\u0027m going to repeat I\u0027m gonna know he\u0027s here jabber uh-huh so he\u0027s responding I don\u0027t know it\u0027s Mike\u0027s he\u0027s responding to what\u0027s on the screen he says by design and I agree that to is correctly stated so we have Martin Dan and then we should close out and maybe still have time to go grab a coffee or so I just make very quick comment is I think that probably be helpful this covered the import issue as well fixing imports I think that\u0027s part in my opinion s part the problem statement okay so import should be included absolutely yeah when we are working on this we should make sure that the restaurant and the your revision will be the same because the rest supports versioning of api\u0027s and then we could you know essentially make sure that the API versions are compatible you know where the young versions yeah I think others I\u0027ve said this before at other context whatever we do in yang has to support any protocol underneath it at this stage so whether it should it should support Netcom press conf whatever comes next doesn\u0027t matter it\u0027s got to support them all so yes we have to make sure that it\u0027s accommodated I\u0027m gonna go to Jeff and then response to suit in response to sue most of the big items are likely to be augmentations with a feature statement so that\u0027s from Jeff pause sorry BGP I can\u0027t leave better glasses that makes sense I would like to come back to a point and maybe that\u0027s important for multiple reason because we for example discuss on one of the documents thus Luke does all the solutions here imply that it\u0027s waiting in direction of keeping the same yang names I order I think I think we that should be a part no no I would like you to ask a question now sorry so I won\u0027t to understand if all "
  },
  {
    "startTime": "01:39:26",
    "text": "the possible solution we\u0027ve been discussing and maybe they were more always imply that we want to keep as a goal the same yang module names for a tool path for a tool chain issue so so one of the solutions you talked about was actually bringing the version into the X into the path and is that the same name where is that now a different name I think we have to discuss the same context of the specific solutions we want to minimize impact to the community into the implementations but we really have to talk about it in the context specific solutions we are 10 minutes over on the discussion if you know we all want to give up the break I guess we could go another 10 minutes okay we might lose our microphones first okay so I guess that\u0027s it then we should turn it off person hold all right thank you everybody we\u0027re going to take a 10-minute break see you and see you back in this room in ten minutes thank you "
  }
]