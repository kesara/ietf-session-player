[
  {
    "startTime": "00:00:05",
    "text": "Thank you all right it is now time by the clock on my laptop, so let's get going We have a fairly full agenda Welcome Please remember the next well. These are your responsibilities if you're going to contribute If you can't fulfill these responsibilities, please don't contribute contribute Remember the code of conduct. Please treat each other with respect. It's okay to an attack an idea. It's not okay to attack a person with the idea Meeting tips If you're here in person, please use the online tool. We will be using it for getting in line for the microphones. It also automatically does the blue sheets If you're remote, please don't use your audio or video unless you're in the mic line and the one at the front That way the bandwidth works out better for everyone and headsets usually help So this is the agenda we posted. As I said, it's long. 11 items here, 10 of which are about presentations Any agenda bashes? job snijders Fastly In the most respectful way, I want to express a little bit of disappointment with how this agenda came to be and encourage the chairs to do"
  },
  {
    "startTime": "00:02:00",
    "text": "better at the next meeting by, for instance, issuing a call for talks Thank you. Yes I think all three of us acknowledge that we need to do better going into the next one, and we are tried to put some processes amongst us in place to make sure we do hold us accountable to actually achieving that next time Thank you. All right let's get started with the first draft Tim doesn't actually do that. Yeah, it doesn't say next slide Yep Oh, hi everyone um so i wanted to talk about the um i document about a best current practice practices for running a publication server Next slide, please If you watch the mailing list, you might have noticed that it's now adopted Adoption call started a while ago, actually Some comments were received Recently adopted, a new version has been uploaded just now. I assume everybody got a notification of them after Chris said, please do do There is some stuff in our edit buffer coming shortly, but I'll get to that in the moment Next slide First, I want to very briefly do a recap of what this is about. The scope of this document is really about, yeah, running the publication server If you, without going into all the gory details, certification authorities in the object can use a publication server as a separate logical thing, let's say. It could be integrated but yeah, logically"
  },
  {
    "startTime": "00:04:00",
    "text": "it's a separate function. I'm using the RPA 8181 protocol for publication then the publication server is responsible for publishing the actual content sent to it by CAs and making it available both over RADP and R-Sync which is then retrieved by relying parties So the highlights of this document we talk a bit about 8181 mainly to point out that there's a different impact in case CA cannot update its content as opposed to relying parties not being able to reach it content. But I think improvements to the actual protocol and I'll get back to that in the moment as well, are most likely out of scope for this document because we're dealing here with what we can do currently. Next slide, please RDP, so key findings, there's more in the document. I encourage you to read it But one thing that is very important is that you need to ensure somehow and we go into details how that the notification file is only made available once the Dell and snapshots files can also be retrieved In particular, there is a bad feedback loop. So, RDP in general actually doesn't use this ideal circumstances, uses less data than R-Sync transfers, mainly because of compression over HTTP But there's a very bad fielded loop because if relying parties cannot retrieve certain delta files then they're supposed to get the snapshot file, and if they all start getting snapshot files then you know it gets worse So, advises provision for this or use the CDN if you can Next slide. Just 10 minutes Quick highlights for R-Sync R-Sync has other challenges"
  },
  {
    "startTime": "00:06:00",
    "text": "In particular, if you want to make a consistent set of data available to relying parties, there's a trick you need to do, well, the best trick that we know of is to have a sim link to a directory that contains all the current information and use that for you Rcing module Some other things like setting predictables time stands to retrieve, avoid retreatings files um yeah I don't want to get into all of this because of the time But, you know, just giving you the overview. Next slide, please Oh, yeah One more thing. We talk about this briefly in a document as well. As you may know well, the RARs provide hosted options services with publication for their members and some NARs do as well And by far most people out there use this but you can also use your own delegated RFCA, and you can then choose to use your own publication server as well And there are definitely use cases where you need to do that currently especially if you want to delegate further down but in general it's probably recommended to use one of the publication servers provided by the RAR or NARs, if you can Yep. No rushing forward, what is in the pipeline for nine next revision? Well, there are some nets. They're not that interesting, I think mainly typos on clarifications one thing that's still missing is what to do in case your publication server, you know, you operate a publication server. It goes down completely, and you need to do a restore from backup. There are some nasty corner cases there that actually also need to discuss with my course a bit more before providing new text But yeah, obviously you really, really try to avoid this"
  },
  {
    "startTime": "00:08:00",
    "text": "but yeah, okay, reality might be that you cannot The problems here are another couple So relying parties may get confused if the RTP serial regresses or if the hashes change. Yeah, you can solve this by doing a RDP reset when you do it restore. But perhaps more painfully, the content of certification authority may also have regress and they may think that they have a manifest that's perfectly valid for another 24 hours, whereas the one that's, you know, that has been restored is only valid for five more minutes or less And there's no way that the cervac can tell the CA to come and re-publish. So I just need some thoughts and some more discussion, I think Like I said, likely out of scope are things that we can do in the RC-881 protocol to improve this. It would be great to look into that But I don't think we can do that in the context of the best current practice document So parking that for now and next slide, please What I want to drive that is I'd like to publish that as your one version of the document discuss and then prop drive that is I'd like to publish that as your one version of the document, discuss, and then probably go fairly quickly towards the last goal If you have thoughts on the publication server restore in particular, then I'd be very happy to hear them. And yeah any other questions, comments? comments? Sonia Online, your previous slide said quotas and quotas enforce were out of scope"
  },
  {
    "startTime": "00:10:00",
    "text": "Your previous slide said that quotas were considered out of scope from your perspective That seems to be a fairly obvious topic for this kind of thing why why is the plan not to talk about What I meant to my intent for this slide was to indicate that there's many things that we could improve on, like we could think about quota, we could think about servers checking that the content actually makes sense parses or is even valid And I think those are very useful discussions to have but if you would enforce that currently you don't if you enforce that currently, you don't really have any good way in a protocol to communicate any error And there's no way really for C.S. to do anything with that information, because they just get a general error And that's why I don't think we're ready to go there So probably best left for an update to 8181 I think so. Just one other brief comment about the guidance for publishing in Perent. I think the guidance for publication server operators is to why that's a good thing for them to do is certainly something that this should contain I would steer clear of guidance to issue about why they should do so, simply by because I don't feel like this is a document that's likely to get read by this audience, and so that guidance has do so, simply because I don't feel like this is a document that's likely to get read by this audience. And so that guidance, I think, will largely go unnoticed and may, as a result, not show up in a better place down the line I agree that the guidance is good. I just don't think this is where it should be Well, yeah I think it should also be in other places but I don't think it hurts to be included here as well Hi, Nicholas Vogel from Martina I was wondering about the recommendation you made about people publishing at the publication points of the"
  },
  {
    "startTime": "00:12:00",
    "text": "IRRs. So, like, is the purpose of the RPGI to have a more centralized system? or would it be a desirable in the future to also have like more people setting up their own publication points? so the CIA functions on publication functions are separated for a reason So even if you have centralized repositories, the keys can still be delegated and that's ultimately where the security is Yeah the security is. Under the current standards, you can only publish them on place and we see we see a lot of issues with the delegated repositories not being available So in that sense, I think it's better to do the centralize maybe in future we can think of more things, but yeah, that's a bit out of scope for now Like mirroring or, you know, just thinking out loud. But, yeah I don't think there's a security issue with publishing at the RER. I mean, you still have the key Snyder's Fastly. I think the key is that we want publication points to be monitored and operated in a reliable fashion and practice now is shown that many delegated publication points are not operated in a well manner And this was cycles on the RP side. So waiting for the timeouts so I think the fewer publication points this ecosystem has, the better from a efficiency perspective. And where to strike that balance like I run my own publication point because I need to do RPTI development, but I would recommend everyone else not to do that. I think including this guidance in the BCP is as good Thank you. Thank you"
  },
  {
    "startTime": "00:14:11",
    "text": "Mm-hmm everyone Please give me a thumbs up if you can hear me. Yes, we can hear you Great So, my name is Alexander Azimov. I work for Yango And it's been a while since I last, but what's the a side drops meeting. But it's good to be back. Today I'm going to talk about ASP documents. Next slide please. I passed you slide control Ah, I see, okay, great Yeah, well, it works So there are three documents that are bound together. The profile document that describes the ESP object format the ASP verification document that outline procedures for checking ice path, and the RTR RTR-related document that defines ASPA PDU In this presentation, I will discuss later updates to all three documents, as well as open questions that remain Let's start with the profile document in the latest update a reasonable limit was added to the number of provider IS that one customer IS may push into the system Some of you may remember an interesting experiment when people from academia decided to check whether very long ice paths would be properly prepared by all routers in the world The result of this experiment caused numerous BGP session flaps across the globe The precaution should help when people from academia and their experiments will return"
  },
  {
    "startTime": "00:16:00",
    "text": "This change has been affected the profile specification and I believe a spare object is quite stable now Now let's jump to the verification document It has undergone major restructuring and rewriting and i won't have time to go over all its changes. I hope you've already checked it out, and I focus on the moment significant update the definition of invalid and unknown paths A key observation was made a few years ago, each valid ice path may have an up-ramp followed by a down ramp If the sum of lengths of the up ramp and down ramp is less than ice path length, the path is invalid. Invalent means that ice path has been leaked or malformed The great thing about ASPA is that it can be used to measure the length of up and down ramps Let's start with an obvious this example. Here we have six alternate systems each of which has registed a speed record. In this case, we can measure the exact length of the upram and the downram and the assume is equal to Aton-System length, so the path is valid Unfortunately, this ideal scenario differs from the real adoption process where only a fraction of atom systems will participate Now, Let's say that Auton System 3 and out on system 5 have not reached ASPA records Therefore, we can measure the length of the up-ram"
  },
  {
    "startTime": "00:18:02",
    "text": "to be between 3 and 4 and the length of down ramp to be between two and three The outcome verification procedure will be unknown because we don't have enough information this leads us to a generalized definition of the ISI check using an ASPA the sum of maximum of up ramp and down up-ramp and down-ramp length is less than ISPath length, then it is invalid. If the sum of minimum of up ramp and down ramp length is less than ice path length it is unknown. Otherwise, it is valid This mathematical definition clearly correct with our original definition of invalid ice path. The use of mean max length variables has greatly simplified verification procedure definitions Overall, the feedback has been positive Now let's discuss the most difficult question The address family flag has a long history in the ASPA documents. It was our original a mandatory part of the ASPA object. There was attempt to make it option which failed due to complications that were required at the validating software About a year there was a discussion if we should drop it for good Both options had valid reasons. On one hand, there is still difference between IPBC and IPV4 customer to provide data sets On another hand, we could simplify both registration processes narrowing the field of possible mistakes and also simplify processing on the router software"
  },
  {
    "startTime": "00:20:02",
    "text": "To make my mind, I decided to extend the modeling of our system connectivity with a ground study. I asked fellow operators, asked on mailing lists, and even send half-automated emails to ISPs The one question I asked was, according to my mode, you have a provider in IP before, and no connectivity in IPV6. Can you explain me why? Responses can be clustered into two types. Mistakes in routing policy configuration or lack of visibility in my model. With this in mind, take into account the fact that simplification usually boosts adoption rates, we finally reach a broader consensus that address family flag should be removed. The latest update to the RTR protocol follows this decision. Therefore, all three documents are now synchronized with their interpretation of ASPA objects The publication of ASP verification in RTR documents has raised some questions and discussion in the minute list. I want to gather two comments in these slides. The first comment can from Randy about the abstract that was added to the ASPA verification document There I stated that with a growing volume of traffic, more ISPs would have proper more monitoring for both V4 and VC sessions with their customers to ensure that they are in established state However, Randy also pointed out that this statement may be speculative. So, we just removed it. The second discussion took place in 3 threat related to the RTR document update equation was raised about whether we need the provider IS count field. If"
  },
  {
    "startTime": "00:22:02",
    "text": "not, whether we could move the flex fields to the first 32-bit area I felt that there was no consensus on this issue in the thread, so I thought it would be helpful to hear the points of view of friend or Rope or early implementers who might have joined us today By the way, Randy, if you can turn on your mic, it will be great Or we can just skip it and move it to the question questions Good, man. See, chat C-chat See, chat. Okay, so okay so this is my last light uh spay it has been around this working group for about six years It has been significantly improved since its early versions becoming what I feel a solid specification However, any technology has a window of opportunity and it won't last forever For SPA, it's right now I hope we can solve together last minor issues and progress these through three working groups items to our ESG Please, any questions and comments Okay, Nang-Go from Huawei Technology, thanks for updating the drafts. I think it's ready to move on, but my question is about the second open question the RTR ASPA PDU I think we do not need to change the position of flex field Because in the IPWC, prefix PDO and IPA, prefix PDO, the flex"
  },
  {
    "startTime": "00:24:03",
    "text": "are also in the position after the lens field So we can keep the consistent design as existing PDUs We do not need to move the flex field in the ASPA PDU in different places. Thanks Thank you for your comments. Ray feeling great so the discussion was kicked started Rudigur folk Hi, Alexander I can tell that yes the quite serious rewrite you did has improved the very verification document after such a major rewrite it is expected that a little bit of more worth smithing and fixing maybe needed if I read your slide with the red removed, well, okay, that's that's a part Actually, I think there we need to go a little bit through the details the security section section, for example, quite certainly looks much better now, but I don't think I don't think everything that's there belongs under security considerations and I'm not sure that everything that would be expected in the security considerations is in"
  },
  {
    "startTime": "00:26:00",
    "text": "there. And I'm like I'm likely to provide quite a number of oops, written comments though that's going to wait until the second half of August Okay, so we will have to postpone slightly progress into IESG but okay it's joke Rudir, thank you. We will be waiting for your comments job snijders, Fastly. I think we're almost ready to move on Right now, our focus should be the RTR documents I think there are about five topics that are working discussing in the group via email In particular, ordering of information inside the PDUs. Because I think this is our last shot at making the RTR protocol as good as we can because after publishing this, we'll be stuck with it for a number of years. randy bush rob austein, if you need help or would like textual contributions, I'm happy to spend some cycles if there a shortage of time on your side But yeah, we're almost there And ideally, working group last call starts with a number of finished or products that operators can use to set up the entire pipeline from signing to validate to into pumping it into multiple BGP implementations so they can inspect the entire pipeline before supporting progression to IESG I think I don't have any additional comments to what you said upset. Then I was right, and see"
  },
  {
    "startTime": "00:28:03",
    "text": "any additional comments to what you said. Just a small comment, first of all, thank you for presenting about this and maybe similar to you up My feeling is that we're close, but there are some open issues that need to resolve please resolve them please keep that momentum going We have an implementation in our test environment to produce hostile objects. We would very much like to enable this in production, but we cannot do so until things are resolved. So I would say, please keep the momentum going. Thank you We will try our best. Thank you Okay, thank you I'm always a bit too short for the good afternoon everyone I'm Sophia I'm the NRO I RPGI program manager in March in Brisbane, I did a similar presentation for the IABG, and I'm really grateful for these times a lot to present to a bit of a more appropriate audience. Next slide, please And to start with, because I'm a new participant to the working group although I have attended a few IT IETFs, I haven't been very active in this working group before So I wanted to understand a bit more, so just quickly I wanted to understand how your role in the internet routing system. So who of you are operator of content networks and of trans networks? And you may be playing more than one role developer of tools researchers and other, is there anyone who do, okay, cool I would love to hear about those, but no right now"
  },
  {
    "startTime": "00:30:00",
    "text": "but thanks for that. Next slide, please So what I would like you to get from this presentation today, first I would like to raise awareness about this new program. I started as a program manager in January, and it's relatively new. So I would like everyone to know a bit more about the program. But also, I hope I will be able to spark enough interest for someone to reach out to me and give me some input. And throughout the presentation, I will be mentioning some specific things that I think is really important for us to get input from the community but also I hope to spark some curiosity so that you want to learn more about the program and I will provide means for you guys to do that next slide, please. Just a little bit and as I mentioned, because I'm a new participant, and I'm sure, a lot of you don't know me, quickly I wanted to share. I studied telematics engineering, both my undergrad and my master's, but then at APIC I became a product manager and later and ontological coach. So I've been a bit derailed from the technical path. So just coming back to the technical world very recently I have attended a few ITI meetings but I have not actively participated in any working group so I'm very new and inexperiencing in terms of how working groups work So that's another thing that I would really rely on you guys and finally in terms of my experience in the internet world, I joined AM Lacknick first in 2010 and then I moved on to do my master's And after my master's, I joined Apinick And now since January, I'm working for the Enero and for those of you who may not know what the Enron is, it's the NAMBER Resource Organization that brings together the five regional internet registries. So APNIC for Asia Facilities but Africanic in Africa, Ireland in North America Latnik and the RIPNCCC with the mission of actively contributing to an open state and secure internet through different initiatives, both in the space of technical coordination, but also in the space of governance governance"
  },
  {
    "startTime": "00:32:00",
    "text": "Next slide, please. And now I would like to introduce the NRRP program. Next slide. Back into 2022, the NRO went through a strategic review process. And the NRO Executive Council, which is the five CEOs of the five RIRs, agreed to work to work towards providing a robust, coordinated and secure RPKI service So in January this year, as I mentioned, I started my role as the NRO RPKI program Manager. This program was actually created last year, or maybe end of 2020 and some conversations started. A steering group was formed and this year in the first few months of the year we focused on agreeing, okay, what is the purpose? of the program and what are the most specific outcomes that we can achieve? So as a purpose, we are aiming towards providing a more consistent and uniformly secure resilient and reliable RPGI service and what of our hypothesis is that we should be able to benefit those network operators that interact with multiple RIRs so that they have, if they have presence, in multiple regions, and maybe experiencing the, like, inconsistence or differences among our that they have if they have presence in multiple regions and maybe experiencing the like inconsistence or differences among RIRs as maybe a barrier for IPCI adoption so we hope we will be able to benefit those among other benefits of the program. Next slide, please And why we believe this program is important the RIRs have been collaborating and quoting for quite a while in like different spaces, but the RPKI program creates a space for more structured coordination and collaboration, and we are aware of some diversity and the differences as I was saying among the RIRs and just as an example, I included a screenshot of a manners document that summarizes requirements and security standards for operators of RPCI services for example the RIRs and in the annex has that table which is a bit out of"
  },
  {
    "startTime": "00:34:00",
    "text": "date, so some things may have changed, but it's just an example of how for different aspects, some RIRs may be aligned or compliant and some may not And those differences are the ones or some of the ones we're trying to understand how they may be in impacting RIPI adoption. Next slide, please We do acknowledge that the differences may be in different aspects of the RPQA system, right? So it may be that some RERs offer some services that some others don't or that they offer services in different ways. There's also differences in the user experience for example, for those that create ROAS using the graphic interface, and I have a slide to show that. You may see that the portals show, look experience for example for those that create ROAS using the graphic interface and I have a slide to show that you may see that the portals show you look quite different but then for the RIR that offer APIs, the endpoints may be different but also at a lower technical level, the may be differences in terms of design decisions or the actual implementations. Next slide, please So yeah, this is the example of the user interface. So the user interface through the five portals maybe a bit different The fields that are required may be different the vocabulary use maybe slightly different, even the information offered so that network operators can create the road based on VGB information, maybe different in some cases it's available, in some cases it's not next slide please so what we are asking ourselves is whether those different are hindering IPQI adoption Next slide As I mentioned, the purpose of the program is to provide more consistent adjudication secure, resilient and reliable RPKI service, but as I mentioned earlier this year we were having conversations with the steering group about what are those more specific outcomes? that we may start working towards? And the first thing we agreed on focusing on is,"
  },
  {
    "startTime": "00:36:00",
    "text": "understanding what would a single global RPAI system look like. So although the title of my presentation talks about an RPCI service in Singula, as I mentioned, in practice, each RIR has their own implementation. So we want to really understand first where we are at right now, but also what are the community expectations in terms of that single global RPKI system Then there's a couple of objectives that are about some specific aspects of the system like the second objective is around understanding better and improving the transfer about the robustness of the system and the third one around security, so enhancing the security consistent consistency of the RPCI system across different RIS. And the final one, and this was so enhancing the security consistent consistency of the RPCI system across different RIS. And the final one, and this where a lot of my work happens, is about keeping the community info and engaged throughout the program For example, this presentation and also if there's any concerns that we can address them in a coordinated way. We do acknowledge that each area has the regional community and there's conversations happening there and there's input regional input being dealt with at each RIR, but in the space of RPKR, we would be able to be able to respond in a more coordinated way. Next slide, please As I mentioned, a lot of focus has been put on that first outcome around really understanding what a single global RPGI system would look like We started by documenting the different services and features and what's the current state of things in terms of what RIRs offer them or not and how, so that we can identify Empire prioritize gaps. We've been working also on our problems statement around the current trust tanker configuration summarizing history since 2005 and we are doing some preparation for use of research in the next couple of months so if any of you would like to participate, please when we send that invite out there would be great to have"
  },
  {
    "startTime": "00:38:00",
    "text": "lots of participants so that we have good representation the idea is to validate whether those differences we've talked about are hindering RPK adoption and also what are the ones with like highest impact so that we can prioritize work on those. Next slide When I say we the program team I mentioned already the executive council, that is the CEOs of the five RIS, the ARPI steering group is ARPICI experts from the 5 five RIS, myself, but also at the guy subject matter experts from the RIRs. Next slide, please Just conscious that I'm running out of time. So my last couple of slides next slide, if you if you do want to know more about the program, there is a webpage under the NRO website and also a couple of blog articles that have been published through the five RIR blogs And next slide please if you do want to reach out we are we would like to get input from the community as I mentioned in particular if there's any big buyers or obstacles that you think that in terms of apical adoption that we could solve through better coordination and collaboration among our irs but in general if you have any ideas or like of initiatives that we should consider, please reach out to that email address and that's it thanks thanks for your attention. You have some questions. Randy? How do you make R.P.I? adoption? There's not just how much is published, there's how much is implemented in routers what parts of the internet Agreed? Is there a question? there, Randy? Yes, how are you going to measure it? I'm a measurement guy How we are measuring? Oh, I'm not personally measuring everything. I'm trying to use everything that is already out there"
  },
  {
    "startTime": "00:40:00",
    "text": "So I'm happy to share some URLs, but I'm sure you're aware of all the projects that measure adoption of our RPKI, adoption of route origin validation Ben? All right, ben maddison working on again Thanks for that. I think this is really, really useful I think there's been informal coordination but I think having an actual forum for that to happen and an actual program to guide that is really important One comment I'd make which there's probably nothing you can do with this immediately but I think it's important to acknowledge that there's going to be quite a disconnect in terms of the kind of subject matter that get wide interest and attention from the member bases of our RIRs. That's going to be kind of like user experienced stuff. It's going to be API definitions. It's going to be web portals that look nice. And I think that there's but I think there's also another category of thing which can be much experience stuff. It's going to be API definitions. It's going to be web portals that look nice. And I think that there's, but I think there's also another category of thing which is going to be much less widely interesting for people, but I think actually more important and more and and more the kind of stuff that you guys are uniquely placed to actually work on and the thing that springs to mind there is is taking a look at the current trust anchor layout Like it's, we all know it's really, really fragile and it's there for a re- to mind there is is taking a look at the current trust anchor layout like it's we all know it's really really fragile and it's there for a reason but I think taking a good hard look at that a few years down the line would be really valuable work Yeah, yeah, thanks so much for your comment and that's why I'm inviting everyone to participate when the time comes We will be sending invites to the relevant mailing list and we are hoping to get a very good distribution of participation so that we can have that representation So I will send you an email directly so that you can provide your input. Thanks for that. Okay, thank you No"
  },
  {
    "startTime": "00:42:02",
    "text": "deck you're looking for I'm job snijders, I work for Fastly I have glasses now so I can actually see my slides It's fantastic Numbers, apparently is the first one next slide please in recent months a group of German researchers pointed out discrepancy amongst multiple relying party implementations about how the CRL number extension inside CRL objects is handled or not handled. tom harrison from APNEC expressed concern about CRL numbers maxing out, reaching the highest possible value, which is 20 bytes minus one bit bit And we have an RFC that mandates that zero number extension must be present in RPQI CRL which all prompted me to investigate what the heck are these serial number extensions even for in our ecosystem. Next slide please Quick recap, what a CRL looks like. CRO is a digitally signed object that contains amongst a other things, an authority key identifier the issuer of the CRL when it was produced, when you can expect the next update and a list of revoked certificates serials, and it contains a field called the serial number. And this is done in the serial number extension. Next slide, please serial number is a non-critical extension and the original RFC that specified x509"
  },
  {
    "startTime": "00:44:00",
    "text": "version 2 CRLs specifies that it is a monotonically increasing sequence number, and this monotonically increasing sequence number can be used to figure out which CRL is the latest one, which is the one that I should be using So the serial number in other PQIs can be used to choose amongst multiple simultaneous valid CRLs, which one should the real So the serial number in other PQIs can be used to choose amongst multiple simultaneously valid CRLs, which one should the relying party use. Next slide, please We have seen this movie before. Next slide in manifest we have the manifest number which is a monotonically increasing value that we use to decide which version of the manifest is the one that we as relying on parties should be using. Next slide, please I argue that serial numbers in context of the RPKN serve no purpose because a well-formed manifest contains exactly one entry for the CRL and that one entry contains a colloquium resistance digest that addresses the content of the CRL, the CA intent the RP to use. And additionally, the serial distribution points in the CA Resource Certificate references the C the CA intended the RP to use. And additionally, the CRL distribution points in the CA Resource Certificate references the CRL by name. And as monotel numbers monotonically increase, this helps us detect replay not just of the manifest itself, but also of the content listed on the manifest So together, all of this guarantees that relying parties can unambiguously decide which CRL they have to use if there are multiple available So in other words I would argue because we have manifest the function of serial numbers as"
  },
  {
    "startTime": "00:46:00",
    "text": "originally followed up by RFC 52A is fully subsumed and they serve no purpose. Next slide, please So there's a number of cases that are resolved if we ignore the contents of the serial number external as relying parties Case one is a very simple one, for instance if the serial number max us out, with manifest, if the number maxes up, we identify this working group that we need a solution and tom harrison has been driving a solution that we rename the manifest file In the case of CRL numbers maxing out, I argue that the problem of them mixing out simply disappeared if we ignore the thing Next one There's a far more complicated case, but if you do a fetch and you get a part repository state, and this can happen if the CRL, a new CRL object appears in RDP Delta 1, and the manifest, and other associated products appear in Delta 2 At that point, the RP has the old manifest but from the RP perspective, it's the latest manifest and two CRLs, the old one and the new one The new one refokes the old manifest but the manifest RC says that if you have a partial fetch or a filled fetch, you have to use locally cached objects which would mean that you do not use the new CRL, even though it has a higher number In this type of situation the serial number has no construction purpose because we prefer the way manifest-filled fetchs are handled and trying to use the CRL number as a means to discover"
  },
  {
    "startTime": "00:48:00",
    "text": "which is the CRL, the CA intended us to use, becomes very complicated So I would argue that the 5280 purpose stated for C use, becomes very complicated. So I would argue that the 5280 purpose stated for CRL numbers is somewhat incompatible with how we do things in the RPTI. So again, we relying parties simply ignoring the CRL number extension resolves this case Next slide, please So in RPKI clients, the validator shipping and the OpenESD, we have now arrived at this image implementation. We check that the serial number extension is present We check that it's marked non- non-critical and that's it. We do not look at the contents and we don't do syntax checking on the content I would advise other RP implementers to follow a similar pattern and this is also the pattern described in the draft proposal Next slide please so next steps I would encourage RP implementers to double check what they are currently doing with the serial number if anything. Please read this draft. It's fairly short. I think it articulates the arguments in a concise way. And finally dear chairs, I would ask you to consider starting a call for working group adoption so we can jointly work on this this We have comments, questions. We have one in the queue MPI nth, why are you checking that the CRR? is there at all? I presume there's a good reason for that, but could we just like, I get why we can't just delete it, because some are which don't follow this will go, well, that's not valid but why do we even need to check that the number is there?"
  },
  {
    "startTime": "00:50:00",
    "text": "I suspect it is for hysterical reasons or historical reasons So at the time the RPQI framework was designed a conscious choice was made to recycle existing components like x509 And it was very reasonable to say we want to use the X509 version 2 CRR profile as is because a lot of tooling works that way So if you remove the CRL number extension it no longer complies with the X509 version 2 CRL profile so I think it's a reasonable compromise to say CA issuers must include the fields because that's the profile we picked and RPs should ignore the contents of the field because we have no purpose for it Wouldn't it maybe be nicer to say that RPs to just ignore it entirely and then maybe in future we can come back and say CAs just shouldn't include this? That's a very reasonable point to bring to the working group and we should have that conversation I am mainly here today to argue that the contents of zero numbers have no purpose and maybe if we arrive at a consensus to somehow get rid of the field or not check it, that's, you know, that's an advanced step bob beck necromancing old standards fan are we absolutely certain we're also not having implementations doing stuff? like sneaking CRLs through AIA or other such fetching mechanisms because they've... Can you speak up? a little bit? Are we certain we do not need to give advice to avoid fetching CRLs? via other mechanisms where this would matter? such as AIA or any of the other"
  },
  {
    "startTime": "00:52:00",
    "text": "ways you can sneak into a certificate to ask for one? As far as I know, all implementations use the manifest as the discovery starting point And for debugging purposes, some implementations can follow AIAs and associated CRLDPs but that is not the general case as it is used in the production environment. So I think there is no concern there there there there please I'm ben maddison again So you correctly identified the one point of disagreement amongst the authors. Please speak in with Mike. Sorry, I'm doing my best I'm right here. You correctly identified the one point in which the authors disagree. I come down on the side of ignorance the extension altogether My co-authors come down on the side, I've checked that it's the per the profile, but then don't process its contents. I think it amounts to the same thing in terms of correctness. I'm not sure that I feel qualified to dictate what the answer should be. I think that should be a question post-adoption If I, Bob, if I understood your question, correctly, Bob, concentrate, concentrate, concentrate Bob, you're still there If I understood your question correctly, that, that scenario would still rely on additionally following the CRLDP, yeah? So that the, I forget which document, but it is mandated that the CRLDP must refer to the same name as that listed in the manifest so if you're correctly following that step then that kind of securities back door should still be cut off in the existing standards. But it's, I don't know that true in practice, but it's true in the documents"
  },
  {
    "startTime": "00:54:00",
    "text": "We should definitely discuss this in the hallway. Next slide Next slide, please The next draft is a tie-breaking trust anchor certificate Relaying parties have a trust anchor locator that contains a public key and one or more URL They fetch the object from the URL, verify that the public key in the towel is the same one signed over in the trust anchor certificate and whether the self-signage is correct You can imagine that as a relying part, you may still have a previously fat fetched copy of the TA certificate around in case the fetch fails you encounter some HTTP error or something else but in case the fetch goes well you have a choice Using the TA certificate that came from the network, or using the TA certificate that came from disk Next slide Why? does this relevance, there still are super old trust and certificates that are still valid and they date back to 2014, and they contain internet number resource listings as subordinate resources that are woefully out-of-date So if these old certificates that are still valid, and cryptographically valid are reintroduced into the ecosystem, perhaps by some network caching elements like a CDN or a provisioning mistake, it would potentially wipe out a significant part of the PQI structure I've made an analysis of the availability of older stiff certificates. You can click to your own. Next slide please So the previous slides sort of demonstrate"
  },
  {
    "startTime": "00:56:00",
    "text": "that it would be nice if stuff from 10 years ago cannot bite us today. And for that we need to move towards short-lived trusting anchor certificates. And with short-lived, I mean something along the line of a year and practically trust anchor operators critically depend on a degree of agility because they must be able in a timely fashion to update the subordinate INR listing the subject information access, for instance if we come up with RDP version 2 or deprecate R-Sync, and they may want to change the URL of the certification and practice statements. So it is entirely unreasonable to imagine that for the next 50 or 100% years, these aspects would not change. Next slide please. Then on the relying party side, it is beneficial if we document a standardized means how to choose between multiple valid TA certifications and how to pick a TA certificate amongst multiple valid TA certificates is a little bit tricky because we cannot rely on the certificate serial that one is not monotonically increasing None of the X-509 V3 extensions per provide useful clues what the better certificate is But we do have the not before and not after date as an indicator of re- recency. And one could also argue that the source of the object, the network, or the disk that contains the previously cached version of the object, could be interpreted as a sign of recency. Next slide So with manifest, this was super easy, right? You just look at it"
  },
  {
    "startTime": "00:58:00",
    "text": "interpreted as a sign of recency. Next slide. So with manifest, this was super easy, right? You just look at the manifest number. One slide back, please One more One back, please Yep. So with manifest, this was super easy You look at the manifest number, you take the highest one you're done. What we implement in OpenBSD are PQI clients is that we prefer the TA certificate that has the more recent not before If the not before, it's the same for the object fetched from the network and the objects cached on disk, we look at the knot after and we choose the certificate that has the soon as not after. And if the validity period between the two certificates is equal, we pick the one that came from the network Next slide, please The justification is we assume there is no or minimal backdating So the not before is very likely to be close to the actual moment of issuance And using this in the tIABreaking scheme, will encourage TA operators to not recycle not before values. Always keep moving your not-before forward if you do new issuances Overly long validity periods are unreason from the perspective that we can formulate arguments that there is a high degree of uncertainty what happens 50 years from now, and therefore issue certificates in the range of 50 to 100 years doesn't make a lot of sense and therefore we prefer certificates with shorter validity periods and then finally um object stored in the local validated cache on disk originated originated from a previous fashion which is earlier in time and an object fetched from the network is"
  },
  {
    "startTime": "01:00:00",
    "text": "therefore can be considered more recent than the one that we got some time ago The time breaking steps are in order of progressive unlikeliness. So step three is within the RER ecosystem very, very unlikely to be hit, and step two can only be hit if the not before is recycled across multiple issuances. Next slide, please So my question to the group is please take a look at the proposed tIABreaking scheme. Please consider implementing a notion of a local validated cache for TA certificates so that if the remote point presents you something that is either cryptography invalid or an HTTP 404 error, that you fall back to something you obtain before We need to figure out if we adopt this concept whether to do a BIS document on the trust anchor locator RC or maybe just patch the section of text that deals with how to make this choice And we can either adopt this work as working group or go for an industry submission and just say this is what one specific implementation did and not make it a working group documents So I would love your feedback on this perhaps on the mailing list, because I'm already over time, my apologies Yeah, and this is it. Thank you So please let's hear some discussion on the mailing list about it Hello, can you hear me? Hello? Yes, I'm going to give you control of the slides Okay, thank you"
  },
  {
    "startTime": "01:02:00",
    "text": "Hello everyone, I'm Yufu Brown-China Unicom I want to discuss whether to synchronize the RPK data that is not required by net network We have introduced that in the, I think, in future IPVC only network is only interested in the IPV6 related BGP validation So we have introduced in the Australian meeting that in China, there are a new China education and research network named the Fiti and the construction will be an MPV6 only network and also China Unicom is fasterly upgrade our network for the IPV6 and we are considering to deploy IPV6 on network in the future So we have due do some tests in our test by that when a network receives unnecessary app we have to do some tests in our test by that when a network receives unnecessary APCA data, maybe there's some disadvantage So the first one is with of the storage on routers. So we do test on our test back that we if we only use the IPV6 only data, we can save 67% storage And the second one is induce some endless transmission overhead And the third one, we think that this is the energy efficient So we want to discuss on that at the present there are RPGI data types in the RTR PDU that IPV prefix, IPV6 prefix router key, ASPR, and like more RPCI data types in the future, such as a there are many secure routing"
  },
  {
    "startTime": "01:04:00",
    "text": "policy, spec language, and also so on and so forth. So with think that from the operator perspective view, there are some options solutions to help the operators select RPCA data synchronize to it The first one, we may extend this norm to support filtering data by RPKL data type. The second one is to extend RTR to support the subscription data type So we think that the first one maybe looks simpler than the second one. The third one is suggested by the drops another That's the last meeting that we can lose the package by the routers. But I think we, from perspective, we operate perspective view, that maybe still reduce some energy stream transmission overhead So we want to propose our discussion that does the network request all the some end-string transmission overhead. So we want to propose our discussion that does the network request all data types of ARPT CARE data and whether to synchronize the RPCare data that is not required by the network. And which solution? is the best and and I think that for the operators that we want more simpler network and more simpler network operation. Thank you you Commerce are welcome, thank you Any comments or questions? Thank you Hi, I'm Jeff Hauser haas, Juniper Networks. So filtering the data can be potentially useful, a thing that we have seen in live deployment, especially at scale, is that when the RPTI data is being fed slowly,"
  },
  {
    "startTime": "01:06:00",
    "text": "as an example, and BGP gets a little bit ahead of things, you can end up with a little bit of thrash inside of your table or what the routers actually panel versus what policy and RPKI is in sync So filtering is one way to maybe help with this. The second thing potentially for the working group to consider is maybe RPA router either could be configuration at the back end or it could be something passed via the protocol can provide some hints that allow for prioritization of the things that are important Thank you Okay, thank you Hi, I'm Sun Liang from Channel Mobile Our topic is definition and problem statement for consistency in inter-domain royalty and forwarding So next slide, please I've given you slide control Oh, thank you you you So we first say what results in the inconsistency due to load balancing antedotosis etc., PPR, or BGP flows spec may configure to redirect traffic to a new next hope a S which is different with the NextHope AS determined by S-Pepad in BGP update And there is no control plan or routine process awareness takes take this piece"
  },
  {
    "startTime": "01:08:00",
    "text": "for example, the expected aspect of AS1 is AS2, AS4 However, AS2 redirect traffic from S4 to S3 The expected S-pass is AS-PAT is AS4 to 4. Will the actual path is AS-1-3-4 And the original AIS cannot know that actual path Another reason is ambiguous routing specification Roat aggregation will convert the ordered AI sequencing to the I unordered AI site. However, as site does not represent the actual path of the B2 Road. The original AI may be ANAS and does not see the actual forwarding S path from the BGP announcement the inconsistency could lead to some security risks track thick black hole. There's no correspondence road for the next HOBAS result a traffic black hole The complete forwarding passes corresponding road for the next hopper as resulting a traffic black hole. The complete forwarding S-pass is composed of multiple AAS pass from different protocol, which may lead to unnecessary lessening of S-paths or loop malicious AS-PAS, the actual forwarding path is not visible to the original AIS which may cause its packets to path through some AISs. It does not exist expect Now optimal road to the AIS may prefer some AISs that may not be concluded in the actual path to sit does not expect. Non-optimal road to the ayes may prefer some AISs that may not be concluded in the extra path to select an optimal route route So the consistency in interdomain rotating forwarding means that inter-a-s traffic is forwarded along the S-paths in the reverse direction"
  },
  {
    "startTime": "01:10:02",
    "text": "Yes, it's the S-pass attribute that records the number that is passed through However, the actual forwarding S-pass is usually different with them S-pass in BGP update So how to keep consistency of interdermarotian and forwarding We propose a solution with two steps First, all turned deviation as paths by looking up the S-pass in A reps-in Then the ASAP that generates the deviation S-pass is obliged to check and advertise it to other ASS ASA The consistency in interdemean routing forwarding provides the ability of the original AS2 plan its own forwarding and it can be used in internet visualized inter-domain source address validation troubleshooting, and intent-based routing So any questions or comments are welcomed and we will reform the solutions in the future. Thank you Okay, we're going to go to the next presentation Hello? Can you hear me? Yes. Okay, thank you This draft is about profile for mapping origin authorizations. That's more Next please I gave"
  },
  {
    "startTime": "01:12:00",
    "text": "you control of the slides. Okay, thank you Just talking to propose more. It is a new digital style object IPQI and is used for the verification address mapping, announcement in multi-domy IPVC's own and network. This draft was further established to set up before ATF 190 The current version is 4 4 So we're going to scenario, this document for area of IPVC only network network, which the handling network protocol is only IPV6 between only two P devices, but they can be due style at the ad for IPVS4 delivery IPVC only IPV6 between only two devices but they can be due stack at the ad. For IPV4, software delivery, IPVis is only network, IPV6 mapping prefix are configured as a PE to unifying location of each IPV4 network. So, IPV4 network prefix is considered as mapping origin given IPV4 address block So in MPP4, protocols, a new extension called FormMAP 6 is defined for announcing the mapping relation between IPV4 address block and HPVV6 prefix from EE to ingress PE The problem statement it is evident that the validity of transmitting IPV4 service data in IPVC network lies on the authenticity of the map evident that the validity of transmitting IPV4 service data in IPVC network lies on the authenticity of the mapping or ranging IPV4 address block If tech maps IPV4 address block using a fake IPV6 micro fix, IPVs for sub-data will be routed through the attack control route and reach to its wrong egress PE resulting a situation of IPV perfect high-jacking hijacking As some, so the approach used RPKI architecture to verify the authenticity of the"
  },
  {
    "startTime": "01:14:02",
    "text": "mapping arranging of IPV4 address It defines the new object called Moore More is critical graphically some binding between IPV for address block and it's right my pvs, mapping perfect, that is not to be denied in BGP announcement. With the more of object, a legitimate holder of IPV for address block, for example, the SP can authorize an IPV6 mapping prefix to map the IPV4 address block this is a e-content more more and uh answering one format of more is revised based on the comments of rascotally and the job standards as a object of RPKI, since Moore is object RPKI before a relay relay party use more to validate mapping announcements, it must perform all the validation checks specified in R316 6488, as well as additional more specific validation steps So as mentioned that since the draft was submitted, before ETF 119, Comments contributions received, job students give several approvals to more e-content. He also proposed as a deflation of canonical ordering a V4 prefix, which will note IP software routing protocol software to more easily verify the company as e-content. Also proposed to replace RFFICS, by its native version in the reference section. And the RASF also give a new version of ANC module and one significant enhancement, which on its related version in the reference section. And the RASF also gave a new version of ANC1 module and one significant enhancement, which are known for several IPVSI prefix, and each of them is mapped to this IPV4 prefix Jeeve Huss and the DMA drawn as co-authorses"
  },
  {
    "startTime": "01:16:00",
    "text": "So we are looking forward to receiving more comments and suggestions, and further refirm will be made to approve the WHO document and that we authors would like to ask for working group adoption of this document This is it, thank you Okay, please, let's continue the discussion of this idea on the mail list. Thank you Oh, thank you We have the presenter Okay Can you give me the control, please? I did. All right, thank you very much. Good afternoon everybody. So in this talk, I will discuss the FCPGP protocol specification. So we have been, since the past few IETF sessions, we have discussed FCPGP. So in today's talk, we will basically recap on the basics and then we will discuss some comments and suggest since IETF 119 and we do some major trends from previous draft and we will also report some implementation status So for the time of sick, I will briefly introduce FGP so it is a new BGP update validation scheme that adopts the per-pathletion scheme. In this case, the E2 AS only cares about its indifference neighborhood, immediate pathlet platelets in order to secure the entire paths So we collect"
  },
  {
    "startTime": "01:18:00",
    "text": "a lot of the comments and suggestions from a the group since IETF Mobile 9 nine including some of them are like the draft is somewhat light, lacking necessary materials and the demonstrating FCBGP is secure as secure as BGBSEC and there are a bunch of other So I will go through some major changes in this draft. So in this, in this current draft, there are some key changes including first, first of all, we remove data plane related to content in this version of primarily focused on the control plane stuff. And then in a section one, we end the KD K-differentiator of FCBGP, stressing the partial deployment scenario. And in Section 2, we also explicitly states the Nikkos negotiating new capabilities are unnecessary And in the Section 5 and 4, we end additional protocol descriptions regarding the sending and receiving the BGP update messages And we also end some other operational considerations and security concerns and so forth I will go through some very high-level highlight changes. First of all, in the abstraction, or in the in the in the first section, we this I will go through some very high-level highlight changes. First of all, in the abstraction or in the first section, we define the K-deferior enter of FCBGP. So the parameter primary differential enter is the FCBGP and BGP BGP SEC offers the same level of security guarantees in case of full deployment, but FFGPGPGP and FGPSEC offer the same level of security guarantees benefits in case of partial deployment Primarily, FCPGP trades partial Thank you but FCPGP offers different level of security benefits in case of partial deployment. Primarily, FCPGP trades partial deployment as the first class citizen In the trade number two, and we explicitly state that FCPGP relies on RPKI, and also use the BGP set keys to see and verify forwarding commitments"
  },
  {
    "startTime": "01:20:05",
    "text": "and the change number three is we explicitly or give more practical description about the standing and receiving process of how a BGB speaker should process FCA update message message And change number four is we explicitly state that the route selection policy So we do not modify the priority of BGP route selection in FCPGP Instead, we leave the route selection to the local policy. So the AS have their own local policy to basically process to assign priorities for different passes Change number five is the AS Federation Park and we discussed how FCBGP works with the AS Federation in case of, you know a large AS have multiple, multiple small numbers. And we define us some flags to be, to handle this part of ASFederation Another big change is about the route server and there are a bunch of cases where, like, in IxP, there are some transparency route server which might not end its AS number into the AS pass So in this case, we would discuss two scenarios. In the first case, if the route server decides to insert its ASN into the AS pass, it will basically, the RS will act like a typical FCGP-enabled AS It will be processed the FCBGP as if it was a regular AS But in the case, if the RS does it insert AS into the AS pass,"
  },
  {
    "startTime": "01:22:02",
    "text": "it will basically try to, the art will populate the FCBGP second into the FCBG list And we specify some cases of we specify how the RS should populate the FCBGP, FC, FC segment in FC list if it does not insert its AS into the AS pass Oops, and the change number seven is about inserting the AI number zero and we discussed the security guarantees, we discussed the security issue there there should be no ASAS zero in the AS pass attributes of the of the PGB update message therefore as there will should be used to populate the PA as in field when no previous ASHOPs is in the ASPAS pass. These are all the very high level very highlighted changes we made over the draft And for the implementation status, we have implemented both software-based FCPGP prototype and hardware-based FCBGP prototype in the software we use FLR, and in hardware, we are partner with the H3 company to develop FCBGP under CR 1, CR1900C series. So there are some, these are some of the specifications over there. And next steps is we are looking forward to the working group adoption And we also welcome new additional comments for this FCBGP draft. OK Okay, would you please make that request on the mail list? Okay, thank you So we are down to just"
  },
  {
    "startTime": "01:24:03",
    "text": "a few minutes left. Please keep the presentation to the highlights Okay, thank you. Hi, I want everyone. I'm she from the one's laboratory and I'm excited to share all you up here and hope together some feedback from the community All draft proposed a sign MOS globe, SMG, which is a preliminary solution to protect the vaccinate MOS roads in the network as a complement to RPKI Head Start with our view of the program according to the RFC Nigel 1930, a prefix it should typically have a single ASS at its origin. However, KDAS and advices on BGP reporting data reviews that the MOS had become a common phenomenon For example, some commonly adopt MOS to mitigate DDoS or DDoS attack and some service providers also announce the same prefix in multiple ASs to a chain traffic engineering goals and if a high speed and reliable data service. Although the practical design, significant can improve the network availability, it's difficult for networks to distinguish between the prefix hijacking and not to make MOS conflict as they are often displayed similar characteristics characteristics characteristics To identify the possible hijacketing among numerous conflict, the network managers match use current road originate registries such as RPKI However, we analyze the MOS load in the past years and they found that only about 21% of the conflict are validated as many H. In fact, over 700 conflicts per day were classified as invalid which is"
  },
  {
    "startTime": "01:26:00",
    "text": "nearly 10 to 90 times higher than the result from the current more immune system It's clear that these conflicts are not all the routing security incidents, most of them are just normal traffic, but they are headed such as susceptible to being dropped by the ROA system One of the reason is that the ROA only indicates the authority by the credit holder for the AIS to advise this, to advertise this prefix. However, in many scenarios, the authorized AS also collaborate with other ASS within their organization for the traffic engineering goals So in this example, the BYOIP customer just outsource the prefix to ASA and each with an ROA. However, the ASA may collaborate with other ASS's in the same organization to advertise this prefix But from the perspective of other network, only routes from ASA are valid The laptop made traffic from the collaborating AS will be flat as malicious by ROV We have observed this happening in the real-world internet routing, and here we show two concrete examples examples And to mitigate this, to mitigate this issue, we propose a sign MOS group, SMG to assert that a group of AISs intended to collaborate announce an IP process And the SMG object includes two main fields an IP prefix and an ASLIS list. The SMG should be signed by all the listed ASAS which confirm that all these ASS has agreed to announce this prefix together, ensuring the announcement is to make, accurate, and we are truly authenticated And we also highly recommend that at least one"
  },
  {
    "startTime": "01:28:02",
    "text": "of these ASs should be authorized to announce this prefix through ROA And this is an example of a DEA encoded SMJ object and the detailed description could say or worse And here we will briefly describe the protocol for issuing and evaluating SMJ based on the aggregate signature In the issuing protocol, each AS in the AS list, should sign the SMG group, SMG objects by its private K and authorize AS should verify and aggregate all the individual signature into a global signature and find attach to the object And to validate this, the reliant party will perform Swiss steps. First, check the format. Second, signature verification, where the RP aggregate all the public key into a global key and to verify the global signature. And third, a consistent check, which means the RP checks that there is the corresponding ROA which has the same prefix and AIS And third, a consistently check, which means the RP checks, that there is the corresponding ROA, which has the same prefix and ASVAC in the object And SMJ is this designed to complement the ROA system and it could integrate with ROV while operating economy but providing additional benefits And we just allow, allowing the space of all possible combinations of ROV and SMGWR verification here At last, we implement a prototype of SMJ in GoLaw and Evaluate the performance of each operation, and we can say from the result that the entire procedure of each wing and SMJ, including three ASs, only needed by about four milliseconds and the RFP only needs one million second overhead to validate it In conclusion, we propose a sign ammo growth SMJ to enable the multiple"
  },
  {
    "startTime": "01:30:02",
    "text": "alexes to announce an IP prefix collaboration and security, and it could support the scenario such as the Guinness cover collaborations, traffic engineering, and DDOS mitigation and security, and it could support the scenarios, such as Venus collaborations, traffic engineering, and deductions. For more details, please read or draft Thank you very much. That's all Okay, we're out of time. We have one last presentation. I'm just going to ask the speaker to do a few highlights We certainly don't have time for your whole slide then. Okay, thank you I cannot control this slides now I did give you control Thank you. So I'm going to quickly introduce the highlight of the updated version of Bicon's app Bucon Sav aims to inhale the Zab robustness by using a blocklist generated by VGP updates, noise, and aspars related to the provider code. It can help avoid improper block and can work together with existing self solutions that generate a live list And we have revised this document according to comments received from IETF 190 and on the meaning list And here shows the comments received from Ben Medicine, KSRA, and Nangoon We revised this document specifically, we add a new series to introduce the goals and a new section to introduce existing allowing list based staff and describe how to be section to introduce the goals and a new section to introduce existing allow list-based staff and describe how to deal with the overlap between ProvidCon and custom code and provide a summary of recommendations BatoZile has two goals"
  },
  {
    "startTime": "01:32:02",
    "text": "The first goal is avoiding improper block and the second goal is maintaining directionality The block list can perform bad better in achieving the first goal because it has avoid improper block and the allow list performs better in achieving the second goal because the blog list can have more improper admins than the allow list And here shows an example In this example, we show prefixes in allow list and blocklist. In this figure, we consider sales on AS1 to S2 interface. If we use an allow list, it must contain all prefixes belonging to the customer code of AS2. So if a prefix is limited propagated in the customer coin, the allow list may mean this prefix, leading to improper block. And if we use a block list, it should contain as many prefix belonging to the provided coin of a AS1 as possible, and it must remove prefixes that also belong to the customer code, such as the prefix P2 So, we provide the recommendations that network operators can use either an allow list or blocklist on different interfaces facing a cache AS or a network peer AS Specifically, if the network operator can ensure the allow list cover all prefixes, in the custom code is recommended to use an allow list. For example, when the customer coin is relatively small, or ASS in the customer coin have registered as farce But if not, it's more recommended to use a block list by default to avoid potential improper block For example, when the customer coin is large or some"
  },
  {
    "startTime": "01:34:02",
    "text": "ASAs in the custom coin haven't read registered as far as So in summary, Baconsau provides an additional option for network operators to deploy self on interfaces facing a customer AS or a peer AS by generating a blog list. It can help avoid improper block and still maintain coin level directionality. And network operators can flexibly choose to use an allow list or a block list according to their needs and the actual situation We thank these people for their thoughtful call comments So in the next step, collaboration is welcome and we'd love to request working group adoption for this document. And comments, questions are welcome on the mini list. Thank you Thank you. Please send that request for adoption to the main list So we're over time, obviously we need a long slot next meeting And thank you very much for staying late Yeah, what's a guy Thank you very much you"
  }
]
