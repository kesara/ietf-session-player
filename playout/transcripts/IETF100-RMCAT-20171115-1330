[
  {
    "startTime": "00:03:09",
    "text": "okay welcome everyone to the Orem cat session so I\u0027m on number instrum and next to me is Colin Perkins with two of the co-chairs we also marked in stimuli he\u0027s not here in Singapore probably also not online given the time zone yes the note well applies of course as always you can find all the meeting material on the user slot do we have may need a minute taker and the jabber scribe thank you young man do we have a minute a crass one so I will take notes but it will be useful if someone else could take some as well and send them to us to cover any gaps yeah norm normal note-taker is not here okay can anyone help calling out the bit on the note gory I\u0027ll help you out but I\u0027ve got to fist type an email too quick which is gonna take like 10 minutes to type thank you very okay you have seen the agenda we\u0027ve been through the administrative part so as normal we\u0027ll start with the run throughout the working group status on the different documents we then have charging who will present the updates to nada this would be a remote presentation Ingmar will show some of the experimental results with scream and then so it will give us an update on the design teams work on the feedback message for the working group document status so we now have two of our candidate algorithms that are in the RFC additives queue so the couple congestion control is there waiting for the north draft because there is a normative reference so once nada is completed the couple CC will proceed so that is ready the or The Scream draft is also in the rough sea editor queue the shared "
  },
  {
    "startTime": "00:06:12",
    "text": "bottleneck detection the write up for that draft is ready so during that review there were a few needs that David will fix so we expect to ship that next week the novel draft got the number of comments during the working group last call so we had an update of that following that feedback and charging will present the updates and and you evaluation results as part of this meeting and for the google congestion control that draft is still pending author updates so I guess we yeah we will have to see what will happen with that one for requirements evaluation we have the old requirements draft which is still in the energy queue waiting for other documents then we have the evaluation drafts so we have the powder the about has draft that is ready for working group last call what is holding that up was that we wanted to ship it together with the eval criteria and here we are waiting for a small update on the tcp model so that draft has been stalled in that status for a bit so we\u0027re trying to push the waters to get that in and if not we may have to have another approach to move the documents forward so I think maroon was saying he was hoping to put an update of it this week so we will see what happens otherwise I think we had to put the deadline for that draft and maybe see if we can get another editor in to help complete them so I think it would still be useful to have them go together because they are so tightly coupled but it\u0027s a small update that is missing one of them and the status has been the same for for quite some while there so we would like to get those documents moving then we have the the wireless test draft and the video traffic model and those documents are also basically ready I think maybe charging will also say something about the video traffic model today so we need some reviews and implementation experience so we discussed all of these these drafts the last time feedback draft has now been moved over to abt core so it will report on the the completion of that draft here then we have Colin\u0027s draft on the analysis of the feedback so that draft will remain in an orange cat and I guess be updated depending on what happens without the draft follow us as a supporting document then we had the different drafts related to the interfaces and we had that up for discussion in our last meeting and the "
  },
  {
    "startTime": "00:09:12",
    "text": "conclusion was basically that we thought that the codec interaction or the working group thought that the code that interaction and the framework draft could still be useful and Varun NC had say it had a action point to try and go through these drafts and come back to the working group on the suggestion on how to proceed I had on the framework draft there was a comment that this need to be in line with the RTP topology draft mmm RC right now I have reviewed that again framework drop as a co Thor I didn\u0027t really find that there is a there is so much need to be updated on that one the question here is more about like how do you unlined the codec CC codec interaction with arm frame or draft my opinion is like is just like putting them I mean figure it out like basically it\u0027s a one draft or two draft we need to be having said that I think me and Varun I I kind of did in we didn\u0027t manage to have a time to actually do that but I hope we can do it faster but otherwise the framework draft s especially I think is pretty good shape actually do I need getting the cue sorry no please birth yeah thank you so for the framework draft maybe one thing I should mention is that we\u0027re open sourcing the NS three run cat code and that code kind of provides a reference implementation of let\u0027s say our understanding of the framework so it can serve as a reference as well yeah and as that he was mentioned the previous comment on allowing the terminology that\u0027s something we can address but it\u0027s Mora finding the time to do it yeah thank you okay thank you judging but so side you and Varun will still have a look look at both of the documents and come back to the mailing list as we discussed last time or you now suggesting another approach forward well I cannot speak for Berlin but it has been I mean lack of time basically I mean II my approach would be like well if it is importance is the interaction if the framework document is really really is ready and and you have a reference implementation for that one then perhaps we should we should deal with them separately framework document I mean as one of the thing that pointed out in previous meetings like none of the Canada algorithm currently follows the framework document but do you see "
  },
  {
    "startTime": "00:12:13",
    "text": "this was the yeah the I think the reasoning here is like when you will go on a standard track then ephemeral document will be used and it\u0027s just like that maybe we should we should deal it with separately because and I I\u0027m not actually sure right now like how much CC codec and framework document need to be aligned I\u0027m not sure about it but Varun has more strong opportun than me so maybe it\u0027s better like I can talk with Berlin let me put it like this I\u0027ll talk with him and see like what he thinks about that one and then update the working group on the mailing list sounds good okay yeah sounds good and as you as you said say the the the current drives did not follow the framework so it\u0027s will come in the next step hopefully for the so in that sense it\u0027s also not extremely critical at this time because we are not on this point so but it would be good to have a plan for how we proceed with them so yeah that sounds good okay so our milestones so we have now completed a few of the ones that we had in the summer so we have the couple congestion control was tripped just before our previous meeting so that completes that milestone or at least partly and with the SPD draft being hopefully some next week that milestone will be fully completed the congestion control candidates the first ones which scream has been summed and feedback requirements Center apt core has also been completed so the one that we are a little bit behind with now that is the requirements and evaluation draft so maybe we will update that and they say but we should try to get that out so we will we will see how we will put put the deadlines on updates and then look for other ways to proceed if it cannot be done you had I think that\u0027s the directress right way to do it put it on our deadline like well you you need we need to fix it before that one because the other that the test just drops are waiting on it so I don\u0027t see any reason for doing that actually yep okay and then we have our the rest of the deadlines is coming later next year okay do we have any questions or comments on the status if not we proceed to the presentations and charging is first up with another draft so charging will you "
  },
  {
    "startTime": "00:15:14",
    "text": "also be able to control the slides from your side Oh you want me to display them here I I don\u0027t yet see the control for the slides yeah maybe it\u0027s easier if you flip through them yeah yeah the chair and yeah I also got the note the chair needs to control them okay you\u0027re a little bit loud churching I\u0027ll try to speak more softly that\u0027s good okay yeah great so yeah I\u0027ll give an update and another draft and basically actually the next page gives a brief outline so basically the updates are several aspects we have some update on still you know taking the algorithms but mainly isolated for the last based behavior and sort of scenario along and then accompany the draft and did algorithm design there is the open source code so I\u0027ll give a status update on the open source code for the and s3 ram cat that\u0027s where the NADA reference implementation is and are also mentioned briefly some update on the sync codecs open source code which is more tied to the video traffic model draft as the chair set mentioned we do have a slide to cover that and finally with these updates I\u0027ll show some sort of a selection of updated evaluation results we have the four set ready to be shared with the amazing you know submit mailing group working group but I didn\u0027t want to bore you guys you know to flip through 50 slides so I picked a view where the changes are reflected in those sort of more representative ones and finally a summary of the draft changes from o2 o4 205 and also some of the I would say planned changes for another revision just because of some more recent review comments we have received over the mailing list next page please basically for the algorithm updates we have been motivated by actually the issue reported by the julius flora from our mailing list he reported the problems he encountered with his own and on net plus plus implementation of the nada algorithm and he basically reported that for low link scenarios nada seems to be pushing away his other he lost based TCP flows so that was kind of motivators as to you don\u0027t revisit that part of the algorithm and hopefully do a better job of coming up with a more robust behavior when it\u0027s competing against other lost based flows so the changes were made in the algorithm are actually kind of revisited the entire flow in the sense "
  },
  {
    "startTime": "00:18:16",
    "text": "that then we tweaked first off we tweaked our decision in whether to get in and out of a lost based modes basically we we adopted a self adapting thresholding to make it more adaptive so that it can serve self scale for different link capacities then secondly for this transition also and this is more like a technical tweet we also added a linear interpolation when our algorithm is getting in and out of last bit you know basically switching between one mode in another because the way the congestion signal being calculated is following two different sets of equations so in between one we\u0027re doing the mode selection we just added a linear linear interpolation to ensure a more smooth transition of the reported congestion signals that gives a more basically that avoids some of the radical changes in the algorithm sort of in the sender adaptation and then finally in our last penalty function in previous versions we\u0027ve been following a linear sort of a mapping between observed packet loss ratio and corresponding delay penalty term in this version we have changed to a quadratic after some experimentation we find quadratic form a mapping between loss and corresponding delayed tends to kind of penalize hold back the nether flows at lower link rate that was all sold but basically motivated to make nada work lower link reads not to starve other flows so these are the main changes and next slide I\u0027m going to maybe explain a little bit more for this self adapting thresholding part basically in the previous version of the draft we simply picked a kind of an expiration date it\u0027s kind of our expiration time it\u0027s a fixed threshold to to consider whether the flow has observed losses and you know if if the flow no longer observed losses within a given period of time it will try to get out of the last base mode that obviously needs to be tuned for different link capacity environments because TCP sawtooth will have different widths for different and delaying vendors products so in draft l5 we actually adopted the the calculation used by DF RC for calculating an average loss event interval and we use that as the basis for coming up with a threshold that now self adapts with this measured average loss interval so this makes the algorithm a little bit more self scaling as we were seeing the results and then of course to be a bit more tolerant for "
  },
  {
    "startTime": "00:21:16",
    "text": "missing a last event or two we add a constant multiplier so there\u0027s still a parameter bid to be tuned but it\u0027s much less sensitive typically we can stay with the same constant multiplier and it worked worked with a wide range alpha bottleneck link bandwidth to illustrate this on the next slide and basically I\u0027m showing the experiment of test case 5.6 in the rampant eval test draft but then by changing the bottleneck capacity so on the left you see the result where nada the blood flow is competing against TCP the purple at a shared bottleneck of one man and on the right day Shira bottleneck of 10 meter per second so the the rate TCP cut its out of sort of out of range for this plot but what we want to show here is that in both cases during the middle part of this experiment where TCP starts nada sort of correctly operates in lost base modes even though the TCP sawtooth behavior the width of the TCP and you know sort of is widely different between these two so this is an illustration of how the self scaling and helped us to for the algorithm to correctly switch between the mode without having to can tune them for different environments next page and then this is more a summary so for test case five point six and we really want to ensure that it\u0027s kind of robust for a wide range of environments so we followed actually kind of the I would say like the suggestion or the exercise that Julia was doing himself basically by sweeping over different bottleneck bandwidth and different propagation delay values and here will report the average rate the NADA flow obtains while competing against a loss based tcp under these varying characters so there are two regimes on the low bandwidth case let\u0027s say below two men per second we can see that regardless of the path propagation delay and in this updated version of nada we shared the bandwidth with TCP roughly equally basically were getting approximately half of the bandwidth now when we get to the high bandwidth case ideally that\u0027s where the total link bandwidth could have accommodated a nada flow at you know source back straight without backing off at all and then you disappear on top of it but because nada is still reacting to losses as a measure of congestion suitable ever so slightly so it\u0027s backs off very occasionally as you guys have seen through this graph so we don\u0027t "
  },
  {
    "startTime": "00:24:18",
    "text": "get too awkward at our max and also because of the sawtooth widths mmm basically different link propagation delay would exert different amount of penalty I would say on another flow but still maybe the message taking back is that we still can hold some ground and obviously in this case were no longer starving ECG so that\u0027s the main kind of study it for and improving the robustness behavior of nada in the last flow competition environment and next page now the other thing we changed in terms of our evaluation approach for the code that is kind of sorry for de nada congestion controller is somewhat tied to the traffic source we use for driving it previously or our experiments are reported mainly based on this what we call it the perfect orbit basically it\u0027s like mimicking CPR behavior codec but then one experimenting with dist and TCP base flow we realize that with the video codec behavior one main thing is that for a given fixed and frame per second certificate for a given frame interval at least the flow has some crescents you know on a periodic basis so we added a new traffic source type in our implementation of the sync codex that\u0027s more tie to the video traffic model and dropped where instead of spreading out let\u0027s say at very low rates instead of spreading instead of having a very wide packet interval in this case we actually still have a fixed frame interval and also based on the new traffic sort of and then the data analysis with it we presented critically at IGF meetings we added some random perturbations after frame intervals so we believe this new fixed you know so called fixed FPS codec is a more somewhat more realistic you know sort of modeling of the video traffic behavior so for all our test case evaluations as you\u0027ll see later we use this one as default but of course our implementation easily supports switching between different codecs the other one we added is this hybrid codec which the main most of the explanations are in the video traffic model where basically will combine the trace collected from realistic encoding experiments with some statistical modeling of the transient behavior so that\u0027s another one that an applied updated there the current video traffic model has already described and now in our Cinco that\u0027s implementation which is catching up so let me just insert a brief status update drive for the "
  },
  {
    "startTime": "00:27:18",
    "text": "traffic model draft basically as to our understanding there\u0027s no more sort of outstanding issues or sort of reduce that we want we I think we have basically completed all the things we have we have sort of and wanted to control so that draft should be ready for further review and maybe working group maskala yeah but where are you not getting enough review and the code is of course available online and next page so now getting back to the other an open source code that\u0027s the NS 3 rampant code we have presented its structure and how to use it kind of more in a forecast manner in our last and intermediate meeting and now finally we\u0027re happy to report that we\u0027re ready to release the code I just checked the link before joining the presentation my colleague Sergio has already sort of released the code so the link it\u0027s not really soon right it\u0027s our line available now yeah so and we we really welcome people to take a look at the code and you know it\u0027s basically implemented as a standard and s3 modular and somewhat follows the conventions of industries of modelers and also it adopts the sync codecs as source using sort of the submodular import mechanism and it supports reference congestion control implementations we have provided two examples that dummy controller where you can configure you know descending grade from explicitly and whatever you configure the the controller just sent at that rate and you can change on the fly and another controller which more or less and follows our draft description up to version or five literally so and then of course hopefully with these two controllers you guys can get the idea and you know do your own controller we we have designed the code so that it should be we think it should be easy to add and try out your own and we encourage people to give us feedback on that and then also in this referee reference implementation we have and support for the test of both the wire test cases and the Wi-Fi test cases that\u0027s the section for in the wireless test case the missing part is cellular and that needs we need some additional support of that one there\u0027s a question should I yeah Janek so does your simulator use I\u0027d use this the feedback is specified in CC feedback or is it still using one packet per feedback message I don\u0027t know they were sometimes a great question because and while we\u0027re developing the code the feedback messaging a draft is still kind of evolving so we\u0027re basically using the basic per packet feedback but we have already embedded you know to do to to "
  },
  {
    "startTime": "00:30:21",
    "text": "catch up on the draft yeah so the next page yeah now now I just flipped through maybe bear with me with a few slides of update on the results this one is to show the test case five point one that\u0027s you know where we will first try our case and we just I just want to show how it works for different traffic sources the CBR like and the fixed fps that\u0027s the new default that before that we use adopt for all our evaluations as you guys can see it more or less follows the same behavior but there\u0027s a little bit of I would you know noise or valuation because of the frame interval perturbation we have added yeah so the name is a little bit misleading it\u0027s not fixed fixed it\u0027s really fixed width perturbation next page and then these are the behaviors when we have the hybrid codec where the frame sizes are and using in sort of recordings of encoded frame sizes so sometimes you know sort of the code I guess the codec output is lower than what\u0027s specified and then the one on the right is for content sharing which is and there were some discussion I think early on we\u0027ve previously found the mailing list which it attempts to mimic the behavior of slide sharing behaviors occasionally this big thing otherwise the the frame sizes are very small next page and this is the case where I\u0027m showing the kind of the before and after for an the test case 5.2 as we reported in the previous meeting and in the testing so previously our last week behavior were still fairly fragile so in this case it actually got lost in the last base mode but after our can somewhat tweaking of the last base we now got a a better result you know for that part of the graph and then everywhere else you just see a bit more sort of random fluctuation understanding I receive it next page so the other one that at least personally I always want to check is this case about you know wrong path round-trip time fairness so as you can see in this new version we still converged the same route regardless of the difference propagation delay each flow and experiences and on the end of but then the flip side is that the standing grades are that you know not as smooth as before bidders now we have this fixed at PS traffic source and it takes also very even a bit long to converge next one so that\u0027s kind of "
  },
  {
    "startTime": "00:33:21",
    "text": "all the evaluations results I\u0027d like to share during the presentation I\u0027ll be happy to send maybe a PDF document on the mailing list for maybe on they can to to the for connection of results for people to review and to summarize the draft changes from all four 2:05 that\u0027s the change we have already made the main changes are really in updating the algorithm descriptions as sort of as I just explained for the Lost based behavior and I believe that one have also addressed and sort of some of the review comments we have got from working group last call reveals and going forward we have more recently collected some additional review comments from Ronan and also Michael has pointed out some kind of mistakes and in our use of normative versus informative preferences so we\u0027re basically intend to collect additional issues that were aware of basically update update and fits those and also update the section seven on implementation status just want to check if my audio is fine because I think my slide is gone my slides ago I can rule hear me correctly oh great yes so somehow I can\u0027t see the slides you Oh okay if the people in the room can still see the slides I have a local copy so I can keep parking if you don\u0027t mind basically for the draft yeah we and so these are the things we plan to update pretty soon probably I see even you know doing the course of IETF 100 we can update the draft because these are things we already have information Oh you "
  },
  {
    "startTime": "00:38:31",
    "text": "you you you you you okay can you can you guys hear me I hear some what we heard yes but I don\u0027t I don\u0027t see this okay great so the slides is back it\u0027s a it\u0027s a live test and you know like oh oh life systems it yeah sorry for the the glitch in between yeah basically I was trying to mention that for our planned changes all these we can complete very quickly because these are things we already have sufficient information I\u0027ll maybe my question back is like what happens let\u0027s say after we submit all six that I\u0027m expecting as if I end of this week but we should be able to update of course we want people to review the updated changes but maybe process wise do we need to go through this and working group last call again or is it more that we can rely on the reviewers who have provided feedback before to kind of double-check the changes we have made and then assuming the draft goes well but are working in parallel now what we want to do is or as a next step is to start thinking about real world experiments are moving beyond simulation we\u0027ve previously have collaborated with render a little bit "
  },
  {
    "startTime": "00:41:32",
    "text": "and got some cut his help in trying trying out nada in Mozilla browsers but we kind of dropped a threat you know due to time constraints now we feel like since the simulated version the code is out we can come back and look at experiment so that\u0027s what we want to focus on sort of experimenting with embedding nada in the the Mozilla open source browsers yeah that should be the end of my slides I yeah in the back up I have a few additional results but that\u0027s more like if people ask to see specific rooms okay Thank You Sachi so regarding the process so as you have now made some updates to the algorithm we will run a second working group last call on the graph and that in parallel of course during that the previous reviewers also can can check that they are happy with the with update okay sounds great yeah do we have any questions or comments for charging anyone you want some one question about this lost based behavior did you evaluate it with its CB or like model or is it was it with the smaller real video model well not the real Victor FPS so in our simulation for instance for Tesco is Python 2 we have also tried out a CPR playlist and for also all sorry I take it back I should not so five point two four five point six in our simulation we also turn on those other traffic sources but if I remember correctly get satisfactory results early on but then after we tweak the algorithm would include visited as much yeah if you\u0027re asking about CPR please be John Lennox I guess sort of a related to my previous question guys in your experiment when your plans for experimenting in the Mozilla browsers what do you are you planning to implement CC feedback there or is there some other I know they have various other preliminary mechanisms but he plan to use for the feedback when you\u0027re in Mozilla experiment or you don\u0027t know yet my understanding is that it\u0027s basically four algorithm to work with my Trinity we kind of need per packet information writer at least at the receiver we need perfected observation of the delay and packet loss we may need to look into whether the current feedback mechanism already supported only we need to add some bigger based operations yeah so yeah I suspect what you\u0027ll need is in fact CC feedback which will also be useful for testing with our CC feedback is actually workable yeah I think that "
  },
  {
    "startTime": "00:44:33",
    "text": "would be really good and touching it would also be great if you send the link to the full set of experiments that you have performed and the version also has access to that when we do the second round the working group last call sure yeah I\u0027ll probably send out a link you know sort of like a Dropbox link so that I don\u0027t you know yeah yeah I made it new box yeah it\u0027s a big first yeah yes so it\u0027s accessible okay thank you searching thank you then next up is Ingmar spicy food okay okay good like this and the mm presentational tom screaming experiment with the sort of an application that is outside the original intent of this orrin cat working and it\u0027s were doing it using it to remote control vehicles on the picture you can see a robot and below students at University Lily University of Technology I sorta just took this scream multi camera and that\u0027s the control software and put it on a probable chastised with although the remote control we had a lot of fun with it and do it intentionally in long run it will end up in a mining truck switched on mysterious matter is wrong that is not just fun and yeah I can take the next slide and if unless I guess everybody knows what it is about it they\u0027ll be about going from a crappy video image when you do remand it want to remote control a car or something for whatever you want to do a reason you want to do it do you get something that is more stable when some somewhere around here on the left pane you you should see a a core that\u0027s what returning our own little fuel use congestion control you although the top can see the core I can hit the brakes in so you don\u0027t hit it and the thought is not visibly that it\u0027s on the left hand side you had almost one second delay in the video and okay connectors next right and the problem is that in order to do remote control and you want to have a remote control user that it doesn\u0027t get exhausted after work one one off all resolved you need to have very good quality and that is for the ergonomics done you need to have several cameras in order to get the were almost strike driving experience and I can\u0027t first video is important also and "
  },
  {
    "startTime": "00:47:34",
    "text": "although that results in peak paid phrases can exist 30 megabits and and even though well we posted LT and fair foggy deployments can can guarantee higher uplink bit rate the reality sometimes you end up in congestion cells or very coverage some or combination of the two so any sort of remote control operation needs to be raised adaptive that\u0027s quite obvious and you can do some enhancements to improve performance you can then for identify the network and that is talked to an ongoing process all the time on and you can article quality of service you can prioritize if you want to talk to a commercial application you can prioritize user not a bear with higher priority for your remote control applications and also add the explicit congestion notification to it all to load packet loss as to congestion sing-along get these emotions done but the thing is that I\u0027m going to present just without the without the tube lower bonus did you know Key West on Noah is young can take the next slide and what it looks like if you\u0027re a remote control and don\u0027t you want a congestion control is that just get the camera feeds from the left hand side from the remote entity and just fire and forget it or TV or UDP and whatever sort of bit rate that is too much will be queued up in a network or dropped in the network and can get you in the lane or one second in LTE or prank before we get lots of packet losses so it\u0027s not very useful and invested better cases it works but then when it doesn\u0027t work you not want to drive the car okay you can take next line and the what tell you what you do that you hadn\u0027t and at the at the congestion control on the center side and you don\u0027t own feedback on the receiver side that was the in this case it\u0027s it\u0027s creamy and it takes to all the RTP packets and it sort of feeds back sort of betrayed information to the back tuning coders and also you can have some sensor data well all different coins that use and UK you try native congestive cultural ties to keep the network you know and that\u0027s good for interactive control and it\u0027s sort of a avoid running over an elderly lady and it\u0027s implemented in running code and using a sort of off-the-shelf cameras to detect the next slide here and if you take screen with one page previously although you have followed a turret or should be fairly familiar with it stands for self clocked rated at Asian for multimedia it\u0027s a window based congestion control and pretty much like "
  },
  {
    "startTime": "00:50:34",
    "text": "TCP but without the retransmissions if you want to do retransmissions then you use the normal or TP or retransmission mechanism and it acts on packet loss as well as delay and also be seein is the easy on is enabled in a network and what you do q the OTP packets can be temporary queued up in sender you don\u0027t send more data than that\u0027s actually Toto act in the in the network and that can be image can some can have some cue in delaying and understanding side as well it developed since 2014 and it\u0027s actually now lo and behold is in normalcy editors cue after a long while long wait and it has been a long run but it\u0027s a long journey but is enough soon finished you can conducing with your loss to the media that is packed in our TV it can be video audio haptics motion JPEG and there\u0027s all this still image on the stuff but it\u0027s mostly only the video that is tested that much and let\u0027s Optima try it out multi-stream handling and prioritization we can hook up several sort of cameras or a sensor so that stuff and we can total prioritize one or the other the prioritizing work stills always not in exact prioritization well you show us some more about that available as open source it can operate between bottlenecks speed so like 50 kilobit per second up to and it has been tried out to honda megabit but the on a megabit is not with fake video coders because we don\u0027t have any video coders that\u0027s pre us on a megabyte video right now ongoing work currently working on l4 s support and almost done and will be pushed up to the screen don\u0027t get table when it\u0027s done and there will be store to the student project doctor willing integrate scream energy streamer plugin okay next the feedback it\u0027s not the sort of the proper feedback format this sort of a home a girl home room a feedback based on XOR and it has Authority calculates accumulated size of easy and more fights and add some nectar on a timestamp but all the all this can be replaced with a a VT course easy feedback message when it gets a more mature which is terribly even fairly soon and also at supporter bonding if more than one stream if you have many streams now you can send one or more TCP feedback for each stream and that cost of little bit or it can say it\u0027s on Mary or TCP overhead of if you bundle what is "
  },
  {
    "startTime": "00:53:35",
    "text": "it / packets yeah and the most challenging works has actually not been network congestion port that the if if I was allowed to sort of count the number of hours that spent with this so roughly eighty percent has been to cope with a varying bitrate from video coders your keyframes there are lots potrait variations and also the case at all funder quantize are still changed on keyframe intervals so if you in the middle of the road or a group of pictures want to change the bitrate it\u0027s not a guarantee that you\u0027ll that the Bitterroot will go down on up up and often hard work video coders video coda striping cameras they\u0027re very limited tuning capabilities and that has had Lord she impact on the design of the congestion control its additional checks and balances in the code that is not necessary if you had sort of an ideal video coder but reality sort of forces to add extra code to correct to cope with that take the next line and on the sender side here I used reuse the sort of IP cameras of the Panasonic brand and in order to make them stream OTP do you actually implement the North ESP client for each camera and you sort of thought if he stream on make it go through go through this cream sundae what if everything is multiplexed that\u0027s not my question on that okay Rhonda you\u0027re up for a question one quick question on the graph on the previous slide I take it you\u0027re running the video encoders with fixed interval iframes and I would presume also the that\u0027s that\u0027s because you\u0027re not handling error error recovery via other mechanisms like retransmit and so forth is that is that true yeah there\u0027s no no way every color oh and also nothing at all because it\u0027s an IP camera yesterday you actually can\u0027t request sort of the OTP regions missions I don\u0027t remember or TX and of course arm cat supposed to work for streams that aren\u0027t necessarily web RTC streams so some of those will certainly be non error recovered okay yeah the congestion the sorry so always talking about congestion server though the complexities are quite modest currently it runs on a Raspberry Pi 3 and it consumes like five to ten percent sort of a cpu power and don\u0027t have the "
  },
  {
    "startTime": "00:56:38",
    "text": "exact figures because the Raspberry Pi implemented a sort of a VPN tunnel as well so and it was served below into a 20% when you\u0027re running at higher bitrate so I had the students doing that work for me so okay and we can take the next slide and or ECU aside us or to demultiplexed the treatment and play out on different photo GStreamer play out demo that\u0027s about you know and the players are disappear quite low complexity there is scream receiver is sort of dump it on dump it\u0027s only take a record three receive packets and create a feedback so and as we go to a stream prioritization and the objective is to ensure that you if you have an important forward camera for instance you ensure that that camera gets the most of the largest share of the congested bottleneck if you don\u0027t tell the congestion then your own stream all the cameras would get the high bitrate but it\u0027s only when you disturb when a battery starts to be get become limited that you\u0027re sort of a sort of prioritize between and it\u0027s something that\u0027s called weight weighted created pay scheduling with a configurable of weights and you will probably call it something else so and that alone doesn\u0027t help but you need to also totally enforce with priority rate adjustments to make it work and that is because there are video coders that you cope with and some sometimes don\u0027t we\u0027ll give you a median code or insider even though if you\u0027re running with the sort of remote control perma boils and you can have a very low activity in one cameras it could be facing just a blank wall us off like that and in theory with these kind of setting on priority the front camera would get 72 percent of the oil congested bottleneck and a rare camel for Laura fifth 14% and left and right we get too much lower Sharon but that is in theory on the next page I believe shows what it looks like in the real test drive and you can see that on the upper upper sort of a graph you can see that every spit rate is something it can peak it Peaks up to like 24 megabits per second and you can see that the front camera very very quickly Congrats the higher-self highest and the bandwidth and the how-to cameras pick up slowly as the see is that the bandwidth inking is increasing and there were tons to say more that are between roughly three hundred eighty seconds and 420 the we\u0027re running in a basement so with very poor LTE coverage there are you can see that who you can get ought to be get lots delays when the link throughput drops and that is not much to do about it and one reason why you get is that it\u0027s "
  },
  {
    "startTime": "00:59:39",
    "text": "only delays pay delay based congestion control I had to turn off actually the lost paste port because they have some mysterious uplink packet losses even though it\u0027s LT shouldn\u0027t be packet losses actually because but it seems like populist leader some kind of a very narrow path sort of a a shallow queue in the uplink processing at the drops packets because you don\u0027t see that much of a ik you in the name of stealin a packet losses so it\u0027s only today based and and sen would be really good as it\u0027s very very high on my wish list before we pour our before unretired and just joking not an inter quite a joke but where it goes and in some cases could be that the congestion window is the doesn\u0027t react quickly enough to increase delay and this could be a setting issue there\u0027s a lot delay based ranching and no you can see that actually the prioritization it works fairly well but it I believe it is not reasonable to assume that you can extract priorities and agree for that purpose is the four priority levels Israel is good enough you can\u0027t expect in reality to get much high granularity done that that is my impression of list next slide how much time I spent you can add the initial impressions to this extreme privation and the average behavior in general isn\u0027t it looks quite okay in some cases you have some glitches in the video but if the benefit is actually when you have many many cameras if you end up in poor coverage so all of a sudden is that the low priority camera will take the hit because of the weight is scheduling so even though you sort of get them dramatically can reduce throughput the front camera will work quite well so and we get some kind of tunnel vision effect with the throughput drops basically when you\u0027re driving in a basement to the side cameras were just crap and let cool burner and some room for improvement and is that easier to switch off some cameras in very problematic conditions add some extra code you have to turn em off or just disable these streams and also verify this runtime priority switch and there is an external sort of a mechanism you can open in re in the runtime you can switch if you mean for instance want to reverse your vehicle and you might want to increase the priority for the back camera that is implemented not not try it out so in knowledge real media all in simulators next slider you and easy and support yes easy and works "
  },
  {
    "startTime": "01:02:41",
    "text": "unless alone no shit Sherlock yeah what else is this actually in the LTE carrier as doing ecn for you or no it\u0027s all in the LTE is there still lacking is gen support where is the where is the bottleneck that you see on is doing something useful for you where is the bottleneck that it\u0027s giving you is useful easy n Sigma C who\u0027s mu stirring the marking in this case I\u0027ll be really huge still know how to sort of educational especially actually in 3gpp need to educate sort of convinced that is a good enough in this set up is as big bottleneck actually running and the dr. groves all simulations and the one is without a QM and our right hand side its way code code Ella with easy on and you can see that if you implement these yen you get more stable sort of queuing delay and actually more stable bitrate and this is totally the mimic sort of a keyframes also run it\u0027s a draw the complex video source and if you if you dare you can look at the YouTube clips we\u0027re sort of run there\u0027s the scream algorithm we don\u0027t VIP Cameron or just me just waving me to my hand son who Eden without you seein enable coder and in that case we chose the three megabit button I can and erased yesterday if you have complex video sources easy and can improve performance greatly so this was a emulated scenario but the one before was the real test yeah it did you sort of him emulated bottleneck that\u0027s correct correct but on your previous graphs that was a real test what does without dzn support of course yeah okay with some I\u0027ll have a question here yes yeah okay can you hear me so actually my question is regarding both for the ECM based one and for the previous one when you say when you\u0027re saying that congestion window sometimes doesn\u0027t back up in turn what are the corresponding packet loss rates that you observe because the cloth don\u0027t really report us the flows experience sort of packing losses you mean in this one you actually have in this case this is lighter what is it well water okay so for ECM basically you\u0027re saying then what\u0027s the truth the marketing ratio yeah yeah I know in this live test there was no easy incapability Network yeah what you saw is that you have you had you have the occasional packet losses they are not "
  },
  {
    "startTime": "01:05:42",
    "text": "that annoying actually when you\u0027re on but they\u0027re still ugly they\u0027re still too much for being used in a sort of a real commercial deploying not done before we want zero packet loss especially with video but as it is now if remember correctly goes like 0.5% packet loss which is a bit too high for video and the possibly one can use retransmission to cover it out but then again you a delay end-to-end like it you see also do for reflection is not an option because the packet loss is coming burst it could be burst of 10 packets lost under that it can be difficult to formulate correct unless you use the interleaving or something like that what get more complicated as a packet loss is coming burst and that is also an indication that is that a tail drop cubes on board go there is no other traffic in the uplink what an answer enough for sure maybe a quick question so when they\u0027re saying that the packet loss ratio is low only 0.5 that\u0027s kind of averaging over the entire session or is it sort of locally because if you\u0027re saying that forward error correction doesn\u0027t work it seems to be indicating that the instantaneous packet loss ratio can be too high hapc to come yeah in this case it can move yes we\u0027re trying to get in contact with the ship\u0027s tech minders actual to see if they can resolve this issue because it shouldn\u0027t be packet losses it\u0027s not though it\u0027s outside the LT specification because there\u0027s the barriers that are used the Q\u0027s here in on various they also to default Paris and they use acknowledge mode transporting operand it shouldn\u0027t get any packet losses but still you get them though it\u0027s an implementation issue the whole time or did you you said you\u0027re in a basement part of the time did you drop down to maybe an older specification as you were in some in some cases you have less packet loss yeah 3G or something in poor coverage scenarios it\u0027s getting good coverage also so it\u0027s a it\u0027s not a real a matter of coverage I try to sort of study the issue and as wasted a lot of hours trying to track it down loss in the queue so this is where the loss happens I guess yeah there is some cues on where that drops packets that is among what will believe it\u0027s a bit too hard to track what the issues are I think the bottom line here is like in the uplink is not optimized port this kind of thing I mean we\u0027re running like 30 megabits per second and appling video this is it isn\u0027t even like never been thought up yeah when they\u0027re making the "
  },
  {
    "startTime": "01:08:42",
    "text": "product I think it\u0027s a specification perhaps in production I don\u0027t think like they have and I think in order didn\u0027t mention like they tried multiple vendors in multiple more amps and they all have same problem so this is I I personally don\u0027t think like any condition come from can solve that so there will be package losses until the implementation is done so I as you mentioned like we\u0027re talking with the some of the chipset tender and say like if we can solve the problem and that would be really good to say yeah the uplink is they 4lt or or any rap technology radio technologies that there is a synchronous system in downing an uplink and up ting is not just not optimized yeah and we\u0027re trying to get every bit of it and I must say like this this put this scream with my expectation was far like well we need to do lot of tuning to do that but humor tells me that\u0027s not the case I\u0027m really happy to hear that that we can use in such such is like really high demanding cases screamin thank you I really very also joking that y\u0027all take the price laughter LT is a currently optimized for a point up bring it to optimize for the transmitting pictures of your capture or flowers or fluid or your kids or whatever this is has not been on the table earlier but they\u0027re hopeful it will oh sure so actually maybe I didn\u0027t clarify my question so I was more interested in when you mentioned that like there are places where the stripper jobs and the congestion window doesn\u0027t back off in time presumably that would introduce self-induced losses right so I understand that the uplink sort of has some let\u0027s say non congestion in these losses mysterious throughout but I\u0027m more interested in maybe the understanding of whether there\u0027s any places where it\u0027s a kind of a self-imposed a lot due to congestion yeah yeah of course you get more packet losses for instance at 360 seconds that\u0027s correct sure so having a packet loss ratio trace graph would also be helpful yeah yeah I would of course I\u0027ve been i thing is that a turned off a packet loss reaction because with their packet loss reaction i\u0027ll good we only go to like two three never make a bit per second and that it because you also produce packet losses or not the really congestion relate about this or just occur sure you can turn you can tune your algorithm to ignore losses but it\u0027s a different thing to say in the evaluation to still report on the kind of the last race yeah that would be very moody yeah no but by the way it\u0027s a very cool use case "
  },
  {
    "startTime": "01:11:42",
    "text": "I I think it\u0027s much cooler than you know making boring conferencing videos so yeah I really like that actually the students had a lot of fun with it ya know we can now look at with yourself and you have a private love I can we maybe need to speed up or follow up quickly on searchings points I mean that there was the discussion of PPR in I think I see CLG earlier this week and they got some strong feedback on ignoring packet loss myself and you shouldn\u0027t do that I say it support the record don\u0027t ignore packet loss just but in this particular case I needed to do it knowledge get things running so but it\u0027s not okay okay that\u0027s a kind of conclusion at you you can get a high quality video with a video feedback for a remote control application by using congestion control your words are getting black screens and long delays and that\u0027s often and it follows to Shannon quite good and it toaster I expected worst behavior especially when you\u0027re running in the basement but you had really poor coverage on and even video with complex the video caller that you\u0027re using and it they are not freely adapted for or for real-time application they\u0027re all adapted for surveillance and and still it works quite well and it you get good quality I don\u0027t need man spend more time on how much time do you have your whole time for extra Sora 15 minutes left and we have sine T value time for this right good I think it\u0027s good if we can wrap up yeah yeah okay thank you for watching my very interesting to see working in production so before I start I would say like don\u0027t in ignore the packet loss but use something like called ECM to actually solve the problem not try to try to have too hard on your constituent class all like all packet loss issues that would be my messes so here my name is Jo Jo shorter and I\u0027m going to represent the RM CAD design team today so the arcade design team I think those who have been following arm cat knows like we\u0027re trying to do some condition january condition feedback messages so next like so what we I\u0027m going to do like tell you like what we have been "
  },
  {
    "startTime": "01:14:42",
    "text": "doing so far and what is the current status and what\u0027s going to happen in every Cove so in after ITF 94 as far as if I\u0027m correct we the arm cat group working beside it like okay let\u0027s let\u0027s analyze all the requirements from different proponents we are at least have three proponents at that time and the initial slide with three circles represents that one so we have three candidates they have different kind of requirements the design team was from so that okay look into the recommend see like if we can basically find their generate feedback masses then they were the design team have been working almost like two years now then they have been meeting and have been producing different kind of analysis and results and finally produced at design and presented as a to kind of format excel block and an artistic messes then we presented this to every T curve because I\u0027m cat doesn\u0027t have the authority to finalize the that kind of thing it was not chartered to do that so we went to every to go and say bike well this is what we have now Excel block based and we have artists and then we get some feedback and I think the most the the sizing factor was the deployment deployment possibility so people has it was noted like people has more experience with participe kind of feedback and they have like you have fear you have timber and all this thing there so it was saying if the comment was like if we we can drop the exit block and focus on this artistic way feedback so that get perhaps more deployable so that\u0027s what happened next slide so this is the this is the this is the goal if you if you don\u0027t remember this is a recap again theory as I said the design team was formed to analyze the requirements of the candidate algorithms and then try to say at and and generic feedback process and the main I think one of the main reasons what to do that is interoperability so basically one application that implemented say GCC and they want to talk with scream or nada and in a communication point to point communication or whatever them should be able to talk to each other so it not everybody need to implement all of them because we had any situation like I don\u0027t think like I\u0027m cat in a situation right now that\u0027s really well for experimental purpose will have three candidates up there so this was one of the things that okay if we have a common feedback message then we solved a lot of issues will so next slide so the design team have been looking into different requirements so one of the things like "
  },
  {
    "startTime": "01:17:42",
    "text": "okay we need a packet label kind of information and also there is a consensus in this group arm cat same like we\u0027ll go for it Anubis adaptation because there is lime some of the algorithms were like receiver based some of the world could be the most sender based I think screamo standard based from day one and then GCC came and also become a sender base or hybrid kind of when Nara has been doing receiver base but they also said like a centerpiece might be really good and they the reason for sender base was basically more manageability and deployed again so these are the design team when we looked into that one design team I kind of have three kind of information that\u0027s important one is a packet and in fact that\u0027s the RTP sequence number you basically see like you can calculate loss on top with that then you have packet arrival time that\u0027s important you would like to one of the big input to our algorithm design have been the delay and jitters and obviously you would like to use you so basically if the pure path is supporting you say and you have you seen more big you\u0027d like to also convey that back so these are the information we said like well these are the we all agreed on like these are the information you need and the next phase is to have the packet format right yeah so we also said like this would be information and this will be sent by group group by ASUS or C so next slide so as I said like now we have only one packet format where a packet from the destined that\u0027s one based only like trans artistic transport layer feedback messages and this looks like this I think I don\u0027t need to tell you like there are some header here like on the top and the bottom like basically before x term that\u0027s the that\u0027s the thing come up with header if you I think it\u0027s 45 85 says that and then we have for for this feedback message we had like beginning sequence in Sabine\u0027s for one one kind of sourcing when you\u0027re reporting it you have a beginning an instance occurrence and that\u0027s like the number of packets you are reporting and perfect basically block we put block and then we have LB saying like whether this fact that it has been lost or not if it is lost the ecnv and these arrival time upset August zeroes and then basically easy and obviously as I said like we need to send bill you send back the information whether the packet has been you see an experience a lot not and then also you have a arrival time offset and this offset is calculated from the reporting time stamp so basically when you\u0027re generally put you kind of put how how like how do you call it in behind or have in on past you have received a packet yes so the this was the this is like how it "
  },
  {
    "startTime": "01:20:44",
    "text": "looks like and obviously as we I think the solution packet type was like 205 just like a suspect so with this we also also thought about like okay the different candidates also had different I mean they did tend to send in this interval report in different interval and we only analyzed their proposals it was between 50 to 200 milliseconds and the decision the design team was like okay you negotiate the interval either you have some before interval and then you can negotiate between these two and there was I think Colin did some analysis and it was shown like you can do even like per frame or media frame you can have if it generated in for a certain needs cases right so this is this is how it looks like right now next slide then so the colonists are like this I think a chairs already said like now this design team draft has been replaced by a verdict or every core working group will be taking the CFP that\u0027s the new kind of name maybe you\u0027d like to use like timber or something this year be yeah something new so the video will take this draft and make it finalized through the external process and they expected countries like you have a stronger RFC okay so this is the current status and next slide so what happens to our accredited design team I think this is up to the working group but from as a Adam Caddy\u0027s until 8:00 I also like job well done we have done it for the way we have this that\u0027s why I put the goal there like what are we supposed to do and to me the draft looks really good there are some I think there are some editorial chairs needed like there are lots of places we use the term design team and all these things so that need to be changed but I don\u0027t think there there will be too much fundamental changes in the information required or the packet format and obviously you can you can say like there are like during this process of this packet selection a package perform at you have been analyzing different like well Brannan relief or like lost packets its put ecn mark marks in a separate vector so that you didn\u0027t descend it every every kind of report blocks and stuff like that I mean all this optimization could be done and we can revisit all those things but the basic information needed for a center-based algorithm to work that is kind of fixed the packet format can always you can ship here and one bit here and there but I don\u0027t think like you need a design team to do all those "
  },
  {
    "startTime": "01:23:45",
    "text": "thing so I think we can just conclude the design team and on equity core we take and the comments as it is my proposal would be like everybody follow this work in a VT core and maybe our authors of this draft we can sometime if there\u0027s a major change happen or any progress happens in every tick or we can come back and give in a at that of that one but I don\u0027t think they for all those things you needed isn\u0027t him that\u0027s that\u0027s what I said I think as a PT court chair I mean the two things are certainly when we do working group last call in abt core we\u0027ll make sure to notify our mcat to say please review this and comment on AVG core and then the other thing is if the if this is a you know if the document authors choose to keep using the same methodology they\u0027d use of the design team that seems to have been quite successful so I\u0027d be happy if they did that but it\u0027s same people in a you know did with the different you know hats on but that\u0027s fine Hume anyway you awesome I read the draft only recently unfortunately ignored it before sorry for that and I believe it seemed to be doable to implement it and I will actually when it turns out that it\u0027s deemed mature enough for will sort of implement it that instead of this poster version that are currently implemented about two maybe one comment that needs to be refined is that it\u0027s a feedback per frame that will at least in high bitrate that will cause a scream - hiccup because the key frames can be horrendously a large and if you went for entire key frame you notice and the feedback frame because of delays in the network you can order a clocking if you probably not hit the other algorithms what the screen will suffer from it but I think I think you hear the idea is like no you\u0027re not supposed to like like that\u0027s a target like per frame but obviously you can actually do the range report so you can you can show you can select like I think the amount of time is so this I mean you can configure your artsy\u0027s yeah exactly it\u0027s whatever you like so yeah if you need feedback more often just configure so and also the when we say per frame we mean set the interval of which you the feedback packets to your do you know you\u0027re out the reciprocal of your average frame rate not not actually wait till the new frame all right maybe yeah also maybe you don\u0027t need actually perfect at feedback perhaps even if it\u0027s a big iframe chopping up and do different number of factors so with that I don\u0027t have anything to say actually and I would like to come like thank all the design team members for doing this and it had been a really good experience yes thank you to the design "
  },
  {
    "startTime": "01:26:45",
    "text": "team very good and I think it\u0027s nice if you when you submit new versions you can also inform on the orange cat mailing list that there is a new version so that people are still aware and then they can follow it in the AVT core discussions okay thank you that is the last item on our agenda so unless anyone has any other comments we can conclude for today so thank you all for coming thank you thank you and if we could get the blue sheets please if you did not sign please come up and sign "
  }
]