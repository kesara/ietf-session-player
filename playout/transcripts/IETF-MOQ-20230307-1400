[
  {
    "startTime": "00:00:05",
    "text": "Spencer can you hear us now can thank you so can folks can see the uh participant account is still creeping up so we're probably going to wait uh just a minute or two but while we're waiting perhaps you'd consider volunteering to serve as a scribe or backup scribe all you need to do is let us know your name by putting it in the chat room or speaking it aloud either one would be great thanks"
  },
  {
    "startTime": "00:02:07",
    "text": "okay we really will need to describe um and so I've put on my video so you can imagine me peering down at you as each of you tries to look quickly in your laptop and uh not catch my eye obviously you cannot catch my eye very easily since you don't have your video on um but uh it would be very useful and uh as a remember reminder we don't need uh this person said this and then the next person said that style we have a recording that's all going to be handled by the recording uh we're just uh taking note of the decisions um so it's a relatively uh low effort type of thing to do and we would really appreciate it thanks"
  },
  {
    "startTime": "00:04:03",
    "text": "okay well we've climbed up enough that I think it's probably time to go ahead with the note well um if you are new to the IHF this no will is not the sum total of ITF policies in effect it is instead a pointer to them you can read these reminders at the top and then the definitive information is instead of linked documents in the in the bottom uh essentially there are some IPR requirements and some behavioral requirements that you must adhere to um so we would appreciate your paying attention to this both in today's meeting and further use thanks very much uh for the chat several of you have already used the chat panel inside of meat Echo you can also use Zulu directly um we will use the EQ within the code to talk since this is a virtual only meeting um and we'll try and optimize the queue a little bit if there's somebody who indicates to us that they're direct reply for example let us know that in chat and we'll try and get the direct replies in but generally speaking it will just go in keyword uh source is noting in the chat that he can see and hear fine that's great to hear we are still looking for a primary Note Taker and one backup so if you can serve as one or the other uh now would be a great time to let us know uh because we will have to pause the entire process of three hours uh while we wait for somebody to to sign up for this um and it could get very tedious for three hours worth of looking at this one slide uh once again it doesn't have to be uh this person said X and that person said why it's just recording the decisions"
  },
  {
    "startTime": "00:06:43",
    "text": "uh Alan asks if there's a prize for the scrub no our next step is I will start asking my phone uh to roll a 22-sided die for me and we'll ask people to invent excuses on the Fly uh depending on when their number on the die comes up so really this would this would go a lot faster if somebody would uh just agree to serve this scribe Martin Duke thank you Martin uh everybody else uh we will deputize you as Deputy scribes just leap into the note thinking tool there and help art now remember you don't have to write everything down Martin it's just if we make a decision and hopefully fingers crossed there will be a few decisions today um for Martin and the backup scribes to write down and we can go on from there uh thank you for not making me break up the 22-sided die oh Alex pointed out wheeloffmans.com um and uh again to reflect from the chat um Martin has suggest that if you do say something in the mic and you want to make sure it's captured corruptly please do check out the notes uh as soon as possible well obviously you'll get a chance to look at them again when they get turned into formal minutes but we can check them out earlier if that's"
  },
  {
    "startTime": "00:08:00",
    "text": "even better now agenda bashing this is our current agenda uh Mr via and rules we are two minutes away from the end of that section um so hopefully we can bash for the two minutes and stay out of them and we'll have one hour of discussion around the object model um presentation of the current proposal uh we'll have a discussion of the relays and then the 35-minute section on issues stress results Spencer go ahead yeah thank you the uh the agenda looks most refined uh the one question I would ask is um we have okay so two things two things have uh the intermediary design team since our last meeting and uh one of them is uh we're we're still kind of inventing terminology on the Fly uh and it's not bad terminology but uh you know we have no idea who else you know who what other people might think those words mean um and uh the second one was uh we're a chartered for our for uh an architecture draft and um we're starting to get yeah we were starting to get into some things that might go better in an architecture draft um so maybe uh just adjusting the"
  },
  {
    "startTime": "00:10:00",
    "text": "agenda to uh include something about you know maybe this is under planning for Yokohama uh but basically uh what the plan is for those two uh ideas between now you know between you know Yokohama and then of course Beyond we're not going to finish that uh instantly but thank you uh thank you Spencer looks like there's uh Cullen and Q is what color sorry mine was an agenda bash I was only going to try and resolve the audio issue but it seems to have resolved itself and it's in chat so no worry okay okay um so let's do this uh as Spencer suggests in the wrap up and planning for Yokohama uh I think that might stretch the amount of time we need for that 20 minutes so we'll take that out of the issue discussion unless object model or relays uh goes a little faster than that is everybody okay with that change okay um I also saw in the um in the chat that you're getting a lot of clipping from my audio it is a new system I'm using today so it's possible that it is how I've got the system tuned so I'm gonna um once we start the android model I'll do a quick drop unlapped Alan takeover running the slides etc for that and log back in uh with a different mic in the meantime uh it looks like we have one more slide which is our goals for today uh just a reminder our aim is to get"
  },
  {
    "startTime": "00:12:03",
    "text": "through Yokohama and into a state uh where the authors can publish drafts that can be adopted with the intent that then we would start working toward uh drafts that we can start interoperability testing on um from successive meetings so that's the goal overarching goal uh we think for today we're trying to get consensus uh at least from those of you uh who joined us today on the big rocks the object model and relays um and then try during the issue section to determine which issues need to be resolved before a draft is adopted so that's the goals for the meeting and uh I think we're ready to go and Maria is saying that the audio is fine so I will not log out but I think I will hand it over to Alan at this point we do have things loaded as pre-loaded slides if we want to have them run directly by the presenters so that's awesome Alan which way would you like to do it do you want to run the object model one or do you want the presenters to uh as Christian do you would you refer to request control here or if you want me to do it I can certainly that you do it it's not an issue for me I'm kind of trying to keep it simple uh okay I tend to not see the pre-loaded slides in my view do you see them in yours yes I do yeah okay so it's just to the right of the hand ah I'm looking in the wrong place it was again meeting materials yep for some reason they're all double but they're the same I checked okay I see it says I'm not sure I"
  },
  {
    "startTime": "00:14:01",
    "text": "succeeded in doing anything but it says a new deck is being shared does that come from you Christian okay I see a new deck is being shared as soon as you can see I don't see it okay let me try any any actual day okay um I also see two oh you said there were two copies of everything now I got it okay thank you so good morning or good afternoon or good evening for all of you around the world here uh we have uh one big walk on the agenda as a Ted Pursuit which is uh looking at the moq data model we have a huge thread on GitHub of discussions about details of the appear for data model and discussion of that I've tried to keep it simple in this presentation and focus on the thing that we really want to decide how do I change slide okay the first thing that I've tried to do is start with the almost consensus that we have and the almost consensus that we have is to use tracks as the building block in the moq protocol basically we think of a truck as a specific encoding of a media stream I'm happy to have someone suggest another what the mega stream because a major stream kind of conflict with the stream issue in quick Etc but um so basically you say hey suppose someone wants to watch a football game between Madrid and"
  },
  {
    "startTime": "00:16:01",
    "text": "Barcelona uh they will have a choice of multiple tracks depending of which language they want to use depending of which video format depending of the richness of their their devices and how they pick the track is something that I don't think we should decide in moq because I mean there's a big richness of decision there and that's better left to user agent and scripts catalogs whatever second Point multimedia experiences typically involve multiple tracks and that's kind of obvious if we have a video conference with a streams from a variety of participants and probably many swims like in this case I would have one stream for my video and one stream for the sharing of slides and possibly years to Impossible swim for audio uh those will have to be organized but the organization is not part of the transport itself that's a kind of a decision the organization is delegated to some kind of catalog or maybe a if people don't want to think of catalog as something that you download once and never update maybe your live stream that provides you the upon time since now look at this now look at that kind of issues and which gives you the tracks that you want to compose in order to of the experience so two decision there how user pick a specific track I think should be outside moq"
  },
  {
    "startTime": "00:18:02",
    "text": "going to spin our wheel for a very long time and the same for things like catalogs which are indeed part of the applications using moq but probably not part of moq itself because there are so much variety that if we try to specify that we are going to do either something which is only adequate for some experience or something that is so generic that it's not a standard at all now second part of the thing that we almost have in a oh good the consensus on is the presentation of what the track is and the almost consensus is the track is we presented a series of objects and an object is carrying some content I mean the part of the of the media stream a part of the track uh and that content typically will be encrypted will Point not be visible by realize I mean we we can decide to have extension of the architecture with the equivalent of back-to-back user agents and things like that but as a basis I mean the realized do not see the inside of the media and the object doesn't have just a binary blob of course also has metadata and the metadata is used to manage transmission and we'll go to the definition of metadata later different application can Define what an object is in different ways the most common that we have seen so far is that an object is for example a single video forever"
  },
  {
    "startTime": "00:20:01",
    "text": "but that's just one possibility and also possibly it was discussed on GitHub is the use of layered encodings with a a series of layer providing further one further IO and higher definition on the video and in that case it might make perfect sense to have each layer and call it as an object and I know that we add in the in the in Luke's implementation an object is actually a group of block I mean in the sense of MPEG for a protocol point of view that's not a big issue we we just want to make sure that it can be carried and that these objects can be mapped into the um transmission apis afforded by quick now I said that we had a almost consensus there one point it which we do not have consensus yet is how objects are organized in groups and there is a related point which is how object um how the metadata is used to control Transmission in particular to congestion control so we almost agree but not quite among the issue uh how do we name drugs uh do we have an intermediate object above the tracks that says hey this is a group of truck of some kind and what are the groups of objects"
  },
  {
    "startTime": "00:22:01",
    "text": "let's discuss that a first proposition this first proposition is based on the discussion I read on GitHub and it seems to be kind of the the middle point that people agree on is to treat track names as urls and specifically as OPEC URL uh it is a URL in the sense that it can be passed in the same way as HTTP to find the authority and using the Authority Field contact the provider of the data or the organizer of the data uh but the track itself is opaque the talking that means if it's opaque so in the equivalent of HTTP you'll be that the pass component will be a whatever the application says it is uh it'll be sufficient to identify the track but nobody can go inside nobody but the application can go inside that blob and and find that oh these parts is composed of this and this and that components that I can use I mean gnome and maybe they are but that's for the application to decide that's not for the transport level or the relays so you you have a question now um Christian you want to take yeah somewhere do you want to take an idea oh we can certainly take them and give me some time to to have a breather ammo the only question is the clarification um I hear my own audio Echo um"
  },
  {
    "startTime": "00:24:00",
    "text": "I hope this isn't bad for everyone else the uh distinction between what can be an object one important point that may be lost by um this uh General flexibility to put a kind of granularity of object as a little locked into an encryption will require an author's off tax someone so when we have that authentication tag you typically can't do anything with the media until you get that authentication tag and do and do the decryption so we need to be mindful that that the object granularity um may be uh dictated by what the application wants to render and it can't render anything until it has authentication tags for the Indian encryption context and yes and that's probably some some kind of Overlook there I have this mental model that the authorization is performed when the client or the relay first tries to access the track by asking the origin hey can I do that in fact that's the very reason why we have a URL and another genius that I can have a transaction there and that transaction says hey I am a relay I am getting a client that wants to connect to these moq interim video conference shall I try and let them that's pretty much the authorization part now whether we want to carry the authorization in each object with a higher granularity I did not envisage that because we typically do not do that today we say HTTP even you either you are allowed to read the content of a URL or you are not you are seldom a lot tool"
  },
  {
    "startTime": "00:26:02",
    "text": "just read them in the old lines but we can still debate that later I I suggest that you you open an issue for that is that okay MO okay so let's continue I mean the the way uh we see authorization here is that it's pretty much the same as HTTP it's there the the client or the relays I mean do a transaction with the origin or a representative of the origin to define whether they are able to access the media or not and the relays enforce that now there is a little bit of architecture there and at some level this kind of authorization issue is very similar to what we have in EAP when someone when a Wi-Fi router decide to let you in or not based on some remote authorization service it's very something we want to implement using oauth and it was something that we will have to detail at this stage in the reflection is just something you say Well it happens it happens there I would like to listen to this track there is an authorization Exchange and it's very probably an exchange not just a single token and and at the end of The Exchange I mean the relay is informed that yes you can save that oh no now uh that same transaction"
  },
  {
    "startTime": "00:28:00",
    "text": "can carry more data in particular we have one debate which is very clear in the discussion which it says hey An Origin that is basically The Logical owner of the track it's not necessarily the publisher there are many systems in which the publishing is delegated to some kind of content management system in video conferences the publishing can be done by the different participants themselves I mean there is a rich thing there so it may well be that the transaction there that we do is there that doing the transaction the user will tell oh you want to be look at this football game this is the URL you shall actually use and probably the UI is decorated with authorization tokens and whatever so that you can get the actual content so that there might be some redirection happening at that level foreign close to consensus it's not quite consensus but I'd like to declare consensus the at some point second proposition we have a lot of discussion on GitHub on Not Just Trucks but also emissions or broadcast or think the values nature and we discussed composition we say okay the composition is saying that I'm going to have questions video on that video and and the and the shared slide that's a composition issue yeah it varies over time Etc but in case of some media like say video games you will they probably have several tracks that are requested at the same time from the same publisher"
  },
  {
    "startTime": "00:30:00",
    "text": "and if you have the same publisher you will want to do the authorization just once so you have a question from Spencer okay yeah um thank you thank you uh I I actually put my hand up for the previous slide but um I um Let me let me do the one for this slide as well and then I will only interrupt you uh once um so um could you say a little bit about what an emission is um and if it's just track serves more the same origin um that that could be okay I wish I wish I could I mean I'm not personally convinced that we need that concept but uh but the the idea is as I said the idea is say hey instead of having a client do five different authorization requests for uh one video and another video and and the terror of the video game and and the events from the game and Etc they may just do a single transaction that says Hey I want to get that bundle and and we said that bundle might be named so I get that bundle which is identified by URL which we could call an emission that's a most that's the name most people use for the concept and and then go ahead sorry and then you you do the authorization once which will be the big Advantage there and then as a response to this authorization you get the list of two acts that you shall download or process and then the transmission of those those"
  },
  {
    "startTime": "00:32:00",
    "text": "tracks can start that's that's one model as I said I am I am not terribly convinced uh I I think we could get pretty much the same service by uh carrying a list of track URL that are born to be on the same origin in a single transaction okay that will be that will be just probably just equivalent in terms of transport and number of messages and number of transactions and wait time Etc and will not need to add another concept but hey where am I you can do it would be wrong and so we want to listen here um cool so the the thing I wanted to mention on this one is uh we we had some conversations like in the last four days on the uh in a very intermediaries design team uh talking about a concept uh where basically a media sender uh was called an emitter uh so like I say just I was just trying to understand whether these emissions had anything to do with the emitters that we were talking about on it on the intermaries intermediary design teams um and um I suspect that they're not but we don't have to figure that out now so uh if I go ahead I'm sorry no no I mean I'm looking at other questions I'm putting on the on the chat room as well yeah and and and clear I mean that's a but my my good feeling is that like to have a model that is as simple as possible to say we do drugs maybe we do several trucks at the same time and and then if you want to have a higher level construct the application"
  },
  {
    "startTime": "00:34:00",
    "text": "does it but I mean as I said it's uh we can have a consensus description the consensus discussion at the end of this presentation yeah um so I if I could just uh slide you back to the previous proposition for just one question um and that was basically I wanted to make sure that this was good in your mind does this work the same way uh for people who are uh contribute you know contributing content to the uh so basically uh in HDL land uh yeah put and you know put sort of get so this this is the this is this is if I'm thinking about this for uh contributing uh media this this would be the same well yes I did not go into the details of publishing and yeah clearly we have cases we have basically two views on publishing you have one publishing that says hey publishing media is done through some kind of content Management Service it's not exactly the point of moq the the URL that Define the track points you to the content Management Service and you get the content from there right one View s of view which is quite common in video conferences in which the content is contributed in real time by the participants and if the content is provided in real time by the participant then it would make sense to have that content through relays or for whatever and it would also obviously make sense to have an authorization transaction"
  },
  {
    "startTime": "00:36:01",
    "text": "to decide whether Christian is indeed authorized to send video automatico right now right cool thank you thank you for thank you for both of those Christian okay so now we go to the point in which we have a multiplicity of opinions uh which is the notion of groups we have a discussion about the internal structure of a truck and the first discussion of that internal structure is where that the objects are organized as a series of groups so a drug is composed of a series of groups and each group is composed of a series of objects that's um I think there is some I mean say it like that nobody objects the the one part you can ID is whether we want to tie that to synchronization and it's very clear that any media experience will require synchronization point I mean you you can do rewind fast forward seeking points in the in the media for suing video you can join a conference what it is in the middle of the flow and then you have to be able to join that in a way that is not showing you have to be able to re-synchronize your experience after you have had a network event of some kind so it makes sense to have synchronization points which are defined as you can start transmission from that"
  },
  {
    "startTime": "00:38:00",
    "text": "point and um if you have started with receiving transmission from the point from this point then you can safely play the media and it will be it will be good and what can be also done is that that's what we see in some implementation is that if the system is overwhelmed and cannot send everything it might Amazon a current group and jump to the next one to diminish the load on the network so that we drop in the tail I think I mean decide that groups are indeed synchronization point is something that we should have consensus today because otherwise I mean we are we are going to I would say Wonder in the movies but um and you're and you're starting to grow as people want to talk to you about it but oh okay and then uh finally a proposition [Music] is a on the group metadata object and group metadata for congestion response I mean we know especially if we have relays that relays would have to implement some kind of congestion response because if they find out that they are receiving data from the Upstream at the rate higher than what the downstream can process they have to prune some of that otherwise you're going to make big cues and those big cues make the experience terrible that kind of dropping has to be controlled by metadata of some kind"
  },
  {
    "startTime": "00:40:00",
    "text": "with the goal being that the publisher the applications have a clear idea of what the network of relay will do and they can use that clear idea of what the network affiliate will do to organize that data in a way that makes sense and will give a good experience now [Music] [Applause] um at that point I I wonder and I would have to ask Ted whether we want to have that discussion now or push it to a little time I think I was not asked to have that discussion right now uh so you already have people in queue for your proposition three so let's start there and see how far we get uh just from a time check perspective we have about a half okay thank you yes my Audible yeah that's not a book because I can hear myself um I I kind of agree that uh we need to nail down uh exactly what boundaries groups are delineating and making it so completely application uh specific that the semantics are lost um so one one thing that immediately comes to mind is we uh we may want to consider something like the groups are always uh stateless and the objects may be stateful between them that's a little bit like saying that there's dependencies but I think it's a little bit more in"
  },
  {
    "startTime": "00:42:01",
    "text": "the line with understanding what relays and you know it should be like elements would already understand stateless transactions would correspond to a group but then stateful objects would be more like you know subgroups sub transactions the actual transaction itself you know continues the clarification first are you proposing that object within a group have a dependency to object within other groups no well it's not about the dependencies between the objects it's about the delivery because we're not trying to capture the application semantics because the application already knows it's semantics we're trying to capture what the different elements of the data model need to know about these semantics and for for the relays and the other elements not the application itself they need to know that the group is stateless and and that the objects are are staple between them so that there's space sharing between those objects but the groups can always be served statelessly yeah yes I think we that's the same meaning as saying it's a synchronization point as in we can start at the beginning of a group and we don't have to import the state from outside we can just play it and and indeed we will have dependencies between the objects into groups we are the some discussion of that as discussion of the congestion response because the the tricky part of the construction response is that you you want to trim some of the content of the group but if you trim the wrong content you make the whole media unusable because you have not seen the dependencies"
  },
  {
    "startTime": "00:44:01",
    "text": "and and then that's bad so we we have to have a discussion as well on how exactly we uh we explain those dependencies and um I would prefer that it not be a full graph of dependencies okay dead is it your turn now uh I think so could you go back to proposition two for a second sure hopefully this will be um so I I think that my perspective here is that we need to to get clear the difference between tracks which are served by the same origin and tracks which are served by the same origin which are themselves interrelated and I think you might have missed Cullen's question uh some time ago about whether in a layered encoding the two different layers would be in one track or two um so I think we we may need to to come here and make sure that when we're talking about things above the track layer that we have uh in the mental model both this is a collection a set of things which are not related and this is a group and I really wish I'd used a different word just then uh this is a this is a collection a set of things which come from the same origin but uh don't relate to each other and um this is a uh and Mumble frats that does come from the same origin and where the two things do"
  },
  {
    "startTime": "00:46:01",
    "text": "relate to each other and so I think we have a a question that starts here and comes into group and several other places and what we want to do at a metadata level about saying these bits are related even if they're not necessarily required for um a property independently decodable and I think there's a good bit of discussion in the chat at this point suggesting that for the synchronization thing we might want to rethink the naming of that to talk about you know an access point or or something different but I I think from my perspective the the kind of basic thing of like is this group handled together um I had missed before this proposition 2 and Cullen's question that handled together was by itself even ambiguous when you were dealing with um uh layered encodings so we may want to think a little bit more um about a more generic mechanism for indicating the interrelationships that that may not be as simple as required and not required yes yes I mean well first we certainly need to need to dig further into the representation of layered encoding and I think there are degrees of complexity between different solutions if we have to introduce dependencies between drugs or dependencies between groups that's a fairly big additional complexity I think in the case of layout encoding it will be much simpler to put everything in a single track and to have metadata on the objects in the track to"
  },
  {
    "startTime": "00:48:00",
    "text": "understand how you play them together but again I mean um what what this means is we're pushing this to the application layer and if that's where it belongs that's where it belongs um and I'm okay with that as a as a proposition for this what that turns out to mean then is that the only case where you'll get this track set or bundle or whatever you want to end up calling it is when they're not required they're authorized together but not required to be rendered whether where they're they're not there's no dependency among them for the renderer yeah I mean if there might be the dependencies in the in the form of timestamps or whatever but the application can put that in the object content that's not something we want to be worrying about in the transport okay I think you're ready to hit will up then well okay okay audio test before I speak we hear you you can hear me yes okay thank you Christian uh three points can you switch to prop prop three slide so firstly yeah there's a lot of discussion on the thread with this and she spoke synchronization I think is a misleading term here because it invokes sort of time sync as we're used to its syncing audio and video this is more about joining the stream or accessing the Stream so I think it is a fundam it should be a fundamental property of a group as part of its definition it's a point at which this track which is a Continuum of flowing data that you can start accessing it and the term of the art term of art I like is track access point because that defines what it is and it's there's a lot of corally correlation with stream access point that we're quite familiar with in the"
  },
  {
    "startTime": "00:50:00",
    "text": "dash world second point it should also by virtue of you being able to access it at this point it's going to be independent or stateless as has been previously described so I don't need any other information to start consuming this track it may not be audio video it could be long location or something like that but uh those key attribute is it's independent from this point on the objects within the group may depend upon that group so they may depend upon you receiving the start of the group the third point I think is important is it should have a numeric identifier because that automatically conveys a sequence and it's going to be important for relays to be able to find the last group in order for you to join the track automatically a client will not know where where how where the data looks like in a track and it's going to ask for give me the last uh group that I can join and I think by having them numeric we simplify the sequence otherwise we have to convey it as a separate attribute thanks yeah I think I agree with everything you said okay and and I take the point about the nomenclature according that track track access point instead of synchronization point is is probably uh less confusing look hello uh so first off I think this is a great summary I think these slides are fantastic because there's been way too much text this is a good way of distilling it down um I just want to go over a slide two or the proposition two um as in what's the the point of an emission"
  },
  {
    "startTime": "00:52:01",
    "text": "um the goal in my mind a mission broadcast is the same thing in my mind but it was always meant to be a way of saying these tracks are synchronized as in they share presentation timestamp they share delivery order so they can be prioritized relative to each other uh so you can say audio from this emitter should arrive before before a video from the same emitter for example um there's a bigger question is if you can do that synchronization when you have unrelated sources as in two separate emitters how do you prioritize between them and my current answer is you can't like this is effectively a property of an emission is that it is synchronized um so I think it should be there I think uh composition just a layer on top that effectively says we don't know how to synchronize these two emissions so have that at client um but yeah that's just my two cents um and tracks the scope to an emission so I'm not even sure if they need to separate URL or if they should just be scoped I I hear you I I am not sure that everybody agrees with you but uh I mean the the flip part of that is that if you build dependencies between trucks it becomes pretty hard to manage that in the Twin spot but uh I mean fundamentally I'm trying to like I'm using video real quick to deliver audio before video and I think that's a pretty clear requirement like during congestion you should deliver the most important track first which really requires that they be tied somehow joins or Associated at least and should we do that with uh"
  },
  {
    "startTime": "00:54:01",
    "text": "xpc tweets of dependencies between talks so it should be do that to his priorities let's effectively the priorities the priorities are scoped to an emission which is to say that these tracks are prioritized against each other um yeah I would I would I would do it based on priorities that's delivery order um but that was always the intention delivery orderscope because I mean the problem is that if you want to say for example that object 19 on this audio tracked is synchronized with object 43 on the video talk we can bring in a lot of complexity in the transport I'm not sure if they're synchronized per se but you do need to tell a relay what it should drop and that drop decision should be you know it should depend on the trackses and you drop this object in favor of this object on a different track I mean yeah and basically what Alan's saying is the mission's just a prioritization domain yes okay yes I mean uh I think we should definitely dig further into that okay um I I think my my question and little it in some ways oddly follows up a little bit on it's more an observation about about this layered track so um look clearly I think um you know the relay needs to understand what it drops is the right way of thinking about these two different tracks when we're talking about audio and video and uh it seems like priorities are you know a very direct way to do that um but when we get to a a layered codec we"
  },
  {
    "startTime": "00:56:00",
    "text": "have to wait there's two decisions designed paths we could go down here right we could put them in one track or we could put the two different layers in two tracks and uh the either way the relay is going to have to have enough information to know understand that it should drop the high quality or the you know the higher quality track before the lower quality track right um and it I think it's all right if layered codecs are a little bit more complicated for the application to to deal with so I could certainly see that we could easily do this as those the adaptation layer was a separate track and the relays didn't really need to know any more than they know that audio or video are connected they just know the priorities for this thing that you know it's that all the complexity of conducting those two layers together was handled by the Manifest or was sort of application knowledge the the relays just knew that it had these two different tracks with different sort of priorities for how they dropped and delivered them so that'd be one design um I think the other design would would obviously be to put them in the the same but now if we put if if we put the layered codec uh the two layers in the same track then we definitely have to be putting enough information on each object that it understands the priorities of those objects in the relays notes which of those objects to track to drop inside of the track and it also makes it a little bit harder for a client to sort of say something like I only want the low bit rate version the I only want the low bit rate layer I don't want to receive the high bit right layer and at the point where where you know you want you're receiving the low bit rate layer and you want to temporarily try the high bit right layer and then go back again I don't know so I think that those I think that would be pretty easy to map out what the there's really only two designs there's only you know we have to go A or B there's no other designs they're going to work here it's either in the you know and map those out and and see what they both look like"
  },
  {
    "startTime": "00:58:00",
    "text": "um do you have thoughts on sort of you know which which one of those would be the best design Direction I I do think that we need to have a specific effort on layout codecs to understand what's happening the the problem I think we discussed that in a theater as well is that layout codec our layout in two dimensions they are layout in time and they are layered in space and then you have a rich set of dependencies for example if you are layered in time you could have said the 15th frame per second objects and the and the uh in the 30 frames per second object and the 60 frame per second objects and hey you have to say okay if I decode a 60 frame per second object can I do that without having seen the 15th and 30th percent object that can be four and so I maybe maybe not I don't know maybe but you have to decide that the other kind of decision that you have to make is okay suppose that at some point in the group I decided I have to do up the 60 60 frames per second object does that mean that I'm going to do up everything until the end of the group every of those objects because I mean they are unknown dependencies between those things or do I have some kind of a result Point simulator uh no that's just one dimension if you take the special encoding you can have say the 720p object and then the 1080p object and then the 4K object foreign with the separation in time"
  },
  {
    "startTime": "01:00:01",
    "text": "and at that point during the graph of dependencies can be a little bit challenging so it's probably doable I mean we do these kind of things all the time but I think that we should have a specific challenge says okay suppose a correct that's something like that combine temporal dependencies and spatial dependencies how do we organize it is it easier to organize it with several drugs is it easier to organize that is a single track with metadata linking the object I mean the single track has the advantage that you will get a single sequence number of other objects that gives you an implicit delivery order but I think at that point the the discussion I've seen on GitHub are a bit exploratory and and we should have probably a focused discussion on that okay so uh just uh to let you know we have three more people in queue and only 10 minutes so I think having a focused discussion on this does seem like a useful outcome here would the notetaker please note that an action item to the chair is to identify that group thank you foreign yes okay thanks question for uh putting these slides together um I have a few observations and probably a few confusions that I would like to get clarification to the group which is um when we talk about objects I think we are talking about objects in different granularity and that's been source of confusion on what it means in terms of encryption context what it means in terms of prioritization context and how it can be fair between objects of"
  },
  {
    "startTime": "01:02:02",
    "text": "different sizes um if everything is put in some some order of priority uh and also on the previous discussion about um 30 frames per second objects or the 60 frames per second operate my my thinking here is that we are talking object as an output of an encoding um like like an encoder frame at a certain quality on on certain temporal dependency that's kind of my definition of an object is I just want to make sure if that kind of Alliance what you're thinking uh that's on that's basically the proposition uh one slide uh if I'm not wrong um and and second thing thing is that on the like we can go one by one but second thing is on the groups as uh I agree with what Mo and will said uh I would they being synchronization points and also having stateless that way it's easy to kind of go from one group to another group in in a way that's an application uh your village may not have to understand everything about an application is um and the the last one about the layer coding is I know we are discussing about this uh separately but one point I would like to say is that like if you look at anything like uh latest uh codecs like av1 uh the they have this huge uh dependency descriptors that identify how uh various uh frames across different uh layer and temporal scalability Depend and that structure is sent as an RTP header extension or or as a video object payload and uh and we we need to kind of think turn around this layered encoding and think about what's the receiver is asking about okay it can the receiver basically ask that I he would want a particular uh what we call in av1 terminology a decode Target which is like a combination of spatial layer uh uh capacity saying that I would like to just get VGA at 15 FPS how is that kind of answered uh just"
  },
  {
    "startTime": "01:04:01",
    "text": "looking at the Publishers that we missed the picture on the on the receiver side and hence we need to start looking at what does it mean and should it make sense to push this complexity to the application layer and keeps keep the relays uh as simple as possible which is um you get set of data you want to forward based on uh subscriptions um that doesn't make the transport definition much much smaller and and and easier and last point I had was on the track identifiers I think making the track identifies something uh as neoral would make a mock just worry about tracks and leave the rest of things to application on what it means to put it in emission or and broadcast or or a composition and what properties that brings along with by putting things together uh yes we I think a lot of what you said there are falls back into this initiative we have to have on how exactly do we deal with layout encoding and yes you could have a complete dependency graph saying that oh in my group object 10 depends on object nine and seven and four and two and one and if any of those is not arrived yet there is no point we could say that we could say that I have a list of dependencies and and carry that in the header and as you say that Max relaying more complex because I mean will I have to be worried about that graph and and get an implicit order etc etc we may be able to simplify by using the ordering of objects in a group to have"
  },
  {
    "startTime": "01:06:02",
    "text": "comparison operation instead of just I mean individual dependencies I am concerned that HTTP 2 went into that path of having a very complex graph of dependencies and presentation orders and then they have to work it back because nobody could implement it properly so there is a point of trying to get to the the right level of complexity so I'll say let's have this discussion on layout encoding go into the concrete details on how we do that what that implies and then we can see it Victor you hear me yes okay uh I wanted to comment on preposition to specifically the issue of tracks being related so there is the there are two when doing the live streams or are often two priorities that do kind of uh things to goals we want to simultaneously achieve one is we want to prioritize audio over video generally and the second is we want to prioritize new content over old content uh and the problem here is well how do we combine those priorities do we always prioritize new audio and old audio uh over new video and old video and the answer is you usually want new videos"
  },
  {
    "startTime": "01:08:00",
    "text": "and New audios and new all I'm sorry old new audience and new videos and all the ideas and old videos uh but the problem here is that new uh in order to do that you have to have some shared timing model between those two uh since you generally you want newer audio before the catch here is you want to prioritize new video over all the audio and in order to do this kind of prioritization in order you since you don't care about in order to do this kind of prioritization they need to be synchronized uh since uh it doesn't make sense between two sources which are not synchronized but you can do that with the resources which are too high oh and that is where roughly the concept of and this is roughly the reason why a transport would need to know about things more than individual tracks from my perspective yeah I mean the basically what you what you propose is something like we discussed that I think before is after if to ask are part of a bundle force them to have the same structure of groups or or something of that nature so we can say that okay if we go fast forward to group 10 on video we should also go fast forward to group 10 on audio that's something like that is is that what you have in mind well well it's not just that it's like I If I have a player buffer of 10 seconds I want to only have 10 seconds of video"
  },
  {
    "startTime": "01:10:01",
    "text": "and audio because I don't care anything in the past but of course that kind of buffer the kind of time control is per clock Source not per track or per multiple independent tracks which don't share a clock source yeah I mean um yes I mean I I hear you I I must say that I am a concern about the extra complexity of having synchronization point between two arcs and that in practice it may be that sending the audio fast enough is good enough but so basically that's another very concrete point that you want to discuss suppose that I have an audio track and a video track how do I synchronize them and do I need to have the synchronization inside the transport that's uh I think that the second question after the layout encodings Jody yeah yeah can you hear me yes okay good I wanted uh so thankful representation uh really uh very helpful uh because uh following all that be all those beers where was it with uh of a Hazel but uh thanks for putting that well so I just wanted to touch on the concept of of groups just for my understanding so it seems that uh that we are uh we are saying that the groups is a is a group of objects that belongs to the same track that they start with a tap with a with an access point that says with the they are decodable from from the beginning and they are also uh have monotonically increasing ideas okay so basically uh if"
  },
  {
    "startTime": "01:12:03",
    "text": "the group always starts with a decodable access point and the objects are identified also with monotic monotocol increasing ideas why do we need groups so what groups give us because we can just put a flag in an object that is uh the since the objects have sequence because they have an monotone increasing sequence ID if we put a flag in the object that says okay this object is attacked then what extra features the group uh groups will give us I I think that what you're describing though is is something which is about the concrete representation in the protocol I did not want to go into the concrete position of protocol right now when you could indeed do that and things that are based on on flags are thinking less for burst than things that are based on hierarchy even though the classic Prime with flags is that if you do Miss the object that carried the flag you don't know that the object that comes next is on a new group on the previous group yes it's really it's really a question of basically encoding and the robustness of the transport and things like that yeah but in this particular use case it seems that it's perfectly okay because if we miss the object with the flag so with the tap then we we don't we don't get is the rest of the group belongs to the previous or the network since it's not recordable we need to wait to the next step yeah but that means that you will need to have an indication in the subsequent object that they refer to these previews stat access point and that's kind of the same thing as having a group I I think there is no"
  },
  {
    "startTime": "01:14:00",
    "text": "there is no practical difference it's just an encoding issue okay I I'm still not convinced but definitely groups concept would work too so it's not a matter of uh yeah okay it's not a strong opinion so thank you and Bernard uh I just wanted on the the layer coding problem it matters the great deal whether it's sender driven or receiver driven because in the sender case it has to information on all the layers whereas in the receiver case the receiver will only have information on the layers it is receiving and that makes a huge difference because a receiver that's only receiving a lower layer won't know the upswitch point unless they're encoded in the layers that it's receiving so you need to know whether you have a fender driven architecture or receiver driven and I think I think that we are pretty much in a cell to even model if only because when this is Villa is doing fan art and if you have freelance doing fan art I mean a receiver can only control something locally at the end of his fan art branch and only the sender as a global view but what we have heard from from you but also I believe from"
  },
  {
    "startTime": "01:16:02",
    "text": "I think it was current is that we can have a case in which a receiver when they subscribe to an object say just give me the first layers because I'm I'm I don't need to have the full definition so there is this notion there that a user can say yeah I know it's that object will be all the way to 4K 60 65 per second but I am interested in 720p at 45 per second I I don't want to have all those extra layers yeah it doesn't take into account the codability but that's something a server can know or the decodability is expressed in the dependencies between firms right that you you understand what you have anyway thanks okay well I'm a little bit confused because uh we locked the queue uh and somehow you moved into the locked queue so that that was a neat trick and you can you have the floor briefly if you'll tell us how you did it um I wish I knew okay I've joined the conference about four times because I'm getting kicked out like uh Ollie is too I think so maybe that's to do with it okay very quickly I think on groups uh I think it's relevant to consider them directly in the protocol because people have been assuming that groups are addressable we've always talked about objects being interrupted but I think really more likely the groups are the most"
  },
  {
    "startTime": "01:18:00",
    "text": "addressable things and entities are subscribing for or grabbing the groups not the individual logics okay so I think I think we did go ahead and close the queue Tim Tim I'm sorry uh you you joined after the queue is closed um and uh I think we're we're running a little bit behind now um in terms of action items I think we've made some progress today uh and I think we'll we'll we're going to ask the folks working on this to do is to go back through the chat because I think we're still looking um for agreement on the properties of objects for and now that thing which might be a above track and I think that there were some emerging agreement in the chat um in particular about the relationship between um the application selected decodability or or encoder behavior and its relationship to each one of those and so that might be the way that we can approach this next is to say okay assign them a letter and say a represents this relationship to the encoders presumption of behavior by the decoder and by the relay um and I think that might help us um when we come to Yokohama I do think that there's a lot of valuable stuff on these slides and I think the conversation has been very useful thank you very much um but I think there's still a bit left to do the other thing that's going to be related to that is this group that uh uh Kristen you you mentioned we needed to to sit down for a while and talk about the specifics of what this all means for layered encodings because as you say the dependency for layered encodings look a little bit different and especially if you're going to want these things that sit above the tracks"
  },
  {
    "startTime": "01:20:01",
    "text": "to be able to express dependencies across these and for that to be true for layered encodings it's going to be quite complicated um so if you are interested in being part of the group that sits down to do that please send Alan and me a note and we will help get everybody who volunteers uh together uh Christian don't bother sending us a note your draft okay thank you very much um okay uh so uh Ellen who's next uh who's the next presenter I think Spencer so I'm going to switch the slides out I'm gonna try there we go uh chair slides intermediaries all right Spencer you got it I think so let me pass control too okay excellent um so thank you uh so this is a progress report from the intermari intermediaries design team and that was formed after the January uh interim meeting and uh this is not to say that you know we've discussed things but this is not to say that we all agree on everything that's in this slide deck um and just a call out to the uh uh design team members here and uh ask that uh if there are things that uh I'm getting wrong please uh feel free to to uh"
  },
  {
    "startTime": "01:22:00",
    "text": "dive into the Hue and uh and uh help the working group understand what I meant to say and do I yeah okay and so so basically uh background for this session uh great quote uh from Luke uh like Ted mentioned we've all got our own preconceived notions of how media is supposed to work over the last 30 years we need to step back and really explore the different roles why they exist what data they need to function we'll be able to justify any messages and their contents once we can map out how data needs to flow so I thought that was a great uh great quote and it made me think a little bit because we work on some similar but not identical media use cases we use ideas that have similar but not identical meetings across the use cases and uh just like I say reminding uh people the interim intermediaries design team was uh has been working on figuring out what a group of six people can agree to um obviously it will be interesting to see what a larger group can agree to uh as things go along uh so one of the things we were talking about is one of the ways we got started was basically saying well what are the roles and uh if we're Our intention is to describe what relays are doing um let's talk about what relays are not doing just so that we understand uh what's already being handled somewhere else in the uh in the uh mock universe before before you involve relays um I uh what yeah"
  },
  {
    "startTime": "01:24:00",
    "text": "so um we were working for most the time that we've been talking we've been working with a model where we had Publishers and subscribers and what we were calling media sources and media syncs and um we've had some discussions starting last Friday with uh two or three more roles and uh I could say something about that or somebody else can uh but like I said I'm just talking about what the what the design team has been talking about uh so that basically uh Publishers are providing uh publish requests catalog messages and object messages I understood from the discussion during Christians uh presentation that not all the not everything comes from uh the publisher directly if I if I got that correctly but uh so like I said we've got things to think about especially after we've heard what other people are saying and that subscribers uh handle the other the other side of that basically uh providing subscriber requests consuming catalog messages and consuming object messages and then the media Source was generating media content uh encoding it possibly and encrypting it possibly and the media I think would be doing the same thing that the media Source did in reverse order um like I say I think this is probably a good yeah this is a this is a uh good place for me to just mention uh the other ideas we've been uh suddenly talking about in the design team uh one"
  },
  {
    "startTime": "01:26:03",
    "text": "was uh what was about a uh so an entity that uh creates catalogs or creates a composite of catalogs and then we have some uh discussion about um a definition for something called an emitter and uh receiver and we are try we are trying to understand the relationship between that that uh pair of of uh roles and uh media source and media sync I'm not I I'm not sure if that's just a terminology switch or if there's something more involved there but like I said that's something we're still trying to figure out okay so that takes us to uh like I say this is uh stuff we started out with uh for will uh but basically looking at what minimal uh distribution topologies would uh would look like and so this is if you don't have a relay and if you do um and uh then uh maybe a more interesting topology like I say this is the one this is the one uh where we're showing like a full ingest and full you know and distribution again this this was a this was a this was a figure diagram that was originally taken from uh will and then uh discussed a bit and uh modified a few places so people may have seen something like that this uh the the one thing that changed during our discussions was uh"
  },
  {
    "startTime": "01:28:03",
    "text": "thinking about what it means to be an origin uh and potentially a back-to-back uh subscriber publisher um and there may be and there may be some more uh there may be some more um nuances uh in what an origin is but that's this is what we've been talking about so far so and this is actually a uh another will diagram that we had modified a bit to try and to try and explain uh what the different you know the different roles are and between uh between media sources and media syncs and then what relays and what Origins actually look like um there a bit so you know we've got uh again uh starting at the top you've got a mock endpoint publishing directly to a mock endpoint and then with a relay in between the two uh in between the two endpoints and then uh two endpoints publishing media to advice that mixes them together and we're still uh talking a bit about terminology whether a uh for the you know what it what exactly it means to be a media mixer for instance uh and then uh two endpoints having a Web Conference through a relay where each endpoint may have all of the roles uh"
  },
  {
    "startTime": "01:30:00",
    "text": "publisher or subscriber media source and media sync and then uh a publisher uh streaming the game through a CDN to a client where there's just a Cascade of uh of uh relays so uh that one and see so do people have this the you know these ideas somewhat firmly absorbed where I we can talk about more details we'll stop for 30 seconds and see if anybody wants to get in queue I will hey Spencer thanks for putting all this up just a quick comment as we're looking at this the the diagram here for two endpoints having a Web Conference or a relay both endpoints would be publishing and subscribing the diagram shown there is it's the one on the left is publishing on the one on the right is subscribing you would actually need two lines right they they should both be publishing and both subscribing it's uh yeah yeah she's rejiggering the image but in case that was confusing anybody um there would be double sided to that right and thank you uh these so I think one of the things that I told the design team I hope we push down more on is basically you know we kind of have uh an understanding from about some of the lines but making sure that we have all the lines uh because you know these uh you know as you as you see these pictures don't uh include the lines for the uh media flow uh this is basically kind of"
  },
  {
    "startTime": "01:32:02",
    "text": "uh the relationship on publishing publish subscribe but yes uh hi Tim hi can you hear me I can all right a couple of comments sorry I hear myself echo which is quite annoying um first one is we have streams that go to the relay the endpoints will do a publish request and hopefully a subscribe the publish request namespace is most likely a more specific of the subscribe so we want to make sure that we don't send data back to the publisher now how I'm doing that today is tracking the published request flow stream or or flow ID of some kind that says that that was where the Subscribe also came from and then we'll not send it back so I feel like we need to have some standard for handling that especially in the case of multiple streams and being symmetric with the publishing excellent and uh I see that I see that the note takers are typing uh away on that point uh and uh thank you again thank you for that uh note takers and um just for anybody that's uh in the conference um if you keep an eye on what the uh notes say to make sure that you were captured correctly uh we'll probably all be happier um so uh Alan"
  },
  {
    "startTime": "01:34:03",
    "text": "yeah I have one question on this slide on the right hand side where it says mock origin and it has the four boxes yeah I understand that in the picture there are some Origins that have four boxes but I'm not sure why every origin would need to be for a Subs uh scrub subscriber for example or a sink I uh I appreciate I appreciate that comment um and I I would be tempted to hide behind the title which says various use cases but not all every possible use case but I really like I say I really do appreciate uh the observation and the opportunity for us to clarify that thank you um Silas yep thanks man sir and I agree with Adam um not every origin required to to be a media source and a media sync uh in in many cases it's the opposite of that where we don't want Origins to be involved in any encrypted flows uh to access the raw payload um it's more like less like in webex.com it does not look into media that's going through that so it's in those cases only the endpoints or the one that should that should have access to the end-to-end encryption key and and if we look at this role roles and their trust model and then apply them to the physical components that Implement uh some of these roles in the architecture then it becomes more clear and and some of the the direction that you've been presenting would help go in that direction okay like like I said this is this is where we are now this is not what all of us agree is the right answer forever"
  },
  {
    "startTime": "01:36:01",
    "text": "cool uh and nobody else in queue okay um so if we if we are all relatively synchronized uh here uh let's move on a bit and uh this might get livelier so if we were looking at what mock endpoints do and like I say we ended up thinking about that so that we could say this is what endpoints do and so relays don't do it uh so being the source or sync for media and being a publisher and being a subscriber you know our idea was that those things happen at Mock endpoints and that these are things that the endpoints are trusted with um keys to encrypt and decrypt the raw content if provided and modifying or originating object headers and payloads uh parsing and manipulating catalog messages and object messages originating subscribe messages and originating published messages um I think it's like as I say I think it's fair to say we we are talking about a couple more Concepts in uh the design team that uh might uh might affect what the uh what the definitions of an endpoint are but this is what this is what we seem to be landing on so far as of today um comments or questions hi Ted"
  },
  {
    "startTime": "01:38:01",
    "text": "so I guess this is a comment on the what am I entrusted with um I think we will see classes of endpoints here and that in some of those cases that some classes of endpoints won't be trusted with all of these capabilities um so we as long as we think of this as the set from which um the rules and trusts are drawn rather than presuming that it's always going to be the case that all of them have this I think we're we're probably good to go but I just wanted to call it out in particular because there are going to be some kinds of um sessions in the real-time case where have um of nodes might be able to both originate at subscribe messages and originate published messages and a different set of nodes might be only able to originate subscribe messages right and uh so I I appreciate that clarification and I think there was also an implicit clarification uh which was that you would be able to select uh things that endpoints do and in order to describe a uh class of endpoints and that that would actually be a helpful thing for us to provide for people who are uh trying to deploy uh mock in their uh in their systems so thank you for that um I'm just uh so and uh I'm just looking at the notes so I was hearing uh that they are having different uh trust levels but also that the uh that the uh endpoints will not all"
  },
  {
    "startTime": "01:40:02",
    "text": "endpoints will do everything that an endpoint can do cool thank you um and so if I go into slide eight uh these were the uh examples of mock endpoints that we had which I think that may be starting to head towards uh that the uh suggestion that Ted raised and uh so you know we're publishing a stream or we are a Web Conference client which may have a lot of things going back and forth but also three of our examples were for uh where for middlebox functionality which we were if you look back at um what if you're looking back at uh Slide Five which I just flipped to that basically you know we're talking about we're talking about uh combining things uh into a back-to-back uh endpoint if that's a if that's a reasonable back-to-back mock endpoint uh if that's a reasonable way to describe things and and that different functionalities may be put in back-to-back endpoints uh as we're going along so uh yep yeah so uh so like I said just thinking in terms of uh transmucers as you know I'm picking out different rights and things like that uh if transcoder says something where I say"
  },
  {
    "startTime": "01:42:02",
    "text": "I really need to be able to uh decode the actual media and encode it using a different you know using a different uh stream type that that was something that would be happening in the middle box and something that would do uh composition would be something that would happen in the middle box and this is mostly to get pull these things out of uh the functionality that we're thinking of for relays okay any questions there hi Tim sorry I have to allow audio every time I can hear you now do you guys hear me double or is it just one I'm sorry I don't know if you can hear me twice I've only hearing you once okay all right so on the relays and the subscribers and and the media devices in the middle there's a use case that I've been running up against which is finding the nearest X number of receivers of a pool that should receive that data data so if it's in the west coast versus East Coast I have a hundred transcoders all subscribe to the same namespace but I want the media with the relays to go to only two which are the nearest ones okay so I'm looking at trying to solve that I'm not sure if that's in here or not I can tell you that I don't believe the design team has talked about that yet and uh"
  },
  {
    "startTime": "01:44:02",
    "text": "just to just so just speaking completely for myself I think one of the things that uh that is happening is that we are tripping over uh maybe not use cases at the level of the use cases that are mentioned in the charter but uh additional use cases that have uh specific characteristics that other use cases don't have and specific characteristics that might affect the design of the protocol uh so so what you just what you just mentioned is a really good thing for uh us to put in the use cases part of the requirement document uh actually kind of kind of needs to be on the subscribe you have to basically say how many do you want to see the stream and then if it fails there has to be some chain of fillover okay yeah yeah I think another thing we are figuring out as we're going along is uh exactly what the responsibilities of the division of responsibilities is between the uh application uh and uh the mark protocol uh you know basically how much how much does a mock uh how much does a mock implementation do for you so I uh like I said I'm I'm nodding my head up and down there yes I do feel like this is a relay function though but yeah okay and foreign so thank you for that and so finally uh talking about relays"
  },
  {
    "startTime": "01:46:01",
    "text": "um we talked about them as if they were Publishers subscribers uh and that may they may look that way so this is Spencer free wheel here a moment they may look like that to the rest of the system but um they might or might not be originating uh subscription and publication requests or information they may be uh relaying it so um what we are trusted to do uh to modify an object header to forward subscriptions to other entities to forward the Publishers to match subscribers to store the published content which is we'll talk about more I'm sure uh to validate uh authorization credentials for published subscriber Quest and I've I've had a uh question in my mind about uh how how involved Origins are in uh in uh authorization and uh I think this this conversations we're having here have been very helpful for me uh with that as well um so no questions on this slide then let me go to the next slide things that uh mock relays are not trusted with and the design team has talked about this a bit less but uh this list has been out there"
  },
  {
    "startTime": "01:48:02",
    "text": "in our shared space for uh pretty much the whole time we've been a design team uh not parsing catalog messages not parsing object message payloads uh not originating subscribe messages and not originating published messages um I should stop there for questions on that one hi Ellen good morning Spencer um question about originating subscribe messages um so I imagine if you have a relay where you're waiting for a consumer to your subscriber to show up issue a subscribe then a relay can subscribe on their behalf to an upstream for example but it also seems like you might want to have relays that are pre-subscribed to certain things which you anticipate uh subscriptions for so is that something that is allowed or does it just not fit into this particular taxonomy of of relay so uh I would I think I would uh answer that to say it doesn't fit into this taxonomy yet but um one of the things that I think we also have to uh do to move ahead and make progress here is to figure out what um what is actually relay functionality and what is actually uh back to back endpoint functionality and that may be a bit more obvious on the next uh on the next slide"
  },
  {
    "startTime": "01:50:00",
    "text": "um is that does that does that work for you Ellen yeah I mean I think it it's a little bit um I I like we have a formal definition of this is a relay but if you don't fit into it at any point you can be like well I'm not a relay I'm two in points back to back which means no none of the rules apply to me anymore um are we okay with that um or do or what I guess in other ways like why are we specifying um the what a relay can do if there's such an easy way to sort of like I think maybe it's more like what can you what is a relay required to do uh yes yes exactly exactly uh so a thing we have been talking about is of course the definition of minimal relay functionality so uh that you know exactly what you're what what we're saying which is uh if I tell you that I'm a relay uh can I actually forward anything you know so I mean that's like Basics right uh but if I tell you that I'm a relay what other things can I do and uh that's actually the next slide so uh please be ready to jump back into queue for that um not hearing you quite yet sorry okay I think you're there yeah okay I agree with Adam's uh concerned there I think we need to take a step back and think about there are roles like publisher role and relay role sorry"
  },
  {
    "startTime": "01:52:01",
    "text": "publish a role on the subscriber role and there is a physical or virtual entity that are sitting in somewhere uh that's performing that's called a mock relay and we need to basically say what roles that apply to mock relay and on both publisher and subscriber role would apply to mock relay that means that they can um subscribe on behalf or publish on behalf of the previous relay or the previous client they're connecting to to the uh to the to that mock relay and when we kind of take these roles a separate thing and then you apply apply to these boxes like the mock release or mock end points or a transcoder or something then we can we can basically say the roles Define the functionalities that if that that really could do and I would uh strongly uh think uh for kind of like encourages not to think about the core minimal relay functionality and maximum relay functionality yeah uh to keep it simple I would just say realize anything that that does publish a role a subscriber role and it does not have access to end-to-end encrypted Keys anything beyond that should be have a new name not uh something uh some special form of relay thanks um so uh many good points that uh Sue Haas just brought up there um I I agree that so you said step back I would say step sideways to step forward uh that that uh for us to push down to the next layer uh the next level of what we've been talking about and saying uh much like Alan was asking if does this taxonomy do what we needed to do and if it doesn't what do we need to change in order to do be able to do what we need to do so uh definitely definitely agree on that um the uh"
  },
  {
    "startTime": "01:54:01",
    "text": "the you know so you uh we're also talking about the uh definition of we're also talking about the definition of uh what's the relay and what's a uh back-to-back uh lock endpoint um and I think I say I think the next slide actually uh helps us guide that conversation a little bit um but uh we've been having uh a spirited conversation uh among the design team members within the last 24 hours on that so I know there's more work to do um but I'm I'm like I'm liking uh what suha said thank you for that um Tim okay are you are you able to go are you able to turn your audio on audio yeah there we go yeah it's cool I I had to rejoin excellent I was just gonna quickly add a use case for the reason why a publisher or a relay may need to originate a published message and that reason is with fragmentation and double fragmentation if we allow that so if I have a transmitter publishing at 9000 into you my messages will be larger and datagram messages and then there will be fragments within"
  },
  {
    "startTime": "01:56:01",
    "text": "that the relay is going to receive that pass it around providing it the MTU around with all the other relays is 9000. but then I have all these subscribers that have different MTU sizes so if we handle mixed MTU that will require relays to repack and refragment which technically is a new published message yeah so uh you you see the tension between uh even the first slide I had about this and the second slide I had about this where you know our our relays uh publishing and subscribing or are they forwarding uh published subscribe messages uh so I think what you're talking about there is in the same uh category um which is uh something that uh something that and we'll keep calling it a relay because that's what the slides say now what something that the a relay might do in order to transform the messaging um you know or you know in order to uh in order to uh over you know in order to in order to accomplish something that the uh that the subscriber needs to have happen whether that's uh dealing with MTU uh fragmentation or whether that's uh some more things um like I say we we should be talking but uh I've I'm leaning now in the direction of uh really being able to uh subscribe on their own behalf and publish on their own behalf and probably I'll probably say more about that on the next slide uh I will"
  },
  {
    "startTime": "01:58:02",
    "text": "hey Spencer I just I want to see how to answer Ellen's original question but I also want to answer Tim's and yours relays can't subscribe on their own behalf because look look at what they're not trusted with passing catalog messages the catalogs Define the subscription IDs so relays don't know what to subscribe to because they they're not trusted with reading the catalogs they are simple components they're given instructions and they follow the rules if if they're asked to do more than that then by this taxonomy they're not a relay anymore so I I think per Allen's question if you want to pull content to the edge of your relay you the relay can't do it because it doesn't know what to pull you have to give it a message through your command system or through your call to the edge system that would instruct the relay what to subscribe to and it may and then it'll be there in advance of your true clients but I don't think we should break the model here that a relay is the simple component because that's the one that we can really scale up if it has to understand catalogs then we have to constantly update the relays every time there is a new Behavior we don't want that we want a reliable reliable simple thing right right so so you are you are uh you were pinging me about uh a number a number of uh reasons why um we have minimal relay functionality so cool um uh thank you for that will uh suhas you're able to unmute service there we go uh clarification or you know asking for to what will said uh um I think uh a relay should definitely"
  },
  {
    "startTime": "02:00:02",
    "text": "be able to forward a subscribe yeah down I I think I don't know if we are capturing that or not according to subscribe or publish because if if real does not have the content it has to forward it somewhere towards the origin like what Christian was talking about and that needs to be captured probably we need to basically uh add that as what it can do that should be the meanwhile functionality it should be supporting yeah you you guys are working so hard to get me to the next slide but I I I haven't done that yet but you're working hard to do that uh Tim yeah I'm not exactly sure probably possibly describes without other relays thinking members unless we change completely to include that this is relayed from Tim you are suddenly breaking up and you have not been can you hear me okay yeah I can hear you okay uh and and when you just said that I could hear you clearly okay I was just saying that if we poured subscribes that will inadvertently cause the other relays and think that they have direct subscribers and that it's an edge which is not true so now we're maintaining a peering tree or a mesh of relays of all the subscriptions that are aggregated with next hops going to other relays and now we have a forwarded subscribe from a direct source that's gonna get a little messy like I said uh you'll notice you'll notice that uh what we're talking about here is now in a document yet because I don't think we're through uh suhas could I ask you to take a look"
  },
  {
    "startTime": "02:02:00",
    "text": "at the uh notes it looks like your last comment may have been uh been missed and uh I was agreeing with two or three different things you said so uh please please check and make sure that uh the notes include what uh what I was agreeing with sure I'll do that thanks Mr thank you uh so let's I don't have anybody else in queue so let's go to uh what mock relays do so the meta the the prime directive uh for relays that I've gotten is that they're doing things that do not require access to unencrypted Media payloads and that's that's what I've been working with in my mind for a while and then in conversations with Will in the last 36 hours or something like that um he was he was also mentioning the thing about uh not wanting to have everything in the universe that's able to see unencrypted uh media metadata so that's actually that like I said that's actually more restricted than the model I had been using in my mind um and I'm still processing through what the implications of agreeing with Will which I want to do um what those what those implications are uh but just going down the list that we've been working with um we said so replication a word that basically says I'm subscribing to one broadcast and I'm replicating the same broadcast to a subscribe you know potentially one subscriber and fan out when you are replicating one"
  },
  {
    "startTime": "02:04:01",
    "text": "broadcast to multiple subscribers that seemed to me to be kind of minimal relay functionality but stay tuned so um again in conversations we've had the last 24 hours in the design team um thinking about hot by hop reliability and up to some level of reliability basically saying uh if we're doing fan out the relay is going to have information that is going to multiple places and to make you know to make sure that uh for some level of reliability it gets to the multiple places which may have different path characteristics so um in my mind after the conversation we've had in the last 24 hours I think that hot by hop reliability is part of potentially part of uh minimal relay functionality after conversations with will I understand more clearly that hanging on to information to do Hub IHOP reliability is not touching the same thing as uh hanging on to information to do caching functionality for reliability for rewind replay basically you know once you've decided to cash how much you cash and what you can do"
  },
  {
    "startTime": "02:06:01",
    "text": "with that that amount of uh media information is going to be kind of up to uh the network designers and let me say the last thing and then we can just go crazy at the this is my last slide um but uh we've been talking about rate at rate adaptation and that had made it onto my list of uh what relays to because we've got this we've got this uh item in the uh mock Charter um where we're saying uh one of the you know one of the things one of the things that uh the working group is doing uh and actually the common protocol for publishing media for ingestion and subscription will support quote Erica uh colon and Skip down about three and it says rate adaptation strategies uh based on changing codec rates changing chosen media encoding qualities and other mechanisms what I've gotten is that that is not uh minimal relay functionality that that is actually not even relay functionality that that is something that's going to be a lot more you know quickly going to turn into um back-to-back uh back-to-back endpoint functionality um and at that point um there's my last slide so I think that I should open the floor for questions and um Ted how much how much time do we need to spend how much time do you need"
  },
  {
    "startTime": "02:08:00",
    "text": "when do you need me to quit talking uh well because the we have some elasticity in the issues resolution uh let's take the um the questions now if there are questions on on this presentation and we'll see how it goes we are a little bit over time but not as badly over time as we were before you had a fair amount that came in during the presentation so hopefully oh cool yeah yeah uh thank you thank you for that and it's probably worth saying uh this has been very helpful for me and I hope for the other design team members to uh flesh out the the next work we need to do uh so um we may not have to agree on things on this call in order to agree on things in Yokohama uh questions comments hi Alan yeah I just wanted to um maybe highlight something that uh the question that I had that and will and I were discussing in the chat so uh which is about this this idea of preceding content so um what he said there I think makes a lot of sense which is that most streams like this are not of interest and there's no way a third party CDN could handle preceding all of them and that makes a lot of sense um although I wonder if we would still want to allow something like a publisher can contact a relay and say I would like to precede this to you uh as part of the I don't know would that be part of like the web transport URL it connects to or something like it's waiting to say like is it okay can I send you this broadcast and then it Relay can say no I don't want you to do that and and then you know but some are pre-authorized"
  },
  {
    "startTime": "02:10:00",
    "text": "um or maybe this is solving a problem that doesn't need to be solved just like whatever the additional preceding is not that important or for the cases that it is it's okay to not have a standard for it um that's it so I I can't speak to uh how badly we need to uh standardize a way to do preceding but it seems like to me that um what we're talking about there is uh where it's helpful for caches uh to be doing something like this because you know if if a point of a relay is to forward things on behalf of things on one side of it to things on the other side of it uh if that's the definition of a relay then uh we can you know we can we can do a lot if we're you know so if if this picture here was uh used for preceding if uh if if does that make sense you know imagine imagine that imagine that there's content coming in from the left and that uh the this thing in the middle uh subscribes to it and uh and uh down you know it basically uh gets that content and puts it into Cash so that when uh when requests come in from the right um You don't have to go past this box this this clump of functionality uh to uh provide that content is that is that kind of what you're talking about there Alan yes and I think uh both Luke and Ted"
  },
  {
    "startTime": "02:12:03",
    "text": "pointed out that this is a fairly complicated problem that probably isn't the one we need to solve at least right now so uh I think I'll just back off I I I I I I I I I I respect I respect your I respect your desires uh the the thing I would hope is that we uh if we don't solve it now at least we don't break it now so that we can never solve it in the future uh Martin how was your day uh it's a good morning thanks Spencer um having trouble reasoning about this relay because I guess I don't understand the end to end encryption relationships and I I wonder if this is in scope of this work like if like if for instance each publisher has a one-to-one encryption relationship with in terms of content encryption with the subscriber then relays have no point right because the um like because there's no content scaling like I mean everything every like individual byte stream has to come from the origin so clear is not what we mean so how does how does this work do all subscriptions have to eventually go up if if the relays can't know about the content encryption then to what extent does everything need to go back to the origin uh to go issue keys and all that stuff um and I I don't know it's maybe not a question for you Spencer but for the group is this in scope or does um or do does everyone know the answer to this except me already so like let's give Martin a second to record his own question but I'll be I'll be inviting well uh to uh talk next"
  },
  {
    "startTime": "02:14:00",
    "text": "and um oh he's he's so he's still typing he's still typing do it do it guy all right I got it okay excellent excellent okay uh well yeah I I just wanted to answer Martin's question and he makes a good point if it's a one-to-one encryption right then actually every the publisher must talk directly to the subscriber why do you need relays in the way so you the case where you might want relays is if your publisher is very far from your subscriber say you have a publisher in Miami on a bad internet connection and the the uh subscribers in Seattle you can wrap that traffic up I think op and over 10 different asses which will happen if you connect directly or the Miami uh subscriber would connect to a local relay which is then connected over dedicated fiber to another relay because it's a CDN so part of the purpose of the CDN is to offer Midwest traffic that's higher quality than than the general routing so that would be a use case of putting relays in between even if you've got a one-to-one encryption yeah uh thank you for that will uh that and that is almost a quote of an exchange that we had on the design team probably within the last 18 hours um so uh this meeting has been an excellent forcing function for helping the design team Focus uh James good morning thanks for this I I want to also have a quick stab at answering Martin's question but covering a sort of expanding it a bit further um you're right that will will was right about the why would you why would you do"
  },
  {
    "startTime": "02:16:00",
    "text": "it when there's only a if there's a one-to-one uh that you can then build networks that are shorter paths and all the rest of it you can also do it for privacy measures such as a few skating uh the the sender or the publisher IP addresses from one another in the case of online telephony or or whatever um but there's I think the vast majority of use cases where we will need to encrypt the media uh one to many or many to many use cases in which case the this this gets a lot more more complicated and actually it gets a bit more beneficial and I think that there's two things we need to to work out here as a whole and we're talking about uh this sort of stuff is firstly that uh all the key exchanges and all the rest of that really needs to be kept outside of the protocol and we just need to provide enough information so that uh the eventual media sync I think is a language that the design team is using um knows how to do the key exchange but the actual key exchanges are an exercise left to the reader and the other thing I think we need to work out is for each component that is in this chain how do they authenticate to one another and I think that if we get some clarity over over those two pieces we'll answer most if not all of the use cases where we need to talk about um authentication but but also around management of encryption encrypted media uh and and thank you for providing that uh additional you know focus on focus on privacy as a benefit for uh having relays so cool thank you um Ted and Alan I think at this point uh you can uh write our request for uh agenda time in Yokohama uh on the list that you're"
  },
  {
    "startTime": "02:18:01",
    "text": "keeping sue us I'm basically echoing what uh James and we'll talk about with another example saying that in a conferencing scenario where you you would like to have multiple people in a meeting that would the best use case but there'll be a series where for one-on-one calls between Alice and Bob you will still prefer going through relay because it does provide benefits of not having to do with peer-to-peer topology understanding and setting up the eyes Nat traversal and those kind of things because something cloud and that's kind of lets you kind of uh go from a meeting that can be scaled from one one one to one meeting to say one to many meetings and and in that case in both the cases it becomes natural to use one protocol to kind of support both and in most of the cases that we are thinking about the mock as uh games thought about it's like for the media it would be a symmetric encryption and that would require either a DRM based something a key that's been set and sent to everyone or it would be something more on the lines of an MLS keying that would happen outside the scope of the mock to set up the group key and and that gets typically used for for the endpoints through the MLS exchanges nothing to do with Mock and keeping those things separate would be would make the transport more or specific to delivering encrypted media thanks cool thank you uh Ted I'm sorry yeah they're starting to talk about uh key exchanging in particular whether um the use case that Will was outlining was geographical in nature was important and I I just wanted to say from a scope perspective I don't think that I read the charter as limited to that that end"
  },
  {
    "startTime": "02:20:00",
    "text": "to end does not necessarily mean uh that that it is encrypted from a single publisher to a single subscriber using a single key and I think that the DRM cases and other cases people have raised are uh am important to that I think the key point to this for give the overloaded thing is that my reading of our scope is that we're not trying to presume that the relays especially the fan out style relays as opposed to the back-to-back user agents have any access to the immediate and that's important both from a privacy perspective but also from a design perspective because that means that anything they have to know about the media in order to do their jobs has to be in the transport metadata in some way um and I think from my perspective the the whole yes please let's put the the the question of um Key Management to decide it's very hairy and we've already got enough very hairy things to deal with but the biggest thing that we have to do is assume that any one of these devices that's not acting as a client has no access to the media for the purposes of determining what we as the protocol designers need to put into the rest of the system and and that to me is a main point here that scoping in the charter and and that's just what I wanted to say thanks right and uh YouTube you just uh Ted you just you just nudged me to say something that I've been thinking but uh I don't know that we've ever written down which is uh the thing about uh what you have access to being transport level stuff versus uh the uh mock level stuff uh basically the media level stuff"
  },
  {
    "startTime": "02:22:02",
    "text": "um that uh we've talked about uh putting anything that the yeah relays use that word uh that the relays need to uh in order to do their job uh as relays uh putting you know just copying that into a mock header that they would that they would have understand access to and be able to understand uh so it's not that they can read it's not that they can read the media metadata it's that we've made a conscious decision to uh provide the uh media metadata data to them so some part of it to them so that they can do their jobs uh and I'm sure we could talk about that on the mailing list um Christian this is a comment on the uh graph that you have the interest and distribution to puruchee I think that this particular graph is only one way to represent the publishing process and I I see it myself in a very different way I see the relay organizing some kind of cloud managed by the management of the relays and the publisher function basically client mapubliche to a relay and then the relay adds to go to the origin for authorization verification but the data itself doesn't have to be right the data itself is just effectively you could think of having a something like ospf for the cloud saying hey I I have this particular track URL"
  },
  {
    "startTime": "02:24:02",
    "text": "available here right and so I I am a bit concerned there and I think that we should clarify the relation between relay and origin because there are fundamentally two kinds of relays the real estate act on behalf of the client and the real estate act on behalf of the origin in a classic CDN the CDN has a contract with the publisher that enters what and and how they will republish something that the publisher is providing and that gives it a very specific relation like for example a relay that is part of that public of of that CDN with a contract with the publisher is going to interact with the origin based on that contract and says yeah please tell me if I can do this or not a Vita that is not is not going to interact in with your vision that way it might but it's it has no basis no shared contract nothing like that so we should also look at that uh Christian I I almost interrupted you in the middle of what you were saying uh to say that uh you were you were making a very profound comment uh that I'm making sure uh is in the minutes I I I I agree with that uh you know the basically that I've I hope we don't end up with like 30 different special case uh relays but uh that's a distinction that I I definitely think is worth is work but uh it's worth capturing so thank you thank you for that you're welcome uh Tim"
  },
  {
    "startTime": "02:26:04",
    "text": "all right yes so I just wanted to add to the use cases for the relays even in a point to point even if it's one-on-one encryption is that the relays do provide a consistent Edge for our communication between two or multiple clients and at least from what we've been seeing at WebEx it's been very challenging to get media to go through firewalls through the through the customer infrastructure and having consistent access to in-region resources has been a very big ask by many people including like most of the European countries want to talk to only European U.S folks want to talk to us only we we have various use cases that we need to pinhole things into certain areas and it's very difficult when we have traditional signaling so just want to highlight that that's a very useful use case to have the relays excellent um thank you Tim um and uh I think that the queue is closed and that there's nobody in it uh so um is it fair for me to ask the chairs to summarize uh what they think next steps here are so I think the next steps are we need to take them the minute so that of the meeting and review them and make sure that we have the points that were captured um reflected in the documents and that's"
  },
  {
    "startTime": "02:28:00",
    "text": "the the Baseline here I think we're once again I think we've made a good bit of progress in shared understanding um but I think we have to have um it'll written into the documents before we can uh kind of colic success as as you see at the moment we're we're at 26 people in the room uh Which is less than uh we had in Seattle and could have been less than I expect in Yokohama so we're definitely gonna have to take this to the list as usual and go from there yeah uh excellent so um just for me please don't feel like you need to answer this question uh on the on the on the call but uh when you say making sure things are getting in the documents um it seems like a lot of what I'm talking about here uh is relying on the terminology you know relying on terminology that uh the intermediaries group has kind of been making up if they go along and uh that it we're talking about ideas that might reasonably go in an architecture draft uh James if I uh were before we started doing the design team discussions James and I had assumed that we would be putting these things in the requirements document in the use case requirements document because uh so many of the things we're talking about here are uh you know that the use cases and requirements descriptions would rely on those that you know rely on these ideas and rely on these terms um but I don't know that that's the right place to put them do we want to spin up of architecture draft with a repo so that"
  },
  {
    "startTime": "02:30:02",
    "text": "we could have uh this level of discussion without annoying the protocol team so I think that we can let me check with um Alan about that and we'll try and figure out what home this needs and I think there are two pieces to it one is speak right I mean no our requirement strapped is definitely further along than an architecture draft that we just started would be um and having this available now might be valuable even if it later moved into a different document so the good thing is we have the slides and we'll have the minutes and we can go from there cool uh could I just ask uh ali uh did I understand that your uh working on a terminology draft able to finish it up before this call my apologies for that but I'll I'll try to sync up with you later this week or next week okay uh just uh just suggesting that uh we make sure that we're communicating with you just so that we're not writing a whole bunch of stuff that we have to rephrase later I was I was making some progress and then a lot of things you know Nev stuff has come in out of control but we will get back on track absolutely perfect uh thank you uh so we will we will uh we will communicate with you uh early and often thank you guy and now I turn everything back to the uh to The Host ah I see Ted just rejoined but it looked like he was offline uh for a minute but"
  },
  {
    "startTime": "02:32:01",
    "text": "thank you Spencer uh for that and uh the next thing on our agenda uh was going through some issues I didn't see anybody flag any particular issues um on the list or via tags so um Emir we have about 15 minutes where we could talk about them so I uh I'm gonna go ahead and share the current issue list but I guess I would solicit from the draft authors and we'll look at the work draft first if there's particular issues that you think um getting Clarity from this group of 26 people would help in uh adding information to provided updated version of the draft that we will have for the draft deadline for Yokohama uh either jump in the queue and let me know which ones we should look at or just paste them in the chat and let me see if I can share my screen uh the media slots are all taken what's the trick for making getting revoked slides there you go do I really want to share my screen maybe not okay it looks like it's being shared these are the issues that are marked architectural um I don't see any of the draft authors uh in the queue um what should what should we do uh in terms of do we want to review all of them [Music] um right okay 66 relaxed catalog definition uh let me pull that up and then will why"
  },
  {
    "startTime": "02:34:01",
    "text": "don't you uh go ahead thank you yeah we we had a good amount of commentary on this you can scroll right down to the end otherwise um we'll get dizzy um but there have there has been some eye ideas there's there's two basic uh I think fundamental things that that were quite interesting came out the first is that we can consider the catalog as another track and this is interesting right a catalog before it was a special entity or a document and it it then described tracks which themselves were different but in this case we can consider the the catalogers just to track it has um it has a join point which is a independent catalog and then as as new content becomes available in this in the broadcast um or the package of content so the catalog gets updated and you can issue updates to it and clients joining would want the latest version of the catalog so I thought that was a an interesting outcome from the discussion the second point is and you see it there uh and Luke filed an issue on it after a proposal from myself that we can actually merge a a URL the web transport URL uh we can use it to carry information about the content that the client wishes to consume in other words the catalog definition and we can either Supply this as two pieces of data or we can merge it into the one and that I think is also a fundamental point that I I would like us to discuss and I have different I have pictures of this that I can share if if it's easier to debate that versus the text"
  },
  {
    "startTime": "02:36:06",
    "text": "okay thanks will for setting the stage I don't know see if anybody's jumped in the queue okay here we go uh suhas I I I've been part of this discussion for a while so I agree that uh catalog as reading like going back to Christian's point about treating uh mortgage delivering tracks uh makes sense to treat catalog as another kind of track and and the same set of properties with groups uh the uh that also falls uh really cleanly uh for catalog as well and uh I would uh on the having the your the web transport URL also in having information about either uh the broadcast or the or your url or the track URL that's something we should consider and um I would like to uh kind of take count from Christian's presentation on uh considering them as an URL and then how that uh Maps into the web transport connection URL that uh we will propose to the list Texas Luke go ahead so I think the main um Thing Worth discussing about catalog is a track is just what to do about updates um hypothetical example you've got like a hundred tracks each track is like a different participant or something and every time there's a track editor removed is that a Delta that you put on the catalog track or is it a is it a brand new independently decodable one um like how how frequently should you make independently decodable tracks Etc like I think we just need to discuss the the whole um how do you Delta updates for tracks um and where do we knit segments fit into that but uh I like the idea of"
  },
  {
    "startTime": "02:38:02",
    "text": "having track zero for sure being like a special uh this is the catalog this describes all the tracks within the emission slash broadcast uh okay I put myself in the queue as an individual uh I want to make sure I understand uh well I can say if one is for so uh having the catalog be opaque um particularly so that we it's very clear that relays aren't supposed to muck around with it uh or not required to make around with it um that seems fine but it seems like if we're gonna start doing interoperability we'll also need some kind of another document which defines some kind of catalog uh that says like here are the tracks you can subscribe to otherwise we're we're lacking some information about what we're going to need to do so I think it's totally okay to have a base protocol where it says it's opaque but I think that we'll also need to have some kind of placeholder at least in the short term and that would handle like the questions that Luke destroys is it Dependable they're Delta encodings like what how does that work uh as a track um so that's one point the other point I wanted to talk about is uh using the web transport URL for uh broadcast and so we hadn't uh conversation earlier in this meeting about um emissions groups of tracks uh and sort of mission or an emission is a broadcast so it just means that uh sounds like if we make the broadcast part of the web transport URL then that means that web transport can only convey one emission and I guess I think I saw some discussion on the list about that so if we could maybe just highlight that part of the like clarify the understanding there or if we need to to discuss more and I'll jump out of the queue Will's next yeah I wanted to answer um first uh firstly Luke's comment about"
  },
  {
    "startTime": "02:40:02",
    "text": "um how do we how do we do Delta updates on catalogs I think if we follow the group construct that we followed earlier then it fits quite naturally in other words you would issue you would issue independent catalogs in other words the full catalog as your group and then you would do Delta updates on it as your subgroup objects and a new client joining the relay would know I have to go back find the last full group and then give it give that plus all the Delta updates from that to the client when they join and then it could build up it's good it's fresh object model of the catalog and in terms of best practice about how to update it I think that's a function of how frequently it's changing if you're in a Web Conference of 100 people someone's changing every few seconds you're going to do a bunch of small Delta updates right you don't want to publish the whole hundred percent list every second but for a streaming sports game where there's one video One audio and it doesn't change in four hours you would just publish it once and then you have to issue a cash instruction to the relays to Cache it for a long period of time far longer than they probably would for the Delta so there's some correlation between how long we cache content and it's anticipated uh change frequency and then for the for the second function I actually wanted to share a picture is there any way I can do that do I ask to share slides well uh let me I think I have to stop screen sharing and then you can try to start and then I can improve it or we'll see if that works okay I'm going to share the whole screen or just uh It'll ask you for a tab don't worry okay all right yeah I don't want the the call to hang on you want to go ahead and ask your question well will is trying to put a slide up sure um I think the only other thing worth considering with the the track zero and somebody will run into this when they write it down but uh how do you negotiate track formats or"
  },
  {
    "startTime": "02:42:00",
    "text": "catalog formats um as in I don't know that needs that negotiation like do I use what format do I use for the catalogings to be somewhere um and that was part of the purpose of the catalog message is you could specify what format the catalog was in I forgot to answer that Luke um um that we have in the proposal it's like three different ways to specify the catalog type and I was also talking with suhas about if we have a catalog right and there could be many different types of catalogs so we need some way to convey it this it's catalog number six and a registry of catalogs and then we need a separate spec So speaking with suhas about we need to be writing a base spec that tells you how to write a catalog spec and then people can go off and write catalog specs that interface cleanly with the base protocol assumes that there's there's it still kind of assumes that there's one catalog for a broadcast and it's of this type I think at least for backwards compatibility I would totally imagine like I could publish two types of tech catalogs um you know with the new format and the old format um and I just don't I don't think you can do that with this card proposal but we'll need in the weeds it's fine it's the implementation detail Fair Point oh okay so uh Luke I think or will I think I granted you permission to share it you did I'm just trying to find the right tab I got likes okay okay I just want to make sure that it wasn't on me and then foreign presentation I kind of felt that uh we are talking about catalog to be a composition which can have tracks from multiple emitters and that will also give a subset if an emission is all made up of"
  },
  {
    "startTime": "02:44:00",
    "text": "from one's emitter then the catalog can map to an emission um I I would like I'm okay with either way but we need to kind of make a conclusion because that kind of goes back to the next question which is what is in web transportation map to uh there's been discussion that it maps to an emission versus a composition and if you're thinking about a catalog as the scope and if you say a catalog maps to a composition then a web transport session would map to a composition if the other way you know on the flip side it would map everything to uh emission and um maybe my reading of Christian slide was uh wrong um I like to either get clarification on that one okay thanks suhas okay um will you want me to take Luke's question and I have a clarifying question also or do you want to run through the slide first well this was yeah this was the explanation for the uh combining the URL so I thought it was easier with picture I can talk over this later I don't want to inject myself okay all right sounds good uh Luke I I was just gonna say that everything scoped to an emission um like the catalog is for a single emission the web transport session is for a single emission if you want to receive like you know compositions which is different emissions from different sources over different possible links and different cdns even I I just think that's out of the scope of of the transport protocol I I think I and this as an individual I think I have the same understanding which is that a composition may be coming from multiple different places uh and that there's value in having a catalog which is scoped only to a single emission it's like these are the tracks that make up this emission if we want to also have something that says"
  },
  {
    "startTime": "02:46:02",
    "text": "um here is a description of uh uh what I want to show on my screen which is actually emissions from a lot of different sources uh that which can be coming from different cdns different links that's fine but it's that wouldn't necessarily be scoped to a web transport session or a quick connection so I I think I'm just trying to I don't think I'm being very clear about it but I'm trying to agree with what Luke just said that um one web transport session for one admission and there's one catalog which is also scoped on admission I think that's those are useful and and I noticed that Ted has locked the queue and we're down about a little bit less than 15 minutes so we'll try to uh drain the queue here uh and then move on to just planning for our next meeting uh go ahead Christian when I hear this discussion I think it's uh it needs to be grounded in two issues which are routing and authorization writing is that if the client is looking for some data for some stream it will do a connection maybe for a relay towards the origin of that stream and so the the web transport connection is definitely tied to a client and An Origin so if the client is looking at media for multiple Origins it will most probably use different connections because otherwise it might not be the most appropriate relay so that that's one thing the also plot is authorization and we have to decide whether the authorization is performed at the level of the web transport connection or at the level of the individual track"
  },
  {
    "startTime": "02:48:00",
    "text": "requests when I hear that basically we have a group emitters Etc what is concrete there is the authorization issue we could have a model in which the authorization is done pair web transport I mean I do a web transport for the purpose of getting this kind of I mean this particular URL emitter domain whatever and and then we have all the authorization done at that level I don't know whether that's what we want to do but at my my point is that when we discuss that we have to tie this advancing schema to routing towards the proper intermediate and to managing authorization and that's it yes uh okay um I'm not sure that we have much time uh for will for you to go over the slide but I know that it was sent to the list and there has been some discussion there um so uh was that time right to you as well Ted and well that we just we don't we don't go into that right now yeah you don't want me to talk over it I won't but as long as people know it's there and we can discuss it on the list that's fine but I think something like this should be discussed and it would be good to get some some air time for it in Yokohama and that brings us to our next question which is what needs air time in Yokohama um so obviously uh this is one request that we've gotten uh I think we got one from um Spencer earlier and I think we're expecting an update based on today's conversation from the folks that we're working on object models Spencer you're in queue"
  },
  {
    "startTime": "02:50:03",
    "text": "okay Spencer don't tell me what you need uh yeah so uh I had just sent a uh email to the uh working to the chairs copy the working group about the requirements draft uh and just suggesting that uh James and I do uh submit a dash 04 before the cut off on Monday and let you all uh do a start Polly working group for uh adoption on that so uh we don't we didn't need to talk about anything today uh except for me to say that out loud uh but uh putting something in you know putting yourself again in Yokohama about uh provide you know providing an update through the working group on that including any uh issues that are raised during the uh adoption poll thank you okay um so yes and thank you for the reminder to everybody about when the draft deadline is because that that will uh Drive some of this so if you are one of the folks who uh was presenting today and got feedback that should be incorporated into the um the documents you're working on if you could do that before the draft cutoff then those will go into the hopper for air time in um Yokohama suhas will work with Christian and others and also the meeting notes to see if I can update the data model PR I have received some comments on too much of text so I'll probably reduce that as well to see keep it more focused um and I'll um and try to get the pr to the state where it can be reviewed again okay"
  },
  {
    "startTime": "02:52:01",
    "text": "um Ellen were there other things you wanted to pull into the discussion about planning for Yokohama uh no I guess if if uh you know we're we're obviously not that far away so if you if folks have other things they want to talk about please we'll send out a call for agenda items on the list soon um as we try to build the agenda we do have two meetings um scheduled they're late in the week they are uh there's not that much time between them so there's uh that's some Advantage for starting late means we can potentially get some work done for people who are uh there but then we don't have a lot of time uh to follow up from the first meeting uh and help that feed into the second meeting so uh keep those things in mind um yeah I'm not sure there there's any other uh actions we have right now okay uh then just a reminder to everybody that we are actually quite late in the week uh so we have a final agenda now and we have the last slot on Friday uh so after our discussions you will definitely be able to go out for uh a beverage or some other uh refreshment in the Yokohama Hinterlands if you're not uh getting into cab to get to one of the airports um if you believe you need agenda time and we didn't discuss it today please send a note uh to the list and to me and Ellen and we'll start dealing with those as they come in and I think that's it for today thank you everybody for your time and for the uh very useful discussion yeah thanks also to to the scribes uh or scribe uh thank you Martin uh be ready to sign up describing Yokohama people we"
  },
  {
    "startTime": "02:54:00",
    "text": "can't keep relying on the same people um yeah thanks everyone thank you thanks thanks everybody for uh terrific uh uh input today and uh don't forget to make good choices okay"
  }
]
