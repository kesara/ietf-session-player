[
  {
    "startTime": "00:00:40",
    "text": "This is an IETF meeting, which means our rules apply. Rules are covered Our disclosure rules are IPR rules are covered by our best common practice, our note well, you should be familiar with them. If you're not, please visit the link at the bottom of the page. Basically, it says that you, by participating, you are subjecting and agreeing to the ITF's IPR rules and that you understand that everything you say and do here becomes part of our permanent record. We also have, guidelines with respect to how we interact with each other. And We have a, a code of conduct that says, please treat each other professionally and with respect, we know that sometimes discussions can be heated and engaged engaged and we want you to be engaged with the topic, but please keep it technical and remember these are your colleagues, and please be respectful. For those of you in law in person, please do join scan in this, helps us know who's there, which is important. But more important is if you would like to go to the queue and say something,"
  },
  {
    "startTime": "00:02:00",
    "text": "go to Mike and say something. We're using an integrated queue between those people online and remote. And so we ask you to use that, the on-site tool. And, for remote participants, you know, please keep your audio and video off. Unless you're, acknowledged by the chair. We know that there's been some challenges of that this meeting. I'm making some entertaining intainment because of it, but we prefer to just try to follow our process. We already talked about the 2 control. We are also using the our a note taking to, tool to do joint note note taking. I just put it into the the link into the chat. Please. Join it. Join it, help us capture any of the discussion. You don't need to capture everything that said on the presentation or on the slides, just the discussion and we are hoping for some good discussion during the meeting. Our agenda has changed slightly from what was originally posted we have, about a couple of things. First of all, there's been an addition that number 10 was a recent addition. It came out of the ops area, working group, where this, this, scheduling module has, been proposed, then it's been there was a suggestion to bring it into this working group. So it's going to be presented towards the end, The other thing is number 6. The presenters for number 6 had a conflict they're presenting right now so we can move them to the end. This slide gives you a bit of an update of where we are on our documents. If we run through them, you'll see that there's"
  },
  {
    "startTime": "00:04:00",
    "text": "a number that are on the agenda. We're gonna hear about them later. We've had some where the there's been an update already sent to the list. And, I think the only one I really want to point out is ACL extensions because We we had done a last call on it, and there really wasn't great, response. And that's there was no there wasn't a lot of response positive or negative. So we are running it around last the second last call and, really asked the working group to take a look at it and to comment. Kent, I don't know if there's anything you wanna add to this slide. No. Thank you. Okay. Thanks. Great. We've had no, liaisons or communications not one's not found through easy search. This is our standard slide. I think we're we're doing well with it. We so it's pretty familiar. We do have a little bit of, process change we, felt that it's not always clear what's happening with the status of the documents that you know, when we come up to these cycles and we have the publication deadline for an update, and we also have, a request for status being sent to the list, but we really wanted to have a little clearer policy, on what do we do with working group docking of, each of these IEP apps. And we are asking that at every IETF, we get a status update for every working group document so we know what what has changed and where are the open issues are? And we're we're also asking you to do it at the same time as the Internet cut off date so that we have adequate time to have discussion before and if necessary, bring something in so we can have adequate discussion in in, during this session."
  },
  {
    "startTime": "00:06:05",
    "text": "This came out of, this working group, this idea, and actually a comment from Kent I chair a couple of other working groups. We like this so much. We're we're now doing it in those other working Mahesh, our ID is in queue. So, Please, please, please, Mahesha, I usually do make it a point to say thanks, Saurabh. Every working group that he's been involved in, So this is me saying, thanks. From the working group. To you for all your years. Service. Thank you. So a couple of comments. I think, on the previous slide, way you had the list of traps, you had syslog struck out just wanted to give a quick update. I think that expired because the draft had dependencies on the client service suite of drafts. That, Kent was working on. And I went the latest status on them, most of them in the proof status. For publication, The others fairly close to being published. I believe the authors. That is Joe Clark and I can probably update The syst log draft revised. Right. I looked at that this morning, and the sislog drop has normative dependencies on cryptotypes and the, TLS client server. But only on the client, side of it. Not the server side of it. So you're good. Okay. Alright. So I didn't realize that. Okay. Maybe you can give that status update after this The other comment is on the plan procedure change in NetMark in the last slide that you put up, Hello. I really appreciate"
  },
  {
    "startTime": "00:08:02",
    "text": "And I think, as a procedure, I would encourage other working group chairs whether here Kent, Joe, to see if you may want to adopt a similar procedure for your working groups. Battle for having status update for every working group document. And I'll point out this was actually initiated by discussion a by cat, more than, me, but I I fully embrace it. Yeah. I, I I I was I was going to say that's a great idea. We should do that. And in the spirit of that, and though I didn't make the cutoff, because client server had entered last call, there's a dash 32 now of syslog that is live and thanks to med. The reason it's 32 is he found some process issues. So it should be fairly fairly good to go at that point. Assuming there's nothing more on the client side, You're fine. Hi. Scott Mansfield, Erickson. The, there was a comment about no liaisons. So I put a liaison in the chat window. That that did come out, in December. And it's an advertisement, really, because in the ITU, We have that a group gets together every month or so, to talk about Yang related topics with the ITU. I ETF, 5 triple e, route to anybody that shows up. Is welcome to come. So if you're interested in that type of coordination, look at the liaison if, you need any other details to send me a Send me an email. Thanks. Well, I'm apparently, liaison searched challenge. I thought we had 1, and I went and used the tool and typed a net mod it showed me nothing. So clearly, I did something wrong on that tool. So please thank you for"
  },
  {
    "startTime": "00:10:01",
    "text": "putting that out. Also, thanks to Mahesh for making me feel foolish and forgetting to thank Rob. I, actually, meant to do that and, I'll blame the time zone or something, but, of course, that's not really it. I I forgot, and I apologize. Rob, it's, Been great. We, we really enjoyed working with you. And more than that, we are, really looking forward to you being back. So that you could be a because you were you have always been a really strong contributor to group. And were looking for you to contribute to the group, not as a date, a ID, but as actually a technical contributor again. So thank you, and we're definitely not saying goodbye. Okay. With that, let's, move on. And I think, you're next up. So, I this is Scott Mansfield. Oh, do I need that? And you should send the payrolls. Athen, Oh, Scott. I sorry. I forgot. I was thinking that Rob was next. But you're right. On the x. Alright. Thank you. So I couldn't have asked for him better segue. That I've just received because Rahm name is on these next two drafts as well as mine because we're to get them moved forward. So I just have a very short presentation won't, hopefully, won't take up too much time, but I wanted to provide an update on these two drafts. There, I updated them and what did I update in them? Well, they're, they were a mess, to be honest, there was lots of things that needed to be cleaned up with editorial issues and the front page was all messed up and the diagrams worked in the proper format. And so I'd spent, I spent some time getting that stuff ready and getting the"
  },
  {
    "startTime": "00:12:02",
    "text": "ML, straightened out. And so but there's no been no real technical change to either of these documents for 6 months. So at the the end, the work that I'm doing in the Microwave topology work could use these draft too. So I think it's time to just get these off our plate. See if we can find some people that are interested in reviewing them. And, and getting them moving again. And then the same thing for the sub interface V it was just an editorial pass, and I fixed the there was an example where it used the best example, or it used a best draft in an example, but it was normative. So I fixed, I made it, made it a non normative a, informational reference and fix the, JSON so that it would actually like, ver verify. So those are the things that have happened in in those two drafts since since last meeting, and I'd like to get these going So now that now that Rob's back, maybe we can find some way to get these things moving again. These are, I think, are from 2007 d when they first started. So Thanks. That's all I had on these. And so, yes, at least from when I first came into ITS. So I've been around about So one one quick question though, is that There were some comments on the list from somebody who wants to leverage these in and the outcome of the was, but there's a question there is do we use case try and include that. That's an excellent. I and that's an excellent question. I think we just take that to the list not to not to use, not to steal your words, but I think we take that to the list and find out because the thing that they wanted would make a valid use case and a really good exam in the, interface extension draft. So that would help also get it moving. I mean, yeah, I I keep saying last call. Let's do Right? But, I mean, I wanted to be technically correct."
  },
  {
    "startTime": "00:14:02",
    "text": "For one thing. And the other thing is if there's people that are interested in participating they're realize that it's there. We have time to put that stuff in. So Okay. Good. That that sort of answers my last question, which was the next So take that question to list. we'll Resolved and then over the last call. Correct. Sounds good. Thank you. Thank you. Just run forward. Feels like a while since I've last been, presenting these sorts of updates and things. But I I'm gonna get into more details. That's what one of the drafts have that I've updates more recently, but I've note that I've taken these slides from 2019, the first copper size, because in some senses, the whole eco space ecosystem hasn't really changed very much on that side. And I'm presenting on behalf of the, office So just to give a quick overview of the whole space, I think everyone should know this, everyone who comes working with regular snow and stuff. We've got 5 drafts in terms of solutions, and we have 1 requirements draft. The requirements draft was done ages go. It's sort of sat that hasn't really changed. Of those five drafts, and since you've asked for state updates, effectively, what we're going to do today is we're gonna talk about the first 2, and these are the 2 that we're close to, and in fact, there have been last call once and it'll be an updated help the last call. And effectively, we're going to do another last call on that, I hope. So those two graphs will cover in more detail today. They get the sort of base groundwork of young versioning done. And then there's 3 more drafts on top of that that then extend it different ways. The yang packages is almost like an alternative to yang library that could be packaged off the bot and describe collections of young modules together. And then there's 2 ones for doing, sort of a protocol selection of how you choose which packages and negotiate when you're connecting to device."
  },
  {
    "startTime": "00:16:02",
    "text": "We spent some time on both of these, but not over the last cycles. Been in several years, we haven't really progressed these in much way. As we've been trying to make most progress with the first two. And then the last one, schema comparison, I can't remember exact time frame may be about 6 months or a year ago. We did look at doing some more work in there. But again, that one I think needs a lot more work. It's sort of to go too many different directions. So our current plan is to try and get first two done, last calls, ship those 2, and then we can move on and work through the rest of the other Move please. to the next slide Ah, set? yes, And and to this point, I will try and help try through to get I'd like to see them finished as well. Right. So I'm gonna give an update on one of these, the young module version update, and then Joe's gonna give an update on December draft. So And, actually, I'm not too hungover today, which is quite surprising, but Thank you last night for everyone who's there. I didn't prepare these slides. So, Richard, prepared these slides. So thank you for that So to give a recap, effectively in 118 we made loads of changes. We had a last call review. I think we've moved a slide before that. And, lots of comments came back on the on the sort of complexity of the solution, and, overall asking us why we we were having so flexibility in whether we could simplify it. So, on the back of that, various polls and discussions and, like, haystack polls and things, hopefully got a better consensus as to what stuff we're trying to focus on And effectively, this draft has gone on a diet. So, so I took some time to go around these using the delete key and deleting various sections of things that we thought we could live without at this time. Try and get down to the moon subset that we can agree on, get consensus and then get it shipped. So I I've had to go over what we've deleted quickly, and say what's remaining, and then we're done. So the changes we've made, first of all, we've removed"
  },
  {
    "startTime": "00:18:00",
    "text": "revision label and revision label scheme. So If you're familiar with the drafts, used to be very flexible in terms of how they described you how you could do versionally. You could use different schemes. You come along and use Yang Simba. We define you could use Simba And the the idea at the time was to have a base revision label that was agnostic to the scheme that's being used and have that flexibility. But one of the pushbacks was why do we need to to support different revision, versioning schemes, and we're adding too much complexity there. So agreement was to take it out of this draft. We're losing this sort of generic, revision label scheme. And we have December draft that we are standardizing separately. That's introducing a single scheme that the IETF is gonna standardize for versioning Yang modules. Instead of revision dates. So that's gone. And obviously, the revision label scheme as another leaf is no longer required. So so that's gone as well. So that's one of the changes. not Why am I moving on? Try again? Yes. So number 2, so this is some text added early on, when I was trying to simplify how you resolve ambiguous imports. So when you end up importing multiple different, versions or revisions of a young module, how do you resolve those? And what I was trying to push it towards was to say, I'd like it. So if you have any ambiguity between import only and implemented modules, you always choose the implemented module. But actually in 79, I still like that. I still think it's a better scheme. The 79950 does have a solution to this problem, and it says you choose the latest. So even if you've got, you input only a later revision, that's effectively the one you resolve to. So the conclusion was we don't need to solve that here. We don't see solve it now. And I think we could push this back to, like, a young next and maybe in a a future version of Young, maybe we try and refine how this behaves there. So that text is gone, and the text you see here is what was in 7950."
  },
  {
    "startTime": "00:20:02",
    "text": "So deleted. Next one, So with With the change to how revision labels were being described, and losing the sort of abstract behavior of revision labels. And going to a version scheme, we came up with the idea that actually you simplify this this minimum import, statement that we had before. you recall how it used to So work, if was quite complex intent in sense of it would map, your minimum imports, which might be a revision label, down to the actual revision date associated with that. And then you'll look through the revision history to find those particular things. And if if that particular revision turned up the revision history, it was allowed for the import. But because we now have taken, labels out of this, that's doesn't really make sense. Doesn't work in this document. And since the solution was, we would split the the, recommended min into 22 different statements. Recommended mint date, which is documented in this one, and then Joe will describe the other one that's in the December draft. So when we move to recommended min date, we can lose the complexity of having to look back through a particular history we can do a very simple date comparison. So any date that is older, newer, I would say, newer than the one that you select will be, acceptable revision to import. And so it becomes a lot easier to implement. You don't need to look through this and are a lot easier to describe. But, but this works really well if you are versioning using revision dates. And if you're doing the existing yang process of everything being a linear history, because then it's fine. But if you look at this next slide here, it doesn't work so well when you have a branched history. So there's an example here that you have. I've got web with a broad history that's described down there. And if you look at version, 2019 041."
  },
  {
    "startTime": "00:22:02",
    "text": "That derives from 2019 0201. So if you look at this, and you do an import, from, 2019, April 1st then both, both sides of that branches are valid. 20, 19 5th, May 1st, and June 1st of both valid imports. And that's probably not what you want in this case. Cause normally, if you're trying to say, I wanna to import April 1st or later, you really wanted the ones on that branch. And what this actually comes to is you're going to do a nonlinear development of yang modules, you probably don't want to be using revision dates of the way of identifying those. You want to be using, version labels and you you do the import y version label and sort of that soul effectively. So that is one gotcha where this system is It it simplifies it, but it's designed to work better with, with version with just using module dates. Rather revision dates rather using, version labels. I'll just say, if anybody have any questions, you do feel free to come to the mic at any time. So, so that's a change effectively, and what we regard as a simplification. In terms of how he described the history, and we can remove some text for that. The next one, so we were proposing when we're doing this to have a different format for the file names for yang modules when they were using a revision label as opposed to using date. And, effectively, what we were proposing is to use a hash between the name of the module and the revision label. We struggle to get consensus as to exactly what symbol to use. Excuse me? What it should look like and whether it should change at all or use a different symbol. And so our conclusion was we, effectively couldn't easily reach consensus We this is not a must have item that we need to have now. So we'll take this out. And again, we'll defer it to, a young dot next problem to solve. The one thing to say is here is I do believe that a lot of the vendors have this issue that they're gonna want to put revision labels or version labels on their module"
  },
  {
    "startTime": "00:24:02",
    "text": "and I suspect that there's going to be a de facto standard that people are going to use this form would be my guess. There was also a question as to how much Lou, do you want to ask, take your question now? I thought it'd be good for you just to, to state where you ended up in the document. So everyone is clear. About, I and can chime in because of the point you just made, So what does the document say right now in terms of what to use? The document the document now says, I think it says nothing about it. I think it's probably, section was deleted and hence it doesn't describe anything to do with how you'd label these, these ones with different revision labels because this document itself doesn't talk about any revision virgin labels at all. So I I think your statement that we're gonna end up with vendors doing different things in a de facto is not really a great place to end up. And I hear you that it's it's There it's coming from a desire to get the work done. But if what we're doing is causing us ourselves problem, it might be worth pushing on this one a little. Okay. And that's that's my opinion as, as, know, individual you maybe a little bit is, from a care perspective too of not wanting to cause problems for industry. I mean, we other the other thing we thought about here is not really great was to put this, like, into an appendix as, like, this is how you could do it. But then it sort of I sort of cheating the system, really, I think. I'm not sure that's a better solution. Maybe we, a last call time, we pull this out again and see if this is something that we want to to put back in. I mean, the tech putting the text back in is quite easily, but maybe try and push that a little harder see if we can get consensus as to whether And, I think if anyone else in the room would like to comment."
  },
  {
    "startTime": "00:26:09",
    "text": "I put it in the chat window. I agree with Lou that I think, We probably shouldn't. Try to drive to a consensus. Benefits it off. Okay. As one of the companies that actually already uses this notation I think it should be very, very useful, but 5 years. So unless can stop the debate with whatever we conclusion today. Please. Let's let's remove it and leave it later. So maybe we have one last try, on that specific issue on the alias, see if we can get get consensus. And then move on. And and the one thing to say here is when balash, because one of the push on this is it would take a lot of effort to change the tooling I think sorry. I said belash. When pair tried to change the tawling and pyongyang, I think he was two line change or something. It was it was really minimal, to support this. So I I don't think it's a big tolling impact. I know Joe's coming to microphone, but, the timer says you're out of time. For this slide. But go ahead and, climb. Just just a reminder on the time that was just really there for for Rob so he could pace. They they have another, 20 minutes of of I know, but, the screen that Rob gets to see doesn't show him the timer. So I just wanted to let her know. Oh, okay. That's that's fine. I'm we're good. We're number 11 with us. I'm I was just gonna say you you mentioned the PAying thing, but likely this would fall in December the way it's structured now. I think if we were to put this back in because there is overarching revisionally. That's true. But, yeah, that that might be tricky as well. Okay. So I'm gonna move on Augment of IETF Yang Library,"
  },
  {
    "startTime": "00:28:03",
    "text": "Nothing has changed here effectively. So we we are effectively adding a couple of additional bits of metadata into Yang Library about, the conformance as to whether deprecated nodes are implemented and whether the obsolete nodes absent all we've done here is because of other stuff we've removed or taken out of the draft, we renamed that to make it a bit more consistent because all is left. So, the minor change now becomes active Yang state's conformance. Few other changes. There was a section about version instance data, and the sort of, it wasn't focused. The rough consensus was to that this could be deferred that it wasn't add, actually adding that much value to this document. And potentially be better in a new version of the instance data document. So that's been taken out. And then there was a contentious this, description about, versioning infected white space and saying that we wanted to, if you change the white space change the when you would end up publishing your revision. That caused some grief so again, we've taken that text out. So, so it's not on there. Anymore. So that's all the changes that have been taken out. So a very quick recap of what is left. In the documents. So there's the new extension nonback compatible to document when it's not non backwards compatible changes recurred in the history. We've updated and strengthened the rules in terms of, what counts as a backwards compatible and non backwards compatible change. So that's extending, from RFC 7950. There's the new extension recommended mandate that I've talked to you, talked about already. We've got guidelines on how you do management life cycle management of young modules, and then that's the augment of young live that I've talked about. So It's we've dropped about 25 percent of the pages. So it's shorter. Sharper and and ready to go. And then the next steps effectively to pro request another working group was,"
  },
  {
    "startTime": "00:30:02",
    "text": "call after, after I theft 119. So that was what I thinking was. In terms of I think we need to have a quick look at the issue in terms of the module false names, as Joe says, I think that's gonna end up in December document rather than this. And maybe that means if that's if we get to that conclusion, maybe we can last this one straight away and then move on to December 1 after that. So that's my update. Is there any questions or Would wouldn't you have to mod modify this document first to make that change? That you just spoke with. No. So that's the point is because the revision labels have come out of documents, then there's no there's no text referred to about giving an alternative name. You would be in the Yang Semba document that defines the new revision The version and you label would say, can call them what was this way. I could one thing that's sort of sort of not great with that was that these that this document was the ones that's doing the update of RSC 7950. This is the one sort of doing the the more the language structurally changes, whereas the similar draft I think was trying to do less of that and more of just doing a revision, a version label, although it has got the import 5 version in there, So, so maybe actually that's already balanced anyway. I see. I think we are just sort of where we have to be in. Before before Okay. We can certainly take it to last call after, you know, after this meeting, And see how it Yep. goes? And I'm done, Joe. Yeah. I I I think the, making the change in summer is completely reasonable. Particularly with all the simplifications that you made with taking out the different options. Think that's completely reasonable. I was hoping we could do the, last call and the two documents together. Just because you might hit other interdependencies like this, and that, I think it's helpful to I'm it's helpful and unbookful that we can bring them to get do the same kind Either either is fine with us, I think."
  },
  {
    "startTime": "00:32:00",
    "text": "As as I speak for the authors, but I think that makes sense. Either way he works is his okay. Okay. Hi. My name is Joe Clark and I'm going to talk a little good about the other part that we've been heavily working on, which is the semantic versioning update, for yang module versioning. Again, on behalf of the authors and contributors who meet regularly to discuss this. So we focus just like with module versioning on comments that we got on the list. Comments that we got at our last meeting and we ran a poll. We had a hedge doc where people were able to talk about some of the things that we identified as key issues. So based on all of that and based on some of the restructuring that Rob just talked about in terms of modular versioning. This is where we wound up with the current version of the December draft. So one thing to notice is it would there was a a 11, version 11 and then 12 around 118, and then it went 13 and then a quick 14 And that was due to some issues with the IANA considerations in 13, But then what we noticed was with the way that we're doing versioning, and I'll talk a little bit about that. The way we're doing the the comparison of versioning with importing. There was some tech was that that needed updating. So after as a Monday after the, the lockdown was lifted there's a 15 in there. So what we'll talk about here is what's in in teens that you're not confused if you go and read it. So even though this says, look at the from 12 to 14. If you want a full picture of all the restructuring that we did, look at the diffs from 12 to 15. Try them there. Sorry. God. There we go. The first thing we did"
  },
  {
    "startTime": "00:34:02",
    "text": "as Rob mentioned, we got rid of these multiple revision label schemes. So right now, there's no other scheme other than timber and more specifically, there is no revision label anymore. We've added the December draft adds an extension for version. And we simplified the name. We simplified the namespace or prefix. We're now ys for Yang Simber, we were ysverprevious, previously in 12. So now ys for our prefix, and then the extension is called version. It's a very simple wireless version, and that will have the Yang semantic versioning in there. The rules around the Yang Symantec versioning have not changed. We don't really mention all of that here, but it just briefly you have the major, the minor, the patch just like you would have in regular, simber2.0.0. And then we added these 2 modifiers or yang, an underscore compatible, and an underscore non compatible. And I won't go through all the rules there, but that part has not changed. So we've we've we've kinda settled on that a while back, and we're keeping with that. But we did change the name of the extension. It's now just version. And the prefix is ys. The big change here is this new extension recommended men version. As Rob mentioned, we changed just recommended men, which exist prior to the 118 refactoring, we had a recommended mandate in module versioning and the corresponding recommended min version in timber. Recommended minversion ties to a a a specific semantic version, unlike recommended mandate you can have multiple recommended min versions. So for example, remember Rob's picture I kinda had it here, of the branching. You might wanna say that I have a recommended minversion of 3.1.0, and because I know I back"
  },
  {
    "startTime": "00:36:02",
    "text": "ported some things into another branch, I might have another recommended men version of 2.1.0 as an example. So you can have multiple recommended men versions here, and it will be a logical or like which one it do any of these match. The other thing is these rules of how recommended men version will be, will be recognized or or resolved, so to speak. So let's say you have, in fact, I think I'll do it here on this slide just to give you an idea of the rules. We'll jump back and forth here for a second because they are on two different slides. But let's say you had a, this is your new import statement. Import example module, y s recommended men version of 310. Cell. Let's say now you're gonna say how which which module which version of example mod that I may have do I actually import? Well, if you have a example module version 311. So it has a revision statement and a widest version of 311, then it would be satisfied by this rule one here, which is it has the same major or minor version number and the same or greater patch number. So in this case, we say we need at least 310, and we have 311. Yay. We can do it. So let's say we wanted at least 310 and we have 320. Well, we can also do that by rule 2, which is it has the same major version number and a greater minor version number. So it has a greater minor version number. In this case, Whatever the patch number is is ignored, we can we can import that. Bullet 3412 This is also valid because this this is satisfied by rule number 3. Which states that has a greater the module in question because we'd said, remember, we need at least 310 but fortunately, we've got 4 12. So because the minor the major number is different, we can import that."
  },
  {
    "startTime": "00:38:02",
    "text": "Now let's say we had 311 compatible We can accept this because in this case, the major, the minor, the same, the patch is the same or greater, and we'll and because the patch is greater, will ignore the modifier. That's one of those modifiers compatible. 3 12 Seamway 1 once we have a greater patch number, we'll ignore the mod, will ignore the modifier, and we import that Now what wouldn't satisfy this is 31 0 compatible or 31 0 non compatible. Because They have modifiers, but the major, the minor, and the patch version match. Now how would you Let's say how would you import? Let's say the the recommended, we had a 311 compatible, and we wanted to make sure we import that and only that we would have to say y s recommended men version 311 compatible. It has to do an exact match fires for those modifiers not to be ignored. And this is one of the reasons why we allow for multiple instances of recommended minversion so that we can pick up these special things that that may exist, the vendor may do, to, to back port changes into a, a Yang mod. Either compatibly backwards compatible or non backwards compatibly. So we can have multiple recommended min versions, and that's the rules. And how those resolve. This what I presented here is slightly different in 14. That's the big change that went into team to clarify this. So what I presented here is what you'll see in 15. The revision 15 of the of the draft. The other thing that we had to do, because we pulled out all of the, revision label stuff from, module versioning, we had to decide what we wanted to do with the Yang Library updates. And we thought the augmentations to Yang Library where we"
  },
  {
    "startTime": "00:40:02",
    "text": "where we augmented inversion. We thought that was is interesting and useful, so we wanted to keep that and it made sense now to keep to put that in December. Graph because that's now the only place that's talking about this this extension to the revision statement, this revision version. So we we put the, the modifications in here There is another yang module. So there's now 2 yang modules in December graph. 1 is for defining this, the wireless version extension the pattern for a, a Yang Symantec version and the recommended min version and the other is for augmenting our Yang Library. So keep things nice and separate there. And that's just this is the augmentation that you'll get throughout the Yang Library. The last thing at the diff. You're like, why is there so many lines changed here? This is the last big set of changes. We wanted to create a very early on in the draft. And both this draft and in, module versioning, of what a blanched history might look like. Just to give you just to set the stage early on that says, this is kinda why we're doing this visually. Why we're doing this and how a a yang module from a revision standpoint might progress, and you may remember this picture from such presentations as Rob a few minutes ago, that's his his linear or or nonlinear branched history on the left. Well, maybe you see it that left and we go. And on the right, you see the corresponding semantic version. That gives you kind of an idea, visually why we're doing this. And hopefully, we'll we'll help clarify things for for newbies reading this document. Just like, Rob had for those of you who can't wait for the movie, here's the recap of changes that we did in, semantic versioning. We re we pulled out the generic concept of revision label, gave it just a version. We created a course"
  },
  {
    "startTime": "00:42:01",
    "text": "responding recommended min version that's very similar, to recommend a min date, but as some notable differences and as useful as Rob mentioned, when you are dealing with those branch Revision histories. We augmented the Yang Library here, that augmentation isn't different. We've we've had that before, but it was in module versioning. Now it's in December. We added that clarifying picture, and we made some other edits and and fixes based on our own reviews and others who who chimed in, and we really do appreciate that. That is all. Questions? Give me one more slide. Oh, do I? Next steps. Kinda just trying to shoe horn it in there. Well, the next step was before, this meeting began, to request a working a new working group last call for this and module versioning. Now it sounds like we're going to go back and and put in the file name changes, into Semver, into this draft, and and see, you know, maybe it it it does end up being more on the rough side of consensus, but but clearly they're they're and we already knew this from Balash on on and others chiming in, that there is some desire to have this this file naming convention. So we'll look at that, but we we really feel this is very close. We've We've listened. We've debated. But we're and we think that the the this combined work is is very close. We might just have that one little thing to to add back in. Hello? Digital loop. Yeah. I'd like to I'd like to have a moment offline with the, with Kent. And the, the authors about how to one that. I I think we should try to have a very focused consensus call on the list. Rather than do it as part of the document, and sort of like the questions we had before."
  },
  {
    "startTime": "00:44:02",
    "text": "And, so we can we can do that quick and then move quickly to working group last call. I I, you know, if we start pulling it into a document and doing revisions and lots of discussion. It may be that we, you know, it drags out for another whole cycle and I don't think we want that. You know, Kent and I, you know, when we're next to each other, it's easy to have, like, sidebar on that. We haven't had a chance to do that. So, you know, Kent, if that sounds right to you. You know, we can work offline for that. If you think something different, I'm okay with that too. Yes. That sounds good. I was gonna get in line as well, to ask question, but, James is first. James. Shop. I had a quick clarifying question. Are we also intending to augment into module state. Or are we explicitly not planning on doing that? I Just because we use everyone says that people either should or must Yeah. I think should it make. Also update module state for backlist compatibility Yeah. I I remember. I think in my that came up. And I was hoping no one would ask me the question because I couldn't remember if we did it here, and I don't think we did. That's a good question. That that that was kind of an open question. In, I think it was n mop or maybe it was net count on another draft. I the the it was it was asked in the vein of much longer do we have to do these deprecated branches my personal opinion, I don't care. Let's do it. It's it's not hard to do. But I I I don't know that we we we've addressed it yet. Okay. So Kent is a contributor, I think. You have 5 minutes or 4 a half left, and kinda wanna address the elephant in the room. Rob's presentation seemed to be fairly non controversial. I would that would get"
  },
  {
    "startTime": "00:46:01",
    "text": "through, there wouldn't be too much pushback from a non backwards compatibility. We need to wait for yang next type perspective. This one brings in sort of new concepts. And I'm trying to I'm hoping that you can sort of address that and you know, extend the, explanation or some sort of rationale to the work group that would help them bridge that gap that but this isn't going to cause great problems were great trouble to existing mechanisms. So okay. So, yes, This does introduce well, both drafts introduce new concepts. The new the concept of is something backwards compatible or That's module versioning. To your point, that is something that probably isn't that controversial. We we we know that there are back non backwards compatible changes happening, and we want to signal them. We also introduce into that a recommended minversion, which changes the import pools. Admittedly, for tools that will support that, if I have a if I have a module that that I could potentially import And today, I just say import this module, it may or may not satisfy the requirements I need. And at some point, my compilation is gonna fail. Because if my the the module that's doing the importing has a dependency on a node that does not exist in the in the module that I have to import, it's gonna fail. What we're trying to do is just signal, hey. Earlier on in the process, be aware that you need a newer version, a newer revision of this module in order to satisfy that dependency. We Aren't really changing that rule in Semver in the Yang Simberg draft. What we are doing is is binding or a catching a human readable or human kind of parsable label, even though we're we're dropping the revision label concept but we're attaching this this identifier to a revision that says if you looked at this quickly,"
  },
  {
    "startTime": "00:48:04",
    "text": "your human brain would see whether or not if you if you had two modules of the same name, would see quickly is this module compatible based on rules that most of us from a software background might already be familiar with, is there compatibility issues that I might want to be aware of? So if I have, for example, a version 2.00 version of a mod of of module FO and a version 300 module FO. I can look at, oh, There's probably changes here, and they they may or may not affect me, but I should go and at that. In terms of the import, in terms of the behavior change, it's similar to what module versioning has, meaning that if I'm saying that I need at least 3.00 of a module to satisfy this this import, but you only have version labeled 2.00 or identified by 2.00, you're you you might not be able to import that. And even without that, even if your tools didn't support either recommended min version, or recommended mandate, you would get a failure at some point anyway in you didn't have the module that satisfied those import requirements. What we're trying to do in both drafts is make it easier for operators, easier for those consuming the modules, to know whether or not ahead of time, they've got the right capability that they've got the rights dependencies in place to be able to handle the work that they need to do. Ultimately, this is going to feed into some of the other that that, Rob mentioned in terms of yank packages, to make it easier to group module dependent modules together and give them the same version identifier. So we wanna reuse And in fact, you'll read in in we didn't talk about it here because it's been around for a while, we have this term artifact in the timber draft because we wanna be able to reuse that no of a semantic version in other things that are yang related. And specifically in these this this concept of packages. So we we we think this isn't"
  },
  {
    "startTime": "00:50:04",
    "text": "we we don't think this is dramatically changing the way Yang behaves. We think this is making it easier to understand how modules interrelate better than they have today. With just import or import by a specific revision date. Just a quick follow-up. Are you saying that it's an, like, an opt in And if the Like, does the graceful fallback to to existing existing existing mechanisms that, yes, in in in many ways it is, because if you're if you're tooling supports these new extensions, then you will attempt to do the right thing, or you will your tool will be able to say you don't have the the the module that satisfies this, whereas if your tooling does not support these extensions. You're free to ignore them. You will ignore them. And later on in the compilation or or the operational process, you will get notified that there's an error because, for example, you'll try to use a grouping that doesn't exist. You'll try to, refer to a node that doesn't exist. And so you'll we're trying to up low we're trying to load the errors up front from a compilation standpoint for the tooling that does but we don't feel that we're introducing radical new things that will will change the ultimate behavior down the road of what one is experiencing when consuming yang modules. Alright. That sounds good. We have, Maria in the queue. Mario. Hello, Maria. I'd like to ask a concept question. Sorry for jumping into this, in the middle. Because I didn't, I didn't check on this development recently. I'd like to ask, you are, introducing a versioning scheme, which is a string which should be passed somehow by dots and then you compare the numbers. So it means"
  },
  {
    "startTime": "00:52:01",
    "text": "in a machine readable format where we have possible methods, how to encode structured data, you are introducing a string which, encodes structured data to be actually compared. I don't see how this alliance with, all those principles, but I'm maybe 2 principle. Thank you. So we are we're we are introducing a we string, to your point that has some semantic meaning to how it's constructed. The the string is is primarily there to, be used by humans for for just visual looking at it and saying, yes, there's there's differences here. We do have a draft that that Rob alluded to on tooling where we want to do more of the machine consumption of that string and also the machine consumption of the modules to be able to to identify more, backwards and non backwards compatible changes in more of an automated fashion. So so the the the string does have rules to it, and we we define the rules here in the, in this draft to be able to say, okay. This is how you you parse it, this is how you understand it, but we will have more coming, after this initial work for being able to do more machine consumable analysis of both the version and the con the contents of the Yang modules. Please Yeah. The thing is, I am basically, thinking whether it makes sense to have, like, another structure inside the structured, inside a structured language. So M if, if this is something that aligns with the with the young friend Cyprus I am not saying that it's bad. But, it just smells for me. Top, I can I may be 2 principal"
  },
  {
    "startTime": "00:54:02",
    "text": "I we didn't wanna make this overly complicated either? And we we chose Semver because there were already, kind of socially agreed upon or or industry agreed upon rules One of the issues we ran into was the Semver people did change their rules without changing the version of Semver, we mentioned that in the draft, but that's why we kind of there, and we didn't wanna create a lot of new concepts that were specific yang, we struggled with the compatible and non compatible we ultimately landed on there because we needed some of that, that branching that Semba really doesn't allow for it's ambiguous. So that's the the one difference but ultimately, we wanted something that would be recognizable and wouldn't feel too foreign from people doing, say, software development or people with software experience, and that's why we we we stuck with more of the the simple spring versus a more complex structure. Yeah. Okay. I am try I'm starting to get it from me. Thank you. It's a cutty cube. You, Maria. Take please take it to the list. I was gonna only make a very quick con to say that, obviously, the regular sender allows you have extra bits at the end of this. It's already effectively a string anyway. Yeah. So Alright. Thank you very much. You for the update. And then? Alright. Hello, everyone? Let me Okay. pass you to slide control. Okay. Perfect. Thank you. Appreciate it. Alright. So this is a came up with late at night. Alright. Is it good for now? louder, A little please. bit Alright. Is this better now?"
  },
  {
    "startTime": "00:56:00",
    "text": "Okay. Everyone's be very quiet. Alright. Let me switch off my headphones and maybe it's Do you hear me now? you. Oh, much better. Yes. Thank I guess it's not working very well. Alright. Set. Let me try. Alright. So let me try it into out a bit more, No. No. We you. hear you fine now. Thank Oh, okay. Cool. Alright. So, this is something you came with last night just close to the cutoff date. So, we're going to be so feedback is welcome or free to, feel free to throw tomatoes at me. Alright. So this is about validating any data in yank, with a context in a yank library. So, looking at RFC 717, 9750, I was checking the any date, any data statement, and it has a few things that are interesting. First, it claims that it can't take any data that potentially is modeled as a yang that is not known at, design time. And it allows for external protocols to signal that model later on. YAN Data is being used in multiple out of seats, mostly, to either accept any input or return any output to the user. So either accepting an some tree filter, for example, or returning, the result of this filter back to the user. So what's the problem here we're trying to address? So At the moment, there is not a structured way to validate what is given in, as a substitute of any data, at the moment."
  },
  {
    "startTime": "00:58:00",
    "text": "The tools I have looked at, Lipiyang and, basically, accept anything that is you know, encoded as the act without checking if that is valid. It just accepts anything as long as it goes to like Yang, so it's okay. So that can create some problems. And we try to address this as draft. So we made a few assumptions. Is the 3 of any data is always specified in a end model. And here, RFC, 9750 doesn't really specify it, but I think the spirit of it says yes. It is modeled as the end. That was not very explicit. And the second obstacle that we have is, is that sub data is, is this, 3 complete or not? So by complete. I mean, did you take a few, like, a note another data, again, data tree, and you put it as it is at once at data, or you just take some parts. And I think because Most of these various comes from, after a filter. So most of the time, it's gonna be incomplete. Alright. So for the next one, so we made few observations, 3 observations years to come to solution. they have data encoding. I looked at, First, Jason and XML. C bar haven't checked it thoroughly yet. But most of the time, just looking at the end data, you can assume what is the name space of that module that it came from, and what, are all the name of it in case of Jason? The second observation we make is they and a library already have the information. So you know what's the name space, you know, what's the name of the module. And, what we try to propose here is"
  },
  {
    "startTime": "01:00:00",
    "text": "just look it up. So for a parser, I need to be able to look up that information and validate the data accordingly. When it comes to subtree factor. So for implementing this, I have looked at only Lipyank Implementation and what I observed here. I'm showing here example for XML, but the same thing applies for the JSON encoding is, they disabled strict parsing while they go through subtree that is for early data. But, you know, if you don't disable it, Actually, it will be able to work and validate this data, correctly. So you'll not be able to put anything that is wrong. There there is this is an early draft, but there is still couple open questions. The first one I alluded to is a complete it incomplete the end of the tree. So how are we gonna delegate something as incomplete? You need to be able to do a subset selection, and you have to loosen up a bit the rules of Yang, some people have issues with that as well. The second thing, the library might contain multiple materials set. So which one you wanna refer to and, use it as your module name space, there. And with that, I'm happy to hear feedback from the group. And if there's is interesting for people here. Okay. you're Alex, in the queue? Yeah, so Kya Ahmed. Thanks for this work. I think, this is very interesting work. The first So what I see within your draft is, you have 2 conditions. The first one is restricting young. So I am very supportive of that, stating that any data can be validated using young modules. The second one is the open issue that planned here complete versus incomplete. Here, I am"
  },
  {
    "startTime": "01:02:03",
    "text": "Abid, I have some sort of mixed feelings at what point we are stating within the young, within this draft that, any data, so any data that is within this leaf is valid even if, there is a mandatory statement in in the young. Right? So here, maybe I would suggest to either add the expath or subtree filter as a parameter of the of the method, to validate that, or even having 2 flags. I think you propose them in in one of our threats already, that you have one way of validating the date, the data in a complete way and one way on on incomplete way. And that way, you could, still have, you are not modifying, the young validation rules. So that's, that's my take. Click in, And Belage, what? I'm sorry. Benoit, while you're stepping to the microphone, there's a question mark if it's working, So or speak loudly. Okay. So Benoit speaking. Hello, Ahmed. So, In one of the first slides, you mentioned that any data is used to not all RFCs. So I know what you're trying to do. You want invited the content of the push push updates. Do you believe that the content of other need datas in dotrc. So is this just a mean, just a telemetry issue or something wider validate any any data. It is, to validate any data. I mean, they am pushed definitely is a primary driver for this, but it is to address the problem at its core rather than to have a specific things for React Bush. It might not apply to IETF Connectionless OEM because they are"
  },
  {
    "startTime": "01:04:01",
    "text": "the having a solution for Yang Mount, there. I didn't understand it very well, maybe we can commit to it. And for any data structure extension. They say it's encoded as any data, but it's not really any data, so it will apply there for but for the other RFCs. Yes. Balaji and Ericsson. First to ben Benoit, in 3 gpp, we have situations where you store let's say, interesting attributes or interesting data, and you don't know in advance which set of data that will be. So it's stored. It's not just in notifications. The other is about this complete first incomplete. To me, that sounds very much like validation on candidate. You don't validate every constraint because Yes. Let's say your main elements might be satisfied in the next edit config only. So Sean, you're in the queue? Just, something you might want to add as well, is Yeah. Hello. Yeah. to, the path of the any data that you want to that you want to amount because basically you might have several any data not in the same module. And in that case, you might want to have a mapping from this, any data nod to the to the young library that you want to use specifically for, for each point. So you might want to to specify that So, to To clarify here, so the point is once the parcel get into the subtree that is under any data node,"
  },
  {
    "startTime": "01:06:01",
    "text": "once you read these notes, you will be able to tell where they are came from and you're gonna validate So even if you have multiple any data, leaves in your module, it actually applies inside each one of them, and you will be able to tell for the sub, like, the sub notes where they came from and be able to validate them. Did I get to your point here, or I'm missing something? I think the point is if you want to validate, for instance, your any data one should contain. I don't know IITF interfaces and you any data too should contain, a young libraries. You want to to to specify that so that if you put your own library in 80 any data. 1, you don't have the you have a nail I see. This is where I'm, impartial. So this is what I push back. So If we do this, then we cannot restrict the any data and we cannot change it to be really specific data. So, my point was to keep it as open as it is. So I'm not trying to introduce strictions on what data goes in. But if there is a data that in, I can validate that it was correct according to a model somewhere. I think we need to, switch to the next presentation. We're we're definitely over Thank you. So continue the discussion on the West, please. K. A second. Let me pass. Hello, everybody. Yeah. Thank you. So I wanted to talk about, this yang based sensors to my tree that was mentioned, back in Prague. Has not been any new, release of power or and, fill out the list documents since Prague"
  },
  {
    "startTime": "01:08:04",
    "text": "But the reason is not that it hasn't happened anything is it has happened too much So we didn't get things back in the re readable order before the cutoff date. But there's lots and lots of work going on here and many extensions and changes are happening. The first couple of slides you may recognize if you remember from Prague. This is about this young based hunters, telemetry, and I see the green check mark there is on top of the text. Okay. You have probably seen, in recent, Mountain Years. Lots of grafts that are being produced, based on young on from, elements, of various kinds, for example, about the energy recently. The question is though, what can you use these graphs for? What do the these lines really mean? Can you is there any way to trace what this data is coming from Can you compare these numbers between vendors or between operators often, the lines the graphs look great. But they are difficult to know if you can't base real decisions on them. Because you don't know exactly what's included. And, what the precision is and many other things. So we have started to build this field at least framework which is a sort of general framework for collecting parameter data. We had defined something called aggregators, collectors, and providers, And this, is based on the idea that we should be able to use this framework together with devices that support Jang based structures, of course. But also, together with data sources that are not young, and that don't not inherently young based or something like that. Like, from from as an MP or red fish or other kind of sources as well. Because we want this to work with existing devices that are out in the field today."
  },
  {
    "startTime": "01:10:00",
    "text": "And not only some of those devices, but all of them. So we have, created this Young modules, field at least aggregator collector provider, the provided part is going on the devices, and the other ones are for the controllers. And the described this in Prague already, and I'm not gonna repeat that. But based on questions I got afterwards, it was clear that I was not making my message very, very clear. So I wanted to try to describe the same thing in a different way. So here we have this graph on top that's the end goal of this exercise, we want to have these graphs and then that graph is coming from a collection system, I would call it a connect a collection Christmas tree because it's tends to be wider and wider towards the bottom. At the bottom, we have the devices themselves. And we are collecting data from all these devices and storing them in times of your databases. And aggregating them together to form and to add more and more aspects of things together. And then getting this few graphs on top. If you zoom in on this, near the top, you'd see that the first thing that we are interested in on the top here is wanna know exactly what we are measuring, what are the units, what's saw things are in scope for this particular line here. What did we include there? For example, which part of the network are included but also specifically, like, is cooling included here as, embedded carbon for these devices included here. What's the precision and the other sorts of metadata? And then you would all the rest of the tree is based on configuration that somebody would write. Operator of this network. Will have to create this Christmas tree, inform configuration. We are not hard coding anything in the Yang when it comes to"
  },
  {
    "startTime": "01:12:00",
    "text": "fracture of the collection. You would have to say that, yeah, the top telemetry flow here is, the unit is, CO2 equivalents per hour. And is collecting from this and the way that you are combining these data sources is by using linear interpolation and multiply multiplication. The the whole point with doing this as configuration is that it should be possible to dump this whole collection configuration tree to somebody who wants to inspect what do these numbers mean? And then you should be able to tell. What is actually being collected here. It should be transparent. Because today, there's lots and lots of system that produce graphs, but you don't know what they mean because the the way that things are collected is a packing code somewhere. And even the people presenting the graph typically don't know what was happening on the way. But by doing this, by configuration, we both get we get flexibility as well as transparency, and that's a key point this And if you drill down a little bit further, can see that you get into when you get down to the bottom and want to collect data from action devices, you can see that here's where you configure, which protocols to use like redfish, pulling, with the intervals and which path to to actually go and query And those paths can be red fish style. They could be as an MP, they could be yang based, it could be really anything. And that's key because you want to include everything in the network or potentially at least allow for everything in the network, and lots of the things in the network don't have yankush. And, many of the things that you will collect data from also, as data sources that sisterially. So you will have to compensate for that by using files or other things like here, for example, we have a case where the where the data that you read from a particular"
  },
  {
    "startTime": "01:14:00",
    "text": "device, the the data that you is not accurate. So you need to put on, It was what do we call it? The glasses that compensates for those, incorrect metrics. This is file that has a correction value for all the red values here. That's is applied at the narrative of them there. And then at the bottom also, we have this yang mapping to, time series database. Formats where we describe a particular way how to MAPF. Yank in model beta. And that's true. If you have, even if you're reading something from SNMP or Redfish or whatever it is, we want to have a giant description of that data. So whoever is doing this collection, mechanism we'll have to provide yang model for that data that we are connecting. Not for everything on that cooling or, server or whatever it is. And the this is, our strategy here is twofold. We want to work, on the controller side, with all the existing devices that are out there in for hiding metadata and allowing also to control power draw and stuff like that, go with the low power modes and things like this. But we also want to work on, on devices that are new. I mean, things that they're starting to be developed now, are proposing some yang models for what is a good device, good behavior, should be some young models for providing standardized forms of data when it comes to energy and management, for example. So that's But we can't wait for those those standard share from the device level to be standardized and then implemented and then deployed in the field. And then widely deployed in the fields. Before we start doing this. That's why we have this"
  },
  {
    "startTime": "01:16:00",
    "text": "two folds started in here. With that, I'm, I'm done. We have time for one very brief question, and then, we can swick forward switching over to the next one. Right? Thomas Kaufman. Hi, Jan. I only have one, question and one remark. Document right now is a standard track document Shouldn't that be an informational or do you intend to develop any any protocols in this context. If you include yang models in protocols, then definitely, yes. Okay. Because I was thinking, right now we an animal working group, and I have a similar kind of a document but I've been choosing, like, an informational document. And out of that, basically the protocol changes or yang modules are then going into, like, Ned Khan from fire was asking. Yeah. Maybe somebody who understands how you develop yangmall information models can explain that to me and we can think about it. But this is how I understood the processes right now. Again, another good list discussion. We needs to keep moving. Yep. Yes. So, I have a presentation about this, young full embed, which is basically to to solve an issue that we that we had with the that time any fast, so I'm presenting here a fixed fictitious use case, just for the example, which is basically assume you want to to model all your IP addresses in your in your network."
  },
  {
    "startTime": "01:18:03",
    "text": "This is actually in our case. It was not a faces that we wanted to have. It it was We wanted to include the module, for young push because we wanted to add the configuration in the data manifest and so it's, it's kind of a of a similar issue where we have a device level model that exists, and we want to reuse it in a network level. So here, basically, we we have a list of devices and we each device has an ID and then and each device, we would like to have let's say the the full, interface module to have all the, basically, all the interfaces in the network, in a in a single way. And if we want to do that today in young, you we can do copy pasting. We can rewrite the ATF interfaces to have the top level node in a in a a grouping, but, The issue with that is, it breaks all dog months, so we have to rewrite all dog months as well. And, there is another way to do that, which is with young won't, but then it becomes, something dynamic So to, to state, what what there is in, in Young. Basically, There is what is covered in your month is, is our implementation time overtime, which means that to know what you have in your let's say included in a given moon point, you need to have more information that you provide either at implementation time or at run time. What we want to do, in particular for the for the"
  },
  {
    "startTime": "01:20:00",
    "text": "that a collection manifest is to have a module that is fully defined at design time. So we don't want to, have to specify later what is the what is the content that we want to to include in the in the in the in the in the in the symmetry. And this is also, the the difference with what what I made presented earlier. Here, we want to what we want to do is really to have something that is fixed at the at design time, and we want to be able to specify directly in the young module what is, what is the parts that we include? So this is the the proposal that we have. So, basically, it would be a a new extension the so this is the solution for the the problem in the in the introduction, would look like that. So, basically, what you would do is that you would, import the module that you want to include and you also the impact of the extension And then, you would need to add a name, any data, not the idea of using any data is for, client that cannot support the extension. They would just see, some albitavi data tree which which means that, they don't have to to validate it. And then, inside the this any data, you would use the extension to list all the modules that you want to have. And specify the the prefix. So for the for the what it means, it would would mean the, basically, the same thing as the young, young context but instead of specifying the contents of the moon point, using the"
  },
  {
    "startTime": "01:22:00",
    "text": "using a young libraries we would def define it directly inside the the the young module And it's worth noting that, some other, scheme a language. I have similar features. For instance, protobeth, open API they they can do this kind of thing, which means at this point, I want to include the content of Nosever, schema, I see that there is a question from. Well, actually, I'm gonna read some And also speaking, because mainly young guy in 3gpp, This will be very interesting for 3gpp Yangmodels. Where we have a basic problem that the, let's say, the root of the yang models can be either a subnetwork or managed element. If it's a subnetwork and everything that's under managed element has to be put under the subnet work that brings me to the second This is a simple case where you just put one yank module in the standard data contents. Usually, it's a hierarchy or a tree of young modules that would be listed that would be mounted there. So Fixed mounting would be very interesting. I could even get the liars and statement from 3gppto indicate that interest if needed. Oh, okay. Thank you. So for the hierarchy, you could put, you have some any data in the module that you want and this module could have their own any data. Jet. Scott Mansfield, also Ericsson, but different hat. The, this is solving a problem that we've seen in a liaison from the broadband forum. So you're"
  },
  {
    "startTime": "01:24:03",
    "text": "you seem to have hit on something here that that's very necessary and and very useful. And if at any point you're ready to this is to the chairs too. At any point, you're ready to send a liaison to try get some more people to look at this, just just let me know. And then, we can we can certainly have a lot of discussion around this one. It's going to be, very interesting for, or other groups that want to do this because where there was a liaison from the broadband form back in July. That talked about a scalability issue. And the way that they tried to solve the scalability issue was to take the interfaces module from the IETF open it up. Change it by adding things to the front of the tree. Which is exactly what this is doing, but in a standard way. So thanks for the thanks for the work. Thank you. Alex? Yep. So very interesting work. I I kinda have the same comments. I support the way you are doing it Can you call back one slight? I have a question. So you full embed the full tree for for for the IETF interfaces. But are you allowed also to just include some only parts of that young module or you are including the full tree. Okay. So, can we go to the next slide, please? So, I think this is the point 3 and this one. So thank you for asking the the open question. And I think also the preview sensor we have answering the question 1 so it bounces useful. So I think this is this is, an extension we consider. Yeah. So maybe we'll we'll do it as well. Okay. Thanks. Yeah, James coming."
  },
  {
    "startTime": "01:26:00",
    "text": "Came very interesting work. I know you have it as an open question in the document, but I just wonder if you'd had any thoughts about how you might deal with leaf lettuce. Leafrefs? Yeah. So, basically, the ID would be, so for the leaflets, if it's inside the the multi part, it should be, included it should it should stay within that part. So, basically, as as a separate context, like, like, in young, with the with the second point here that we could have the the the pound notch mechanism to include the extra extra nodes. And, we could envision to a brief offer so from the module that is mounting the the other one, because, they have the we have the full information here to refer to a particular Okay. So you may And with that, we actually have to go to the list sorry. We we have we still have a bunch more to get through. Thank you. Hey, Rob. Has last, comment. Okay. Just a couple of quick comments. One of them is I think it's worth picking up the Yang Pack's work, not not necessarily because it's only slightly different from this, but I also consider a similar sort of thing about doing handling or or the mount points and just finding the scheme that's So in particular, it covered some of the other issues. So I think that has some of the things that might be worth interest be of interest here. The other thought I have, and I don't want to slow this down is is is this a too big a change for Yang and should we consider as part of yang.next is the other question I have. I see some head shaking in the room, but no, no, Balash. We don't have time for the conversation. I also wanted to show, plus one support for this work, much better than just came out in my mind. Who's presenting the next up, Perfect. Here we go. Waiting for Okay. Thank you"
  },
  {
    "startTime": "01:28:04",
    "text": "Well, this is, this is some work that is, cost started in in the well, we presented it, what we have presented it a couple of times in the, OPSog area. And it was suggested that, Could belong better here than than in the ops. So I am here to see the the opinion of the group and see whether we we can move it forward here or or elsewhere. So, basically, the the goal is our provenance is about, what, and particularly about data provenance is how we can keep document the trail of what the what has happened with data. As it has been aggregated and progressed, stored, etcetera. And in the in the case of the of the Janian Berman and the in this proposal is about warranting the urging and integrity of Jan Datasets. And as you can imagine, this, the proposal is to do it by mechanisms for for digital signature. This was motivated, but from the discussion I had, with among others with, with Jen, on, another draft on how to, provide the manifest declaring the, the nature of the collected, datasets, And, well, thinking about it is not only for kind of money first. There are many cases in which, well, this could be applicable whenever there is a data intermediary, it's not that you you have put data for at at rest. Or whatever this is going to be used for e aim, by for, training of AA systems, or for running whatever the the all the trades. DF. Foundations for these. I mean, well, that the point is that, well, the current practice, normal thing of how you can guarantee the the authenticity and integrity is"
  },
  {
    "startTime": "01:30:03",
    "text": "but it's based on the transfer protocol. We are we are using TLS. You're using SSH. You're using the certificates that are associated It's something that you can store and and associate, but the capacity of verification of this is limited one once you are trying to use the data offline or you're trying to use to use an aggregate that is not using the same. Trust for mechanisms, and the ideas to, to up to in this in this proposal is to use native support inside Jang in some inside the data associated with the data itself or we've made the data that it corresponds to the data. And avoid this kind of transitive trust that they say, I trust you. I trust that you were talking someone that's authenticated to you, so you trust them. That other party and that you're telling me that I had to to believe that and supporting something that is important, when we are talking about something like I I couldn't get the mechanisms. Like, the one John was presenting John. That is something that is difficult to The the the the Jan is is check photos. Jack Lindblad is. But, please, we're running out of time. Okay. And, so the and and it's based on on this, forecomes as, singing and using the the detached by payload, so we don't need to provide additionally an envelope. So for that, the proposal is to use COCI, signature, midstream based on these provide this, type, this type dev that is new one that is on on the provenance signature that is and describes how this is a this, signature is is generated the method comes from the from the cozy, specs in which the AVS to use, the single signature format with advantage detached payload. The payload, they were designed generated according to to certain rules,"
  },
  {
    "startTime": "01:32:02",
    "text": "And in the information, what we are improving is the the identification of the key for further verification, deserialization methods, and any other parameters associated with the with the certificate. This is This is the mechanism as as described. They are for cozy. for And once you have the the signature generated, what we discussing during the We're we're waiting nope. So where where this signature could be associated with the, with the, data So at the end, we we ended up with 4 foreign closing measures that can be provided. 1 is as a leaf element. The second is about, part of the push when you're using this in the in the in gen push, Those are, have termed these as provenance elements because they are associated with the data. Itself. There are 2 other enclosing methods in which you associate the signature, the the the signature strings with metadata. Either when the data is arrested in a in a jam data file, and that it adding, an element for the provenance ring. And even as a and that's something that the last proposal that we wrote is about including proven as, as as the annotations, a particular case of annotation. These 4, enclosed methods are described in the draft as well. What this all of this for Meadows support is a is a precaution that is important when you have aggregated and you have as I said, and you are combining them into several different sources or whatever for for storing the data or processing the data and, what this described in the draft. And here is that Each one of the methods, support. I mean, and I need a combination this kind of precautions so you can have a sign for an element and assigned for a list or assigned for a for a a number level aggregate, aggregate of the data"
  },
  {
    "startTime": "01:34:04",
    "text": "So right now, as I said, we are a version tool right now, for some discussions inside. We are I'm here because, there was this Egyptian of or or bringing this to to net mode. So whatever the suggestions or whatever the even I mean, I I don't have any any kind of Problem in bringing this here, if if the group thinks that it's more adequate here than than in ops. And right now, we are we are trying to address the that are identified as to be decided to be provided and we are we are working in a in an implementation that is quite promising. We have some results, but not matured enough to be shown, but, you hope right now, but I hope to bring An implementation to the upcoming hackathon and, hopefully, to to report the results there the results are. And, well, what that happens, and we have something that demonstrates that this is feasible, that this is doable, and this is has a reasonable cost. The computational in in size, etcetera. Well, look and look for, adoption. Here in ops or whatever. And that's all Okay. Yes, Lou. I was I literally had that poll about to go, but then I heard Diego. It seems like a proof of concept at the moment, and you'll come back and report results and then we'll see the interest in the room. Does that make sense? Okay. Yeah. Yeah. Yeah. Yeah. Wait. We're working in it. Yeah. That that's fine. We were gonna just do a quick poll straw poll to see if there's interest in the room. If you're if you're still developing the concept that I completely agree with, Kent, let's let's after when you're ready, come back, give us a report, and we'll go from there. Thank you. Thank you. Yep. Yep. Thank you. Very, very interesting. Alright. And Edward. Oh, you're room. in the"
  },
  {
    "startTime": "01:36:00",
    "text": "Very good. Nice to meet you. Okay. Hi. My name is, Ed Brain. I a co chair the DTN working group, the meeting of which is happening, tomorrow morning session 1. My In in that working group thank you. In that working group, we have started, well, started. We have start we have been doing work. On a management, architecture relating to some of the management things that we are seeing in in mostly space networks. So to that end, there is a a document that is, going out right now for review called a delay tolerant network management architecture, that, speaks to how we manage devices in certain circumstances that we call challenged environments and in particularly those that are using and communicating over the bundle protocol, that we that, put out in the D10 working group. When we talk about what a challenged environment means, we sort of look at things like this. We have constraints that are levied by our environment on us. Things like, the latencies are are significantly longer than things that in seconds and hours and days. And of course, some of that is, simply we don't have line site, but some of it is we don't have power or we want things turned off. For that reason, on the top right, there's really no timely end to end data exchange and we don't always assume that we have timely access to infrastructure. On the bottom left, there are asymmetric links that we have to deal with. And the asymmetry is one thing, but also when you have very low links, maybe our management information back is just not something that allowed to go over the link because the data is is more important. I, I point to a lot of space type examples here because, for many of the space agents, they've all said things like bundle protocol is the transport protocol that they want to see end to end. Being able to manage that in these space cases is is an important consideration. For us in in in our working group."
  },
  {
    "startTime": "01:38:00",
    "text": "To that end, when we looked at how most space missions do their autonomous fault management. And this is, a claim, based on experience in sampling in in the industry. Everyone has a roughly similar way of handling fault management on board for space systems. And these are typically stimulus spots systems, they are sometimes proprietary, they are typically, favor heritage implementations, and they want really deterministic process your $1,000,000,000 asset, if you can't talk to it, you really need to know what it's doing and how it's cascading down a fault tree and into safe modes. But because of that, you wind up with very mission specific tooling and they really don't focus on standardizing pieces of this model. And that is, of course, different than perhaps what we see. Here in the IETF and with our enterprise management systems where we do have standard models and standard transports and open source tools and very large installed bases. But less, not 0, but less focus on command based open loop control. And so one of the things that we've looked at is how do we take the fault management autonomy best practices from the space system, guide that into operational economy that is also flyable on these platforms and do it in a way that overlaps with the standard models and transports that we are building here. Because as we know, we are starting to see an overlap in space systems and network systems. So to that end, we came up with a generalized autonomy model. And again, the claim here is that if you were to sample the types of organizations that build deep space spacecraft or spacecraft in general you will see systems that that can resolve to something that looks like this, which is typically a rule based system. There are time rules and state rules obviously time is a kind of state, but it is a specialization and optimization. There's externally sample data and operators controls variables, macros, reports that are generated, and we want a reason about that. But in particular,"
  },
  {
    "startTime": "01:40:00",
    "text": "there are best practices related to if you were doing stimulus response systems, You want N of M evaluations. You want maximum fire counts. You want maximum numbers of evaluations and cool down periods, in between because This is not just information flow, but, of course, things that affect the physical behavior and health of of the platform, but also these autonomous systems reason about instances of the data. And when they push out rules and define rules, they say things like, you know, if the data that is fresh and sampled right now has a particular characteristic. Then take that data and use it to parameterize an action that is going forward. And and so there's a little bit of a mix between the of the data. In these systems. And that will become important in a slide or 2. And then typically because these are deployed systems, we go into these cascading rule sets of detect errors or off nominal congestion in a minor way, try and apply a minor, mitigation if it persists then apply increasingly, greater mitigations. And there are some examples of it. I will skip over these in the interest of time, but know, this is a a false tree, piece from a public Basel in the new horizon spacecraft, which is the thing that took pictures of Pluto many years ago. And it's just an example of how you can have a excessive thrusting rule for 33 a half minutes? And how would you detect that? And what is macro to walk through it. And it is an example of the thinking that people do in fault systems on these platforms. To that end, when we have looked at it, it's how do we migrate that fault management autonomy like system into operational management autonomy type system for nodes that are running in DTN and challenge environments We said, well, we still have managed devices and managing devices, and we still have commands and reportings that that go back and forth, and we still want pre shared definitions between them."
  },
  {
    "startTime": "01:42:00",
    "text": "But there might be a a slightly different take on this which is, at the very end, if we have agents that are conforming to this, what we would like to see as encoding the practices that we see in systems today, in these space systems today, is that the management is configuring a local controller. On the platform with the idea that you activity with the remote controller or remote manager, but you will likely not have those same periods of disconnectivity with your local controller because co resident. In that sense, you build up those stimulus systems and the understanding of the data that you are expecting for them, and then onboard engines, local engines, apply those rules at times when you are disconnected from the remote manager. And, architecturally, we have gone down this path because, again, it is the capture of what we see as best practices in a particular domain, And from an architectural viewpoint, we had two questions to this working group we were asked to come and present it here. And the first question, of course, is, is this an an understood command based system, for these for these kinds of deployments, are there any significant concerns, about this for network data as opposed to the fault management data, which it is used for. And then the second is how do we model this in a standard way? You know, for subsequent work here, we said, we want this information modeled in Yang. We have made initial attempts to model this in Yang. We have, some part of this as domain specific language, some with restrict statements, modeling this in Yang is the right thing to do. We in the DTM working group are not the experts in Yang, so in a way I'm here because I am seeking professional help. So, as such as it is. So with that, that is our overall system and our approach, but we think that we need help in understanding the language or understanding, upcoming modifications to the language or areas where we can come up with domains specific language to get all of this to work together. And get us back to"
  },
  {
    "startTime": "01:44:04",
    "text": "Well, I can't go back. Getting that's okay. Getting us back to that Venn diagram of and overlap between space systems, and best practices in network management here. So I just want you to be aware of that work. Obviously on the detailed work of your mailing lists or, or tomorrow, please come and talk about it. And happy and eager to have any questions or comments here in the minute that we have remaining. Okay. So go ahead and hash. So, just so reiterate what Ed was talking about. The stock was brought into the network working group precisely for the reasons that, you're applying is for the script to try to take a look at it from, both our language and a protocol perspective to see how Yang. Or an core, or any other could be used to solve the problem. So I would encourage group to try to take a look at, Management Architecture. Just a comment on one of the slides. I think it We had a Venn diagram between the space craft management system. And the enterprise management system, and seem to imply there was no overlap between the two. But that's just a side comment. We we we need to make that bigger. Yes. Completely agree. Okay. So, I guess, Kenta's chair, very interesting work. The reason why it's here is so that we can see if Yang as his is suitable, or if modifications have been made, like a profile thing, you mentioned some restrictions. So if we took, you know, carry the conversation forward about what this options are, And, you know, maybe even find a way to make them standard. We we do have right now two documents also in the DTM working group that show how we can build and model this system with unrestricted yank. The question that came up was, are we doing it correctly?"
  },
  {
    "startTime": "01:46:03",
    "text": "Mhmm. So we are, we are, of course, very open to to comment and update and and corrections of any Okay. And one, thought I had was, both RPCs and actions have input and output, but but if I understand your, DTN, the output can't really rely on having output So we would ideally have a way of saying that for those kinds of game modules, output statements are not to be specified. Yeah. And there's like the restriction clause. There's some way of of saying, anyway, not to use here, but, yes, the that is that is the help and additional information we need to Okay. There's a comment on the list or the chat window about possibly taking this to the gang doctors list, Oh, that's a great idea. And we should keep moving because they have 2 more and not a lot a time, but, thanks for that, Ed. I think there's you know, as you're hearing from the group, there's a lot you can leverage here. Alright. Thank you so much. Thank you. Did you steal the clicker? Oh, here it is. Okay. So hello, everyone. My name is. So this presentation is about a common young debt model for scheduling. This is the first time for this work to be presented in Netmoat Working Group. This is draft or we submitted in the ops area working group. So just give, the documents status of this work. This is actually motivated by, some other work we did in area working group, which is above the, SL extension and part of that extension is related to the scheduling augmentation. To the SDR model, for example, to implement and I see our policy that, tax effect from 9 AM to 5 PM. So there is some period and recurrence related parameters are defined"
  },
  {
    "startTime": "01:48:04",
    "text": "to augment that SL model, but then it is suggested to move this scheduling parameters into the reuse book groupings and then separated from this draft best on the feedback from the working group and we intended to be common. We intended the the the definition of scheduling to be common, we align with the representation of period of time and the recurrence form as defined in existing RFC. And the this is mostly because we also try to identified some ongoing efforts almost at the same time that are related to the scheduling contacts and some of that efforts are from the area working group and others, one piece work is from the TBR working group, the time we are into routing, in within area. So in the last IT meeting, the authors of different drops related to the scheduling. We had a side meeting together to discuss how this draft could be, better served as the common building blocks and how the various requirements could be fitted and based on this document. So we updated the draft based on the outcome of that discussion and we put the update to the TBR working group for their review. We received fit positive feedback from TBR Working Group. So now we have 3 users of this scheduling a young definition now in addition to the the the SLX attention. The use we we call you Sarah work. We did And we also have the scheduling OIM tests work in the ops area working group, which is about the network diagnosis using the OIM tests in a precise period of time or based on occurrence rule. And another is from the TBR schedule young. Draft, they they try to, define some scheduled and network resources"
  },
  {
    "startTime": "01:50:04",
    "text": "entrepreneurs changed, based on, predictable recurrence. Of of some period. And this, this is the overview of the groupings in our current schedule young debt models. I don't have the time to present them 1 by 1, but all of our modules is about the grouping definitions, to represent some common scheduling, parameters and this this is nothing about the Netcon protocol extension. And for next steps, this worker is was presented in the ops area working group Monday this week and the requested adoption in there, but per the eighties call suggestion, that model booking group might be, more appropriate to discuss this work. So the authors would like to ask if is the net mode interested to adopt this work, how should we proceed our adoption in ops area working group. So now we have a lot of normative dependencies on this work. The their extension work, we believe now is ready for working group last call but waits for this and there is also some urgent requirements from TBR Working Group. So that's it. Comments questions. Sure. Luke, Can you start a show of hands full for this? And my comment, let me see. This idea has been presented in the past, and the comments that were made then was why do we need scheduling on the device when controller can always push updated policy, configuration to the device on a schedule. And I think the reason why something like this is necessary is for autonomous systems. You don't necessarily always have the ability. I see Ed space based systems, they have to be able to, you know,"
  },
  {
    "startTime": "01:52:00",
    "text": "resolve things themselves. So, I do think that something like this is necessary. And I'm gonna do the pull in two steps. The first is general interest. And then the other is suitable foundation, I'm personally expecting that there's gonna be interest, but not a lot. This supports for a suitable foundation because This was a late edition, and, my bet is many haven't read, but I may be wrong. Joe, do you wanna make a comment while we're Okay. Joe, definitely come make a comment because, we we're we're gonna this is gonna run for a minute or 2. Yeah. I'm gonna It it was known with Joe Clark, as ops area, working group coach here. It it was mainly to understand or or state that The ACL work is is close to last call, and we we we wanted to get some quick ish kind of impression of what Net mod might wanna do here. And I pulled myself out of the queue because I thought, well, maybe this poll will give me some of that. So the first one, there was actually quite a bit of interest in this almost half the group. Who who are half half of those present. Less than half, but almost, we're interested in the topic. So that's, I'd say surprising interest. Oh, surprisingly good interest, I should say. And now I'm asking, you know, who who thinks that this is work is a good foundation if we were gonna go adopt it. It's interesting we're getting a fair number of no opinion when we really were"
  },
  {
    "startTime": "01:54:01",
    "text": "looking for yes, no. Probably varies on who read the draft or not. Maybe that's it. Maybe no opinion means that they haven't read it yet. You know, for a draft that's a very, late addition to the agenda, I think we're actually showing pretty good support. I think we'll we'll talk about it and, you know, hearing hearing that the ops area really would like see motion on this probably is a motivation for us doing a quick poll but I will Ted and I will talk offline. Yep. Okay. Thank you. In in general, surprising support. Thank you. Right? And is Tony or Ron here? Hi. I'm Tony Lee. I've only got 5 minutes. I'm gonna talk fast, keep up. When working on yang model for power management, This is to support doing some traffic engineering. And, the 3 power, TCE that's trying to do power management needs to be able to reach out to devices and understand what power they're using, what components are using power. And then be able to control them, shutting them down won't things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get things get Unused. Alright. So This is what I just said. Right? Significant thing here. We see lots of diurnal traffic patterns basically, everyone goes to sleep, access networks are unused. We can shut down lots in part lots of the network. Our simulations show that we can shut down about 75% the data playing in act large access networks To do this, we are proposing several things. And by the way, I we first proposed this into Ivy. They told us to go away when we were redirected to here and APSA"
  },
  {
    "startTime": "01:56:03",
    "text": "And subsequently, we have already gonna be redirected to the green boff. First leaf that I'd like to propose is a used power, and this is part of be component. So this is recursive. And can be re reported by various different components within a box. This is in Watts, which is awkward, but open config is using this leaf already. And so that's what we're tryna continue with we wanted to have a knob to be able to turn it off particular components. This is a bullion right now. Many people have already asked me for a slider and I don't know what that means. When the controller wants to power save something, It's only knows one thing. Turn it off. Before the controller can turn things off, it needs to know that it can be turned off. So there's a leaf to describe that. And also a leaf to Enable or disable automatic power management on the device as a whole. Lots of devices tried to do automatic power management already. Specifically fans are very commonly spun down to match the current temperature inside the box and spun up if required. Sometimes that breaks. And so having a yang knob to turn that off from management plane would be very helpful. We have a need for describing functional dependencies. For example, we have switch cards in a box. And line cards depend on switch cards, and there is nothing in Yang that says that so far. We would like to add that, just so we don't accidentally turn off switch cards that look like are unused. Here's the tree representation. Ron and I are Yang Nubies. If we screwed up please tell us gently. We also would be very helpful to know about traffic."
  },
  {
    "startTime": "01:58:03",
    "text": "We can modulate how much power a switch fabric uses if we know how much traffic is coming into the box, a controller can tell us exactly how much traffic to expect And we just need a mechanism to communicate that to the box. So here's what we're proposing. K. That's it. Any questions? Thank you. Yeah. classes? This is mine. Which classes? Which Come on. We've rushed through those presentations to give them more time. No comments? Ted, you were in queue a moment ago. Are you? I was. I well, what else make comment that, Tony might interest you. I used to work for Juniper And, 20 years ago, filed a patent with Matthew Palmer on power based routing. The whole idea was to be able to do routing based on, you know, how green the energy was. So data center was powered by solar. And it was a sunny day in that area, then, you know, route the traffic that way, or if it was not wind power, then you know, it's all about, how to make the routing as green as possible. Of course, you'd want to do it in layers, right? So that would be kind of an out, like, security layer. It'd be raised management, in layers. So, that was my comment. Thank you. K. Mahesh, I just, put a comment also in the chat window to say that I believe this enough interest in the community for because think this was, as, Tony said, presented both in IV and a working group. I believe there's enough interest in the community to have at least a buff so I'm hoping that the interested parties will come together. To put above first proposal for 120. Yeah."
  },
  {
    "startTime": "02:00:01",
    "text": "This job that we're definitely interested in, we have, you know, with, similar idea in, IV speak louder, for this chart, we definitely, we are interested actually where you have a similar job in the IV because then actually I think share some synergy. Just a quick comment, you know, for this component dependency, you know, So if we disable 1 of the component do I need to, you know, also disable all the other, you know, dependent, you know, component. So this may be too detailed. Oh, yeah. Well, actually, Angel. Estimate. As far as I know, there was some workshop in the IETF about energy. It would be very interesting to hear what their comments where and what they proposed for such topics. Know how long ago that workshop was? Few months ago, I think Yeah. I'm doing that as far as I know, was there. Okay. I was invited to that workshop. Sorry. I can't tell the dependencies is to prevent you from turning off things that are still in use. So you would not turn off a switch fabric if there's still line cards using Any other questions? Three people still in queue. Yeah. It's, out of time. Yeah. We're out of time. Thank you very much. Made it through all the presentations, and I believe we've had a successful meeting. Lou and I will go over the minutes to, review chair actions. And, act on them as quickly as possible. Lou, do you wanna make any concluding remarks? I was just gonna say thank you all for, helping make this a successful meeting And look forward to seeing you at the next IETF. Perfect. Have a good rest of day."
  },
  {
    "startTime": "02:02:00",
    "text": "How did it go at getting most of the nights? The sun bits I didn't get. So Thank with that. you. You're you're awesome Yes. Hi. Mhmm. That we can have about we do some research and, okay, that's something that and to have we want to just with move forward"
  }
]
