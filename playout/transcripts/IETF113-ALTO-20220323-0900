[
  {
    "startTime": "00:00:06",
    "text": "okay yes okay uh let's get started uh so uh hi everyone and welcome to auto session so this is a hybrid meeting and my name is ching woo join with me online we have yen siddharth and mohammed book there and we will host the remotely and actually in a room we have judy actually to coordinate and to manage the midi echo so thanks jody for volunteer very appreciate not aware and probably already familiar with this if you make any contribution and please uh make sure you follow itf rules and if"
  },
  {
    "startTime": "00:02:02",
    "text": "you have ipr please just close it uh codec conductor and uh and when you make a contribution or you make comments to others topics please be friendly and focus on technical discussion add a mix trivial and as usual we'll use midi echo to for the kill control if you do the presentation or make comments please enter into the queue and by pressing the red button and if you uh speak please identify yourself and when you stop speaking please mute yourself and uh for jabba scriber and we minutes taker we actually have danielle king and richard to have her take a minute so thanks ben and the richer and the jabber any other any volunteer for the chopper actually uh i think the rule can help you to watch the java yeah uh blue shield actually we have uh electrical blue shift please make sure you join the medical so your attendance will be automatically recorded and you attend them in person please make sure you join the medical as well and work remotely actually uh as we know actually most of the work actually will be done on the menus please leverage the meninist and if you bring if you have any new"
  },
  {
    "startTime": "00:04:00",
    "text": "idea please uh introduce your idea on the meninist and for working good job it's important to raise the discussion on the list to resolve any open issue and uh for informal meeting we actually already have a weekly webis webex meeting and to uh facilitate the uh chat item progress and for online meeting uh if you think you have any good proposal can fit into the order charter and you can request the share to schedule the online meeting so we are happy to do this rpr disclosure and so this meeting agenda for today's discussion will focus on childhood items and the two items will be discussed one is auto om support the second is auto new transport and also we actually have a deployment experience updater and this is also part of our auto chatter and if we still have time actually we will discuss a new uh non charter item which actually [Music] introduced a new idea to discuss how to integrate the g2 into the auto and also we have auto related activity uh uh actually we have computer aware networking both actually this will be introduced by luis so any agenda batch okay uh let's move uh move on uh for document update and uh"
  },
  {
    "startTime": "00:06:00",
    "text": "since last night it meeting we actually moved four existing work item to the offset queue so thanks for the author and editor for tremendous effort and we finally deliver this for work so let's give applause to all the authors and editors and also in addition we have a new worker item to be adopted which is a course model draft this actually is a companion job for the past vector and we already initiated the adoption call in uh before this meeting actually this has already have a zero zero working group job and our chairs plan is we were uh immediately initially the working last call uh right after this meeting uh for new era actually we got a four new era actually uh all of these right actually are related to the auto based protocol and so for the first one actually uh raised by the samuel uh during his security direct review he identified a typo actually these need to be verified and also for another one another two actually relate to the course mode actually we need to uh uh you know make update to the other baseball game it's kind of type already this has been discussed on the list with auto based political author and uh for all these three i think this need to be verified by our id so any comments on this"
  },
  {
    "startTime": "00:08:00",
    "text": "uh milestone update actually currently we have already have a three uh milestone and uh but uh because of the existing work item actually will take quite a long time actually so uh so we chair actually uh suggest that we can make a milestone update in addition we actually introduce a new uh work item customer specification and this has already discussed with our ad and the set of the milestone so we propose the milestone actually to change it changes the time frame so any uh suggestion for for this any input or opinion on this proposed milestone uh last one actually we shared this class actually how to socialize auto actually we really want to increase more visibility to the auto activity and our purpose actually is disseminate this worker to all the other [Music] areas in ibtl and we also need to you know socialize this author to the operator community and operation developer community and uh we actually have a sitcom ai actually um actually proposed by the auto design team member and this will be a continued effort and but we need other venues to promote the author in operator community and application community and in addition we seek more volunteer to build the auto tutorial actually and this will be discussed in for example office area hot area or some other venues"
  },
  {
    "startTime": "00:10:01",
    "text": "and if you have any input to but please let us know in addition actually we will consider to edit a paper in ietf journal and we can hold the pen and but we need an input from the auto design team and an auto community so i say uh luis do you have any comments on this yes i think this is from telefonica yeah we i we were talking jordy and me about the different uh potential venues that we are identifying here in in this meeting precisely so our proposal will be maybe to in one of her weekly calls to to make a proposal maybe a survey of what could be potential let's say targets to socialize although with different working groups here also even research groups from irtf so just to comment the or proposal of commenting maybe in one of our weekly calls and and and to to plan some activity in that respect okay okay thanks for input actually i hope you will contribute to this kind of effort yeah so any other opinion if you know actually we can uh kick off the discussion for a general item uh and i think the first one is jason right jason so please take a take away"
  },
  {
    "startTime": "00:12:00",
    "text": "yeah i just asked to share this slide yep maybe i need to stop my share right can you request again maybe okay okay i see [Music] okay so hello everyone this is jason and so there's a slide for discussion about the the new generator for the autoimm and management data module i work with to roland and kai and we are working on this uh document right now they pick a summary about this document the main goal of the document is to try to try to provide the young data module for the om and the management of the auto protocols unless it version already uploaded to the data tracker also we also have the other copies on the github and in the recent version we also include the aussie young audio code also on the github can be accessed i think where we can request and reviews for the initial version of the uncle and for the major uh changes uh since the latest uh between this latest version and our previous version so why not change the vision day document title from the om to the o and m so so which means the oem and management that we follow the guideline this is comments from the"
  },
  {
    "startTime": "00:14:00",
    "text": "edu in the mailing list so we check the gala of the art 6291 so i think they this document not just target to the om i also include the management part between this title to the onm also writes the scope and requirements to be exactly aligned with the rfc 7285 and the rfc 7971 it's also a common comment from many reviewers in the middle east so another major changes will make the initial yamada code ready so i think it's ready to be reviewed and also thanks to the supermass contribution to the english version so this is the current basic requirement we post in the latest version so you can see the basic requirements they have the several requirements uh which align to the app system tuning 85.91 so all the references the given in the table and we also have the [Music] additional requirements so that's for the extensibility so as the auto purchase is extensible so we also requested it data model for the auto onm still should allow for the augmentation to support the potential future expansion so that's a the current additional requirements i think is very important for this document and then so this is the current status of the our progress for of those requirements so you can see we have already have the initial proposal for the from three times five"
  },
  {
    "startTime": "00:16:00",
    "text": "five one five point two and the six and eight uh so right now we are working uh progress on the the first requirements and the 5.3 and day 7. transfer it's in our plan but i've been still in the to delete the i'm not any purpose right now but uh hope you can finish it by the next scientific meeting so we want to use this slide to give a very quick uh overview about uh how we manage this uh data model so how the model can land to the other server architectures so they did blackbox uh its black clothes means uh component uh in the auto server so it is inside model scope so this this model will provide a uh the the current document will provide any model for those components like this server management the information resource management the performance monitor logging and phone management and also the data source listener so never requires a data mod spot but in the auto scope we also have them data brokers to define how to store and use this uh clock from this resources and also need some [Music] implement specific algorithm plugins to really define how to translate this data data sources to the specific information"
  },
  {
    "startTime": "00:18:02",
    "text": "resources they are in the autoscope but not in the scope of this data model document and they so this is the gift for the server setup so which is the first requirement so this part will define some meta information for the server level uh oem and management but it's still in working progress so you can see the current information word they only include some copies of the required information so trying to [Music] make it more comprehensive like we try to also include some http server lesson configurations which is inspired by the redstone server data models and also we also need some dns computations for the server discovery which is required by the fj72 86 and 86 and this one will be the major piece of this data model which is provided model for the information resource management and to achieve this uh so that this is the uh requirement five so to achieve this uh we separated to the three pieces why is uh how to define uh information results so it provides some common parameters for its resource and the resource specific parameters and in each"
  },
  {
    "startTime": "00:20:00",
    "text": "research specific parameters the opportunity to specify what algorithm used to generate this information result and which data sources can be used to generate information and for the third monitoring they so they the green uh landmark uh to the uh these atoms uh marked in the green colors uh means uh it's already included in the current model and the atom marking the red colors means they still work in progress it's not still not in the conjugate models part but we are trying to work on them to finish this by the entire active meeting so the meterpiece uh we still need some discussion about how which specific information needs to be put for the mailman on impact which is because some information will associate with the application performance so that probably will be implementation related not uh so we'll try to summarize some common features from this uh merman so to get some proposal and another major pieces already including the current data model is that they of all they recommend which is how to"
  },
  {
    "startTime": "00:22:01",
    "text": "provide the sensibility so how to extend the current to the model to support some future features like if the developer wants to implement some specific algorithm to define how to generate a information resources so this example gives issues how to argument the algorithm choice of the auto network parameters with a creation algorithm so it's required simple so you just need to specify so which source id uh should be used and the third item will link to a layer three networks about which is defined in another your model so it can be provided by the netcom and we reference another [Music] individual draft which provide the reference algorithm implementation so how to translate this uh the layer 3 network model to the auto information the network map and the custom app yeah so the obvious days come to progress uh we achieved for the current data model but we still have some questions about how to proceed so the first question actually generated recently in the mailing list which is uh because this data model referenced several uh identities and the numeration"
  },
  {
    "startTime": "00:24:00",
    "text": "type defined which are managed by the ana registries so to make it uh this model extensible one question is that uh to remove them into a separate ion management uh match the data model like there are no auto tabs uh we just keep in the common uh models though so we already asked the young doctors about what's the best practice for this for argument that if we make this change so it can fill up update like the metrics and the customer updates so it will be easy to support it without updating the our basic community module but the him also introduced some complexity so we need something for this part so for chair uh doing two stuff here and there's some discussion oh we just post all the questions and then we can yeah i see this issue you are already you know sent to the list and also copied to the young doctor to get a confirmation so we can actually discuss with you and offline and we have two uh proposals on the table one is you can change your numeration into the identity the second actually you define all all these type of definition in the ana module so i think both uh proposal actually works but we need to you know double check a young doctor get their feedback my uh i think we can open the floor to get any feedback for anyone to share your opinion"
  },
  {
    "startTime": "00:26:01",
    "text": "okay uh i see richard asked the question was complexity when decomposed sorry to kind of explain a little bit uh not sure i understand your question so mike richard can you go to the mic richard go ahead i i heard jason want to discuss about this composition he mentioned there could be some potential complexes therefore i was wondering what kind of complex is i think i saw some uh uh a quick comment from druva that there might be complexity i think maybe there's some like a potential uh caveat that people need need to pay attention so what would that be being when you mentioned about profile matrix performance can can have a some complex for example uh for example tcp throughput right a big part of configuration would be specified which tcp model so they're all kind of issues so what oh okay so therefore i'm listening to see okay i i i saw some comments by matt as well but i want to hear from you as well jensen go ahead okay yeah actually the yeah the complexity see a part yeah i mean what isn't getting to to get the feedback from the the younger doctors because i see some uh some documents uh some yamamoto purpose document will integrate the ana management into the single"
  },
  {
    "startTime": "00:28:01",
    "text": "mother but something will separate them yeah i'm not sure what's the best practice okay i'll i'll take it until the meaning is to this house a bit more thank you okay so yeah we can we can move this uh the more detailed discussion to the main list and uh i just uh post some other uh questions here yeah so one other questions about yeah because a lot of parameters can be configured for the auto information generation but we need some principles for so which one should be defined in the standard basic module and which one should just delegate to the algorithm not to be the common parameters like i see some uh one uh be suggested by the base particles and also the f6m9 symptomizing knight but yeah for example the east coast magnitude configures the different two pids and i also probably have some parameters to point out what's granularity for each network map and cosmic and also probably have some plan-specific computing to define the the information resource level access control so which client can request this uh resource and which can come out it can be detached by the current ip or some some other metadata from the client so"
  },
  {
    "startTime": "00:30:01",
    "text": "i think we need to achieve some principles so which one is to include in the in this data model and which means not in the scope should be moved to the algorithmic tension so uh jason go back to the question sure yeah do we have a standard algorithm we can leverage it now what do you mean standard like algorithm actually this is a module i'm not trying to define any algorithm so acronym should not be in the scope of the data model actually algorithm should always be some kind of extension okay maybe i'm misunderstood i think we can focus on you know a basic parameter that has already been specified specified by auto based protocol and we can stick to the basic set you know yes do you have some comment uh so do you want to speak yeah maybe you move to the next one how do you have it how many slides do you have yeah actually i just prepared the the first three simple discus questions so most discussions come to try to move to their main list so you"
  },
  {
    "startTime": "00:32:01",
    "text": "can define more details and this three one i think it can be finished in the meetings so another discussion about the yeah so far you can see the other requirements as for the also servers so we don't have any comments for the auto client side but actually in the initial versions we also mentioned that yeah we're trying to include some include the auto client in the scope of this document because the proper point parents using the auto client also do some uh to need some oem uh for example we need to configure the the caching management the server discovery part and if the house client can access the multiple uh auto servers i also need some measurements for which one to be choice so but i think uh the om for the auto client should also be important but one thing uh i'm not sure is that if the yamamoto is a good approach to expand for the clan oem okay uh any comments for this question i say martin uh martin duke google um so i think you're asking the right questions here um but i think chin's advice is good um you should strive to reduce the scope of"
  },
  {
    "startTime": "00:34:02",
    "text": "this wherever you can um and if no one is willing to speak up for any of these uh particular features you should probably just omit them make sure that they're extensible to support later but um uh i mean like i said if someone wants to speak up for any for this or for any of the other features that's great but otherwise just leave it out thanks okay thanks for coming rachel i think martin gave a very good reach idiom from yeah so uh martin keep a wonderful comments and very good suggestions uh i i do want to but uh somehow i i do i think uh the issue of how to configure auto clients it's an interesting issue because that's an issue uh that we encountered during uh yeah changing yourself right and we stored it to configure use it right for user download command and a huge amount of back and forth about how to configure the the client and do we do using command line how do we use computer file uh what kind of primary do we configure they're clearly uh they are application specific they're all different culture right really essentially command line from cern so they have different suggestions so uh i think marketing suggestions is great but maybe there's some way to tell people uh exactly how uh i think uh you will mention the consistency across different young modules and maybe here we can also subscribe to people for different uh auto clients for example you know ruseo or we're working on some other applications as well and what would be some common ways to configure auto client can be a very interesting way to move forward yeah i also think yeah"
  },
  {
    "startTime": "00:36:00",
    "text": "it's very important yeah yeah i tend to agree with uh richer actually otherwise for normal client without auto protocol support can discover the auto server you know there's no way to do this you need some configuration for auto client i say uh joe and hi so one query which i had for the auto working group to also guide us is whether the current auto clients which are envisioned do they already support yang based interfaces for om techniques is if that is not the case even if we write a yang model the issue would be that yang model may not get deployed because these are the kind of client client devices that do not use rescon for like the typical techniques that we have for young models so this part was not very clear to me so i would be looking for more feedback from like you know people who are developing also clients to give us that feedback as well yeah that's a very good uh point yeah that's also my concern because uh yeah for my own experience so far we are not using the yam mode to develop the client because some applications uh that try to use their level is the auto server the auto pro code but you not use the red comp uh netcom to be because the the um high level application now they [Music] some application for the network devices are the controllers awesome i think so they are not using the their modules to"
  },
  {
    "startTime": "00:38:02",
    "text": "match their applications so the clients also now use the yamamoto server but probably some other applications will use yamamoto so i'm not sure also read this question today mainly to today working group to say if other people have seen comments on this and i think med also mentioned that on the chat it doesn't hurt us to create an alto client yang model like you know it will act as sort of an information model for even if somebody wants to use some other techniques but this will be the common data that any auto client must use so sort of using yang as an info model that we have standardized but it's okay but like you know we would need more feedback from the working group so that we can do the right thing yeah i agree okay so jody do you have a clear comment actually we run on time for this topic hi uh jordy from qualcomm yeah there was a conversation just a couple days with alberto and fabio and also the idea of um uh you know how do we not impose modifying the application uh to integrate with an auto client potentially providing like a proxy so that you don't have to modify the application basically so that the auto client would run in a proxy or and then there's also conversations on edge computing um for instance law balancing so um presentations at competing aware networking and so on um about performing load balancing and so the load balancer that decides how to steer traffic in the edge cloud uh could benefit from from an auto client uh implementation so those are a couple of use cases um that um you know it's worth uh asking whether this would require some kind of a"
  },
  {
    "startTime": "00:40:02",
    "text": "specific use case whether it's a proxy or an lb that could benefit from from you know uh interaction with an autoclient uh basically so thanks okay thanks that's dirty with our good input so jason you finish your slides yeah so that's just uh some proposal to update the milestones yeah i think we already integrated into the slide yeah so try to okay make the means yeah vector the next item thinking and it's ready for that reviews by the december yeah because thanks everyone and you can give any feedback on many cities how open issue in the github yeah thank you okay so for your request to adoption call actually we see a lot of interesting for this work and you guys make a lot of good progress and we see actually maybe we can you know initiate an adoption call after this meeting so in a room if anybody have some objection please speak up and otherwise we will proceed okay thanks jason okay please stop sharing so next topic is ronan take away yay hello everybody uh the next slides are about uh aldo transport uh and the draft is in a nutshell covering the topic how http 2 and alto"
  },
  {
    "startTime": "00:42:02",
    "text": "can be combined and work together the work was done with richard kai and jensen here and yeah my name is olan shot and i will do the presentation today i hope you can hear me because i have the mic here and have the mask uh on but if there's no complaint i will do it in that way okay then next slide please so as i state the motivation and requirements uh is that hd poet 2 at the moment is not usable or not used for alto and this work tries to give the proposal how this could be established and how it could works and we want to introduce this idea the ideas that we have and then have a discussion regarding this the next slide so uh just to regulate recapitulate what is the status also based on the base rfcs and we have here also rc 8895 which already has introduced a server sent event mechanism sse and we can see it here on the right hand side the ultra sse example but unfortunately this mechanism is only available with for http uh one and um the isg review has considered to make a proposal how hdb2 can work and the idea is in a way to use what's already defined in all the sse but make it available also with http 2. okay um so before going into the details just a double check to the requirements for sure we have also collected uh the requirements from the protocol so and client can have an auto resource connection as it is defined in fc 7285 and then all the requirements from all"
  },
  {
    "startTime": "00:44:02",
    "text": "the sse for example start incremental update stop an incremental update of the research and signaling all of this stuff and for sure have also ensured that the communication between server and client works well and then from the auto base framework yeah for sure using http we propose only to use the element number of verbs and now comes the http design the push promise mechanism that in a way will improve the transport of the optimization of the communication between the server and the client and last but not least there was also the idea to have some kind of capability negotiation but when we go to the next slide so at the moment our work no no our cover work covers these requirements so uh zero to six and uh the flexible deployment that's at the moment covered in our work so now we come to the design overview and the idea how to uh make it workable next slide please so um when now uh going into this slide you can see here above from there also the current uh possibilities of the alto server we have uh information resources sources we can have static resources like a network map but and also filterable resources like cost map so this is the basic all the functionality and we have also the goal that we have a single http connection between client and the aldo server which tries to be addressed here with this h2dp connection overview and the ambition is not to change here things and have also the ambition to keep the http"
  },
  {
    "startTime": "00:46:01",
    "text": "2 protocol as it is and then the idea is to have here some kind of intermediate layer between the alto and http 2 that allows the server to use the http 2 connection and the idea is to make the auto sse mechanism available for http 2 and we introduced or makes a proposal or the introduction of the idea of transport queue so it is shown here in the uh picture and by uh we are in a way implementing this transport queue in the in this information model we have uh also an yeah let's say an incremental update skew and uh receiver set information that is automatically created with transport queue is established so various clients can connect to different uh yeah let's say 10 transport queues and one client could also connect to different transport queues to get the different information i i hope that is clear and now we will describe how this will work then in principle but before doing this the information structure so client options connection to the server the client ops that identifies the transfer tuite itself and then in principle the client has mainly read capabilities and requests for the status for example of the transport queue the element method the element in the message queue becomes a receiver the client receives push updates from the server and the client has a capability to close a transport queue or to close the connection okay next slide then and now we are showing how the transport"
  },
  {
    "startTime": "00:48:01",
    "text": "queue is established so the basic operations here we have here create read and delete operations and similar to the older sse we have here a method in a way to to create here uh accurate response of the server so the client creates the the the queue by sending a q request and the server responds with the information of the transport queue and this is more or less the json text that's used next slide how does it looks like so the server request here you have your post information and uh to uh the passes uh the transport queue that where the information of the server could be pushed to the client and the server responds us here with establishment of the transport queue to the to the client this was um already stated then we have also as stated here the client reads uh uh um possibility but also uh explicitly a delete of the transferred clue queue so the deletion of the transport queue is mainly also from the view of the client so if other clients are connected to the transport users transport you as itself cannot be a delete because there are some dependencies so the transfer for client is and feral and um in case the client deletes it so from the client view he cannot expect that this transport queue is still valid so the client has also the possibility to delete let's go then the next slide will show the read option of the transcript queue could you please go to the next slide so here transport queue example read"
  },
  {
    "startTime": "00:50:02",
    "text": "so uh when the transfer queue is um established then the client has here the information of the appropriate transport queue sends information to the server and the server response for example here with incremental update queues and the server set and then we have here some sequence numbers with let's say some tech ideas and as shown before in the picture we have some relationship between the transport queue and the the dedicated stream tags the next slide um incremental updates cue how this works then looking into this again it's important to know that the incremental aptitude basic operation is only a read operation so the client cannot create update or leak incremental updates queue directly it's associated with the transport queue automatically as uh i stated and if there is a request for example to a dedicated transport queue we have here also uh the link of the transport queue and then the dedicated uh for example information that's then uh forwarded to uh to the client um this is related to our requirements that we have stated here and yeah that is how the incremental update works so next slide individual updates so here we have the pull read push read important if you have now a client pull so with the get information and update uh the ue and this looks like followed well next slide please yeah so we have"
  },
  {
    "startTime": "00:52:01",
    "text": "here again the client pool with the path and uh then it's rca associated here the information for example a cost map that is then pulled down to the to the client the normal alter information one can say let's need it then the server push yes and now it becomes to the to the in interesting thing and the relationship also to http to what's a little bit tricky so the server push uh is uh though the client needs to to have an information more or less on which yeah away the server push the information and we use as mentioned earlier the push promise mechanism and um yeah and how this is established that's shown in the uh next slide so you can move this so um the server push and as an authentication example as phone for we have here the sequence number and the dedicated text so if the client has no match it chooses let's say the first entry and if the client has already some matching criteria it chooses the next uh next in for the next number and then now going to the push prompt mechanism of http 2 for example when the server push for example in a dedicated stream and hear the information in each stream then the relevant information us is auto solver sn pushed down towards the client now let's say then therefore the client knows in which queue or where the integrated update happens and then also receive a set information how it is yeah sweet get status delete yeah for sure the client uh in case has"
  },
  {
    "startTime": "00:54:00",
    "text": "the opportunity to delete also the transport queue but in case also connection is not available then from the point of view of the client the transfer is also closed yeah then next slide stream management is also important how is now all the stuff it was more or less the the intermediate layer between the alto and http 2 but we have also a relationship how stream management is done the objectives are here to allow concurrency of the streams to reduce latency reducing minimum numbers of streams etc is more or less a goal of http 2 and here is now shown the relationship between the frame layout and headers without so important thing is that we use something like a stream id and the stream id is then written down in the stream identifier or in the steam dependency if we create a transport queue for the steam dependency is zero because nothing is there before let's go please to the next slide and yeah for sure if you close transport queue it must be sure that there is no steam dependency and then also the relevant information is written down and yeah in the fields are properly yeah and close transport queue and then for example it's uh if you have here just an request or wanted to to read something then the uh stream id is also written down and then for sure as long as something is streamed and the steam dependency is not zero and the identifier is written down and same thing with the promised stream id so this is then the consequence of the"
  },
  {
    "startTime": "00:56:00",
    "text": "concept that this needs to be worked together yeah i think this is a setting max of concurrent streams this is some detail each push needs to open a new stream and steam transport queue i think that we can omit this slide and go to the next one then please and yeah and then we now come to discussion discussion and open points and yeah open point is what is missing yeah so we do not create generic message or that does not allow uh creation of message to and the client cannot publish info shared with other clients so that is something so we have not the ability to have a direct exchange or things there we are also aware of the broker discussion that has done so we haven't looked so in the details but these are also options that can be discussed yeah and then uh the capability of negligation we have as mentioned earlier this occurrence is not addressed in the draft next slide and also calendar semantics is not addressed yeah and that's it now we can discuss or get your feedback okay thanks ronan actually a good presentation so uh actually i have some comments on the slides actually so in the page 25 is any out of order delivery issue for streaming management is there are you know i see no no no issues do i can you go 25."
  },
  {
    "startTime": "00:58:10",
    "text": "25 it was 25 gin all right yeah 25 35 25 25 next one okay objectives so uh do you do what was the question do you see any uh issues regarding this i'm just wondering because you for stream you have dependency so it enforces that such kind of dependence among streams so when you send a stream is any out of order other order delivery issues yeah and this is done we can answer the question yeah yeah you can but but this is this is mandatory but yeah yeah i i i would like to answer this question because this is excellent and uh okay so the uh yes so there are a lot of streams running going on right inside this system because that's really the purpose of using hdb2 for streaming concurrency uh for example a from the design of course the newest version has not been posted and all the details of course are only posted on on deck of slate uh we were very careful that there will be no out of order delivery and of course we need to go over a very formal proof but let me just give you a sense about why we don't have uh auto order uh delivery for example the main main thing which we're trying to push through using the new transport is to send increment updates there are actually multiple mechanisms to make sure that we don't have other uh delivery of the income updates and number one is that all the push promise push promise they are only sent into a single stream which is a stream which is"
  },
  {
    "startTime": "01:00:00",
    "text": "open for this particular uh transport queue so therefore because if you're inside a single stream and you're carried by by tcp and all the packets inside the single uh stream will be delivered in order by tcp so therefore all the project promises one by one will be sent uh to the client in order so therefore if the client will process all the promise in order and therefore the client actually can know for example uh put the prime minister six and eight and twenty they're all sending other and so therefore the client can know the order of the the income that's therefore they're safe and number two uh there's also building a mechanism and to assign a sequential uh sequence number to the incoming updates so therefore the client actually can check into it so therefore the client can really do it in the transfer layer using stream or can also go to application layer uh to yield the second number so there are two ways to protect they they are the other delivery so therefore i think uh that's an example because that's the main part we we are sure but of course we want to even try to write down some kind of formal proof that there will be no out of delivery in terms of uh the the requirement of course otherwise actually we want to maximize also all the delivery as long as there's no dependency okay so uh another question actually i want to make sure make sure uh the auto neutral spot doesn't require uh you know uh extension to the existing http protocols is that right yes uh and so john can also answer right of course i think uh from from the way we design is we make sure we only use uh the the central hb2 uh uh capabilities of course we are using the assignment right for example here jordan show this particular figure and and we're trying to use http 2 capabilities for example how to assign the stream dependencies and how to how to assign the identifiers"
  },
  {
    "startTime": "01:02:01",
    "text": "and so on and how to assign which request to which streams to maximize the leverage of the capability for example also assign for example wheat to really allow some kind of scheduling but everything capabilities will be inside uh db2 of course the api need to be a little more careful when the client or the server any product client is using http 2 because the api should really allow the application the kind of specifics okay for this request send to this particular stream for this one please send to this stream and then of course the server also need to be confirmed in the sense that server should pick the right uh when they when they send the the request i think it must be confirming as well so if a server must send the the the packs into the right stream otherwise we don't really need any modification of http2 i think that was the requirement okay uh last question from me actually is you know for auto portal you define four functionality transfer queue incremental updater uh request and also receiver said so for all these four functionalities will be mandatory or somehow just optional uh okay so given that i i'm on the queue already they are all necessary to really get incremental push updates but if you don't want incremental push updates uh for example in the initial request when the increment updates increment updates flag is set to be false which is uh two in which it can be by default like the true but of course you can make it a false and then the increment updates feature will be turned off so therefore basically there's no increments so therefore if application only wants to provide a way uh to uh provide this uh insight to the large scope deployment to show that there are large number of clients watching and you can turn off increment updates but now the client can only see the queue"
  },
  {
    "startTime": "01:04:04",
    "text": "okay thank you so any other comments from the floor so ronald you have already completed your slides i see you have some open issues you haven't discussed or you finished the issues we need to address these open issues at the moment i cannot say when it is finished we also need to check exp especially in the capability initiation how this works so we we at the beginning here in the analyzing how to solve this okay so giving the time limit actually i think maybe we can move on and for some other issue we can take it to the list and we can decide how to move this work forward so so we can we can bring this into this draft or we can separate it and do in a separate work the the open issues because i i think the main issues regarding the transport and http 2 are already addressed here in this draft i think the mandatory things are the main things are already addressed and described okay so let's uh uh for always you take take it to the list and we can see how do you yeah yeah yeah i i i it's also for me i'm quite open but uh potentially it would make sense to split some some work but let's do it discuss on the list i uh both ways are possible yeah"
  },
  {
    "startTime": "01:06:00",
    "text": "so richard do you have any comments yeah i do want to get one question quickly and given that we have other people here is this design is very very http 2 specific and the guidance i think roland and i and with this design team with this cast is uh how much do we should we consider essential https three like a quick any guidance and oh we should really just get this one down and focusing on http 2 because quick somehow iq3 will open a total different way for example all these stream assignments somehow or just like a dependency they're all quite quite http http 2 specific so any guidance from the working group to us my suggestion is to get hdb to solid and then we can make experimental on quake so might be echo there it is okay walking into the queue i guess um hp3's application interface should be very similar to http2 um so i'm a little surprised that it requires a lot of re-engineering to to update i mean can you say more about it uh so uh martin for example i believe uh for ours this one uh we are for example if you look at this current slide uh it is depends on for example all these are blocking for example all the streams because fundamentally everything will be underlying there's a single tcp stream running right because we interleave everything"
  },
  {
    "startTime": "01:08:01",
    "text": "uh it's a single tcp stream because it could be two essentially a single tcp running on on a single tcp so therefore a lot of for example all the other things probably would be very safe and uh so therefore on the client side on the server side you probably don't know what about outdoor delivery at all because tcp enforcing essentially a single stream of course you should have issue of had a height of a line blocking uh in this level even though you interview all the streams and my understanding of quick rgb 3 would be then this kind of highlight blocking will disappear right because they're using essential different udp and you're not going to if there's a single packet loss you're not going to block everything below be behind it so therefore then we we need to really check if that will cause potential issues for us in terms of and this may not be the functionality but i didn't come for performance or design requirement so therefore we they need to investigate to see how what the impact it really is so so so you're concerned that you need order delivery between the streams oh maybe it is buffering and those type of things inside the clan of server set because here we assume a lot of some optimization assuming somehow a packet will be always delivering order because tcp really delivers everything in order even when you interleave different streams yeah so my my understanding uh i could be correct here my understanding of http 2 is that hp2 is not even really promising you order delivery between the streams because the protocol could be full controlling the streams differently etc um if it's just a matter of you like thinking about it a little bit um i would encourage you to do that because hp3 is going to be an rfc before this is um if it turns out that you need a bunch more protocol machinery to support http 3 then then that would be a different discussion to have i don't know if i want to make this you know 20 pages longer or something because to support http 3 like maybe it"
  },
  {
    "startTime": "01:10:01",
    "text": "could be a different document but like uh i mean easy for me to say but i would encourage you to like do a little bit of analysis i i don't i'm surprised to to learn that this is potentially a concern and and i would hope it turned would turn out not to be sure sure what will investigate but let us clarify with you so if we deliver this document initially for example by a next ietf and we're mostly very specific to hpd only and we leave the work of looking at the capability or impact of hdb3 to be to be the future work are you happy or our working group happy or that working we would recommend that we should always like initially already start look at until the impact of potential hdpd3 um certainly like uh you know like the the document so first of all it is perfectly fine to like for early versions of the draft to just consider hp2 and like and like consider hp3 later um uh so i would say that that to me the the case where uh we do the analysis it turns out that http 3 does require like a bunch of additional specification i'd be 100 fine with submitting it as is um uh now in in the case where we just do not do the analysis um that would uh i would not like that i would have to think about whether that would be like unacceptable um"
  },
  {
    "startTime": "01:12:02",
    "text": "uh my inclination would say that i would probably grudgingly accept something where we'd just not done the analysis but um that seems uh it seems like just something to do like in my opinion that's kind of a due diligence thing to do um but but again like i don't i don't know if i want to put the full force of my id role behind that assertion as an individual i would say that let's say for now is that does that make sense yeah i think it makes sense to me because uh right because your land is essentially where guy yelling is guiding the most thing we're focusing on b2 y'all then what do you think we need to go to queue so so uh when we just this this uh discussed this uh the main motivation was to focus on http 2 because uh it was mandatory and it was a quick way forward and so we didn't focus on http not to overload the work so in my opinion the analysis needs to be done too and i am happy to yeah as i said like when we chartered this i was i was offering an assumption that that the upper layers the upper layer interface for hp 2 and 3 were almost identical um and that the value proposition of the application was almost identical and that there should not be a bunch more design if that turns out to be untrue then i'm i'm 100 comfortable just shipping this as an http 2 rfc and like maybe if there's the then later doing it for h3 separately but again my my initial guess coming in is that that is actually not the case and that it is essentially the same mapping but i could be proven wrong thanks the other question any other question okay thanks everyone yeah"
  },
  {
    "startTime": "01:14:01",
    "text": "thank you i think no yeah thanks mona let's move on to the next topic i think it's jody and kai you will join present um okay jody i think you can take away yep hi um yeah i'm jordy from qualcomm and um this one and this is kai from central university yeah so kai and i are actually going to be talking about the alto code base project and um so i'm going to start and nkai is going to take over yes actually yeah okay yeah um because most of you are familiar so i'm gonna sort of script through even though the slide deck is self-contained so because it's gonna be offline so people can actually take a look at the slide deck and sort of uh think of this as a self-contained uh deck but mostly i'm going to skip through this slide here to begin with and what i'll say to i guess is that um you know we we came to the realization that um to help alto get some visibility and actually uh uh adoption basically that there is a need to"
  },
  {
    "startTime": "01:16:00",
    "text": "uh to have a code base for alto actually there's already codebase and there's an open auto project that kai and jensen and others have actually been leading um they need to bring it up to speed um and actually have sort of a a community to help sort of drive that development and the reason we think this is relevant is because we think that um you know visibility network visibility is very important for the kind of applications we we're looking at at these days uh and alto provides a key component for that visibility specifically in applications like edge computing for instance so we're going to be talking about that secondly but um yeah and many others actually not just edge computing but many others really you think about um how do we get application performance is really three components visibility intelligence and controllability and so with um so much going on controllability and and so much effort you know we think visibility is lagging behind so without uh proper visibility it's very hard to do control and and then sort of make intelligent decisions so that's what this is sort of about in this case to help out to get some visibility to running code uh and trying to bring the community together there are actually several efforts already going on with different vendors but it's sort of fragmented and um because we're going to be looking at um many different kinds of networks and we think that uh you know we can really leverage some networking effects here and sort of uh build that code base so if you look at the alto architecture which you which i'm sure so you understand already you know just um two main building blocks the alpha server and the outdoor client right and so uh there's a northbound api and the southbound api and the service is provided by the alto the visibility services that in between so on the northbound basically you're interfacing with applications so a few examples but uh you can see it some of these are coming from the edge h cloud already so uh you know xr v2x uh iot and then the hackathon demo we put over the weekend was with uh science networks another very interesting use case um and um and"
  },
  {
    "startTime": "01:18:00",
    "text": "ncdms of course historically alto has been very uh predominant on cdns and and originally back to the original days on p2p but as you can see the applications are evolving sort of the need to have this visibility and on this new landscape basically but in the southbound we're looking at actually multi-domain networks right so many different components and um with the conversions of the edge and uh and the ip together the wireless and the nd and the and the core ip at the edge uh it's uh on the edge computing side this is a it's about the main problem really so going expanding from data centers which are in the core but also in the edge and then once the backhaul mid call throne hall ran mobile core multi-domain so this sort of landscape tells us that you know we could really leverage uh by sort of bringing some code base together and not having to reinvent the wheel you know developing plug-ins for different sdn controllers uh and same provide run some code reference for the application side and so on and so forth so the effort here decide to sort of leverage uh all these um efforts to sort of uh not having to reinvent the wheel um yeah so let's talk then uh then how does that map actually so again a different view but the same picture essentially so um yeah so again northbound api certain api and then we're looking at building some open uh so uh open sourcing some of uh some uh some of these components here building some open uh some components here that would allow to avoid having to develop this over and over where value is really being created is at the at the core here but uh and then you have the software api plugins to interface with the various various sdn controllers uh so over the weekend we demonstrated integration with mini net but also openout already integrates with opendaylight but of course uh there's a need to sort of integrate more with more com sdn controllers to help uh adoption of the standard right"
  },
  {
    "startTime": "01:20:00",
    "text": "uh the same thing for the itf uh sorry for the alto client side and then uh you know you could have you would have the the the apis uh potentially being open uh and then but then vendors could also develop their own components within these okay i want to talk a little bit about um if i hand it over to kai about how do we envision this happening um basically so uh within that uh the hackathon actually provide a sort of a good uh good mechanism here so we're looking at um you know the autocode based project ends up providing a parallel track to the the working groups standardization effort towards implementing the features introducing the are in the latest rfcs that's one but then uh you know the idf hackathons uh we intend to use them as three checkpoints a year for us to test interoperability test the the sort of the new features and and demonstrate them and socialize them and get feedback uh basically on running code so uh and the the focus of this effort is also gonna be on really on production use cases right so uh really applications that are already running and how can we help them by bringing more visibility like the one we had over the weekend with uh science and traffic with rusio uh and so on so yeah i divine build production open source environments for use cases and deployment and sort of follow like the lena startup approach where you know really and then driving this by you know use cases are meaningful um many of you here actually have use cases that are relevant we want to know about them and uh and then what we plan to do is you know starting next week from the hackathon we're going to regroup and then collect all the feedback from this week uh look at all the possible use cases and select maybe one or two and work for them for the next hackathon basically so uh and we're gonna continue to do this as we continue to build a code base as well right so"
  },
  {
    "startTime": "01:22:02",
    "text": "uh three checkpoints and in between you can you know you you know there's a time period here of two three weeks where we are going to be opening in the outer working group suggestions we're already getting some suggestions on which features which are uh which use cases are important and then psyc one and then aim at demonstration in the next hackathon as we uh continue to build that that code base okay uh yeah so basically you know i don't have to go through the whole thing here but we are invoking the community for participation uh and then this is actually gonna be we're driving this through there's a lot of interest from the students actually to participate and this this is a big thank you to richard yang professor young and professor kai uh you know uh from yale university and sinchon university and and and then uh for for bringing the students it was actually very good experience for the past month you know working with them so we envisioned these two roles developers and mentors mentors are usually experienced people from the ietf work uh auto working group um basically and then developers are usually coming from universities students uh that are interested in learning uh you know and on interesting production production use cases and then real you know something that's really uh really running on a standard uh we think it can be really good a learning experience and so uh today we have you know two three universities already participating but we also call for you know other universities other universities that might be interested in participating so you know uh we are already potentially discussing with maybe upc and other universities we really want to make this also sort of comprehensive in terms of uh people who might want to participate um yeah project resources so we're gonna you know leverage uh github some of the new features for scam management if you will and uh yeah that's an example of the the dashboard that the the scrum dashboard that we use for the hackathon this is now completed basically next week we're gonna be sort of moving on to the next"
  },
  {
    "startTime": "01:24:00",
    "text": "one uh yeah so at this point kai do you want to take over yup thank you jordy uh so carry on hear me yeah okay okay sounds good so uh so uh so after this introduction i'll give some update on the auto deployment and also the state status of the cloud base and also the demo that we did in uh during the itf hex so next page please so as part of the chatter item we're actually collecting information about existing employment using auto and we have the wiki on the itf webpage which collects a list of implementations and we also uh there are some widely known deployments that we already see from the previous auto working group presenting in 2008 the comcast and other vendors actually connect very few uh a relatively large scale a few tests to for the p4p protocol which is uh kind of a predecessor of the auto protocol and then we also have the binox deployment with dash telecom i think roughly starts around 2017 and has been running for uh several years and uh they also use auto as one of the northbound apis and uh we are also working with telefonica to use auto for their cdn deployments and i think from the deployment we actually see there's actually a shift from for the work use cases so previously is mostly about the p2p traffic and right now it's shifting to a cdn traffic and we uh we're also working with russo and also the pacific research platform and they are providing use cases such as 5g and"
  },
  {
    "startTime": "01:26:01",
    "text": "i think they also mention like network slicing using techniques such as srv6 so well uh so we believe like the five uh five shooting techniques and also uh the large scale data management could be the next use cases that where auto can play an important role so next page please okay so uh so right now i'll be talking about uh the the hacksaw that we did for the itf 113 and here is basically a summary of the demo so we are using minute to simulate a network and all the applications are actually running real software using specifically in containers and the demo environment is packed as multiple containers for future enhancement basically uh so jensen is doing most of the work and we have the the doctors will be made available available through the ietf hacksaw on github and so uh what we did during the icf hacksaw is actually we uh demonstrate the capabilities of auto to select uh like uh to give cost information between uh deep sources and a single client so that basically enables the source selection based on the network map and cost map and we also compute two types of costs so this will be based on the new document basically the performance metrics and we are able to uh basically provide two metrics but well we'll give the details later and then for the hacksaw we actually uh conduct some development and a new library written python is provided so that people can use these libraries uh to fulfill for for future development and also we uh we add the auto-based replica"
  },
  {
    "startTime": "01:28:01",
    "text": "selection support in the lucio scientific data management system so next page please so for people who are not familiar with the russia develop data management system uh here's basically introduction so the russell data management system is used by lhc-1 which is also part of us we used to host the data generated by the student project and the data will be actually spanned across multiple projects including cms and also atlas so this large-scale physical experiments and what we did is we modified the auto the lucio a client code and we uh basically previously the russo client code enables the clients to select replicas based on for example random order or using uh dual uh location information and what we did in the hack zone is to enable basically to integrate auto in basic integrated auto client with a lucio code and then we allow the russo client to select information collected by the auto okay so next page please and the hack during the hexon we actually uh implement functionalities from these three uh drafts so for the base protocol we actually use the network map and course map and for the flow based course query so this these two are individual documents and we actually implement a flow code service so that uh we can express uh not only the cross product between source synthesization but in a more fine-grained way and also we implement two metrics in the auto performance cosmetic document so next page piece"
  },
  {
    "startTime": "01:30:00",
    "text": "so here is a summary of what is achieved during the hacksaw so we have uh like we said before we had a client library in python and then we uh integrate autoclient with a certain russo replica download command and we also uh we plan for three demos and we were able to achieve two of them and also the third one is still partially uh partially completed and we are still working and hopefully to get working before the next hacksaw and then we also have some saucepan auto integration with sdn so um and during the process we're actually using uh what jordy has mentioned before that we're using the scrum board to basically keep the software management yep so next page please and here is basically the two other measures that we implement during the hacksaw so what the the one the first is actually the one-way delay uh metric and the second is available bandwidth so next page piece and so here is a list of the docker images that we used during the uh as the test environment so some of the containers are provided by the lucio uh project so the uh for example uh the lucio container basically is where the client is located and then we have the uh xrd uh container basically that's where the data are stored and then we have the auto the audio container which is used to generate the auto maps so next page please and so here is actually some screenshots for the demo first we were using"
  },
  {
    "startTime": "01:32:01",
    "text": "the container nets uh basically canadian is a container that enables the containers to be connected to a virtual network so here we use containers to construct a network looks like this and then from this network we actually construct to all the resources the first is auto natural map and for the natural map we actually group the uh host based on the access link and then uh we collect bandwidth information between the hosts as the auto cost and provided through the out of course map and the the third step is we actually uh uh by invoking the by passing the the address of the auto course map to the russo uh command which we have modified to integrate the auto capabilities and then it enables the sorting of the replicas based on all the information and because we are using bandwidth so actually this uh the sorting order is from the largest bandwidth to the smallest and then we were able to select the one with the highest bandwidth in the in this demo so next page please and here is the results that we get when we basically use as flow as the monitor and i think the the first the figure on the left basically shows when we randomly select a replica and the maximum balance with uh perfect gain is about four to five times higher so next page please and then in this figure obviously we are doing the same selection process except that we're using a different matrix and we're not using the bandwidth information by using the latency and for latency basically the sorting orders will be slightly different and also in"
  },
  {
    "startTime": "01:34:01",
    "text": "increasing order so we select the one with the smallest one-way latency and then uh but but for this use case actually because of downloading is mostly determined by the bandwidth so when we use the latency selection uh it does not give the best performance but actually but but it still shows that we enable the capability of like exposing this network from providing this network visibility to the rucio client so let's page please and uh here is uh what we're doing for demo2 so we're actually providing uh the multiple uh throughput prediction for multiple flows and uh here the screen basically we're using uh two we're initializing like multiple flows downloading uh downloading requirements and then uh we used a prediction uh through multiplication based on the uh uh basically network utility maximization model and uh we already modified the auto interfaces to support the flow core service so that the cost would not be provided for the prosta the cross-product of sources and destinations but for more fine-grained approaches and this is actually uh proposed in one of the individual drafts which we are pushing for to become a working group document so next specialist and uh what is not a fully achieved during the hacksaw is the third drama is to so in the in the demo one we're actually starting a download for a single client and uh in practice what is what usually happens is where there actually are multiple concurrent downloads and for multiple congruent dentals choosing the"
  },
  {
    "startTime": "01:36:00",
    "text": "one with the maximum bandwidth may not be the optimal solution and what we're trying to demonstrate in this demo is that maybe we can we can average the information provided in demo too basically the super prediction when there are concrete uh tcp flows uh and so for demo three we're actually trying to uh developing basically to integrate the multiple uh flow throughput prediction capability into the russell clan but this is uh not fully uh completely and we look we are hoping to get this demo down in the next item hack song and then we can maybe get also uh have like further demonstrations about how it can improve the performance so let's start please yep i think this is this is and so i'll give the floor back to you charlie yeah yeah i guess any questions but before uh yeah i just wanted to also say thank you because uh you know there's a lot of people actually who worked endless hours for the last 10 days actually it has been like a couple of months planning and so on but the last 10 days you know i should really say thank you because people say three time zones and it's the same late night so thank you all everyone for the adaptations and hard work uh yeah so any any questions on these yeah martin duke google thanks this is very interesting and and pretty impressive um um it was it was nice to see like three different drafts incorporated in this work that kai presented um and i seem to recall cern having deployed some stuff here so is is russio the service that already had alto so is this is the diff here"
  },
  {
    "startTime": "01:38:01",
    "text": "from 7285 to adding the additional drafts or is there or is that a completely different thing so um i think this is a a new thing uh richard might have more historical background we will have some yeah richard actually yeah so uh martin could clarify uh this code and 7285 and all the stuff they're part of rules already so of course they really need to finalize and do all unit has and so on so but overall let me just clarify that russo is the the data management system for search and for audio items and so on and the workflow actually is complex so a workflow typically what using their terminology i don't know if there are any like uh uh uh uh certain people uh or rules of people here doing a call here but of course they can ask him to clarify and we're mostly working with uh uh the project lead and martin and and mario uh lesnik and they are the project leads of the russo team and there's also radhu who's the transfer lead so therefore they they guided us about the integration of auto and with the rule the system and for the user at high level there are two workloads what they call and one workload is called the manual workload which basically means uh whenever a client for example when they download the file they won't really do analysis and they would start something called a user download and that part actually worked out so this part of code actually is already in the system they probably hopefully we can get fully deployed onto the drupal system and soon and all the code i think we went through the old review last week so hopefully this will really become part of rusev and but actually the main main work main workload is what they call the automatic uh workload which is automatically replication of all the data into all kinds of sites that part of code to do the integration need to modify their database schema which is tricky so we are hoping"
  },
  {
    "startTime": "01:40:01",
    "text": "that we can really like hammer down the details with them for next week and then we can start really modify the database schema and integrate into the total uh uh the total automated workload so therefore then we can claim that we have a full integration of the both auto this moment mostly is for the manual uh workflow which is actually a smaller part of total workload i don't know if that's clarified or not yeah that was an interesting clarification but i'm not but but my actual question was prior to this project did rusio have any ulta support at all no it doesn't okay so it all right so because at one time i remember having explained to me that cern had some sort of alto deployment is that a different tool so there's a deployment and we're working with the es net and the pacific research platform okay ronaldo yet but on something called grading graph which um is something i'm actually going to present in a couple minutes uh i don't know if that's a reference that you were connected science networks with and we're actually gonna be working with packaging that into alto and deploying that at esnet prp uh and starting with prp i should say and then people into potentially es net and then yeah and then so certain there's a lot of synergies because this as you know it's uh all neighbors are connected so yeah yeah okay thanks all right i'll wait for that then yeah cool okay uh i think so thanks jody thanks uh uh kai and uh you did a very good job for uh hacksaw actually build the code basis is very important for auto let's uh move to the next topic so give the time and limit i i want to suggest maybe jodi you may only have 15 minutes for this topic"
  },
  {
    "startTime": "01:42:01",
    "text": "um play okay sorry about that baltimore's lecture advance in auto requirements right here use casino requirements sorry and uh yeah so um let's get through this but um you know this is work actually coming from research uh there's a couple of papers we publish at sigmatrix and sitcom and then uh you know uh professor richard yang nine months ago about nine months ago and reached out to us you know saying you know hey this is interesting maybe could we uh discuss putting this in into the alto uh work basically so first of all thank you to uh richard uh for reaching out and that's been very interesting in nine months i guess since then and uh yeah and thank you everyone for the coaching actually and the guidance uh from the you know from everyone at the outworking group really um so um but yeah so this is an informational draft um and what we so the details i'm going to skip the leaders of course but if you are more interested you can look into the papers um and the what i'll try to do is to"
  },
  {
    "startTime": "01:44:01",
    "text": "introduce vulnera structures uh briefly and then um we're going to talk about use potential use cases for alton and then requirements um let's see so the the context here i'm going to pick on the congestion control problem say so the congest the conventional v on on congestion control basically for the last 30 years is this um idea that the performance of a flow is uniquely determined by its bottleneck link right so this comes from jacobson's paper back in 1988 that literally saved the internet from congestion collapse basically by inventing the first congestion control algorithm and this is a true statement right i mean the the performance of a flow it is uh determined by its bottleneck link right but while this is a true statement with um we realize that there is a much more sort of fundamental or intricate um um element going going on in a communication network the analogy here is uh with an iceberg if a communication network where an iceberg the notion that the flow uh the performance will flow is uniquely determined by its bottom egg lean would be the tip of the iceberg underneath what the submerged part is what we call the bond mecha structure which really reveals system-wide performance and how flows and bottleneck links relate to each other and the forces that they exert on each other basically so let's see how that works i'm gonna just put a very simple example to see if we can capture the idea um and and what's the relationship with alto basically because we're going to show that bonding structures are a very compact way to sort of uh summarize the state of the network that takes um that includes topology routing and flow information in a single d graph and that actually allows you to quantify things and compute derivatives on the network so it's a it's um it's a way to sort of capture the state of network that applications could potentially leverage so let's take as an example this network so links are circles so there are four links link one through link four each one with a different capacity flows are lines each one with a different color so there are six flows and i'm going to skip"
  },
  {
    "startTime": "01:46:01",
    "text": "forward and just show you what's the bottleneck structure so this is the bottom like structure of this network basically and then how do we read a bottlenecker structure so a bonding structure is read as follows links and flows are vertices in the graph so for every flow and for everything we have a vertex in the graph if there is a directed edge from a link to a flow then that flow is bottleneck at that link it instead like for instance flossy is bottlenecked a linguan because there is a directed edge from ling one to flow three if there is a direct attach from a flow to a link then that flow traverses that link that's the relationship so float3 versus link to because there's a direct attach from pro 3 to link two because flow three is bottom like a link one it also master reversal in one therefore there's also this is a bi-directional edge right whenever you're bottleneck you have a directional edge now why this graph is relevant uh is because this graph actually allows us to both qualify and also quantify the forces that flows and bottlenecks exert on each other and reveals a hierarchical structure of the submerged part of that iceberg that tells us how how to drive system-wide performance if you want to know how this graph is it can be computed uh you can be computed in polynomial time uh you can actually compute a you know um this graph for a us-wide network in a fraction of a second so this is kind of the algorithms are highly scalable and that's some point but basically i'm gonna sort of talk about a couple of concepts only uh one is um that the fact that this graph reveals how perturbations on a network propagate uh through the system basically the ripple effects suppose that there's a perturbation on a link what that means that could be several things for instance if it's a wireless link could be the signal to noise ratio is changing so what the graph tells us that if there's a perturbation on link two that's gonna have an effect on flows that can be reached from this limb according to the bottleneck structures so this tells us that only these flows here which are reachable that they have a path"
  },
  {
    "startTime": "01:48:01",
    "text": "will be affected by such perturbations but these flows will not be affected because they i cannot go from link two to flow one there is no no path it's broken here and so on so first tells us how things are interconnected um the same applies to flows if there is a perturbation on a flow if i tactic shape or flow that's going to create a ripple effect on the network uh and it tells us how it propagates basically so so far we've been talking about the the sort of the quality the quality of the qualitative aspects of the problem but the other element is that bottleneck structures are actually computational graphs themselves they cannot we can also use them to compute the magnitude of change uh if i if i have a perturbation i can quantify how much the change is uh how much is that going to induce a change on a flow basically and so what is the perturbation perturbation is basically taking a derivative on on the system right so a small like an infinite decimal change on a link or or a flow rate that's going to have an effect that's like taking a derivative so once we have a tool that allows us to compute derivatives that is a tool to help us optimize optimize application performance and that's the connection with alto well microstructures we think that can be a good way to summarize the state of the network and empower applications to make this you know figure out how to do better routing how to do better flow uh traffic shaping or scaling rate limiting for instance for xr applications i mean the reality that you need to sort of encode the rate of your your sender according to the multi-domain uh uh you know available bandwidth sort of uh you could actually use this kind of um um framework so i'm not gonna go into this but it's a tool to also quantify quantify these changes and compute derivatives so um yeah so anyway this notion that can a butterfly in mexico grade a tornado in asia of course the answer is no but everything is interrelated and baldnecker structures tells us how about the you know what's the effect of a butterfly flapping its wings in mexico in china say for instance so uh yeah i'm actually gonna skip through"
  },
  {
    "startTime": "01:50:00",
    "text": "this yeah you know the slide deck is there uh and then it's just gonna sort of jump into yeah so this this just reflects the idea that you can actually compute what we call gradients or derivatives uh using the vulnerable structure and the bone maker structure is think of it as a computational graph so one of the values is that um this allows us to do these calculations very efficiently uh because these are delta calculations on a graph so if you're trying to solve these problems using lp rapidly they are not scalable because you have millions of flows and so on so it's hard but these kind of calculations you can actually do two or three orders of many faster using these these techniques and uh so it's not only that just quantify qualify but also the speed that we can do these calculations and we're looking at sort of doing this kind of kind of um analysis in many cases uh sort of near real-time okay so i'm gonna skip through these uh but um you know types of perturbations so perturbations are derivatives basically so um and um and so we can you know we can compute many different kinds of perturbations and think of them as derivatives let me actually skip through this and just uh jump into the outdoor use cases so uh you know we have this sort of tree we realize that bottom line structures you know they are sort of a foundational element if you will and so that's what through the research we realized that you know there are potentially many applications you could use them network design traffic engineering ai even because bonding structures are a computational graph and neural networks are computational graphs too so you could think of fibonacci structures as a as a neural network itself so uh and but the point about sort of the the work here is also how does this get connected um we think that there's a strong connection with alto thanks to again uh richard for connecting uh and also but then also throughout this week here participating you can see that in many different working groups there"
  },
  {
    "startTime": "01:52:00",
    "text": "are potential connections uh basically so i listed some of them here uh but we're still exploring and we you know we look forward starting from from the output to see how we could explore potential uh uh you know cross-working group collaborations yeah use cases you'll have you'll have them in in the in the eye draft basically so you want to look at them but um and then what i'm going to do is just i'm going to pick on on one of these use cases optimize your writing and congestion control and for this one we have a use case what we do here in the in the eye draft is actually we take an arbitrary topology we actually choose the b4 topology google's d4 topology so this is actually uh back from 2013 sitcom paper so it's a simplified now of course it has many more data centers but um and then uh i'm gonna do i'm gonna just show you the more sort of human readable version of that slide so this is a the subset i guess of the google's before network with links uh across the globe and then we're going to compute the bond mecha structure of this network and what you get is uh this one so this is in the i draft but i'm going to make this more user-friendly what assumption here is that i'm gonna make some some kind of a random assumptions about ad hoc uh that everything has 10 gigabits per second capacity and that uh the the the two links between the terms and landing links have 25 units per second and i'm just gonna make a very simple use case which is every the pair of data centers from us and and europe are connected both ways okay in fact you know before runs is a sort of multi-path network but and in this case we're going to assume a single path so you can actually complete the bottom like a structure of that and this is what you get then you can start reasoning okay if i want to do a large large dataset transfer uh you know which path should i be using and so for instance here in the bottom structure we see that uh you know the turns and landing links are at this level the bottom line structure and uh and these two links are here"
  },
  {
    "startTime": "01:54:01",
    "text": "i i highlighted these two links uh because um they are sort of relevant there's this property that the the the links at the top get less bandwidth so these are actually the links that are sort of more bottlenecked there's a notion of being more influential because these links actually influence the performance of the whole network so that they tend to be more relevant and then what i'm going to do i'm actually going to skip through the interest of time but basically here what we do in this use case is i need to transfer data from this point to this point i have multiple choices and i'm going to use the bonding structure to to uh to predict the performance of the raid this is sort of like solving the joint routing and congestion control problem together because what balance structures do is model the congestion control algorithm and tell you if i place a flow on this network according to this path that's going to create a ripple effect and i can compute what congestion control will do and get you that rate basically after the deploy after you place the flow and if you do that then basically in this case we showed that it's actually better to not use the shortest path that you're going to get more bandwidth if you use the non-shortest path and uh and so uh sometimes some of these uh outcomes are non-intuitive basically and you can also reason about them so yeah we have a few requirements uh that we start sort of um uh discuss uh in the group or through the draft we're starting to discuss it this is very preliminary i should say uh the the initial requirements um are in the draft so maybe we don't have to actually maybe time because uh to do that but they are in in the in the draft they are very intuitive at this point i think um and the requirements are actually structuring in four groups you know one is the bsgs abstraction you know do we want to create an abstraction for bond like structures that's an object basically that would go into the specification uh requirements number two uh information received from the network so what kind of information we need to"
  },
  {
    "startTime": "01:56:00",
    "text": "extract from the network in order to compute the wellness structure requirements regarding regarding the information passed through the application so you can think that one is the southbound the other is the northbound this would be the northbound what information given about megastructure what information we pass through to the application do we want to pass the whole volume like structure as a compact way to represent the state or maybe some elements of it and then features features that would go into this potential bonding structure graph service uh and some some some initial sort of uh debate or discussion about what features we we want to put into you know for consideration basically so you know welcome any feedback at this point we're just uh discussing this understanding what's the connection and and trying to get some coaching guidance on on the steps here uh yeah looking forward to that conversation thanks jody actually have the time limit we don't have time to take a question maybe we can uh take it to take it to the list you can you know introduce your uh draft on the list and we can keep on uh discussing on the auto weekly webex meeting next let's move to luis maybe you have to yeah hello this is andreas from telefonica uh yeah next slide please"
  },
  {
    "startTime": "01:58:07",
    "text": "yeah well the idea of this presentation is simply to comment about the computer awareness capabilities and how uh what could be the role of alton in this story so a content service provider for sure from a long time ago but now also operators are developing the networks by adding compute capabilities spread and disability across the network this is not necessarily related to edge for sure the edge is there but we could talk in general terms about computing capabilities so cloud they more or less centralized data centers and for sure also edge computing so it seems to be interesting to know about where and how these computer capabilities are really connected and also to extract from them also even metrics so to understand to what would be the latency what would be the throughput that we could have for reaching whatever amount of cpus and status in the in the cloud path this is clear for the resources but also this could be an augmented for connecting a service function so we have a notion of where we can find a gateway or where we can deploy a gateway or whatever other function that we could consider so there is some space for optimization on service delivery management and and planning by combining the information of compute and and the work you know together so breaking those silos that are today is how they couple and permitting for decisions uh for placing of functions so for simply connecting and accessing resources so next please so yeah for just for finishing this week but there was a uh both um named tan how about computer i want to work in that precisely was that they're trying to address this same problem space but from the routing perspective so trying to define routing solutions for for that we consider that alto can can address the same problem in space but from a different engineering perspective from an ethereum point of view or angle so the idea would be to have alto as a element capable of exposing combined information between network and and compute capabilities so adding metric"
  },
  {
    "startTime": "02:00:01",
    "text": "resources topology view and reachability and so on so far in fact there are two existing pieces of work on this subject i put the the draft and just simply well the the final message for this the goal that we were considering with this presentation would be to explore the how alto can communicate contribute on this so uh to define a solution on the to this problem space trying to propose this as a subject for future working group recharging and with this uh with that i finished so thank you okay thanks uh luis actually a good topic actually can actually i think uh has a lot of you know uh you know for also actually designed for the uh the sitting application actually you know uh for computer awareness working actually you know very similar to the cd application so i i think also can be the potential solution for uh computer aware networking so that that's a you know keep on discussing this and cooking your draft and for audience if you have any uh imported to this and uh feel free to uh uh join on the menace or contact with luis and as a prevalent for the cairn and with this actually we we actually at the end of the meeting and so uh matt do you have any last words or nothing no no it comes from my side actually yeah yeah it's not here but i'd like to thank the yen to serve the author and uh he will it i'll go in the auto chair yeah so thanks of all and and that's a closed meeting"
  },
  {
    "startTime": "02:02:12",
    "text": "thank you okay out"
  }
]
