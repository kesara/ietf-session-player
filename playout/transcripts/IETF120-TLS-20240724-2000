[
  {
    "startTime": "00:00:01",
    "text": "Thank you Good, see you Okay All right, get going All right, let's get going going, all right. All right, folks to get started with the TLS Working Group session so please take your seats if I could get somebody to close the back door so we can reduce the noise. That would be awesome All right. So here is the Notewell slide This slide is an overview of the policy of the iETF there are a numerous links on here that you can use to look up the policies on everything from IPR to anti-harassment and privacy So please take a look at this. This is important information for you all. We also have a another slide here on the note really well, which is just an emphasis that we should all treat each other with respect and keep things professional in our discussions in these meetings And that will help us, you know, work more efficiently and end up with better work products Everybody, please"
  },
  {
    "startTime": "00:02:01",
    "text": "join the meeting with the onsite tool so that we get an accurate representation of the number of people attending this meeting in person and also so that we can you can join the queue This is how we'll manage the queue is through the onsite tool So if you want to ask questions or participate at the microphone, please do that next slide agenda okay so we have a scribe scribe Sean will go through some of the ideas status in a minute We will probably try to rearrange some of these things, well, I guess to move the hybrid and ML can things a little bit earlier, because some participants have to leave early for that discussion, so we'll try to move those a little bit early if that's okay with folks And then we have some additional topic on TLS frozen ss ss those a little bit earlier if that's okay with folks and then we have some additional topics on tLS frozen s s s s s l key log for e c h extended key update, and trust expressions will close out our meeting Any questions on the agenda? All right, I'll turn it over to Sean Hi, so I'm just going to blow through these slides really quick because I sent this to the to the list already So you normally go through the working group status. I don't want to waste time because we've got a pretty tight agenda. We are going to use the stopwatch today to make sure we stay on point so that we get to everything But as you can see, I went through each one of the drafts and its status. There's a couple things that are stuck on various things, and some things are moving forward. Some people have told me they're going to reinvigrate things. So that's great So please read the email Now we're going to go to which one you want to do what you want to do hybrid key exchange first"
  },
  {
    "startTime": "00:04:01",
    "text": "or ML for Kim hybrid MOKM first? All right, cool, let's do that one first All right, thank you dear drive Hello, this is re-uping something I introduced I don't know, last meeting, the meeting before. I don't remember. This is just a document to lay out how to do key agreements in TLS1.3 with just ML Chem, the future fifths draft that's supposed to drop any day now or next month. This is very very similar, but not the same as the hybrid key agreement thing that we are very happy with and I'm going to talk about next We need a document and not just a code point and not just an IA allocation because we don't have any other documents that say how to do chem-based key agreement in TLS not hybrid, not combining with anything else You can infer from hybrid design a lot of the things I wrote down in this document, but they aren't written down So I wrote them down, and that's all it is I am not asking for recommendations I'm not asking for a mandatory to implement I'm not asking for any of those things. I just want to write it down because I would like to be able to do it in my TLS application and I know there are other people out in the world that would like to be able to do it, especially ML Chem 1024 So that's it This is in the draft It's just literally these two ways to do it Some people have been like, well, what about 512 to just round it all out? I'm not opposed to 512 but I know that most people who are not meaning to comply with CNSA 2.0 or any of that stuff seem to like 768 768 seems to give you small enough but conservative enough parameters. I'm not opposed to 512, but it's not in there right now Next please. And then this is just kind of how you do it You're going to generate an effect"
  },
  {
    "startTime": "00:06:01",
    "text": "going to generate an ephemeral key pair. You do, uh, you do decay you do it in caps to your key pair you send them and then your server will reply with a sorry, it's the other way around. You generate your femoral key pair, you send it to the server, the server does it in caps to the key pair and sends the cybertext back over, and that's how you do it next please and then the shared secret that comes out both sides of ML Chem, you shove it into your TLS-13 key schedule the same way that you're doing it in the same place for hybrid design the same place that you put it for ephemeral Diffy-Helman, elliptic curves ephemeral diphylum, same. Next Okay, I already said this why can't you just do a code point? Because we don't have another document that tells you how to do this thing. This is trying to fill that void. Should this be recommended? Should this be a mandatory implement? I don't think so. Not at this juncture. Maybe in like, a decade, we all feel that way I don't, I don't care. I just want to be able to do it officially with TLS103. What about which? doing chems? What about PQ signatures? Not in scope not now we don't know how to do it right now we have a lot of things to talk about with PQ signatures. This is not about PQ signatures This is just we have a nice thing. We already doing it in a hybrid way. I just want to do it by itself It's just drawing the rest of the owl, as it were Isn't this too early? I don't think it's too early at all. People are chomping at the bit for these documents, the Phipps documents to come out years ago at this time. We've already deployed hybrid in Chrome, Envoy, CloudFlare It's already getting negotiated in a lot of places. This is doing less cryptography, simpler cryptography in a way, and drawing the rest of the out I do not think it's too early. Why not just use hybrid? Because what if you don't want to and what if you are totally comfortable going directly to ML Chem? do not pass go, do not collect $200, why not be"
  },
  {
    "startTime": "00:08:01",
    "text": "able to? And there are parties that will be required to do only ML Chem 1024. And I want to do it. Why can't they do it too? I don't trust the crypto Whatever Read that slide and whatever There's already a long queue So, Honest, you're up first All right, we got nine minutes, 10 minutes. Make it quick. Yeah like this approach because it's easy to integrate and sort of like feels almost a natural extension because we've seen other proposals in the back which were sort of radical modifications to it feels almost a natural extension because we've seen other proposals in the past which were sort of radical modifications to the way how DLS worked and that scared me a little bit because of all the work that it requires to sort of move there. So I'm in favor of this this Yeah, can we go back to the FAA? slide? Which one? Oh, FPQ Okay, so I'd like to push back with some of them We said that you can't just get a code point Yes, you can. The policy is specification required. The specification does not need to be an RFC You can totally get it just with a draft or a document from some other place. That said, the fact that you can does not mean that you should. I think the right thing is to adopt it here and have it as a working group document So mandatory to implement, I agree. That's not is it too early? No, it's not. And the document, even if your document is a destined to be informed I think that's wrong. I think it should be proposed standard Proposed standard is just that. It's proposed. It doesn't mean that everybody has to, it doesn't mean that it becomes the standard that everyone adopts. It could be a proposed standard. Definitely for information It's not too early and if somebody doesn't like it, well, it's a proposed standard. We don't have to implement it. You're not forcing anybody there's no protocol police so yeah"
  },
  {
    "startTime": "00:10:01",
    "text": "that's it. Thanks. Pretty much agree Kyle? kyle nekritz, uh, I support this I think I'm echoing a lot of the same points. If we don't do this now, then I think it becomes kind of unclear what exact we're waiting for Just on the 512 code point, I would like to see that as well just because that can make a significant difference if you're trying to fit things into one packet when you don't have that much room left right yep well, just because that can make a significant difference if you're trying to fit things into one packet when you don't have that much room left. Right, yeah, just to meet you to that. I support this, people want it. I want it, but I'd also like to see 512 just to run things out Thank you. Cool. Paul? Paul Valkis, sort of AD So this combines a particular cam with the description of how to generically do chems, right? Yeah but it is being particular about these supported groups. This is how you put generically do chems, right? Yes, but it is being particular about of these supported groups. Sure, sure. So let's say instead of you, we know how someone from the Klingon Empire standing here doing saying, this is how we should generally do chems This is the one we propose here as an example We might not be as happy about that, right? So come to my talk on SACC tomorrow when we talk about crypto and IETF Personally, I would like to see that split up, where if we my talk on SAC tomorrow when we talk about crypto and IETF. Personally, I would like to see that split up, wherever if it is possible to say, like, this is how you should use chems without any specific cam then I could see that much more getting an RF than if we tie it to one specific one because that's exactly what the security edies are trying to avoid, where we seem to be favoring one a cipher over another. What if I do both? and I split it up, and then I immediately re- seem to be favoring one a cipher over another. What if I do both and I split it up and then I immediately re-edit my current document to be like, this is an instance of that because that's what we're doing with hybrid design Then maybe I will tell you you can get a code point put on RFC for your can Chris Wood, I'm supportive of this as well I wanted to comment on the last item in the fact here"
  },
  {
    "startTime": "00:12:01",
    "text": "which is on whether or not we have confidence in the design or the algorithm itself. I think we do but I would caution against having the same level of confidence in the implementation of EML CAM that exists So I think this needs to happen at some point, but jump to ML Chem only right now when we're not quite sure we have the same like production ready implementations of the cryptographic algorithms might be a bit premature so otherwise yeah full steam ahead so i would like to ask Paul something. So is it possible that we could because no one's speaking against not doing this So this seems like we're clearly on a path for working group adoption And we adopt it and then if you're like, no, you gotta remember the code points, we remove the code points My question is, because I'm, mean, the idea is that people are like, this document apparently is going to remove the code points, we remove the code points. My question is, because I mean, the idea is that people are like, this document apparently is gonna drop anytime now, and then people are gonna be banging down the door for where, if I wanna do this, how do I do this? You can't do this. Can you really not split it? into documents? Well, we could, but the question is, can we just? you know you can definitely adopt one of them. And the other one, we can, we'll have to the discussion on Thursday and Friday about specific algorithm so I know that I know that you are motivated can you split it And then we can, so if the plan is really, if you're directing us that the thing, the clearest thing to do is if we split the code points out and we just have the mechanism and specify how to do it, the track is really friggin' short. And then we can do a work group call for adoption, and that sounds like a plan. Does anybody think that that? is a bad idea? I have qualms because some chems jared mauch bigger and have other security concerns and someone is nodding vigorously and I think we all know some of the things we're thinking of ML cam is easy mode of all the cams that are currently under discussion as things we might deploy in practice. I'm thinking of classic michael gibbs. There are things that I would write a lot more words if I know a doc document is going to be possibly deployed with classic"
  },
  {
    "startTime": "00:14:01",
    "text": "McAleese than I am with MLCAM. So if we start to split it up and we start to be like, well, what about these considerations? for all these camps? We have to add more stuff to a document which means it's not going to land as something that people can trust and start implementing the way they've been doing hybrid design a lot longer from now So I agree in principle, but I am very, it's going to gum up the works to what end John? Yeah, hi, it's John Greene from Entrust. I think I was thinking about the same thing because you're this document is about ML Chem specifically But having, you know, you have the generic mechanism or a mechanism that could be more generic in the document, right? I guess if that could be separated out. And then you could have other documents that make use of that, then it could be really helpful because we know more chems are coming right there's the whole round four there's going to be more and having a way to do that will be very helpful I have a counter argument to what I just said. I can make it super restrictive i can be like everything needs to be hash in. Your big-ass public keys, your big assypher text, everything is going in the TLS 133 key schedule because it's all in your client hollows and your server hollows and all that. And you do not get exceptions if you have a chem that is based on a difference security problem but results in big cyphertexts or big public keys or big in, you know, compute times or anything like that. I can write that down really easy And it might make some people unhappy, but it'll be secure. All right, we're going to need to lock the queue because we got too many anything like that. I can write that down really easily. And it might make some people unhappy, but it'll be secure. All right, we're going to need to lock the queue because we got two minutes and 40 seconds left, and there's four people So I'm understanding that the proposed split here is to define how chems work generally and then instantiate it with ML Chem two documents yes i'll basically take the super general stuff that I already have and just be like you can use this for any chem that has"
  },
  {
    "startTime": "00:16:01",
    "text": "yes, that has NCCA bunch of problems. Yes, that's the problem. Like, is like enumerating that so like I think if we know if we know how to do it with ML Chem, like, let's just do that. If we can abstract that later and follow that, if there's demand for any other side suites of the same shape later, if, like, we know there's going to be demand for this, like, let's do it. We know how to do it and if there's demand for other similar stuff later, then we can abstract. Like, solve the problem and then abstract I was very very big just and then abstract. I was very, very brief. I completely agree with that. I think one document that describes MMM is the better solution for all the things you said. I just wanted to put it on the record that I agree with with So, Paul out is now with my AD head on So why do you need RFC then? Why not just a code point? Because we don't have a document that says how to do it just with any cam, let alone M cam. We have hybrid, but in inferring what you do if it's not hybrid is left up to the reader. So this is literally just finishing the other side of hybrid design for just a cam. Okay, so I guess to me that still feels like that your document is doing two things and that could be in two different documents, but we can talk us up more of list dennis jackson. I think, you know doing the safe thing for the combiner and and keeping it scoped to MLCAM is like the smart call. Just because people copy each other's homework all the time without really understanding what they're doing and you know a lot has been said about combiners and i i think we probably all want to try and solve that issue as soon as possible but if we need this sooner than doing the simplest, safest thing seems like a great way forward TOS13 is blessed to not have to worry about as much stuff as other settings for both key agreement or hybrid key agreement"
  },
  {
    "startTime": "00:18:01",
    "text": "I don't oppose a general chem or TOS 1.3 key agreement thing because we don't have to worry about the stuff like binding properties as much because everything is going in the TLS1 key schedule. We are in the ponies and rainbows land. But it does add more stuff to the bureaucracy mill. This document has to concern all these things, and then this one has to reference it so that's kind of where i'm thinking Cool, yay, thank you. I'm gonna talk some hybrid key exchange for TLS 1.3 this is not my document. I contributed to it. This is Douglas Stabilla and a couple of other people. This is how you take elliptic curve Diffy-Helman and a chem the only two instances so far, have been using ML Chem previously called Khyber, or specifically Khyber 768 and combining them into TLS1.3 key exchange to do your shared secret at their very end We have two instances that point to the document. Hybrid design is the general way and then the two documents, X25119, Khyber and SECP-25 and Khyber are two different drafts, and they define their code points. So I think we're just talking about moving hybrid design forward The 25519 Khyber one has been implemented and deployed for several weeks now I think we're getting 20% of fresh negotiations between those two ends are negotiating and using hybrid post quantum TLS1.3 in the wild So yay. I don't have any number on the SEC P-561 I think the only thing to say here is that the generic one, hybrid design, is on version 10. It's been tested It looks good. I think we don't have any significant concerns with it. And so I think and just under underlining that it"
  },
  {
    "startTime": "00:20:01",
    "text": "will move on and then any new code points, any new hybrid key agreements will have their own individual documents. It's basically exactly what Paul just said So we have two if there are any further, we just create a new one and we ask for a code point and there we go. So I think hybrid design can move on and we can probably try our last call soon so to be clear, there's no MTI in the hyper design No, no, yeah, yeah, yeah, that's the other thing. No MTI and no recommend either. That is our plan going forward unless somebody gets to the microphone and start screaming pretty quickly. Yeah, no no recommendations or anything like that just we can use it. So whoever taking minutes, please make sure that that's down That's it. Thank you. All right That's it. I think it's just questions Yep. Now I think we stop stop All right. So do you mind why why? Hello, hello I'm channeling my Ecker. Actually, I don't know I do speak quickly, but not as quickly as him, and he'd probably tell me he didn't want to do these slides anyway. So next So last time, if you remember, we were all worried about, I was all worried about trying to make sure we got the errata that was out on 8446. Address We did that. Many thanks to Ben Smith who went through his 25 or so errata and figured out which ones still applied in the latest version and then it ended up a couple. But we ended up merging things if you noted on the list of the consensus calls on each one of these things and we moved them all forward thank david benjamin as well for providing some unifying client cert and server search selection text, and also forbidding the sender from some setting duplicate support reports. So we have a couple of Q'd PR Now there are two. One is very straightforward Seems like everybody was good. There's one minor point I guess, the very last part of the change. Martin said it would be better if you kind of clean the text up. And Eckers said, sure"
  },
  {
    "startTime": "00:22:01",
    "text": "I'll get to that when I get done with this thing that he's off doing this week Now the next one is about making 255-1-19 a mandatory implement. Everyone take a deep breath We're going to the next slide. Let's keep it professional Whenever we talk about curves, people seem to lose their minds and it ends up being a dumpster fire. We are not going to do that today keep that in mind okay next. So the PR as written, uh, as discussed on the list, was to make x25 ion We are not going to do that today. Keep that in mind. OK, next. So the PR as written, as discussed on the list, was to make x25I and 19 another mandatory to implement algorithm Now what I'll say is that on the list, it's fast it's faster, it's better, it's still, it's deployed now I care about FIPS compliance, I don't care about FIPS compliance don't bother. I mean, those were basically all the arguments on the list or the discussions for one point or another But the point that I first remember seeing brought up, I think it was by andrei popov, was like, this isn't even appropriate for this particular document because we're just doing clarifications so I think that's actually the question we have to answer first. So I would like to move to the next slide I proposed HUMS, but I actually think it's we're gonna do a to answer first. So I would like to move to the next slide. I propose HUMS, but I actually think we're going to do a show of hands tool. And so the first one is, is it even appropriate? to make this change of this ID, which was supposed to be? just for clarifications? And we'll do a second one, if and only if Hum 1 is a Y why which is to actually make this change because in talking with the And we'll do a second one, if and only if Hum 1 is a Y, which is to actually make this change. Because in talking with you, a lot of you in the hallway, I'm going to put that PSA slide in all freaked out that like we were going to have a large knife fight here And everyone was like, eh that was kind of the response I get it, I'm like, wait, have we like blown? steam off on this particular topic? So I've been very happy that the fight or six of you that I talked to were like, it probably won't be that bad. So Honest, do you want to hop up there first? Is this a mandatory to implement? for clients and servers? both? So, yes. Okay Well, although I'm not working in IoT anymore, but in general, like having"
  },
  {
    "startTime": "00:24:01",
    "text": "mandatory implement for different algorithms specifically when you have hardware support for one and not hardware support for the other is kind of not great. Right. Well, again, so that whole discussion may be moot if we don't even make this change. So that's why I want to do the first change is whether, right Because yeah, we could dive off into speed and support and all the kinds of, you know, things, but at the end of the day, it's what or not we're even going to make this. Have you made a To make, well, to make a change, to whatever, bad English So hopefully that was clear enough And there's a hundred of you in here in this up That's what I love about writing hums early Everyone nitpicks your English because I screwing it up often All right, folks I think we're turning towards not making this change. So I think if we're going to end up making mandatory implement algorithm changes later it'll be done in, you know, some other version possible But I think at this point, this discussion is dead I guess we will need to confirm this on the list. But unless we get a whole lot of support on the list for making the change, we'll go ahead and close this PR after a little while And I yield five minutes and 45 seconds to the next person Is that you?"
  },
  {
    "startTime": "00:26:01",
    "text": "Hold on Let's move. I'll evaluate it for me. Can you present the next slide? Thank you we're not, Meetecho is not allowing me to kill the slides Okay, let me try this again Yes All right, now it's working. All right, they're just back up All right, this is an update on the formal analysis triage panel that I suggested, and I think everyone was on board with I think at the last meeting, the one that was, I was online for We would, yeah, we initially called us a formal analysis triage panel and then someone realized that if we just called it the formal analysis triage team, we could call it the fact So now it's called the fat I'm making t-shirts. You know, complimentary, not directly complimentary. So this is reference to like the first kickoff that we are making t-shirts. You know, complimentary, not derogatory, complimentary. So this is reference to like the first kickoff that we will be why we wanted to do this This was the call for 8773 this, where during the, the we wanted to do this. This was the call for 8773 this, where during the last call there was a lot of noise about we would really love to have updated formal some formal analysis, not just updated some formal analysis on this change to TLS1.3 and this is basically where instead of only pre-shared key or certificate-based off, you can do both This has been noted to be not ever included in the modeling, uh, symbolic, computational otherwise of TLS1.3 or other broader models of TOS period. So when I, you know,"
  },
  {
    "startTime": "00:28:01",
    "text": "mentioned this in passing to, you know, a person who has tons of experience doing this sort of thing, they're just sort of like, oh, yeah, we now I, you know, mentioned this in passing to, you know, a person who has tons of experience doing this sort of thing, they're just sort of like, oh yeah, we never thought about that. We always assume that these things were completely destroyed. So basically this kind of spurred like, well, how do we kind of include a concern? consensus-based process to get feedback from people like that? Earlier in the process, when we make changes to TELUS 1.3, not all the things that come through this working group but specifically 1.3 because it and specifically specific areas like the confidential authentication properties that have been well time of established of TLS 1.3 by prior formal analysis proofs tamarin models, pro-graph models, com, you know, lots and lots of modeling tools Next and next. So the proposed mechanism, relied on existing consensus-based mechanisms that we have in the group, which is basically we have a rotating group of invited experts who have experienced multiple doing security proofs of TILA group, which is basically we have a rotating group of invited experts who have experienced modeling, doing security proofs of TLS1.3 and other, you know, secure channel mechanisms during adoption calls during last calls, to give their you know, knee-jerk reaction to a proposed document, a proposed document to come for adoption proposed document to go to last call, both because sometimes you adopt something and then you go to last call and some diffs have happened in between that you just kind of want to, you know, double check that anything you have done is still valid. And then if they recommend that update analysis would happen, you know, get their guidance on how long it would take, how much work it would take, do they know somebody that can help you, you know, complete the work, that sort of thing thing Yeah, next. Just more of the same"
  },
  {
    "startTime": "00:30:01",
    "text": "same So during all of these, you know, requests for feedback from the fat, we literally send them an email with a link to the draft, the document, say, what do you? think? Do you think this invalidates prior analysis? Do you think this requires updated analysis? Of what kind? What security properties do you think? specifically need to be analyzed or established? or revisited? And then collect all of their response emails and bring them back to the TOS Working Group mailing list That's basically it. The panel membership can be refreshed on a regular basis, and every time that we send out for feedback from the triage team, we tell you who's on the triage team so you know and they can then continue to participate on the working group mailing list or not because some of them are not IETF people and we do not want to limit the feedback we can get to just IETF people who can be on the IETF mail lists. We have at least jon peterson who's our already said that they might be interested in additionally helping out with this sort of work So what kind of formal analysis? There's a lot of talk about tamarin because there's been a lot of tamarin analysis of TLS 1.3, not just tamarin Our panel can suggest specific approach that might be brand new, that might be building on existing work that might just be pen and paper proofs that has a extremely important value too. Computation models for different components of TLS any and all of the above The goal of all of all of TLS, any and all of the above. The goal of all of this is to take this golden Google that we have of high degrees of cryptographic assurance of TLS1.3 and maintain it over time as the protocol continues to evolve and change because it's a living protocol that lives and is used in the world and implemented by people and deployed by people and comes into con-"
  },
  {
    "startTime": "00:32:01",
    "text": "change because it's a living protocol that lives and is used in the world and implemented by people and deployed by people and comes into conflict with I want to do certificates and pre-shared keys not justin ethier or, for very good reasons So we need to do work to keep that up So the first thing we tried to do was doing it 877 8733-8773 BIS. This is hard mode because it had already gone through an adoption call. It had already gone through a working group last call. People already said and vaguely tried to go get form analysis of it and did not succeed Now what? This is what it is. The actual document, you know, if you guys go get formal analysis of it and did not succeed. Now what? So this is what it is. The actual document is if you best. So we went to the triad team. They got a bunch of our feedback from a us, and we sent it to the list. They requested and recommended more clarity in the actual document 8773BIS, on the intended security goal like that's just updating the document itself and further analysis, security analysis to check a special the authentication properties, and that symbolic analysis tools would be suitable, such as pro verif tamarin and things like that there are maybe some others that are slightly less popular The document hasn't had any changes yet since this came down i think we heard that the author and Usama, Muhammad Masama, are collaborating on the work. If we have any updates, we love to hear it And we have not made any further consensus calls regarding any of this work yet, considering that this is like hard mode. We kind of just have to like do one eventually to get the consensus of the working group that one yes, we want to do this and either block or whatever on getting this feedback or not. I think that's it There are a couple more slides, but Russ, since we're talking about your draft and Osama you want to get in line too, we can do that Yeah, I object to this characterization of where we are are So I completely agree with the goal of the for"
  },
  {
    "startTime": "00:34:01",
    "text": "methods to maintain the protocol, but you posted a summary of the fat result questions were asked, no answers have been submitted and no consensus call by the chairs has been posted. Which question? They're on the list. It was the day or two later after you posted the summary. There's been no reply to that message Thank you Summer team also a bit surprised by this because Rustin and I had a discussion around this and we were still waiting for the reply from the chairs to give us a consensus called whether we need to proceed with this or not or what the working group has decided about this. And the second thing is that I do have some concerns around the process overall, how it happens Like I didn't like that. Even with the conference is foreign instance, you see like I get to see that this is the review coming from reviewer number one I didn't I might not know who it is but at least I know review number one has commented this, this thing. Reviewer number two is completely isolated from that reviewer number two said X, Y, Reviewer number three says ABC B, C, but I know that X, Y, Z was coming from review number two he has one mentality that i can kind of follow around reviewer number three was saying something else I could follow that around but in this case, the summary was not really helpful in the sense that it was isolating it was combining all the things together and I couldn't really see which is coming from where and how the two are how everything is together merged together So what I'm trying to say is that I lack, I, I, I,"
  },
  {
    "startTime": "00:36:01",
    "text": "have concerns around the transparency in the process I would have liked to see that everything could happen transparently on the mailing list and I could see what is coming from where or at least the minimal thing is that I could see that separately isolated that, let's say even if they want to be anonymous ABC so review number one is saying this thing all all the question answers, review number two is saying, let's say, one number whatever all the questions to the answer all the answers to the questions that he gave should be at least isolated so that i can see that what exactly is uh overall going on. So, so, and I would have liked let's say to be as a volunteer for doing that formal analysis, I would have liked to be a part of the process itself So I would really appreciate if the process could be more transparent and be done on the formal net on the on the on the mailing list rather than being done outside the mailing list that's really good feedback definitely we can make one of the goals is to make it very much like academic review and you're right that in more of an academic review setting, you don't know who reviewer number one is or review number two is, but their answers are all collated as from reviewer number one or reviewer number two or whatever we can definitely try to do that in the future. I think that's very valuable The second part is basically we do want it to be quite transparent in that like I want to be part of this process That's why we get their feedback on a snapshot of one document and then bring it all to the list That was all the words from our review team We do want to keep it anonymous so that they aren't just out on blast in the IETF or on the public internet because a lot of them are not IETFers. They are academic They are not on mailing lists on the public internet We want to get their, you know, professional you know, expert feedback but we don't, we want to keep it, you know very specific. We want your feedback on this document. We want your professional opinion and recommendations and bring that to the list and then everything from there on"
  },
  {
    "startTime": "00:38:01",
    "text": "is what does the working group think Please discuss. Please let me let us know what you want to do with this professional review and feedback of this document britta hale, I second the request for having more transparency in the process I agree that a lot of reviewers on these probably will process. I agree that a lot of reviewers on these probably won't, they're names out there in the same way that we do on the working lists But normally in a review process, there is a committee list of people who might be asked for review Oh, they're all up there when we first make the call. All their names are listed the entire list, not the might-bees, like this is the entire list Okay, so first of all is the transparency of who might be asked. And then second, of what time? of analysis might be asked about you mentioned several different types of tools and methods, but each of these shows very different things. Formal methods analysis is not the same as a computational proof. And those two approaches are going to, we've had a long history in TLS of different types of analyses done and it's good to have a cohesive view versus if we ask a few handful of people and what do they say and also i think there's something to be said about reviewers being willing to come forward and whether or not that's being transferred to the list. So I can speak personally that I was one of those people who was asked to do the analysis on this particular draft and I corresponded to several other people who are actually in the area who've done stuff with PSK injects with TLS before. And we all came to agreement about whether or not this analysis would actually even be worth it and what do you mean by worth it because the prior analysis actually would extrapolate directly to this So there wasn't going to be enough of a lift of a change to warrant more analysis We would love to hear that in specific reference on the list about this document because we weren't able to get anything of prior work basically to say, we think this is fine because of some reason. Right, so that's our transparency that's lack exactly So when you ask a reviewer, there should be a"
  },
  {
    "startTime": "00:40:01",
    "text": "transparency of whether they're willing to come to the list or to interpret the information too, otherwise we're having a very black box method method dennis jackson So I'm one of the people on the review panel and also like without disclosing anything about how it worked. I think like, I generally agree with the comments that transparency would be helpful and I think the best one of the best ways that we can achieve that is to like cleanly separate these two bits this was very much a formal analysis triage which was, you know, a first glance of like looking at the the draft that we see in front of us what do we think we would need to see to feel more comfortable about it? And I think that is like, it's only the first part of the conversation And a clean way to separate that is to be clear that the analysis panel you know give their feedback but what the working group decides to do with that and how that relates to any other IAT process shouldn't really be within the remit of the analysis panel because we're formal verification experts We're not necessarily IETF experts. So there's some of us do both And that like would lend itself to these kind of follow-on conversations where the folks that are experts in a particular, more narrow area can say, oh yeah, well, using this result here, we can actually do this in three sentences there's no paper in it but we can clean that up to the IETF satisfaction And that's that's really nice. And yeah, the second thing is that I don't think, like, there's only going to be like a small number of people on the panel of people any forward progress and that also means that anonymous comments probably won't work super effectively. So I think you know in general transparency is probably the way forward like a public mailing list where people can also potentially interact and discuss. And then, but trying to make it very clear, it's not about IETF questions and the folks there aren't going to know the distinction between a proposed standard versus experiments or versus informational they're not going to know what working group last call means they're just there"
  },
  {
    "startTime": "00:42:01",
    "text": "to look at a document and say, I have these security concerns or I don't have any security concerns. Maybe there's a way we can like cleanly factor that. Thank you Samma, should I go first? Okay So, so I would completely agree with what she said So that's one of the things I was also expected that whether Proverif is good to go, whether we need some body analysis, whether we need computational analysis, what exactly do we need So that was also one of the things which was really unclear And if we have that kind of a panel so one thing that I would expect as an outcome is is exactly that that okay at least symbolic analysis is required or computational analysis required. What exactly is required? So I had an offline discussion with one of the panelists and the outcome was that it's not even clear that whether the panel did not even decide whether symbolic analysis would be good or whether computational analysis will be good. They left it over to the working group to decide that. Yes. So that should be at least when we have the, so when we call them experts, so at least the one of the outcomes from there opinion, at least they should decide that whether this is the high level boundary the topmost boundary that we can have between the formal analysis, either, let's say, symbolic or comparison So at least they can recommend if not decide that okay so we would like symbolic kind of analysis i was a bit surprised to hear from him that they didn't even discuss whether symbolic was required or whether computation was required. The only thing that was discussed was something is required what that something is to start with is also like something that someone who is also waiting for that okay so and I think the whole process is now in a loop that the chair are waiting for someone and we are waiting for the chairs to respond so I would like more procedural thing to be added to the process so that we can we can be more clear we can move forward faster that's kind of why i was uh pointing at we were doing it hard mode because if we had to bring this into this feedback triage feedback"
  },
  {
    "startTime": "00:44:01",
    "text": "not this is required or not from this panel because that was always part of the conceit This is just a first look, gut check triage and take this feedback into either an adoption call or a working group last call There would already be kind of discussion happening on the working group, not just well, a panel of experts said we think it needs this, but this is not our, it needs this, it must have this, or else it's not achieving some specific goal We did not make a consensus call yet We probably need to do that because we're doing this outside of the plan, I guess I think that's part of it. The to what Dennis was saying, I think having two different settings, the working group setting where it's about documents and procedures and consensus calls and stuff like that, and then maybe another forum to settings, the working group setting, where it's about documents and procedures and consensus calls and stuff like that, and then maybe another forum that we host to discuss security programs and changes to TLS 1.3 to try to further on beyond the triage analysis to an actual recommendation of this needs a symbolic very verification of a property or not or no we need a computational proof of, I don't know, NCC cca or indistinguishability or something like that that discussion can happen there, and maybe that will improve the trend transparency that people seem to desire So we can change a couple of things. All right, Rich unless, Paul, unless you're throwing your AD card down Yeah, hi, rich salz I can post a link to questions I asked that didn't got no response if you need them in the chat. But at any rate, one of the slides said this is modeled after academic review of papers. And I think that's not what this is, right? there's not a paper and someone an anonymous review who might be conflicted or different or submitting a competing paper"
  },
  {
    "startTime": "00:46:01",
    "text": "is you know helping to make a go-no-go decision on a conference as to whether or not something should be presented This is more like collaborative research. So I think the model is wrong. Second, you know, said several sentences about triage and again that also to me makes it pretty clear that the model is wrong They're not deciding anything. They're just saying whether or not something else should be done. And that's an individual opinion. If people aren't willing to attach their name to that, no. We had I just don't think it's worth listening to them but frankly, but I'm kind of obnoxious that way We've had much, many interactions with cryptographers for TLS13. We had a whole public work on whether or not it was ready, right? And we encourage the academic community to participate, the Tron Workshop apparently went pretty well. Hugo Croutts came to many of our interim meetings, and we've had other formal analysis actual analysis of various parts of TL TLS-13, and none of that was anonymous and none of that was blocked by who the participants are or this barrier that's implied i think the thing overall the whole concept of that really goes against this spirit of the IETF so I think this needs to be brought back down to the base thing and reconstructed more like the open IETF processes. Thank you Paulots, Edie. I have some it is unclear if the fat operates under the Note Well of the IETF and rather all those rules and regulations that we set for our community apply. And so if within the IETF we are sort of putting a a blocking a blocking process into place that relies on things outside of the IETF, then that's the wrong process, right? there might be IPR issues because these people didn't operate on a note well and we're not aware of things. So I think we should be"
  },
  {
    "startTime": "00:48:01",
    "text": "really look at how we can sort of fall this into proper IETF process And sorry, and it could be that we I think we should really look at how we can sort of fold this into proper IETF process. And sorry, and it could be that we're just getting external advice from outside the IETF, which is fine too but then we cannot make it binding in our process within the IETF Never, never binding, bringing feedback for the work group to discuss as part of their own consensus mechanism I like what Rich said on anonymity I think it's probably the wrong model here. When I reached out, as a as a chair of OAS to that research community to do analysis of OAS nobody said that they want to be anonymous. On the contrary, they wanted to be evolved. They are now actually part of our community and proposing solutions So having people to subscribe to the DLSMetling is specifically if they want to provide feedback and discuss it and explain what they mean, I think that's quite important They don't have to subscribe to the IETF mailing list, but in least to the DLS mailing list that would be extremely helpful. They don't have to read all the emails So I think a little bit of fine-tuning would be appropriate here. Okay jonathan hoyland Cloudflare not a member of the formal analysis triage team, but somebody who did one of the formula analyses of Tamarin in Tamarin of TLS1 3 specifically to 8773 the author authentication properties that we prove no longer holds onto this change so if we think that the formal analysis of TLS13 was important, then I think this does have to be blocking, but I don't think it's a huge lift to actually redo those proofs but it's just a lot of busy work"
  },
  {
    "startTime": "00:50:01",
    "text": "because we'd have to rewrite all of the proofs because it changes the key schedule, which was the first step of our proof. So it's a lot of work for a very small change So if there's a lot of desire for it, then maybe we can get someone to do it. But I will say that it does break our current proofs All right, Dennis I'll try to be very quick. I think this is the core of the problem We have people that are willing to volunteer their time to do security research but don't want to do IETF politics So I think as long as they're only asked questions about the security of things they're more than happy to give an opinion but when that becomes pressure that's really tricky. So if we can give people a transparent, safe space to provide those opinions in, and then let the working group figure out the IETF side of things, like the authors can, in that sense, like the authors can always come and make a case, like we've given this feedback, but for what we need it for and when we need it we'd like to do this instead and it can be a more work that that is a working group discussion and the actual just the people that are doing the security analysis have this opinion is then something that is like input to that I think that would would probably resolve a lot of these concerns. I definitely agree I note that a transparent open process where people can avoid politics seems the opposite of what I would think a person who does not want to be harassed on the internet to do work for free would want We've had at least jon peterson run away from this political process because they were getting dragged in to fights on the internet after being asked for their volunteer professional expert opinion out of the goodness of their hearts to help TLS1.3 because they were just asked And they're just like, if this is how it's going to be, like, screw this I'll just not participate so"
  },
  {
    "startTime": "00:52:01",
    "text": "I very much understand that this just like, if this is how it's going to be, like, screw this, I'll just not participate. So I very much understand the desires of one to segment the working group kind of procedural mechanisms and the security open discussion of like what we need for analysis for certain properties of TLS given changes but I am very aware of maybe saying modeled on an academic process was the wrong choice of language I'm very aware of people whose opinions and expectations are very valuable and I would really like them to be part of keeping TLS1.3 safe and security as it lives in the world but protecting them from internet flame wars So not too bad not too bad. It's bad, bad Yeah, it's closed. So I think we, we chairs, I think we're taking away a couple things One, we clearly seem to have dropped the ball with, 8773 bis. We will get together with the authors I could not find something where I thought we were supposed to be sending a consensus call, so we need to make sure we're all on the same page there and we're going to try to figure out how to change the process a little bit. A little bit of a mea coppa since we're doing it process, definition, and application on the fly we didn't quite get it right. We are not trying to gum up the works. That's not the plan We're trying to make sure we can try to figure out how to maintain a relation with the people who did a solid and did some review. Thank you Rich. Rich, you're up I don't know who wrote the draft. Next slide, please That was a joke. Okay, just description, ECH keys, encrypted client, hello used to be ESNI, which was a lot easier to say than ECH"
  },
  {
    "startTime": "00:54:01",
    "text": "They're updated regularly and they have to be published to DNA because otherwise clients can't find out how to encrypt the hello to get to you The concept of this draft is there's a zone factory, Stevens invention, most of this draft was Stephen's work It pulls a well-known resource as in dot well-known slash something, to see what the keys are. If they changed, it then tests them for validity. It fetches them over a HTTP, so you can trust the authenticity you know, the server, and so on. And then if it's got, if the key are all valid, it publishes it to DNS. Next slide please Basically, here it isn't a picture worth a thousand words the client looks up AA double quad A service B records, DNS, service binding records, and so on uses it to speak to the front end site. It might be the model is there might be a front end that's doing the increase clientele, say, for example, OECDN speak to the front end site. It might, the model is there might be a front end that's doing the encrypted clientele, say, for example, O of CDN, or it might be the actual origin and so on. They might be one process, they might be processes where they reconnect with the TLS to the back end and so on But it's the zone factory thing on the right hand side the queries, the site doing the encrypted clientele reconnect with the TLS to the back end and so on. But it's the zone factory thing on the right hand side, the queries the site doing the encrypted client to low traffic and checks it verifies it, publishes it to the appropriate zone. Next slide Changes in the since the last draft a lot of editorial changes we upgraded from xml v2 to v3 we had greater compliance with the service B binding document, like there's only one alias entry and things like that finished out the ionic considerations. There is a new registry for the Origin Service Bee where you can specify what kind of field you want. I'll show an example of the next Sorry, the other way around. A JSON service binding that has JSON entries that you can put"
  },
  {
    "startTime": "00:56:01",
    "text": "in there. Security considerations were written We resolved many issues. They're on the last slide. We'll talk about a couple of them, one in particular So here's what an example looks like The regeneration interval I forget if it's in minutes or something one hour versus you know, however many, whatever that divides out too The endpoints is an array of objects the priorities, so you can have multiple ones and say, well, first go here to this CDN or this front end, or then maybe try the CDN. I know what the priorities that I would use if we were among CDN but you may have your own choices. The key thing is the params field. It's an array of key value pairs, of course, being JSON. ECH, that's the key. The other kind of, and you can have multiple endpoints in there. The well-known factory checks all of them picks the ones that work, and then publishes that to D DNS. The other option is you can have an alias pointing to something else, and that's this kind of construct where you have multiple things with parameters or a single alias is how the service D document specifies to go Next. All right, so these are the issues There's a GitHub URL at the top just going down them in order in priority order do we have any IATN issues I don't think so. It's all just JSON and it's solved all of those problems So does anyone in here, I mean, there's like a few people maybe that have id and uh you know I, whatever the hell that thing is. I, yeah expertise in this working group to review that because this is one of the problems that I foresaw was that we, this draft got bounced around a little bit, like go over to, you know, the art area and get some input because if there's no one in here that's going to say it anything about this like we need to get some other input from other people. And I did get those early reviews yeah and don't make me email john klensin"
  },
  {
    "startTime": "00:58:01",
    "text": "well that's well that's the other there's like three people right yeah so okay I don't see any hands going up as I knew make me email john klensin. Well, that's, well, that's the other, there's like three people, right? Yeah. So, okay. I don't see any hands going up. Oh, so I don't put my myself on a queue, but I have idea an experience. I've worked on the protocol with junk cleansing and the rest of the fault. I can review that Thank you. Cool. Thanks All right Issued architecture for intermediary in the modern web, or at least, you know, more than just the single vanity site. There were often many people, many entities, any one of which might terminate TLS they're in front of the real origin. We need to figure out probably how to handle that. You have load balancers different protocols. You might be taking H3 converting it down, converting it to HTP10 or something as people are known to do. HDP gateway in particular HDP gateways are called out in the HTTP document, so we need to figure out how to do that Anyone has any ideas or suggestions? post to the list, open it up on the GitHub you know, add comments to the GitHub issue One origin can claim to speak for others This is probably underspecified. martin thomson did an early review and so of course we'll have to address that Then the final one, and the one maybe we can use some of the time here to discuss is is this still encrypted client, hello specific? probably not but that's You know, the only thing that the ECA specific is the name at this point And so, you know, do we want to change the name? Probably not But there was a thread on the mailing list. I don't know how useful this is for other things It's probably useful for the various what is it, the bootstrapping service B entries draft. We need to figure out a protection model, probably who can add what kinds of fields in the"
  },
  {
    "startTime": "01:00:01",
    "text": "params entry. But I just wondered if anybody in the working group had opinions on that last issue. Should we work harder to make this? more generic and open up? figure out how to address that? Yeah, I mean, I think getting an answer to this would be the good outcome for this draft for this meeting So I basically, I mean, I think Rich and Ben also share the same opinion that well, I'm not sure, my opinion anyway, is that you're know if if just doing this for eCH make sense, then we'll go ahead and do that and it should be finished earlier If other people are interested in using this for other things you might want to publish in Service B records then it really would be good to know about that now and then talk to them about what they want and try and figure out how to do it I think I'm going to share interrupt here. If this is going to be more than about TLS, we're going to kick it out of the working group. Right? That's the, that's the, that then talk to them about what they want and try and figure out how to do it. I think I'm going to share interrupt here. If this is going to be more than about TLS, we're going to kick it out of the working group, right? That's the that I mean it was it was brought here on purpose because it was specifically about TLS and where the TLS experts are. We're suddenly going to be doing something that's much broader and more applicable to the other things it needs to go elsewhere I haven't had anybody ask for something that wasn't to do with TLS The question is if you're looking, you know, ALPN, is that to do it to us? So anyway, it's asked this question So I don't know, is david vernet? He's in the queue He's right behind. He's in the queue So anyway, I don't really, I know particular, if there's if there's, we want to do more things with this around TLS, I'm perfectly happy to do that. I'd love that we can decide that soon so that we can kind of progress. Either keeping an easy head specific or generalizing it somewhat to be also that TLS things Yeah, I think David was talking about the key"
  },
  {
    "startTime": "01:02:01",
    "text": "shares would be useful in his draft and so there's many parameters in TLS that we may want to consider putting in here other than just the one SSL TOL the key shares would be useful in his draft. And so there's many parameters in TLS that we may want to consider putting in here other than just the one SSQ. But yeah, there's not going to be the HTTP binding. It's a good thing they're meeting now in another room and can't pollute us Sorry, Arnav Yeah, on OTHADI.com, so yes, on the on the point 14, same point, I think it would be good perhaps to make an exploration about what might come in just so that you can, I mean, I'm not against, I can understand you want to generalize that could make sense but you need to perhaps yeah call for for a group to look at what else could happen there so that you can solidify your model here to abstract it or generalize it and maybe we can take it from there. Just a suggestion. Sure There are a couple suggestions in 14. As I said, I think key share was one of them from David david benjamin Wake up benjamin, I guess folks have said what I've meant to say, which is that the key share prediction thing is another place where this would be useful. I sort of expect that like, you know, now that we have this nice new DNS record that we can stuff things into people will come up with all kinds of interesting ways to use it And whatever the exact mechanism is, I think, since we, like, you know, internet practitioners, whether it's H-TB or TL or whatever working group, have like not done much at least you know in the sort of space of protocols I'm familiar with with Dan yet, I think having some clear way for like when your DNS provider and your host provider are different folks to like coordinate with the useful So I guess, I think yes, there are things in TLS that would benefit from this. I would maybe not put too much"
  },
  {
    "startTime": "01:04:01",
    "text": "weight on the like i sort of understand not wanting the document to like a so I guess I think yes there are things in TLS that would benefit from this I would maybe not put too much weight on the like I sort of understand not wanting the document to like go kind of crazy but you know if I think I maybe not put too much weight on the, like, I sort of understand not wanting the document to go kind of crazy. But, you know, if, I think at the end of the day, we want to find the thing that is like most useful for service operators. And if that does mean we like sort of open the door a little bit that might be worthwhile I don't know. Anyway, I guess it sort of depends on what else people want to do with it Ben. So I feel like there's a miscommunication here. This draft is already fully generalized. It is a complete, like the time of the draft no longer has any normative connection to ECH or anything related to TLS at all, but all of the motivations that we've come up with for every use case that we've come up with that motivates the existence of this draft and there are now maybe four are all TLS They all come out of TLS. So this is an interesting situation. This draft can serve any purpose The only purpose it actually serves is all related to TLS but its internal structure has nothing to do with TLS. It's entirely between HTTP and TNS. So I'm not telling anybody where to put this draft, but I think it's useful It should happen somewhere, and we should change the title I'm going to disagree with my co-author. It does say you should check the ech keys uh and I think that is the issue like I think the structure it defines with JSON and so on. That's extensible enough to hand key shares for David's thing The issue becomes thinking through who should kind of have control over those between the front end, the zone factory and do we want to write anything about it? so yeah i think this simplest model is the same way the E-C-H key, you're verifying the ECH key you have to be able to verify whatever parameters it's got to be the origin transport only that gets affected, right? So, so how about, I don't mean, can I make a"
  },
  {
    "startTime": "01:06:01",
    "text": "suggestion I suggest we change the title to something that we can buy shed later? And if and when David key share thing is ready to suggest a bit of tech he does that. Otherwise, we just proceed ahead with the ECH stuff so it that is a suggestion. I have another one. It also may have been that I didn't understand that it was supposed to just be TEL specific But I can do a show of hands to see whether we should what are the words that I wrote here? So should we expand the scope of dash will not? ESNI to support additional TLS features? Is that an appropriate hum? It's what kind of does already is the thing. Okay, fair enough Like if it's a JSON thing it's extensible, you can put in the other TLS features if you want It doesn't say you can't is the way it does it. I guess the question should we wait on that or should we just go ahead and and the key share stuff whenever it's ready and if it wants to use this, then get text for that then Yeah, maybe we'll change the title title Change the title. I don't know. Does anybody want to speak against? that that's another way we can do this Kyle, I'm not putting on the spot to speak against her for it Kyle, I do think this is generally a useful document Saying that it is restricted to only TLS things seems like a really arbitrary and strains requirement to me like I can't really think of a good example but like say you weren't using TLS and you wanted to negotiate like using plain text ATP or plane text ASP or something like that. Like that's a bad example, but I can certainly imagine things along those lines okay so i mean if we're getting down to the point of like changing the title and see if something like that like that's a bad example but i can certainly imagine things along those lines okay so i mean if we're getting down to the point of like changing the title and seeing if the other stuff comes along in time great the question is, at what point, how long do you wait? And Paul's getting up now too, so here we go With a minute left I would just say that if this is generically applicable, when you do a workgroup last call on it,"
  },
  {
    "startTime": "01:08:01",
    "text": "please also send it to D&S op so they can have a look at well-ended they don't get surprised later on Yeah, so this one's gone through Dena david blacka did the thing and he said it was ready with issues and our Opster review and our art art review said both said not ready i meant dna's op not D&S Directorate. Ah, okay, yes So I just, I feel like there's still some confusion. I just want to be clear. This is a fully general mechanism that is not in any way restricted to use by TLS in the current draft. The current draft already supports moving of things that have nothing to do with TLS and indeed it has to move things that have nothing to do with TLS It has to move all of the service parameters for the service But none of the people who define any of those service parameters wanted this mechanism because they don't change very often. The only service parameters that change often enough to need some kind of automated synchronization are all related to TLS, both the current parameters and the proposed parameters. There's no particular relevance to like waiting for some future TLS related parameters to be defined because the draft is fully future proofed, compatible, any future parameters that are defined for whatever reason will law through this mechanism just fine Okay Yeah, sounds good to me. Well, maybe we'll put an ALPN example in the curriculum curve. Right, so it reached just a last question From an operational perspective, an architecture perspective, so you you you see this like we would have a separate component in the architecture that would just do that and would be specialized to just organize all of this? I think so but I'm not, I don't want to think on my feet about that answer to that. I think so"
  },
  {
    "startTime": "01:10:01",
    "text": "Okay, let's talk offline. Thank you. I mean, it's not going to replace C panel, but it could come close All right, don't go anywhere, Rich Okay, next Oh, sorry okay so I hate writing the same thing down more than once. We split up this draft right into one part that went to UTA, one part the same writing the same thing down more than once. We split up this draft right into one part that went to UTA, one part that stays in TLS. So I looked at all the duplication that was in this draft, because I know how we like to have TUR stock documents. And so if we remove the bullet list, from the introduction, I forget what it talked about, remove the security considerations because it's not really relevant to choosing one dot 1.3. And then we add a sentence that says nothing here applies to DTLS It turns out the draft is about one and a half pages plus boilerplate. And all it does is keep the IANA in instructions. Next page So there's the text. Ianna will stop accepting registrations for any of the TLS parameters other than exporters in ALPN So is there another page? I forget. There's one more Oh, yeah, post-Quantum also Get rid of the we add the sentence to the introduction It says we're not doing post-quant, the IETF is not doing post-quantum work for TLS 1.2 As I said, it really makes a document like you know, 60 lines Is it still worth doing? I think it does. It sends a message that the IETF is not moving on 1.2 anymore other than critical security fixes Just like to know if people are fine with that or we should just drop the doc Chris Patton, can"
  },
  {
    "startTime": "01:12:01",
    "text": "you clarify? I think I missed it. Do you want to add this? you want to add this text about to no this is the text that's left. Oh, this is the text that's left. That's all it's the want to add this you want to add this text about? No, this is the text that's left. Oh, this is the text that's left. That's all that this slide and the previous one is pretty much the only thing non-boiler plate that's left in the document I mean, there's some nism introduction about NIST and IETF, but this is really the text that's left. It's also the most important stuff. Everything else is wrap rationale that really belongs in the UTA document Hi, yeah, it's john gray. I was just wondering so you say no PQ for TLS1.2 I just wonder if people will do it anyway or if they see 1. I know lots of people are still 1.2 If they see 1.3 is a bigger hurdle than just adding maybe a new algorithm. They might want to do it in 1.2. They wouldn't be surprised if people do. Yeah, I'm sure they will, but for example when we adopt and support the ML Chem only document, it's going to have a note in there that says, don't do this in 1.2. Now, we can't we're not the protocol police as the phrase goes, but yeah just watch out for that Yeah. I have a thumbing question So we had this document, the detailess our which where we define functionality for connection ID for DTLS 1.2 and 1.3 since that has been blocked for a while and now it's even more blocked with the previously discussed formal method triage panel and who knows how long that will take I'm wondering whether now this document will then get published and then have not basically unblocked from doing the work that was done beforehand. No, it does say maybe there is the same sentence that says none of this applies to DTLS 1.3"
  },
  {
    "startTime": "01:14:01",
    "text": "Okay. That's explicit. Okay watson ladd, Acomai, ship it, I see Chris Padden in the chat has said similar thing Paul can get back in all yeah paula just thank you for reopening the queue um does this apply only to our required brianne just thank you for reopening the queue. Does this apply only to RFC required for IANA registrations or also specification requires or like I don't know if this is a first come first serve because can we? really close those in that way? well it's all of the TLS registries are expert required so there are no first come first serve registries in TLS So it's like new instructions for the DE actually as it turns out. So either one way or the other, but it's the same same plan. Okay Yeah, that's good. All right Okay, thanks. And Honest, don't worry, we're not going to see the door in your face. We'll figure out a way to give you an exception yes All right, now, who's next? rich SSLK log for EC ECHH All right, time is over yes, time is over. Timer, how much time? do we give them? Oh, what's going on now? Fire now, cancel timer. All right go ahead. Hello? Next slide, please. So it's cell key loke is a very useful troubleshooting diagnostic capability used by thousands engineers worldwide to troubleshoot diagnose TLS handshake, and whatever within TELS TLS With ECH, we lose that capability because for few reasons and primarily because we don't, we no longer see"
  },
  {
    "startTime": "01:16:01",
    "text": "actual client random it's within encrypted ECH and we also don't have ability to troubleshoot ECH itself and for anybody who is implementing or deploying ECH, it can be excrucially sophisticated challenge to overcome So their proposal solution, this is very simple draft it offers, suggests four things so two new labels for SSL key log one ECH secret that would log HPKE shared secret from which a diagnostic tool can derive all the necessary secrets to decrypt ECH, and then ECH control label to log, well, ECH config that was actually offered by client or accept by server. Then those messages would come labeled with outer client Hello Random, and this draft also clarity that inner client hello random should be used as index for rest of the session as long as ECH was accepted and this is actually how all the TLS stacks that implement ECH today behave with SSL key log K-LK-LK-LK log. Took the liberty to do a few prototypes implementations, just if running code actually matters. It was very easy to implement it and assess because it happens to carry a shared secret from HP key in its context with boring SSL it was a little bit more complex because shared secret is dropped immediately after key schedule process so it took additional callback to implement that and a wire shark implementation to look into that So it allows for troubleshooting for diagnostic visibility into ECH so we can see what"
  },
  {
    "startTime": "01:18:01",
    "text": "inside, what was offered by client client It can also check if server has accepted ECH by looking at magic bytes and computer them to computed once And yes, we can then look into the rest of the session because we know if ECHA was accepted or not, so which client random should be used and look up keys accordingly So the questions that I have, what do you think about this problem? What do you think about proposed solution and should this be potentially adopted by the working group? And if you do get to the microphone and you hated SSI the SSL key log file or the a passion and didn't want to get it standardized, please state that before you start making comments. Steven? Stephen? Stephen? Yeah, whatever you just said. I mean, uh, know. So I guess there's a general question is for everything we do that improves the security and privacy of TNS, are we also going to specify how? to break it as a general question? More specifically, I guess SSL Keylog has been deployed out there this is kind of a new thing are we I would suggest not helping to make this kind of stuff easier I don't think it's particularly necessary for developers You could argue about debugging stuff, I guess And I think there's possibly a kind of a layering violation in the way you're kind of logging the HPK shared secret in that If HPKE was implemented in some kind of more secure way that you couldn't peek in there then you couldn't do this. Now, I don't know if anybody who wants to use SSL key logs cares about such implementations but it wouldn't necessarily work everywhere, I think, is the thing But yeah, bottom line, I know, just like the other thing, I'm against this Kyle. kyle nekritz, I think this is a"
  },
  {
    "startTime": "01:20:01",
    "text": "useful debugging tool, and we suspect what had to be used it with ECH. My initial reaction is, I think this would be a lot easier if we just stuck with the outer client random for the entire connection because it's basically just an identity identifier Chris Patton, really cool work This would be like I think when we were working on ECH this would have been an amazing thing to have. I really like the fact that you can check that the server accepted So yeah, I don't know. I think if we're doing SSH, key log for other things, we should also do it for this. So I'm supportive Yeah, I disagree with Stephen Steven Because this is, obviously, it's a debugging tool. It's not a, oh, I'm sitting on the wire and now I magically can see into the backheads obviously that's not what it is so um i can't sort of share your perspective Thank you yeah sorry I think it's pretty clear we were a little split more towards adopt than not, so we'll take it to the list to try to get consensus on whether or not to drop the draft Thank you. Thank you. All righty Where are we going next? Stopping a queue. Who's next? Agenda extended key updates hannis struggling right now. I keep it short I only have five minutes this time. And I spoke about this topic here already. I got good feedback First time when I presented it, I was introduced to new requirements which totally changed the design I did but along the way I also misunderstood something from the feedback. So I went off in the wrong direction. That's what I presented in Brisbane So you made me change it totally again so which is"
  },
  {
    "startTime": "01:22:01",
    "text": "I'm glad that I didn't start with a formal analysis with the first version because that would have been a six months journey um good so the status is version two uh so here's what we do now uh based on the feedback we use the flex flex extension to negotiate that feature The feature is the extended key update we forward secrecy. We use a message exchange to distribute the key shares very much like the initial handshake would be doing, as it is exchanging key shares Then there's a separate exchange to then trigger the update of the traffic secrets, which deals with the issue of avoiding any race conditions. And we also added then alert message in case Tadapia doesn't want to sort of be bombarded with Keir updates because there's obviously a computational burden The document also talks about how it's forward combat or forward or forward compatible with some of the work that Deirdre talked earlier today about the high it's forward compatible or forward compatible with some of the work that Deirdre talked earlier today about the hybrid exchange because that now that has been nicely integrated with the key share extension and also with the other workshop is presenting about the BQML Chem that can also be supported It's not described in a document or referenced in a document yet because like we just talked about it But so there's a migration path, which was also one of the requirements that I got document yet because like we just talked about it but so there's a migration path which was also one of the requirements that i um got presented in one of the meetings uh next slide so this is sort of a screen from the document, so there's not enough time to go through all the the details on the slides but you see in in the red box you see this initial exchange of the key chip shares, followed by the update of the traffic"
  },
  {
    "startTime": "01:24:01",
    "text": "secrets to instantiate those And yeah, so it's, should be pretty simple, but next slide But there's obviously like also referring back to the earlier earlier presentations in a meeting today clearly something that we need to do and formal analysis for and uh we're working before summer um who is also helping Bras, so helping us too to work on the formal analysis and we had our first meetings already and we started doing prototyping to see how well that works also with the post-quantum crypto stuff, which we find exciting Yeah, with that i'm hoping i'm all the way to uh to the level of asking you now for adoption of that work to move that into an sort of officially into the working group and that's it I think it's extremely important work given that TLS is getting more and more and more wide adoption outside of traditional space within an outside ATF. For example, there is SSH3 I don't think it's within ATF yet that is using quick as a transport and would massively ban it from these because currently is a SSH over traditional TCP can rotate keys but over quick it cannot so that would certainly help main cryptographic properties And the other use cases are industrial environment and some of the other core co-workers have their use cases in the telco space where they replace IPSEC-based VPNs with TLS-based ones jonathan hoyland, Klaugler Have you had any, have you attempted to implement the TLS? flags bit of this yet? Because I had a go at implementing it for the RECMTLS"
  },
  {
    "startTime": "01:26:01",
    "text": "draft and getting the A TLS flags bit of this yet? Because I had a go at implementing it for the rec MTS draft. And getting the API to be something sensible is, well, it was much more difficult than I anticipated. Did you have the same issue here or is it? Actually I started to the new messages that I showed it I didn't assume that things were in sort of negotiated already, so I yet have to do that. We'll do that during the summer. So I will reach out to you and figure out what message I can take away from that. Good that you mentioned it. Yeah so yeah definitely reach out because it's surprisingly challenging okay that's uh I wasn't expecting that if I thought it would be in no-brainer but so did I all right Dennis Dennis um just a one one question so in the draft there's a bit where the keys need to be deleted and you move to new keys and it's currently a should rather than a must And that surprised me slightly in a draft that's about like finding forward secrecy which is all about when you delete those those keys is there a reason why it needs to be a should or could it be a must like We'll have to look at the exact text, but with ephemeral keys, I would assume it's, I would claim that they should be deleted ASAP and only only as long as the duration where you actually obviously need them so I would say probably a mistake. Okay, I think yeah, it would be really nice to tell specifically for the DTLS case where you might have lost messages to get a really clear criteria at this point you can do it and you must do it. So did it, yeah, yeah, maybe it's a it's a wording issue that needs to improvement in DTLS case so there's a also d tls section so in d tls case uh since the messages are sent unreliable, you need to keep stuff around in case you need to sort of resubmit it them in case you don't get the act message yeah but then that can be like a hard cutoff at some point. It would be obviously very sure"
  },
  {
    "startTime": "01:28:01",
    "text": "period of time. Yeah, perfect So, um, so during my chairly duties, are there any objections to running a working group call for adoption on this particular draft? Again, remembering if we adopt it, we can bash it and make it do it All right I will confirm on list or I'll send a working group adoption call to the list and we'll go from there. Thank you. All right I don't know who's up here Who's doing this? Bob, all right, or you're all gonna get up okay cool I would say feel free to move the microphone, but you're supposed to stay in the pink square. All right X I guess the other thing I want to say is that this particular topic has been lively on the list and I want to make sure that we maintain professionalism at all times and everybody minds their piece and keys here So, thanks thanks All right. Hey, everyone I'm Devin. This is david oran Bob and we're talking about a trust anchor negotiation. Next slide Oh, sorry. Oh, I got to really hug this thing thing I can't multitask you know this Okay, so since we last talked about this, I think it was Prague last November, there's been quite a few changes we didn't present anything in Brisbane, so I wanted to give a quick update Based on some of the initial feedback, we got that the lengthy on-list discussion made it difficult to follow all the points that were made and even participate in the discussion we were encouraged to summarize a lot of the things that were discussed and analyze it in supporting documentation So that's what we did. The first thing that we did was we put an explainer document out This covers trust anchor negotiation at a highlight level, and it's a good entry point into this discussion if you haven't looked at it yet The second document that we did is we"
  },
  {
    "startTime": "01:30:01",
    "text": "PGI Transition Strategies Doc This one goes through a bunch of PKI transitions that are relevant to TLS and attempts to analyze how those transitions are impacted by current solutions and how they might be impacted by trust anchor negotiation in response to some of the feedback we got on the complexity, of trust expressions which it is a lengthy draft we also submitted another draft with a different about of the feedback we got on the complexity of trust expressions, which it is a lengthy draft, we also submitted another draft with a different approach called trust anchor identifiers This sort of inverts the flow of this. We'll discuss it in more detail later And that's draft back TLS Trust Anchor IDs And so Bob will discuss that in a little bit And then since primarily Brisbane, most of the conversation up until maybe a couple weeks ago had been centered around surveillance scenarios, privacy considerations, and security concerns So where we were able to directly address the technical security considerations in the draft, we added these two sections to both trust expressions and trust anchor IDs as well as minor changes throughout to address them Now, when it came to the surveillance scenarios in particular, because very nuanced differences in a scenario can lead to very drastic outcomes, we wanted to be very specific, so apologies for the length of this document and how similar some of these use cases are but we want wanted to be complete rather than skip through some assumptions so this document, I think actually it's on the second to last slide. Sorry, there's not a link here. That document covers these scenarios. It attempts to summarize this discussion points raised on list. If we've missed any anything please let us know we want this to be as complete and accurate as possible. And then lastly, we want to talk about maybe some next steps here, given the state of effect Next slide All right"
  },
  {
    "startTime": "01:32:01",
    "text": "So we call this trust anchor negotiation, and what in the world does that mean? So as a brief recap to a problem that I'm sure many of you all familiar with, TLS has lots of parameters negotiation steps such as cypress suite negotiation And the problem here is the client implements some set of cipher suites, the server implements some other set of cipher suites, and our goal is to find a cipher suite that they both have in common and this happens again with curves and basically every other TLS feature and we do this because we need to support cypher suite evolution, right, like different clients like we realize some ciphers are bad, we need to remove them we want to introduce new more secure ciphers, maybe different implement have slightly different preferences on whether to prioritize like key size versus forward secrecy until TLS1-2, thankfully we sorted that one out, or things like this. And so there that we we have this generic negotiation mechanism in the protocol to accommodate all these things. And as a result, the internet can sort of move forward without things being in lockstep. Next slide So trust anchor negotiation is applying the same thing to trust anchors. The way we use certificates and TLS the so we're going to use the example where the client is authenticating the service certificate just because that's where most of our sort of motivations come from, but it's worth noting that you TLS has certificates in both directions and sort of the problems and stuff solutions are analogous in each. But for the purpose of this presentation, we're going to assume the client is a relying party, the server is the authenticating entity. So the client wants to talk to example.com. The protocol TLS can only authenticate based on keys. And the server is authority for example.com and has some key and somehow we need to commit the client of this fact. And so we do this by having CA's sign assertions of this. And so in the in the model that you know we all use in TLS today or any certificate based TLS deployment uses the client trusts some number of CAs We often call them trust anchors in 5280 The server has some certificates available, which attests to its true key and name signed by various CAs. And the trust anchor negotiators problem is simply select a certificate based on what the client"
  },
  {
    "startTime": "01:34:01",
    "text": "trusts. And like with Cypressuit negotiation, we want to do this because this supports various kinds of PKI evolution strategies Next slide So why does this matter? so we're Cyphysuit negotiation we did this because client ecosystems often have variations in Cyphys they support. Client ecosystems in today in TTI and TLS are also similarly have slightly diverse trust models, whether they overlap slightly or very little or sorry, slightly or a lot So for instance, within the same PKI, such as the WebPKI, you often have many root programs and the root programs make independent decisions often they overlap a little because the goals are very analogous but ultimately the decisions are independent they're made at different times, and sometimes the decisions are slightly different Within a root program or within like you know clients with similar decisions, things still diverge over time because the older, when a client needs to go change some of his trust decisions, the older versions of that client still exist and those will have the older versions. And so over time, these will diverge in more extreme cases some constrained devices such as IoT devices, may trust only a smaller set of routes because they didn't have the resources to hold them. They may not have the same update processes that the large clients have and that adds even more diversity into the ecosystem Further specialized clients like mobile apps might do only care about connecting to one server, and so they might do things like pinning which I think there's an RFC for that one. And throughout all this, servers need to somehow navigate it. Next slide And the other point to make it is not only is this the reality of the world it's actually useful that it's the reality of the world Because why do old and new clients diverge? over time? Well, because PQI has changed. And we can solve this by never changing PKIs, but PKK changes are necessary for users security. Sometimes we like we trust these root keys that have the keys to the kingdom for all whole of the internet. And some of them are very"
  },
  {
    "startTime": "01:36:01",
    "text": "old, and when you have a key that is very old, it is more likely to have been compromised somehow. And I think we do not need to explain why I'm an attacker with the with owning the root key of a CA can compromise the user you know we can build things like transparency mechanisms to try to mitigate this harm. But at the end of the day, transparency mechanisms are an after-the- scheme, and so the attacker has still managed to compromise you. It's just that we found out afterwards So rotating root keys is as an example of a change, sometimes CAs need to be removed because they were the older keys or some other trust issues and over time we also add new CAs to sort of keep things rolling forward, maybe to like raise like meet a new security bar and so on and beyond transitions there are also performance benefits to allowing a little bit of wiggle room here. Because if you just not have if you force everything to use the same certificate then the certificate has to target the lowest common denominator You have to send all of the cross signs you need and everything else but if you are able to tailor the solution slightly, for example, to a newer client or to some other property, then you can have to up-to-day clients trust the short-lived what used to be an intermediate certificate directly. You might avoid unnecessary cross signs when you know the CA is already trusted. You might do some parallel issues when the cross signs are expensive due to sort of non-technical reasons why like CAs do not just willingly cross-sign each other And you might imagine even more tailored designs, such as the Merkel Tree Certificus draft we presented a few a while ago that had a sort of bare-bones negotiation scheme and this is sort of the start of this design was to try to extract that into something more coherent a sort of bare bones negotiation scheme and this is sort of the the start of this design was to try to extract that into something more more coherent is self-contained. There's a lot more to say about these sorts of transitions so I invite you all to read that document Next slide All right, so all of this is why the ecosystem's vary a lot. And somehow the server's need to deal with it. So what happens if the servers can't deal with it? When that happens, we have a conflict between security and availability"
  },
  {
    "startTime": "01:38:01",
    "text": "On the security side, we need to be able to change the PKI as needed for user to meet user security needs, but at the same time, the server's goal is to satisfy all of its supported clients And you can, as a result, run into conflicts. For example, if one client removes CA1, and supports CA2, then you can say, well, you should just use CA2 or one of the other supported CAs. But the server also needs to support some other clients, which only supports CA1, this might be because the other clients are older or perhaps some other reason And some, and if there's no more interesting, between the two clients, then the server is sort of stuck in a bind and as a result we need to sacrifice one of security or availability. If we sacrifice availability, then the servers have to drop support for these older clients, and if we sacrifice security, well, then the PKI changes either do not happen, or they take a while we wait for the entire ecosystem to catch up and some of which are like constrained IOT devices that will not And I think anyone who sort of worked in this space can tell you when there's a conflict between availability and security it's secure it devices that will not. And I think anyone who sort of worked in this space can tell you when there's a conflict between availability and security, it's availability that wins. And as a result, the casualty of this conflict is user security And sort of if you think about it, this makes sense because if you match the number of parties involved here, the client is saying, OK, well, I need to make this change to make my users secure and then the server is saying well i need to get this working because I need to drop those clients, and so somehow client one needs to tell unrelated server that to tell the server to drop these unrelated clients and it's just like not a reasonable conversation to have if you have negotiation we have another option the servers can use both see tell the server to drop these unrelated clients, and it's just like not a reasonable conversation to have. If you have negotiation, we have another option. The servers can use both CAs, and depending on the clients, send the correct one Of course, there's still some cost to this. The server needs to maintain relationships with both CAs. We might be able to automate this in various ways but ultimately there are two certificates being stored but this at least gives you a way out of this conflict Next slide So to recap, the goal of trust and negotiation is we want to enable server to handle client diversity so the server availability does not conflict with our PKI goals, security, performance, and so on"
  },
  {
    "startTime": "01:40:01",
    "text": "And in sort of thinking through this problem and looking at the use cases we've sort of identified some properties that we want our solution to have We need to make sure that the overall goals, the PKI transitions, should not impede server availability We want, as a result of this, that RUB programs can make timely security decisions on behalf of the users. Throughout all this, one thing to keep in mind, is that in most TLS deployments, there are far more server operations in CAs and Root programs, and so where possible we want to minimize server operators burden And so that is why our draft has things like an Acme extension for the CIS to send multiple certificates that's really orthogonal to our draft but we sort of put it in there because it's sort of part of this like, overall deployment story and in the in service of like reducing server operator burden and because all of these mechanisms need to ultimately be implemented in the service option to deploy it out and rolled out we want to as much as we can is better to have fewer mechanisms that cover the whole problem rather than a bunch of independent mechanisms that cover pieces of the problem, might not cover all of them, and now we need to like how these all combine, we need to handle the client servers that only support half of them we might need to do several rounds of updates and so if we can sort of capture the problem in a crisp way, like we've already done with cipher suites and other TLS parameter negotiation, things get a lot tidier And of course, as we transition to PQC with a horrific giant signature, we really want to minimize bites on the wire and this is all covered in a bit more detail in the explainer Next slide. And then I'll hand it over to Bob to talk about the Don't die Don't die, we like you We have, nope, I have to stand in the box. I'm a walkie talker, so stay on my feet to the floor We do have two approaches here We brought in another one to make a very much simpler version of what we still want to achieve So starting up front, there is a way already in TLS to do certificate negotiation, to ask the server for what you want. It's called certificate authorities. The biggest problem is"
  },
  {
    "startTime": "01:42:01",
    "text": "what it sends is just too large. It's sending a subject it's 100 bytes on average, and some PkIs have many CIA, possibly hundreds So there's two approaches, trust expressions we've already presented mostly in Brisbane. It's been out there. Trust anchor IDs is recent. Next slide Just to recap trust expressions, the clients in trust expressions express a CA list as effectively a name with deltas They're pre-provisioned with this. This is knowledge they get from their route program, and that's maintained with the CA. The server receives trust anchors, server receives certificate chains from their CA with metadata added on to know which trust expressions to match. Most of the complex here is between the route program and the CA, and that's why the documents very long But in the end, this is a TLS extension to ask for a trust anchor via a name and to match one via a name between the client and the server. Most of the end, so next slide Cinker IDs are a way to basic let's take certificate authorities and change it to be more useful. The first problem is the names are too large the solution is pretty simple, we just make shorter names We allocate via any mutual agreeable mechanism between clients and servers an OID for each CA So for each trust anchor, we just allocate an OID under a relative, under a private enterprise number. If you do it, sanely, should be about five bytes per CA, maybe a little more, maybe a little less, depending on the actual number allocated You configure the server with, the server will get these identifiers by the certificate property list the same way we have outlined this happening with trust expressions And the client just gets configured to know the trust anchor IDs for each of"
  },
  {
    "startTime": "01:44:01",
    "text": "the trust anchors that it trusts from its report program. So we define a new trust anchors TLR extension that looks more or less just like certificate authorities, but carries trust anchor IDs instead of the full subject. Next slide The difference here is that we do end up in most situations being server offer and client select we don't want to send the full trust anchor list or we want to not require you to send the full trust or anchor list. There might be client bandwidth or there might be privacy concerns about exposing every the client actually trusts instead we use a retry in the same style as encrypted client hello after the server can offer its full list of trust anchors So the client may send an empty extension or a subset if it wants to make a guess at what the server might have No matter what happens, the server decides to then send its entire list of trust anchors that it has in the encrypted extensions message and handshake At that point, if the client looks at what it gets back, from the server and it can't use it, or if the server hangs up with an error, the client may then take what was in the encrypted extensions, look at this, say, I want this one and make another connection requesting something the server actually has hoping for a match on the retry One of the things that we don't like about this is that you actually have to implement a retry mechanism It's possible to consider work to possibly do this retry flow within the handshake, but we've not done this in this draft right now. That would be something to possibly bash around with the working group if we wanted to consider it. Next slide however to avoid the retry latency in entirely back to the will this just be used for uh sorry, Rich the retry flow that adds latency. So instead we could list the available list of trust anchor identifiers in the D be used for, sorry Rich, the retry flow that adds latency. So instead we could list the available list of trust anchor identifiers in the DNS by an HDPS service B record"
  },
  {
    "startTime": "01:46:01",
    "text": "The clients would look this up for an additional prediction in a trust anchors extension At this point, the DNS could be stale the DNS could have the wrong information in it compared to what the server actually has. So at that point, you would only use the retry flow to repair a misprediting when the client gets the wrong answer from the DNS picks incorrectly, and you have to retry with authoritative information from the server itself And this obviously has a server operation challenge to keep the DNS and the TLS configuration in sync Hopefully we could use the method already in draft by this working group to solve that problem. Next slide So here's the side-by-side comparison with trust expressions and trust anchor identifiers One of them only expresses group program trust stores. Trust anchor ID supports arbitrary CLA lists. It's usable by anybody without having to define a root program if you will relationship trust expressions is analog it works for both client and server certificate negotiations. With trust anchor ID the retry flow is really only possible with server statistics because of the way TLS works today. For deployment mechanism, servers use just static configurations from CAs and trust expressions. Nothing really changes But servers need to synchronize TLS and the DNS for the best performance and trust anchor IDs Root programs can work really changes. But servers need to synchronize TLS and the DNS for the best performance and trust anchor IDs. And root programs coordinate with manifests or route programs just have a static manifest where they just put an identifier on each of their trust anchors Privacy concerns are sort of a flip of each other The client CA list is passively observable in trust expressions, assuming the trust expression is publicly known. You know what trust anchor set this client is using with trust express"
  },
  {
    "startTime": "01:48:01",
    "text": "It's not in trust anchor ID You actually have to actively probe it The server's list of certificates would have to be actively probed with trust expressions, whereas presumably if the server is putting its trust anchor list in the DNS it's very publicly visible in the case of trust anchor IDs. The interesting thing is, is both of these mechanisms can exist together, and they can the DNS. It's very publicly visible in the case of trust anchor IDs. The interesting thing is is both of these mechanisms can exist together and they could be used in conjunction with certificate authority So you could have one or the other or both or all three Next slide Okay, so circling back to the security considerations that we discussed earlier, as I mentioned, we've updated the drafts where specific techniques points were made and these were addressable Things like speculation on how policymakers make decisions in light of this don't really fit super well in the draft Texas itself. So we've written a support document on top of that I will say that not that number of words is an indicator of quality in any matter what whatsoever, but the supporting documentation now is nearing around 13,000 words So we are doing our best to be holistic and complex any matter whatsoever, but the supporting documentation now is nearing around 13,000 words. So we are doing our best to be holistic and comprehensive in responding these things, and I will once again say if there's any analysis here that's incorrect or incomplete, please let us know our goal is complete and accurate analysis And next slide, please please So to wrap things up, we have to propose two approaches here to solve trust-acre negotiation understanding that these are pretty weighty drafts given some of the non-TLS complexities involved If you've read them, thank you. We truly appreciate that we our primary purpose"
  },
  {
    "startTime": "01:50:01",
    "text": "of talking here today is that we're looking for feedback from the working group on preferred approach. We've put forth two different ways of solving this problem and we are always welcome for feedback on List or GitHub GitHub issues are actually very easy to track and address directly And finally, we want to sort of open the issues are actually very easy to track and address directly. And finally, we wanna sort of open things up for discussion. We would like to take the temperature for just general preferred approach in the realm of trust anchor negotiation in TLS. And based on that, sort of feed as input to our call for adoption strategy down the road Thanks Paul. Thanks Paul. Let's keep a professional, all right? Fine, fine In Ikev2, actually in Ikev1 we also had this problem of certificates being too big and there years ago, actually it's the worst because we were stuck to a UDP packet. And there we actually chose to do just a hash of the CA And then if you really only want five bytes, you can hash this hash it and this truncated to five bytes i don't know why you would go to indirect way of getting OIDs and going into Deadwoods to get a unique identifier The decision to go to OIDs, was something that was just a first attempt at truncation. To be clear, we were just trying to shrink this down to size. It's something that is assignable. It's also managing the authority And when it comes to trust anchors, there are multiple different like the hash will differ based on nuances within the certificate itself. And so this could be something that could be tracked commonly commonly with a sort of a central not managed by us authority but we're open to other suggestions in this space if it's uh it's better all right so just time check We got 10 minutes and we got, I don't know, 8, 9 eight, nine people in the queue, so keep it really quick. Thanks"
  },
  {
    "startTime": "01:52:01",
    "text": "Alessandro Gideon, Gideon, Cloudflare. So my sort of gut preference would be for the trust anchor IDs, you know, just put stuff in the and what could possibly go wrong But I have a couple of questions for you. So you say that, you know, for trust expressions, most of the complaints between the root program and the CA which I guess works fine if you already have a root program already But say, maybe I am a guess works fine if you already have a root program already, but say, you know, maybe I am a mobile app and I want to do some keypinning I guess that would require me to have those relationships with the CAs, is that or because I would need to sort of communicate some kind of trust or ID that the CA would then communicate to the server or the subscriber So the question is if you have only like one or two CAs because you're doing like a pinning thing Yeah. So you're right, like trust expressions does not handle that one as well That's part of why they sort of coexist so you could, if the CA's if you're okay sending you know to one hundred names, you could just use the existing sort of big authorities extension Or, you know, we could do a bit of both and do the other one. So, because like when you only have to, when you only have like a few, it's sort of the problem's easy. You're just trying to list a couple of them and move on with life. It's the trust expression and the sort of complexities around having to invert the selection there being like. Yeah, I guess similar question for like client certificates i guess we we do already do you know the certificate authority extension for that it's slightly an all because there could actually be, you know a few of them and those bites could still add up um but sure Yeah, so trust not care ID is for the non- non-inverted case works just fine for client starts as well, so you could define the shorter names and you know right yeah yeah i see that as a sort of optimization for the existing"
  },
  {
    "startTime": "01:54:01",
    "text": "extension, right? So that, again, would be my problem Chris Patton with my security of transport at the lake of the transport hat on Question for Bob is the retry mechanism significantly different from what we have for ECH today? I don't believe so So I think I know NSS, Boring SSL, and a few maybe a couple of other stacks, probably rustles by now probably has this already, so I'm wondering how much of a lift that would be for people. A full retry in an application where you have to open a new connection that's beyond the scope of the TLS that that is occurring sits, which is one of the issues. Yes, yes But we have the same issue for ECH um so with that said um i would i i slight preference. I think Anchor IDs is heading in a better direction So that's with that trust anchor ID is good even with the retry I think it, yes okay then Schwartz how do you imagine this handling horrible enterprise TLS interception? scenarios uh and also like less horrible Charles proxy like debugging T how do you imagine this handling horrible enterprise TLS interception scenarios and also like less horrible Charles proxy like debugging TLS interception scenarios? Sorry, could you, when you say the horrible TLS interception scenarios are, is this in the case where a client trust a misbehaving CA or there's a misissued certificate involved? No, no, I'm talking about the case where the client has been configured with an additional C that's only used locally and is outside of any route program So without making comments as to the desirability of such configurations in that kind of environment where you configured the client to trust a like terminating"
  },
  {
    "startTime": "01:56:01",
    "text": "proxy, there is only one CA, and so this the the server quote unquote server the terminating proxy just always sent you that certificate so it didn't really matter. So like it doesn't interact in that, like, they didn't have this problem to solve in the first place I know, the question is just, what am I supposed, what is the client send oh okay so you're asking whether the client like what's the client will send yes so that the discussed in the privacy consideration section of the two drafts but broadly, if you send the thing you have sent the thing so you should only so you don't have to have all of your roots participate in these designs, you can choose to emit some of them, and so in the trust expressions model, we were envisioning that you would sort of send you know, the built-in ones in your browser or something analogous for whatever your other client is. And you wouldn't send the user-added ones because at least without some clear signal from someone authoritative who owns the device, like that's a privacy leak. Okay. Does that require? some kind of new interface between the operating system and the browser to understand which of these see, operating system CAs are like global part of a root program and which are like weird local ones so this depends on exactly what the like this is some operating system specific on some systems so I guess I can speak to what Chrome did Chrome used to use the operating system list and then switch to using its own when Chrome switched to using its own of course like it's very obvious which one came from Chrome and which one came elsewhere When we use the operating system one, the were various APIs to tell the difference Some of them were more janky and some of them were less janky so depending so I guess in the case of trust expressions, there's already necessary that the operating system provide you this trust expression information. And so if it's already able to do this presumably it's also we can like use that same time to extend it with whatever is needed but broadly it was already kind of possible But in general, we do assume that the clients know something about what they trust and can make decisions"
  },
  {
    "startTime": "01:58:01",
    "text": "accordingly. Thank you. And I can add that on the trust anchor IDs side, the sort of decision is less stressful because it requires active probing, though we might still, like, you could still imagine the client by filtering down. So just to make sure we get some input back from the working group. This is a big if, if we were to do this, which one would you prefer yes would be the trust expressions and no would be the trust anchor IDs. We can keep doing this but Kyle, go ahead. We're definitely running on time though kyle nekritz, so first I want a second the point about the availability taking preference over security in these cases The other way around that is to deploy a really unfortunate mechanism of negotiation like client hello fingerprinting, where we take a non-examination signal if we say we're not going to do anything in the space, I think it's inevitable that that's what's going to happen so I think it's very important that we do something here on these two drafts I think I have a slight preference to the trust anchor IDs, although I'm quite concerned about the retry mechanism but I won't go into the details due the time have a slight preference to the trust anchor IDs, although I'm quite concerned about the retry mechanism. But I won't go to the details due to the time. Watson. Watson, I really think we need an interim or something to talk to these issues There's a bunch of complexities we haven't even touched on for some like command line programs using Debbie and through structure copied out of Mozilla's, but you don't know anything about the case capabilities. I just think we need a lot. There's a lot of detail here we don't have time to talk about now So I think right now we're just trying to get a general sense of which way to go. And I think it's definitely trending towards the trust anchor IDs. That definitely gets us going. We want to have an interim or something else, I think we'd want to make sure we get the documents edited first. But thanks Andrew Andrew Chen trust trust expressions makes a lot more sense to me. It seems to it's very parallel to the world where as a server you're trying to probe a client to try to figure out what it supports just by like doing J it seems to it's very parallel to the world where as a server you're trying to probe a client to try to figure out what it supports just by like doing j3 fingerprinting type of thing this just makes the whole thing a lot more explicit so the client can tell the server exactly what CA is I support and then as a server can pick"
  },
  {
    "startTime": "02:00:01",
    "text": "really easily. The retry aspect of the anchor ID worries me. It makes setting up a TLS connection come so unpredictable as to how long it will take and if you're doing things that are latency sensitive, that's it seems like I would actively avoid anchor IDs to avoid the kind of non-deterministic connection time All right. At the close, Farrell, you get the last word. Oh, well, let's not do it So I interpreted a no opinion there as many don't like either the time. All right, at the close, Farrell, you get the last word. Oh, well, let's not do it. So I interpreted a no opinion there as many don't like either of the both. I think before I think we was raising the list by Tim, before doing this kind of stuff, I think we should think through what we think the dynamic, the long-term dynamic of interaction between the TLS protocol uses and the route programs and PKI should be. I think for various reasons, we should do that for between the TLS protocol uses and root programs and PKI should be. I think for various reasons we should do that first, I think, before we think about whether to address this and if so, whether to base as starting point on either of these approaches. That's why it's a big capital F there at the beginning. So, yeah. All right Thank you That is it. Thank you for attending the TLS session We will be in touch. Russ, if you're still in the room we'd like to talk to you Well, there was a show of hands, and just to be clear that for the minute that in terms of picking, whether there was trust express or trust anchor IDs, that it was 20 in favor of trust anchor IDs and six in favor of trust expressions and 12 no opinions I don't think Russ is here, I think he left Thank you Yeah"
  }
]
