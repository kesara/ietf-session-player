[
  {
    "startTime": "00:00:30",
    "text": "Can you hear it? Okay. Where is the work? Thank you somebody's message with us Testing, hello Hello, no, no, no, no, no, no, no, no, no, no, nothing still no, no, no, no, no, nothing still. Hi. My name is, whoa, there we go Are we good? nothing still. Hi. My name is, whoa, there we go. Are we good? Yes, thank you very much. Yes testing testing Oh, is that right? If they can just outside of icy that okay? Hello, hello, low, no, no, no, no, yeah okay"
  },
  {
    "startTime": "00:02:06",
    "text": "All right, I think we're good. Charge us up we're good, charge us out. Yes, we'll start them right, I think we're good, charge us out. Yes, we'll start. Hi, everyone welcome to Vancouver or at least those of you that actually are here this is PIM at IETF 120 120 So I've been told that we should give you enough time to actually read the note well more or less So yeah, please have a look at the note valve slide here I hope you all are familiar with it. So these are some important policies that we should all know about Thank you this is the agenda. Any comments? on this? It's a much shorter agenda this time for some reason than what we had the last couple of meetings david lamparter, I'm not sure if it's part of the agenda. I do want to point out the route alert discussion that is happening on the mailing list. I don't think it needs to be discussed here and there's probably nothing to be done about it But if you're not aware of it, there is some MLD versus router alert deprecation thing. Maybe read the email and that's it Yeah, I'll mention it briefly soon. Yeah, okay thanks so i'll do a little status update to the different working group drafts. So we have this BIS documents for IGMP IGMP-Everson 2, sorry, V3, and MLD MLDEWerson 2 and IANA requirements So these are all you know, they have all gone to the IESG Yeah, I hope hoping those will move forward easily"
  },
  {
    "startTime": "00:04:01",
    "text": "One thing here is with MLDV2S was just mentioned, in MLDV2, we are usually move forward easily. One thing here is with MLDV2, as was just mentioned, in MLDV2, we are using a router alert, and there's some discussion about deprecating router alert So some people potentially want to you know, maybe remove router alert from MLDV2BIS, but yeah, people may have different opinions about that, but one thing I feel strongly about this, at least that you know, it's would be bad to have a bit like progressing to Internet standard if existing implementations would not be compliant. But yeah, I'm sure there will be some discussion about this and we will hear about IESGs is saying and there's some emails on the mail list as well We're also revising the what this is called host stack requirements for multicast or whatever it's called. Thorless, we'll talk about that later later um so we haven't requested publication on that yet and we haven't done the last call yet either, but we'll see how that progresses But the other main thing with that is really to mention IPV6 and also as SSM. Got those things didn't exist when the first, when the RFC 11-12 was written. Okay we have some DR-related drafts We should figure out if we actually want to work on those things in the working group? And if we do what? should be the path forward No No, he's not. Otherwise, we have a bunch of documents we requested publication for so not just the BIS documents on the previous slide, but also"
  },
  {
    "startTime": "00:06:01",
    "text": "point-to-point policy The policy ping has passed last calls. We'll request public for that shortly like this week or so PIMLID requested publication LISP extensions as well, and the AMI for our draft also So lots of documents leaving the working group group of course there's always a chance that you know IESG or so on will come back and we will have to do some more work on some of them but hopefully not And some yang models that are not being discussed today Lessons learn this on the agenda And finally, we have some documents related to zero XeroConf, and one of them will be presented and discussed today All right. Any comments on this? and the questions? Yeah, thank you we'll move on to the first presentation presentation Okay, hello again everyone. So this is a new working group draft. Thank you for your support. And the course of the way is Luis Terponica. Next please Yeah, sorry I can just make one comment. So I see what I forgot to add to the working group slides is that yeah we just adopted this document and we also adopted this PFM extensions document. So I should have put those on the slides but uh okay sorry"
  },
  {
    "startTime": "00:08:01",
    "text": "go okay thank you very much so this book will also the page i already mentioned a put those on the slides but okay sorry go okay thank you very much so this book along the page all I already mentioned in the previous meeting so we definitely trained to support multiple upstream interface, so called March forming or march pass supported by MLD, IGMP PLUCSI. Okay, next please So the overview of this draft is we propose the extension that allows IGMPMR proxy devices to receive broadcast sessions or channels through the different apps upstream interface. Of course, the downstream interface, we have a receiver, multiple receivers, so only the extension allows to add the functionality to support multiple upstream interface. But so so-called we now, it's Marchforming. So the intent status is informational because there is no protocol message extension in this draft, but actually our different draft that will include some functionality to change the dynamic configuration based on the some conditions How, which upstream interface is good for the current status and so on. So that kind of protocol extension will be happened later, but this draft itself doesn't provide any protocol or message extensions. So that's why it did status is informational. So we have two major main sections One is upstream interface selection and the other is upstream interface configuration. So upstream interface selection, we have two methods subscribe upstream interface selection and the channel upstream interface selection Either selection mechanisms can be configured with a two main configuration One is address prefix record the other is interface priority. Interface"
  },
  {
    "startTime": "00:10:01",
    "text": "Priority enabled to select either interface takeover or robust data reception I will talk about them later. So, and this draft interface dynamic upstream interface configuration as I may mentioned earlier. But just this introduced the signaling based upstream interface configuration like NIDPMLD Prochnoka extension, and also provide SDN-like control-based apps upstream interface configuration. But again, this is just a interaction, so the detailed specification may be in a separate draft Next week. So this is upstream interface selection mechanism. So we have two way to select the upstream interface. One is subscriber-based upstream interface One of multiple upstream interfaces is select from candidate upstream interfaces based on subscribe address prefix. And the other is a channel-based upstream interface selection. One or multiple upstream interfaces is selected from candidate upstream interface based on channel or session ID And the source address prefix is prioritized So both subscribed by based and channel-based apps upstream interface selections can be called existed However, however, subscribe by best appellate interface selection is prioritized So, and also we can use a default app upstream interface if there is no configuration or long configuration Next please can configure such kind of upstream interfaces? The entry of the address preface-6 record consists of subscriber address prefix six and channel or session ID, where channel session ID is a source address prefix and multicass algorithm prefix. So the as a example, I can show here that the possible combinations by interface can be receiver"
  },
  {
    "startTime": "00:12:01",
    "text": "address or prefix, S and G, receive s star, receiver star g, star s g star s g star s g and all stir. So this is a prioritized order So the and the interface priority also can be specified or config for interface takeover which means that one interface is usually activated and the other is in a standby mode But if something happens, then the address ups upstream interface takeover happens So in that case, maybe the other P6 record has, so several or multiple interfaces have the same address prefix record, but the priority values should be different So the one interface is usually active there other is standby. And if we have all the same address prefix record, configuration and the lobster, sorry, priority, values, then we can use both This code is Lobster data reception. So use much multiple interfaces. If both address prefaces record and the interface priority are identical. In that case the proxy device itself can send a join or subscribe message to multiple upstream receiver, sorry, multiple upstream interface via multiple upstream interface then the same content comes from both and the proxy device can select which should be forwarded to down downstream receivers. Next please So we have one potential misconfiguration So for the subscriber-based upstream restriction This happens mainly we have potential misconfiguration. So for the subscriber-based upstream restriction, this happens mainly when we have a shared link for"
  },
  {
    "startTime": "00:14:01",
    "text": "the under downstream receivers. So upstream interface selection per subscriber receiver aims to differentiate receivers based on their contract or other matters or considerations However, so look at this figure the left-hand figure. So this is a maybe something like a regular case So some provider won't to distinguish the receiver in this figure receiver one, receiver two So the proxy devices, this proxy device configured receiver 1 one is prioritized because of some contract. So here's a joint message is sent toward Lead Cloud via interface 1. And the interface 1 may have a higher bandwidth. And the receiver 2 may have some, let's say, something like a flea contract, and then is interest message sent to interface via interface two so this kind of business model happened, but if the receivers, these receivers are on a share link, even though the receiver wants a joint message is sent toward the interface one, the contents coming from interface one can be shared with the receiver two. So this, of course, happens if the downstream links is shared link is shared. So that kind of scenario we need to clarify. But well this happens in several cases Next please. So the next step is we definitely need to define the different, therefore, active in Tauber to detect an in inactive upstream interface for interface takeover Because currently, what time is the best time for"
  },
  {
    "startTime": "00:16:00",
    "text": "detect the activate or activate or inactive interfaces? So currently, there is no definition. So we will consider much, take carefully consider the some time when the interface the doesn't, oh, is that on. Yeah. Okay. Coming back. So this kind of timing we should definitely define as of course guideline should be tuned So it should be tuned. And we also need to consider interaction with signaling methods we have been also working or thinking about protocol extension how dynamically select the best upstream interface using IGMPLT protocol extension And also we need to request updating IGPMLMLD proxy young model but this comes after maybe publication Okay, so, so, so, okay you David Lumputter. I'm not quite sure I don't understand how this works if subscribers have more than one prefix. Is that a concern here? Subscriber, so receiver has a if they have more than one prefix assigned to them for Unicast, like if the address, do you need that for identity? i i'm not sure i completely understand what the interactions here are are um i maybe i cannot catch you a point but anyway, so Le SIABer, so maybe i cannot catch your point but uh anyway so let's see where uh so the device proxy device can confide So categorize, though, distinguish the receiver some receiver is a paid customer. Some receiver is not a paid customer So, so in that case, we can configure this"
  },
  {
    "startTime": "00:18:01",
    "text": "paid customer should be prioritized So if we have multiple products streaming interface, the first one is, for example, high bandwidth, and the second one is lower bandwidth So we can categorize based on the such kind of contract So it's not, well, this is an aim for defining such kind of a receiver or others prefix Thank you question I don't remember now, but do you have any discussion about using Unicons? routing to decide on a prefix? Like for SSM, you could choose potentially upstream interface based on what has the best Unicast route What do you mean that the Unicast route? So Proxy device has a Unicast Cloud 2 Yeah, yeah, let's say, you know that yeah the proxy has like a unicast routing table. Mm-hmm. And so it knows that, you know, for certain Unicast prefix interface, one is the best and some other prefixes some other interface right toward s yeah you're asking toward this yeah uh there is no consideration about the towards S. So this is just a configuration for the list receiver side so if you have us some best path toward S, then usually, oh, okay So this kind of scenario must be mentioned in this draft yeah just just a thought i think it might be useful so I think you know what what you are the defining so far is maybe more like a static configuration that certain flows should go a certain interface Well, if you use the routing table, it can be more dynamic but i know the problem is, of course, that you may have many interfaces, and what is best for Unicast may not be best for multicast"
  },
  {
    "startTime": "00:20:01",
    "text": "But I think it could be uh could be okay i understand okay thank you thank you yeah okay guess one not Yeah, okay, we're going to say. I guess one other thing, too, is potentially with embedded RP You know, you know have an embedded RP group, you can see what is the RP address and which interface has the best route towards the RP okay okay potentially. Okay, I see. Okay, I see. Okay these things were discussed on the mailing list recently was which interface has the best route towards the RP, potentially. Okay. Okay, I see. So some of these things were discussed on the mailing list recently where someone was asking about host behavior when someone joins, you know, when there's an MLD join on a host and the host has to decide the interface And I think the same can apply to a project Okay, got it. Okay. Okay. Thank you yeah i will consider it thank you Thank you. Thank you Okay Hi, I'm Stigvanas I'm going to present this draft on PFM enhancements. So I've been this couple of IETFs have been presenting two different drafts related to PFM And at the last meeting, there was a suggestion to merge the two drafts into one and we have done that. And the merged draft just got adopted a few weeks ago, a few days ago. So yeah next slide So the two drafts that got merged into this one, one is about forwarding enhancement I'll talk a little bit more about that, but I have presented that in previous meetings as well. And the other one was"
  },
  {
    "startTime": "00:22:01",
    "text": "defining sub-tLVs The sub-tLV draft also had like one specific sub-tlVs on bandwidth but as suggested we have removed that for now, so it doesn't actually define this sub-tlv, it just introduces the sub-tlv concept Okay, next slide Right so for the sub tlv um the idea is that you already have a TLV for announcing an S-coma-G. But if you want to have any kind of additional information about an S-coma-G there's no easy way to kind of say which of the S-coma-G is in a message this applies to The most natural way or pretty much the only way I can think of, is to allow for sub-tlves so that you have an TLV that defines an Escomagy and that TLV can have sub-TLVs that can have any kind of information that we think is useful for a particular flow Next slide, please. So here is how it's defined today with basically just S-coma-Gis or a group and then a list of sources kind of like the PIM joint format. Next slide and the news the new TLV that I'm proposing is basically I simplified a little bit here with just the group and a source, not a list of sources And then you can have sub-tLVs that can have various properties about this particular flow Yeah, Band-Diff could be one, but there can be yeah, there's a lot of possibilities here here So, yeah, I don't have a list of sources here partly because I think it's unlikely that you have the exact same additional"
  },
  {
    "startTime": "00:24:01",
    "text": "flow information for multiple sources and also just to make it simple to parse The downside is that you are using a little bit more space in the packets if you have many sources for the same group as you have to repeat the group address. Next line. And then the other part of this combined document is the flooding optimising The basic idea is we have an existing RFC where you can announce a router ID in PIMHELOS and we can use that so that if we have multiple links between two routers, like we see in this diagram here with three links, we can actually know that the router is sending PIMHellows on each of those three links are actually the same router So there's no reason to announce the same information to that router three times. So the simple idea is, if you have this case, let's just send it once on one of those links The only problem is that normally they're receiving routers are RPF check and would only accept it on one of the links and they don't know which one So another part of this optimization is that you do a relax RPF check. So you do an RPF check, you find one of these interfaces You check what's my neighbor on that interface, it's router A And then you say, okay, in that case, I'll accept this message from Router A regardless of what interface it comes on it just trust that Router A is not going to send it multiple times Okay, next slide I think this is pretty much explaining what I just said So that's all I have for now It's more or less repeating what I presented before So we're looking into doing a prototype of this just to, you know, see that things are working well"
  },
  {
    "startTime": "00:26:01",
    "text": "in practice If anyone has ideas for, well, any comments on this, things we should do differently or ideas for how this can be useful like the sub-tLVs, please get in touch bring it up on a mailing list Thanks This is Dino, in your diagram with the three interfaces, could you send joins over all of three of them? for like in a MOFR type? mentality? Yeah, you're not suggested But you can send joints on all of them. So you can say this announcement, you should only receive it once ideally not like on each but you can still send joins on any link that you And the upstream router knows only to forward on one No, you will actually, you can say this is just for learning about the source The actual join can be sent on any interface. We're not changed the logic. Oh, okay. That's what I was wondering about that. Right So you could say for MOFRI, right, you want to use a hash or something or, I mean, even general PIM, we want to use a hash to spray it out and that's the same as before One thing, I guess, I've been wondering is whether it's useful to do this for BSR or if it's not just worth it but it could easily be done for BSR if we think it's good Okay, yeah, thanks Thank you to say it all right here. Huh? Oh, yeah, yeah, right advance? Oh, yeah, that's yours. Yeah, we're ahead. Let's get your luck That's small font So this is the draft we've been working on for some time now We update it before every IETF with some new topic just to describe a variety of"
  },
  {
    "startTime": "00:28:01",
    "text": "protocols used over the years, why we make no longer use them, and in some cases why we still do it's already proved useful for me i used over the years, why we maybe no longer use them and in some cases why we still do. It's already proved useful for me. I had someone reach out to me recently a pretty famous engineer that you all know who is a professor and they wanted to just know what the latest is with protocols, multicast protocols, and so I just forwarded this draft to him just to kind of give an update of what's been going on and it proved helpful double. So this is the one in red is the one we add just recently It was suggested by Atoshi last IETF and that is just group address allocations. So we added a little two-paragraph section on that topic. Next slide So this is that didn't format very well but this uh just the text from that. We just go over just really brief some of the previous approaches to multicast group allocation dynamic multicast group allocation. There used to be a working group called Malik, multicast address allocation which I don't remember very well, but some of you probably do, so we may be able to include some more information about that, but that's where MadCats was specified along with some other And so we just go over that a little bit And then I get into next slide, maybe the next couple slides Yeah, next slide next slide yeah next slide yeah so then we just go over something that Nate recently revived in the last year and that is just some new ways that we can do this dynamically without any configuration in a decentralized way. And so we recently revived in the last year and that is just some new ways that we can do this dynamically without any configuration in a decentralized way. And so we've come up with a couple solutions. Zero comp and gap which has been presented several times and just kind of go over those solutions a little bit And then"
  },
  {
    "startTime": "00:30:01",
    "text": "next steps are, you know, we've been just focused, we were just focusing on major issues and lessons learned and didn't plan to include all protocols but Greg actually mentioned in a couple meetings ago that it was just focusing on major issues and lessons learned and didn't plan to include all protocols, but Greg actually mentioned in a couple meetings ago that it would be good just to include them all. So we agreed just to cover everything that we can come up with. So this will be something that we'll be working on for quite some time, but we are making steady progress. Thanks again to Hitoshi He mentioned the last one. The next one that we think we could probably come up with is reliable PIM, like include port reliable multicasts in general. So that's pumping something that we'll add. Greg Yeah, just I haven't read that section, but I don't remember is STP mentioned anywhere? Yeah, it is. There's a section on this Is it in the address allocation or is it just? On its own Interesting, okay part of the story. Yeah, yeah, it is. And we can, I'm sure expand upon it And that's another good point. You mentioned story That's kind of what we're trying to do is just create a story of the history of Multicast and it seems helpful so far. Any questions or? suggestions on other topics going forward? besides what I already mentioned? Okay Hello? Yes Yeah, so I think to go along with similar to what Greg said, I think the new section is good, but it a part of the story of addressing. I think it's would be good to tell the whole story of addressing from you know, the ad hoc list, the ad hoc blog that SDR used to Glop. Great you know, the ad hoc list, uh, the ad hoc block that SDR used to Glop, uh, great to know where Glop comes from because it's not even a acronym. I've always wondered that There's the Unicap. I do Unicast-based"
  },
  {
    "startTime": "00:32:01",
    "text": "you, Unicast-based, multicast-prefix stuff uh you know the 232 234 slash eight stuff Um, there's, uh, you, and, and then also, talk about SSM, how SSM in many ways made it all moot. It solved the addressing problem at least for SSM. So I think you know, a broader story of addressing in general would be good where this fits in And I think in the text, you, you can Madcap briefly, but I think it would be worth covering also, you know, MAS and MDNS and, you know, that malice stuff was was a little bit before ahead of my time as well. I was just starting when that those things were happening so along with Greg's spirit of let's let's talk about everything I think we should talk about MASC and Maloc So to that point, Lenny, that this story, I have written, I'm still writing, I still have a bit In my version, I don't have this text, that's all four in section three is the narrative that references each one of those As for Glop, that was peer Lothberg came up with the idea, Fetter to Meyer, we went to coffee that morning and he liked Glop as a name and asked us to find a way to make the acronym work And we never did and that's how the IETF works Yeah, okay, thank you. Yeah, so to Lenny's point and Gregg's, maybe we should have a section just on address in general with some sub points related to that. So maybe we'll figure out how to format that and include those And failed acronyms. Yeah, and failed acrony okay thank you All right Nate, you're up"
  },
  {
    "startTime": "00:34:01",
    "text": "All right, can you see me okay? Let me pull up your presentation I've got a demo I can run, actually too, so I can run the slides here Or we can give it a try Whatever you prefer Let me go back tried Trying to like Treadsharing Okay, here we go So I mean you can see that? Yeah Okay, great. All right, so these are updates. Sorry? Can you go into a slide show to make it bigger? Sure Yeah. Kind of do of. There we do. Perfect. Okay. All right So primarily today, rather than discussing the document we've done that mostly in the previous meetings just going to discuss some recent discoveries and some updates that I made to a couple for those So just a reminder, there's a proof of concept out on GitHub. And then just a kind of an update. We're working now on a more extent proof of concept that will have actual application data so we can experiment with things like how what happens when a collision occur and what the actual effect to the user will be"
  },
  {
    "startTime": "00:36:01",
    "text": "on that So the issue that discussion recently is that in the past, what we've been focusing primarily on is collisions where two different hosts are allocating the same not necessarily IP address, but by the time it gets translated into an ether address, it becomes the same Ethernet address. So how do you resolve collisions at the Ethernet level with that? There's another type of collision that is actually more related to the internal hardware of the switch So up here I reference a US patent that switch that and some of the behavior that that would occur in a switch, but basically that the switch will have a big addercing table, which is a hash table. And when it's trying to look up what to do with a given Ethernet frame, it'll look up, it'll cut calculate a hash of its destination macadro address and use that to locate an entry in the table And then when you go into that entry in the table, you know, what's commonly how hash tables are implemented is you would have a maybe a linked list after that. But with this particular switch, it uses bucket instead. So this, the example I've got on the screen here is a switch that has a four buckets for each entry in the hash table So when it's looking up, the destination Mac, it calculates the hash goes to that location in the hash table, and then finds the entry that corresponds with that in Mac address Now, if all four entries in that table are full, then there's no room for additional addresses so in this case you might have three unicast addresses and add a multicast, or you might have two multicast addresses and two unicast. In either case, there's no room for additional addresses and if you go to add a new unicast, for example,"
  },
  {
    "startTime": "00:38:01",
    "text": "that could potentially be problematic as far as being able to communicate with that device So the patent talks about things like aging entries and stuff like that but want to try to account for that in the allocation protocol So just a reminder how the zero comp algorithm works is it uses NDNS and it creates a PTR record, a unique PTR record that reflects the layer two address for the allocated IPV6 address It uses the programming algorithm to query for that PTR record and if the programming algorithm completes without a conflict, then the application begins advertising that PTR record. And that's kind of like saying, I I've allocated this address Now the content of the PTR record, is kind of a mix of the host name and the application. We include an application there so that the same host can allocate multiple addresses for it now this allocation is meant to really only happen the first time the network powers up or a new application joins the network and that's accomplished by retaining that group ID that's randomly generated So you save that in long-term storage, you start up you kind of make an assumption that you have that available and you start with that, you still do the probing but there will no longer be a need to there would no longer be any conflicts associated with that. So those conflicts would not be repeated. So what was that? in the newest version that I posted last night to the Zero Comp file, to the problem statement it kind of gives a general description of these types of collisions and then to the zero cop algorithm, it adds what's called a veto record"
  },
  {
    "startTime": "00:40:01",
    "text": "And again, this is a unique PTR record. It's got the same generated string as the address, but in this case it's published without probing, so that it kind of takes pressure And it also forces a conflict And that conflict would override the address that's been allocated by one of the hosts already Now the PTR name, denamed for that is the string veto and basically that would kind of override what the application is allocated, but basically the application would respond the same as a collision. It would allocate a new ID it would retain that new ID and so that same conflict is not repeated in the future so along those lines I want to try to pull up a demo here just what that looks like for the proof of concept that we have on a GitHub"
  },
  {
    "startTime": "00:42:01",
    "text": "Okay, so that's the demo and that's basically what I had to discuss. Are there any comments on that or questions? David Palmer the so you're going to, you're using local multicast DMS Can it also use the um, DNSSSD gateways? to an actual DNS? or do all the things have to be on the same link local? Sure So, yeah, yeah, the document kind of talks about the a little bit in that it primarily meant to be for the local network, but that it could be extended into other subnets you know based on incorporating other things like the gateways that you mentioned there. Yeah, okay. Yeah, all of that testing, the perfect concept is all around the link local and DNS. Okay thank you sure This is dig So I think it will be useful to get this precision or reviewed in some more application working groups or like apps area or something like that I don't know if you have thought about that or one thing is you know, we want application people to be aware of this and potentially use it and you could also be some input from people that maybe know the other we want application people to be aware of this and potentially use it. And it could also be some input from people that maybe know DNS a bit better than we do here Okay"
  },
  {
    "startTime": "00:44:01",
    "text": "um do you think reaching out to um maybe DNSSD? is one we've we've got another um draft with them related to kind of multicast service discovery And then what was the other working group you mentioned? I think there is still some what was the other working group you mentioned? I think there is still something called apps area that this like application things that don't have a particular working group group But let me let me look into that and see what we can find out Okay Yes, what I'm suggesting is maybe next slide IETF, you know, could try to present to some other those. But yeah, let's look into it offline. Okay You want to move on here? your next presentation? Yeah, I think so And if you want to run the screen for that, that would be fine I don't have a demo Okay, so I presented this idea, I think it was at IETF 118, and then it was called a null and boy porn null and void ports Since then, kind of looking at it, decided to really focus that more on the use with multicast applications The thought at the time was that maybe it could apply to Unicast as well, and I'm not, after thinking about it more, I don't really think that would be going to work out. So again, focusing"
  },
  {
    "startTime": "00:46:01",
    "text": "on this, we have a draft document out there and the authors there. Next slide please. So when thinking about this, you have to first maybe think about what is what is the transport protocol for. And so when you look at demultivation, for unicast traffic, the idea here is with transport protocols, the port numbers are used multiplex the traffic that's destined to a different application, but on the same host So the, as far as the protocol stack, goes, the network layer or IP layer gets into the host, and then what's in the host it may go to any number of applications and the port number tells you which application to direct that to. Now, the traditional approach has been that each application protocol has been a assigned a unique port from the registry but as more and more applications were being developed, it became apparent that the port assignments there are scarce resource and we should be more judicious in assigning those So the other thing is that when you're running two copies of the same application, that the port assignment can struggle So if you're trying to do two different FTP servers, you have to put one on with the well-known port and another on a different one and somehow communicate that to whoever is trying to contact it Now, as far as improving this, a lot of improvements have been made for dynamic ports allocating a dynamic port and advertising that using DNSSD So that's really reduced the need for static port assignments So the idea here is that we can do something somewhat similar with Multicast. Next slide, please So think about the multiplexing for multi-gas traffic So multi-gast is more complicated. All of the hosts, in the multi-cast group have to have the same port available And furthermore, that"
  },
  {
    "startTime": "00:48:01",
    "text": "has to kind of be pre-negotiated. You can't go to every host in the group and say, okay, well, give me an open port and negotiate that with everybody. It's got to be something that's known ahead of time So doing that, that would be hard So the traditional approach has been a static port assignment But the thing with multicast applications, is they don't actually need ports for multiplexing because the destination adders already identifies the receiving application So because of that, the destination port field is redundant and furthermore if a packet arrives on a host, there's been a lot of work to get it there, and so we should be using it. And if we don't need it, then we should do something to make sure that the host doesn't actually see it like cut it off at the router or at the switch or someone Next slide, please So just a reminder, multi- addresses, we've got the fixed addresses. Those are how allocated and maintained in the ION registries and then as talked about earlier in the lessons learned document, there's a couple of different algorithms out there for a dynamic assignment the Madcap, zero-com Lessons Learn document, there's a couple of different algorithms out there for a dynamic assignment, the Madcap, Zero Conf one that we just talked about, and GAP Next slide, please So the proposed solution for demultiplexing the multicaster or handling the multicast port issue is basically to reserve two ports and designate them as multicast application ports. 4-9-150 and 151. So these are the last two ports of the user port range, and their consecutive ports to support the RTPRTCP protocols which would be used for video stream distribution Now what's really nice about this is that we don't need to modify"
  },
  {
    "startTime": "00:50:01",
    "text": "the network stacks of existing platforms in order to get this working. We can allocate these ports and start using them right away Now, depending on the platform that the application runs on, there may be different requirements on this, but the idea here is that a conformant application could set their reused adder or reused port socket options to share that port with other applications So again, the host stacks don't need to be updated but it would be beneficial to do that And then if you wanted to say, if you needed to modify the host stack, you would modify it so that those, to act as if those portals, are always shared, so you would never allow exclusive access to it to Torlis, you had a question. Do you want to ask that now? or? At the end, he's said. At the end, okay, thanks. Next slide, please So this was a demo using SOCAT and if you want to go back and look at that, that's in the IETF 118 PIM meeting, but I'll put it up here again. One thing this demo ran on Linux and the reuse adder socket option was not needed on this because it was the bind happened to the multicast address. Now if you bind to the any end, you do need to do reuse adder but the problem with that is that you then receive the packets from every multicast address that comes in there. So you, again, I think with this, if you're developing an application on Linux, you would probably elect to bind to the multicast address to make sure you only got the packets that you're interested in. And if you, for some reason, needed to bind to the any address and you might want to mix in maybe like a ebpf packet filter or something to make sure you're only getting the packets"
  },
  {
    "startTime": "00:52:01",
    "text": "that you want there. Next slide So I kind of made a note based off of the feedback that we got from Torlis on the mailing list that these were two things to this discuss. So specifically, the reuse adder reuse port, Torlis had made a copy these were two things to discuss. So specifically the reuse adder reused port, Torlis had made a comment that we should go through and figure out what's actually needed on the different platforms and that seems prudent I think, probably Linux, Max we should go through and figure out what's actually needed on the different platforms. And that seems prudent. I think probably Linux, MacOS, and Windows would be good to dive into further And then also just general questions on how it would work with source specific multicast. So I think Torlis is at the mic, so go ahead, Torlas. Yeah, so the first thing I will wondering is whether we could get ports that are not today also used by Unicast because if, you know, one of the ports is randomly used by another Unicast application that hadn't set the you know we use Adder, reuse port, then the multicast application would fail as if we didn't do all the work So maybe they're explicit, you know, two ports we can carve out. I'm not sure which working group would the best be for that in, but I think we would need to ask somebody like Eric Bing you or so, UDP, transport I think that's in the area Then before even getting to source source-specific multicast, I'm wondering whether Phil filtering happens if we have two multicast applications, different multicast groups, same system, and now they're using the same port Are these packets, you know? filtered at the kernel level or? would the library need to filter them all? would they not be filtered even? I remember just when you know, Steve Deering put that into the kernel there was no such filtering so the application had to filter everything, but I don't know where we stand to today. Yeah, no, yeah, if you bind to, if you bind the socket to the the group address you should only"
  },
  {
    "startTime": "00:54:02",
    "text": "receive that particular group or bind to group and port Yeah do a UDP socket, you have the port and port you do a ulyp socket you have the the port number that you're binding to so destination package will only be that port number And the grid address And the address. No, no, the address the address is not part of the bind The bind API uses a sock adder, which has an address and a port. So tom strickx trigger IGMP or MLD you need to put the destination multicath group address into a different API call than the bind That's not the bind. The bind doesn't do the join Right. It doesn't do it So you're right that if we let's say, can make the kernel filtering of the destination at address happen by also doing the bind for the destination address, that's one possible trick All I'm saying is we should figure out that we feel safe that if we have run multiple applications that, no, wait a second, let me quickly finish, that we're not getting into, let's say, undesired filtering at the library layer, right? So punting packets unnecessarily to the user land and then filtering them there This is Dino. We don't have a problem If you bind, you bind with a specific address in port, and only packets to that address will come to the application. If you bind with any in the port, then you'll get packets from any address. So it's up to the application programmer on how it happens It all works for two decades now Mike, it might be worth going back one slide So I mean just check out all these different multicasts"
  },
  {
    "startTime": "00:56:01",
    "text": "application, right? So I think it's quite untypical to put the multicast address also into the bind You typically only put that into the API call join Multicast Group. Yeah, that's where you typically put it in. Well, I think there's differences on Windows and Linux too My recollection with Windows is you actually have to bind it the interface address and do the IP and member to get that multicast Right. So the, wait a second, the This is for Linux up here For the IGMP join, I think you also have the interface address, right, so that it knows where the uh, which interface the join goes to, so you don't need to have the interface address in the bind. So I think, you know, is right, we can put the multicast destination address in the bind I'm not sure that that's commonly done if that would be sufficient. Right, in the end, just let's So I think Dino is right, we can put the multicast destination address in the bind. I'm not sure that that's commonly done if that would be sufficient. In the end, just let us feel safe that we're not changing that everything is filtered in the kernel that we don't want on our socket, right? david lamparter applications have also used to bind address to determine the source address if they're also sending to the multi-cast group. The solution is obvious here, use two sockets And also the problem is if you use SSM, you can only buy to the group address and not to the source. So I think that's still work to be done, which you mentioned in the presentation This is Dino. So I've written apps where I bind with any because I want to receive on that port when it's sent to my Unicast address as well as multicast address that I have joined But it's a separate step to add membership to each group that you want. So yes, you can accidentally as an application program or not a kernel programmer, to screw up If it turns out, that we feel safe, we can do everything with the same level of kernel stuff, just we may need to do more binding and maybe"
  },
  {
    "startTime": "00:58:01",
    "text": "more sockets, that's at least good to know and put it in as a no, right? If we can't figure it out and there is going to be more punting, we may still like this, right? Maybe not for all the applications I'm just saying we should be aware of exactly the punting situation and what's the best we can do against it So it's Stig here. So it's common even for you Unicast applications to bind to address and port. Like you want a different web server on different IP addresses or something like that For multicast, I'm not quite sure if they in general join and bind to the group but they can easily do it, at least, the socket API supports this and the filtering. This is Dino. Sometimes you bind on any because you don't know what your IP address is or keep they in general, join and bind to the group, but they can easily do it at least. The socket API supports this and the filtering. This is Dino. Sometimes you bind on any because you don't know what your IP address is, or it keeps changing But yeah, this is a problem potentially for SSM that you know, you can't share the same group address for multiple applications You could do that today if you have different port numbers but now you need to make sure that it really is unique for the application. I guess that's what was mentioned on the mail list. But what we don't know, right? So I mean, maybe the kernels actually are better in doing the filtering also based on what the joints are David is saying no. You've looked on the kernel, right, so, but let's try to figure it out out The other, the first point that Torlis made too is related to choosing a different port that was not likely to have any sort of unicast use for that And I don't know that there is any port out there that does not have the potential to have a contract That's kind of what we're trying to do is be the first first ones But we, as you said, right, so we have allocated static ports for specific applications and now we allocate another set of static ports for"
  },
  {
    "startTime": "01:00:01",
    "text": "this, right? So I mean that that space will work anyhow this is Dino related to your point Nate um multicast quick might have this problem Sorry, that's why PC. It does that on the next one. Sorry Something like you're making coffee or something after day So Multicast Quick might have this problem where the port number may be needed to be used for both Unicast and Multicast So we have to look into that. So it should be okay if someone is used this port for Unicast at the same time as long as they do reuse Adder Azure Yeah. But yeah, I'm not sure whether PIM is the right working group for this or not It's kind of good to do it here because people know multicasts, but at the same time, I wonder if interiors or something could be a good place We need to look into that I think if we can do the testing to get through our understanding what happens on the API level and what we recommend we can still move it to another group if somebody thinks we don't want to finish it. Yeah, yeah through our understanding what happens on the API level and what we recommend, we can still move it to another group if somebody thinks we don't want to finish it. Yeah, so at least I would say happy to keep doing it here but of course yeah before potentially i adopting it, we should think about that and just in general where else in the IETF do you think we can get some good input? Where would somebody? do an update to the UDP? I don't know. End area? Stewart did present this on the hot arse meeting on Sunday so maybe somebody will read out from that Okay, well thanks everybody. Thank you"
  },
  {
    "startTime": "01:02:06",
    "text": "Good afternoon, everyone I'm Sanizan from the TE This presentation is for using multi-topology in Ping. And I present this draft on behalf of our co-author, Benchong, Sting Jeffrey, and Holman. Next, please This is a brief introduction of this draft. We know that Pim Mureli uses the shortest path computed by the IGP to build the tree to multicast source from the receiver And now there are some standards about supporting multi-topology and flex algorithm in IGP such as we know that OSPF can support multi-tapology per off-C for and flex algorithm in IGP, such as we know that OSPF can support multi-topology per FC 4915 and the ISIS protocol can support multi-topology per FC 5120 And the both of OSPF and the ISPF and ISIS can support flex algorithm per UFSI UFSI-9-350. So in this chapter, we'd like to introduce the multi-topology and the flex algorithm to be used by PIN. Next please So this is the example. We know that in this figure there are two multicaster flows and the have both the source are one at its first top router, and they have the same receiver router last hop router, are same So there's only one shortest passing the figure, such as R1, R2, R4, and R1"
  },
  {
    "startTime": "01:04:01",
    "text": "So all the of the multicast flows will follow the same path to reach the receiver But the bandwidth in the path is not enough for the two multicast flows. So there is pegged laws If we can use multipolar or flex ego in this example, so two different paths can be used for the two different flows So the multi-cast flow one can forward by R1, R2, R4 and R6 And the second multi-cast flow can forward the path from R1, R3 R5, and R6 So different passes can be provided and there is no packet loss This is PIM extensions for achieve this goal We know that we defined our new sub-TOV for the new working group document, PFM, for wording in enhancements. Sorry, I haven't updated this priority for wording enhancements. Sorry, I haven't updated this presentation slides. This is also the working group documents So in the draft, new group source in TOV has defined and it can carry multiple sub-tOVs So we defined a new multi-tropology sub-tOV under the group source info and also we define a multi-tropology joint attribute for the past building from the receiver to the site"
  },
  {
    "startTime": "01:06:01",
    "text": "source Oh, sorry that's all for the solution It's easy for understand if you have any questions or comments, well come. Yeah seems like easy for I understand if you have any questions or comments, we'll come. Yeah, go ahead, ASEY Linde. I'm sorry, I'm sorry I've been I'm guilty of Meetecho surf and I'm not in the room. But you know, the I in PIM stands for independent and you know just by the RPF, use, can you? any topology or it can go to a route that's been computing using flex algorithm Why do you why would we need this? Sorry ACU voice as low, please repeat, could you please repeat your question? again? Can you hear me? Yes, I can hear you but your voice is low How about now? Better Okay. Yeah, what I was saying, the eye and p.m is for independent and that means it's independent you don't need i don't see why you need this, because you can have the RPF can, for PIM, can you any topology or it can use or a route can be computed using Flex algorithm. You don't really need extensions to P PIM. I don't think you do. I don't know why you need them Oh, yes. I haven't I haven't algorithm. You don't really need extensions to PIMP. I don't think you do. I don't know why you need them. Oh, yes. I haven't read the draft. Sorry, I haven't read the draft either OK, OK, let me explain it again. Maybe I, uh present it too fast please move the presentation the slides to the from A. Yes, so we can see this figure, as you see,"
  },
  {
    "startTime": "01:08:01",
    "text": "different parts can be computed by multi-topology or flex ego by IDP, that's right. But we know that it can't be used by PIN directly because we always cause the roots from IDP for the shortage path as the default topology So if we'd like to use specific, multi-topology or flex ego for routing computation, we must know which topology or flex ego we should use for them. So we must advertise the information through P or flex ego we should use for them. So we must advertise the information through PIM extensions to all the research including the receiver to know the information and the receiver. Yeah, I think we're in a circular argument here I'll have to think about it more, but I don't think you do. I think you just do the you just do the RPF and you can you know, the RPF can be to any, any one of them topologies, or it can be to a the source can be computed using flex algorithms. So I don't think you need it. I'll have to, I'll have to read it and think about it a little bit more but i don't i i'll and and i imagine you're going to get some of the other people in the queue have have similar comments anyway I'll give them a chance Yeah, allow me to jump the queue to try to answer or AC's question. Specifically, about protocol independent part My understanding is that in the old days we have DVMR where we use DVMRP to carry the routes that is used for RP And then the PIM comes along with say it's probably independent, meaning that we do not use PIM protocol to carry the RPF routes. I think that's the meaning of the proper independent part"
  },
  {
    "startTime": "01:10:01",
    "text": "And now we okay, then You know RPF is probably right that, right, but it's right, but it's, right, okay, yeah, so that in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, it, is R RPI, like in the DPR case, right? Yeah, okay. So I think that should answer is his question about protocol independent park And then how to, when in the presence of MT and flex-out we do need, when you do want your tree to follow a particular topology, or particular flex-argo, we do need this extension here to signal that information Yes. I guess only if you want different groups to use different topology That's the only reason. I guess that's what you're trying to solve, right? Go ahead, David, go OK. Source group Oh, sorry. david lamparter So my PIM routing domain and my IGP routing domain is not necessarily the same size. For example, I could have three different larger networks running OSPF, ISIS, and one PIM domain across that. And those three IGP domains, may use entirely different topology ideas even if they're doing the same thing How does that work here? So if you can divide the topology or not network into different topology or use a different flex angle for it No, so I have three networks as far as Unicast routing is going to for it? No, so I have three networks as far as Unicast routing is concerned, but only one network as far as PIM is concerned, because interworking PIM is hard"
  },
  {
    "startTime": "01:12:01",
    "text": "So in my Unicast set routing is concerned, but only one network as far as PIM is concerned, because interwalking PIM is hard. So in my Unicast setups, I use multi-topology, but those three networks have different setups for how they do things So the ID from PIM would need to make sense for all three of them, or this breaks down. That's kind of my argument here. So you ping domain will access all the three domains, or just all three. All three We can use tunnel for it Because you want to cross some domain, right? Okay, Steve, just not far as want to cross some domain, right? Okay, Steve, just not this is not why I came up here, but just a comment on that So I agree that that would be a little bit hard to see cross some domain, right? Okay, Stig, just not why I came up here, but just a comment on that. So I agree that that would be a little bit hard to solve, but just one possibility If the idea you specify, it's not the actual idea that you need in the IGP, but more like an abstract idea that says something like, I don't know, a certain you know, you want I don't know, max bandwidth, whatever, and then you can transfer that to whatever that is in the local IGP somehow. I don't know all right peter's been very patient go ahead Peter. Hey, hi, guys. It's Peter from Cisco. Can you hear me? By the way. Yes All right, so just one thing maybe you to think about If you look at how the flex logo is defined, it is defined for a specific data planes today it is defined for SRMPLS, SRV6, and IPE Algo prefixes. You do not say anything about any of this, and you have two choices Either your sources say anything about any of these and you have two choices. Either you, your sources and destinations need to be part of one of those planes or you need to define a new data plan for this plan purpose, even though this is not a data plane as such but it would have to be a new data plane from the Lexago perspective so i didn't find anything about that in your drafts so just something to take into the account Yes, for the first hop route"
  },
  {
    "startTime": "01:14:01",
    "text": "he must know which multiple or flex ego should be used for the multicast flows. And this can be done by administrator configuration or something else Yeah, my point was a bit different, but maybe we can discuss a flying Zedina. So I think the conversation is way more complex than it needs to be and I will defend AC's point So this has been implemented a long time ago with verfs So PIM could run over multiple verbs, and it was a configuration item in the implementation on where PIM should join. And since source addresses were either in one or the other or translate with Nats, which is a more complicated case, you could dis the implementation on where PIM should join. And since source addresses were either in one or the other or translated with Nats, which is a more complicated case, you could decide which verf you would use and consult the rib, hence AC's comments about independent, that you don't need to signal this inside the protocol Okay, now having said that AC, what they want to do is they want to make it more dynamic and they want this particular sort on this diagram to tell the receiver what to topology it's in. So therefore it knows what to do join. And so it's basically providing it a verf ID or a rib ID or something so it looks in that particular table to RPF i.e. joined along a certain path I'm going to jump the Q2 and say I understand now I just don't know I just a certain path. I'm going to jump, I'm going to jump the Q2 and say, I understand, I understand now. I just don't know. I just don't know who'd want to manage a network with, uh, different source, source using different topologies and different flex algorithms and having it all run together. It's called MVP. It's already done And yes, it's very complex But Stig here, so I know people that deploy networks that don't use separate verbs like Dino said, but"
  },
  {
    "startTime": "01:16:01",
    "text": "actually use multi-topology And they basically need some kind of static config on the router to say that this specific group I want to do RPF look up in this topology and some other group look up in a different topology So the benefit with this is that you don't need to do static config that matches up on every single route You just need either the Lasap router in the joint case to have the config or the first subprud router if you use PFM matches up on every single router. You just need either the last up router in the joint case to have the config or the first up router if you use pfm. Do you mean different to to to this could be put in ISI, but this proposal just presented with the panel, that's applying that analysis, right? Yes, we didn't define any IGP extension for it. We just use it yeah. No, no, this is Dino What you're trying to do is signal this information and this signaling information is broadcasted And when you broadcast in PIM, you use this new feature called BFM You could have used a link state protocol to distribute it like OSPI and Iest-Ius, and that's just fine. You decided to use PIM PIM PIM Jeffrey from Juniper, to David's earlier comment about multiple IGP domains I think that the boy comment about multiple IGP domains. I think that the border routers will just have to translate the the FTE identify or the border routers will just have to do to translate for the FTE identifier or a flexible identifier Another general comment is that this is actually a mimic of the MLDP in the multi-topology and in Flexago mimic of the MLDP in the multi-topology and in the flexago. And that draft is, I believe, it's in the IESC evaluation phase now, where basically mimicking the same thing here we draft is, I believe it's in the IESC evaluation phase now. We're basically mimicking the same thing here. We, in the MLDP case to a union to find out how to reach your roots using D different topology or different flex-argo. Here with"
  },
  {
    "startTime": "01:18:01",
    "text": "doing exactly the same thing. It's just that we're doing PIM. So that's another way to do think about it david lamparter, I am. I think Stig, you have indirectly answered a better way to do this by, like, the fact that it was can previously be done with configuration by putting groups into, call it VRFs, call it whatever else if that is what this mechanism community I think it will have far fewer corner cases weird issues because you not stuck to having this MTID being communicated between the PIM routers. It's coming from up into the PIM routers and it's telling the PIM router what to do with a particular group and then you can control what scope it's applied in and you can deal with the IGP doing different things in different places and you're far closer to what the existing implementations are doing. I'm not sure why this is moving away from having this be kind of configuration based into putting this into PIM itself I don't think that is the correct direction for this Yes, you can do everything by configuration, yes right but I'm not suggest this be done through configuration. I'm suggesting that a protocol that replaces the behavior of installing configuration and carries the same kind of information and settings into the routers like you do want the protocol to carry all of this whether this is an ISIS being flooded or you can put it like candidate RP propagated to the pin routers that way, that would also work. I'm just saying the, the transported setup for this should behave very similar to what we already have in divvying up groups into different VRFs and these different VRFs do different things for their RPS I agree you don't want to have that as a convict everywhere so fix the problem of"
  },
  {
    "startTime": "01:20:01",
    "text": "distributing that config instead, I think So we have two motivations of this chapter. One is not motivation. That's our goal First one is that we must advertise all the information in the we let every router especially the last hop router, to know which path should he be joined, right? So that is from special multi-topology or flex angle. So the receiver must know Of course, you can configure it. And the second one is that the multicultural tree is building from the receiver to the source. So we must make the two steps consistent I absolutely and strongly disagree with that. Two PIM routers, do not care whether they both use the same i absolutely and strongly disagree with that. Two PIM routers do not care whether they both use the same ID for some RPF lookup. The thing that matters, yes, it needs to be consistent but the MTID or anything like that is not the factor did determine that. From this figure you may know that figure, you may know that if the receiver, A6, doesn't know which topology or flex ego she should join he may join every passing the drug figure, right? So the R6 will join the path, the shortest path configured by IGP if he doesn't know any topology or flex cycle, so he will join all the, he will send all the joins to ARF and R2 to R1. So, they will use the only path for the multicars flow forwarding. So that's what we don't want it. That's why we don't want it. So we must let the last hope receiver to know which group should I join"
  },
  {
    "startTime": "01:22:01",
    "text": "So we must get some information from the source or something else. He must tell me, which flows must belong to which topology or flex ego. So we must sign for it. What's the sign be originating? So we can get it from the pfm advertisement. Or maybe you can use the MOSPF or something else to carry the information to spread in the network. That's all okay. But we prefer the PFM enhancement because it's provide an efficient way to follow PN ping me information advertisement so we can use it for the receiver to know which multi-topology or flex ego should be used for the multi-cost flow yeah I'll do more reading okay so you can you you can see the group source info TOV as defined in the newest PFM forwarding enhancement working group documents. It can carry this group and source information of the motivation flow. So we carry the special topology of flex echo information as associated with the TIRP So we can let every router in the network to know the information And so the consistency in the network can be on guaranteed. Yeah, I mean, who am I from Nokia? I mean, let's look at that at 20 000 feet right this is a steering um There's a lot of providers out there that are trying to do IPTV over 5G networks or over even like regular networks as a carrier and they just want to steer traffic for 4k, 10 ADP or estate standard via different flexal algorithms, blue or red or default, right? So the only thing we have in our arsenal right now, and some of these guys"
  },
  {
    "startTime": "01:24:01",
    "text": "they don't want to do NG and VPN, right? Because let's be serious. When you do NG MVP, VPN, there are issues right now, we are going to segment routing, I mean, LDPR RSVPTE I don't want to say that, but I mean, nobody wants to bring in an another protocol into the network when you're doing segment routing So when it comes to SRV6 or when it comes to the segment routing, right now the story is beer or go to 3C or stay with PIMM, right, PIM supports IPVC So the question becomes if I want to steer certain traffic let's say I have a stock ticker that needs to get gold, needs to be blue, and then I have TV that needs to be bronze, and I want to steer this type of traffic. How do I need to see? it? This is, in my opinion, what this is trying to solve Yeah. Just from 20,000 feet This is Dino. So the way PFM messages work, they come, they start from a source and they go downstream it appears to me that the out of the policy is made that by the source gets selected to topology. Why not have the received? select the topology is is this a conscious effort in the design to make the sources? do it? As the previous work version of this structure, we just wanted to use the receiver side to decide the topology of FlexEgo to join. But it could, yeah but it could be decided anywhere in the network and it's just being distributed from the source the server yeah we be thought it sort of this way in the previous version, but finally we found it yeah we we thought this way in the previous version but finally we found that it can't keep the consistent consistency from the source to the receiver Because every routers in"
  },
  {
    "startTime": "01:26:01",
    "text": "the figure must know which one is in the multi-topology and the source if the source can support the multi-topology is the receiver yeah yeah understand i'm just worried that at the receiver side, at that part of topology those sets of nodes know the bandwidth and the resources that are available much better than maybe the source does. Because don't forget the source is supporting whoever wants to join and receive, and there could be very bandwidth and different types of flows going on So, I mean, I'm not making a statement one way or the other I just want to know, was it a conscious effort to make it be done by the source? Yeah, I can try to reply to that. I think this time probably part of a disconnect is probably because of that we put that info into the group sourcing for TLV. What we really signal here is just what topic this tree should belong to. It really has nothing to with the source itself. And I also want to reiterate that what we are doing here is really, really just a mimic of what MLDP multi-topology is doing. And that document is in the RFC editor's queue now and so all the questions and arguments here for PIN I think that if they are really valid, then we have another we have a problem with MLT as well, but I don't think we have a problem this really just we need to clear that disconnect I think we should do a better job in creating all the disconnect here And yeah. Go ahead, A.Z acee lindem Lab in. Okay, okay, I understand now you want to do the multi-topologies per group source dynamically and somehow signal them I can understand that"
  },
  {
    "startTime": "01:28:01",
    "text": "And you have some comments. But as far as the flex algorithm, is concerned, within a topology, the lookup implies what algorithm, you really can't specify that in the multicast protocol. So I don't think you want flex algorithm under here I think you only want the multiple topology. You can think about that You don't want to specify the flex algorithm because you have a source You do a lookup in a topology for a for a source That typology, that has already been installed by the flex algorithm corresponding to that source. You can't specify a different one via the multi-cap to look it up So you don't want, you don't want, you don't want a flex corresponding to that source. You can't specify a different one via the multicast to look it up. So you don't want a flex algorithm in here you don't want you don't want a flex algorithm in here i think you sort is from from the receiver side. So you can look up the rib for the specific top of FlexAGO, right? Right, no, but there is not a, there's not a separate, there's not a separate rib per flex algorithm. There's one rib and you use a different algorithm, there's one rib per topology, there's one rib and you use a flex algorithm to install the route corresponding to the source in it You don't need flex algorithm. I mean, you don't, I don't think you need it here. You want me to put, you want me to send it to list? you don't, I don't think you need it here. You want me to put, you want me to send it to the list so can be discussed? Yes, sent it to the list and we need to move on Yeah, that's what I was thinking. I think we're in a circular argument Yeah, yeah. Go ahead, Stig. Okay i'll just try to say at yeah the high level we're trying to do steering. And the obvious option today is that you configure each router with whatever information you need for the steering right? But what this proposes is that either you can configure a the receiving sign at the LOSTAP router"
  },
  {
    "startTime": "01:30:01",
    "text": "what to use so that in the join message you can signal that to upstream routers so you don't have to configure your core routers with whatever information The other option that the draft also discusses is to use PFM and do this from the source But it allows for both. The idea is the same that you can configure just an edge device and that can communicate to whatever other devices that use in the network, what to do But yeah, there's some challenges here and things to look into the people i mentioned but yeah at least you can do from either side. And one issue with the receivers is that what do you do if the receivers are concerned differently But better you do it on the source of receiver side. Yeah, you kind of need all the routers in between to agree on what that particular idea or whatever means, like what to do with that Okay. So I'd like to share some information from our implementation When we implement this draft, we think that if we only configure in the research, side, we can make the route from such as the R6 to R4 or R5 then if the R5 can support the topology or the flexago, he will return the route in the default topology. So the root may not be wont to join. So the flow may be, the path may be built also but that's what we want to do forwarded. So it's approach So if some in, implementation has different results you can let me know. So if we use the function, defining this structure, every router will know the information, the group source information and the associated topology and flex ego. So every"
  },
  {
    "startTime": "01:32:01",
    "text": "router will know if he support the topology of the flex ego if he received the wrong joy. There's he support the topology of the flex ego. If he received the wrong drawing, he will look up his table and find that, oh, I can't support this topology or this flex ego. So he will not forwarding the join to the next stop. So the multicars flow will not be forwarded by the wrong road So that's the consistency that we want to achieve We'll talk about later. Yeah, go ahead, Peter. After macro loop After macro loop. Yeah. Peter Yeah, I just want a quick comment on jeffrey haas parallel with MLDP In MLDP, the data plane was SRI SRMPLS. In SRMPLS, Flexi Algo can give you different paths per ALGO for the prefix because you have different labels associated with an ALGO If you look at the SRV6, you can compute past the SRV6 locator in a different ALGOS because the SRV6 locator itself has been assigned to an ALGO So there's a big difference. Think about it Thank you, Sandy That's very great. Peter, please send your question to me directly. Thank you. That's very useful information. Yeah. Thank you Thank you. Dino This will be real quick and it's not nearly as interesting as the last presentation This is just document status In the LISP working group, we have in the charter, it says that we're going to take the multi-capt overlay working documents into standards track so I just wanted to report on that"
  },
  {
    "startTime": "01:34:01",
    "text": "There's some of my own documents, but it's related to LIS lists. I'm going to skip over that and we just have one comment about the gap thing, which we'll talk about at the end. So we have I can see this better, we have 6831, which defines lists multicast on an overlay and how sources and senders on an overlay do more multicast routing. And that was published as experimental in 2013 The working group decided to go ahead and standardize that So we created a individual contribution called 6831 BIS. We're going to make that a working group document, so it'll be IETF LISP 6831 BIS, and we also did that for 8378 as well, and I'll explain what those two things mean. So that's those two documents are going. Now we have this, third document, which is an individual submission but we want to turn this into experimental. And this allows us to map the overlay group to an underlay group, very much like in the old days when we were running on SMDS and frame relay, how did you map the IP group address to a link layer group address? We have the same sort of problem here but the underlay now is an IP network. So, um, and frame relay, how did you map the IP group address to a link layer group address? We have the same sort of problem here, but the underlay now is an IP network. So I'll explain what we're going to do. But it turns out the way this works for the standards process to work is that this document points to both of those. But those two do not reference the group mapping because it's newer and therefore we can go to we could standardize the two rFCs quicker Next. So just the refresher on what 6831 does. This defines how you run an overlay multicast an underlay native multicast. Okay. And you basically use PIM to build the underlay distribution tree based on the joins and sources that are sending on the overlay okay? That introduced this overlay state called EIDCOM"
  },
  {
    "startTime": "01:36:01",
    "text": "comma G because the underlay network doesn't know about the source termed EID here And what it would do, it would map it to in the map cap to an Arloch comma G where the Arloch is the IP address of the encapsulator. It turns out G is the same value here. So what we prepare in that draft is that the overlay group in the underlay group, would be the same thing. That could present problems for providers. In 8378, we decided to have a signal-free way of doing multicast where we didn't use PIM, where we used the mapping system to define where receivers are, and we could do head-end replication if the Arloak set was either unicast or if it was multicast or a combination of both that could send over both those types of environments so basically there's a signal-based one using an existing protocol called PIM and one that uses the mapping system, and that's why we called it signal-free Next. So with this list group mapping proposal does is we kind of form formalized this s comma g definition with respect to overlays and we over state would be S-E-I-D and G-E-I comma g definition with respect to overlays and the overlay state would be s eid and g eid and what that actually means is since it's on the overlay the underlay doesn't know about in either Unicast route or multicast routing, doesn't know about SEA S-E-I-D and G-E-I-D. So basically the S SEID is the source that's sending and the GEID is what receivers join to Underlay knows nothing about it. So we have to map, this is what's in the mapping system. So we have to map it to what's used on the underlay, and that's what the Arloaks are used for. So today we have something called S-R-Loccombe U-R-Lote, which means the srloak is the encapsulating router and if it's sending the multicast to a unicab location, because there's no native multicast, we call that a unicast R-Loc. Otherwise, it could be sending it to an underlay multicast group"
  },
  {
    "startTime": "01:38:01",
    "text": "called G.R. Loak. And then the, and this spec basically says, how do you map from G.E.I to G-R-Loke? That's with this spec does. Next. And we have two solutions to that. One is hash-based, so there's no cord coordination. It's completely decentralized where the GEID just uses a Shaw 256 to produce the GR looks. So all the receivers for the same GEID will hash the same GM GR-Loke, and the coordination is algorithmic or automatic. But if you do that, that means it's the receivers and the applications that are just deciding what groups to use and an underlay provider may not want those group addresses to be used So maybe if you want to put control in the in the underlays domain you use the mapping system. And the way it works is that you can put a distinguished name in the mapping system something like this group 224-111 where the 224-1-1-1-1 is the group EID that runs on the overlay, and it could map to 225-125 and that's out of the address range of the underlay So if you do that, then the ETR is just basically look up this mapping and they could all coordinate to the same group to join on the underlay I think that's it. We don't have to do this because it's list related. Okay. And you can go to thanks for all the fish. Okay fish Okay. So the reason I'm doing all this is because I'm planning on retiring really soon And so we were trying to get a status of what the documents are And so what came up in the list working group between Stig and I was, what are we going to do with the gap draft? So I could, I don't know if you want to discuss that or make a comment on that. Yeah, so we- For this working group Yeah, we've, I'm on the draft so I have to be careful. But we've just, we're planning to try to"
  },
  {
    "startTime": "01:40:01",
    "text": "progress zero comp and gap quickly are you are we do we have to the end of the year or to the end of next year for you uh Let's see, 2025 I won't be here in 2026. Okay, so we have a year and a half. We have a year and a half. Okay, yeah, we got plenty of time But that's not very much time in IETF time. That's true That's true. So we will make sure these progress Thank you Tourless Okay, I wanted to give an update on this bistro draft. Next slide So as a reminder, 11 an update on this BISDraft. Next slide. So as a reminder, 1112, original definition of IP multicast which later on we started to call ASM when we introduced SSM, and it also specifies IGM version 1, which is where the fun begins namely when just, you know, a few years ago, you run into problems and networks with the surveillance cameras that explain that they only implemented IGMP version 1 because it's the only full internet standard. And obviously that's better than something like this crappy, you know, proposal standard IGMPV3. And so as part of our story, let's play the IETF game of actually making the things we want to sell full standards and not the old stuff ASM still very useful, not for internet, but for other scopes. But IGMPV-1, we want to retire. So that's kind of, we need to cut the draft in half throw half away the IGMP So that's basically what this effort is"
  },
  {
    "startTime": "01:42:01",
    "text": "Pretty much removed the Appendix A, which is IGMP version 1. And then of course, also made the applicability statement that, you know, we've got what was our you know, RFC for SSM, over the internet. So ASM for controlled network We also learned as part of the process here in the working group that obviously we need to try to figure out how we can keep the users of IGMP version 1 in existing IGMP V2 and V3 implementations unchanged We don't want to change any code that runs and include IGMPV1 if it's IGMPV2 and V3 implementations. So that was somewhat tricky to get all right, all done right, then I think some AD also stood up and said, let's capitalize the must and should. Luckily, that was actually well-written text, just, you know, capitalized was required. Keep all the original text unchanged so unless it was wrong and insufficient And then we had two bonuses that we could put in there First of all, the new naming, ASM and mentioning SSM and then also adding text for IPV6. We don't need it any of the normative specifications. They were all done later in some other RFCs, which are now all references here. But we didn't have any you know, RFC to point to to say, here is the host stack for IPC multicast and explains how that works right? So that, you know, there are these packets with IPVC destination addresses. So that's basically all added. And so, yeah, that's basically what the work that we did Next slide. So the chairs, nicely asked for early Ianna reviews so just in the last few days, I added the IANA section with all these, what was it?"
  },
  {
    "startTime": "01:44:01",
    "text": "seven or eight registries where 1112 was mentioned So they're all going to go into pointing to 1112 bis now the new one, except for the IGMP code points, which actually are referring to the message code point for IGMP version 1. So that's the only one going tom strickx to the old RFC 1112 I am asking Ianna to put the references for 20 version 1, so that's the only one going tom strickx to the old RFC 1112. I am asking Ianna to put the references for 2236 and 3376 into the IGMP query because each of these IGMP versions has strict done a different version of that message format that only itself can distinguish so hopefully by making that explicit in the registry will make it easier for readers, you know, to figure out that this is not only IGMP1, but that this code point is used by V2 and V3 So the author here thinks the doctor, is ready for working group last call which hopefully in this working group triggers also more review then. I'm also trying to go to the strange new working group you haven't worked of M-Bondy and ask them as well If they might, maybe there are some people not not here in the room right now. We'll see So, yeah, so the document should very easily compare with IDD them as well. If they might, maybe there are some people, not here in the room right now. We'll see. So yeah, so the document should very easily compare with ID-DIF. So primarily Appendix A is going That was IGMP version 1, and instead there is a bunch of explanation. But in the main text, I think all the changes I was explaining should be very easily identity as div, so hopefully we can get a little bit more reviews here during, yeah, hopefully work group last call. So that's the request for us It is to the request, yeah, by requesting, yes. Okay all right so thank you we've got a a good problem in this working group which is really as of late is that we've sent seven or so drafts to gunter's way We've asked for publication, so he's pretty busy office"
  },
  {
    "startTime": "01:46:01",
    "text": "is really as of late, is that we've sent seven or so drafts to Gunter's way. We've asked for publication, so he's pretty busy all of a sudden, and now we've got the gap in zero comp that we're trying to expedite a little bit But yes, we will do that. We will do that work will do that group last call and we will just continue to pile on Gunder Anything else? Because that's the last presentation. Maybe it's just like, quick question. I don't know how many have read this latest version, but if anyone has any concerns about last call, if they know any issues or things they want to address great if they can let us know now or just even a mailing list shortly Thank you. Okay anything else? All right, that's a wrap Until Dublin All right. Thanks everyone. Thank you very much Great discussion discussion Thank you Thank you"
  }
]
