[
  {
    "startTime": "00:00:55",
    "text": "them. Alright, folks. This is TLS. Hopefully, you're in the right place. Presumably all of you seen the note well, kind of the guiding principles of the IETF. So if you're not familiar with it, you probably wanna look it up, but I'm sure by this time in the week, you probably are. And as a reminder, We all want to be on our best behavior."
  },
  {
    "startTime": "00:02:01",
    "text": "during these meetings and treat every one with respect keep the conversations civil civil. Thank you. The other thing we wanna make sure is that for people in the room, that you do log in using the online meeting tool. or the on-site tool. There is a blue sheet that has the QR code, if you don't have it, is Does anybody need the blue sheet, or can we all I can arrange for it to go back to you. if you need it. it's this with Lucas. I'll pass it around. Okay. Okay. Thanks. think yeah. And and In particular, use that we want you to join the using the on-site tool so that we get an accurate room count as well so that we don't end up with a really small room next time. And in addition, use that to join the QPs. probably have that. So we have reasonably Short agenda today, But basically, Is there anybody who has any additions to the agenda Any bashing of the agenda? No. Okay. Great. So then we can jump in. Stephen here. Alright. You are 1st."
  },
  {
    "startTime": "00:04:06",
    "text": "Stay. Okay. Thanks. So this is a draft we presented before. So it's Richiles and Ben Schwartz are working on this with me. Next slide. There's a story. I guess we saw that before, so Next slide. this picture, Next slide. There's a couple of issues I just wanna talk about. That's good. There's an example. Oh, I can I can give you the right slide. Never mind. So just just an example. You get a JSON response, which has the ECH config or an alias one. there's an error in that slide and and and in the draft in that the In the ADS mode, there should be no port number there. which we figured out. So we fixed that. Next slide. The changes we just added one thing to the JSON for version 3. I've started working on an implementation of it, which is incomplete still. and it's we started kind of seeing issues as we try to write the codes. next slide. So there's a couple of issues to talk about. I I think it was mentioned 4 on the list that if that SVCB the definition of ECH equals in SVcb, if that comes back to this working which I guess is the plan. Or do we know if that's the Tanya? Yes. probably is the timeline. So I think if somebody mentioned that this could be merged with that, I think it's probably better to keep this separate for now. just wanted to raise that in case somebody wants to are you upset? Nope. There's GitHub issues. So there's a couple of those I wanted to chat about quickly. and then they'll be done. Excellent. There you go. So I think we probably want to add support for specifying the inner ALPM when using ECH."
  },
  {
    "startTime": "00:06:01",
    "text": "in this. So we'll probably add that So this is a way to for the the origin to tell it's DNS infrastructure. Please include this ALPM. in the HTTPS resource record. Betty Schwartz. I think I think we should close this as fixed. We we we have to do it, of course. Yeah. I I mean, I think it is fixed in the current specification. I think this is a this issue was was open in prior revision, and it has now been closed because -- 2 of the 3 authors disagree about whether this is in the current draft, Rich. We'll fix it. Right? Okay. Next. Next slide. So we'll include that. So this as part of this, basically, the the the DNS infrastructure provided with ACH config list values to put to put into HTTPSRs. And I guess we can't have a must verified, but it seems sensible that you would check that those ECH config values work. before you publish the DNS resource record. So we say kind of a way of doing that. I I think seems sensible to have that as I should. So that's what we do unless people think otherwise. And then if there's only there's only kind of one issue well, sorry. This of things about that. One is that you get an ECH config list. So you might have to explode that into individual public values to check each one. So the the the draft mentions that. And then if you get an alias again, you just check does ECH work. You don't have a particular value to check. And that kind of the first case, basically, you need this kind of a clients, so we just know that. And then there's what URLs check. And I guess we'll just use the dot well known itself as the thing you use when checking does ECH work? So I think we've kinda sorted that out, and we'll"
  },
  {
    "startTime": "00:08:00",
    "text": "that in the next version unless somebody wants to say something else or Say it to be a must I think would be retired. Nope. Okay. Next. Yeah. There's the actual URLs itself, which is if you see the second bullet there, It shows you the URL you have now. I have a test setup that uses different DCH configs in in the same dot groups. So the previous version, there was a file name dot JSON there as well. just wanted to check probably everybody else seems to think that's a weird setup. which I guess I probably agree with. So we don't typically have web servers that would have different ECH configs, would share a dotroot on a on a file system, I think. Nobody's confident. Great. Okay. We fixed we leave it as is. close Ellen. He's making one more, is there? Yes. Oh, remember this one, Ben? I mean, I I always get confused by this. When you're not on port 443, things get a bit more complicated in my head at least. Ben Schwartz. Meta, I think we we can take this one offline. it'll I don't think that the the working group that needs to spend time figuring out this. I think it's just a spelling question. Okay? But, I I mean, I guess the thing is, you know, just you know, I I think it is the case that the working group want protocol to work on ports other than 443. So We will need to make sure that works. Right? And I think that was it. Maybe that maybe there's one there's one more slide. No. Okay. So that that's basically it. There's a few other issues that are in the slide somebody's looking ahead and wants to talk to any of them, I guess, I'm here. for another 10 seconds, at least. The next step then is to, you know, get that passionate implementation working."
  },
  {
    "startTime": "00:10:01",
    "text": "and then probably pop out as 4. And I think it'll be kinda nearly ready at that point, and it can just sit waiting until the rest of the world are the more interesting way to, like, the ECH thing itself has to do That's all I had. Nobody has other things to race. I escaped. Thank you. unscathed. Alright, Dennis. Okay. So I'm gonna I'm Dennis Jackson from Mozilla. I'm gonna give a quick update on where we are with ECH experimentation. So we've been running this in Firefox nightly. since 104. The chrome folks have been running it in Canary since 105, Cloudflare have been running it a fraction of their domains since 21. The telemetry that I'm gonna talk about in this presentation, it's all public. can get it all at telemetry.mozilla.org. toll drawn from our nightly and beta users. The first thing we're gonna look at is how our connection success rate has changed with the use of VCH, So in yellow, we've got a baseline taken from release. we're not using ECH. And then we have in Orange, ECH, Greece, So this is, like, their the testing mode where ECH is advertised in the client hello. it's not used by the client and it's ignored by the server. And then we have ECH 1. It's actually being used in in nightly, in blue, And, basically, all of this is within epsilon of normal. given that we're comparing a release population against the nightly population, and users of those 2 distributions look quite different. just to highlight that the y axis here starts at 90% to zoom this in. So this is, in general, pretty healthy."
  },
  {
    "startTime": "00:12:03",
    "text": "Latency gets a little bit more interesting. We've got the base line, again in yellow. we see that Greece kind of coincides with baseline we'd kind of expect, But as we kinda look at the actual usage of ECH, we see it slightly slower the fastest 25 percentile, and then it's slightly faster. for the slowest 25th percentile. And that's a little weird because when we do ECH, we know we're doing it with Cloudflare. and Cloudflare have pretty great connections. So in general, we'd expect this to just be fast full stop. everywhere. And when we kind of dug down to look at this a little closer we can look at our retry rate in ECH. So in ECH, when we make a connection intending to use ECH, There are 3 outcomes. In blue, the connection succeeds. In red, make the connection. It authenticates correctly. but the server advertises that ECH has been disabled. we see that's fairly constant throughout this this timeline. And then in teal, we have connections to the server where the server's providing us with a fresherechconfig. and this incurs an additional round trip. because we have restart the connection with this new fresher conflict, And since about Firefox, 1112, this rate has gone way way up as you can see. It's not causing breakage for users. but it's not great, and we need to figure out what the what the root cause is. It could be that it's an issue in Firefox. Maybe we're incorrectly caching some of these ECH configs. It could be an issue on the cloudflare side. where whatever they're advertising in DNS is not being correctly provisioned. but it's something we're looking at. at the moment. Since April, we've switched Firefox nightly into a hard fail mode, So here, Firefox doesn't really try to reconnect. if ECH doesn't work. and the user's gonna get a very ugly TLS error page."
  },
  {
    "startTime": "00:14:02",
    "text": "From that, we get user reports saying this site is broken in nightly, but it finding Firefox what gives, and we can go and investigate and and see what their situation is. So from that, we found 2 sites operated by the same organization. reasonably popular, and they just bath whenever they see an ECH grease extension. This was pretty concerning, but actually just testing it they bath whenever they see any TLS extension they don't recognize. So there's nothing ECH specific here. it turns out it's just quite a faulty, quite an old TLS 12 implementation. We reached out to the organization, and they've actually committed to fixing it and rolling out TLS 13. So happiness, In terms of next steps, yeah, we've got a down and find out what's going on with this retry issue. And we're starting some small scale release experiments. So Chrome have announced they'll be doing a 1% trial with release users between now December, and we'll be starting our own Firefox trial next week. I'm happy to take questions if there are any. Otherwise, I think it's back to issue bashing. Questions for Dennis? Alessandro Goudini Cloudflare. Just a quick question about your trial, trial, which how long is it gonna run for? That's kind of indeterminate. I renewing it at 1 month intervals. Okay. So we'll see how the data looks like after the 1st month Sounds good. Any other questions? real quick. Alright. Yeah. Steven. ahead. Go ahead. Go ahead. Go ahead. prob. Yeah. So my my question is more to the to the chairs, I steam And how do we interpret this in terms of moving the drive forward? just gonna say that anyway. I don't were I was gonna say speaking with an editor hat on, I think now we're gonna try transition into issue closing mode for the draft."
  },
  {
    "startTime": "00:16:01",
    "text": "ideally trying to close-up things before working with last call before or around 118. and unless, like, the experimental data that we see emerging from these trials, like, goes incredibly south, but that is the that is, I think, the plan at this point. Okay. So Okay. So working with Best Twelve before product, basically. I mean, we need to do the work to close open to consider open. and decide which of those are worth including in the draft or which of those are worth punting. So there's some things that been talking about for a while in the past. So One example is, like, how do you deal with padding on the server side? And we kinda went back and forth in various designs. Maybe the option there best outcome there. So just punt and deal with that separately. I think the intent is for those bigger issues, bring them to the list, see if we can get consensus to either adjust them or close them. and deal with all the editorial issues as the editors do. sometime between now and 1 18. So -- Right. It's a plan. So all plans are are -- that is that is kind of our plan. smss Yeah. But but we're not planning another hold after that. We're just we're planning to just move ahead now and get it all done. I'll I'll turn that over to the We're not. I mean, unless your experimental results show that we're cratering something, then yeah. So the I mean, I'm thinking the plan is that, like, beginning of the the New Year. It's what the ISG and we're accidents. Thank you. Right. And so just to follow-up on that. And the issue We'll send a list or a couple messages to the list. ideally one per, like, major top level issue, padding, for example, is 1. and we'll see if we can drive to either resolution or be, like, actual PRs against the text or closing them out over the next couple weeks months before the property and coming up. So anyone has thoughts and encourage you to you know, take a look at the open issues, weigh in there, or just wait for the emails to come we can bash it out on the list. Kyle, Kyle Meckhardt's meta."
  },
  {
    "startTime": "00:18:03",
    "text": "just wanted to add, we don't have any real things we can share yet, but I'm hoping they have something in the next, like, couple months. It's not going to use DNS, at least initially, 2 discrete keys. hoping next couple of slides as well. just by next to one of us, you mean sometime before Prague or like, around that time frame, have to be too specific. I'm sorry. I I don't know. You don't And I wouldn't weights. Understood. Thank you. David. Take the benchmark. Oh, Small clarification on the slides, Chrome is already at 1% of stable, So, hopefully, we will have numbers by next to ATF or something to share. Okay. Thank you, David. Alright? super quick ECH update. Thanks all. Dennis, you're back. Okay. Hello again. So this draft is a new compression scheme. intended for use on the web PKI. And the main selling point is that we wanna enable a migration to post quantum CA certificates, without inflating the size on the wire. It's a fairly simple and self contained draft. but there's still a lot of details and optimizations that need to be worked out So as many people probably know, there's an existing certificate Compression RFC from 2020. It's reasonably widely deployed. across servers and across a number of clients. and it specifies how you do client and server negotiation,"
  },
  {
    "startTime": "00:20:00",
    "text": "the compression scheme in use then goes on to standardize Zetlip, zed lip, broadly and set standard. This draft is just a compression scheme. for the rest of this talk, I'm not gonna be talking about negotiation. because it's already handled as part of RFC8879. and there's no changes there. So we're just talking about how to compress these certificate chains. The scheme is fairly simple. It has 2 passes. the first pass, we compress the known intermediate root certificates, And in the second pass, can press the resulting chain with a shared dictionary. specific to the web PKI. As you'll know, typical chain, 3 certs, root intermediate and NMC. You might see more you might see less in practice. But the interesting observation is that or the routes are already predistributed. the clients, and increasingly, we're seeing clients already distribute the intermediates as well. So, for example, in Firefox, we ship a full list of all intermediates with our clients, And we do that both for performance reasons. but also compatibility reasons to fix broken TLS servers that don't have the right chain configured. And so the idea is simple. Why do we need to send these intermediates and rips if we have them on both sides? so we can compress them. And we can compress them just to individual 3 by identifiers, The first bite is just a separator. and the second two bites are just an integer. referencing the specific certificate The heart problem is, of course, how do you arrive at what those identifiers are gonna be. And to that, we have the common CA database, the CCADB, So this is a database operated by Mozilla, Apple, Google, Microsoft, Cisco, and others are already members. and it's widely used to manage root store changes. So the current, like, CA application process involves registering with the CCADB, submitting your various route and intermediate certificates."
  },
  {
    "startTime": "00:22:03",
    "text": "and then getting approval from the various root store members. So in the draft, we define how to extract the relevant CCADB certificates, the intermediates and the roots this comes to about 2000 certificates, which we can then give an identifier to. with 3 meg of spice. But The nice trick is that because browsers are already shipping on of these intermediates, we don't have to store really anything extra. on the client, And on the server side, they only need to offer compression, not decompression, And to do that, they just need a hash to recognize the certificate. and then a map into what the identifier is. So the actual space taken on the server It's about 0 point 0 6 Meg. So pretty small. This leaves us with a chain that's had the intermediates and roots taken out, they effectively don't contribute to the size anymore. but we still have this end entity certificate. and we can split that indemnity certificate into stuff that's specific to the certificate. the public key the signature, the various SCTs, This comes to about 400, 750 bytes, And then we have a further half kilobyte kilobyte of strings which are actually shared between every certificate that changed back to that intermediate. So these are things like an OCSP URL, the different policy statements, the CT log IDs, key identifiers and so And we can compress out all of these using the right shared dictionary. and we take that kilobyte, half a kilobyte, and we can press it down to a 100a150 And now our resulting certificate chain is much, much smaller. for the past 2 dictionary, at the moment in the draft, we're scavenging the common extensions from CT logs in a vaguely principled way. and it comes to about a 100 kilobytes. in total in total In the longer term the CCADB would like to host a form where CAs can just provide binary data to use with compressing their search. And the important thing here is that need this draft to be equitable. for the various CAAs."
  },
  {
    "startTime": "00:24:04",
    "text": "obviously no good if we define a draft which privileges the largest CAAs. at the cost of the newest members or the smallest members. we'd want everybody to be able to contribute to this dictionary Equally Equally. And you know, as a result, everybody stands to stands to benefit. you can, of course, violate this principle and make things much, much smaller. You can get all the way down to 3 kilobytes, without changing the performance impact. but then you really are just favoring know, the 5 largest CA's, and we don't want to do that. In terms of versioning, you've probably realized how we're gonna keep this up to date. we're gonna have UCAs need to be added to these lists all the time. from looking at the churn in the CCADB, periodically, like, annually is a reasonable time frame for how long we'd like to update this. and potentially less And the reason is just adding new certificates to root stores. It's a long process. It typically takes around a year at the best of times. Like, Mozilla is quite proud that it takes us a year. In general, to get into every root store right now, you're looking at around a 3 year timeline. And I would like to get that down to 1 year for everybody. It's hard to envision it being less than a year. The other trick we have is that because this draft isn't doing any kind trust negotiation, We don't have to wait for a CA to be approved into a root store. add it to the dictionary So when the CA applies, we can add them at that point to the dictionary. And if they're later approved, They'll benefit from compression. from the very first day. And the idea then is that we version these dictionaries assigning a TLS certificate compression code point to each annual version. and then dictionaries are shipped as part of the TLS library. Listen. And just to, you know, be clear, There's no kind of OCSP stapling here. There's no kind of server side network fetching. This is all version just part of the TLS library. and deployed with, say, a yearly software update Real quick, Dennis. a couple people in the queue."
  },
  {
    "startTime": "00:26:00",
    "text": "Did did you wanna ask a question on one of the current slides or Yeah. It was kinda No problem. No problem. sites of questions right now. Yeah. We can do questions right now. No. Actually, this is really interesting work. Thank you. One of the things that I wanted you about is, obviously, with the changes coming in a month or so, certificates are about to get even more regular and little bit less wild west than they have been. So I was wondering to what extent are you noticing that the various very unique features of CA's are things that perhaps gonna be going away in the future or could go in their way in the future. You know, does it make life more equitable since it appears that there is quite an impact the, you know, the behavior of the top CAs versus the lower ones. If we the more regular certificate profiles going to make that problem better? Or is there anything we can do on the c a browser forum side to help you out with this a really interesting question. I haven't looked at it in detail. I That's kind of assuming that things wouldn't improve kind of go from that baseline. But, yeah, maybe it's worth talking about that a bit more. Yeah. No. I'd love to talk to you about it. Yeah. be really interesting. Watson Lad, Akamai, Do we need all these CAs? I mean, it seems like we have now up formance reason, to really chop down on some of the small CA's where the issuance isn't worth the security risk for the whole week. Obviously, it's a can of worms, but Yeah. Watson, I think it's a great question, but I don't wanna litigate how we run root stores. as part of this draft. it can wait until after Thanks. So I have just a couple more just to to finish up the the presentation. So in terms of evaluation, did a benchmark from the Franco top 100k, Looking at the median, you see about, you know, 4 kilobytes certchains. with with with with existing certificate compression, you get that down to about 3.2."
  },
  {
    "startTime": "00:28:02",
    "text": "With the abridged search, we get that down to just a kilobyte for the entire chain, And that's actually pretty close to optimal. If you look at the incompressible public key signature data, where we're now within about 200, 250 bytes of what we could hope to achieve. On the 95th percentile, things look even better. 5.6 kilobytes down to about 1.5. for the entire chain. So we're shipping an entire search chain in a packet. I think is kinda neat. In terms of deployability, The other nice thing about doing it is a compression scheme. We don't introduce any sources of error. So if you're not using a web PKI route and you deploy the scheme, anything breaks, you might not get as much benefit as you might hope. but it's not gonna make any connections fail. It's not gonna require any operator oversight. So as a TLS library author, you can enable this by default, know that you're helping people. not gonna cause them any problems, any grief, in a yearly kind of versioning we would only be changing binary data. So back porting here fine. There's no code changes that are coming every year. And, yeah, to stress again, it's equitable for both the CA's and the websites, In terms of next steps, there's been a lot of great feedback from the mailing list already. So Thank you. Thank you. I'd like to go back and benchmark how different dictionaries works. Like, we can build the dictionary for 21 for 2020 and see how it would work with the CT log trains from that year. And it'd be nice to get some numbers for what this latency improvement is gonna look like with classical chains, There are some great discussions on the mailing list and 3 to call out. was basically people looking at improving how these dictionary formats could work. whether past 2 is actually in its worthwhile, particularly if we move to PQ search, is that saving of 1 kilobytes meaningful if we still have an overall 6 kilobyteschain, whether there's, like, a different versioning strategy that might make more sense. for example, like, you know, we could ask Aina to allocate 6 code points upfront, so we're good for the next 6 years."
  },
  {
    "startTime": "00:30:00",
    "text": "or, you know, do it in a more ad hoc process. a particular thank you to some of the people that gave some really detailed feedback a panels bus, Kathleen Martin and Ecker. Thank you for your detailed thoughts on this? And with that, I'd like to turn it over for questions, comments, and see if there's interests in adopting this. Alessandro Gideon Cloudflare. So so there's obviously, like, a few issues that need to be ironed out. But it's a really interesting solution that to to a problem that already have, for example, with Quick So it's not just post quantum. it would provide value like thoroughly you know, immediate immediately. with our existing quick deployment. about the the the dictionary, We sort of got into that discussion originally when we did the certific compression work And then we decided you know, it's not really worth it. with all the, you know, discussion that was going on at at the time. It might be interesting to to revisit that. But at the same time, I guess it's not necessarily like like fundamental to the to the scheme of the compression. So you know, you know, you know, you know, Okay? Thank you. Hi. Erica Squola. So I thank you for this interesting and I think counterintuitive work when you showed it to me. I was, like, surprised it works as well. So so fantastic. I do think we should have this draft. I think there's definitely I've heard a bunch of comments about how things can be improved, and, like, you know, iron this out with the working process. That's process is for people famous to say that, you know, cap takes it from 70% to 100%. I think this seems like it's only 65. So we should do that. I do have a question However, for the area directors, which is The way this draft specifies things is there is a procedure, which one follows. as a server or a client in order to construct this database. And I'm unfamiliar with any situation in which the IETF has ever specified"
  },
  {
    "startTime": "00:32:04",
    "text": "standard, which had such a complicated procedure assembling a piece of information, which I'll show you how to do read on that every side. And so maybe this is cool. and maybe it is not and and I'm not saying this. It's not it's not a deal breaker, but if the consequence is that the IETF has to run this procedure and embed this this database in a in the RFC. that would be useful to know because that why she changed a number of the questions which she raised above. Right? particular, there's no need to be, like, the code points because what that like, then later, whatever. So my question for the early directors is, Is it and maybe you have to hit this back to ISG, is could we publish RRC? which says the way this works is you, like, Read this read the following things out of the CCADB. I'm the following time. I have to follow time of the day, the falling phase of the moon, and that's what goes in here, or can we not? Do the ADs wanna field that now? Or have some time to think about it? all the room in? Paul Vartus, AD. That's a very good question. I will I will love to talk with more than just Roman on this. Yeah. Just as a escape hatch. So, like, right now, know, the dictionary is intended to be part of the RFC to make it easier for people to deploy. we can always move to, like, dynamic dictionary negotiation. but then we're just you're punting it to applications to go and find their own dictionary. isn't like super satisfying. Yeah. I mean, so there's a room. I don't think we should decide on the design or even kinda talk constraints, I think we should go to the ISG, kinda talk through what the space is of kind of options, and maybe they'll inform the kind of the way to let's not preclude anything So we'll take an action. Great. Thank you. So Are you done? So my name is Deb Cooley. I work for NSA. My question is you're only planning to do this for the I feel really loud. Usually, I have to stand on my tiptubs. Publicly trusted CAs. What? Pardon? No. Stop."
  },
  {
    "startTime": "00:34:00",
    "text": "So So you're talking publicly trusted CAs, which is fine. I mean, that's a huge part of the ecosystem. Right? But there are a lot of enterprise that are also used that could probably also stand to use this sort of compression idea you thought about that? Have Probably Yeah. I mean, it's it's tricky because not. you know, we're serving the enterprise space. There's there's really varying levels of competence at which people run these internal PKIs. you. I know I know I know some people do a very, very good job, but Thank there's a very long tail of people that that struggle, Yeah. Yeah. Yeah. that does make it difficult. And that does make it difficult. It's because You have to, you know, produce this list upfront and make sure that you keep it up to date, and, you know, we see in practice people struggle to distribute those intermediates themselves themselves Whereas in this draft, we're relying on the fact that clients are gonna you know, version version this for them. I think it's interesting. We could easily define this for different route stores and make it very generic. and they could then make use of it, but they would still need their own code points, which are available to just be grabbed as far as I know. So so I will say have as as So I don't I mean, I don't run. I'm a I'm a security evaluator. Right? So I watch it and tell them what they're doing wrong. but as that person so we do have to deploy our own route in our own intermediates and our own subordinates. So, generally, our chains are one longer than what you're talking about. but we do have to deploy those and put them into the stores because they're there already. We don't get them for free like everybody else does. So, yeah, I think you could certainly benefit, especially if you've got longer chains. and you could use the same process that's described in the draft. really just changing, you know, where you pull that initial listing of of Salesforce. So I think that's a vote for having the draft be a procedure a protocol as for? We can figure out we can worst match that a little bit,"
  },
  {
    "startTime": "00:36:02",
    "text": "at the moment, it already tries to parameterize it a bit on which root CAs are involved. we can talk about how to make that work for us. So my other wonder is whether you could put these compressed objects into the CCA ADB, itself. Yeah. I think that's that's reasonable. But, again, it kinda comes back to the IOTF question. of of how to organize this and how to to ship it around. I do think it's an interesting idea. I I I wonder I also wonder whether it will help us in the time frame. When things get bigger and bigger, can we actually put things other places we don't have to pass them across the water quite so often. Yeah. Absolutely. Awesome. Thank you. Thank you. Kyle Meckritz. I'm very interested in work. I think this says great idea. I'm very glad we went with the 2 byte code point for the compression type. One other use case that I see as a potential here. I haven't completely thought this through, but with multiple root programs recently having varied degrees of announcements on trying to rotate roots themselves more quickly. I think there is, at some point, going to be an issue of trying to maintain compatibility with clients that are not updating as quickly. And if we now have a a code point that's potentially in client's saying how updated they are. I think we should be think through, like, what possibilities at AS. And if that helps us potentially in a server, serve different routes or decide which cross signs that we might need to include as enemies as well. I think that's a potentially very valuable use case at this. Thanks, Karl. Yeah. I think that's a really interesting question on the trust negotiation. something like David Ben and I were talking a bit about recently as well. this draft, I'm trying to steer a little clear of that. insofar is, like, this is trying to be quite slow moving. so that everybody can really benefit from it."
  },
  {
    "startTime": "00:38:02",
    "text": "I think in terms of, like, the rotating of roots themselves, There's still some stuff we need to work out there around the threat model. and how that helps. But, yeah, that's really interesting. Thank you. Jonathan Huddl and Cloudflare. This has sort of been addressed in the Zulik, but I just wanted to bring it to the mic anyway. this sounds like you might be opening up another venue for the TLS crime attacks. I it's look in the Zulu, it's been explained that they don't apply. But, like, put it in the security thing that people like me don't go, Does this, like, Yeah. Yeah. Yeah. Okay. Good to know. Thanks, Jonathan. Rich Salzakumar. Yeah. I think this is really cool stuff there's obviously some things around the edge that we'd wanna address. I would say fix, but address. Just just make sure there's a toolkit so that all the other server operators can easily generate the database. Like, obviously, you will and Chrome is open source too, but sfs my developers don't have to write one. That'll be easier for us to adopt this in CDNs. Thanks, Rich. Great. Yeah. Martin Thompson, I'm in paper of adoption. to answer some of my questions before, I don't wanna rely on the ISG going off in their ivory tower to make some decisions about this, and I think the community can probably make a decision about the question of procedural versus whatever. Though I think it does need to be a broader discussion and just this working group. So there is that, but my preference would be that that we focus on just doing one for now. and then talking about codifying practices if it if it turns out that we need to be able to update more frequently. So The first version of this, I think, would be a fixed thing. the second one or subsequent ones would with at some point."
  },
  {
    "startTime": "00:40:00",
    "text": "do a little bit more to that point, those folks who want their enterprise search in here. have the option of registering a code point based on the existing procedures that we have. And I think that's a very good strategy for someone looking to get sort of performance advantages that that accrue to something like this in those sorts of settings, particularly for those those larger enterprise settings. it's not particularly difficult to go out and and write the necessary applications in order to get your code point and and have that work. Yeah. I I think it's just classification required or maybe even experimental basis for the Yeah. And and it's possible that you could put a little bit of guidance in this document, you know, if you wanna build your own, here's here's a sort of template for how to do this. We've done this in in in other documents as well. you've got your FF 0, whatever it is, prefix that you've you've got there is potent there's also the potential to use that to expand the the effective code points base for diversity there. Yes. So if you do that, at that point, it's gonna break if you that's that's true if you misnegotiated. But if you're talking about a a, a setting where the clients need to have your roots anyway. then you potentially in a situation where having them know compression dictionary is is not particularly big jump. beyond that. So I I I think we can make that work, but I I would sort of caution. Let's let's keep it to the simple thing for now, work through the problems there. prove that it works and then talk about the iterative -- Yeah. -- and and programmatic version. Hi. Rory Steele. So I'm I'm still trying to wrap my head around the idea sounds very interesting Am I right to say that sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of you're sort of sort of you're sort of you're sort of you're sort of exploding some structure within the transparency logs to build a sort of"
  },
  {
    "startTime": "00:42:00",
    "text": "a kind of domain specific compression, This is a general sort of thing that can be pulled out and used in other transparency scenarios such as note the supply chain transparency work or key transparency work, where perhaps some part of this compression piece might be generalized, and and it seems related to the question on, like, If you're specifying that, compression dictionary, in the right sort of way or perhaps it can be reused in other contexts. Yeah. That's really interesting. So At the moment in the draft, the reference to CT, just for scavenging these extensions. So, you know, it's quite ad hoc because I wanted to be able to do some evaluation without having to ask a bunch of CA's to provide me with example profiles. the original motivation for this work was actually looking at running a CT log But more effectively. Right? because you can use this for for compressing the individual records. And, yeah, I think there's there's some things probably worth exploring now. to see if we can we can make it work. Love to chat with you after. Yeah. That'd be great. Yeah. So I'm partly up to say what Martin had said, but I think an observation that, like, should be obvious, but just to make sure it becomes the same page, nothing prevents a client from supporting concurrently multiple compression compression lists. And so And so it's and so it's perfectly straightforward for a client support. generation 1, not generation 2, but also generation 1. And prietary stuff that your enterprise is configured. And so it is not necessary for that enterprise. And in particular, it's not necessary for that enterprise, to I to populate their list completely. All they have to do is populate it with their own certificates. which can be a very small dictionary. So it's the so they don't have a giant challenge of discussing it. Yes. So So I think that, like, that's a pretty good answer to, like, the the the the problem I had in enterprise to deal with this. because it only burns 1 22 bytes in the in the client hello. nothing in the server and nothing in the server messages. And if it turns out that we, like, run out of compression go well with freaking that somewhat. Yeah. Absolutely."
  },
  {
    "startTime": "00:44:01",
    "text": "Benj Schwartz. Meta. So first of all, there I wanna note that I haven't heard any discussion of the privacy implications here. you know, if there is no explicit versioning, then there's very little leakage here. But the more configurable this client hello option is more it reveals about the client in plain text, I think there's there's some threshold at which I would say this only be used with encrypted client. Hello? So in terms of the privacy leakage here, the intent here is that every single client can deploy the same compression dictionary. So there's not gonna be like a Google dictionary and a Firefox dictionary. That's just gonna be everybody that's using this draft is using the same code point. So there's no, like this this which is much less than what the current client hello already else because it's specific between different Firefox and Chrome versions already. So it's it's incremental leakage. Right? is it's on top on top of any of existing fingerprintability, It's No. It's not necessarily. It it it it's, like, can be completely redundant information. Right? Sure. If if it's if there's truly no entropy in it, then 0 bits of additional leakage on top of the existing -- Yeah. situation. But that's a little hard to believe. You just mentioned that there's multiple versions, so there's gonna rollouts of these versions in periods where where clients disagree. There's We've just heard discussion about potentially inviting enterprises to advertise additional compression algorithms, there's that would be highly identifying. Yeah. But I think it's worth understanding the wider context there. Like, we already give enterprises switches to do their own TLS config anyway. for example, if you're a regular enterprise and you're running TLS 11. Like, that's obviously traceable over the network because everybody else has turned it Yep. Yeah. But that's, like, also, obviously, a a super terrible idea, whereas this is kind of a good idea. Yeah. Yeah. And I would also, you know, kind of"
  },
  {
    "startTime": "00:46:00",
    "text": "refate stuff like with TLS 12 that people again widely using, which reveals the service certificate in in plain text, for example. Like, that's a lot more information about what a client is up to. then what this is revealing, which is just that you had a TLS library update in the last year. Sure. So I wanna Remind people to think about that. as a CTLS coauthor. This is a lot like saw like, one of the components of of CTLS, and I'm sure this has gotten more attention and love than than the CTLS version of this has. Maybe maybe we can just backboard it and and rip out a bunch of text from CTLS or have to think about that. I do think that A 2 byte code point space is not comfortably big enough to invite of the enterprises in the world to mince their own compression compression code point, I really think that we we need to be a little careful about that and I think probably the right answer is something some some version of the pattern we've seen many times where the short code points have strict requirements and the long code points are easy to get. Yeah. And I think that is the current format for the current compression points, Worst case, we can always mint certificate compression with a 4 bite. identifier if we have to. Alessandro Guodimiclott alert. There is, like, the the initial range is sort of reserve, but and then there's a longer range at the end for experimental use. But, anyway, I wanted to reply to the the whole crime discussion As far as I remember, there's actually text in the RFC. So if that's the case, I don't think we need to repeat that in every drop that actually uses impression, fresh impression, fresh impression, fresh impression, And, also, like, if it wasn't clear before I'd be interested in implementing and deploying this. Docker. Thank you. Real quick, Dennis, may I suggest on Ben's, like, fingerprinting"
  },
  {
    "startTime": "00:48:04",
    "text": "a comment. Maybe just add a couple of text. Yeah. Absolutely. security considerations. Basically saying what you as the mic. Cool. Thank you. Thank you. Basestmann Klotzler, is Greg. I'm a favor of adopting. have you got any performance metric on how on CPU cycles required for the compression plant Yeah. I don't have anything for you at the moment. The dominating factor is Zev standard. and you can run that between minimum and maximum. The server can choose have a level of compression it wants to use, The difference in actual, like, compression ratio is about a 100 bytes. if you wanna use the fastest possible zed standard, you can. You don't you don't lose too much from that. Thanks. Thank you. So, unfortunately, the way that the So I agree with you that you can work a a 4 byte compression scheme. unfortunately, the way the way that the the way the compression system works in in TLS as opposed to say quick is that the numbers not taking me less space than the smaller numbers. And so And and so and so and so it's not useful to and so in the current design, not helpful to segregate the that that that's popular ones and lower. That's just a convenience for location. It's not a it's not an performance optimization. So I think, you know, if we were to do You know, I I I I think it we're gonna run up 1 or 2 attitudes. 1 could say that, like, you know, since it's our first come for served, we'll, like, watch the deposit or or whatever they're spec required. Like, watch their repository and to start scaling half full of them, we'll make a full right version. know, we can make a forward version now too or an or a variable length you thing, but now or whatever. Right? But I think but what But initially, it's really not not enough room for everybody out everybody to have one. But I I think my suspicion is we'll actually see very little use of that by enterprises. because enterprise is typically, like, people are on the fast network anyway, and so it's not that big a deal. And So I I think it's probably fine. But if it's not fine, I think we can find it fast enough. But as I say, I really gotta say that, like, that that right now, it doesn't help you to use small cut points. Yeah. Yeah. Absolutely. It's it's fixed two bytes."
  },
  {
    "startTime": "00:50:05",
    "text": "Alright. Thanks, Dennis. There seem to be pretty clear in this document in the working group, but in the interest of being, I guess, complete, I'm gonna do a quick show answers to see, you know, if they're if everyone who hasn't yet spoken could do could do so in in favor of adopting this or not. So Yeah. In the echo. Yep. So I'm gonna start that now. Okay. I mean, it seems clearly going in one direction. only one person did not raise their hand if they would like to come to them, I can say why. free to do so. Otherwise, we will confirm on the list Alright. Thank you, Dennis. Thank you. Next up, we have Rich for TLS 1.2 is frozen. Okay. Hi. Rich Sol's talking about a draft next Page. side, Okay. So at the last IETF, I committed to we do a you know, I write a draft saying that 1.2 is frozen because it can sense this was that we can't deprecated yet. the industry isn't ready for that. So"
  },
  {
    "startTime": "00:52:04",
    "text": "What the hell? No. No. I'm come cheer anymore. I got some time. So the intent by saying frozen common term, may may not know it. There's no new changes. Right? We're not gonna add new things. We're not gonna add new signature algorithms, new certificate types, and so on. but there may be deprecations because the tax will get stronger, and so we'll find the version, you know, we'll find beast 2 or son of crime or something like that. thanks to Nimrod Avraham, for joining as a co author, he made many improvements probably wrote about half the draft at this stage. next No new algorithms. You can register ALPN and key exporter. labels, labels, This is what the draft says. Otherwise, no new registries of no new registry entries of any kind that be in the INA instructions and the designated expert instructions. of which I'm on. We need an annotation for all of the registries to say some so you can say something like this is for TLS 1.3 later. Like, for example, when we standardize on public on quantum safe algorithms, you know, TLS 13 or later. particular, this would imply no post quantum support in TLS 12. which might help be a driver to TLS 13polesquatin. Next, Impact on other protocols. any new protocol must say must support TLS 13. if there are deployment concerns such as we're documenting protocol already in widely used. We've seen that happen with very you know, with various crypto algorithms sometimes get documented with the draft says, if deployment considerations were concerned, They may also say tlsone.2. Next, requesting adoption,"
  },
  {
    "startTime": "00:54:03",
    "text": "wait a cycle, and then the next IETF I think it's gonna be ready for last call. So questions. Mike, go ahead. like, Elsworth? If somebody discovers some fatal flaw in the logic documented in 1.2, and we need to go back and actually do a security fix some core logic. mean, in practice, we would just do it. But the way you've worded this is we wouldn't be allowed. Well, I'm not sure. I don't think we'd actually Changing yes. we can always put up if we have to change, say, you're talking about, like, the state diagrams or the message flows if we found a security flaw in TLS 12, I don't know. the IETF may say, well, clearly, 12 is broken. Don't do it anymore. Or and all the vendors would just fix it, and maybe somebody would issue an RFC that says this one, you know, TLS, not quite that yet. Jonathan Holden Cloudflare. Just to future proof this, maybe don't say musting to TLS 13. because then when we're trying to deprecate it in 30 years' time, we'll be like, oh, we still have to include 13. That's okay. Yeah. The current yes. The the currently specified latest version. Yeah. That's a that's a good editorial comment to make. Thanks. hope I remember it because I'm the one taking notes. So Nehalzky will Jonathan just said what I was gonna say. I was gonna ask why not 13 or newer? Alex Is 13 in trying forever intentionally? No. No. It was just because Yeah. somebody put in the notes or send an email, it should say whatever the current version is. Thanks. Thank you, Martin. Kyle Edwards. I think this is the intent here. But when we say"
  },
  {
    "startTime": "00:56:02",
    "text": "TL is point 3 as a default, and then TL is point 2 as an option. we really mean a negotiated support. Right? Yeah. Yes. Nicole. Yeah. It's what what you spec in the, you know, the Minman min max versions that you negotiate. Yes. even though on the open Internet and the Well, user facing Internet, TLS 1.3 is prevalent plus. For enterprise deployments, I don't think that's the case today. And if we are to add stuff like workload attestation, I'm a coach on one of these, but never mind. the the notion. of of attestation. for enterprise workloads, enterprise APIs, we're not going to be able to do that for the protocol that people are actually using today Okay. So with We're not the protocol police. I mean, if they're not gonna deploy 13, which is this official standard now. I'm yes. I understand. are out deployment issues, and this is just trying to say you know, shouldn't do below 1.2, which I think the industry's pretty much already moved to. of course, enterprises aren't moving as fast. enterprises are never moving as fast, and And I think I think we're we're shooting ourselves in the foot. us and the industry with this blanket decision not to touch 1.2. I'm curious. what do you think we might need to change in 1.2, adding noose encryption algorithms and stuff? So so that's specific draft I have in mind is is"
  },
  {
    "startTime": "00:58:05",
    "text": "is adding some some new code point to to the certificate payload. it doesn't matter. It's something somewhere inside of the TLS and Chic. Okay. David'skenazi process enthusiasts, apparently. I think your draft attempts to do 2 things that are somewhat separable. The first one is any new protocol running on top of TLS should be recommending 13 and not saying you'd do one 2 and then maybe think about this cute new one three thing. So that that that's kind of a BCP, 100% agree with you. That's, like, not doesn't even need to be binding. It's, like, common sense. In that way, lushing out as a BCP, So if someone tries to do the wrong thing, someone can go, hey. Look at the BCP you're holding it wrong. So that 100% good. The other part of your document is Don't you must not touch 12. And so let's say Let's game this. Let's let's say, you know, This gets published. We move forward 6 months, and the the scenario you just right. We find a fatal security flaw in 12 that can be fixed either with, you know, let's say, you know, something like extended master secret in 12. or it can be fixed by just use 13. And then we have a choice to make. We can use either of these. And At that point in time, we will make that decision based on that vulnerability with the information we have. the thing that this seems to forget is that can't look at any PRESTRC and rip it up. all you need to do is see an update tag. And so at that point in time, Whether this RFC was published and written or not will not come into that decision."
  },
  {
    "startTime": "01:00:01",
    "text": "because that decision will be informed by deployment experience security, like, importance of the vulnerability and so forth. So I don't see the work of saying don't do one to us particularly useful. Because at that point, that will just be a nudge And personally, I think, you know, implementation aspects, deployment aspects matter much more than in our see that someone wrote at some point in the past. what I might suggest as a process side to to do this nudge, could be a change to the charter. of this working groups. We all love recharters. They're fun, and they give our ID's job security to specifically state things that. But even then, I'm not convinced there's much of a need there. But, again, I don't feel don't feel too strongly. I won't, like, get in the way of this, but I don't think there's a need for that part of the document person I think the intent or certainly the intent as I was writing down what I thought the working group feeling was the working group didn't wanna do anything more on 1.2, and we wanted to signal that to the outside world The writing may not be too good enough or not. And maybe the working group now, because what you've said and Sharon Yaron has said. Maybe that's not the consensus of the working group right now. fine. We can have a 1 paragraph DCP. I'm fine with that too. If we go into it with that message, then that sounds reasonable. I won't, like, object to this. Thanks. Watson Led Akamai, I really like this draft. I think it's I think we've over the years had a number of cases where people have been share the word depreciate. there is a word for saying, you should start thinking about moving a new thing and that word is appreciate. I understand why you can't use it. But I think people need to get over the meaning of this word and realize that we need to do that. We need to have a way to signal you should start moving a new thing. I think Jeff does that. Contradavid, I think that recording the sense of this working group in a way we can point you and say, Here are the reasons why we said that"
  },
  {
    "startTime": "01:02:02",
    "text": "We don't wanna work on 1.2 anymore. we wanna put our efforts on everything you want, TLS 1.3. Your upgrade path is TLS 1 point 3 I I think it's valuable as a way to sort of record and crystallize our reasoning. regardless of whether or not it's actually a effective forever in the process. Obviously, we can go back and revise it by just writing it down and remembering, didn't do that has an effect. Actually, I think it's Florence, are you in the queue? Ben Schwartz, Meta. Okay. I I support this. I think it sounds like there's been some concerns specifically about how this would interact with a high methodical catastrophic security issue. Maybe you wanna consider a term like feature freeze. I think they're people talk about freezing in different ways of feature freeze, I think, conveys your idea that there's not going to be any new functionality added to TLS 1.2, which is a little bit different for saying that we're not going to try to fix serious issues, although you can you can perhaps say that we'd like to avoid that, and we'll try to try to avoid that. I do think this is valuable as an IETf consensus information document to the outside world, like, Don't expect us to do anything interesting with TLS 1.2. It's not gonna happen. and as an enterprise as if I imagine myself as as an enterprise system administrator, I might actually rejoice. to hear that my old systems are not going to have anything interesting happen to them. and they're just going to stay exactly the way they are, and and there are going to be very few updates the libraries that depend on and so on. Yeah. Yeah. bug fix releases only. Hi, Florida School at UK And TSC. So I don't know what, like, how the enterprises there are out there who are still using TLs 1.2 because they're relying on features TLS 1.2, but I I would suggest it's non zero."
  },
  {
    "startTime": "01:04:04",
    "text": "And I suppose this this concerns me a little bit because it's completely reasonable that those enterprises would want to continue using TLS 1.2 in a purely configured way. and would also want future features. And I appreciate that that's not what the working group as it stands once to work on, and that's fine. But if somebody turned up in a year's time and said, want to work on this. there is support to work on, like, a particular feature to TLS 1.2. then it feels like addressing that proposal at that time with the people in the working group then it's it's the right way to go about it rather than saying, as of today, if you turn up in the future and want a feature, then, no, we're not doing anything. So Yeah. Yeah. Honest, I I think the document in the way it's worded conflates 2 issues. One is the question of what the group wants to work on, and the other one is how the deployment situation looks like and recommendations regarding its implementation and use and I'm fine with for the crew to decide that it want to spend its energy on on extensions for TLS 1.3. but I'm I feel uneasy about conveying the message that it's not a good idea to use TLS 1.2 and implicitly detail s 1.2 because some of the industries are moving much slower than the web industry And so they have they need much longer to transition over to 1.3. And that's that's my worry you is implicitly you can reach through the document. You implicitly saying, like, switch to 1.3, which Because we don't considered to be good anymore. the 1 or 2 version, which is That's fine. Yeah. So I think No. that's probably a fault of the writing then because we did explicitly say, you know, You can configure TLS 12 securely, and maybe we need to make that fix up some of the other wording. So this is Deb Cooley from NSA again. It pains me to say this."
  },
  {
    "startTime": "01:06:03",
    "text": "but it is true that enterprises do still need TLS 1.2. There are some things you cannot do with TLs 1.3. When TLS 1.2 does go away, which it will eventually. because it will become vulnerable, those enterprises will have to do things differently. So while we encourage them to work on that now, They're not there yet. Sure. I think I am next. Yeah. Good. So guess, I guess, I guess first so I think first of all, I deserve that the Charter actually does like, make a bunch of hand waving about how we don't wanna work on older versions. But it specifically says, changes additions to older versions of DTLS where every extensions are safe, which is scouraged and requires significant justification to take out those work items. So I think, like, you know, I can imagine striking that fax somewhat. I I certainly you know, I think I certainly I certainly agree that, like, if we ran this duration where there was, like, some like, massive vulnerability 1.2, and it could be fixed by, like, changing one bit in the header, which we probably just, like, bite the bullet and do that. So I I I think, you know, I I think that that would probably, like, attention to what we wanna do is say, like, we're do not expect, like, any improvements at 1.2, like, any meaningful improvements at 1.2. You know, I think that would be, like, the probably the easiest way to do is, Davis, yesterday, we didn't modify the charter and basically, like, sharpen that points a little bit. You know, I think we say I think we say, like, you know, I don't wanna work that too much, but, basically, say, like, you know, not gonna do any more of these, and the only thing we do is security fixes. I think that the easiest thing to do that probably rather than having the RC. I don't I don't really have a strong opinion about the other But I think if what we're trying to signal is we're trying to signal is we're not maintaining this any we're not doing anything other than, like, maintaining for security, I think the charter is supposed to be. I guess would say, we would have to make the charter change e even if we publish this this document as an RRC, we then have change to say the thing this document has. So I would ask whether we could just change"
  },
  {
    "startTime": "01:08:00",
    "text": "So just because I did this talk last time. Right? that's where we started, and then we everybody said it was better to have an an RRC to point So I'm fine if we walked back and forth. That's why we wanted to do this exact I'm this discussion. So atnalini. I mean, yeah, definitely. There's a non zero number of enterprises that use TLS 12. I but I and I think maybe a little bit is a solution is, like, if if you're maybe the title is maybe part of the problem too. I mean, because there's 2 different things. I mean, if you're mean, definitely everybody needs to be encouraged to go to the latest version. No no question. about that. People are slower than we would like. Of course, no question about that. but I think if you if the message you're trying to convey is that the group doesn't wanna do stuff. It's not quite clear to me that TLS 12 is frozen. It's not clear to me that maybe that is maybe a little You know what I mean? It's like, that's a little different statement. than what you're trying to do. I don't know if that makes sense to you. Okay. No. I think whoever it was, it said, oh, no new features in 12. It's a better expression of the sentiment that the document was trying to get to. Yeah. So I'm going to discuss whether we should or should not, but my point is more about we speak about enterprises, But enterprises are not in this room. Right? So I met the poll, none of the people we are talking about, like, energy Providers, retail, finance sector. They are not in this room. Just to give you a scale on security side, I recently asked a question to a group Cesar of a prominent energy company. what is your strategy for the next 5, 6, 7 years? He said, Arnaud, my strategy for next 50 100 years. and I really leave it at that. Okay."
  },
  {
    "startTime": "01:10:05",
    "text": "Hi, Roman De Naidu, No Hat, Carnegie Mellon University. I was quite weighted by what David said earlier. I know that they would still be too short drafts, but I would separate the future design guidance for all the other protocols for what we would say about another existing point of call that now. Would that then go to UTA? Yeah. Actually, yeah. My off the top of my head. Yeah. Okay. I'm David Skinazi's security enthusiast this time. I'm somewhat confused about the comments that I have made at the bike line about enterprises until s 1.2. And about talking about features that TLS 1.2 has that TLS 1.3 doesn't have, My read of the situation as an individual contributor is that there is some pretty strong consensus in this working group that those those features that TLS 12 has that TLS 13 has are considered bugs. That's why we removed them in TLS 1.3. And, actually, you can bring those back in TLS 1.3 if you want. There are drafts that have been written about bringing by a and esthetic keys. You can even write a draft that puts the certificate in clear if that's something that you think is a good idea. And so I'm kinda confused by this idea that, wait a minute, enterprises are doing one point 2, and, therefore, we should work on these things. I don't think this is what these enterprises want. What these enterprises want is browser vendors or server vendors to be deploying these TLS 1.2 fixes. I hate to be a spoiler but they won't. Like, I'm not talking on behalf of any browser here, but I can I think probably suspect that if there is a new feature coming in and even if the spec says we'll do it in 13 and in 12. it's very possible that multiple browsers will say we're only implementing this in 1 3."
  },
  {
    "startTime": "01:12:01",
    "text": "So all of this talk about enterprises and 12. That's all nice in theory, but I don't think this has should have any impact on the work we do here. because let's talk about the people implementing this. Those are the main constituents of TLS and what happens in this working group. I I I feel did you live? Valley responses, I kind of feel obligated to channel Peter Gutman I can't do the accent so I won't So So when I say that enterprises rely on it, doesn't mean I agree with them. Right? They do rely on it. they do they do feel that they need to have boundaries there. Little walled gardens. Right? So they're a little favorite thing to have. And when your resources on the inside that needs to communicate with the outside, then you need to be able to make sure your little walled garden is safe. And so the way they do things today, You can only do with one for and what album is sweet. I don't like it either. I don't usually work on these things because I might Not be polite. So So yeah. No. We divide and conquer, and there's another guy that works on the things because honestly cannot do it. Right? So there is change of foot within the enterprises that I support. to do away with some of those things. Those people are to their they're very persistent and very persuasive, and it's difficult to to persuade them to do things a different way. And I do agree with you. You could design it another The problem is they can't build it. They have to buy it. And so it has to be already in these products. ahead of time. Right? We talked about this back during the little, you know, the little times when we were talking about RSA and TLS 1.3. Right? We talked about the fact that you could use static d"
  },
  {
    "startTime": "01:14:00",
    "text": "you could use all sorts of stuff. Right? it has to be has to be implemented in a product, and a lot of these product developers put it in there unless it's a standard. So I agree. I mean, I'm that's why I don't I I don't know that I've ever come to the mic to talk about this before. because, generally, I don't agree with the whole position. So and that's me personally. not Exactly. So and in December, I will be an individual. So so So you know what I mean. Right? So I don't I think it's hard. Right? I don't want to see TLS 1 point to deprecated so much that we can't can to the the you don't wanna cut these people off at the knees. You do want them to migrate into something more. Sensible, it does take time Sometimes, I mean, the speed of government can't tell you. slow, really slow. So Yes. Oh my god. Even by even by ISO standards. or let's not talk about yeah. So that's why that's why I think you can't I think we need to be careful. I I do agree that you don't wanna add new features to it. I do agree that you don't wanna spend any time working on it. I do agree that you wanna signal to the out that you're not gonna do anything more to this. I'm fine with all of that. Right? I just don't think you can't don't please don't deprecate it. No. I know. He Well, yeah, but there's a draft. that deprecates that algorithm. Not his draft. Quick response to David. The reason I was talking about 1.2 in the enterprise is not the funny stuff that we all hate. that would mean changes to browsers,"
  },
  {
    "startTime": "01:16:01",
    "text": "It's mostly about service to service traffic. So API traffic. And to give one good example is about a year ago, my own team had to had to add LS 1.3 support. to one of the most important open cell service mesh implementations. because it wasn't there. And to this day, 1.3 is not configured by default. in that particular package. So it's it's all about inertia. Once again, I'll be very brief If we need to send a signal after 5 years that people need to be moving this way, we need send that signal, and the word is depreciate. If nothing else is gonna get their attention, and they need to claim. step different yeah. Okay. Depricate. Sorry for the pronunciation. but but nothing else is gonna get their attention, that's what they need to hear. And if fact that they're complaining about it and they aren't complaining about anything else, says that that's the word we need to use. Alright. Key was closed at this point. Thank you, Rich. So the I I think the chairs do agree that there are kind of 2 fundamental pieces of this draft first of which is the recommendation that Domino's used TLs 1.3 going forward and and is generally considered a good practice. And the second of which is that TLs 1.2 is for guess, some definition frozen, feature frozen, what have you. We would like to see them kinda split up. And based on the discussion that we had last time in the meeting and the the the comments with the mic here. like to do a quick kinda show of hands to see who is interest if the working group is interested dopting that. TLS 1.2 is frozen component of this draft as a item for this particular working group. do do an echo or meet echo, no. please let us know your thoughts."
  },
  {
    "startTime": "01:18:02",
    "text": "The the charter question that was raised by Ecker, I think we can address that separately. Shouldn't be too much reacharter on the basis of, you know, this particular document being adopted. Okay. We have 54, 5114 against. Does anyone who mostly did not raise their hands. They wanna come to the mic to say, why? the Yeah. provide new information. to the group that has not already been presented at the mic as to why this perhaps should not be adopted by the group. Okay. If not, thank you very much, Rich. If we if if you're planning I assume you're planning on confirming to the list. Absolutely. Give me a week or 2 to, like, split the draft and fix some of the editorial comments? Sounds good. Yeah. choose a message when you're done, then we'll take care of it. Thank you. Alright. I think then last if we have boss or Tom, I'm not sure. Do you wanna drive, or do you like us to drive? Would whoever took the notes while I was talking the name of the No pants. No pants. Thank you."
  },
  {
    "startTime": "01:20:03",
    "text": "So because we're only working on putting post quantum into TLS, authentication with various drafts, I thought it would be good to give an update on the new content signature schemes that are on the horizon. As you might already know, NIST picked already 3 signature schemes, delive in Falcon And Swings, which are going to be have final standards probably mid next year. So one more. is because they are not that great. So So Falcon I mean, all of them are large. Falcon is the smallest smallest signatures and public keys, but the promise to to crits signatures you need with acceptable, performance, you need floating point arithmetic, which is really hard to do in constant time. So that's not a great up at Falcon. The Lithium is is easy to implement, and as fast, it's it's signature as a quite bit big and just like a spodal key. Then there's the question of security, which is not well well, then there's swings, which definitely is secure, but the signing time is up terrible and they're rather big. there are a few ways to cope with this. So by not changing the signature scheme but changing the protocols, so various variations on suppressing intermediates such as Dennis presented, we can replace the handshake signature by cam, off cam, or oscenosis cantillers. And there's bigger redesigns such as mercury certificates. But these But the easiest thing, of course, would be to have a better signature scheme, and, I guess, in this degrees. That's why they launched an on ramp with a lot of submissions, this will take"
  },
  {
    "startTime": "01:22:06",
    "text": "probably many years, at least 3 years, I suppose before anything out of it. That's and so the 2 weeks ago, then 1 week ago, they published the the the all the submissions. So would be nice to have a look at them how they effect less. So these are the 40 submissions. And within the 4 1st week, and these of them were already broken. or actually, these are not all that are broken. after I prepare to slice also DME sign the security that came into question, although and of Felicia. This these are not necessarily completely correct. Right? But someone sends an email. I think this is broken, and that attack might or might not be correct. Not all of them come with scripts to actually bracket. A few of them knew. Okay. Of them, not all, are actually practical. So these ones are the ones that have verification times which are more than 5 milliseconds. Then these, which are crossed off have signatures larger than 3 kilobytes. I really wonder why they bother submitting. So for for for the for TLAS, there are 2 use cases where where you have a public So it's searches with certificates and and the least certificates. and where there's no public key such as cities and root certificates. So for public keys, So for specific usage you wanted, the public key plus the signature is is smaller than 4 kilobytes because otherwise, white water, you can go with the lithium. So then we are left with EHT, which I think is broken. Only these few were left. If you look at them, then the The best one is the new sign, although that one is an attack on it published 2 days ago, which might or might not there's"
  },
  {
    "startTime": "01:24:04",
    "text": "be fixable. And after that is mayo, and then we already have Falcon and Hawk. Hawk is quite similar to Falcon. So but it's better. But in the security assumptions, it's quite similar. So the question is whether whether That will be added as 1. And it mayo looks here very interesting with the public key of a kilobyte and signature of 300 bytes. Actually, Mayo has has a smooth thread off between SARS of Publicly and SARS of signatures. So you can increase the size of the public key and decrease the size of the signature, and they've chosen 2 trade offs. for the submission. For for SEDs or for world certificates, Yeah. be cross of all the ones that have signatures bigger 666 bus, which is falcon, and we're left with with these. which, again, DemiSign is almost too good to be true. I don't think it will survive. You have various variations on unbalanced oil and vinegar. They have they are quite interesting. They have publicies of 60 kilobytes, and signatures of 96, but so UV, so that's the plane variation. that exists for quite a long time, and probably is secure. but it's especially the variations on UOV, which decrease the size of the public key that are where security is always a bit uncertain. UV looks very interesting. And, again, mayo looks quite interesting with the larger variant with 5 kilobytes. publicly and signature of 180. So concretely, what could we do? if you just use DME sign, then that adds compared to p 56, only 3 kilobytes, and that would be complete Sorry?"
  },
  {
    "startTime": "01:26:02",
    "text": "And that would be completely mitigated by Dennis' abridged compression. but did survive the weekends. I don't think it will survive the next weekend maybe with So mayo, if you use mayor's not. So mayor's 2 variants, one with a bigger probability, and smaller image, someone with a smaller public key, but slightly bigger signatures. You can use both variants in the two roles. that's at 3.3kilobytes. which is practically completely mitigated by Dennis' draft again. Only the sunning time is a little bit worse. about 8 times worse on p to 56, but we're still looking at only 300 microseconds. secured is definitely that in the DME sign that Although, Perhaps there's a big attack attack on mail. We just don't know. It needs it needs the few years of analysis. Then we can also use a UOV, which will have then we'll have 60 kilobytes for the for the public keys, which is fine for for for for roots and and the a a certificate logs And if we would use Hawk instead of Falcon for the for the segment for the handshake signature, it would add 3.2 kilobytes. If you instead would stick with the lithium, we're looking at 7 kilobytes, which is still much better than the 17 kilobytes we're looking at if we're just using the Lithium. And as a final one, I wanted to mention ski sign as Watson mention that only list. That would add I mean, few hundred bytes, but we're looking at the signing time of more than a and a verification time of more than 35 milliseconds. So I don't think that's workable at all. Alright. Alright. I lost the"
  },
  {
    "startTime": "01:28:05",
    "text": "So a record still no perfect drop in, but it's much better if they at least survive. I want to say that this is all very preliminary, not just the security, but also the performance numbers. we can expect them to to chase quite a bit. Thank you. Alright. Becker. Go ahead. Thanks for doing this. It's really good to see, like, this big data here. So I'm I'm gonna channel DGB for a moment and then and and then ask ask you to see so wildly speculate So I the the gelling d g b is point that the that the the key sizes won't change, but the but the performance may change. So that is just we're expecting faster versions of these implementations worth says my impression are, I think, are relatively fixed and the centralized are relatively fixed. So that suggests that that that things that have good things that have have good numbers on on size, but not certain performance might be good to be first be looking at. So now my invitation to wildly speculate is Do you do you have any any intuition for which of these micro get dramatically faster this one being burst mark. of I think the only the the ones that are actually interesting, mayo and UV, they are really pretty fast. Well, may have can be a bit faster with signing, but it's a real already I don't agree that the key sizes are fixed. So in the in the in the For instance, if we look at the lithium, their key sizes changed a bit, not automatically, but they changed Also, key charge key sources will go up if text on vector. Right? Because If you are if we need to increase parameters to to to to mitigate an attack. And probably the key sizes are going So the key sizes will change."
  },
  {
    "startTime": "01:30:02",
    "text": "They might get better actually, Yeah. Like, they they did for for not not dramatically, but they can get a bit better. Yep. Yep. Watson Lad, a computational during isomorphism enthusiast, with s q s q i with sisqisqisqisign, The main computation is something that has gone a lot faster over the years. and there's probably still some room to squeeze it out Particularly in the signing operation, the main question there is The structure you need to sample from to be good enough and There's quite there there's ways to improve that potentially. And the verification times the survey evaluated she nets you can look at the graph like how it goes over the years that there might be more room. But it's I I I'd say it has to be at least 10 times a fast the verification time to be But, again, 35 milliseconds is a lot. Yeah. Tom, go ahead. you to comment on Aker's comments on the performance of these games. We picked 5 milliseconds for verification time with a reason. because 5 milliseconds already seems like quite a lot if you need to verify a bunch of signatures. but it also seems like Not so. not so tight that performance improvements are are ruled out. So I think that anything within that five millisecond ballpark might go down to maybe 1 millisecond, maybe a little bit less. But there's a bunch of schemes in there to have There's one that has the signing time of a minute, which is no. Sorry. 7 minutes, which is Priyong, which is just very dumb."
  },
  {
    "startTime": "01:32:02",
    "text": "at least, the its performance is is credit if pre owned gets a hundred times faster, then it's probably still way too slow, of course. The the Internet of Zen is also an approach Ecker suggesting chat, but one second time, many times, I'm I'm I'm sometimes a bit impatient. k. Thanks. Any other questions for, boss? No. Thank you. we did have one additional topic to bring up Jonathan summing you to the mic, because we're now at the end of our session. cross Hi, everybody. Jonathan Hoylens, Karofla. I don't have slides because we came up with this 2 hours ago. So there was some discussion about using exported authenticateters for things in HTTP. And one of the changes, we would want. would be to make it such that the client can just send a certificate without being having it requested by the having it requested by the server. And so I just wanted to bring that up here as a does anyone have a particular objection to that that's so bad that I shouldn't bother trying to write an RFC. Excellent. you repeat that? So the moment with exported authenticators, In the only way for a client to authenticate themselves is the server says, please authenticate yourself. That seems very unnecessary. and I don't see a reason"
  },
  {
    "startTime": "01:34:01",
    "text": "why the client can't just be like, Hi. I'm Bob. And Yeah. So I I I want to propose a change to ERC. or, like, a neuropathy or whatever. And if someone doesn't have a really strong objection to that, I'm gonna write it and try and get adoption. But if someone's like, this is a terrible idea, I'd like to know before I do that. I I don't have a strong objection today. but Though I may have injection when it comes up in HDP. Yeah. But But part of the support authenticator is the context value from the server. so I guess my question would be, would you be using a fixed contract value? Would you be using Fiasmirror nonsense? Like, what would you do? That's a very good question. not thought it through yet, but that would have to be something. Okay. So so it sounds like so it sounds like that's the that's the point that we have to to make sure that would we had didn't break whatever properties we thought that that being provided. Yes. That that would need to be worked out and proven prefer plan. Chris Patton. Hi, guys. I'm a little confused. I heard 2 suggest One about, like, exporting a key, and then another about Here's my certificate without being prompted. Oh, okay. Yes. So the at h At HTTP biz, we had 2 different things. one was just using the TLS exporter key interface. The exported authenticators is another thing that calls the same interface. is not actually the so those were 2 separate ideas. But, yes, 11 potential way of solving the unprompted ore thing is to use explicit authenticators, and I would be very keen if we could do that. And then the other one was The other one was we are going to reimplement exports for authenticators with different context strings and call it something different. Okay. Hey, Nick Sullivan. Hi, Nick. Author of exported authenticators. at I'm gonna have to go back on the list. We did have this mode."
  },
  {
    "startTime": "01:36:00",
    "text": "in there. We had 4 modes prompted and unprompted both ways, but we removed the unprompted client 1. partially I have to check exactly why, but it had it didn't match up with any of the security proofs in TLS. because it didn't match any patterns in TLS. So There's idea of an empty authenticator and export authenticators, there could be potentially an empty authenticator request that's implied. I I'm not sure this is impossible to do, but there's a reason it's taken So if I if I remember, the the reason I remembered it being account was if you do this in early data, then you can leak the client cert. And so the the updated version would have to see Don't do that. But there might be other reasons as well. Yeah. Oh, Mike Bishop, from the HTTP session, we're just trying to avoid reimplementing something we already did a couple years ago. the the 2 changes that we would need to use exported authenticators are This being able to do it unprompted from client to server, and also currently exported authenticators strict it to only X 509 certificates, not any other credential type supported by a certificate frame. Yeah. It's in there. I'm gonna ask her read again to do the opposite then. Yeah. It says that there's no technical reason you couldn't but it hasn't been analyzed, so don't do that unless a subsequent document says you can. And so I think your helpfully volunteering to do that analysis and then write the document that says you can. Well, I I I'm already working on the analysis. So the document writing yeah. still someone in the queue. No."
  },
  {
    "startTime": "01:38:02",
    "text": "Alright. I think that's it. Unless there are more questions for Jonathan, And must there's anything else oh, the only thing I wanted to add is we do as chairs, we owe you guys to Joseph? I guess finalize the consensus call on the obsolete tech stress. we're gonna do the return route ability check working group last call. shortly thereafter. So expect working group last call and some calls on the an existing working group last call. Alright. If there's nothing else, we can get some time back. Nice in a row. We finished early. Thanks, folks. We'll see you in Prague."
  }
]
