[
  {
    "startTime": "00:00:01",
    "text": "are cooking stock Okay. Hi, everyone. Hi. Justin. Is it okay if we stop A personal invite to Justin to join there. Yeah. So Welcome to the or session, and this is the first of 3 sessions. So we have a lot of material, which is fantastic. We have as you were still late, a bunch of good presentations lined up. Refund on, for this meeting is online. Hey, Fat. Say hello to the group. Hello, everyone. From Snowway Ottawa. Yeah. Greetings back from, humid, Brisbane. And I know it, because I walked over here. And changed my shirt. Rafa, do you actually want us to walk us through the first slides before we hand it over to the actual speakers. Sure. Hey. Okay. Welcome. Welcome everyone. So as you probably noticed, we have a new area director So I don't know if Deb is in the room. So And, first, we wanna She's not in the room. No. Okay. Hold We have a new area director, and so we wanna first thank Ron, for all his help and has, leadership, and helping us, with"
  },
  {
    "startTime": "00:02:04",
    "text": "many things, around the with the with the it has great support the earthwork group. So thank you, Roman. I appreciate your help and congratulations in creating a role. Awesome. Next slide. So if I add can I add something kind of riff out about that? The transition since dev isn't on the on the call. So first, you are in much better hands, now that you have Deb, things should be running kind of even, even better. Because I'm staying on on the ISG, we're gonna do something a little bit different transition wise. Typically, when you do the AD handoff, all the documents would disappear from the outgoing AD and drop into the queue of the new incoming AD. And historically, that introduces a bit of delay because there's a spin up time for the new AD. I've already negotiated with Deb to keep document velocity. Everything that's in my queue is gonna stay that's past public is is gonna stay with me, and I'm gonna drive it to completion. And hopefully that's that would take out the, typically, 4 to 6 or 7 week delay that that would again introduce everything that's still with me after kind of public, there's just kind of 2 documents I'm gonna drive to conclusion itself. Great. Thanks for calling. Next slide, the harness Okay. It's a it's a delay here. Okay. This is the note. Well, So, hopefully, you're familiar with this already. This is Discover everything that we do at the ETF. So if you're not familiar with it, Please make sure you are familiar with it. Next slide, please. These are tips. Hopefully, your already familiar with those. If you are in person, use the light, version If you are remote, use the full version and and make sure you are on mute, unless you you wanna speak, Next slide, please. Please log, use the QR code to log in. So we have the, accurate count of the participants in the room to Yep. Yep. Awesome. That's something I can't tell you."
  },
  {
    "startTime": "00:04:02",
    "text": "Excellent. Cool. Yeah. It speaks up. If you go to the agenda, you can also, the agenda online, you can also get to the on-site tool from there. There's a link Okay. Cool. Thanks. Okay. Next slide. Okay. A quick update. We we have the security, BCP, a think very close to, like, at and and publication requested, but, like, I don't know, Roman, do you have an update on that? Like, what's what's the latest name? No. The the security BCP is much further down the document kind of pipeline, Right. waiting for for some revisions before I can bring it to the ISG. It's it's Awesome. Perfect. Perfect. And the other document is just waiting for the BC be Okay. Awesome. Thank you. Next. Okay. Today, we have, obviously, we have 3 sessions. For today, we have Brian will start us with talking about SDJOT Mike and Aaron will be talking about resource metadata and we'll talking browser based apps be about George will be talking about transaction token And Kelly will be talking about identity training And Aaron will be talking about an Indian session authorization grad is kind of a new draft. This is We we had to shuffle a few things, but so that's the reason this ended up here. So that's, for today, next slide, please. For Thursday, SDJOT VC. Think Oliver's gonna drive this a token status list after that at the station based client authentication, Nance and point that status attestation by and we added kind of a new draft that we just wanted to give people a chance to speak to the to the work work group for a new idea that they wanna"
  },
  {
    "startTime": "00:06:04",
    "text": "kind of discussed. So we give them a a spot at the end of this spot. At the 10 minutes slot there. And Friday. Next one next slide, please. So, Peter will start with cross device small BCP. Aaron will give a quick update on 2.1. Dean and Sarah will be talking about, say, that profile for RAR, George will be talking about first party apps. And Aaron will be go talking about global tokenification. And another addition to to this is, again, signed Jot the the other case set Richard Bonds, he wanted to talk about this. He sent an email to the list. I think So so that's our agenda. Any questions, comments about the agenda? Any It's in the bash. If not, I think I would like Brian to It gets an start at his 10. Thank you. Thanks, Rafa. And and also, welcome to the online participants, see that we have a A large number A folks, sir. Thanks for joining. And and maybe inconvenient for for some of you completely realize that. How we doing? I can't hear from ticket. Okay. Alright. Good morning. Wednesday morning, everybody. I get to kick things off here, which is fun. Talk about selective disclosure for JWT. On behalf of myself and Daniel and Christina who are remote, I think. They're definitely not here, but I believe they're joining us remote. Customary photograph of the location and, with that, Let's Go on to the next slide."
  },
  {
    "startTime": "00:08:01",
    "text": "So quick rough agenda here. I wanna complain a little bit jetlag and the time zones, know I'm not the only one, and I know it's Wednesday, and I should be over it, but I'm not my brand is a little fog and slow. If I freeze up here, Mitch McConnell style. That's why. Bear with me a little bit. What? What? Too soon? Oh, well, there were a few laughs. I'm gonna give a brief ish overview and refresh sure of what this thing is. It's always hard here to sort of cater to the room to room tourists and people that have been following overview. So I'm gonna try really hard to give, enough context to be meaningful for people that aren't familiar with the work and not too much the rest of you. Go over changes since the last time we met, or as Mike likes to say since our our heroes last month talk a little bit about the open issues and questions and take a closer look at just a of those. And that's the extent of what I've got today. Could I have the next slide, please? So, Rough overview SD Jot is a salted hash based mechanism for selective disclosure of individual elements of a JSON object used as the payload of a JSON web signature structure. That's a lot of words. Mainly, this is about, SDJOT is selective disclosure for JWT claims so that You can issue a JWT with a bunch of different claims in it. And the holder of that JWT can present it and select from the set of claims, which ones they actually want to reveal in the context of that. Presentation. There's been a lot of talk about things recently, various formats and so forth. I wanted to reiterate here one of the main aims of SD Jot is to be easy to implement and understand leveraging familiar established and widely used data formats and cryptographic algorithms, those being those in JWS, JWT, stuff that's used, predominantly everywhere. Everywhere is a big fur, widely used out there. There's lots of"
  },
  {
    "startTime": "00:10:04",
    "text": "for familiarity. There's lots of deployments. So it this is really meant to be a easy to use, easy to implement incremental step on top of existing functionality, not a completely new concept. Next slide, please. Just the kick and look Oh, oh, Thank you, Hannes. So real quick example of an SD Jot we have here, The first three parts, they're color coded, show a regular old fashioned jot JWS. You have the header, the payload, the signature, all basic 4 encoded, and SD JOT unique functionality here is this last part where there's a series of basics 4 URL encoded. Things till the separated tacked on to the end. We'll look at the insides of this a little bit. That works inside of the payload, there is this SD claim, that is an array, and this can operate at various levels within the content area, but I'm just showing at the main level. It's an array of hashes digest values, each of which is the digest over one of these disclosure objects. So both maps to the closure, references that and ensures the integrity of the disclosure because it's signed underneath the payload and it's a hash of that closure. So each one of these points to one of disclosures, each of what's shown here is coded, has a decoded, excuse me, has a salt value the actual claim name and the value of the claim. Results there to, sort of prevent brute force hash recovery of the values and so you couldn't, if there's like a know, a claim value, a name value that has a small space, you couldn't brute force those values into the hash and sort of reverse reverse the hash to figure out what the value of the actual claims are. Which would undermine the value of this. I'm not jet lags kicking in. I'm losing my train of thought. Anyway, That's the main idea how it works."
  },
  {
    "startTime": "00:12:02",
    "text": "So you see that the main structure in here, you have the hashes. They reference these disclosures outside of it. The whole thing then, this is what a holder would receive from an issuer And when it goes to present that, say the holder only wants to reveal Their birthday. So they take the original SD Jot, pull off all the other disclosures, and just tack that one last one onto the end. So that's still the signature still verifies. Integrity of all this is still maintained. But the actual presentation to the to the verifier here only reveals The one The one claim value that's to close in this last piece, which is the birthday. We also have the concept of a key binding shot, which is an additional JWT, you can tack on to the end of the entire SD dot structure. That proves possession of a key held Encoded within the Jot itself using like the CNF claim, So a a public key can be encoded inside the main body of the JWT and this SDG or the, KB Jock can be appended to the end. Includes things like an audience, and a hash I'm sorry, audience and the knobs that provided by the verifier somewhere, and it can prove possession of the key inside of the inside of the payload with respect to this particular presentation, It also includes this, As the hash claim, which is a hash value over the preceding rest of the SD dot content itself, which sort of ensures the integrity from the holders perspective of which claim, which disclosures were intended to be presented. So since we last met in Prague. We published 2 revisions, 7 and 8. What's new in 7? A variety of things. We now reference our our see 40, 86 in the considered considerations about salt entropy."
  },
  {
    "startTime": "00:14:02",
    "text": "It's basically just an actual reference to saying that random number generation is hard. Here's some advice about how to do it. Neil Madden suggested we make this reference. I think it's worthwhile to have. Did some IANA stuff that's largely on unconsequential, but they reached out to us and made the suggestion. So we did it we strengthened the security considerations around what claims are basically not making claims which control the validity of the jot itself selective deals closable. So there's there's stronger tech and they're now saying that you can't make things like, expiration or the confirmation claim selected is disclosable because then you put into the hands of the holder the ability to disclose or not disclose things that would be relevant to the security context of presenting this to dot itself. So we're saying, you know, can't. Can't make those selective disclosable. They have to be in the main body of the document. While also saying that the verifier should have policy around what claims they expect always so that they're not subject to potentially a mistake here and selective due to disclosable claims being withheld that might affect security that that if they were presented would make it invalid. If they're not presented, somehow that threw the the the the policy on the verifier side needs to be static. To, avoid those sorts of mistaken not attacks, but mistake mistakenly accepting things that their policy wouldn't otherwise allow for. There was a little bit of ambiguity around what to do where you if you encounter duplicate digest values in the body of the document, those were at different levels or whatever, basically, it's it's been clarified to say that if you find any duplicate digest within the context of the the payload itself or any recursive inclusion to the document that needs to be rejected if it's invalid and that the 3rd any unused digest digest that were included on the unused disclosures, excuse me, included on the outside of the document that weren't from the inside, then that too is if"
  },
  {
    "startTime": "00:16:02",
    "text": "if there's any leftover, that too is an error condition needs to be rejected. There were some questions around sort of the edge cases that's come up in a various formats, edge cases around the tilde separated months. We've tried to be very clear about cases how that's used when there's no disclosures, when there's no, KB jobs, just better illustrate it and give examples thereof. And we did change the claim name, of the hash that I was speaking about previously, the hash over the prior, SD Jot content with the disclosures that's presented inside the KBJot change it from _sdhash, just the SD hash. And that's a small change, but it is breaking in that it it changes the claim name. Although the prior one had only been published for one draft. This is a small update. We tried to do it quickly. And it's really just to sort of align name usage with context, and, the underscore didn't really make sense. In the in the context of the Kv Jot where we've used it to sort of help differentiate claim names in the actual payload content of the SDJOT, is it just sort of a a change to align things a little bit better? There I am, jetlag Ravbling again. Hopefully, that makes sense. In 8, marked a couple of RFCs normative. They were informative to sort of mistakes. Trying to be a bit more prescriptive about suggesting the use of the, enough, JWK confirmation claim method to be used to convey the key binding key. So it's still is not required to do that, but we're more strongly stating that if you're gonna do key binding, This is probably the way you wanna do it using the RFC 78100. C Enough with the JWK method. And it basically encoded the entire public key within the contents using the, the CNF claim. Some editor changes, some reviewers came in and and, just"
  },
  {
    "startTime": "00:18:01",
    "text": "noted some things that that could use some clarification. We tried to accommodate that. Daniel rewrote and expanded on the unlinkability considerations in the privacy section I think really did a nice job of further explaining what unlinkability means in which context what SDJOT can provide and can't provide and various different ways of its usage. To, to be very clear about what is and isn't possible there. In the course of that, also mentioned rather clearly that the key binding key is potentially a correlation handle. Which was largely obvious to a lot of people, but it kept coming in various conversations as though people were just discovering it for the first time. So we tried to be, be very clear just on the outside. At least say it in the content of the document. So it, it wasn't as much of a surprise. We removed the entire mention of 5 key binding methods, there was a lot of sort of handwavy text in various places that we're saying if you wanted to do key bond and proof by some other mechanism. Great. Do it here. It didn't really add anything because it's still possible to do that. But these sort of un actionable callouts in the document were were maybe a little bit distracting and encouraging things that that, we didn't necessarily want to encourage and in the course of that, Also remove this entire section on enveloping SDJOTS that was also not normative, but just showing a bunch of examples of saying like, well, you could sign this. Put this inside of this and sign this, none of which now is inhibited, but we're just not going out of our way to sort of show examples of possibilities of things that aren't normative or or interoperable anyway. There were some editorial updates, aimed at a little bit better consistent treatment of disclosure, which is the whole 64, you are all encoded. Piece versus the contents of the disclosure inside it. We there was some some text that wasn't totally clear on that. Hopefully, it it it's better use of the terminology now."
  },
  {
    "startTime": "00:20:00",
    "text": "And missed something here, but updated the, Oh, yeah. Sorry. Updated the PID example, which is, the personal information document, out of the e e u. There's an example in there evolving as the EU stuff evolves, and this, hopefully more or closely tracks kind of where the current thinking and direction of that is going. And we've currents with those examples, we've tried to be a lot more explicit that that example, as well as the one that references the, w3cvcdatamodel our only examples of what you might be able to do using SDJOT applied to these sort of data formats. They're not normative in any way. They're not actually defining anything. Just just suggesting that you could do something like this. Trying to be really clear, though, that it's not actually a normative definition, even though it's in an appendix, and an example, just trying to be more clear. Can you do your assistance? Nope. A lot of the aforementioned changes were driven by reviews, suggestions, so forth by various people, try to say thank you. I won't cover all of them Barnes. Thanks in the back. Rohan, thank you very much. I know Neil probably not online, but he made a lot of comments around the last IHS that that helped really tighten up some of the the recommendations and wording around cryptography and hashing, probably forget some others, but just wanted to acknowledge the acknowledgements here. And then take a look at, some open issues. So really, Useful screenshot of a github here, but try to just discuss a few of these. We'll talk about this a little bit more, in just a slide, but looking at redesigning the JWS JSON serialization. Richard suggested, providing some ABNF"
  },
  {
    "startTime": "00:22:01",
    "text": "around the, the format itself, and, and then in the course of that suggested and provided some ABNF that was neither syntactically nor semantically valid. We thought about that a little bit, but I think we have something now that is both and would be easy to include. So that's out there, but we haven't gotten to it yet. Richard, again, noted that the JWS serialization has existed now, doesn't have anything and doesn't cover anything about key binding. This was actually in an a prior draft because of some fluctuation and some oddities around the JWS utilization that we're trying to deal with. But is likely to be put back in in a slightly different context. Talk about that a little bit more in a minute. Editorial stuff about section headings, Richard again has suggested some, improvements maybe to some diagrams, that stuff now is actually pretty far out of date, and maybe we could chat about that sometime this can see where we could take Some of that. There's There's a lot there. Some of it may be useful. Some of it needs to be aligned. Richard again. Has suggested that we have a separate token and presentation format this in particular is both only a terminology change, but also a relatively significant change, and I have a whole slide dedicated to this. We'll talk about shortly. Clarifying the algorithms to accommodate recursive redaction. So there's this concept that discloses can be nested within disclosures that the hash can reference another disclosure, and that can be recursive, which allows for redaction or selective disclosure at multiple layers. Richard, you had an action item here to review and just changes around clarification a couple months ago. I think maybe you've forgotten about it. But if you have some clarifications, it would be nice to get those in. So subtle reminder."
  },
  {
    "startTime": "00:24:01",
    "text": "Yeah. It's, it would be just editorial clarification. I think it's just sitting out there. I think Nat suggested we have a formal section on abbreviations. I'll go back to insurance So so just on recursive redaction briefly, I think there may not be just editorial I think there's I think the the algorithm for, you know, processing an SD Jot and undis and disclosing what's disclosed. I think that's correct. I think is missing is, for, Discussions on how you correctly choose what to disclose and not. Because if you're gonna if if you've got a chain of recursive redactions, you're gonna remove something at the middle. You need to make sure that you remove stuff down at the end or else you end up the new stricter validation rules, you end up with an invalid with an invalid. Yeah. So around the holders choosing which to disclose under the contract. So good stuff. that's Okay. Not one of abbreviations. I think these are maybe actually covered in another PR, but we'll we'll do that. And then This is a weird sounding one, but presentation is capitalized as though it's a defined term. But it's not actually in a definition. There is an open PR, which is why it's noted here that, unrelated to this changes this and, and sort of treats it more as a, a non special to define term and just use it in the context of this actual meaning. Rob, Brian, just a reminder. We are running out of time. Okay. So Okay. I'll go quickly. So, on separating the formats, Richard's thesis here is that sddot itself provides different security properties both with and without, a KB job. Or without KB binding. And the verifier really needs to know which it expects or else and I feel like this is a bit hyperbolic, but in some sense, it's somewhat real. You're gonna get things like vernailabilities where the KBJADA stripped and somebody would, would accept it without knowing their policy that they shouldn't be."
  },
  {
    "startTime": "00:26:00",
    "text": "You can do different things with us, both with and without KB. So we should talk about them in completely different things. PR 394 introduces and uses this distinction, which is a selectively disposable jot, which is everything up to the key binding, the issuer sign jot, and the disclosures, That's always an SD dot period. And a stuck grid of the disposable jot with key binding or SD dot dash KB. This PR has been out there for a while. We've gone through a lot of iterations back and forth on it. And with my editor hat on, I feel like it's looking pretty good to proceed after iterating on it and forth. I started writing this log a long time ago and thought maybe I'd bring it here and, put it in front of the working group and get enough pushback to tell Richard to go away, but I think it's actually flipping the other way. So we could use some productive input on it. If you wanna take a look, give it give it a look over, but I at this point, I think it's something we're gonna look to proceed with sort of barring major objections out out there from the working group, because I think help clarify and improve things. Of course, there is still a little bit of bike setting, what we're gonna call this. It was originally ignored. We've got the dash. We've got Plus, we've got the, Tilde, which I think is cute and nice, but, there's some need for agreement on it. I think the dash of the plus would be good, but bike settings. Always hard to get to agreement, but but input is welcome here. There's, Pete and the queue. So running low on time, can I finish the last slide and come back to Peter? Okay. Cut it cut the sort of a rumbling short, I'll try. We're looking to revisit the JWS on serialization. Again, despite being logical, what we have in there, current JWS JSON serialization approach is not well suited for existing JADA's implementations in the EU digital identity context. What needs to happen to facilitate this is update such the the disclosures and the KB Jot"
  },
  {
    "startTime": "00:28:01",
    "text": "into the unprotected header and descra and then describe how to use those to construct the input into the KBJots SD hash, there's a PR out for this that's outstanding, and, basically, it looks like these two things here basically just including those things within the JSON serialization inside of the header. And, in the case where there's multiple signatures in the database serialization, the general serialization, only using the, the first signature element to to construct those things. That's out there. And then looking at next steps, there's obviously some impending changes but the main format and processing have been really largely stable for quite a while now. There's a growing number of independent open source implementations, available and this is referenced by a variety of other specs, frameworks, profiles profiles and foundations, etcetera. We are obviously not ready for working group class call working group last call right now, but I think that we are getting pretty close. So looking forward to, IETF 120 in Vancouver, which is the photograph here, and I will stop rambling now. And, we have a queue. Starting with Peter. Peter. Hi. This is, Peter Chinchi from, Peter Chinchilu from Huawei. Actually happening in the chat so It's a starting a thread already. So it's more like a common than a question. So, actually, when you go to the, to the claims. So when this, first attracts me, it actually has a record use case. Of the, digital driver's license where it can compare your age to a, you know, legal thresholds. So in here, like, the question I have is that do you have, like, a audio algebraic, comparison capability to the, age of your, claim right here. And the answer I have in the chat is no. To either disclose it or you have another claim that is, you know, age over eighteen or something."
  },
  {
    "startTime": "00:30:01",
    "text": "It's just, you know, it's more of a comment. So because this is a very, very nice use case that attracts me, And, I think, it could make sense if you address those you know, at either at a claim or add some fancy crypto, 0 knowledge crypto, but that sounds like overkill. Well, either way, maybe that's you know, I dress that maybe. And, that would be a great use case too. So you're right. There's not, 0 knowledge crypto. There's not anything fancy like this right now. You can include a claim like this. Exposed the whole birth date. Or one of the examples actually shows something more granular, which is the age over and with a, a couple of different entries for age over eighteen, twenty one, whatever. And you could then selectively disclose one of those or the appropriate one of those in the context. And in terms of the scope and complexity of this specification, that's as far as this is going to fine. So that the latter one would probably be the functionality that you would you would look to employ, I think. Correct. There's a granularity, granularity. Privacy that you can consider. Yeah. And it's trade offs. Okay. So sorry guys. Brian, thank you. I think we're we're way over time, and I know we we've locked that queue already And so we apologize for the people that were attending the queues. We have to caught it here. And go to the next, presentation. you, Brian. Thank In general, for future presentations, like, make sure that you leave enough time at the end for actual discussion. Yeah. So so we can actually come over there. I'm just gonna say a quick thank you to the authors. Obviously shipped a ton of issues at you, and I've you've been to work with. So thanks for Thanks. Thanks for the detailed reviews, Richard. Yeah. You can use the click My advancing my other swines or images?"
  },
  {
    "startTime": "00:32:09",
    "text": "Good morning. I'm Mike Jones. Thank you for all being here today. And I will be updating the working group on the status of protected resource metadata specification. And taking a page out of Brian Campbell's playbook. This is of my photographs from this week. Week. It's not working next. Okay. I do. So in the last couple working group meetings, at ITF's. I've talked about What is this for and what does it do? I am not gonna do that if you wanna read that. Rewind 4 months and look at the presentation from the last time in Prague next So what's happened since itf18. We switched from concatonating dot well known to the end of the URL to the awkward sticking it in the middle before the path after the host, which is what, the well known RFC and Mark Nottingham. Insists that we do. So we've done that. That way we won't get stopped at IASG review, etcetera. And we had to do this with the as metadata, even though It's a terribly awkward construction. We changed to have the WWW authenticate return the URL from which you can fetch the metadata"
  },
  {
    "startTime": "00:34:01",
    "text": "as opposed to returning the resource identifier. This was based on working group feedback, both at the previous meeting and in subsequent discussions on the list. So that's done. And, fully, Skokum as he does found a bug, and we've corrected it. That takes us to an interesting point, which is every issues that been filed against this back. Has been addressed and we know of no others that are outstanding. Therefore, cutting to the chase, is it time for Working group last call. So, So it ain't. Does anyone have in the room or online have an opinion about But it is just ready. Are there any new open issues or other comments, because If not, we would We would just start a working group last call after the after the end of the meeting. Don't hear anything. So I think Justin, record in a meeting that we should start a working group last call on this Oh, Christina? Oh, Okay. Okay. Yeah. The booking group last call then. Go ahead. How much implementation experience is there? For this draft. All of the open ID federation implementations use it. So there's at least 4 or 5. So this became mandatory in the refrigeration spec It is. It always has been. Okay. Okay. Thank you."
  },
  {
    "startTime": "00:36:02",
    "text": "Okay. Atul? Yeah. Just to note that even the open ID shared signal framework is, we'll use this. It doesn't need it, but It's something that will benefit from and I'm not opposed to the last call. I'm just sort of wanting to make a comment that This makes it possible for a resource server to get a token that is far more capable than what it's what it might need. And it might lead to token abuse and, you know, I kind of discussed this and I realize this is not a problem with this particular spec, but it's it's an issue that I think we should we should think about. Okay. So, Yeah. I I do we have a few review as a tool, I would you be willing to do a review in working called last call. Yes. I will. Any other show of hands, people who commit their time after the IETF meeting to to to a review as well. Peter, I see Peter Sand Monte. K. So we at least have 3 of 4 Yeah. Philip in the queue too. Good. Just raising my hand. Okay. Philip is raising his hand as well. Excellent. That's very good. So Rickford and I will get together issue working group last call, the side about the shepherd and get it done. Thanks, Mike. You can have the rest of my time back. Brian will be vanquished. So we have the browser based apps Yeah. On the agenda next"
  },
  {
    "startTime": "00:38:00",
    "text": "What do you slide control. That's me. You can give me You you you ran so much over time, so you have eaten up it. But if there's time left, Brian will definitely, get to those just Oh, no. No. It's perfect. Perfect. Perfect. Perfect. Perfect. Perfect. Perfect. Perfect. Perfect. Perfect. Perfect. Perfect. Perfect. Perfect. Perfect. Aaron, some Great. Can you, hand me the slides? If I figure out how to do that. Can you request control for the slots if you do? Oh. No. I think I just did. It has it input. Posticarbonate eyeliner. Can can you do it again? Yeah. Can you do it again? N. It says ask slides. Is there a button? If you if you click on its face and right click over the three dots, one of the should be to give him control. Erin, you're just we'll flip slides. Can you please just take a please? snapshot, Great. Okay. Welcome. Sorry. I couldn't be there, but the photo I took in Brisbane last time I was there. I wanted to give an update on This draft. It's been making some pretty good progress. Go ahead and go to the next slide. So so sure we're all familiar with this by now, but the, premise of the draft is to include recommendations for people who are building apps that are executing in a browser, also known as single page apps, and that includes both with and without a back end component of the application. Alright. Next slide. The latest significant changes in the draft have been a major restructuring of this. A lot of this was Thanks to Philippe Derick and This is an ex excerpt of the table of contents and the new structure, basically, we're going through now"
  },
  {
    "startTime": "00:40:01",
    "text": "a list of threats to JavaScript apps and, describing the different types of attacks and, what happens if those attacks are successful And then, next slide. Then going through different patterns for building apps and describing which of those patterns solve which of the attacks. Some of them solve more attacks than others. Next slide. So the BFF pattern back end for front end, we can see that this section talks about The attack, relevant attack scenario, and this is just frosting requests for your users, browser. So if an attacker can get into the app, they can't steal tokens, but they can proxy request because no tokens are in the front end in this scenario. And when now it this now references the, you know, the other sections to talk about the the threats. Next slide. We go through this with the other patterns as well. So this the pattern of a back end that coordinates the acquisition of tokens and now you can see we've got a few more different attacks that are possible So it is now possible to extract a access token As well as proxy requests, And that means we can use stolen access tokens. Go to next slide. And the other the the 3rd pattern being a pure browser based auth client. This one has the most attacks and consequences of those attacks because of just the, inability for for a pure browser based client to have a lot of the protection mechanisms that the other patterns have. But overall, the the goal of this draft is not to say that anyone of these is the best option. It's to point out the relevant attacks and consequences that are, that are in each pattern. Next slide."
  },
  {
    "startTime": "00:42:03",
    "text": "So from the last time we met we had some great re reviews from Philip and Louis. So a lot of those changes are are now incorporated. There's, there were some clarifications on what it means to use cookie encryption in this context And there's a new security consideration regarding the use of post message, which also references the security PCP, which also mentioned, post message. Next slide. So at this point, we are, there are No open issues. We've addressed a lot of the we address all the feedback that we've gotten There's been I don't know if you saw, but there's been a couple of emails on the list over the last couple of days. But, we've been We've addressed those comments. It didn't seem like there's anything new brought up in those emails. It was all stuff that already been captured in the draft. So we believe that there isn't anything left to Do on this and would like to suggest Moving this to work in group last call. Thanks, Aaron. That's fantastic. So it's my question similar to the to the previous presentation for Mike. Is anyone up checking to the To us issuing a booking code plus call on this document, That's in, Justin? To be clear, I'm not object objecting. I'm just I have some comments. As I'm sure you saw it, on the list, I did a full read through of the document and had a lot of comments on the text. I do wanna emphasize that that that my comments on the text are all around making what's in there clearer. So, I can, it, there are parts definitely felt like, oh, this is a piece of text that used to be before something else, and now it's after. And so the seasons don't line up and blah blah blah. And I think that going through and sweeping out a lot of that."
  },
  {
    "startTime": "00:44:00",
    "text": "Kind of, editorial debris, will vastly improve the readability of the document. But I really have no No objection to it going to last call even in its current state because the kind of comments that I was giving, that's the kind of stuff that you would wanna come up in last call anyway. It's like, this is what we meant. It doesn't quite say that. Here's how you might be able to say that. That kinds of thing. Overall, I do think it is a, a strong document. I think it's a very needed document. Out there I've been throwing people at this draft for years now. And, yeah, I this is basically a long winded way of saying despite the, you know, seven pages of notes that I put on the list of things that need to be fixed I still support it going to working group last call, because I fully trust the editors to be able to address those bits. Thank thanks, Justin, and thanks for for the data review, I I didn't notice it on the on the list. But, Yeah. I I Recently read through the document myself, so I'm, also convinced that it's a it's a strong document. And so let's issue working group last call, you I consider your review just in a the first one, And, there would be others as well. So Could I have a few show of hands for people who want to or commit time to reviewed the documents. So we have some good, working Hooplast call comments, I think it's a really important document, one of our sort of, like, usage I will super good usage for I'll speak up for a coworker of mine who was actually at the last meeting, and he offered to read through it and submit comments. And he is still planning on submitting them. So can include his review in in that as well. Mhmm. What's his name? That's Andy."
  },
  {
    "startTime": "00:46:00",
    "text": "Andy. And, Jim, spoke up on chat. Yeah. There you go. Just a clarifying question for the notes, since Aaron mentioned that stuff has been fixed in the editors or after, at least it sounded like that. Should we Is is that in a state that should be published as a dash 18 to officially kick that off, or do we wanna stick with with 17 for the review. This is a question to the editors and the chairs. Oh, sorry. I 3 no. There's The draft 17 is the latest There's nothing right now. Got it. Got it. Draft Yep. Got it. Okay. Sorry. I misunderstood. Thank you for clarifying. Yep. Sorry. Okay. So we have Justin's review. We have Tim, And we have Andy doing a review So that's a that's a good start. And, of course, Ruth and I will way review as well as part of the shepherding. to Process. Okay. Excellent. We'll do that also, after the IDF maybe a little bit space so we don't overwhelm the group. Perfect. Next presentation, transaction talk It it should consist. Yeah. Seemed consistent. Yeah. It's Alright. Where is my date? So ubiquitous photo from Tuesday morning. Alright. So just, give a high level overview transaction tokens, it's the the goal here is do you manage"
  },
  {
    "startTime": "00:48:00",
    "text": "basically authorization and transaction, and you immutability within a trust domain boundary. I talked about this in a lot more detail at the Windsor working group on Monday, But, basically, a transaction token contains like, who the transaction's about, the that's an entity. It doesn't have to be a human. What is the context, both request contact or other context about the transaction and whatever sort of details about the transaction that you want to be immutable. Most of this is driven by the fact that most of our deployments, you you it takes multiple workloads to complete a transaction. And so because of that, you want to basically ensure the integrity of that transaction as it transitions between multiple workloads. And I will say in the vast majority of back ends that I've seen the best I've seen is basically machine to machine authentication, right, like MTS. So This machine is allowed to call that machine to invoke an API but the the the details of the APIs being invoked tend to be specific. So, I mean, tend to be replay or if you compromise the internal machine, you could change the parameter values in and hence, this gives you a little bit Better movement towards 0 Trust. Okay. So I'm gonna run through all of these. This is pretty much the changes to the spec since draft of 1. Was published for, IETF 118. We the the main the main piece here is that we had originally started using the sub ID out of the, set structure, and we moved back to using just a standard sub claim. Unlike Open AD Connect where the sub claim is down to the issuer and transaction tokens, the sub claim is bound to the auth"
  },
  {
    "startTime": "00:50:05",
    "text": "And then we also we'll talk about next. The this the specification allows for some intermediate workload to request a what we're calling a replacement transaction token. And in that process, you want to be able to know who requested the replacement transaction token as along with the originating entity or workload that requested the original transaction token. So we added some logic in here the main piece here in this we can discuss is, You know, I we basically just said that the requesting workload, which is a claim inside contact structure, can be a single value if there's just one, but if there's more than 1, it's like XFF. Just depend the requesting workflow to the end of the array. And so it's not a this is not a explicitly not a path of all the workloads the transaction has flown has passed through. I think we should do that some a way that's outside the transaction token. And we need to probably look at that separately. But again, this is an area that is up for there are some questions about, can transaction tokens only be used when you're crossing the the trust domain boundaries between external and inside your perimeter And the answer to that is no. So we clarified that. We talked we clarified how subject token and subject token type, which are required parameters in the token exchange. Can be leveraged, in an internal call. Brian had provided a lot of feedback around how we weren't profiling it well. So we A lot of these changes sort of came back out of that added a section on for the transaction token service itself"
  },
  {
    "startTime": "00:52:00",
    "text": "on processing rules for when a request comes in for a new transaction token, things that needs to do, like, the requesting workload needs to be authenticated. You have to validate subject token. And then giving the transaction token service authorization privilege for making decisions about what kinds of claims go and what places when it issues, right, because you could have a case where requesting workload tries to ask for a transaction token for a particular purpose. And it's not authorized to do that in which case it should be rejected. Again, Mark clarifications around token exchange and specifying a specific type for the issued token type. When you requesting replacement transaction token, some additional processing rules that you can't change the sub and you can't change the audience. And then as we said before, what happens to the workload that's requesting the replacement transaction token. How is that Included in the resulting transaction token, so a downstream service could process correctly, We added a section on how do you pass a transaction token between servers And, and basically, we sort of hand waved here. So this is another key point of discussion. Should we define a whole new VP header for this. Should we whatever. So we just basically said, for now, it goes in an HTTP header, but we didn't make any specific know, specifics about what HTTP header or what it should be named or any of those kinds of things. I'm pretty sure Brian is not in there. So this is something that that we need to discuss, you know, on the list. Hopefully, it you, how we want to do this. I'm gonna come back to something else that sort of touches on this, but That's a big open area. So I think out of this"
  },
  {
    "startTime": "00:54:00",
    "text": "slide deck here. The 2 things are how do we process? How do we sort of track the set of workloads that requested new replacement transaction tokens, that's kind of new work here rather than just clarifications. And tighten things up. And then this one on do you present a transaction token how Dean, can I wait until I'm done? I think I've got just a couple, and we got time. Updated security considerations, around some thoughts around actor token and actor token type, which are part of token change, which could be used for client authentication. I don't think most people would. So, a little bit of work there and, And then basically put how the requesting workload authenticates is out of scope for this particular stack. Right? There's many ways that that could happen. Okay. There's I wanted, and I should have taken, page out of Brian's book about copying the issues list. There are 2 issues, in the, in the OAuth GitHub site for transaction tokens, but I think are also important one of them has to do with how do you use a transaction token in some sort of long running batch request. In the past, I've seen this in the context of you know, GDPR user says delete my data. So the the user identity store gets deleted but I need to keep the identity, the identifier for user around long enough to clean up all their data. Right, is that sort of propagates its way through the system where the core user data may it may be gone. So that is an issue that's outstanding, I added a comment to it this morning, Unfortunately, my app is not showing me the numbers. And then there's another one which has to do with Should we separate transaction tokens from JWT? So this spec specifically"
  },
  {
    "startTime": "00:56:02",
    "text": "is very much bound to JWT and OAuth and HTTP. Constructs, You know, should there be a way to define this in some more abstracty mechanisms which we could have other bindings Justin has this issue in the issues already. So either on the list or in the issue in GitHub, that's another topic. So those are sort of, I think, for things. The alternative. The the motivation for for an alternative format is performance, sort of a smaller size, or is it, different features that are not available with the GWT. So I think the issue is We're gunning you know, whimsy is one. People have been talking about, hey, could I do this a more efficient way, like, protobuffs. So you know, if I'm delivering a a transaction token between multiple workloads, know, in 50. Maybe that could still be a job, but maybe it's something else. So the issue that question predated with whimsy. So that's why I'm wondering. Well, we we knew predated the Wednesday working group. it it It did not predate The whimsy discussions, like BAF, I remember. Yeah. But Do you mind if I jump good. Yeah. Good. Good, Justin. Then we'll queue just to hit this. So The initial motivation of me filing that issue was on honestly more for just you know, architectural cleanliness. This draft doing a couple of different things all at the same time. There's a format and sort of a Well, there's a data model for the token. There's a, syntax the format for the token, and there's a protocol for exchanging for that kind of token. And it's all rolled together. The initial question was Do these all need to be together? Cause I think that that's a question that we"
  },
  {
    "startTime": "00:58:00",
    "text": "as a working group, need to ask ourselves in documents like this, Are we necessarily tying all these things together out of just convenience, or is there a reason to tightly thread this? Or Do we need to explicitly build in some abstraction points I don't know the answer to that, but I think it's a very important question that we need to ask when we see documents that combine format and protocol and data model altogether. Like this. We've all we've all We've all seen them and seen them go both ways. Secondly, to George's point that, yeah, the conversations that led to whimsy existing have been going on for quite a while now. And, a large part of that has been and is currently there bits of this draft that can be reused or aligned with or abstracted from that make more sense in a whimsy environment. So, Is it going to be like, our transaction token is going to be an instance of this is a whimsy token going to be an instance of a transaction token instead, like, I yet. I don't think we know the answers If you wanna be, speaking as Wednesday chair, if you wanna be part of design team that's gonna go look into that, answer, please reply to the whimsey mailing list to We're looking for good people for that. George, I do hope you're gonna be part of that conversation because I I think that that would be important. I I think that there are a lot of important moving parts here that touch on things far outside of just OAuth and OAuth access token. And I think it's really important that we consider that as we're building this. And as it sort of reaches out into the wider world. So I don't know exactly what those abstraction points are. Efficiency is very likely one of them, but it's that's far from, a singular motivating factor. So sorry for the rambling answer. Dean, Hey, George. Dean Sachs. I just had one"
  },
  {
    "startTime": "01:00:02",
    "text": "comment, section 222 replacement transaction tokens. Has a throwaway line is the last line that says, the transaction token service exercise caution and what kinds of replacement requested supports is not to negate the entire value of transaction tokens. That feels really, really open ended and very hand wavy. But it's not addressed in the security consideration section. So I don't know what your plans are there. I don't know if, you're looking for some help there, but, there does seem to be some prior art in this space with I believe macaroons, are doing something similar to down scope so I don't know if we can look at that as as inspiration, but I'd be happy to help you. Yeah. No. That would be great. Let's let's definitely clear up the tech I think, you know, kind of the things if you change the purpose of the transaction token in a replacement transaction token. What is really mean from the integrity of the transaction as it's flowing through. Now in Justin's conversations, you know, in the identity, changing case where you're switching between 1 trust domain and a different trust domain, you may be required to change tokens are within a single trust domain. So it shouldn't matter. So I think that was the intent of what that line, but I agree with you. It's very it's very fuzzy and and we should be much more specific about what the processing rules are in the context of replacement, transaction tokens. And to be quite honest, I would love to see on the list, some real world examples, for where we think replacement transaction tokens are highly valuable. Just because I think it will help add clarity for the kinds of processing rules that we would need to tighten up Well, I think this is the place where we can be clear that the transaction token replacement should only down scope the, the, the, the scopes for the, the token. And not increase the scoping of it. And so if we can Yep."
  },
  {
    "startTime": "01:02:02",
    "text": "Map that out such that you can validate it is only downscoping and never going the opposite direction, think we can we can build some assurance into this protocol, but happy to help with that. No. That'd be great. Thank you, expects Cool. I I think I Rayford and I will ask for Drop a mail to the website list or a website now from Wimcy Group to ask for some reviews. I think he sounds to me that this document would almost be a must read for anyone interested in Bimsey, what could be So we may may get some good reviews. In addition to that, think the document now, several iterations in, I think it's in a much better shape than it was, in and it's maybe a good time for some of you who haven't been involved in any of these discussions to can look at the document, I think we need some some more ice, Yep. Yep. Yep. Yep. Yep. Yep. Yep. Definitely. Any any volunteers to to Give it a quick read. Yaron? Yep. Yep. Brian in the queue there. Oh, we have also Prime? Yep. I'm to good Anyone else, Yaron and microphone. Can I have a second one? So I'm working. Sure. Thank you, Chor. Okay. Hi. I just wanna be a little pedantic about the header thing because I've had fight with it in other documents before. You do name a header in here use to pass token. Okay. To the And the point about registering is that you're not really supposed to do that, without going through the formal process of registering the HTTP header, which turns out to be. More than just naming it. So Right. So I think it's understood we have to go through the ugly To the necessary process sorry. Through the necessary process, of doing that. And we head in got to that point yet. And I think there was some question"
  },
  {
    "startTime": "01:04:01",
    "text": "is, do we, is the working group feel like it's necessary to find that mechanism for how we present them. Because if we don't need to define the mechanism, how we present them. Because it's internal to a trust domain, then we wouldn't have to go through that process. That's why Okay. Right. That's why it's Was left there is fuzzy? But you're right. You're absolutely right. We we need to do one of the other, and I think we were wanting to get some feedback from the working group as to what direction we should go I see. I see. Got it. It's sort of in that half state now that Yes. And It's totally in the half state now. Known to be in the half state. Sorry. I wasn't clear about that. But It came up as a topic. It 118, I was like, how how do we present these? So we felt like we should put something in the spec But, yes, with the understanding that it's Totally not correct. For we're going to define that. So feedback on the list on that would be great. I'll try. Are you? You dropped I think it's cool. At all. Yeah. Yeah. Yeah, I mean, on the header, I feel like know, we it is it'll be good to define it because, you know, that'll increase interoperability. And I also wanted to get an opinion from the group, from the room about, you know, what that particular name that we have, that TXL dash token as the header name. If you see that as a, you know, positive neutral, you know, there's some issues with that kind thing, Just a Yeah. Just a little bit to echo Brian since he and I both went through the process of defining just a couple of HTTP headers. How hard could it be? It's been a running joke for us for the past couple of years."
  },
  {
    "startTime": "01:06:00",
    "text": "Really hard. And, So I would encourage, the chairs to reach out to the HTTP directorate and ask for an early review. And perhaps, engage in that with those folks to get feedback about where the appropriate place to put this would be. Once we have a direction. To me, there are 2 obvious places, the authorization header or a custom header. I don't know exactly which one makes the most sense. I will, I will give you a quick preview though. They are going to tell you to use structured field values. And if you don't, you're gonna have to have a real good reason not to. Which you can do, but make sure you have that in hand before you go forward. Thank you. It From a deployment perspective and people who have been know, sort of deploying this as we're working on the spec it actually turns out to be very valuable to separate this from the explicit authorization header, partly for migration purposes, and partly for, context where you may be using the authorization, header, for things like client authentication, which is separate from the token itself. So that that's sort of the reason one of the reasons, a a separate header, and I will definitely take all the help from you guys, to and I, and Peter, in the sense of, like, how do we structure that stuff to do it the right way? Right. If that isn't, explicit in the draft sort of the reasoning behind that, I would encourage you to to add that because that's that's a very helpful perspective. Okay. Great. Thank you. Where Abijan we go up. Identity chain. Hi, everyone. I'm Kelly Bergin here on behalf of my"
  },
  {
    "startTime": "01:08:02",
    "text": "coup authors to talk a little bit about identity and authorization training across domains. Next line. You can use the Fitel field. Oh, wow. Try it. Did it work? Okay. Demos, Okay. So so this is a picture of Tasmanian devil, a friend of mine was here last week on vacation. She sent me this picture. It may not be local, but, none of my co authors had a picture. And, Tas was my favorite, loony tune characters. So here you go. To rat, A red. Oh, I hit the wrong. What happens here? Alright. I'm holding it the wrong way. Okay. I get it Alright. So, today, I'll talk about the challenge of identity training what our approach is, what's in the draft, changed it since last time. And next steps. And this was, adopted as a working group item. Since last time. So I am gonna go a little bit into the background, Hopefully enough to get, new people the idea without boring the people who have seen this before. Alright. So, in a situation where a client has obtained a a token an access token for resource server, that resource server may have, multiple services inside it. And sometimes, service in that resource server may need to as a second resource server and sometimes that second resource server may be in a second or different domain. It's not clicking me more. Did I do something? Oh, well. Software chair,"
  },
  {
    "startTime": "01:10:02",
    "text": "Alright. And so, the the final service in this resource server may I have some information that it would like to know in order to grant access, to the client. Things like who was the resource owner, What authorization did they grant? What other entities were involved and what authorization did they have? Next slide. And then we want to consider the situation where second resource server is in, in an OAuth situation where there's an authorization server. And so there's gonna be authorization servers for each of the 2 resource servers. Next slide, please. Alright. So here is what, we come up we have, are gonna propose. Next slide, please. So the solution uses 2 existing, OS standard token exchange, and the assertion framework, so at first, the client, has a token for the resource server in domain 1, He needs to, have a a token for the resource server in, domain 2. So He exchanges his access token, in with the authorization server in domain 1, to get an authorization grant, for trust domain too. Then the client uses that authorization grant, interest 2 to get an access token from the authorization server and trust domain 2, and then uses that access token, to get the, the resource and trust them into. Next line. So this is the generic picture of the solution. You see the, the client is just sort of floating above because we have two situations where one where the resource server access the client, one where the authorization station server access the client, but generally speaking, the client, is going to exchange the token"
  },
  {
    "startTime": "01:12:00",
    "text": "to get an authorization grant, step 1, use that assertion grant to get an access token step 2 and then present that access token in step 3. To the resource server in domain 2. Next slide, please. So here's the first, specific example of where the resource server in domain 1 access the client and so you see the food service, is going to get access, to the 2nd resource servers. Next line And then the other situation that we have, the use case is when the authorization server in domain one access the client. And since it is an authorization server, there's some sort of, internal token exchange where get out it, generates the authorization grant itself. Next slide, please. Alright. So what's in the draft? Next slide. So, in the draft, we have, specific steps for how to, go through, generically and specifically, the steps of, identity and authorization training you see here, the example generically Next slide, please. This is the situation when the resource server is acting as the client And you can see at the beginning, you may need to, request the metadata next slide. And here's the one with the authorization servers acting as client, and you can see it generates the, the, authorization grant itself as part of the internal token change. Next slide. Alright. So in the draft, we have a token exchange profile, and this has been updated since last time, It can see in the draft we have, that we should not use the requested token type parameter"
  },
  {
    "startTime": "01:14:03",
    "text": "we've, got an issue to change that to relax or remove that should not because there is a use case we have now where I think Aaron has one where he needs to use that. And so we're going to I guess either relax or remove that should not, from there. Next slide. I also have, a profile of the assertion flow nothing interesting there. So next slide claims transcription. So when that that there's gonna need to be some sort of relationship between the authorization servers because, for example, the the subject, ID may be different in the 2 domains, and you need to be able to know how to transcribe the claims from one domain to another so that when the final resource server receives the token and knows how to process it. Next slide. Alright. So what's new? We've changed the name before, what we've added authorization into the before it was just identity chaining across trust domains. It's announced identity and authorization training across domains to to make it clear that we're not just doing identity training, but also propagating the authorization information throughout the tokens and the training. We've limited, the we've limited the, authorization grant format to a to a jot, more specific term. We've used, you know, jot authorization grant and then some editorial stuff, rename some section headers, moved use cases to the appendix, and some minor example fixes and editorial issues. Next slide, please. Alright. And, again, next slide. So here are some open issues from GitHub. My TV is dead. I'm gonna have to stand out here to look and see"
  },
  {
    "startTime": "01:16:02",
    "text": "I'm not gonna talk about all of these. There's just a few I wanna I wanna hit Should I advance or Oh, no. No. No. Yeah. Is that It's an icon. But yep. So we wanna add cinder training mechanisms, DeepPop, M TLS. This may be a big haul to get that in there, but, I think there, I think it'll be in, Oh, how does the AS know it should generate a JWT authorization grant? Is the audience valued enough, in the token to be exchanged for the authorization server to know that it needs to generate an authorization grant. And I guess those are the those are the big ones that I wanted to talk about. And I think that's it for me. So, if if there's anything else you wanna talk about any other open issues that you'd like to address we can talk about that, but that's that's all I wanted to cover, and this is the last slide. Any questions? Yeah. And it any questions? On this document? Aaron. Yeah. Hi, Aaron Paraki. I was curious about the center constraining mechanism issue Is there anything that needs to be done particularly uniquely for this versus just saying, by the way, you could use any of these underconcerning mechanisms to bind a token, or is there something unique about The The cross domain aspect for that for that binding."
  },
  {
    "startTime": "01:18:04",
    "text": "So I think there'll be some challenges in the, going Cross Trust Domains, for example, an MTMLS, if you're gonna propagate identity information And you've got the confirmation claim. How do you process that or propagate that if it's tied to a particular certificate. Things like that. How how would you I think it's important to talk about in the draft, rather than saying you can do it because I've been thinking about it for a while, and it's, I've had a challenge coming up with a good solution. So I'd I'd like to see what other people can to come up with. Yeah. At the very least, I think, it'd be useful to say please. Please. To to mention sender concerning mechanisms. And then if there is anything that's particularly unique about what you have to do to use them for this. That's absolutely worth pointing out. Alright. Thank you. Brian, I was just gonna follow on and to provide a little more color on that. There's a lot of different variations that depending on who is calling who and changing what that makes under constraint really really difficult, there's some cases where it's not so much, but trying to capture all those and n describe him in the doc. I, I think we'll be challenging. For instance, Erin, like, one of the canonical use cases here is where the original resource server received an access token from the outside world. And exchanges that access token for the, the, authorization grant to go across domain. And in that case, if that original access token is center constrained. It's actually center constrained to the client outside, And so the resource server in that case is not in a position to present anything. Constraining it. So you have to sort of take it out its word there. But if it was switched. If that original client was making the exchange, then you you could potentially constrain it. Can always constrain the issued token, but then that can get confused with"
  },
  {
    "startTime": "01:20:03",
    "text": "the, the token is being presented. In some cases, you can't do proof of possession. And for the authorization grant going cross domain, there's not actually current. Defined way to send or constrain the authorization grant itself. So we might wanna look at doing that too. But, It it Doing in and of itself is uncomplicated with the various flows in different ways that it can manifest itself at complication and, and talking about it in the sort of logical way is hard. As you can tell, as a try to talk about it. It's it gets really confusing. Thanks, Brian. I think as you were talking, what what struck me is I think, we need to maybe write down and, and then work through them 1 by 1. To your point, sometimes it's gonna be possible if the k in the cases where it is not, I think be great for us to be explicit about why not. But maybe, like, the next thing to do here just write down all the possible flows that we need central constraining for. Sounds good. Okay. K. Thank you. Good. Which is the next one. So now I lost my Not sure which one was turned. Next one. Okay. Position Okay. There's only one. Yeah. The last Perfect. That one. Aaron, Great. Thanks. Alright. I'm back. Hi, Aaron Parecki. So I wanna talk about a new draft. I've been working on identity assertion authorization grant, go ahead to the next slide. This is actually a profile of the drop we just heard about the identity and authorization training across domains."
  },
  {
    "startTime": "01:22:00",
    "text": "So This was, It's a profile, although you might be somewhat surprised to hear that based on what I'm about to describe the use case. For this ads. Go to the next slide. So before we get into the Draft. I wanna talk about the context for this and the problem that I'm trying to solve with it. So in a enterprise deployment, scenario, you might have this kind of relationship where a bunch of different applications made by different different vendors all do single sign on to the identity provider. Using a buddy connect or SAML or whatever SSO protocol. And these applications are completely independent from each other. And, we do, you know, we do SSO so that the user has the a single account that they can use to get into all these different applications. Next slide. Okay. However, if we talk about what API access looks like between them, it's actually kind of a a giant mess. So it's very common that these applications actually want to get data from each other For example, your, you know, video conferencing software needing your calendar or Licky wants to embed content from other applications. And what we're left with is essentially letting or requiring each of these application depend for themselves to figure out how to negotiate API access between them And the The identity provider isn't really part of any of that that workflow at all. Next slide. Hi. One way this ends up actually reflecting on the user experience of these applications is you end up with, like, a a Wiki page like this where wanna, like, embed content from these other applications that tied, in through"
  },
  {
    "startTime": "01:24:01",
    "text": "and, SSO through the enterprise MVP. And you end up you drop a link into the Wiki page, and it'll try to go and fetch a preview of that of that content, and and ends up happening right now is you have to go through this extra process of doing an OAuth flow from the from app to app. So in this case, this Wiki software is saying, hey. In order to fetch this Slack conversation, need you to actually connect your Slack account. To this and go through an OAuth flow. Next slide. So from the user experience side, we end up with a lot of off consent dialogues, which look wildly different between each other because they're all from different vendors. The the scopes presented will be very different depending on the, again, depending on the vendor. And it's just a lot of friction for, no real purpose because ultimately, it's in the enterprise context. It's not even the user that needs to agree to that data sharing because the enterprise has already agreed to the data sharing of of that data. So that brings me to The identity insertion authorization grant. Next slide. So the goal of this draft is to take that single sign on relationship that these different applications have. And extend that relationship to broker API access between them. So next line It is we heard in the previous presentation made up of 2 existing RFCs, token exchange, and, the job authorization grant. So this is made up of 2 to these building blocks. Token exchange is the first step where you take this identity assertion an open ID connect ID token or it could be a SAML assertion. Do a token exchange flow to get a jot out the other end, which is the, represents the authorization of one app to get data from another apps API, then"
  },
  {
    "startTime": "01:26:01",
    "text": "take the John authorization grant and use the use r c7523. As a, as a as a Request for an access token and then you get out a regular OAuth access token response at the other end. Next slide. So in this kind of deployment scenario, I forgot to draw the little circles that that put it in the context of of the previous drafts what they call domain a and domain b, but, you end up with the client software doing this token change back to the enterprise identity provider. Getting that jot, taking the jot over jot over to the resource servers authorization server to ask for an access token. Next slide. The reason that this works is because The sort of unstated thing here in the previous draft was that how does this This authorization server in this domain know that it's okay to trust this drought that came from somewhere else. Well, that's in this case because Both of these Applications, do already have the single sign on relationship to the same enterprise IDP. It can use that same relationship to, as that trust root so that it knows it can it can validate the job through that same Simcher. Okay. Next slide. So why is this a profile, or why bother profiling? Why not just use the draft identity authorization authorization training across domain. There's a couple of important points. In the authorization training draft, the how the initial token is obtained as out of scope isn't really ever mentioned actually in the draft kind of just assumed that So the Client has one already. And it's actually, often implied that it's an access token."
  },
  {
    "startTime": "01:28:03",
    "text": "In this it's implied, but not required because it's actually just using the token exchange framework, which can take in different kinds of tokens in the identity assertion, draft, that initial token is explicitly and token that is obtained through a single sign on flow. And then similar to that, the input to the token exchange in the identity training is generic or flexible. It's basically just saying go use token exchange and any of the token types that token exchange talks about. Can be used here. In the identity search and draft. It is explicitly only identity tokens that are accept it. So only ID tokens and SAML assertions, not access tokens, not refresh tokens. 3rd in the identity training draft, there is a brief mention about how this trust relation needs to exist in Northwest to work, but it's left out of scope of that draft, in the identity assertion draft that truss that cross domain trust relationship is explicitly because both have that connection for SSO to an identity provider. And then lastly, in the identity at Chaining Draft, the actual jot that is used as the cross domain thing. The thing that's the output of token exchange and input to the authorization grant Isn't there's nothing additional to find beyond is just just a jot in the identity training draft and in the identity assertion draft, It there's very a very explicit list of requiring certain claims and actually defining Symantic's up certain claims, things like things like this needs to be the what's going on? Please, please, please, please, please, things like, The audience needs to be the certain thing where we need this client ID claim because of this reason. So, why why profile essentially because, the identity training draft"
  },
  {
    "startTime": "01:30:02",
    "text": "enables this use case but is to open to vague, and in order to actually get interop between all the parties participating in this use case We do need to lock down a lot of those options. And and narrow the scope of it So this is meant to be a interoperable profile for this particular use case where someone who wants to do this can read this draft and actually end up with something that works with the rest of 45. Next slide. I think I have a couple slides in here that just quickly go through, like, the the request responses, don't wanna go too deep into this, but just to give you an idea of what it looks like, this first is the token exchange request taking an ID token. As the subject token for the token exchange saying, hey. We need to get this request a token type. Is this identity, authorization grant, for this resource, which is this token endpoint over at this other application, And at the bottom, I put in a a client assertion or a a a Jot private key job authentication, client authentication just for good measure. You can see we can also request different scopes for this application as well. Next slide. The response to this is a token to change response, which means weirdly, we have to have the token type of NA, which is, I guess, some sort of legacy thing and the parameter access token also weirdly, as mentioned in the token exchange, draft isn't actually an access token. It's just a thing that has to be called access token for reasons. That token is the jot authorization grant that will be used in the next step. But the issue token type is the thing that actually says what that is. And then similar to how an if a client requests certain scopes, the response can and can say, yes, you got all those scopes or actually only got a subset of those scopes face based on policy."
  },
  {
    "startTime": "01:32:01",
    "text": "Next slide. So the next step will be the client takes this jot assertion over to the other application, the token endpoint at the other authorization server and says, hey. I need an access token. This would just be like a a regular OAF, access token request. Except now it's using a jot bearer, with the assertion being that jot the claims in the jot will describe in the that that jot type will describe what this is to give it the appropriate way is to switch over to the flow, it can validate the the signature based on the, issuer claim in the Jot, things like that. And next slide. Yeah. The response is a regular, OAuth token response. I. Next slide. Yeah. So the other important thing here is that, because of how we expect people to deploy this. We wanted to make sure that We are not imposing any new restrictions on the actual access token that's at the the end result of this because we're assuming people already have anoa framework because they are currently doing OAuth to other applications and issuing tokens of whatever format they've decided is appropriate, this is just less same token response that you would already be sending for, like, an auth code flow And, Not making any new requirements on access token type or format or anything like that. Next slide. So the status of this work this is currently implemented in a development branch at Okta. It is deployed for live testing. We have, demo apps built that do do both sides of this. There's a little sample a Wiki application. There's a sample to do list application. They can go through this whole sequence to do the exchange and get API access across across the different"
  },
  {
    "startTime": "01:34:02",
    "text": "across this across these domains. And we are working with 2 companies who are also planning on implementations of this as well, and we're just starting that work now as well. So that is the presentation. Happy to answer any questions if there are any. Anything, Did paper see similar sort of needs or have some comments or questions on the content that Aaron presented Want to rebuild this work, find it interesting, church Fletcher, Church, Aaron, so it sounds like basically We're bootstrapping off the ID token to identify the authenticated session and then creating basically, the the authorized access token off of that identity right in the sense of accessing APIs, it gets a little bit, I think, to maybe Someone else has come in here this morning about, like, do we need to add center constraining in certain places around the the ID ID Jag token that's issued and I'm thinking mostly about Is there an impersonation scenario if I get access to the ID token that would then allow me using this mechanism to get, you know, access tokens to other things. Sure. Yeah. I can speak to that really quick. Can you go to slide 10. I think that's gonna be the most useful picture. For this. This one? Yeah. Thanks. So,"
  },
  {
    "startTime": "01:36:03",
    "text": "The there's a couple of assumptions made here which are spelled out in the draft, which is that there are actually OAuth Clients, There's an auth client registered between the two applications at the bottom. Which which today is used for a redirect oauth redirect flow. Which means that authorization grant request can use the same client authentication and same sender concerning mechanisms if they want to. So All that is possible to do without really any any new work. And then similarly, the client that's doing the token exchange to the enterprise IDP, It already has a registered client there with, again, its own client credentials or or center concerning mechanism. So, again, we can use the same sender concerning. It exists there. And I obviously would recommend doing that if if possible. So I would. The I would absolutely be up for adding a mention of, hey. Here's how to do center consulting with I don't think anything you need to be defined, and I think it's actually pretty straightforward to make it work. In this scenario based on, the the relationship between the existing, the the parties here. Any questions that before I get to the second part of your I don't think so. I think, don't think so. Maybe we just add something in security considerations. I think a a senderconstraining section would be useful beyond security considerations. Yeah. I think that's a great idea. As for the impersonation question, Again, because there's because there's existing client relationships between the different between all three legs of this relationship. That that information about which clients which is meant to be embedded in the authorization grant, then similarly, like, if you just grab an ID token from somewhere, you can't go and do a token exchange not because"
  },
  {
    "startTime": "01:38:04",
    "text": "you would need to include the client authentic authentication of the client that that ID token was issued to in order to use the token. So It's not just an arbitrary ID token in authorization out. It's ID token plus client authentication in And now you can't just go stealing any tokens. So It's I think it's all covered. Under this. Okay. But it's it relies on that the fact that there are client re registered clients between all three parties Great. Thanks. Okay, Atul. Yeah. Hi. So I think this is really useful and, you know, definitely something that that needs to be done. I I just sort of was wondering if this can be done as a profile of the, ID training spec rather than a separate xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx6xxxxxx6xxxx6xxxx6xxxx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xxxx6xx6xx6xx6xx6xx6xx6xx6xx6xxxx6xx6xxxx6xx6xx6xx6xx6xx6xx6xx6xxxx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx6xx And, if you look at slide 11, you know, everything you talked about seems to be kind of a specialization of ID training. And so just wanted to get your thoughts on that. I'm not sure what you mean. So this is meant to be a profile of the identity training draft. I thought the specific mechanisms that you were doing more somewhat different from what we're doing in ID training or Is that sort of No. It's it's It's it's So a little bit of background on this. When I started this work, I started with something that actually did work quite differently, and things were called different things, and then realized that actually, it is In fact, exact mechanism you're describing, any training so I reworked the whole thing to actually literally use the identity training draft as the base. So if you were to Implement this Drafted, draft, draft, and It it is it is a 100% a"
  },
  {
    "startTime": "01:40:00",
    "text": "within the framework of the identity training draft. Like, there is nothing new added in it. It's just a restriction and profiling and some additional requirements of of what the parameters mean, but It is a 100%. A profile of the identity tuning draft. Awesome. Thank you. Alright. Yeah. I was just gonna comment. I think we may actually see additional profiles. So keeping it as a separate document makes sense. So that I could foresee a whole lot of family, but maybe 2, 3 more. As we, as we need to tie down to specific use cases. I wouldn't wanna try and compress that into one document. Yep. Thanks. Yeah. I wasn't suggesting from being making it one document. So just to be clear, them. Yeah. No. I wanted wanted to make this work fit within the identity training draft. So and was able to do that. Okay. Thanks. Thanks, Aaron. So since we still have a little bit of time left, I wanted to come back to the open questions Do you try to press best best best Rifat, ahead. go Yeah. Yeah. Christina has a comment about the naming then able to document. Christina, do you wanna talk about this here, or is he gonna I don't have much to add other than Yeah. The naming of the drafts was slightly confusing to me. Like, I understand the rationale of, like, intention of both, but looking at the naming. I mean, I understand the background, Aaron, that you started separately. Maybe aligning it somewhat, would be Mountain Clear. I this is a a tough Naming is hard. Let's just say that. So In the time that in in the time between The last meeting and now what you didn't see was the whole Discussion about the naming of both They"
  },
  {
    "startTime": "01:42:02",
    "text": "identity training draft and this draft. The identity training draft started as just identity, and then we added identity. We added authorization to it. I think I think that was mentioned in the last session. So the draft no identity and authorization training. Which that was meant to sort of make it more clear that it is possible to profile for authorization use cases and then The reason I chose this name for mine is the the the, I mean, it's two parts. It's the identity assertion is the input And then the authorization grant is is The name that is 7523. Of the authorization grant. So it's, yeah, it's in my mind, these are already kind of connected, but I see how maybe it's not obvious, but I don't At this point, have any better suggestions for how to make that more clear. Atul. Hi, Anthony. So sorry. I mean, if Can can this work also with Samuel? Like, I know. Okay. Just wanted to not tightly bound to make sure it's IDC. No. It's not. It's, in the example, I only have a ID token example in the spec, but It does mention the SAML assertions are a valid input and because token exchange allows SAML tokens as input it's it's it's it's It's fine to to do that as well. Hi, Justin Richard. I think I've oh, Oh, go ahead. Sorry. I didn't see you there. Go ahead. No worries. I think this is just me probably losing the thread here, but I got the impression from the last presentation. That it was jot only as input. And so hearing that this subset profile. Is it"
  },
  {
    "startTime": "01:44:03",
    "text": "or am I misunderstanding? Misunderstand. No. Slightly slight misunderstanding. The Yeah. The account. Thank you. The job only, part of the previous in the previous mention was actually the assertion, the output of token exchange, and the input too. Okay. So the the intermediary piece is jot only. Right. Exactly. Okay. Thank you. That that clears up a lot. And that was actually an alignment that we did between these two drafts. Over the last couple of months as well. Okay. So we finished this one. Perfect. What are my next steps for, working group adoption of this. I think we let this cook a little bit. The other document is It's also sort of, like, the identity training is is just getting into a phase where we say it's a little bit more mature. We would expect more reviews to come in And Like, if you find, people who are interested, outside Okta, who also sort of would be interested in this. I think that could be a good indication that we should sort of then run a a qualified adoption Does that sound good? Yeah. I have I have 2 already. So I will I have 2 interested parties already, so not hopefully able report more in, in July. Could we have still a half 15 minutes left. So I think we should, sort of jump back to Brian's presentation and if, those who had these questions still remember what the questions where, we should discuss them. We should use the time we have efficiently. Brian, do you want to come over here and and moderate those,"
  },
  {
    "startTime": "01:46:02",
    "text": "happy too. I I don't know. I apologize for running long earlier. And if there are questions, then can we We can talk about them now. I'm happy to do so. The context has been lost. I can sit down too. I think it might be nice to kind of Maybe go to the last slides, We were focusing on field finishes, Who are thought? Not that far. This one? Is this the only one we had? Think you had, like, slide is Richard. Richard. Yeah. This one. Mike, Make Jones. I read the PR and commented on it. But, in my mind, An s t jot that does or does not include Key binding is still an SDJOT and not a different data type. I would not use a different media type. I would not sort of divide the world unnecessarily. It's just an optional feature that you use or not. Richard? Do you wanna respond to that? You sneaked on too, Mike? The concern here is that, yes, it's an op it it's an op it's some degree is an optional feature. You could but it's something that in doubt it gives you different security properties out of the object. If I hand you an SD JWT without key binding, You have no idea whether I have the private key that goes with it or I can I just chose some things to disclose to you, and I could be I could be replaying it from some some I got from someone else? But if I hand you one with key binding, you have proof that I have the private key."
  },
  {
    "startTime": "01:48:00",
    "text": "And so we just need to make sure that whoever's verifying that knows which properties they're getting. At Richard, Wouldn't that wouldn't the ex the different media type really help? Because if I'm, if I'm making that attack, I would just also change this for the media type, And so, like, it sounds a little bit like This is a attack that is very similar to what was percent last at the last IETF meeting in Lambs where if you do make make changes to that agricism, then you could do some some downgrade and potentially then mount some attacks and the solution that was discussed in Lamb's was Well, couldn't we actually incorporate something into the key derivation of, procedure. So, obviously, that was on encryption, so we would have to adjust that appropriately. But, something along those lines that relate to the use of the crypto graphic mechanisms or to fund it on discuss the issue and fund it on additional data that needs to be negotiated outside the use of the, the mechanism. So what I'm thinking about here is if I'm in a specific environment, if I'm saying I'm using the, a token with a key associate with it I need to sort of indicate that somehow in the policy, like how would indicate that I only accept certain algorithms. I don't accept anything. So something along those lines. So this this is why I basically the the state of it now. And I think Richard's assertion is is not actually changing any of that, but just restructuring the terminology so that it's more clear which object we're talking about and lessen the opportunity for mistakes around that policy to come up precisely. Yeah. It's not a security. If you arrange your is much like with alginate. That's why I bring this up as the analogy. If it's the augment, if you arrange your policy, about what algorithms are acceptable, You will not be vulnerable to this."
  },
  {
    "startTime": "01:50:01",
    "text": "But while we found in practice and operation, is people don't arrange their policies correctly, and we end up with vulnerabilities as a result. So the idea of creating a clear separation here is to make it more difficult and discourage people from arranging your software, in ways that you have to very precisely arrange a policy to distinguish the two cases. But, in, instead, in this curfew of the treat these cases very separately. So that they're difficult to confuse. In Yeah. To Brian's point, it is not just terminology, There's a different media type, which, in my mind, is extraneous. And Haunas explained why it's extraneous. Because The very fact that you claim that something uses a different media type, and you claim that it has a Key binding doesn't mean that it does. The recipient still has to verify that there's a key binding. So the the different media type doesn't actually help with security properties at all. So I would not do that. I said that in my PR comment. Thank you. Thank you Mike. John Bradley. So the SDJWT has a confirmation method that the Receiver has to verify. I mean, that's in the signed object. From that's that's the issuer is putting it in there. So, That's what drives whether or not It's a keybound SDJWT. Well, Maybe I misunderstand. But there's a confirmation method,"
  },
  {
    "startTime": "01:52:01",
    "text": "You're supposed to check the confirmation method. Otherwise, it's an error. So I don't know that the the Media type actually helps with the validation. Perhaps it helps with the requesting. Yeah. The media type is not at all intended to help with the validation. It it's there as a tool to do things that people might wanna do, like, request something Right. Indicate that it is, but it that's not a I think that there's perhaps a stronger argument for If you need to request if you wanna request 1 or the other having immediate type might help you with that, I think it's dangerous to infer that the media type actually comflates with the confirmation method in the JWT. Cool. I mean, just to be clear, we should never have an interface into which you can shove an SD JWT without key binding or an SD JWT with key binding. Because those things are gonna give you different properties, and it should be handled differently. So, like, we should guide against any designs at the protocol level or at the API level or whatever. That encourage you to just shove something in without regards to whether it has key binding or not. That's my point here. And that's the point of all of this this this, you know, submit to terminology and media type distinction. Is to guide toward designs that treat these things separately because they have different security properties. John, you don't look convinced microphone. Go to the microphone if you microphone. And and for what it's worth, the confirmation claim that's not the only way to express key binding within it and is not intended to be this sole driver of whether or not KeyBoning needs to be checked in the verifier. We've even had folks like Neil, previously argued that there needs to be the ability to except either based on policy allow upgrades and so forth. So it it's not"
  },
  {
    "startTime": "01:54:03",
    "text": "The idea is that it has to be bound to policy about whether you will accept or not. Right. None of these with or without Kibon in and that that has to be it and simply talking about them as different things helps. Well, I I just describe API as define APIs and talk about them as there's no actual I'm so maybe we're talking possibly. So talking about them as different things is is different from necessarily having a different media type for them. So I agree that talking about them is different things. Makes sense. Name from an Right. The common thing that these things are going to be used for is to carry some sort of verifiable credential to a verifier in a 3 party model. And the response is gonna have an SDJWT. In some cases, they're going if it's a pit, it's going to be have a key binding because that's law. And in other cases, if it's a gym membership, maybe not so much. But they're both going to be received, over the same flow by a verifier. And the verifier doesn't know a priority which it's gonna get. Well, maybe it needs to, but in the current Designs of verifiable credentials, it doesn't. That's that's that's the history error. microphone microphone microphone. Mike. Right. But Well, That We have the browser vendors to designing APIs, which prevent The verifier from being able to know those sorts of things. So there there are a couple of things pulling this in different directions. They have I think you've been on some of those calls, but, you know, there are privacy issues Which"
  },
  {
    "startTime": "01:56:00",
    "text": "people wanting to blind different things which may stop that stuff from being known a priority. So I I agree with you at a high level. I not certain, you know, trying to completely separate those at the verifier. Probably means looking at other parts of the protocol Okay. Christina. Thank you. Yeah. So I didn't want the discussion to solely focused on the media types because that's not the only thing that's PR does. So to kind of break it down The first part is clarity. Honestly, against the editor's intuition, this split between the state job and the state job whisk binding jot made a draft pretty much clear, like, easier to read conceptually and stuff. If misrutling this terminology, that's kind of the first starting point. The second point is I do agree with Richard's point that it is very beneficial to separate these 2 concepts from the processing perspective. And I'm not sure I entirely agree with what John said. Like, these two things. Very far needs to distinguish. And whether there's a browser API or an ID or whether protocol, like, clarify honestly needs to know how it's processing what it's receiving, whether it's from the browser API or whatnot. Right? And the media type first d jot with key binding jot just becomes one of that means it can be used to differentiate, but we're not saying that like, Zao only or Zao way to differentiate So I think at least for the purpose of this discussion, if we can get an agreement that differentiating these 2, is DJOT ways and result key binding, especially from the verifier per And, honestly, from the wallet's perspective too, because wallet needs to know, yeah, if it's sending a"
  },
  {
    "startTime": "01:58:03",
    "text": "is stage out whiskey binding or result. Like, if we can agree that that's beneficial, Like, that would help. Okay. Thanks. Thanks, Christina. Show. Actually, NPE are running out of time, but chose to continue Just real quickly, Joe Salloway, for me, I think the different being able to differentiate between these two things mix it clear how you would apply policy to it. Now I may be missing some of the nuances here, but It seems like, a good idea. Thank you, Joseph. Thanks, Joe. Mike, Yeah. To Christina's point, I'm fine with editorial clarity. I am not fine with making protocol distinctions among things that you're going to have to verify as a recipient, anyway. If you have a different media type, You're still gonna have to check whether it conforms to the media type. Regardless. So you're gonna do the work if you have a secure implementation. So don't, like, add artificial syntactic sugar that doesn't help. Nakiya Sorry. Can I just quickly say, why do we need why do we have explicit job typing then? Like, Like, when you get a jot, like, you know that different jots are different, but you still wanted T Y P just for do it know what you are exactly getting. I see this as a parallel. It is parallel, but I draw a different lesson from that. The, type value for explicit typing is part of the sign structure and so can't be changed But the recipient only gets value from that. By checking it at runtime when it receives it. Just like you only get key binding value"
  },
  {
    "startTime": "02:00:03",
    "text": "By checking it at runtime, whether you received a key binding, as part of the signed data structure. So Christina's right. It's exactly parallel. The recipient must check it regardless where it has no value. And and this is just naming to try to encourage that and and try to avoid mistakes around that. The media type itself is ancillary and just there as a means to express that that's what this is that need it, but isn't required for any of the security or processing, it, it's sort of orthogonal to the, the coordinator just for a while to add a media type. I I we ran out of time, unfortunately, on that a specific example, the jar RFC uses the same value as a UIP in the dot and as a media type. Like, we already had already have a precedent doing this. Electric, guys. This is a little different. The this is super interesting. I hope we have some some spare time at the the next two sessions, and we can continue that conversation would like to hear the the outcome or many any directions forward on this topic but for for today, We are done. I would like to thank you all for, The contributions to speakers for their night slides And, I think we've managed to find some reviewers and, Yep. Yep. Go from there. Go from there. Thank you. Thank you. A big thanks to the online participants. And adjusting for taking the notes. Yep. Thanks, Justin. Oh, hopefully, you took notes. Hi, Brita. Bye, guys. Enjoy the weather."
  }
]
