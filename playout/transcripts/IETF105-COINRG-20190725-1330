[
  {
    "startTime": "00:00:29",
    "text": "[Music] hello hello everyone this is computing in the network point we\u0027re going to get going to just a few seconds if you are not here for coin please stay anyway you have a great program and if you\u0027re here for coin well you\u0027re at the right place we still need someone to take notes I had sent them and request this morning and nobody answered so if somebody who is not presenting could actually be the Good Samaritan and take notes it would be greatly appreciated it\u0027s not not going to name it I\u0027m a namely a volunteer I\u0027m so anyway please if somebody can take notes just raise your hand and we\u0027re going to get going oh you\u0027re Rachel thank you so very much so Michael come over [Music] okay hi I\u0027m Eve Schuler and these are my co-chairs we reach Jose and Jeffrey welcome to the coin working group this is our second official meeting our third gathering of course we started with Bob we\u0027re still in proposed research group mode and we\u0027re grateful to see so many of you out there and so many contributions you\u0027re in the ITF IRT F you know this note well slide well things you should know our data tracker where all of our documents are our Charter our milestones we\u0027re in the middle of we\u0027re in the middle of "
  },
  {
    "startTime": "00:03:29",
    "text": "migrating basically from a wiki based mode of sharing information to a get github document archive as well as code archive and the coin mailing list is simple to remember coin at IRT F org and we have remote participants today we\u0027re gonna have a remote presentation and we\u0027ve just appropriated our own slack workspace which will also allow us to have interim meetings more easily we have a full agenda we have basically many many internet drafts many of them will be presented today at least the new ones I think we\u0027ve got eight at this point in time and five of which will be presented today in addition to the administrivia we\u0027ll talk about next meetings that are going to be happening and I think the only change to these presentations is that Dirk and your have a combined merged presentation based on their draft yeah I think it\u0027s you okay so this is Jeffrey for those new to this group so the general goal of this group is to foster research in computing network to improve performance and our folks will be network architecture and protocols and by addressing real-time use-case application isn\u0027t working in progress so we have not modified the chart a little bit after Prague and June interim meeting and also based on that discussion mailing list and thanks for the contributors and the participants so main change now yes on the items in scope section as you can read in this slide but the plan is to capture potential proposals from this meeting and maybe after then we will have a revised devotion submit to I have chair to review and approve with the consensus of this group so we also are working on some milestones very preliminary we know this is a whisky up for a party so it will not tell you that unless we are approved as a formal one but we you know we hope to use this to check some discussions on the future plan so we suggested to capture the still of art and attic articulates some challenges then target to the use case and also identifies the ecosystem dependency and also the requirements then hopefully we can have a specific coin scope may be later next year and specifically enough so that within which new architecture and mechanism protocols "
  },
  {
    "startTime": "00:06:29",
    "text": "can be proposed we are also linked some links the existing individual shaft to these milestones just as related related rafts so basically the input to the disk the input up to the discussion of each apart it\u0027s not we are not implying this will be potential for more research groups draft right it\u0027s too early to see that okay yeah well we\u0027re just a proposed research group we\u0027re kind of lucky that we\u0027ve had a bunch of people already to do work that addresses the issues that we want to do so we currently have as you can see four new drafts which was really good for this meeting and we have three existing drafts and that we\u0027re updated and we didn\u0027t have time to put them on the agenda for today but they\u0027re progressing especially the one on XR is going to be also taken over with a new team to make it progress the other one we have stuff on industrial networks and actually the problems of coin to to drafts on that and then the App Center from we have to do we have to Dirk\u0027s here so we have Dirk number one on what coin is and we have Dirk number two on the app centers and so this is going to continue and obviously collaborators are welcome and if you have other ideas for for drafts please supply them so we had our first hackathon on Saturday and this is the present of people who participated and we had I think our hackathon could have been some kind of a train wreck because p4 is this new language that allows you to program switches and there\u0027s not a lot of people who know how to do that and we were very very lucky that there is a local company called Novi flow who has its business of doing p4 and they lent us two engineers for two days so thank you so much and they actually got us going and so they\u0027re around the table with the team so it created a really really nice team we could also poach a few people from other tables so I ended up having quite a large number of people what we did obviously we there was a there had been before hackathons and before tutorials and other conferences so we can actually take basic examples to get everyone on board we had a remote participant who actually was the guy who knew how to program this so he had his own project on machine learning in in ipv6 and he made a lot of very good progress on this "
  },
  {
    "startTime": "00:09:30",
    "text": "we had I don\u0027t know if he\u0027s here but we had somebody from liquid telecom which is from from Africa who recognized that he could actually do some translation of p42 golang which is the language that they use and on their networks at the end we after one day where everybody was actually kind of up to date and how to do things we had two participants who addressed a real problem that actually we\u0027re going to face boat in industrial networks and in this XR aar VR field which is actually packet filtering so compare a packet to a I called it a the original idea was to have a perfect packet and then compare all the other packets to it and make sure that we can detect when there\u0027s something interesting obviously we didn\u0027t do that we started by comparing addresses so we\u0027re storing one and comparing but just to tell you that after one day people were really really ready to do real work and we also made a list of ideas and I\u0027m going to post that on the github I\u0027m going to we have the pictures what we learned is that the need to come prepared is really good especially when you\u0027re going to do everything in virtual machines the the usefulness of experts in a field that\u0027s expanding I don\u0027t know how many hackathons are in the field where the language is not even fully defined right now so it was really good to have people in you what they were doing you can get participants the same day so that was great people were seeing what we were doing and they were joining the team you do a lot in two days which was surprising in the way and to the teamwork was great and we keep we have now a shorter mailing list of all the people who participated in the hackathon to continue the work that we started and we plan to have another one in Singapore so if you\u0027re interested you can join us so now we have a ton of presentations and we have instructions to the presenters and I see Dirk saying oh you didn\u0027t tell me this so this is a surprise so the instruction to the presenters is if you can please try to link your work and that\u0027s not going to be difficult for you there to the charter and highlight maybe where changes would be necessary and yes so you\u0027re in your next up and if I\u0027m lucky I\u0027m going to be able to load your slides thank you you don\u0027t have to call me on the one that\u0027s better okay thank you yeah so the intention of the draft that "
  },
  {
    "startTime": "00:12:31",
    "text": "is mentioned here and its presentation is actually to provide input to your planning process and discussion to be honest I was a bit surprised to see such a I mean detailed list of mice on the it\u0027s good but no I mean in my experience a research group also takes some time to to find directions and I think oh it\u0027s too low and but I am so this this draft presentation is time to provide some input on say potentially interesting topics and also derive some research questions that could be of interest okay let\u0027s okay okay so I\u0027ll talk a bit about what what does it actually mean when we when we say in network computing there\u0027s a computing missing and then we discuss a few thoughts so or technical aspects and we end with some perspectives on what could be really interesting to do in coin and ok so I mean there\u0027s lots of computing in the network already today so we heard about smart necks on Monday web servers do computation CDN is kind of a computing system as well all these cloud platforms often you hear that edge computing and this is a really fuzzy term and what and typically actually means is extending well understood and widely successful cloud computing concepts to the edge so I would say there\u0027s potentially not that much research to be done there so yeah architectures like mobile edge computing so they sound look kind of you know intriguing or at least unusual but this is essentially just extending cloud computing virtualization technologies and management technologies to like execution platforms at the edge to something was like edge systems like radio base stations for example so it\u0027s nothing really new and and I don\u0027t think so virtualization and automated management for these kind of systems particularly interesting for us then there is this whole category of also widely successful application layer streaming event processing data analytics platforms so this is a key thing here so there also you used all over the place and all the popular was a powered by them so "
  },
  {
    "startTime": "00:15:31",
    "text": "they run in the cloud they run in overlays in networks when network is relatively cheap over-provisioned and and well-managed so when you think about doing similar things say maybe in say less well controlled more more distributed say internet scenarios that there could be an interesting edge there so these over their systems I mean that they benefit from from all the internet tools that we have transfer protocols TLS and so on but they essentially treat the network as overlays and such have relatively limited visibility into the network so you could actually say they treat the network as circuits they use different namespaces have to translate between them so this works well in the cloud and data centers would be interesting to see what can the network do to support these systems say more than more directly and so earlier I think in previous talks we talked about this idea of doing that by jointly optimizing computing and networking resources so for example if you want to make a computer offloading decision you just do not allocate any available VM but maybe you do this based on knowledge about the topology congestion historic performance and so on and so you have a system that basically can do many decisions in network itself can maybe also leverage mechanisms they never actually already has so like routing protocols for example yeah let me just glanceable it a bit quicker because I said this so now when you try to implement this joint optimization for example or this integration of computing and networking they are different candidate technology you could look at so so this function chaining is one so we have a talking with one say two but so something is basically the idea that I arranged say pass from that touches several network elements in my system was the assumption that these elements can do something useful or need to see the the packets in the flow and so these are functions like classifiers filters caches and so on normally this is these systems are fairly statically configured so they don\u0027t change that often you can "
  },
  {
    "startTime": "00:18:31",
    "text": "reconfigure them but it\u0027s not the idea to you know switch back next hops all the time and typically the assumption is that also we actually don\u0027t get in between the TCP end to end control loop it\u0027s more like on a packet level what you do there okay so this is intended for specific operator so called GI lon scenarios not exactly a platform for testability computing but I\u0027m interested to see say what our colleagues have done in the next talk then you just thought about the p4 work at the agathon so there is this work on using programmable data plane to achieve in network computing so marco also has agency at earlier meetings well this is the idea that you can implement some application logic for example in slightly more powerful switches I would say that it\u0027s an interesting approach many interesting abilities but the systems that we have seen so far I think it\u0027s fair to say whether point solution that assumed well you can basically intercept the packets their work with the match action logic and back program the application semantics in languages like p4 this is a fairly limited environment and also has kind of strong assumptions or security I guess would be difficult to do transfer protocols so it I would say it\u0027s an interesting starting point but probably wouldn\u0027t really suffice as a general purpose platform for distributed computing so in this group here so we think we have like two directions that we have been discussing so far so coming down from these distributed computing systems in the application layer and trying to see how we can maybe integrate those things with the network and then say p4x approach for example maybe try to move up the stack and try to see what we can do for for applications so just to enough give us a handle to kind of talk about a few categories so here\u0027s one example that kind of comes from current work that we have been doing for enable computing in a group of say ICN folks so assume you have a kind of network of nodes that can generally offer compute services so this could run execution platforms or any kind of platform that could run some functions so we assumed that we would be like diagnostic to the specific environment "
  },
  {
    "startTime": "00:21:32",
    "text": "we just be able to call some functions or two in each to create some state and of course you want to be able to leverage specific features so like a GPU here or a trusted execution environment there but in general we assume could be a heterogeneous system and so you\u0027d be able to use whatever you need for your application and so in a dissipated application context there could be something like sessions or like an application in in progress that would then perhaps allocate a subset of these nodes and so this would be like part of one session and you would then use them then - yeah locate in sense yet functions but also a stateful so systems that could for example also yeah have side effects men keep stateful number time and so on so in a system like this the assumption is that would be like a disability system maybe that\u0027s programmed in a program has certain application requirements one stand Emily and the dynamic execution determines so what needs to be allocated executed what needs to be transmitted in terms of input parameters and results so there would be some kind of remote method invocation protocol for invoking functions or status functions or maybe state for actor member functions and so in this example here what these functions could be very very lightweight but also say two significant pieces of work and as I said so one function can trigger other function calls and so on so in that system it\u0027s useful to have information about so where those functions are so if for example if I have a stateful act or I want to continue talking to that one it\u0027s also useful to know so what is the resource utilization situation so how busy is this server for example or how well is it performing right now maybe it\u0027s actually formally not loaded but I just figure out it doesn\u0027t work so well for me and it\u0027s also good you know so where are still an allocated resources or notes that I could maybe integrate into the system at runtime okay so in this system we we we distribute this information by some distributed protocol you don\u0027t think about using Network mechanisms like the routing system to at least partially help you with that or to use information that you get from say transport protocol like protocols that are you okay this is perhaps has a "
  },
  {
    "startTime": "00:24:34",
    "text": "longer latency right you have some congestion information in there protocols okay so that\u0027s just an example to just give you someone to type some mind shape we can can talk about some some mechanisms so when you do that first question we could ask okay what are these functions anyway so how how fine granular or heavy weight are these so are we talking about like shifting bits near a resistor or adding on multiplying potentially but more visit on the other side of the spectrum you know like some machine learning application find faces identify people call it police and get people arrested possibly so I think there\u0027s there\u0027s a long big space in between and well potentially I would we would say it could could be all of that put in so obviously not as far as this machine instruction there but you could say have really long time complex functions or services as well as stateless function that you know just you know process some data or does it better analytics and give you constant results on some input data so functions in that system would need data so where does it come from obviously there would be something like input parameters so an image to possess there would be some like an operational context so for stateful service they would also be something we think that so yeah background data that could be kept in a key value store or some database which could be modeled as a stateful actor for example and and you could think about how do you know specify or use those parameters how do you identify the contexts or systems or provisions like this must be made could be like in in the packet or in the message that you convey depends a bit on the protocol solution if you design and but also what\u0027s the what\u0027s a sensible data unit what this function but this functions to be you work on so packet processing so it\u0027s in-service training perhaps could be useful but may not be the the ultimate goal in the end so because there are solutions for that and think about doing something for disability applications we think it\u0027s more useful to talk about application data units and think about yeah some some transport a section that allows us to convey these ad use from one function to the other for example "
  },
  {
    "startTime": "00:27:34",
    "text": "and yeah obviously in an internet context or in any context you have to think about security properties that means mouth indication hell access control so these kind of things yeah functions sometimes need to be able to do side effects to do something useful so this could be persistent side effects or updates to to to database states for example or could be more temporary integrity effects so there\u0027s also categories that we suggest you to look into deeper a little bit I\u0027m not doing this then yes often so in our system designed the question so what our application semantics in terms of how to get actually get data so is it like like a pool abstraction or a push abstraction so pool would require something like a repress response for the color perhaps push is interesting if you want to do some say reactive programming so event triggers systems so we think that that is all fine that doesn\u0027t have to determine well say how the network protocol apply so we\u0027d be able to want to be able to to met these different applications inventx onto a student web protocol but doesn\u0027t have to mean that the network itself for example is obvious within push or so then so it\u0027s easy to say that we want to have a general-purpose disability computing platform but I think for say meaningful applications you also really have to think about performance so distributed data analytics okay I\u0027m almost done for distribute data analytics you could imagine having some some pipelines that you know feed the data into functions and so each function is depending on the input data that the other function generates so I mean this has to be well designed to to provide any useful performance and then things like how can I reuse data and the system things like caching and so on okay let me go over this a bit right now so we have more info on this in the draft so the coin so I mean first of all we are the internet research task force so I think in general we think in general it\u0027s healthy to think about open networking environments so let\u0027s not make too many assumptions on how shielded our systems on how trustworthy either the PS are and and so on so in general it\u0027s a hostile environment where you have to run function on and "
  },
  {
    "startTime": "00:30:37",
    "text": "generally untrusted systems and we have to find way to establish trust for example so that your code runs correctly and and and so on so heterogeneous system things security from the beginning and so on so one idea that we had is it may seem attractive to you know categorize the work in different use cases or scenarios like industrial IOT but actually we think that it\u0027s actually not that useful because in this example here industrial energy they are I guess like with different economic classes of how network computing could be used so there is for example that could be done like a virtual PLC that runs somewhere that\u0027s just virtual machines not not that interesting but they could be also like this with the data processing or some like real-time control so we think it\u0027s more interesting to dually categorize these these functional properties and interaction types and these kind of things and yeah so our suggestion for say if you would did some like you know experimental protocol or something things to agree on we think would be in the model for women method invocation which types of functions are we talking about what is the programming model not so much the different bindings how do you ascribe resources and how you allocate resources what is maybe more specific to implementations is the different execution environments the languages or web sections for those platforms and a bunch of other things and there\u0027s a long list of other things that I\u0027m talking about here thank you very much this is exactly the type of stuff that we would like to have discussed on the mailing list is very very and yeah lots of great questions lots of very good things that we already have a little bit thought about and yes we should move the discussion to the list okay thank you so very much next up is Adrian and I have to load your new versions I [Music] "
  },
  {
    "startTime": "00:35:05",
    "text": "in other words okay hello everyone I\u0027m Adam I\u0027m a teacher student at the recompile tech and I will present you my work which relies on the service chaining and I will show you how you can rely on existing networking to agents to a builder in network function chain so in network in network computation enable you will have nodes which in addition to basic forwarding and holding a function would have also other functions or running on top of n which can be a milder middleboxes in sync running on the comedy\u0027s server or some application functions of ready to a later plane but in any case you will need to be to orchestrate your network to be sure but the set of functions are placed on on your networking make sure that were wide data flow goes through a wide set of functions to perform more complex functions so in the service functional training is achieved with some central control point color orchestrate is called an Orchestrator which has a some limitation since it builds a single point of failure in the networks as some scalability issue and it sadly in our world with legacy device however trainings such a function is mainly routine problems we need to show that a frou-frou set of wage point before reaching with the destinations and we and we believe that we should be at the network layer and we propose to augment classical internet for protocol to make it functional so instead of having some centralized control point which make you manage every flow in your networks and your functions we propose to instead of autonomous nodes which asked network functions and also have a distributed intelligence to traffic for a channel or functions and to choose two instances or they are till event so I will fulfill my no negative cultural works you have some gateways which are attached on which some networks are attached by a extension and some information and based on that they build a network view we\u0027ve we\u0027ve and we visit neutral shoe they are built routing tables what we propose is that we can bind specific products to each tag to each type of functions through to make sure that the Vinod\u0027s "
  },
  {
    "startTime": "00:38:05",
    "text": "know where functions are allocated moreover if you use some any case a dressings you you are able to match not not only a prefix to say go functions but also to map to introduce a GP matrix to state function instance given that the flow has to go through so instead if you if you look at a Vista project you have two pink functions for running on trees in the front on two different nodes and if you look at the topological view of the IGP you have only one nodes and each instance of this specific function is represented by orange and attached to this links you can you can attach any metrics that show you you need to through the whites in San Cisco can be seen CPUs or memory use or time it\u0027s it\u0027s takes to process packets and based on that you you will be able to build the chain of functions for instance you if you you take these networks with some classical hotels running whichever for the wrong one and some some hotels which also functions this this mounted rotors which we comes anyway rotors will announce specific traffic\u0027s for any function fails for instance if you consider that your yellow functions is an IDs and pink one is a firewalls you will have extended view which is on white and based on that you will be able to hood first first flow which is for white which is the red one to make sure that he goes through the ideas and then the firewalls and if you you base your matrix for instance on the CPUs perceptive use of EITS freeways and if a second for wives it will be able to through the second second second instance making is some not balancing between the different function instance so we have built an architecture to for our organization nodes which we call an elevator so you have a control part which is distributing manual on the white and which receive a higher level policy such as the mapping of specific functions ribbon and gas prefix and which will constantly monitor both from the function is asked and based on bats will compute the matrices annals on a GP to to make behavior over Hooters aware but of the functions and what is its from user control a logical path will "
  },
  {
    "startTime": "00:41:05",
    "text": "take when the floating an algorithm will take the or Monti view shadow on the on jgp use the bathroom stand the bathroom Station algorithm and build functions service table which will map the location of the other functions and push it through over connector which is a path which will link the IP networks and the anvil functions and based on the the no caps relations we which I what we have used which is an SH which have been normalized at yet yet you will be able to map the next function to through which we\u0027ve got a bill okay occasions your packet as to earth so we make a simple implementation of these photos of the virtual network functions are simply functions in in network namespace we build our connector which before to make it became we didn\u0027t choose up an open the switch because it didn\u0027t have a stateful memory so we use people to to implement our connector to make sure that each flow will be processed by by the same by the same instance we make floating and not packet based routines and we use the an open source stack which is a routing as a for our water which want to west PF so we have make some made some I large-scale experiments with this implementation we package our anabolic state containers and we emulated 8787 not to topologies which is the top rod nicely infertility we make by working full project and on top on top of it approaches we deployed 10 virtual and network functions and we ask and we configure on our network to make sure that those first function which is were a yellow one and the second which would be I think if there is a fiber instant instance of each of each type of network functions and routing proper receiver is the shortest path and each and the virus takes about a by uprooting the decision and what we show is that based on the link stated participant update frequency we are able to have a stable balancing on the different vnf instances running on our unavailable so what we indeed achieve is "
  },
  {
    "startTime": "00:44:09",
    "text": "that we have a free distributed a framework to change in network functions which is not only interoperable with current voting system and which brings resilience in scalability since jgpz feel proven portable and we achieved through a balance the load among the validity from the edge from the network function instance and we don\u0027t have to add any configuration when we add a new virtual network function instance since when you another would have chose to to start a new instance you just have to announce the anycast prefix related to this event after that since it doesn\u0027t instance a kid to make routing system aware of the new host for simple networks and in future work we would like to see if we can extend our proposal to inter domain service project in provisioning using pi ability and to study the different metrics which could be used to take routing decision for for virtual service functions moreover or some some classical IDP madness and failure techniques code could be applied to our storage solutions and what the next step of our works will be to a check if based on the augments topology we build of another Hooters would be able to take autonomous decision to choose to start or stop and in instances in an instance based on a lot of the networks so if you have any question Just Answer okay so I was surprised to see us be atheist here mixing preach ability in policies in the world possibility in general the reasonably stable work called BGP furnace age that\u0027s progressing in best working group in ATF and it has BGP has built-in constructor router get important expert to impose policies so it would have been much easier to implement and inter-domain would work just as if there\u0027s maybe something to consider okay thanks doc Montgomery do you have the ability to choose your rel based upon the the overall complete service chain as opposed to my criminal series what we have done for now is to take a bio decision you\u0027re on English otters Babar golem nonetheless if you have the "
  },
  {
    "startTime": "00:47:09",
    "text": "Augmented view you can use in my opinion any a path computation algorithm to take more complex decision if needed and you could also instead of make up by outputting makes forceful thing using for instance as a services to serve a six to do that this will be our last question developers would you mention this vnf prohibition maybe see in general castration I guess in the life cycle or no how do you control the life cycle one associated with the routing for now on we have weakened still new business or functions which have started and we do not deal with the life cycle static so you mentioned is about balancing is for after ignition yeah but if you start we have a in our first paper we have made some experiment for all balancing scenario where you have a instance true visceral natural function learned at first and we do choose to start off a third one to change the balance between this one little function instances so it is possible to to modify the traffic engineering doing doing that to make the decision to scale out introduces another question how this was propagated through the routing updates okay thanks [Applause] yeah yeah I guess yeah [Music] "
  },
  {
    "startTime": "00:50:09",
    "text": "okay so hello my name is Ike I\u0027m here to present our draft on the industrial use cases what you will sometimes see behind me okay so what you\u0027ll see here that\u0027s actually what we are working on right now with mechanical engineers in Adam so the industrial Internet of Things as you can see there are quite a lot of different robots working a lot of sensors measuring something and everything is now more and more connected and what the mechanical engineers tell us is that they want to essentially move all the data that they collect there in to etch or remote clouds and they will also want to control the different robots also from flaut and yeah essentially as a third aspect all the data that they moved to the cloud they want to use that and actually throw machine learning and data mining on it to later it\u0027s used to find out how they can improve the production environment and then feed that information back into the system to make it better and based on these three aspects that we\u0027ve seen here we\u0027ve then taking a look at how we can improve that with in network computing and you can see here the general abstraction from the previous figure namely that we have sensors that we have actuators on the on the left-hand side so one end of the of the communication there on the right side you see the edge clouds and the remote clouds which will then be of the other end of the communication and in the middle we have the the network and what we now propose is that we could place certain functions within the network - yeah complement their use cases that they want to achieve and they\u0027re Klaus isn\u0027t so close as presented in Prague and there we have proposed two of them already so network control and traffic filters and now also proposing data stream processing as well as dust really safe T aspects so as these two use cases were already presented in Prague I only go shortly over them so network control the general idea is that the different robots are now controlled from edge or from an edge or a remote cloud and they here the problem is that the latency that isn\u0027t used by the network is too high so that the control loop cannot really be working anymore and what we now want to do is we want to put simplified versions of the control algorithms already within the network so that there can be short answers maybe two to signify it to the actuators that everything is working okay and so that everything is still working on the other hand we have traffic filters so as more "
  },
  {
    "startTime": "00:53:10",
    "text": "and more sensors data is there the amount of traffic that needs to be pushed into the cloud is getting larger and larger but a lot of sensors cannot really be configured well so there might be redundancy in them and so on that all the data might be necessary to push to the cloud and we won\u0027t simply want to filter out under set unnecessary data already then within Network to reduce the load on the network a third aspect then which is actually quite similar to traffic filtering and in product we presented them as one data stream pre-processing so the different sensor values that are pushed into into the cloud are oftentimes then simply combined to form new values and then the mechanical engineers want to only only want to store those combined values and if we now can achieve these this combination already within the network we wouldn\u0027t need to push all the data into the into the cloud but only the combined values so this would then again reduce the amount of data that needs to be pushed to the cloud and then as a fourth aspect we think about complementing the current safety measures that are there in the production so typically you have like laser barriers so that machines stop when someone goes through them but now the nowadays the production environment gets more and more dynamic so that even production or working stations move around in the in the in the production hall so that it\u0027s now not that easy to build hardware solutions for that and we now propose to complement that by utilizing data that is already being sent to the cloud for example a camera data and we could for example identify if to camp with one camera sees the robot moving in this direction and the other camera sees a robot moving and that a human moving in the other direction and maybe identify a collision course that then the robot could be signal that it should stop so in the draft we then proposed quite a lot of research questions for all the for different use cases and I\u0027ve tried to condense them here into two categories the first one is the design and development of the network functions that we want to do so here the question is how we can account for the limited computational capabilities of the network devices so we cannot solve for example in the control scenario you typically have quite complex control loops and control algorithms and so it\u0027s the building these simplified versions of them might introduce some science some sort of inaccuracy and we have to account for that as well "
  },
  {
    "startTime": "00:56:10",
    "text": "and then is the second aspect so now we can build them the different network functions it might be a good idea to find out how we can for example provide basic building blocks for the functions so that they can then be easier combined or our new network cars can be built easier the second big point is then the operation and the deployment of the network functions so now we have the functions but how do we place them where do we place them and how do we coordinate them so for example if we have two functions in the network and we replace the first one how does that affect the second one for example and the second aspect we done also see that the these Network pressures will certainly affect the the functions that are then from computed at the applications in the end and here we have to yeah consider how this will then how we can define the interaction between the in the network parts and the applications so what is then next for us we plan on updating this in our use case draft and then we especially want to do another draft or we plan on doing another draft on transport protocol issues so this was done basically what I stated last on the slide before so the interaction between the end host and the network function in the middle because if we simply come for example combine the two to sensoric values into a third one and then only only one only one packets packet still survives maybe this violates kind of D and 2n principle and we want to yeah we wanna elaborate on what we think might be the problems here and we wanna yeah find out what we can do about that or what essential requirements for such a protocol would be but I want to I want to yeah say that we we don\u0027t plan on designing protocol here we simply wanna elaborate on the challenges that we have there and if you\u0027re also interested in that we are very looking forward to a collaboration this is regard and yeah so then contact mute thank you are there any questions I actually have one without my chair um actually I\u0027ve got in the Hat uh I I think there\u0027s a lot of very good opportunities in what you mentioned but I read the draft also I think what is missing is making a strong differentiation of what is "
  },
  {
    "startTime": "00:59:14",
    "text": "already existing in automated industrial environments which as you know a pretty advanced and what you\u0027re bringing with this architecture and I don\u0027t think it\u0027s clear in the in the draft and I don\u0027t think it\u0027s clear in the presentation either because if I look at this with a very cynical hat on oh so you know they already do that in highly automated production but I actually know from other stuff that there are new cases and they are places in industrial environments where this type of work that your suggestion has a lot of work of room so I would suggest that in the next version of your draft that you clearly identify what is the difference between what your suggestion and what is currently happening in automation yeah thanks that\u0027s a nice suggestion we will definitely think about that I have you read reviewed existing transport protocols is anything missing why do you need additional drop but me thinking current variety of transfer protocols sorry I didn\u0027t get that from the acoustics could you repeat it please your next step if draft um Transfer Protocol yeah do you need something new is there anything you think in existing transfer protocols so what I basically meant with that is this violation of the internet principles so typically so we don\u0027t think that it will work with the existing protocols or at least not out of the box for so that we so the end host somehow have to know that someone in the middle is interfering with what they are doing and this is actually what I meant with with this draft on the transfer protocol sometimes like mqp like protocols that\u0027s usually since kind of environments sorry I\u0027m QP so you know there\u0027s a broker in between it\u0027s not in current I didn\u0027t get that either okay thank you okay alright alright alright so it\u0027s okay no hear me okay so I\u0027m Jen Jen Jen I\u0027m an assistant professor University of Chicago this is actually the first time I\u0027m in a RTF and it\u0027s very happy to be here to share my research and hopefully at the end I get to connect my research to the agenda of coin artery so if I mean unless you live "
  },
  {
    "startTime": "01:02:14",
    "text": "in like another Rock you know that video analytics is everywhere right from public transportation to public safety everything and but the real research challenge in terms of networking and systems is how do you network system to support the video analytics as such massive scale and let\u0027s first look at some trend here all right so first of all did there are two trends in video analytics one and these neural network models are getting more and more accurate at the cost of more and more computing resource okay so it\u0027s getting more and more expensive to run these models and second there\u0027s just a lot more cameras so these two trends are kind of firm as have led to this dramatic growth of the cost in video analytics okay now just to put that into perspective this is not just about compute storage it\u0027s also about networking okay now to put that into perspective think about video streaming internet streaming videos like Netflix or YouTube right these are the kind of application that can\u0027t account for 80% of the internet traffic to consumers now imagine all the network systems these days like CDNs or cloud they are all built around these traditional applications now the fact is these I mean at least surveillance cameras videos have already exceed the traffic of Internet video in that streaming video and the fact that these cameras I mean analyzing one camera feed is way more expensive than just streaming one ok so that means there is the current net in the today\u0027s internet systems is way less than was needed to analyze all these video feeds ok so clearly there\u0027s something needed to increase the accuracy of these analytics with low cost and do so in a way that can scale to the sheer number of cameras and video feeds ok now just to give you a sense of what video analytics systems not like you have a camera capturing video and the video can be analyzed locally or can be sent to the server for analytics ok so naturally you can imagine there\u0027s that kind of edge to cloud continuous a continuum where the high resolution videos will be analyzed locally ok and then only the part of the video that needs further investigation will be sent upstream to some more complex model typically running on a cluster ok and then it would do some future further futuring and the remaining video would be only the remaining video will be sent back upstream to a very complex model in the cloud ok so now so far all I have to talk about is very similar to everything "
  },
  {
    "startTime": "01:05:14",
    "text": "you you have singing edge computing right but there are actually two unique properties of video analytics the first property is that the video pipelines must be very adaptive to the real-time video content now you know just what that means is when the video content changed over time right the resource demand for this video analysis pipelines which will vary dramatically over time as well that makes resource provisioning very challenging ok so let\u0027s just recap the challenge of video analytics is to balance accuracy and cost ok so trial work on me all work these days have been trying to do is to and I\u0027ll customize the video pipeline to the video content so why why this is possible well imagine this is one of the like very typical video analysis pipelines out there right and there are not a lot of knobs control configuration knobs that you can tune so the video in the frames of a video gets fed into this module in am you know that resizes the video and then select which frames to sample and then it will get in fed into this neural network object detection software okay so you can see there bunch of knobs you can choose right so you can change the resolution the framerate and even which neural network object data model to use okay so so people have been trying to exploiting this color for these knobs to customize the pipeline to the video content now I was just informed that this this video is not gonna play so I\u0027m gonna just ask you to imagine what\u0027s gonna happen here so let\u0027s say this is actually two same video on the left hand side you see these bounding boxes these are boxes detected cars detected by the neural network and if I play the video you will see these cars gonna be staying staying staying put I mean they are stopping there and so if you use low framerate on the Left versus high frame rate on the right their accuracy will be pretty similar okay so when the objects are pretty static low framerate operation would be in it will be enough it\u0027s not much going on but if you if I were to click the play button again right you will see there are cars moving into the picture and running in high speed and if you if you have objects moving at high speed the low framerate will give very low accuracy because they were not it will lose track of these objects okay so what it means is I mean that gives us or a key insight that is the video analytics pipeline must be customized to the video content the real-time video content so basic as the video content varies over time like for example speed changes the best configuration will vary over time as well now this is not just about framerate I just used I\u0027m just using framerate as one example resolution and the underlying neural network Lassa fire "
  },
  {
    "startTime": "01:08:16",
    "text": "should also be changed depending on how and how frequent the content changes now all prior work has been doing is like one like so-called one-time profiling they profile the video at up front and then stick to the configuration they think is the best through the remaining of the video what we\u0027re proposing in this recent work is try to try to to argue that instead of just using one configuration that seems to be good we should adapt the video pipeline ok over time to the dynamic video content ok so this is the new idea we we studied this idea in in a recent paper so what is main architectural eh okay so what it may is you\u0027re gonna have this controller in the middle that\u0027s basically sitting in this continuous loop right it will periodically update periodically prefer a profile the video and update the control knobs you use like what frame rate or what model you should use okay and you\u0027re gonna run this continuously so I\u0027m gonna skip a lot of details here but the the option is you can kind of achieve a lot of resource saving or a lot of accuracy improvement right so this is like one traffic video data set and you can see on this the blue ones are profiling just once upfront okay you don\u0027t change the configuration and red ones is the proposed method you\u0027re continuously reprofiling and updating the configuration and it may just be able to claim this right like higher accuracy at the same cost or you can achieve the same cost at a very small fraction of the other scene accuracy it is at a very small fraction of the computing cost okay now this is just research but what what it tells us is even this is good news this actually make the resource allocation very challenging right because now whenever the content changes you have to change your resource allocation and this is actually the plot of the resource demand of the system over time okay and you can see the resource consumption kind of changes by 5 to 20 X even just in a few seconds just because the content changes rapidly right and this basically raises the challenge how do you actually do resource allocation in our computing right to cope with this kind of a spiky workload okay so that\u0027s one takeaway from the first part of research now for the remaining couple minutes that would be just briefly talk about the second unique challenge unique property of video analytics oh yes exactly ok so what that means is ok so let\u0027s imagine again you have a network connecting a camera and a cloud and the camera doesn\u0027t have local resource to process the video typically right so the video has to be streamed out to the "
  },
  {
    "startTime": "01:11:16",
    "text": "server now what what traditionally what people do is they can look at the video and just compress it to some quality level and then send the video back to the server this has two problems either you set your encoded video into low quality it loose accuracy you can\u0027t see anything it or you\u0027re sending high quality it\u0027s good to for accuracy but you may not have enough bandwidth to send it right now the fundamental reason for this actually is because this product I mean the traditional video streaming protocol makes sense to not to use the feedback from the user because for traditional video the users are actually human being right you can ask them to give you experience feedback but in video analytics actually you can because the consumer the user here actually logic they send an algorithm right it can actually pull some feedback from it and this is what we do I mean this is what we\u0027re trying to do and this animation messed up but what\u0027s basically happening here is you can kind of just send a very low quality threat version of the video to the server and the server will run some analytics to give hint to recline what it actually needs right real-time paint so that\u0027s another one but that\u0027s kind of a new way to do this video streaming for video analytics okay and this can actually save a lot of bandwidth but still achieve the same high accuracy okay so the takeaway from this talk just to take away from this talk one is that the pipeline the video pipeline must be adaptive to the real-time video content okay and that means whenever the content changes right the resource demand may vary as well and that will cause some very spiky workload and whatever in network resource allocation on network allocation resource allocation mechanism we\u0027re proposing must be able to cope with that okay and a second because we\u0027re dealing with this video analytics is dealing with some algorithm as the final consumer of the system right you can actually leverage some of this real-time feedback from it and this actually opens up new opportunities to bring the goals of these data analytics to the resource allocation control loop okay and thank you ready for castle okay [Applause] any question so I guess I\u0027d love for you to elaborate on what you what you imagine it would entail to bring the analytics goals to the control loop do you see that there is metadata specific to these kinds of Cascades they could be exposed and then you know what do you can you say more given that you\u0027re the very expert yeah good question so the "
  },
  {
    "startTime": "01:14:16",
    "text": "question is how you if you want an average the server or the analytics logic feedback right so it will be better to have kind of standardized version of metadata to to generalize what I mean I mean most kind of feedback you would be used that they\u0027ll be useful so I think that this is very much in the early stage of research that has been several papers along this line one thing that\u0027s really interesting is so-called you make some assumptions about what the Khan tenth or the video I mean the dynamics of video would look like so basically you you let the server see something okay and the server will tell you okay so it\u0027s this anomaly in me is this usual or not if it\u0027s very unusual right so it will ask you for more information so for example if it looks that looking at very low quality video it sees these objects this just appears once and disappear all of a sudden that doesn\u0027t make a lot of sense right so that\u0027s kind of anomaly is one thing that\u0027s really standout in across several papers I\u0027m just trying to really generalize that I mean obviously they have very different mechanisms to solve that but anomaly in the thing the result is one interesting result interesting sink you look at the other thing is so-called confidence so confidence as in so this neural network usually have some scores attached to each each detection and scores being high means it\u0027s very confident that this is actually a thing if it\u0027s low that means this McClure it doesn\u0027t mean anything but you can treat it as it\u0027s not being very confident okay so that score is one thing also useful as a feedback for you to pull more you use well information from their mean for more lunch do you know if it changed a lot as a bit rate or is going to be much more variable or do you still have a pipeline with a constant before uses the bit rate will be changing a lot versus pretty stable okay right yes so like I said it\u0027s very content dependent if you have a big objects in the middle in a self-driving car if your car is staying in front of you low resolution enough do you have some figure but definitely not at a scale of like to Megan two orders of magnitude it\u0027s usually whizzing one order of magnitude okay so so like if you if you talk about video you\u0027re changing resolution and QP rice qualitative quantization parameter or that\u0027s usually a wasting a range of certain value I mean low and high didn\u0027t what won\u0027t have a difference of more than 10x now that has a reason that has an actual underlying reason that it\u0027s because the neural network these days assumes certain input size so even if "
  },
  {
    "startTime": "01:17:18",
    "text": "you give a very very high resolution video it will resize into something smaller as well so so I\u0027m just saying the magnitude of resolution changing that I\u0027m seeing is not really the full scale of variance that you will be seeing if you have better neural network does that make another question does it reduce the number of steps or tasks in the cloud to edge path steps as accessible you you were describing that the currently there are a lot of different steps to to to to extract analytics do you have an idea about the number of steps is going to decrease yeah that\u0027s a good question I think most of the working this space is not trying to figure out the optimal number of layers between the camera and the cloud they\u0027re trying to say if you have this number of layers how do I layout I mean how do i spread analytics across these layers I think that\u0027s actually a real good question for from this print this group specific perspective to investigate could you put up the spiky little graph again so I\u0027m trying to read the the x-axis is kind of compressed so how many how much time is between the bottom and and and any given peak is that seconds tenths of seconds I guys I can\u0027t really see this yeah well let me let me sort of you really get to the question I want to ask how many RT T\u0027s do I have before I see the spike before I know that that\u0027s why is big so this is me at the scale or me at the scale time scale of seconds the grandeur of this granularity of seconds so I think if you look if you\u0027re talking about network with RT teals sub-second RT t right you in theory you can catch that right I\u0027m trying to get stars how can I catch that and get the resource allocation done right right but but but I\u0027m just saying in Syria can catch that right right up front but you do need several iterations to look like really coverage and after that I mean resource allocation is not free right so it\u0027s not instantaneous so you kind of need to take that into a country maybe that\u0027s x-ray was taking most of the time and then given that edge resources are constrained not just in compute but in memory yes the question is can I buffer enough of this peak so that oh I can keep the data long enough till I can get the resource allocated yeah I think you\u0027re right way I said memories the bottom there because usually this newer network is what\u0027s consuming most of the most of the memory I think if you just want to buffer the "
  },
  {
    "startTime": "01:20:19",
    "text": "video before it\u0027s actually analyzed yes yes thank you you should be able to buffer those you\u0027re saying it the the size of the video is small compared to the size of the model yes yes actually yes okay well well then hmm the interesting question is do you need the model everywhere and can you get the model in right yeah that\u0027s an X if you don\u0027t have the model I guess the memory would be the bottleneck for buffering the video but I think these cameras usually have pretty large storage and buffering super thank you okay last question oh yes did you consider how state your name oh yes sure on UNIX are um do you consider how urgent is it to understand what the camera sees like if it\u0027s really urgent then the neural network should be on the camera and then if it doesn\u0027t understand then only frames on demand frames not the whole video cuz yeah it\u0027s too much so so I think you\u0027re you\u0027re definitely right they are too extreme of the system of the little too extreme for shelves of views right so you can have like self-driving cars where you do have a lot of resource Amir it\u0027s a car right and and and everything is very must be very super real-time alright so in those kind of situation you do want everything local versus if you have a bunch of surveillance cameras or a camera network where you have like thousands of cameras cheaper want cheap much cheaper than the one you are you have on self-driving cars and then in those kind of situations you need to have a back-end Network system to analyze the data and but actually you\u0027re right in those cases we are most people are assuming they are not urgent as urgent I mean as real-time as self-driving cars so they can tolerate certain level of delay yes okay so but but you\u0027re a maybe in the worst case of I mean the worst version of most words right you have a lot of cameras cheap ones and you need super real-time reaction that\u0027s the kind of holy grail of this kind of systems there has to be layering because the car itself is always going to have some kind of mutation versus so but what you can consider is a neural net on the on the camera if it\u0027s a movie camera cannot expect what\u0027s going to happen somebody may jump the kid the ball and then in the edge if you need sub ten millisecond and then in the cloud if you need something that\u0027s that\u0027s really yes there\u0027s a kind of hierarchy of delays you can tolerate if you want to go further layer up from yeah thank you I think you\u0027re the one who controls the "
  },
  {
    "startTime": "01:23:20",
    "text": "the microphone okay yeah maybe you will say can you hear me okay we hear you great very good okay do I see do I control okay very good okay so let\u0027s start so my name is Jesper Eric stone and I\u0027m a VP of Product Management the co-founder of of Nova flow and and I have logged on to this session using Marc Leclerc registration credentials he is a dear colleague of mine me pure marketing strategy and also co-founder and to do this I had to promise him not to use any course language or get him into any trouble whatsoever so you see Marc but it\u0027s really just for Erikson so on the first slide the this presentation is really about the evolution of STM from OpenFlow to p4 and people run time and the slide that you\u0027re looking at right now is just an introductory slide you know Nova flow as a company we were founded in 2012 as a pure Sdn company we really at least our first commercial open flow one two three switch in second quarter 2013 and our core technology is is really this programmable match action pipeline using Mellanox MP use and also barefoot Tofino the key verticals that we operate in and where our technology is used is cyber security different types of gateways and then also on-demand bandwidth solutions in in Wham\u0027s and broadband access so please change so what is a match action pipeline well so the match action pipeline resides in the switch silicon inside a switch or router and it\u0027s really the embedment embodiment of the rules by which we want to process the packet as it goes through the switch and in most switches you\u0027ll find a fixed a sink and that\u0027s really what you see on the left and an in a fixed executes a fixed set of mass action tables defined in there in the silicon the size of these tables is fixed what the fields that you can match on is predefined and the actions that you take in the table in that particular table is also fixed and then you know as an application programmer trying to use this in an SDM context you know I would have to try and "
  },
  {
    "startTime": "01:26:22",
    "text": "map my application into this fixed max match action pipeline so it\u0027s really a bottom what we call a bottoms up programming paradigm you have to see what\u0027s in the silicon and that really drives what you can do with your application and then on the right you see a programmable silicon and here there\u0027s no prior set of mass action tables defined in the silicon and the application programmer creates the pipeline to specifically meet the needs of the application you know the the programmer from from scratch says I need this many tables this is the size of the various size of the tables the types of the tables and then what match fields and actions I want to use in each table and it really allows the programmer and the application to drive the packet processing pipeline in the in the silicon ok next slide please so who cares you know what why is this important and and well in in our view you know this program will match action pipeline enables the following thing the first one is faster introduction of new network functionality in protocols and you know there\u0027s an endless list of of this I mentioned a couple here you know ipv6 i AMSO v6 essentially any new protocol that\u0027s introduced unless the silicon is programmable you have to wait for the next generation of silicon to to be able to introduce that functionality it also allows you to do fast prototyping of new capabilities because the the functionality software-defined another key point is that this allows in this aggregation of network hardware and software that the hardware looks more like a server and then can be sourced differently you know and and then this software is really what defines what the functionality is and then the third bullet here is features are defined in the software and not in the hardware and what what that drives is there\u0027s really no forced obsolescence of the networking equipment as you can upgrade the functionality through software and over time you can also repurpose the network equipment by changing the software more like a server so that yeah and then we go to the open flow starting with the open flow match action pipeline so it "
  },
  {
    "startTime": "01:29:22",
    "text": "and this is like one two three one before it cetera and it allows you to define any number of tables or steps and in any one of these tables you can match on any combination of a predefined set of matched fields and then operate on the packets using any of a predefined set of instructions and actions so it has a lot of freedom the programmer can say I want two tables I want to match on this in the first table I want to match on this in the second table I want to highlight the metadata field as an interesting feature in open flow and and also in p4 it allows you to bring the result from one table to the next and match on it it\u0027s like it carried forward variable and and we have a one customer that that\u0027s using this to progressively build the result and in a number of tables and then in the last table match on the overall result or what happened in there or what the pipeline calculated it makes like this so here you see a real implementation of a true open flow switch and and the purpose of this slide is really to illustrate what a true open flow switch looks like and and switch that\u0027s compliant with you know open flow 1.4 and it may give you some ideas of what you can do with with open flow and from a network computing perspective and and what it shows is it defines let me see them it\u0027s hard to read here yeah so it it allows the programmer to to you know create a pipeline with up to 41 different match fields as defined in open flow one before up to six instructions and and up to 56 actions and inactions include the ability to change the value in any match field and you can put any match field in actions instructions in any in any table and the tables may be a wild card table where you have don\u0027t care bits in the in the match field or an exact match table and and then each table the width or the number of matched fields that is defined by the programmer and the number of rows it\u0027s also defined by the programmer so a "
  },
  {
    "startTime": "01:32:24",
    "text": "good example here is the Novi flow implementation where you have up to 1 million flow entries in at ECAM in up to 60 different tables and then in the exact match use case you have up to 6 million rows or flow entries in up to 60 tables so the programmer can really application program you can really put together that the pipeline using these primitives that then supports the application yep move on to the next one which is the the P for the the P for and P for runtime match action pipeline so so notice what we\u0027ve been working with P for for about two years we released our first commercial product in May 2018 this was a switch nos that allowed you to use the barefoot Tofino switch as an open flow one death v switch we essentially wrapped open flow around p4 and allowed the user to create and run an open flow pipeline on it to FINA white box so basically we the user saw an open flow switch but internally in the nas we map that into p4 code that get compiled and push into the silicon so that was like the first step mmm so when you look at the P for P for runtime match action pipeline the P for part is the programming language that is used to define how a switch Silicon process to packets you can define the parser which is you know what kind of match fields you\u0027re going to get you can program the actions know what am I going to do and then I can program and define a match action pipeline tables in a match action pipeline and then the p4 runtime is really the interface from an external p4 controller or internal people controller to to access and and program this match action pipeline you know add flow entries or initially what what you do first is you load the compiled p4 program then you can add delete flow entries in the match action tables you can collect statistics so the p f-- p4 runtime is really the comparison to open flow from from a networking perspective well while i\u0027m talking your slides are copyright i saw "
  },
  {
    "startTime": "01:35:25",
    "text": "that when you started that means I will have to take them out of our repository is that ok with you because we don\u0027t have it we cannot have copyrighted material ok so what I can do my Jose I could I could submit another one without the copyright let me check my bad yeah ok very good ok next slide please so this slide is really to illustrate the extent by which this the parser and and the the master action pipeline and the actions are defined in software so you basically define an Ethernet header an ipv4 header the tables you know what you match on what what the actions are and so it\u0027s a the software definition is driven all the way down to 2 to bare bones and then on so you have a header types parses tables actions metadata and then you have this thing called external objects so it allows you to create functions in your pipeline that will do operations like check some registers counters meters and also you know I any and the other thing you can think of so to move on next slide so comparing open flow and P for P for runtime both of them give you a programmable math section pipeline however P for P for runtime gives you additional freedoms as you can program the parser and also define your own actions in open flow you know you can do some of that through experimenter extensions where the developer could define new match feel some actions so next slide so here\u0027s a slide showing at the components of a Knauss and what we\u0027ve been talking about is the open flow and the p for runtime and and in that part but on top would add in in a typical notes you also have you know configuration management operations management security management and other extensibility is so and so that was really my presentation thank you so I have a question I have P for people multiple times and I\u0027m curious if you have potentially a more satisfying answer to this question which is I have two programmers each of which have written a p4 program and they don\u0027t know about each other what\u0027s the composition model for composing to p4 programs into one and what\u0027s the model for how those "
  },
  {
    "startTime": "01:38:27",
    "text": "two programs can be loaded into the same switch and what\u0027s the model for if I want to change the program of the switch without resetting the switch yeah it also are very good questions and I I\u0027m afraid I don\u0027t have the answers to that right now but I can follow up without the answer the answer is with the p4 people have no clue how to do this is more I don\u0027t have the answer so I can get back to you with with the answers on that yeah send that to the list that would be great and by the way for those who got here very late Jasper and France lent us two engineers that probably could have the answer to your question and so that was really great are there any other questions at the hackathon yes and the code you saw was similar to the stuff we did at the hackathon any other questions thank you so much Jasper yeah thanks yes thanks um good very good there\u0027s a thingy somewhere quite good think I\u0027m going to be timely and so this draft is submitted a couple of weeks ago as a result of ongoing work as well as proposed research a lot of the questions we are asking we have ideas of answers but real ones really and that\u0027s why we thought it might be a good idea to actually put this to the purse research group because we feel of that might be a good space for it the book is launching center around micro services that\u0027s what we\u0027re working in but we have a slant in the draft around what we call it abscent fig micro-services and the reason for that is is really to start from you know the app economy in the smartphone world and look at smartphones I have about 200 on my smartphone and and you know it has striven you know the development of mobile experience as we launch you know it we use applications around our smart on our smart devices the design is fairly static they\u0027re softer models they\u0027re packaged into an application you download them from of a store and you\u0027re done with there are extended client-server interactions you usually see within these apps but that\u0027s about it and what we want to move to mentally at least as a thought experiment and we have first demos on this is to mental model where we look at an app as a collection of micro services but you can decompose and start bouncing around in the network that\u0027s you know why we call apps so you decompose a nap into a set of micro services you execute them on one or more distributed resources that can be at the edge of the network and the cloud wherever they are and you interpret each of these computers as a "
  },
  {
    "startTime": "01:41:28",
    "text": "pico micro data center and that\u0027s how we turn a term they know the name App Center so we look we don\u0027t look at the data center we said well you just run micro apps on it right that\u0027s what comes from the use case we\u0027ve demonstrated and it\u0027s described in in the draft is mobile function are floating so it said this runs on standard Android we do Android because we just don\u0027t program iOS for reasons of resources really we wrap helper classes micro service helper classes around modules and this is done purely at design time so you have to do this at the moment at least we\u0027re also working on the runtime version does this automatically and the the the example that\u0027s described in the draft is you know very simple you receive an image you processed the image to do some very snapshot II kind of thingy and you display it\u0027s we micro services makes a lot of sense right and and now we interpret a given experience like watching that more video as a chain of micro services that you know perceive process this by and you\u0027re done words and when you run the actual application now which is still an application is being installed as an application from the actual Play Store and all these micro services run on your device it\u0027s just as it\u0027s as you used to because it\u0027s an app right but what you can do we\u0027ve done we wrote a small and software model that kills the modules on the it essentially kills the processes and what you see because they\u0027re micro services they bounce off the actual device and and run in the network as in network computing and in the trophy we describe a policy for using the actual ask you figure I should have probably used a better one and we realize that over an SD Sdn infrastructure the app if it runs it\u0027s a DPR on the top store stands for the modules you know despite process and receive you run them like that they run on on you know that\u0027s just the APIs you see everything runs on your mobile and we have a very simple control UI no intelligence in there the intelligence is yourself that that knocks them off and you kill for instance the processing the p1 of the the micro service and the chain is missing and it jumps onto a processing server in the network the processing is more capable so you can run different processing routines etc you kill the D and it runs onto it it jumps onto a smart TV which only implements the D function not the other ones because it doesn\u0027t do processing so you get distributed experiences really cute we ran this as a demo as a concept demo in February this year I said work to standard Android what we described in the draft is what are some of the technologies we you can do this all as a vertically integrated demo works perfectly the whole point about standards is to do this obviously in a way that it works not just for our demo but it works for everybody right so we outline certain areas in the draft that we feel work needs to be done some has to do with application packaging not entirely sure that\u0027s an ITF area but nonetheless describe that which is usually done at design time and what we do we defined wrapper classes we expose those we are in the process of injecting them into the open source community so they can be used you can also do "
  },
  {
    "startTime": "01:44:28",
    "text": "profiling to do this actually at runtime that\u0027s the real fun part so you have an application that hasn\u0027t been designed at the micro Service and it\u0027s being pulled apart into micro servers at runtime and then it starts bouncing about in the network that\u0027s actually quite cool we hope to demonstrate that in a couple of months time another various service deployment how does the P server makes it there I remember the one before so there was the processing server in the network we actually have done this by combining application installation with service orchestration when you install the app we are not using the actual Android application installer we do use but we have a an extended version which not only installs the application but it points out of the asset package of the application package a service orchestration template and pushes it into the netbook and says dude I need a processing server can you please install one for me right and the packages over there again there\u0027s a lot of standardization you you would need to do to make that work outside a vertically integrated demo and and the integration with the app installation model it\u0027s really quite cute because application users just see an application installation they don\u0027t really see a service deployment so that\u0027s one of the reason why we like that service routing I too talk about stuff bouncing about now obviously that requires that you have in place a service routing infrastructure is usually done as a combination of DNS and IP routing our bouncing about is relatively flexible so we use ongoing work in the SFC working group which is now going smooth the ISE route on so called named service function chaining as well as service routing over to environments but allows you to actually do this really flexibly so we have a couple of demos where you will see if you do this in a standard DNS plus IP system it won\u0027t be required work because the city is not there and we describe this issue in the traffic as well the Dynamis \u0027ti of in network computing in particular when you bounce functions around based and use interactions I walk into the room I suddenly want to go for my actual discipline and the mobile I want to jump onto the display in the room that\u0027s very very flexible and it requires solution for service routing that are probably different from the ones we know service pinning we describe that based on the use case if you have two resources that actually implement the same micro service how do I make sure I\u0027m actually using the one that I really want to use and think about the display it might matter an awful lot on which display you actually display stuff even though it\u0027s the same d micro service I really want to have that one though and have the other one and for various reasons the pinned relations can change very frequently your requirements your constrains change you know I might walk in a different room I do want to go use actually the other display so the pinning has to change frequently as well all right and how do I do this in a standardized manner that will allow me to do this and the last area that we describe the state\u0027s organization we do work with a mixture of stateless as well as stateful microservices state you can\u0027t enforce only one of them and "
  },
  {
    "startTime": "01:47:28",
    "text": "therefore state synchronization is very very crucial typical use cases that are very very stateful are in particular gaming use cases where you indeed need on good state civilization so these are the areas and I said we have a couple they are reference in the draft you can see to ongoing work that we also are currently doing the ITF and other working groups and not generally we try to keep those sections as these are cool areas to work on I think we need some work this in order to move into standardized environments and it would be good to have a place for this alright so the conclusion really is really trying to stick to my ten minutes is that the trapped positions in evolution and we tried to stick this to the app model because everybody knows that I should be played this story to particular people who don\u0027t really quite understand but an Internet really is with a sense of IP packets we played this to teenagers and they love this story alright by for them the internet or application installations so the whole idea that I install my private Internet by having an application is something that really goes done really well and and we also like the idea of moving from the mobile terminal experience as we know today everybody has a smartphone to something add in handy disintegrates into distributive experiences and that\u0027s the the reason why we made that leap but generally I feel obviously that the points also blight the general micro service use cases its itself I said we interpret available compute resources as these peak or micro data centers they can be dedicated computer resources in the demo we gave this year we played the scenario in a entertainment scenario hotel where the compute resource was provided by the hotel for hotel guests so in that case you might really have a computer act downstairs right but Pico data centers could be home devices it could be another user smartphone and be also actually in the use case jumped on somebody else\u0027s smartphone the smartphone was plugged in so therefore it was a suitable data center if it wasn\u0027t blocked in it wasn\u0027t chosen because you don\u0027t want to jump on somebody who runs on battery we believe that the post corner G would be a really really good platform to actually discuss some of these issues bring them together evaluate them but also obviously link to ongoing efforts a lot of these efforts are ongoing in other working groups and therefore bringing them together and probably also you know get more people involved in the discussion is a really really good thing some of the comments that I put on the list already related to that so there were a couple of things that I had sent to the list the next steps and personally I really hope that they propose research group is indeed approved we plan on doing is to update the draft with more information on the ongoing so be quite clear or what\u0027s going on as that they are references in but we haven\u0027t really described in detail but also provide an overview of other realizations because in the currently we are referring to a lot of things that we are involved in there\u0027s other things and also we plan on demonstrating realizations maybe at an upcoming meeting so people can see these funny "
  },
  {
    "startTime": "01:50:30",
    "text": "micro-services bouncing about thank you [Applause] one question so for the solutioning implementation what are the information units those functions actually operate on a good terminating some application so we saw the reference at behalf of the draft is to name service function training so we actually extend it I\u0027ll be proposed to extend service function change which we saw in the presentation before too on entire name basis so you issue a URL based requests rather than IP voice requests and the the service function as was presented in the service function training one before it\u0027s always associated with some form of control we don\u0027t use a manner control obviously our service function changing is defined in the application see the application in the application design you specify that micro chain of you know our PD it\u0027s a Ryan bear we\u0027re also looking at the frameworks that automates that and therefore essentially constructs for you an actual name service chain which is then translated internet such as nsh which and is pumped into the name service function actually receiving or sending so what is it is it a flow of packets or how does it work the so the the draft at the moment outlines the the packet is the actual HTTP request so it\u0027s known on key packet because is that the name yeah so so and HTTP at the moment is the example for a named extension thank you okay okay hello everyone this is polio from China mobile and I was talking about the new draft requirements of computing in the network so as we all know computing in network becomes a nutrient to meeting the needs of emerging business what needs to be computed and why there are several problems need to be considered such as the traditional network protocols only optimize traffic which can\u0027t guarantee the latency of packet loss rate and the centralization of computing resource is not efficient and for the different business there are they may need different kind of computing and they are little interaction among users of applications and the networks which means that they don\u0027t know each other\u0027s "
  },
  {
    "startTime": "01:53:30",
    "text": "requirement and the capabilities so some work has began to consider these issues but more comment words to be considered and the number one requirement is deterministic network abilities which include the latency and packet loss rate so for the latency it\u0027s the concept from in time to anthem which means the latency is not necessarily the lower the better it\u0027s just like to size agreement and Sacre Edition and for the packet loss rate it includes the time bearing routing which found the link time very regular based on AI and the predicting the network performance and there are also other technology such as segmented transmissions to enhance to achieve segmented retransmissions and the number two requirement is computing a well scheduling in this model commuting in sync as a link state and the convenient source information is exposed so cutting to the business required requests dynamic computing power matching is carried out based on network status and the performance of computing resource to achieve optimal user experience and network utilization and the number three requirement is a function based addressing and for the traditionally based addressing it might bring some problems and which come to current easy they such as the latency so in the new function based at addressing the application components destructed to on the server side are distributed under cloud platform and the business logic in the server is transferred to the client side and the kite only needs to care about a computing function itself so as to realize that they function as their service and the last requirement is network Brown who ability and so in network programming and the resource of network and the computing information can be transferred by network to users so L to the requirements of the information transmitted by user to network so the network can configure parameters according to the user users needs and the users transfer requirements based on network abilities which could efficiently support the future application so in the next steps more requirements might need to be analyzed considering the computing capability and some of like discussion about the related technologies may need "
  },
  {
    "startTime": "01:56:30",
    "text": "also need and thanks any other comments so actually this is just a little bit of historical stuff on it the original spec for is is had a per node cost of traversing that node which was called the hippity cost so your packers to go hop hippity hop hippity hop hippity hop and back then we took it out as a gratuitous complexity because there there wasn\u0027t much difference between the costs of forwarding a packet on one node versus another node it may be time to bring that back okay thank you very much so we have just a few more minutes so we intend to have a virtual interim probably in early October we\u0027ll do an email poll and we would like to address probably the last version of the Charter and hopefully a set of milestones I get the message from Dirk the first Dirk Dirk k about having milestone while you\u0027re still it proposed that proposed RG but we kind of like the idea of focusing the work we\u0027re obviously are going to meet at ITF 106 which will be our third meeting and hopefully we\u0027ll be accepted before that and thank you so very much for everybody who came and for all your support actually I think we\u0027re calling themselves the gems so that the Jeffrey Eve and I are really happy of how this is going and we really thank you for all your great work thank you "
  }
]