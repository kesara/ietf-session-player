[
  {
    "startTime": "00:00:07",
    "text": "So who's so whose alarm was that? I hope you brought enough alarms for everybody. Okay. It's it's half past. This is the computing the way a traffic steering working group cat I'm Adrian Farrell, My cochair, Phong Liu, is in China. and our working group secretary, Trung Lee, is also in China, and will do his best with minutes. Dan Kim is kindly volunteered to help with minutes. and he's also remote. So anybody who want to leap intohedoc and help with the minutes. That's great. Otherwise, we'll sort it all out possibly from the recording Okay. Over to you, Pong. Great. Thank you. So let's start the meeting. and good morning, everyone. Welcome to join the test meeting. in iotab117. And here's the North Wales. Just to remind that it will grade follow IETF process and policies. aware that any item contribution is covered. by patents or patent applications. You must disclose the effect or not participant in the discussion. And since we have started to adopt the WG document. Please keep that invite. and to the audio, video, and the photo graphic because of the meeting, maybe made, public and personal information that we provide to ICAT will be handled in accordance wins eye gap privacy, settlement. and please throw it back to others. The document list below"
  },
  {
    "startTime": "00:02:00",
    "text": "has more detailed information So the contact guidelines, please remember to show your respect and have personal discussions. diverse solutions for the global Internet, and be prepared to contribute to the ongoing working off the growth And we are using the mid echo queue control on the chat available for use via. The note will be ticked by somebody But as agent side, we encourage everyone to help with that and check your comments. Recognito Crossulate. So the meeting tips for the in person participants, please make sure to inside sign into the session using the meta echo and use it to join the MyQule. And for the remote participants, please keep in mind to make sure your audio and video off until it is in your turn to speak. And here's the deliverables and the mouse of course, all drafts are welcome. that to both of them in the this tracker and discuss them on the left. but our initial focus must be on our milestones. And for the milestone, we just have done to adopt the problem statement, use case, and require documents. and placed on where only the framework and the architecture are listed as going for offset. So here's the agenda, firstly, we will have discussion of the term terminology which is important for most of our draft And then we will have 2 slots for the problem statement and use cases."
  },
  {
    "startTime": "00:04:02",
    "text": "and and then have we have 3 quant drafts. and one framework and architecture dropped and we also have to sort for the compute metrics. And at the last, we have environmental considerations about the grain. So any comments on that? Okay. Let's go into the agenda first to the discussion of the terminology that face face Yeah. So This is a presentation actually to just To take forward, I'd say some feedback from the working group to around the, I would say, the the very terms, we are using the various documents here. This is really important. for us to think in which we are, I would say, meaning by the very terms because many of those are already overloaded. it will be really good for us at least today that we we can have some agreements on the perimeter of the terms. Next slide, please. So why we are doing this? Especially that there are many, I would ARC, that ROD, I would say, defining the sum of the term, the services, the solutions and so on. So we may just simply go in there here in cats. but duality is that tanks are subtotal. There are many specific aspects that are in in we are doing here in this working up and that there are work to be, I would say, code in the terms that we would be using. This is also important for another OCA for it because many, I would say, There's a lot of similarities with with with what is currently proposed by some documents with and other effort that are done in 88, but also outside. So there is"
  },
  {
    "startTime": "00:06:00",
    "text": "Having, I would say, a clear technology will help position in the this work also that we are doing in cats versus what is done elsewhere So this will also is the a telecollaboration and so the pushing of the various works, miss Lark, please. So this is just to purpose here is not to go to go deeper into the virus ARSES are there, but just to give you, it's an overview. That's why we cannot just record, already in the r x. It's there just to say that we refer to them. This is just one of of the hotel alerts. These individuals, I would say, good definition of the service 555555555 but this is really specific to a node what we are doing here in in cats is not no specific. It it is it is more than that. Next slide, please. The the the this the this other, I would say, if you of the service where you can find these RFCs. It's good. It's starting to be, you know, take exceeded from the node. It's will cover the network side, but still this is too network specific. And it does not cover, I would say, the some specifics that we are doing here in in gas. next slide, please. Yeah. So this one is really interesting because this is the first, I would say, RFC we had in TF, which is a knowledge that we have that that the notion of the service is really over low said. The the definition is there is really good, but still it is network specifics. So we need to have some flavors there to include the computing in in aspects of the of the definition on it. that's why the next slide The proposal we have for, I would say, the definition of a generic definition of the service that can be displayed in the next slide, please. It's based on what we have in the in in the previous RFC. So Basically, without getting into details, what what about, I would say, the internals of the service itself. So The proposal is that we we say that's the service is basically a no premises made by a service provider, autist writing various resources, We don't make any assumptions about these resources themselves. This can be computing, networking, s 2 name it."
  },
  {
    "startTime": "00:08:00",
    "text": "And then and then how these various resources are orchestrated in invoked and solicited is something which has belong to what we call the service logic. and this service logic is owned and mastered by the provider itself. and this is something which is internal to to to to the provider, and it is not supposed to be exposed outside. And the the the resources that are, I would say, solicited there in order to provide that service by the service provider they can be exposed by some analytic functions or some analytic processes that we here in the ATF, we call that service functions. They can be hosted within the same node, multiple nodes within the same service size, multiple sites, no assumption is there in the in the in this definition. And then, how the various resources, the aglutigator, or the in together to provide the service, This this magic is part of the service logic, and this can be done by various tools service functions is is is one of them. Next slide, please. So if we want the definition not to to to have this diff the the generic one to go to something which is really, I would say, related to what we are doing here the in the in cats, This is what we call the competing service. So this is exactly what I have in the previous slide. just we are filtering on the type of the resources. The resources that will be solicited to provide the service already computing resources. That means that the network part will be, I would say, visible. We will we will we will package that that service. And for the other items, The cat's architecture or the cat's solutions they must accumulate all these deployments the the the deployment scheme that are provided there with one caveat there that I would like to use to insist on it. is how these resources are changed is really something which is out of the scope of cats. So we are not here redoing what we have done already in this ESSC. The internal logic, once you you arrive to your service sites is something which is"
  },
  {
    "startTime": "00:10:01",
    "text": "Internet to that service site and not visible a outside. Next slide, please. So once we have this definition off, I would say, the service the the service the computing services, which is our concern, then there is this notion of the service instances. The so here again, we are proposing something which is really, I would say, generics so that we can try to have something to to build on it. We don't need to to have all the subtelties there, we we we propose this one. So what's a service instance? after all a service instance. is that the analysis of, I would say, a set of running resources that that are built according to a service logic that they have mentioned in the previous slides. So many of such instances can be arranged in in the, I would say, on on on on on by a provider. The instances that are there to the same service logic They are providing the same service. So a same service can be provided by by multi all multiple service instances. And these instances can be within the the same, maybe, say, service site. And on purpose, I am not calling this each site or core site or original site, we don't we don't care about that. All what we care about it is that we have a service a set of resources that are running somewhere, and that somewhere we call it the I would say the the service the service size. And the this the service instances They are important because this is the physical stuff, which is which invoke to provide and to honor a request that you issued by a client. So the request from the clients will be processed, and fall feed by by by the service instances themselves. by Dick Bat, Declined does not is not supposed to be aware that there are various service as density in in in this in in the network. So this is not important for the year for for the for the client. When and we are when I'm talking about the client, I'm talking about the software which is invoked in the service itself. So what does the the this piece of software is accuracy. Next slide, please."
  },
  {
    "startTime": "00:12:04",
    "text": "This is what we call the service content instance. So this is the first, I would say, which which is the customer facing. I would say, service function, that will intercept the the the service request. And how this service request will will be processed, whether it will stay internally with the the the service contact instance, SF, or passed to another other resources This is something which is part of this service logic. and cats, don't need to make an assumption about about, I would say, that that that process that's really heading to to to the clients, and this is not important for us. And the the other the other point here is that the same service can be accessed via multiple service contact instances itself. They can be within the same site, or they can be dispatched very among various various sites. And even that service contact instance, when it received the request, It may just dispatch the request again internally. that process that requires business is hidden to to the client itself, and this is something which is part of the, I would say, the server fail of the the provider itself. Next slide, please. So if you want to glue what I had mentioned about the service contact instances, with the what we are supposed to do her in cats is that the the theory beyond the service contact instance is not only hiding to the client itself, but also for the for the CAT's component. The cuts component should not make any assumptions what is done behind that that that point. And Just for people who want to like to have, I would say, some architectural references, we just the the the service contact instance is it what is served by at least 1 egress cats for word error. And, again, I am not trying to make clear any assumptions about the architecture, this is nothing we would be better, but this is just provide an example of how we can implement stuff. Next slide, please. So this this this is something which is this is not rocket science."
  },
  {
    "startTime": "00:14:01",
    "text": "just trivial to say that she had the same cats for border can service, I would say, multiple service contact instances, We can have 1 to 1. We can have multiple, I would say. forwarders that will access to the same service instance for diversity, reliability and so on, but it is just to provide you some I would say some deployment chain. Next slide, please. Yeah. So this this this is because we are using a computer aware in the in our in the name of the working group and also in charter. So this is just to to to provide something which is really simple without going to a further when we are talking about computer aware blah, that means that that that's that's the scheme we are talking about, it will take into account the computing, I would say, capabilities in the state to to as as an input to to to to to enforce the process. And that process can be the forwarding, can be steering, can be computing, and and name it. Next slide, please. So when it comes to cats, And we are we are talking about the stirring cuts is basically this is what I'm trying to to have, I would say, the global problem, we are trying to save in one in one sentence. is about selecting the appropriate service contact instance to, I would say, to to process a given service request according to a set of both network metrics, but also computing metrics. and and that selection, it does not reveal the actual service instance which is which is which is processing that request, Because, again, this will be hiding by the service contact itself itself that will receive that that request. And the metrics that will feed that that process of strategy, I would say, the the packet, They are aggregated. We won't be advertising the metric forever resources, which is invoked in in as part of the service incident s f. So we will have something which some aggregation somewhere there. So this is to be defined and also characterizing the various architecture solution we are we are doing."
  },
  {
    "startTime": "00:16:00",
    "text": "this is something which is really key here because otherwise, will have some implications in these scalability and also dynamically this solution we are we are providing. Next slide, please. Yeah. So so this is just to provide you an example of organization organization of all what we imagined so far. You can have multiple multiple clients. They are, I would say, seen in service request via what we call the the the cast overlay. differ orders that are in the borders, again, they are just provided as as example. am not sure that we need all these components. This is something which open for India in the architecture, and and they would like princest on this. And so and And then there are the requests will be, I would say, forwarded to the various service sites Again, there is no assumption about the distribution of the type of the services themselves and whether the same service is replicated in all the service sites of our given provider, So this is this is really up to the to to to the provider to decide where the it will it will instantiate the the service itself. What would it be visible there is that that component which is important for us the first entry point, declined face in satisfaction, is the service contact and instance itself. Just one mention is that the the links I'm sure in between the the Egress cats for WATER and the civil side, they are not direct this service contact itself. This is just a way of presenting stuff to simplify it. But those instances can be deeper in the service in the service site itself. Next slide, please. Yeah. So so so as a summary so the these are the key the the key term that we think that are important to to drive the work and also to scope what we are, I would say, we'll be doing here in the in the in the in the working group. The the the plan we we are proposing to the working group is that Once we agree on the the parameter on on these various terms, We will record in the in the in the framework. This is our proposal, and then"
  },
  {
    "startTime": "00:18:04",
    "text": "various terms can be referred to by the other, I would say, documents we have in the in in in the in the working group. So just one mention is that this is this is a proposal for discussion. Thanks so frozen and proposal are already wake up to to to to enhance this. So thank you, Ned, for for taking up the challenge to to put this together and and float it, and I suspect there will be quite a bit of discussion. Joel is 1st. Joel Halpern with Ericsson. Thank you, Meg. This really good document I have one knit. It's really a niche. Early on one of your definitions you refer to monolithic and I find every time I look at that, I have no way to know what that means, and I actually doesn't add anything to the definition, So my suggestion specifically is simply to remove that word from that definition. That's fine. Thank you. Thanks. and do it and do it and do it Thanks, Chong Lee. Hello? Can you hear me? Yep. Yeah. Jennifer, Molly. I I think this is a good start. Right? So after reading the a slide, I think this the definition of service and and and service instance is quite are quite clear to me, but the service contact instance is not so clear to me. because, for example, could Could we have a a a use case like that? we only have the service contact instance which is the service instance itself. then at this, I'm not really sure. Yeah. Yeah. Right? Actually Yeah. Actually, just covered by definition, you can have there's no assumption whether the The service request will terminate in that point. It or we it will be"
  },
  {
    "startTime": "00:20:04",
    "text": "I would say, hand it to to to some other resources. An example that I can just provide you with in the voice over IP, we have there what we call the service border controller, the PCCF if you want. that's diff the only point which is visible to your customers. Then the request we we we need to send from that, I would say, idea that that the this BC, for example, in the when you are placing a service voice over IP call, is is is not shown to you. It is bad to, I would say, more notes in in the current network. So that context point is is really the I would say The what what you will receive as a the i the IP address for the locator of your where your request would be would be forwarded to. But then there is no it's not because the request will terminate in that note that the request will stay there. there is some request requestiveness that will that will that will happen. depending on, I would say, on the service logic we are we are we are talking about. Okay. I will leave the time to others, and and and let's discuss this offline. Yep. Thank you. Thanks, Daniel. Then Guam ZTE, I've I'm The from the definition of service contact into instance. It seems It should be under the maintenance and management and scheduling under the cast network path. In reality, such as an l node balance, and they they in the DC Actually, it's not the case. side It's not under the control and the scheduling of that Altine Networks at the May So That's my first concern about in the service contact instance. And the second concern is about service service definition. The definition is clear for me. I I wondering if it's they're they're supposed to be"
  },
  {
    "startTime": "00:22:03",
    "text": "Unified in the standard definition about Service Nautic and and they'll and and and interface because it's just possible As possibilities, there's the service could be provided same service could be provided by and multiple operators Thank you. Just one one more clarification question. The first Yeah. comment, you mean I'm not sure to get the Actually, the concern you have with the with the service connect instance itself. Are you saying that's the load balance stuff should be part of the CAT's -- Yes. -- parameter. Yes. the service load balancing itself or just the way we will steer the request into that that that little bell service bell answer. I mean, I mean, the service contact instance such as such as the no no balance. LV, LB, actually, it's not under the It's not always in logging acting the main in a existing network. it's it's it's it's pleasing the the main hub at DC Network. So from the end to end and competing a world traffic steering. actually is I I suppose the service contact is should be in this within the same same same domain. Okay. Thank you. Jim, And everybody now has got maximum 2 minutes each. Go ahead, Jim. Jim. Jim? Yeah? Jim? Yeah. Yeah. You are. Sorry. I at Ken. I'm like, Ken? Who's Ken? So Jengiz from Future, speaking without any hats on. Really nice work, mate. Thank you so much for doing this. There were a couple of things that sprung to mind that I'd like you to consider One was I didn't see any kind of discussion about naming of services. I don't know if that's something that"
  },
  {
    "startTime": "00:24:00",
    "text": "I know we struggle with that in SFC, and it it seems to me that that would be kinda nice to you know, it It's great having all these service instances, but you need to be able to kind of associate them with some kind of name, and I'm not sure what your thoughts are on that. We'd You don't need to answer now. Mhmm. The other thing was It would be nice to see in the framework how this fits together, with other aspects of, you know, the overall service ecosystem. So, for example, you know, the consumers of this information. I know we're not chartered to do that, but you know, in the in the framework, like, for example, Alto how does Alto fitting to their city You know, how does a consumer actually instantiate what Katz is providing. So A little bit of work around that would be really useful. even if you can. Yep. Yep. Yep. that deck of gym. This is not present for example, the the service name is not presented here because is a little bit deviated to the framework stuff. and they tried really to not include the Acudecturals, by ease because I I would like to so that to to to be open. But, yeah, which is interesting to cover in the in in the framework itself. I remember as quickly as you can, please. Hi. This is Renan from InterDigital. Thanks for the really nice work. So I had a minor question regarding Slide number 6. So the question really is, are we talking of a set of resources or an abstraction of a set of resources. At the level of the service itself is is is really it doesn't matter the would say the physical association of the resources themselves. What is important is is is, I would say, the correct duration of this of their resources, so it can be abstract."
  },
  {
    "startTime": "00:26:00",
    "text": "But when it comes to the service instance itself, then to read the physical versus not to be, I would say, involved and in included in the in the discussion. Okay. So my minor suggestion in the first bullet is to replace offering. So instead of saying an offering, you could perhaps say an abstraction that is made available, etcetera. Yeah. Thanks. Thanks. Last up, Richard. If not, Matt, can you hear me? Yes. Sure. Sure. Okay. So a very quick question because we're talking about services And for someone who is following all these services, according on the computing field, you would email a thing about, for example, Kubernetes. Therefore, in Kubernetes, oftentimes, they don't have concept of contacting services, which is everything just service off over there in particular. they introduce some kind of ad, which is called pod. therefore, this specify every part must be located at a single host that will simplify a lot of concepts. So therefore, have you and here, of course, I think somehow to solve the issue in concept of contacting services and so on. And do you always have contact and services and so on? So why don't you, for example I mean, what one possibility is take the stance of, for example, like Kubernetes obstruction and I just say, okay. And the the instance is somehow required to be at a given no just like a pod, and then you build on top. Wouldn't that be a little bit even simpler. I can vector and terminology and also a little bit more aligned into you know, like a Kubernet structure. Yep. Yeah. Thank you. Thank you, Richard. That's that's a good comment to consider. Brilliant. Thank you. So there's there's obviously some more discussion to have on the list with this to to get the precise words that we were put in the framework document, but I think we've got a good start. Thank you, Mad."
  },
  {
    "startTime": "00:28:03",
    "text": "Alright, Kehan. There you are. Let me give you control of the sides. Thanks, agent. Hi. I'm Kean from China Mobile. I'll briefly introduce the first working group dropped, casts problem statement and use cases and requirements. And in my part, I will briefly introduce a problems statement and use cases, and I will leave the requirements part to Luis from So next slide. This is the draft status. So based on lots of discussion in the Middle East. We have modified the table contents of this this draft. So we had successfully added a new use cases, computing were SD WAN. And, also, we add the requirement the whole requirement part into this the merge inside into into a whole new draft. So to people are not so familiar with the background. I'll first briefly introduce the the motivation of cats So Basically, the use of the mind has driven the the fast development converting compute and network infrastructure. So, like, low latency highlightability and more state stable services experience. So in these So to make this diverse user demise, We need to consider how to deploy service instances and network edge. So there might be 2 major problems. We need to solve in the environment of cats The first one, the service instance deployment selections, So And also the second one is the traffic steering problems. So, basically, when the network is congested,"
  },
  {
    "startTime": "00:30:03",
    "text": "the cases. So when we want to still the traffic to some some specific service instance. the closest service might not be the best. So that's the basic problem we want to solving in the in in in the environment of cats. So in this document, we also modify the some key definitions. just like the What map just presented? So we have modified the major definition of service and also the service instance. So these definitions might be might not be perfect and might be temporary, but they have give some given some key features in the contact in the context of cats. And in in the next version, we will better coordinate with other definitions with the definition from other drafts like the the architecture draft. So next slide, So as for the problem statement, Just like I said, we have 2 major problems in in cats, The first one is the service selection. service selection in the network edge, So Basically, we need to deploy multiple service instances atgeographically distributed network edges. So factors Here need to be considered is the status of network and computing topology, and the locations of users and these service instances And also, we need to consider about the capacity of these of the service instances and network etch and also even we need to consider about the service category. So as for the another problems, we need about the traffic theory. So here, the problems is"
  },
  {
    "startTime": "00:32:04",
    "text": "the close is a net site, a service instance, We select might not be the best. So this is because The closest may not have enough resources, and the load is always dynamically changing. and also the closing site might not have the relative resource that we the user, the client, once most because some considering considering about some products, processing, we sometimes, we need to consider about the heterogeneous hardware in some sites. And also, we need to consider about the network path because there might be some congested link. So these these 3 major points. they need to be coordinated, to be when we talk about the problem of traffic steering, And these these two problems out what we need to solve in the cast Kite's in cats. So Basically, we have some High level use cases. in the previous previous draft. The first one is computing where AR augmented reality, and virtual reality. The second one is completely aware like, a and connected vehicles and another one accompanying where digital twin So in these three use cases, They both the network but run the network delay and computing, the processing processing delay will contribute almost equally. So when we when we dynamically steal the traffic to the network edge, we need to"
  },
  {
    "startTime": "00:34:03",
    "text": "consider both network and the the contribution of the network and computing processing delays. So in the a latest version. We also added a new use case, the computing aware SD WAN and use case that my what more related to a a specific solution. So in this use case, When we implied, use SD WAN to access their different their enterprise network located in different locations. with the computing aware problems need also be thought about Because when we when the want to select the best virtual CPEs, they need to think about the the computing resources. So this this are we we think this one is also a good use case for for the illustration of with cast can be applied So based on all these modification and the discussion, we have received some valuable comments from the list. And during the the doctrine call, So, like, we need to have some better description and clarification on the problem statement use cases, And also, we that that instead of the definition of service, apart from the definition on service and service instance, we also need a clear definition on edge computing. And also, In terms of in terms of the use cases, some of the existing use cases might be appear to be very high level"
  },
  {
    "startTime": "00:36:01",
    "text": "they should be more specific. And also, in terms of newly added use case and the f SD WAN use case, There might be some simpler ways to solve the problems and also apart from the the computing resource. Also, the the policies should also be considered in SD WAN use case. So thanks for all the comments, and we quarters, and we will have a better discussion, and we hope to address these comments in the next version. So for the next steps, Like I said, I will we will address these value comments in the next version. Also, we will consider about the relationship with other newly added use cases drop in their working group. And so just will come more discussions and contributions. Thank you all. Thanks, Kehan, and thanks for the work to get us this far. I wanna remind the working group that now that we've adopted this document, the working group owns it, and the work actually starts now. The use case is we're not aiming for a complete set of every possible use case. We're looking for a set of use cases that will help drive the requirements. Rashmir, you're you're up. Rajvindikabane from Huawei Canada. Thanks for Hello, work is is a well done draft. I was wondering if we can have another or have you talked about services do that that have contradicting requirements, for example. Like, your virtual reality probably is gonna even of those guys that have your compute and and and delay might actually have a different path to actually take. So would that be part of you"
  },
  {
    "startTime": "00:38:01",
    "text": "problem to finish Or is this something that you only consider? To be clear here, you mean a service which has 2 requirements that contradict each other. Yeah. Exactly. Thank you. go. Yeah. is it Sorry, agent. I think we will consider the company. at Thanks, Adrian. I think these problems, I think, we will consider about in the next version to make the definition about this like servicing, servicing to be more clear. Thank you. Brilliant. So We'll move on and and hear about another possible use case. Hello, everyone. This is from Alibaba Group. And besides our last use case presentation. Here, I want to add some spicy here switch about a new use case. from our like AI, model providers per perspective, the use case of computing aware models to see whether it can fit our working group scope. Yes please please Yes. I would like to share some basic concepts here. This year, we talk a lot about, say, large models. It's mainly about 1st is a foundation model, which is kind of to take care of generic. AI tasks and domains. So it's we can consider it has a wider the clear bubble and the flexibility and the but may perform not somewhere for customized domains in specific domain tasks. And normally, it involves, like, very mega scale parameters. And, also, we have"
  },
  {
    "startTime": "00:40:00",
    "text": "many cost customized models for specific domains, like, select electronics, like, electricity and some power consumption domain. and it's so it is trained for the specific industries. And, also, it's more focused on solving the specific problems. And then, normally, it involves some large or just middle scale parameters. Yes. Here is another concept. It's the AI model training and the inference. So in other words, the training would involve large data input and more computing. So normally, it runs on top of there. clouds. And for current data, it may be not so likely to be to deploy in the in the terminal or in in the in the terminal device. And for inference, since it's just involves more data data input and communication and and the the resource consumption is kind of not so high. So In many cases, it can be deployed in like, in cloud or in edge or in the device it says they are post very possible. And but here for the inference, it looks small on the balance between the computing resource, latency, and power cost. yes, please. So For the AI text here, currently, in the industry, we have many current software. tasks. here regarding the inference, so we can see there are some tests some test to tests or test classification and some region tasks, trust, trust, task and also the audio and also the mow multi, multi, model, AI task So here, I want to see especially for the image for the audio and for the video, and this kinds of things were involved in consumption of"
  },
  {
    "startTime": "00:42:02",
    "text": "like, the computing resource and the network resource if we want to provide some better user experience. So this is something I think we kind of redigued to our current group. a nest So here, I would like to briefly introduce some several basic several possible deployments of for this AI. this AI text first. It is all in cloud, so big basically everything. the foundation model and the customized model and also the training and inference will be within the cloud. So this may made, create some problem for, like, the latency. and also some high cost to ensure the privacy in the cloud based in interference. next slide. And the the second is cloud device called inference. So it can provide better performance in the businesses. But it may support only limited AI tasks since we can only support only use compressed or pruned model. in the in the device side. Yes. And, also, there is the cloudedge coinfluence. deployments. So in this case, the customized model can be deployed in the edge to handle to tick care of the training and the inference, and it provides some list of risk. Since in this case, it can this customized models can be very close to the to to use the sites. So to it can bring bring some advantage in the latency, but here when handling AI inference task for the traffic load, between the device and edge is high or this computing resource in edge is not is overloaded. So in this case, the"
  },
  {
    "startTime": "00:44:00",
    "text": "steering is needed to ensure the POS. and that's And the the last is kind of maybe the most complex deployments So in this case, the Cloud Edge and device, they all kind of they were deployed some some sort of model here. So here's the main main point is there would be some careful consideration to use to ensure that edge will only be used when the trade offs are right. So, also, your similarities or traffic steering is also needed here. That's twist. So in summary, why the chip steering is needed? Because as I said, the the vision audio model multimodal air faster they all involve many consumption on the network resource and computing resource. So and it is also kind of common in the same master model is deployed in multiple edge to achieve the load balance and higher reliability. So In this case, the computing resource and network info should be collectively considered to make sure the suitable traffic steering decision can be made. this So here maybe some discussion for our an an maybe is our next step, like, based besides existing defined requirements and use case. So is there a need for the device side application to know and choose whether the inference is taking place. or how the network and community resource be used optimally, just the letters of the device. sites declare the AI task constraints and less edge to figure out. This is just some question is in my mind. So provide discussed here Yes. That's all."
  },
  {
    "startTime": "00:46:00",
    "text": "all those things I want to present today. Okay. Thank you. I don't see anyone in the queue, so I'm gonna take the opportunity to do a show of hands poll. difference This is fun. My question's going to be whether anyone objects to adding AI to the use cases. which would help if I could type You don't actually see me what I'm typing here, which is really weird. this is whizzing along quite fast, and I see basically, three people say four people saying they object to the idea of raising of adding AI to the use cases. do any of those people want to express what their objection is? They can do it on a mailing list, and we can move on. But Tony Lee, I see you in the queue. I also see retainer in the computer. This may will be exciting attempts to vote. Oh, no. That's No. It's it's kind of what people are still voting. I have to broader question. I have no objections to the to the to the inclusion of AI, and I'm happy to say publicly that I did not raise my hand. I have a question about the use cases in general. because some of the descriptions of use cases that you describe here are about"
  },
  {
    "startTime": "00:48:01",
    "text": "understanding the nature of the network so that you can place the various components that make up your AI workload correctly. Some of the problem statements and the use cases you described are about Given I have AI workloads, I need to steer traffic because I have already placed it somewhere I now need to influence the network. one I consider to be reactive I reacting to the state of the network in some way, and influencing the placements, and the other to be proactive, i. e. I have placed, and now I must change the network. I'm new to cats. I apologize if this is a known problem. what is the use case that Katz is trying to solve here? Is it the proactive or the reactive or both? I'm glad you asked that question. Oh, I think my answer is yes. I'm not sure that's helpful. I know that's -- So so I I mean, I think we're at the point of trying to understand what our use case is are and what problem we're trying to solve. That that's how early we are. as a working group. So I from my perspective, I would kindly suggest that work on network metrics work on steering and influencing the network most definitely an ETF problem. placement algorithms for services as we are starting to describe them. wouldn't consider to be an ATF problem. Let's go take it to to Kubernetes guys or or whatever. That's a that's a more general problem than networking. And ETF working groups work well when they focus on a on a known problem and solve it So -- Yeah. So we are at the traffic steering. Yeah. not the -- Not not the -- Not not the the venue choice. Yeah. Thank you. Gotcha. 10ji, on the same side with"
  },
  {
    "startTime": "00:50:02",
    "text": "name here. Yeah. This seems like well, I'm not against the to put this one. the only thing I try to give a general comments. It's like here, just like you have some tasks that need high profile computational capabilities. So it's not like AI. So what my my point is here in, like, This is a general. So, basically, not just the AI. So for the cast, it should focus on the compute. that it's going to integrate with the now itself, not like know, we can get AI. We can get IoT. We get another thing all kind of use cases to put into Yeah. So I agree with that gentleman's Yes. I think from the network layer perspective for the not only I agree with you not for only user AI trust, but also some 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 from the network perspective, it's just a bunch of data. So, yes, I'd say I think for the AI testings, it involves some mid some, like, different scales, maybe the the data scales kind of has its unique feature, maybe much larger, maybe, is our is our the the the streaming or the flow is kind of longer since we have so many kinds of at task here. So I think in this case, we could see if we can find we find some new features about this kind of datasets, we can add something network. being a network layer or maybe very fortunately, we found the current solution can fit where in this a task datasets then Yeah. Yeah. That's we we don't need to do anything here. Yeah. Okay. Thanks. Julian, Rasmid, you you join the queue after I closed it. So sorry if that's gonna have to go to the mailing list. and will Move on. Okay."
  },
  {
    "startTime": "00:52:06",
    "text": "Thank you. Hello, everyone. This is Luis from Telefonica. I will cover second part of the document that was mentioned like a hand before. which is the recently adopted document on use cases and requirements. So next, please. So gutter is is about the process of selecting the servicing. based on necessarily on observed metrics for both computing and networking. from that lessee problem statement as well. from the use cases that were documented in in in the draft. we have derived a number of of requirements that somehow classify in the block you can see here in the slide. So I I will go now through each of these blocks, trying to comment about the rationale of of the the set of requirements we need to file so far. And, yeah, introducing very briefly the the requirements has when. So next please. the first block is about the dynamic and effect So selection among multiple services instances. So the rationale here is that we will have different instances placed in different points in the network. So we need to have the mechanisms for having the the proper selection of each of them. So here, we identify to to requirements by now. So the cuts must provide this the end resolving. of the mapping the service from the service identifier to an specific address in order to be able to achieve traffic, and also customers provide mapping methods for quickly selecting the instance. Okay? Okay? The following block is about the agreement on metric representation. rational here is that the the the objective, the idea is to be in a way of representing the metrics. could be of relevance for selecting the service instance in order to steal the traffic towards that that selected instance. Here, the requirements identified so far is that both cast must agree on on on the metrics to be use regarding the compute, but also as the the last requirement requirement number 4. the network metrics as well. So at the end, the the idea of the objective is to combine both"
  },
  {
    "startTime": "00:54:00",
    "text": "compute and and networking metrics in such a way of providing the proper solution considering the status of both domains. Next, please. I think one before. Yeah. Thank you. So the next block is about the moderated metric distribution. are the rationale for this set of requirements is to to finance our way of disseminating, advertising the metrics, so not not creating problems in in k. the network because of the distribution of those metrics. So the requirements identified here so far is that CAT must provide mechanisms for distributing the MET in, you know, a scalable way. And customers realize this with some rate control, yeah, in order to not flooding the the network with the advertisement on this kind of of metrics. following block is about the flexible usage of these metrics. So the rationale here is to use the combined network and and compute metrics. Here are the requirements is that well, a compute semantic model should be defined for the mapping selection. that cuts must have flexibility in in the in the way of using the metrics and the definition and utilization of this metric, cats as well, match it up metric information that can be understood by all the cans components so that so how they could process in a similar way, all the metrics has been defined. and that calls must use network and compute metrics. And if in case that some of the knows are not able to understand those metrics. to define default actions is a way that we we can continue, I mean, we could have service continuity or not service disruption. Next, please. The following blocks about the session and and service continuity here the the the point of the rationale of this set of requirements, is to do have the possibility of changing the service instance without in impacting their self their service continuity. Their session continuity. So here re as requirements, we have that the decision"
  },
  {
    "startTime": "00:56:02",
    "text": "as well as the service will be maintained in cuts that can must maintain instance affinity. So once we deliver the traffic to manage we can keep continuing delivering the the traffic to the same instance on the lifetime of the service. of the of the flow. I mean, next requirement is that customers avoid keeping fine, time, as they get on the them in Nagel Notes. the penultimate one that causes must provide mechanisms to minimize clients like the States. and the final one that cuts will support the EUE and service instance mobility. Next, please. So the last blocks are these two the regarding preserving communication con confidentiality, the rationale here about any leakage of computing domain or application privacy in in cloud solutions. So customers preserve the confidentiality of the communication related be between the user and interrelationship between the user and and the service. and regarding the final security considerations. So the the ticket will be to have a secure design from for for for cats, let's say. So cards the the service agent cards must be protected. The nature of the users activities should be hidden, and there should be or is it required to to have secure advertisement of the of the information in such a way that we can prevent Rob knows to participating in the network. So next one, please. These were the the requirements that we're describing in the document. The document said has been recently adopted. So in the process of adoption and in the Middle East, we receive a number of outstanding comments that I will go very quickly through them. So so, for instance, we received comments some of the requirements are perspective. Like, the the the fact of mapping of a service identified different specific address. all the requirement of low latency and so on so far. Another outstanding comment is that there are some back expressions in in the requirements. So, like, the the reference too quickly that this Palambigas."
  },
  {
    "startTime": "00:58:00",
    "text": "the idea of metrics flexibility. then the fact that the metric collection is also important, probably, we need to identifies some other requirements in in respect to the metric collection. Also, the discussions about the session and service continuity, probably should be clarified and and providing more more details. And also the fact that the use cases probably are very too high. maybe we need to do a preliminary exercises or refining the execution of the use cases. and from that fact, deriving more, let's say, clear requirements. And the same story for the security team. So next, please. and the last one. So the next step is for sure address the valuable comments received. note, as also I said by Adrian that has been already adopted. So the the the Berkeley Group is now the owner of the document. So the the or we encourage let's say the editors, we encourage the the working group provide comments and and in such way that we can reflect in the document the proper direction. the working group is is feeling as necessary for the requirements perspective. So, yeah, we will make work on the discussion and comments for sure. that's Thank you. Brilliant. Thanks. If there are four people in the queue, if they could be quick. Rick Tater. first off, thank you. Great requirements document. I think it's I'm a big fan of requirements document. It scopes. what's gonna happen. My question is I can see a lot of those requirements being met by working other working groups that already exists That doesn't mean having the requirement is bad. but it's not an enticement to go and invent a new form of DNS specifically for this. So I'm looking for for lots from the chairs to say that's not the intention here. Yeah. Read the charter. Cool. 2nd Thank you. Call us. Just my recommendation, I I see a lot of value of this document, but they'll when I I read it, think that some of the requirements are a bit bag it back in the sense that it's not clear to me if the requirements have"
  },
  {
    "startTime": "01:00:01",
    "text": "of the solution. of the working the working group just some that they are written in a way that is more a requirement for the working group. than a requirement for the whatever solution the working group comes up with. I think that should be a little region of it. Yeah. Thank you for that, Rosie. Arasmid. high one comment and one question. The first question is that when when you talk about metrics, or schedules parts of the metrics as well. So or or simply you're just measurements that you're sending So for example, if a particular service is online for a particular number of cycles, and then it goes down after those number of cycles going to actually distribute this as a metric around as well? or not or not the the comment that I have is regarding the previous presentation and AI, which brings up actually the requirement. some AI features, for example, like federated Learning require point to multi point and multi point to point type of requirements in terms of steering. traffic is sitting in in in in this in this forum. So you might wanna as well Regarding your comment, thank you. Probably something, I mean, captured that role. also incorporate the use case, something that we need to to take into the requirements because of the nature of the use case. Regarding your question, my my first reaction is, I mean, if if if there is services that these are bidding or resubmitting. necessarily will not depart more of the there will not be that would not be a way of frustrating traffic to something that is not already there. So there will not be a bleak metric applicable for that, I guess. So this is is my first reaction. Yeah. Hi. Derek Truson Huawei, one of the cool authors. I think one of the exercises apart from the comments made before, which I largely agree with is to really scrape the requirements on the requirements level I see rather interesting"
  },
  {
    "startTime": "01:02:00",
    "text": "requirements like we must use network metrics I find that interesting considering this as a computer awareness. working group. If I have a service that has no access or doesn't desire any access or has no weight or 10 network metrics, how do I fulfill the requirement So thinking about maybe should levels there would be you know, quite interesting. The same goes worth you know, I'm I'm I'm a big fan of there was a question by Marco Leap, Sean, affinity. I'm a big fan of that discussion. but there is a must requirement to avoid state in the network that is interesting. I'm a proponent of that requirement. people should think about the consequences of it actually will kick out a number of things we've seen in the discussion at the moment. because If I can't keep netbook state, but it's only And there is only another point where I can keep state, and that is at the endpoints. So people should think about the requirements. It would be useful to get the input, obviously, from the working group on that as well now increasingly on those various levels of requirements. Thank you. Hey. Excellent. Moving on, don't you? I will give you the controller as well. Okay. Good morning, Russ Baro. experts, On behalf of my colleagues, I would like to share our related works and perceptions on problem statements and incremental requirements of the current discussed scan to end caps. Next slide, You should have control. If it's not working, I will do it. Oh, yeah. Okay. Thanks, Adrian. And here's the jobs I presented and some by, like, works also listed. And next slide, please. ethyl caps typical use cases and problems are just dust, dust, And here, I'm a sing maybe some employee"
  },
  {
    "startTime": "01:04:03",
    "text": "classified the problems into 2 successive phases. computing aware and traffic steering, the former is attributed to the massive dynamic complex and obscure engines of service instances. due to the features of computing status. and the characteristics of edge computing. Well, the latter problem is naturally derived, which is how such a joint truck steering and of computing and networking. Next slide. who's the first two sub problems of computing aware capineous status is described in multiple dimensions with both ident Co and different properties compared to the network. And those different attributes lack into printable semantics of the network. We believe that computing information, description, modeling, and corresponding awareness schemes. are indispensable works to solve the measures of troubles. And here are some related works listed, and with, like, to prepare our suggestions The computing status should be converted or mapped into metrics aligning with existing network and matrix schemes, in an unstoppable manner, and Join traffic steering should be implemented over's ongoing infrastructure. with both network and converted compute metrics. Next slide. and for the next two problems, the quality is service instances could bring massive in the future. and verifying granularity computing stages information could be dynamic. considering above issues, a cohesive manner is introduced here, to generate aggregated cold screens and relatively stable per site information. and following drafts displayed. ends, appearanceably, it shapes and indicates a hierarchical awareness and breaking skin."
  },
  {
    "startTime": "01:06:00",
    "text": "And E course here is select the first, and x catheters are left should make a second choice Next slide, Let's have Rock Hill Skin introduced here it brings significant values and advantages This method information aggregated, the interest collected stored and maintains in the control plane is reduced A catheter which are online records the information of local instances and the representative interest for the other catheters instead of all instances, Additionally, since the interest aggregated frequency of energy updates is declined and the behavior of service due to recalculation attempts But but despite the values of hierarchical writing, it may want the consequence course and incremental requirements end, considerations That is housesuit equities Is there potential risks of invisible detailed information ends, ends, ends, ends, it seems exists a microloft problem with in the case of a market point decision making. Next slide. Consideration one here is that how to ensure the correctness of an aggregation algorithm As shown below, instances located as respectful catheters suppose computing related service is a step 2 maybe memory attributes and re temporarily ignore other constraints Catherine would just learn and record the entrance of the splayed and here, a summation scheme is deployed evidently. Supposed service request comes from PE3 end stage should be 1 4. 660 value and similar decision procedures from made up p 1 and p 2."
  },
  {
    "startTime": "01:08:02",
    "text": "Zen crafts is stayed between them continuously with generates a permanent loop That's excellent. In a properate irrigation agorisms, leachandcostsystems decisions, And the fundamental reason here is the summation list to the disappearance of comparability between aggregated information and detailed information. and estimation value is always preferred. This one will propose that aggregate information should be comparable to the information of any or that single instance. Next slide, and aggregate value undoubtedly is huge. detailed information and thus way may question the cause attributes to the inevitability of data analytics It is a quiet complex problem taking scheme one here. an example, A service requires end to end delays no more than 50, and it is memory sensitive. A pass value for each attribute type is selected as the aggregate That's 420 represent the performance at pone while 260 and sturdy, represents paging. one seems to be the better selection, However, it's not free as the UI fails to satisfy the delay requirements, And so 6 ads for you to is actually the best Also, with future considerations, number of three reasons, chances may be large and the running status is also displayed in a continuous manner, Thus, it is difficult to distinguish, and it's also may not be necessary just select The best one. here is just an aggregate aggregation algorithm should accommodates multiple scenarios and service requirements Next slide, Also, s display supposed s was 1 instant 2 located SP 1 loose us"
  },
  {
    "startTime": "01:10:02",
    "text": "efficacy at a certain, this defense has not yet been notified to P2 as a timely manner, and PEACH is still steers the traffic to PD 1, which is still reckoned as a best selection. However, SPU 1, whenever it updates its FIB, p u 2 is the most appropriate choice. Thus traffic steer back to Peugeot. which forms a microdip here Compared with microgrid occurred in IGP, The micron loop mentioned here as similarities the tributions stages storage and just overlay conversions. leach in cost system decision making among distributed devices and overs underlying network, it is considered as maybe the overlay micro problem. Just with just that routing and forwarding information and just should they organize in a hierarchical manner and for warning behaviors at a PE should correlate with a hierarchical forwarding behave information basis, respectively, Next slide. And as a conclusion, we here present several incremental requirements for cats, And for our next steps, we are looking forward to any suggestions to refine our jobs and works and thanks a lot. Yeah. Thanks. So so this side set started off sort of requirements wandered into architecture disappeared into solutions and then came back rather nicely to requirements. and I hope that we all understand that we are at the requirements and architecture stage here as as a working group. Dirk, have you got a a quick point? Yes. Thanks. In part, I'm confused a little bit by by this document But I do understand, and we have to really"
  },
  {
    "startTime": "01:12:01",
    "text": "maybe understand better which of these aspects are really within the scope of work and which ones are interesting. They're interesting, Robin. but they're not within the coat of cats, and this goes back to the comments before around monolithic versus you know, composition of services they they there seem to be aspects in the discussion where the problem of actually finding out which instance, and I'm using now MET's terminology behind a service contact point is actually being selected. That's an interesting problem. It's difficult. I'm I'm I'm totally agreeing with that. it's not really what and I I I seems that we agreed that this is not in scope of cats, and we should make that explicit So I think we have to divide those problems off. but are really about the complexity of what happens when you do things across service points and then behind certain certain contact points. and focus on those that are within scope. Thanks. Yeah. Okay. Thanks. So in the interests of time, we're gonna keep scooting onwards. and nothing happened. That's interesting. You can see the slides. Oh, no. I can't remember. Good. Go ahead. Okay. I didn't know on behalf of officers. I will present the problem statements, standard common stuff, and there too, a computer didn't grow. traffic exterior. Next slide, please. First, I'd like to make this simple introduction of the use case that's in the out there too. versus CPE traffics steering. In this system, I I have to clarify is quite it's it's a little different from the from The use case is it Kahan described in his presentation. because right here, the Hello."
  },
  {
    "startTime": "01:14:00",
    "text": "There is more and more industry practices, particularly in the operators where the the computing intensely part of the c PE has been migrated into his cloud. So the physical CPE and the residence will be seen. So the significant cost benefits we could do. And the for for for both the physical CP, which could be quite easy and easy to to to manage. And do they and does the virtual CP in terms of the maintenance efficiency So the key point right here is the a global IP address, which conventionally allocated for the CPE in the residence right, here in this user will be allocated for the VirtuCP in the cloud. Therefore, the domain behind this VirtuCP is exerting and and Air then there are 2 networks. So the subscriber behind the physical CPE would access the service just through virtual CPU in the cloud. And all of the exchanges between physical CP in the residence and to the virtual CPE remain waiting and there too. a network. So the virtual SDP is a cloud in terms in terms of SDP is the first scenario to routing the service request as well as the service traffic. with a public IP address. next to side, please. So here's the the 3 problems in these two cases of for The first one is Currently, the industrypsis is the physics PCE is binded with the specific Virtu CPE which is pre preconfigured. at the access gateway. So when the binding relation changes, man, when when the access kit we want to"
  },
  {
    "startTime": "01:16:01",
    "text": "steers the service traffic service requested to another versus CP instance in another And CloudSite is the service to this this continuity occurs. And the the Virtusa act actually, particularly when when when it comes to the access dev Worksports, use cases to the virtual CP could be deployed, they had a multiple, they had a multiple as computing science. Us dynamic resources to stethurst In in the cars, excuse me, it fails to beutanized, but near 2 networks. And one of the comms to the steer traffic in access gateway, which is to their their 2 networking node. The near 2 excess key we cannot be able to steer traffic to The micro sized dynamic the without no. Location independent dentist service at the end of vacation. Next NexSys means. So here comes the 2 comments. for the there are 2 category framework. Number 1 is the service identification of the layer 2 product is should be specified to computing and world traffic steering. particularly for the excess gateway. or the the the the the network controller and then of the net of the access network. Number 2, we're common is is it computing and where our information may be notified. It's a narrow 2, the access gateway centralized for distributed Continuing row product enhancement controllers. in particular, the near success I think we'd right here is Always, and there's 3 capable networking node, such as PNGandbiras. So there are 2 there are 3 products could be never achieved for competing awareness. Next as I said, please. Here's just thinking of how are thinking of how could be"
  },
  {
    "startTime": "01:18:01",
    "text": "aim command changes. The first is the accessibility coo steers of traffic from the physicacy, each the best sized Based upon the computer and awareness series is specified at the TELUS. and the queuing queue in user network in 2 user peck east or the broadcast to max, MAC address, Could be specifically fine to test this service to identification of virtual CPE. And the index goes to service traffic forwarding policy, and it's computing where it's state permission. excessive base. That's more. Okay. It's fine. Sorry, Linda. In the interest of time, I'm close the queue. It seems to me that this document and the previous one Could do well to try to write up the use case in a very can size way. and then maybe we can move that those use cases into the main use case draft, and that will make space for the requirements to move in as well. Okay. Thank Yeah. Hello? So, yeah, we are high. you like me to give you let's let's see if I can give you control Would off the slides. Okay. Thank you. Hello, Iran. This is Virginia from China Mobile. My presentation is about the commuting and networking information awareness cinema Architecture for cats. the the gentle walker conveyor to this worker include shall we shall we won from Meridian Networks, and Daniel Huang from Litigation. Please next, sir, next slice."
  },
  {
    "startTime": "01:20:05",
    "text": "As we know, face the requirements of emerging. So it's from the convergence of network and computing as presented from Kohan. case is proposed to the the to solve the problem problem of how aim network agents, their traffic to the to the set to the service set along the part of Timo, like a network pass. hope to enable the computing and the networking aware traffic steering decision. awareness of commuting service, information, and network is the foundation. So this document is proposed comprehensive aware architecture. who which is introduced new components and the commute corresponding interfaces and workflows and to facilitate the deployment of cas. and please place the next slides. For the for the the computing network information aware system architecture okay, chosen so important is decreentally introduced to support the vein green, the dynamic dynamic information awareness based on customer's framework as especially, the components includes in is 44 components. One first is cast computing information case. the short for CCIB, which is my is a risk able to maintain thin green to compute the information such as the cell ways, connection, computing, performance, which may be obtained from the arthritis from the clock"
  },
  {
    "startTime": "01:22:02",
    "text": "transition, the Cloud Magic platform. The second component is about cast network metric information base. Who who who which is responsible for 2 the machines that signing green the network information. such as the remaining ben bandwidth delay, which could be obtained from the The second the 3rd cast passes it the component about the Casa Pass calculation. which is a response of whole calculation of of a T Mobile computing resource and the network parts based on the cast information, computing information, and network information from the above and that generates a policy and a deal with to the cast increase larger. The about the the the the other new interface is cast sound info interface, which is intended interface based on the Oh, oh, oh, sorry. This is the answer transition now control of a self sponsored interface between the cancer, and the cancer control center. Given the comprehensive with this architecture. This document proposed a comparison set some of the deployment location. realm resource and the service station load the information and performance of computing resource and as always. And the 2 provides guarantee to the opportunity on where scheduling based on so is requirements. us please next. Please the next slide. Thank you. But facing for surgery, currently,"
  },
  {
    "startTime": "01:24:00",
    "text": "the the specific network of information and the computing. information used by the cas still under discussion. So this document, still clarifies this information basically, on comprehensive architecture describe the about in in order to avoid the introduction too much single loading overhead into the whole network that was advertisement. This document proposed to collect by the content of the computer computing information advertisement according to the content and frequency of information announcement and propose through the different information awareness method and the information announcement protocol. As shown in this table, the compute the information awareness information can be classified into Cobolute City capability status information and the status information. for the completed information is to is referred to related with static information with low frequencies such as the deployment location editor information and so on. For the status information, it's referred to highs habitate the frequency. which, as includes real real time status parameters such as remain a bandwidth delay service connection connection, CPU performance and so on. Please the next For the depending on the depending on the awareness system system system architecture and the"
  },
  {
    "startTime": "01:26:03",
    "text": "under the network deployment, the proposed the proposed this game suppose a a depict 3 typical difficulty deployment mode in looting or centralized model or hybrid model and some and the distributed model. For the centralize the model h h for the centralized model, the cast control case control center, well, is responsible to obtain the com computing information from and and the network information. And performance, so it's it's gathering according to the detailed computing information and the network information. As shown in this table, out then as shown in this figure, give an example. for the detailed communication from the close the manner to close the management to platform. and the network network information can be from the can can be come by through by the bgp areas. telemetry interface from zerters And the the SCP is what is two calculators complete to generate the so is a police based on this computer information and network information. to the cast to the cast rotor. then the catheter receives the service always requirements, then steering to the traffic to the to the to the corresponding service set."
  },
  {
    "startTime": "01:28:01",
    "text": "oh, oh, please please just slash. Thanks. for the second model is heavily the model. For this model, the cast control center, which is computing and the network information through rule SBA are useful to interface. The details of this information are directed towards future to cast ingress routers. The cast ingress routers perform performs the can perform put a a a correct resource matching and continuously in comparison detection after this service traffic requirements. This this this model can be come come come come for the some is fat some high value customers. And to accurately match customer requirements corresponding to the corresponding to the centralize the module. Oh, please just next slide. Oh, the second the the the third model is a distributed model. they said for this model, the ingressed cast Roger Well, responsible for her for collecting commuting information and the network information and schedule and make a study on SAWA's decision. 8 this is what this model is workflow the detail of the workflow can be seen in cast in document cast framework. So a places slash on. Thank you. comments, any question or comment or comments. Thank you very much."
  },
  {
    "startTime": "01:30:01",
    "text": "So thanks, Ruizheng. you you used 11 of your 10 minutes, so I'm I'm gonna skip questions and ask people to take them to the list I will observe that we don't really want to end up with 2 architecture framework documents. So I'd be looking for you to work with the authors of the other document to try to understand what the differences are and where you can information and where you've got points that need to be debated. Thanks. Okay. Thank you. Okay. So now we move on to the bit that's metric us. A long walk of shame. Some pain. Yeah. Hi. I forgot. Oh, thank you. Hello, Ryan. I I'm from. under I will introduce the the draft about computing, modeling, description, This is version 1. craft draft under we will introduce the modifications and And in stream discussion about the metric and Oh, I can't control Oh, thank you. Yeah. Sorry. Me TechCare seems to have got self really messed up, so I have to control everything. Okay. Thank you. this is the the outline of the"
  },
  {
    "startTime": "01:32:03",
    "text": "Right? And we will introduce the intergium discussion first and then the modifications Thanks, please. this is about the the small group had a call to discuss metrics for forecast next phase And this is all organized by the test and the course time summary summarize A summary is The first one is that it is important that the metric scheme used should be blackboard and extensible to support future requirements And the second is about following pretty city, and the the initial metrics the verification should cover only those metrics think that we need to solve the immediate problems. And on a call, we we we have agreed that my requirement, there should be the delay and that includes the network probe propagate time and a processing time. And and the the 4th one is about that we we perhaps have other possible metrics and they will be discussed under talked, and if 80 thinks to be useful Next kid, please. and we will introduce the locations of this watching which we run a graph we mainly modify the section file computing results modeling"
  },
  {
    "startTime": "01:34:01",
    "text": "and with the intent to start with simple metrics forestry And This is a comparison on the we we had some contends to this Section 5. next quiz. And this here, I inter we introduce some requirement or metrics using we always think that the advertisement percoagatement, the usage of the matrix in class are all related. So we recall the scenario all kinds firstly in the in the scenario or we how several places, for example, this I'm in c 1. I'm in c 2, and I'm in c 3. it all can support the service side is one. And what I have is different metrics. For example, mitral combined, mitral 2 and a max equals 3. and the the steps we we 18 in includes four steps as know, step 1, the service point that that lit for example, this MENSI can crack some specific competing information, and we think that we only need to collect the necessary compute computing information. the the service fund will send And the computing information into the network and the parts that were updated on demand or period. That was clear. the, you know, slide 3, decision point, for example, this Grace 1, we have received this computing information and make this decision. So that's the root for the service ID on the ingress"
  },
  {
    "startTime": "01:36:00",
    "text": "is as tabulation. updated. in the step 2 step 4. the traffic for the service ID will reach this grass node and be adding identified unless they are according to the policy in the the step 3. And next page, please. Here is the requirement. The first is about we we think that the the open optimization object or the policy. The decision polls may be various, for example, we we it may be the lowest the lengthiest latency of the sum of the network delay and computing delay. all the optimization opportunity is where all better load a balance and without Here, we will apply for the service points that could support more clients. And second about pipes that the updated frequency or the computing metrics may be various. and So the notification with all the computing metric may be virus. And the last one is we think that matricormodering process should be faulted if micro service instances are behind the handle the same. egress. Next, please. And we also get some design principles here can be considered. The first one is about can start with import cases. And the the the some d the m plan c code can be considered here is the first one is the computing metrics in past to finally, it should be a few on a thing."
  },
  {
    "startTime": "01:38:00",
    "text": "so that we can avoid with with supporting too much information. of the service point. the second, we think that the computing metrics test should be available for the filter extensions And the third is the computing matrix in the cache should be under independent and the price dependent next week, please. We also add this some contents about the con consideration we're using metrics in class also claim that we can start with simple cases. and we can modify it if we think some metrics are necessary. The case one is about the the our plan is optimization object of that of that traffic steering is MIMO, the total delay for the client. this case, the deuterium pond or the ingress, can I collect the network delay and computing delay that make a decision about the optimal service points the computing delay can be generated by the server, and of the service instant. which has a mini o the as ham as terminate all the the ordering all my processing of the request. in the second case, we have another metric that can be considered is service capability. For for example, when server can support 100 sessions, and another comes about 10,000 sessions with Is this time without prefer more cans to connect to second one. Also, for some other optimization objectives, we can also consider other metrics, the US metrics about energy consumptions mentioned that in other craft, Next, please."
  },
  {
    "startTime": "01:40:02",
    "text": "this button next step or we we offer our commerce and refund the draft Although, we can and modify the draft according to other related documents for example, the framework path. That's all. Thank you. Any comments? So thank you. What I'm gonna do is leave the Clio open, but move through the remaining two presentations to give everybody to give them the chance to speak. And if we've got time left at the end, we'll service the queue. So next up is Linda, I think. Okay. Okay. So thanks for the previous slides. Give the framework and the requirement for the matrix for CAT. And here, I'm gonna give some detailed metrics, which is designed for the 5g edgecomputing environment. So it could be a use case. It's a use case driven matrix. Next slide, please. So a little bit background. Right? So In the 5g domain, it is very important. One of the key feature of the 5g is delivering ultralowlatency services So ultra low latency services, There's a network delay. There's also a service delay. So there's 2 combined. Right? And so the back one is to be able to find the combined latest delay for those particular services. And the very important thing, those services, ultralow service It's not for every everything. Like, a a u e can can have one service which require low latency, but majority of services initiative from the UAE does it. So those are the premium service, are the registered services, the application controller,"
  },
  {
    "startTime": "01:42:03",
    "text": "do have the information on what service ID require a low latency service. Next one. So in this environment, keep it simple. There are 3 major matrix, which are necessary to be able be integrated with network delay to reach to achieve the ultralow latency. One is we call service delay. prediction. So it is very, very, very difficult. to to to say for this particular service, how much delay, it will be from different edge centers. This is under the assumption that One service had multiple instances in multiple edge data centers. And So one thing you can base down is how much capacity you have, how much resource you But just having the resource index is not accurate. It cannot actually calculate the delay. So we call delay prediction. So this delayed prediction can be a configured value. based on the service ID. Like, particular service have certain kind of characteristics Their service delay could be xyzat edge data center 1. And this same service could have another value at at edge data center 2. So that can be a configured value. It could be also measured based on the remaining capacity left. And another thing is one The application service logic is not visible to the the operator, like 5goperator. you cannot really predict the service delay based on those values. You can also use historic data. to predict how much service delay it is. So based on the principle that"
  },
  {
    "startTime": "01:44:00",
    "text": "Hey. This particular act data center Historically, is this amount of traffic to this service ID? And at this particular hour, suddenly, the traffic demand, goes up, like, 200%. It could be driven by a particular convention happening at this particular site, attract lots of UAE come to this particular site, Anchor to the cell tower causing huge increase of service demand. So with that, you can predict that. At this side, we can divert some of traffic to other side. So that's kind of we're using the IP layer matrix to compare with historic data to predict. potential service delay at certain site. So that's the category under service delay prediction. Another matrix is we call preference index. So preference index is really service to service independent. So Service a could be require high intensity computation. So at this particular site, maybe they have more CPU power. So the preference on this side on side a could be higher. Another service ID could acquire high bissectional Bandwidth for microservices. So for a particular side with high throughput among the servers they could have higher preference. And some other service ID could be like, require large storage, then at a particular site with huge amount of storage. could have higher preference. So there's a preference index. So preference index is also can be used for sticky service. Meaning, when UEO room from cell tower 1 to another cell tower. anchored to different user plan function."
  },
  {
    "startTime": "01:46:00",
    "text": "will come into the network from different ingress points and the preference i ID can be used to steer the traffic into the previous service sites. So that's the second one. The third one is what we call site availability index, meaning that a particular side. you could have. a whole shelf. just completely go dark. You lost power. Something happened. network fiber cut. Something happened causing a physical, location apart to be complete out. In the BGP, like, say, if you have egress node support BGP. Normally, you have to send many route withdraw message to the ingress node to indicate all the services being impacted. Side available index is basically one value to tell the all the ingress nodes, all the routes associated with this particular site ID. are dumb. so that ingress node can process all the routes associated with this site ID switch them into a different place. So those are the 3 service metrics We call metadata. We propose for the edge computing environment. Next Linda, you've used 7 a half of your 10 minutes. Oh, Okay. I will hurry up. So this just, like, exemplary algorithm to show how do we integrate network delay with the service delay. to come up with 1 single unit number value, which BGP can use to select the path. Next slide. Okay. So for the this is for the BGP distribution. So BGP has this around constrained distribution. meaning that you only distribute the traffic"
  },
  {
    "startTime": "01:48:04",
    "text": "into the route of why interested. So here, we're using route ID the service ID as a raw target to to limit the distribution of the the BTP update. So this have more detailed information in the in IDR doc will have a detailed mechanism on how to achieve those restricted distribution. Thank you. Okay. So here's another things about in the BGP domain, 1 egress router, not only behave as the egress product to those edge services they could be the next hub for many other services like going through the egress. to the Internet so that this is just one reason that we're using the site index instead of route withdrawal or changing the next hop weight because in the BGP, it can change the weight for the next hop. By changing the next hop weight, you can impact great number of routes which may not be the Patch Services. That's it. Okay. We can skip that. So here, just the use case derived matrix. and we're looking for more feedbacks. Thank you. Thanks. We'll continue to keep the queue open, but save you until our Okay. the last presentation. I I want to apologize from the chairs for not having trimmed those slides because there were some solution protocol work in there, and that's clearly not in scope. we're trying to get out of that is the the metric that we need to to discuss. So last up is Jim, I think. Yeah."
  },
  {
    "startTime": "01:50:04",
    "text": "Can you hear me? Yes. Go ahead. me when you want a new slide. Okay. Thanks. Hello, everyone. This is Jin Wang from Tina Mobile. This was my first presentation as ITAV, Okay. I'm here on behalf of others, to report the drop to about current challenges in cats Why are you considering green in cats? as we all know, reducing carbon footprint to net0 is 1 maintain its grand challenges with continuous development and progress of the Internet, a large amount of computing resources is required to complete data processing which could put the also lot of energy consumption computing work traffic sharing is about process selecting service instance for directing traffic to this observed metrics for both computing and networking So green in cash, it was exploring. Next slide, please Okay. There are there are 2 recurring changes in cash So for us changing a computing resource, energy consumption moder ring, computing resource status is considered in cast So is necessary to research modeling building resource energy consumption, in order to save NT, The ant consumption of equipment is different where it's a loss details, For example, the energy efficiency equipments is different when it's not loaded,"
  },
  {
    "startTime": "01:52:01",
    "text": "all and full loads. Zephyr is also a change to consider which fact the contributor considered when monitoring the energy consumption of computing resources Next slide, please. Okay. The second challenge is trends up term opti precision, computing and network On one hand, the max code of computing, energy assumption may be different from the magnitudeofnetworkenergyexemption and how to read the retail of network and the computing status becomes your changer when performing to interrupt her motivation. On the other hand, the introduction of energy and consumption done, maybe accomplest a company by a compromise between user surveys experience and how to save Angie while ensuring user service experience It's also a change when carrying out trend optimization, Next slide, please. Okay. The 3rd change is Energy consumption o, other equipment, you know, to the computing resource, he's maybe in the data center, edge computing nodes or others in order to ensure the normal operation of network and computing equipment to source energy consumption is not only the equivalent is self, but also some other equipment such as call important next slide, please."
  },
  {
    "startTime": "01:54:01",
    "text": "Okay. Recently, the document repeated a green matrix against some green network networking metrics for network in in from notation to optimize the energy efficiency efficiency of the network Yeah. As the damage or equipment level The author considers 3 factors So first, LNG consumption metrics. Some of these metrics could be pro provided by the datasheet as it comes with damage or could be mirrored simply in lab, such as power consumption will adult, power consumption when fully loaded power consumption adds various lows and so on. The others are not fixed and the need to be accounted according to the actual operation of the network equipment such as current power consumption for kilobytes, o peelerpipes come to power consumption for package power drum science system started for the past minute and Suwam, And the flow level these metrics are related to flows such as an amortized energy consumed over the duration of the flow. and the income mental and be consult consumed over the duration of the flow. At the past level, these metrics can evaluate the energy consumption or path and optimize these past. So"
  },
  {
    "startTime": "01:56:03",
    "text": "that the overall footprint is Minmise, The author gave some candidate metrics such as entity rating over a path can't power consumption across a pass and incremental power for a pasture. or a pass. Yeah. at the net network level, these metrics can reflects the energy usage of the entire network Yeah. Next website, please. we will consider how to use green metrics in cast you as we all know, the cash charter doesn't include gritty granulated parts So this drive is your simple attempt Yeah. So welcome more people who are interested in this topic thanks Brilliant. Thank you, Jim. I'm well done in keeping to the time. I'm gonna make 3 points from the chair, then we might manage questions from the floor. Firstly, this green stuff is potentially in scope, and then we are the AD last time around But we need to be aware that it's it's really complicated and and a big deal And so we should try to run it in parallel with stuff and not slow down the the the basic metrics work. On metrics, I'm going to go to auto later today to introduce cats to them and to mention the fact that they're probably interested in Metrc to do with compute."
  },
  {
    "startTime": "01:58:00",
    "text": "And if we perceive an overlap, we should sit down and have an in a joint interim meeting to try to to beat out what the the real core metrics are And my third point is to remind presenters next time around when you've got a time slot That slot includes any questions you want to handle. So you can use your time or you can share it with the questioners. And now we've got precisely 2 minutes If Dirk, you still wanna ask a question, Yes. Yes. I do. I I think your second item is working more people into topic on met if that meant metrics, I'm up for it because my question was mainly about metrics. I put this into the chat as well. I see the I see the interest in delay, but I'm also a little bit worried that they're getting bogged down a little bit too much we want And I would really encourage people to think of even in the AAVR scenario, wanting to send something to an instance that has a GPU has only reactively to do with delay, and I do not wanna wait until we are gets bad in delay in order to make a decision otherwise. So capabilities are really, really important And I dug back into CCPP in the w 3 c, which is a an RDF based, it may be overkill, but it's a very interesting framework to allow modeling of compute capabilities that maybe the authors of the various drafts should take a look at allows you to encode capabilities including where we could probably put stuff like clean metrics in byte scope for the usage, really. Thank you. Good. Thanks. Luis, I hope you can be quick because Julian keeps getting bumped off queues, and I'd like him to have a go. I I would be quick. a comment to Linda's presentation. Linda was commenting about the idea of configuring the delay as a potential metric said that this could be problematic because the delay is buried in a long time. So probably, I I mean, at the end, some having the static value will be a kind of precedent."
  },
  {
    "startTime": "02:00:02",
    "text": "like the other ones that site availability or preference also. I will recommend not to go to a static delays. because it's it's changing from the either state to the network up to the big status of the network. he's batting around the time. Julie. I'm gonna have Nokia. So I wish we had more time for discussion. It appears that it's not the case. One thing that I would like to stress here is that I've noted that we see requirement popping out from different use cases here. I wish we had much better tracking from the use cases to the requirements. Today, we have requirements that go in different directions. It's very difficult to understand where this will contact coming from, sometimes you get the feeling that they come from nowhere. And I've made observations about why I thought that the use cases were somewhat high level That makes it very difficult to create corresponding requirements. And today, the requirements we have some of them stand pretty much in the air. So if that could be improved, in every of the documents that proposed requirement that would be really very profitable, I guess. Thank you. Wonderful. Thank you. We are technically out of time. Pong, do you need to say anything to wrap up? Yes. Well, you. Thank you. Thanks for all the presenters and the contributors just to have some overall common sense. We don't have so too much time. we can see some new draft has both new requirement. It's gas. metrics have frameworks. we hope that the authors of the draft could work together to say if there anything missed or anything to be contribute to this WG. And, yes, that's my confidence. Brilliant. Thank you all. See you on the mailing list."
  },
  {
    "startTime": "02:02:08",
    "text": "Hello? what's so"
  }
]
