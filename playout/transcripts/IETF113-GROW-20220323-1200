[
  {
    "startTime": "00:00:21",
    "text": "um [Music]"
  },
  {
    "startTime": "00:02:25",
    "text": "with any mine anyone minds closing the door please thank you natalie [Music] welcome everyone warren please be quiet hello a warm welcome to all of you it is very nice to be here face to face in part and a warm welcome to our remote attendees from all over the world luckily for us we are anchored in the european time zone native to my home but i very much appreciate all the people that are going bad back to bed or got up really early to attend this session um let's go through the administrative administrative that's a difficult word administrative side of things first of all this session is covered by the ietf notewell this means that we adhere to a certain code of conduct specifically in relation to civility different than other meetings there are no blue sheets to go around i dearly miss the tradition but if you scan the"
  },
  {
    "startTime": "00:04:01",
    "text": "qr code that was here at the beginning of the session or go to the agenda on your phone there's the meet echo lite application and that's how you check in and also how you cue yourself up for the microphone since this is the third day of itf i assume that all the people in the room are somewhat familiar with that procedure and meet echo thank you very much for your assistance and help specific to the grow working group there are a number of resources most importantly our agenda can be viewed online and we have a mailing list i would now like to ask for a minutes taker jared would you like to be volunteered for this job good enough for me thank you for your services jared if anybody can also keep an eye on the meat echo chat which is what previously was known as the jabber thing to ensure that we catch any and all comments and questions that arrive from that communication channel we have a volunteer for jabber scribing thank you warren your services are much appreciated but in order to fulfill this task you will need to open your laptop all right agenda today we have a few topics specifically bmp nrtm mbmp you can see that we mix them up a little bit to create an interesting"
  },
  {
    "startTime": "00:06:00",
    "text": "variance in our cadence today our presenters are remote [Music] and i think unless you have anything to add chris we we can move to to the first presentation yes please all right we're not there yet follow you hello hello paulo good to see you yes great great and thank you for awarding you know 12 minutes uh of the agenda not 10 not 15. that was a greatly appreciated it's precisely what i was looking for um so um i have uh updates on two uh drafts so the tlv and the ebit tlp ebit draft so next slide if some somebody is running the slides yes if you give me the signal i will make it go to the next slide next slide please and next one again perfect so i skipped the context because every time i present the this draft i give the top context so it's in the previous slide for who has lost the context for this one um so just a brief update on what happened since uh the last dra the last version of the document so which is last itf um essentially we formalized a little bit the boolean story coming from you know programming background i was thinking that just saying boolean was clear enough but i received that the feedback"
  },
  {
    "startTime": "00:08:00",
    "text": "that uh we should specify it's a one byte field with you know zero and one that can be encoded in there so thanks very much to jeff and bang for their feedback about that uh following uh the the rest of the recommendation here uh they they were all coming from jeff haas and um so we should ask uh ayanna for two new registries one for the root monitoring a message and the other for the peer down and then we added also an error handling section um so in which essentially what we say that um the tlvs are trailing you know are following the bgp video and of course you can decode the tlds only if the bgp pdu is well formed if you cannot pass that then of course you cannot go beyond that and so you cannot parse the tlds uh so uh side remark is that uh you know if you want to do an exercise which is different from uh you know conveying the messages but uh you want to check the sanity of the pdu and things like that maybe you are looking for the root mirroring instead of the root monitoring um and the second thing the secondary market that was also coming from jeff was that as we know you know the message size is limited and then uh this is already you know a problem with the bgp pdu itself and with bmp by itself because there is a decoration around the bgp pdu uh should it hit you know itself the maximum length and then of course this is aggravated with the the use of tlts so it was good to make a note over there next slide please and so this is the status for the version 7 of the draft and essentially all the feedback that was"
  },
  {
    "startTime": "00:10:01",
    "text": "received has been processed and there is really no more outstanding work so this is a message for the chairs uh and also i don't know if there is any questions or any any anything from anybody at this point i have a question if there's no more outstanding work is there running code that you can report on implementation reports yes yes this is all coded on the collector siding pmsct it is coded it is working it was test um there is at least one vendor that i am aware that has you know such implementation so yeah so i guess you're asking for working group last call and the sausage machinery to start running yeah i think we are already in last call i think i want to go beyond the last call all right all right fantastic so next slide please uh so this is about the uh tlv ebit uh so this is the last present the last time i presented this was at uh in singapore in 2019 the last time that we were i i was in person um and i think this is a very useful draft but uh uh you know uh we received even in the room some uh you know interesting comments about it so i've i thought to refresh a little bit give context again and share updates so next slide please um so what is the problem statement here is that of course uh you know uh we have uh tlds that we"
  },
  {
    "startTime": "00:12:01",
    "text": "explained in the other draft and till these are public our ayanna governed and you know we asked ayanna for registries and then you know um every you know id in that registry will mean something um that is something for those registries governed by ayana are of course for um you know elements that should be supported by you know everybody or generally supported of course next to that there could be some elements that are not that are proprietary that are you know not public uh why is that there is a wealth of reasons for that so the one of the most common is that it's a you know a pre-standard product right um another one is that there is a something that is commercially sensitive but yet another point and this is something on which i will update uh the introduction of the of the draft is also that there could be elements that are very low level so they cannot really be standardized right they could be low level or really touching the internal of the implementation that maybe it doesn't generally exist or make sense to make something you know ayanna go there so this is this specific point which is very relevant it's not yet mentioned in the draft and i will do in the next you know release let's say and next slide please so um as an introduction just in case uh not everybody's familiar with the uh pang pang is a private enterprise number and it's a number that is assigned by ayana so whoever can go to a young and say i am an enterprise and a young hands off you know um an id i i don't know if it's whoever but for example even pmcct as a pen number okay so the pen is the key in order to"
  },
  {
    "startTime": "00:14:03",
    "text": "make the enterprise specific part to work and this is all you know nothing new under the sun uh you know who knows me i know i come from a lot of experience with ipfix working with ipfix and things like that and i just borrowed something that i think it's very useful and it totally works for ipfix but you know porting that to bmp next slide please so this is how ayanna gover and the tlv uh is looking like you know um so essentially we strip the first bit of the type for that e and that becomes the e b to the enterprise bit which could be zero or one so in a young gober in the tlv the e bit is zero and then everything just stays as the other draft the tlv draft that i just presented then next slide please in case instead it is an enterprise specific one the ebit goes to one and you see that after the length you have the enterprise number the enterprise number will be the pan that i was describing before so you have type land the enterprise number and then the value next slide please so what is you know the status right so um there was uh you know some feedback that was processed uh or actually all the outstanding feedback was uh processed um so an operational considerations action was added again on on under suggestion of jeff jeff has um and essentially he was recommending that you know uh whoever is endorsing this uh scheme essentially should um you know make publicly available their privately defined registries and uh and there were a number of"
  },
  {
    "startTime": "00:16:02",
    "text": "editorial comments and things like that there are open questions like what could be the scope of ebit right so for so far the scope is just the tlds but uh of course the you know you can make private messages you can make private stats types and things like that i mean we can be you know more ambitious than this but i would say that first of all and that's the next question whether this is a work that is relevant for the working group and whether um you know uh it would be accepted and the last time just for an extra context and with that i'm done uh let's say when i asked this question there were a little bit of mixed feeling and then i wanted to see whether uh also with that remark that i was making before about that ebit is also about you know things that cannot really be standardized because maybe they are not really their internal internal bits are very low level and maybe do not apply to the wider you know public the well doesn't make sense to make a young a good point for that uh whether that changes anything right are there any questions from participants or the room i see ben virtually wants to get in the queue and is now physically moving towards a microphone uh ben madison work online hi paulo um so i think this is a generally good idea um and i think that given the overlap from an implementation perspective that's likely to exist between bmp and ipfix i think kind of stealing the the mechanism is also a good idea um question on uh could you go back to the uh"
  },
  {
    "startTime": "00:18:00",
    "text": "the packet format slide um uh the the one for the enterprise variant the next one is it coming i see so the the the private enterprise number field is that is the idea that that contains only the private enterprise number or would that be the private that would that be some locally significant value qualified by the private enterprise number because not that no that's that would be just the enterprise number so depend the public you know the private private enterprise number but the type would be the you know locally okay okay i see so the the the the enterprise number acts as a namespace scope for the type of field exactly exactly okay that makes that make sense that makes sense yes um so my only my only concern here um is that this ends up being a way for vendors to all implement essentially the same thing but with their own special name and syntax and you know various different ways in which you have to write the same code 100 times in order to operate a multi-vendor network i think that i think maybe a slightly stronger recommendation about making a registry available possibly in some sort of minimally machine readable format might go some way to help alleviate that but i think you know a a fairly strong recommendation that this should not be used other than for you know temporarily for things that are likely even in the distant future to be standardized would be helpful because we don't want"
  },
  {
    "startTime": "00:20:00",
    "text": "you know a situation where every vendor in the whole world has got a separate type for asparth for example do you know yeah yeah absolutely absolutely and you see this is very along the lines of the feedback that was provided also um in singapore in 2019 and that time who was uh saying that was actually it was job it was job right our very and true job um and the the my answer back then and that's uh you know the only thing that i can answer today is that so first of all is that yeah we should put in there all the text possible right uh we should make this happen because it's useful and put in there all the text possible in terms of recommendation and things like that the second thing is that we can look at the story of iphix because fortunately since we are not inventing anything we can look at the past and see how that worked well or not with ipfix and in latifix we don't see that happening that they all have the very same thing but um not standardized you see uh there are things that are certainly remaining permanent right so uh for example then not the whole career grid not uh logging for example it's something it that is staying into private elements and things like that but uh that is probably because there is one vendor only implementing that or two vendors only you see so i from the story of ipfix i feel to be positive that this mechanism is not abused of course i don't have the oracle so i don't know what's going to happen um and i'm totally willing to do our part as itf and put in there the whole world that we should be putting in order to discourage to"
  },
  {
    "startTime": "00:22:02",
    "text": "yeah that makes sense thanks jeff uh so backing up ed's comments uh i pasted a presentation that i had given the prior ietf and codepoint management the the challenge that you usually end up seeing for this stuff is that uh it's usually back pressure that you get from the registry availability so like the majority of uh you know bmp's spaces were originally done under very tight uh requirements uh the current one is under a specification required which is not quite as loose as first come first serve and what we're looking for for stuff that you'd want to put into non-enterprise space is if this is generally useful make it as easy as possible for people to be able to publish a specification and get a code point and just ship their feature and you know that said part of the back pressure that you get is you know what if you're not sure that it knows something that's generally useful giving the vendors a playground to be able to do stuff is a useful thing uh one of the sort of dangers that's discussed in the slides is that when you do these sorts of things there's always the concern that you know how stable is the vendor going to make something if it's their magic number maybe they're less concerned about stability than ietf might be and we see this for incremental deployment of pgp features is the example that we give in the slides so the enterprise number isn't bad uh there is a motivation in the bmp community that if it's generally useful feature we should be pushing people to push put the stuff into public spaces and we're very likely end up seeing that uh they're could be transitional scenarios where stuff may show up in an enterprise field and they stay there while also manifesting in the more public versions because long term the goals people's collectors will want to gather the information from a common set"
  },
  {
    "startTime": "00:24:01",
    "text": "of code points and not have to worry about well where do i get did you say as path you know for this particular thing thank you thank you benoit briefly was in the queue but somehow disappeared so uh read his comment out loud he indicates [Music] we did not see concerns in the ipfix ie history hopefully so i guess that is a positive sign towards using pen numbers in context of vmp so let me redo it right i want to make it short but okay let me go to the mic now so uh benoit class so yes in the history of ipfix we had the same concern initially and we have not seen that most of the people were actually eager to come and propose them to ayana as uh as in high peak information elements the only one that were not done in ayanna there were particular reasons like it was we would know we could not get consensus across the industry but these are these are really corner cases so it was a concern for us initially and in the end it was not thank you jeff you're still in the queue is the queue cleared up um so the two items paulo the ebitd thing you said it's in working group classical and the chairs need to do work and for the the tld not the e-beat in this presentation you mentioned two drafts right yes the first one yeah the first one needs to complete the working group last call exactly the second one you propose to request working group adoption exactly all right we will do those action items"
  },
  {
    "startTime": "00:26:02",
    "text": "thank you very much thank you very much for your time thank you paulo um next up is sasha romain i think i should actually ask you how to pronounce it in english i i don't even know how to pronounce it in english in that romaine uh sasha please indicate when you want me to move to the next slide and the floor is yours welcome thank you my first itf meeting actually so yeah my name is sasha romain i'm presenting the draft on the near real real-time mirroring protocol version 4 co-authored with job schneiders at strain and staffers constantires next slide please so a little bit of context first uh energy mp4 is a protocol for ir mirroring uh as many of you may be aware but maybe not all the internet routing registry actually consists of about a dozen sort of authoritative registries they have different operators different purposes different scopes and mirroring exists for these different uh registries to be able to mirror data from each other it's a one-way process so for example if someone queries entity comes ir server they also see data that has been mirrored from right and things like that and also a number of uh operators run their own local mirrors uh they don't have authority but they run their own mirrors for performance analysis things like that there are"
  },
  {
    "startTime": "00:28:00",
    "text": "a few common implementations for for ir servers there's a few versions of the right database software out there which runs uh the registries from rypn c and ethernet and apnic there is a legacy version of iard version 2 and 3 that's currently run by rdb level 3 ltb few other smaller ones and there is the latest ird version 4 which is actively developed still by me and runs most of the other larger registries next slide please so currently this mirroring is done with nrtm version 3 and mostly ftp downloads this is a very poorly specified protocol uh there's pdf somewhere it's plain text overall tcp so that's there's no way to check any kind of integrity or authenticity it skills very poorly essentially there's it's very difficult to skill at all there is no status signaling so if you query a server for new changes there is no automated way to for it to tell you you don't have access or i don't know what you're asking or everything is fine i just don't have any new data so there's no way to detect when it breaks there's also the streaming of new changes and the ftp downloads that you initialize with are completely unlinked basically and you sort of have to hope that you got the right tool matched up because there are many fascinating ways in which nrtm version 3 can break quietly weirdly it's actually a major source of support i give to users of ird version 4. next slide please so the new draft is publishing nrtm data publishing the ir"
  },
  {
    "startTime": "00:30:02",
    "text": "mirroring data on a https endpoint which uh creates all the benefits that we have with with publishing things on hbs which is a thing we know very well to do uh it is inspired by irdb so there are some similar concepts and names in here there is a small update notification file which functions as a often retrieved index and points to a snapshot some deltas usually with changes in them and the snapshots are periodic they contain all the records at that time in the ir database they are large and small deltas only contain changes they are bashed into one minutes time frames if there were any changes and all these files are json-based they'll support utf-8 currently in energy mp3 and ftp there's no standard on encoding so all the mirroring is full of encoding glitches everywhere the snapshots and deltas themselves are immutable and they are cacheable so that helps with scaling them and the update notification file itself is signed the end contains hashes of all the referred files so this allows integrity checking a bit more on that later because there's still some open ends but the idea is to offer integrity checking which we are currently missing and finally there's a random session id which has to match otherwise clients re-initialize and this basically allows mirror servers to force clients to re-initialize which there's currently no way for so somehow there are gaps in history clients silently and without possibility of detection or recovery run out of sync and yeah it's uh it's bad next slide please"
  },
  {
    "startTime": "00:32:00",
    "text": "so for br servers the process is basically going to be they generate new session ids i'm obviously skipping over a lot of uh details here but this is the broad overview they generate a new session id generator for snapshot which sometimes may be empty not typically a new update notification file publish that on an endpoint and then you're running nrtm version 4. i should note that this is everything in the protocol is per ir database so ripen c who publishes ripe and write non-auth these are totally separate in for nrtm version 4. next slide please for updates uh every minute where each mirror server will generate a delta file if there are any changes if they were a little late if they had downtime they can catch up but generally every minute if there were changes and they are all sequentially numbered so you can always know that you have a consistent complete set of delta files without gaps they then generate and sign a new update notification file also periodically there's new snapshot files so that new clients who show up they need to start with a snapshot file so that shouldn't be too old it's not necessarily every change so we don't generate snapshots every minute they're too large for that but the idea is that clients don't start off too far behind there's also a regeneration of the update notification file even if it hasn't changed which allows detection of still repositories some iar databases are incredibly quiet they have one chains every few weeks maybe so this allows to attack like is an ir server still publishing to this endpoint or or not and an important distinction to note with compared to energy and version 3 is that we don't"
  },
  {
    "startTime": "00:34:00",
    "text": "none of the data that is transferred between servers and clients is different for clients the mirror server publishes one set of changes that contains everything any client needs next slide please mirror clients they retrieve the updates notification file and signature they verify it if there's data there and the session id matches uh it's the same version you're up to date you know and you don't have to do anything otherwise the client tries to pull in the deltas to get to the latest version if those are not all present because probably the client is has run too far behind or if the session id has become different the client will always reinactivize from the snapshot automatically retrieve that verify process it then continue following along with the deltas again so if clients run out of sync if there's a new publication points clients always automatically recover next slide please [Music] um i won't go through all the fields of the file in detail that's all in the draft but this the update notification file which as you can see essentially lists the current snapshot and the version of that along with all deltas the the ir database that this is for and a timestamp of publication to detect stillness next slide please the snapshot file itself is a fairly simple contains also session id version source name so that we know those are consistent and essentially a list of objects uh nrtm version 4 intentionally does not go into the actual syntax of ir objects basically because we don't have a singular syntax of ir objects"
  },
  {
    "startTime": "00:36:02",
    "text": "so uh yeah that's why they are they're presented as encoded strings next slide please and so finally the delta files are are similar they list changes so one delta file can have at least one possibly many different changes of deletions additions modifications to objects next slide of course any point of the draft is open to discussion but i wanted to highlight two particular ones the first is the database configuration file as i mentioned the update notification file is signed and it then contains hashes of snapshots and the idea here is that we provide end-to-end integrity checking so the ir server that published it all the way to the ir server that is processing this there's also hps which offers transport security for part of this but not all of it the problem of course then becomes how does a client know which public key to trust and how do we deal with key rotation for example because people will want to rotate their keys clients mirror clients don't really sign up there's not really a single way to effectively reach them and so this is uh we have a plan for this now in the draft but this is definitely the most open to discussion next slide please so the current approach we've chosen is to have an additional file the database configuration file which contains ir database name like write private non-public signing key of the updates notification file and the url where those files should be expected and this file is different from all the others in that it must be published on a well-known uri on what i've called the generally known"
  },
  {
    "startTime": "00:38:03",
    "text": "so other files can be published wherever the operator wants to this one has to be published on this particular domain it's also low traffic and the idea here is that if i would say radb then everyone who is familiar with the ir system would agree on the same domain name that we would all trust to say where do we retrieve the update notification file where do we retrieve nrtm version 3 uh where is the ftp server and so to use that as a basis of trust and allow configuration from there this is yeah so this is our approach so far uh next slide please i only have two more slides so question maybe at the end uh another problem is delta expiration uh because many of our clients will very closely follow all the deltas that are being published they retrieved snapshots the update notification file frequently download any new deltas they're going to download a handful at a time and these are also the ones that we want to have low latency so that's why we make them every minute some clients though are going to lag behind they're going to be down for a while connectivity issues anything can happen and sometimes they are days weeks potentially even months behind and they're going to start up um and with one minute one delta every minute potentially there are up to 1440 deltas okay but for many databases i run some numbers it's much less more in the order of hundreds but still significant next slide please uh and so the initial idea was uh trim the delta so that's their size cumulative is less than a snapshot so the idea is downloading a gigabyte of"
  },
  {
    "startTime": "00:40:00",
    "text": "deltas is better than downloading two gigabytes of snapshot because it's still less data however ir data based on some rough calculation is uh changing too slowly and so a client that is running three years behind on ripe would die would still prefer deltas and would try to download 250 000 of them which obviously doesn't scale so optimizing for size does not work here next slide please so the current new plan is uh we expire fast after 24 hours so anyone who is more than 24 hours behind has to reinitialize from the snapshot upside is this is simple you might still have 1400 downloads if you're a day behind although for many databases it would be less we feel that it would be a good balance between allowing catcher preventing excessive downloads and simplicity also good to remember is this is all automatic in nrtm version 3 this is all manual like an operator has to actively start the the fresh redownloading process another idea we had is delta irrigation where we aggregate older ones into larger blocks that are a single download and can be processed in bulk it's more optimal it's more complex personally i don't like it so much but of course we're also open to other ideas next slide please so the state is uh the author of the draft uh ed works on the database team at ripe ncc and i am the author and maintainer of ird version four so the authors we are also the people who needs to work on implementation so there's support from there uh the right database working group uh i've also presented a broad strokes of this in a off session and that was generally supported so"
  },
  {
    "startTime": "00:42:01",
    "text": "there's support in other places also for at least the general concept and ideas it was posted on the mating list there hasn't been any feedback yet and i would like to propose this draft for working group adoption and that's it thank you thank you so much sasha the reason i invited sasha specifically to the grow working group is that from all the ietf working groups grow has a history of mingling with irr related topics so for instance in end of 2015 we published rfc 76a2 considerations for internet routing registries there has not been done in the ietf any prior work on nrtm so nrtm version 3 is a two-page specification hosted on the the ripe website so from that perspective it felt appropriate to to bring it to this working group uh and the chairs will bring the request to the mailing list to guard interest let's go through some questions i see ben and jeff cued up hi sasha ben madison from work online um thank you for working on this it's really really long overdue um there are some really confusing topics that i have to take new recruits through um and what to do when an rtm version three breaks is i think probably the worst of it um so it's really nice to see someone who's actively working on this it looks i haven't i i i read a really really early markdown version of this that i came across somewhere but i haven't read the most recent draft but i think from what you've described it sounds like a sane solution to the to the problem"
  },
  {
    "startTime": "00:44:00",
    "text": "one thing that i found slightly confusing is the the term session id because that seems like it's used not so much to identify a session between a server and a particular client as to identify the base from which a delta is taken so it's kind of identifying the current the current snapshot that's most recent so i think maybe a change of terminology there would make that less confusing um the i had one suggestion about how to deal with the trust anchor discovery problem um that's a little bit less hand wavy than kind of hoping that everybody knows that rad b is radbeed.net which is probably true it's probably not a terrible assumption but it's it's maybe not very robust one of the problems as an operator that mirrors irr data is there's not really a good list of things that one ought to be mirroring and there's not really a good list as a consumer of transit services for example of where am i which databases can i register my things in and expect them to be generally available to anyone who i care about and that's maybe a that may be a problem we can solve at the same time as this by having um by having an eye on a registry which is fairly permissive in terms of its you know its policies but where people can actually go and register source names um and that can then be mapped into the dns somehow or you know there's a whole bunch of one once you've got a registry of unique names like that and there's a mapping between source and somewhere to go then a whole bunch of possible solutions to that problem start presenting themselves yeah i i do like the ayana rs3 idea i think we had it briefly but then i was thinking like what if i"
  },
  {
    "startTime": "00:46:01",
    "text": "email ayanna and i say hey i'm i'm ripe and here's the new key that should be used for update notification file and we're hosting it on this domain now which would also then need some kind of verification process but i think there are there are definitely ways to approach that this is sort of the the shortened version but i agree with you also like just in terms of what registries are out there and and like i sometimes have struggle finding like what red streaks are out there so i think the inner registry is uh interesting yeah i think that if the if the content the initial contents of that registry is bootstrapped in the draft with kind of you know the databases that are out there and are a thing then the you know the the the competing for the same source name problem probably doesn't really arise because it would only be new entrants or much much smaller databases that come after the fact asking for new names there are not a lot of new irr databases being stood up in 2022 i'm going to cut the cue after rudiger folk ben you have an action item writes an internet draft defining an ayanna registry and some procedures around it that's called featurescope uh jeff house hi this is jeff sasha i have a question um last time i worked on this type of technology was back in 1999 for radb so things have obviously evolved significantly past that point and i'm not aware of them at that time one of the problems around the snapshot versus the incremental diffs that you get was a dual tension between the diffs basically encoding the transactions that have passed through the server people were interested in this for historical and other auditing"
  },
  {
    "startTime": "00:48:01",
    "text": "reasons and the intention of being able to quickly resynchronize when things you know broke and fell out of sync this happened especially in those days quite a bit because the software is the reliability of the indices let's just say we're not very good at the time for the work that you're doing right now is the intention to try to reduce the amount of the delta files based on just strictly transaction load or is it a desire to simply limit the amount of traffic that you're expecting to see on the servers um well traffic on the servers is is probably not the main concern the the the issue here is that if we allow a client to catch up with delta files after three years it'll take forever like the client will do this automatically it'll find that all the deltas are still there but i don't immediately know of stuff my head how long it would take but downloading 250 000 separate files over http is going to take a while so we are not serving the client their goal is get the client up to speeds as fast as reasonable without excessive data transfer basically so that's why we want to place limits on how far back a client is allowed to go on this okay this is not actually going to help just downloading a snapshot is going to be faster at some point i completely agreed uh one of the other pieces of the tension was finding out what version effectively a given server is running for a given database was a non-standardized item has that changed in the interim sorry can you repeat the question so as an example uh the delta file gives you basically individual versions so if you're up to delta 100 you know that this is as far as you"
  },
  {
    "startTime": "00:50:00",
    "text": "happen to be in sync for this database um at the time i remember that ird for redb did have the ability to tell you what version it thought it was at for itself i don't recall if this actually got standardized the motivation is that if i'm running a local cache i could actually use that to compare versus maybe the remote cache um it it's kind of it's a little bit standardized like many things in ireland but in rtm v4 that would be the snapshot file so the snapshots sorry update notification file so whatever the update notification file says the latest version is that's latest version that was published there is to catch i suppose that what the server is running at right this second could be newer because it might take up to a minute for a change to be pushed out um okay or is that the kind of gap you're asking about i i think that is in the lines of what i'm asking about if it was the case that the manifest file that's reported uh is provided a conventional consistency because within a minute you'll get the newest data that's probably a reasonable thing if a fully standardized mechanism to query the database version number is not present that might be a thing to spend a little bit additional standardization time at because it allows a local cache mechanism to decide does it have data that is not fresh enough for some strange reason yeah yeah ird will also offer this because we have some non-standard queries right now they become sort of standard partially once they get implemented in ird version 4 because there's there's uh right tb is the only other actively developed implementation uh but yeah there will be also direct"
  },
  {
    "startTime": "00:52:01",
    "text": "queries but yeah the idea is this update notification file if you compare this to what your local version has then you'll know whether or not your mirroring is running up to date also we'll be able to actually detect errors so that will be a big improvement that if your local mirror cannot update that it can actually tell you that it can update rather than producing errors all the time that may not be actual errors as you have with version three the detection of local errors would be great i remember that at the time a significant problem during the mirroring process uh using one of your other example slides if you received an object that could not successfully be parsed locally because the implementations were different this led to potential situations where objects were out of sync yeah thank you for your time i think jeff in ird version 3 and nrcm version 3 you refer to the serials to corrupt the distance between local locally cached data and what the remote server has and in the nrtm version for notification file that is called the version so i pulled that slide up you see version three in nrtm version three lingo would be serial free okay now everybody is confused and again this is because i'm asking about technology that i've not done the appropriate homework for commenting on this presentation in an informed fashion and uh thank you for educating next up jarrett's um i'm looking at the clock a little bit so please keep the comments brief yeah so i guess i'm a little bit concerned about the one minute uh snapshot requirement is the reason why it isn't kind of done on demand based on when there's actually a change uh you know or for the uh you know for the"
  },
  {
    "startTime": "00:54:00",
    "text": "deltas and such because that that seems like having that always misunderstanding then snapshots are more rare because they're very large deltas are one minute but only if there were changes if your ir database never changes the only thing you have to do is update this update notification file which is very small just to sort of clients you know like there's someone still publishing to this to this endpoint yeah no changes means you don't you don't generate anything okay and then the second concern i have is about uh whether or not ayanna is the right place for there to be a registry for services that may not exist in the future because i think many of us have seen irr databases come online and go away over time and going and sticking it in a registry seems a lot more permanent than what actually exists in the operational space please talk to ben he will figure out all those concerns rudiger retired backbone engineer uh i wanted to jump on europe's remark that nrtm never had an official standardized standardized definition [Music] at least not ietf as far as i remember there has been for quarter of a century irr schema definition done in itf as far as i can tell no excess protocol no on the wire protocol so far as i can tell has ever been standardized in ietf and the existing de facto registry does not even include the information"
  },
  {
    "startTime": "00:56:02",
    "text": "what software is run by the various registries which is necessary for tuning or selecting your client code for successfully accessing the stuff it's not only this i know it by heart from the time when i still was working not not quite sure not quite sure uh whether this will actually be fixed uh before the thing is forgotten and uh replaced by something else and better yeah i did mention that nrtm never has been standardized by the ietf but given the history of ietf in irr i felt that nrcm version 4 might be an uh find an appropriate home here but we'll discuss this on the mailing list in the working group call for adoption the reason the offers are here is is to make something better than a two-page pdf hidden on a website but make a proper document that is easy to read and understand sasha thank you so much uh for your presentation and information uh i think we are gonna move on to the last presentation of the grow session hey hello good to see you where on this planet are you i'm in colombia very early okay it's not"
  },
  {
    "startTime": "00:58:02",
    "text": "too early so we are we're in a hurry right or or we are not tell me uh we're we started like three minutes late so we'll end like six minutes late right perfect so can you go into the next slide please um so what we are proposing in this draft is basically a young module for com for managing bmp on routers why not uh well the idea is to have a standard way of doing that bmp sounds like a simple protocol but is it well simple protocol to configure and manage but is it let's figure out ourselves while having these discussions the next one please um so what the model has basically i mean are the items to configure and monitor vmp on devices that is uh well configure your stations the connectivity for your stations the bmp session parameters um i like to highlight two things that probably are not so common between the models of the vendors that at least we have read um first is an action to clear the to clear the session with the bmp station uh well that's basically it and the second part is that we are we try to be very explicit in how we configure what we call the bmp sources um and that is we right now have already uh uh five remotes on bmb the the latest three were standardized um just a few months ago so you have to be explicit on whether to say you this remote is enabled for the station then for others families the same so for every address families you don't take there's no default you have to enable every others family and for the rib modes that are actually"
  },
  {
    "startTime": "01:00:01",
    "text": "not a single rib but multiple ribs per pier then we also would like to be explicit that is you can def so you you enable the peers that you want to send information from or to uh explicitly you can select that individually so by using the by reusing the remote address from the bgp module uh also by the type also you can define which peers you want to to select based on the type of beer uh here we are also reusing the um the bgp peer type from the bgpa module so you can say please send me the information from all the external peers for the internals and so on um because we also needed a way of um of of especially saying we want all peers that's why we also added uh an enum with a with a single value called appears in the vgp mode and the bmp module in this module uh that you can use to say okay you'll send me everything for every year we probably will discuss this a bit more in the next iterations of the module but let's see next one please so we already had a good feedback on this thank you very much for to team jeffrey and tom for this um we already addressed some of them some of the issues uh mostly the ones from tom that were very low thinking fruits and some of them very clear mistakes in this version that we already uploaded versions 0.2 i'm not going to go into the details uh next one please yeah so we do have some some pending points um that we promised to tackle in the next version uh tim mentioned the vmp session options initialization delay backup times uh we will actually re take a look again to all the modules"
  },
  {
    "startTime": "01:02:00",
    "text": "from the vendors that for for configuring bmp and see what else we might be missing to try to add them um jeffrey mentioned the tcp module that is um that is um i mean we can really leverage that module to try to another invent the wheel uh how to use it we're really not sure that for instance we could actually copy the four the four um the four tuple uh connection from there uh it's not in a grouping so maybe we can just copy it or i don't know or we'll see how we can integrate it and maybe and then we can discuss it all together units for stats where to place the module in the routing tree uh this can be important so we so if we for instance uh we put in under network instance then we can you know we can use the we can directly um we can directly monitor those the network instance from there or we can put the network instance in a bmp source so where to place the model the module the model is um it's a good question to have and of course adding examples to i mean to enlighten these trade-offs uh next one please john so this is it uh well grove works on the vmp and we have been working in the last few years about this so i think it makes sense to have this draft in the group but i also let you guys discuss that besides that if you guys have any other questions or comments guys and girls [Music] thank you um jeff has you're up first uh so yes i absolutely think we should adopt this i agree that there's gonna be a little bit of churn as we figure out how do we actually monitor the various"
  },
  {
    "startTime": "01:04:01",
    "text": "address families within networking it's going to be i think when we're modeling challenges we're actually going through a similar effort through that in my employer right now jennifer the second item is about the tcp integration partially what being discussed here is do you want to actually do something model the connection is something that is a little copy and paste in a lot of cases that can make sense many other cases part of the reason to point you towards the tcp module and potentially longer term discussion towards the itf key chain module is you'll want to figure out how authentication actually rolls into this so if you're running like tcp ao or tls or something else similar for the sessions you'll want to model that not only for configuration purposes but you know what your operational state is for that that's it thank you and i agree with jeffrey next up yeah i think this is a useful work uh really helpful for the configuration of the bmp uh my uh brief comment is that uh it is better to consider the alignment with the the pgp model like the uh maybe it is first based on the instance and then peers and ribs follow the because that user of the bmp young will be also the users for the bgp models so that the alignment between these two models will be very helpful second one is also based on the young model design in the bjp model it may reduce the amount of configurations in"
  },
  {
    "startTime": "01:06:01",
    "text": "some circum circumstances but for each uh rape you may need to with this current model you may need to configure the different peers for different ribs but with if you follow the b2pm model style you can configure the peer then the rib and rebound can just follow it under the peer model that is uh yeah for some more detailed comments we can maybe have some further discussion of flying thank you thank you and and our purpose here is to to reuse the bgp module as much as possible i mean we try maybe we are missing some we're having some gaps but there is yeah so indeed address families and peers and even peer types are right now reference than the vgp module when when we find a location into the into the routing tree we might be even be able to make it more direct yeah but that's that's the day okay thanks thank you um all right so the to-do item for the chairs appears to be to issue a call for working group adoption uh this would be i think the first time the grow working group has any involvement with yang so there there might be a bit of a learning curve for some of us at least for for me myself but together we are strong um john thank you so much for this presentation and this concludes the grow session at iatf 113 i hope to see all of you at iatf 114 in philadelphia and a big thank you to the meat echo team i have to say this has been the smoothest running hybrid session i have been part of so"
  },
  {
    "startTime": "01:08:00",
    "text": "folks behind the camera thank you very much um well go enjoy your break and see you next time thank you i'll do that"
  }
]
