[
  {
    "startTime": "00:00:11",
    "text": "Alright. It is 9:30. So good morning, everyone. And welcome to Prague. This is IETF 118. And this is the content delivery networks interconnection working group. So if that's where you intend to be, then you're in the right place. My name is Sanjay Mishra, and I'm joined here with my cochair Kevin Ma, and good morning and very early good morning to some of the folks. And probably good afternoon, some folks that are in a different time zone, on the near the east of the sun. Alright. So, we get started here. Let's see. Note well, this is a reminder of IETF policies that are in effect on topics such as patents and code code of conduct. Please familiarize yourself This is just a linked towards where you can, read yourself. Please make sure that you follow the, IETF policies. And as a reminder, by participating in the IETF, you do agree to follow the IITF processes and policies. And make sure that you you read through, everything that is here. And then, note very well as well. That the IETF meetings in virtual meetings and mailing lists are intended for professional collaboration and and networking. As defined in the IT of guidelines for code of conduct IETF anti harassment policy and also the end anti harassment procedures. Which are documented in RFC 7776. If you have any concerns about bill observed behavior. Please talk to the inputs team"
  },
  {
    "startTime": "00:02:00",
    "text": "were available here in the IDF or we have the email. Just I guess, couple of set of reminders. Moving on, these are the tips for those that are in person And also, those are remote. So I think everybody that needed to be on is at least on So these instructions are sort of really not as useful when you're already in the meeting. So I'm gonna skip these And the agenda is available on, on the link that you see there. Along with the chair slides and any any any other slides that participants have provided And then look, let's look at the, working group milestones. Kevin, you want to walk through these, or shall I walk this room? Sure. You can go ahead. Alright. So so we've got, some of the working group drafts that are coming close to point where we think we can, have them submitted to the IESG And we're looking at, graph that you see there is already, has been submitted to the ISG in the working group last call. After the working group last call, CDN extensions for HTTPS Acme Star. So that's already, and we've received comments on, from the reviewers. Then there are a couple of other drafts that we think, should be ready and we're targeting to have them, go into the submit for specification that is, in December. So we one is the capacity extension, And the second one is the, the HTTPS TLS sub cert delegation. So these 2, are on the docket today also, but we're hoping that these might be ready for, submitting to the IES gene. And then outside of that, we're targeting, one document in February of 2024 which is the, RFC 8007bis"
  },
  {
    "startTime": "00:04:03",
    "text": "it's been open for quite a while, and there's been a lot of work there as well. So the, the target is February 2024 for that specification And then leading on in December 2024, we've got that 3 working group drafts, we're targeting December and of course, these can be sooner. But that's that's what the chairs are expecting that we we should be able to finish and wrap these up. And that includes the Edge controlled metadata. The cash control metadata and the protected secrets metadata. And that basically a set of working group documents as of now. And then if nothing else that gets added into the working group drafts, then we in April 2025 make a we make a decision about re chartering or dissolving the working group. Alright. With that said, here's the, proposed agenda we have today. Number 1, I do want to ask if there are any minute takers that can volunteer the session is recorded. We just want to make sure that, the important points discussed are recorded. So if there's anyone, any volunteer, Please let me know. Please let us know. I can do it Sunday. Thank you, Kevin. So here's here's what we have today. You've got, 6 drafts that are currently active working group graphs. So we're gonna cover those. Approximately 50 minutes. We have, allocated time for that And then we've got 3 other documents that have been submitted, but are not yet working group draft. So we're gonna go through these today. And not going through the list here, but, as you can see in the list, 6 and +3 documents. And then we have open mic about 20 minutes. We've got a couple of,"
  },
  {
    "startTime": "00:06:00",
    "text": "agenda items there, that Alan will be talking about cash management as well as, named footprint. So we'll cover those and then we'll wrap up the session. Any agenda bashing? Alright. Hearing done. I've got one more item before we move on. So there was an an errata submitted against RFC 8006, Kazuki, had submitted this, and he's made, some corrections into how the original, RFC8006, dealt with the, with the windows, the with the time windows, So he has separated out the windows and and the, action from the 2 And, from the chair's standpoint, we we think this is the the correct correction that has been made But now that we have, our area director here. Just wanted to take your input as well if you have any objections or any any view because this was just a correction of the example, the actual text in the document describing the object is unchanged. Correct? Correct. That's correct. Yeah. Right. So, hi, Francheska here. So, the question is, is this, to mark, verify, or hold for document update. And I feel I think can we just mark it verified? I don't think we were gonna do an update just to correct the example. Yeah. It's more like how important is this Eirata for people implementing this. If it's, like, usually a hold for document update means species, something editorial or some title or something like that. That is not, like, fundamental"
  },
  {
    "startTime": "00:08:00",
    "text": "you know, and then it doesn't mean that there needs to be an update to the document. It's more like, yes, this is correct, but, you know, not fundamental for implementors. Yes. It's it's not, I mean, it's a it's a typo in the example, the, as Glenn mentioned, the actual text of how they implement is correct, so We don't think it's, you know, that they hit. Okay. So maybe I will just, mark it hold for document update. I also wanted to mention another thing about, ACMA document to, or yeah, the one that has passed ISG evaluation. And it's it's waiting on me to do the final approval, and I was just waiting on the author to take the comments from the ISG and submit a new version. Before I did that. So that's why it's it's waiting. Yeah. Yeah. So I did discuss with, with Fred and, he thought he had responded to some of the emails, but, I don't see those at all. So Yeah. Yeah. So I I just had that conversation with him last night that No. Me neither. So maybe Yeah. check the emails and make sure that, the, there are at least been 5 reviewers that have sent their comments, including you So, yeah, that that the author owes response to each of those Right. Okay. And so I don't I I'm not sure yet if there needs to be a revision of the document or not Yes. That there would be revision. It's it's mostly, editorial knits really, so, yep. Okay. I will just mark it that there is going to be a revision. And then after that's done, I can approve and move to publication. Thank you. Thank you Alright. So With that, let's move on to the first item on the agenda. And Let's see. Pick up the next stack here,"
  },
  {
    "startTime": "00:10:17",
    "text": "Ben, do you have a hand raised? I I'm first on the agenda, I believe. So I was clicking the slide share button. It doesn't appear to actually do anything. Other than put my hand up. So I figured it would let let me take control of the slide but but that doesn't appear to be how it works. I can do that, but, let me so I I have your slides up. And I can I can drive Okay? Well, if you could flip to the first slide, please. Alright. So capacity capability, advertisement, ex extensions. Also known as capacity insights. The whole point of this draft for those of you who, aren't familiar is to provide a feedback mechanism from the down from the downstream to the upstream. To allow the upstream to make traffic delegation decisions. So the downstream CDN can communicate limits a number of different terms such as egret Spitzper2nd, requests per second, also storage counts, things like that. That allows the upstream to decide how much traffic to send to the downstream? Alongside the limits. There's also telemetry, which can provide real time feedback on how much traffic the downstream is seeing. So we're not really gonna go into the the details of the draft here because It's been part of the working group for quite a while now, and it's a mature document. So this is just a high level summary. Go to the next slide, please."
  },
  {
    "startTime": "00:12:04",
    "text": "Alright. So we adopted this draft last year. There is a a new revision, which I put put up for this IETF, after feedback from both Kevin and Sanjay. I think it's in a really good place. I did notice just tonight, a typo in the document. So there's definitely gonna be at least one more revision I'm sure other people will catch some other things with the document, but As far as the the text itself, I think it's it's pretty mature and and ready to go. At least that's my opinion. So I guess I'm just asking the the group here what the next steps are. Are we ready for our last call? Or does anyone have anything major they want to do with this draft before we do that. So I guess that's an open. Yeah. So so, Ben, I think the the document looks in a fairly good shape from what I read, And, you know, I it looks like pretty, pretty well written and and, between, the IT of 117 Kevin had a couple of comments which you've already addressed, I think that the document looks in good shape to me. I apologize. I haven't had a chance to look at the updated draft. I assume you addressed everything. The one open question was about the Ayanna registry, did we decide yay or nay on that don't have a strong opinion, but I remember that was the question from last time. I think it was it was split. And that we were gonna do registry for some of the things, but not all of them. K. That you added in the latest version, I'll I'll have to go back to the text. It's almost it's also 3:30 in the morning here. So"
  },
  {
    "startTime": "00:14:02",
    "text": "Hey. I know. Okay. Yeah. I'll take another look at it. But otherwise, yeah, I think the the draft was in pretty good shape other than that. Okay. Yeah. Sorry. I can't answer that question. Top of my head right now. No worries. We'll we'll take that offline. Assuming it's good, unless anyone any objections, I think we're probably ready for our last call. Okay. that's all you have, man. Right? I don't think Yes. Well, I I guess, my question, what what's the procedure for do a vote on the mailing list, or how does that work? Yeah. We will send out a a last call notice on the mailing list and, and take it from there. Right. Okay. Thanks, Ben. That's it for this slide deck, man. Alright. So let's move on to the delegated credentials. Okay. Hello? Can you hear me? Yes. Okay. So, update on the delegated credential draft. Can you go to style. So just to recap on the scope, so the draft specifies how to use delegated credentials and defines 2 objects, 1 MI, 1 FCI. And, But in describing how to use them, in in in CDNI, So there's an arrow on the side. So it's not a draft anymore. The, subsidly gated credential. It's an RSC. And, yeah, so they have 2 objects defined. Next slide. So the the biggest update since now meeting is, that there was pre review from, sector. And so they pointed out that there's, to this"
  },
  {
    "startTime": "00:16:02",
    "text": "an optional property where you can, where the, upstream CDN can provide a private teacher's downstream CDN, and the, review, said that And so he proposed 2 ways of addressing that. And, so after a few exchanges with him, we came to this proposal, which is now on the new draft where we specify that if the private property is used, then it must be encrypted using, some, Josiejweenvelope And, the encryption key can be announced in FCI delegated credential objects. So doing so, the, well, the private will never, go in clear text over the wire and, Well, and I think this addresses the review from from So next slide, and just as a recap so that on those two objects that are defined in the draft. So we have the FCI dedicated credential where you can the Downstreams again announces how many indicated credential, it supports us, and it can provide this, private encryption key. It's an option property, And then in the MI dedicated credential objects, it's basically an array of dedicated credential. With this optional private key, which has been, encrypted using the key provided in in the Fci object. And that's it, basically. And Yeah. And so the question is is are we ready for our working group last call? So, I'll jump in here. I did a review of the draft yesterday. So I think"
  },
  {
    "startTime": "00:18:02",
    "text": "principally, you it looks like the the security review that, you received and I see that you have added those changes And I know you have also offline communicated, with the security reviewer. And, so just make sure that you also do that in the a mailing list and make sure that the changes that you have made are sufficient, you know, from the security review point of view. Outside of that I reviewed the draft and, the changes you have made in terms of the, ensuring that there's the, encryption that looks fine. And I've I've got, several comments, but there are there are all editorial, for most purposes, I have a couple of clarifying questions also, which we can just look into the mailing list. We can respond those in the mailing list. Because I just sent those, late yesterday. But I think overall, the the draft is looking, once you have you know, updated the draft, the the the comments. I think it's it's looking good to move forward Okay. I know Kevin has to review as well. I agree. I I think it's I think the the new text looks okay. It would be good to have Mike just confirm that on the list. If we could send a ping to him, And then, Otherwise, I think it's in pretty good shape once we address Sanjay's comments. Okay. Okay. So I will, ping Mike on the list. I will address your comments, Sanjay and, we'll do a new version with the all the units, correct Great. And then I think we're probably ready for last call. Thanks, Kristoff. Thank you. Alright. Let's"
  },
  {
    "startTime": "00:20:01",
    "text": "Move to the next draft here. Alright. Let's see if I can go to the mic and make sure I can, flip the chart as well. So I'm gonna present this for Neil. He is not in the meeting today. Unfortunately. So I will give a quick update. Chair is moving. So let's see here. Alright. So this so right now, we have version 9 that is out. And, we did a quick succession of 6, 7, and 8. Then from 8 to 9, And really the the big difference between, version 9 now and version 8 is that, we got some comments from Ayanna and, So version 8 to 9 really only reflects comments that we got from INA, and they were mostly clarification type of things and and making sure that the the wording is correct so that ion INI is not confused about what is the actual text of the document versus we had some erroneous references that got fixed for example, we but pointing to RFC 8007. Where it should be to the new RFC. So we change the text in section 6 to 6.2.6.1. There was one change. And then, there was a bulk change in sections 112 through 11 7. And that, again, we he had picked up the language from the original 8007. Which talked about,"
  },
  {
    "startTime": "00:22:00",
    "text": "adding the subregistry within the registry. And, Ayanna pointed at ours, pointed out to us that we should really not be using that. And then updated that to have the registry added into the registry group. So that was really the difference. And, you can also and then there were a bunch of nets in the document editorial type of changes that we did. And that if you wanted to see just what changed, you can just look at the diff of the two files. Okay. And then more comments from Ayanna. So on version 9, we got some more comments. And, this is again, this has to just do with, how we have, used the text. So the text could be confusing as to what INA needs to do versus, the things that are just part of the text, but not not tied to having Ayanna do any action. So particularly on section 11.2 of version 9, we use that we are the definition is being repeated, but what is really meant is that we're if we're using the trigger action as a trigger spec, and we're taking the, but we're not changing the meaning of the thing. So that's what was being meant, but the way it came out, the text was confusing. And that confused INA. So what we need to do is make sure that we delineate the of what is required of INA versus what what is the text So, I've given an example here of how we will go ahead and change the text there. And Okay. then there's, another issue from Ayanna was that, And this is I I wanna also, ask the, the group here as well as to how we should handle it. Basically, INA is saying that"
  },
  {
    "startTime": "00:24:01",
    "text": "In some cases, we have defined, altogether almost all in registry except there was one case where we we did not. So the question is that move we we should either say that we should call out that Our references to 8007 has been updated except for this one, or or we update all the references in the new document and and I we can go either way, but I wanted to see if there's any preference Should we go one way or the other? Kevin, do you have any thoughts on that? I'm sorry? So, basically, on the the issue number 2 that Ayanna has is that on the payload types, we have not updated that in the version 9. So either we we say that the payload types remain the same as they are in RFC at 7 or we basically use the new RFC number that we would have, and bring the payload types in the new RFC. I think the existing payload types are already registered to 8007, the new payload types, the V2 payload type, should be registered in this one using this RFC. Right? Is that correct? Yeah. Okay. Yes. I think the new one should be registered registered with the new RFC. Yep. I think that that sounds like, what we should do, and, we'll just clean that up. And did I lose the connection take care of the slides? I'll Kevin, Kevin, do you wanna take, I have to reconnect. Looks like I lost the connection on the network. Sure. And when I get back to the desk, I'll I'll reconnect I don't know if I can."
  },
  {
    "startTime": "00:26:01",
    "text": "Hold on a second there. Alright. It still is working. So, and then the the last issue is that again, with subregistry, there are we corrected that in version but there are 2 other references where we have subregistries particularly in sections 11.211.7. So All that is required is to basically remove the sub registry and just say that registries are being created this registry group. So that's just a minor change. So after the Ayanna, changes are done, what else is outstanding, So there are, I see there are 3 things that are still outstanding. One is, there's been email exchange back and forth with Alan about things that he's looking to do in in cash management and and there are, options that he wants to extend within the, current 8007bis. So we'll we'll just, work with Alan to get that sorted out. And so that's one. And the second is, Kevin, you get review yesterday on version 9. So a lot of comments there. So we just need to fix those, comments And then, the any other that we find throughout the document, fix those So so I think my my sense is that, buyer sometime early to mid December, we should have a version 10 out. Having, worked with Al Anon what needs to be added. And then incorporating all your comments, Kevin, as well as any other knits. So by mid December, I think we should be we should be able to come out with a green version And if everything goes well, then maybe we can, have the working group last call."
  },
  {
    "startTime": "00:28:02",
    "text": "And I think that's all I have here on my slides. So Sanjay, I think, yeah, I I think the draft looks pretty good. I did a full didn't do a full review. I didn't go over the Ayanna section in the exam. Post post post post post post post post thinking those may change, we we can go over those again at the end. I think the big question is Alan's comments and whether those are gonna make significant changes. The doc has already a a large doc. And so if we can handle those as extensions, in in a separate probably easier, but if if there are fundamental changes, yeah, we need to make sure that we That's it, those into the base protocol. Yeah. Yeah. So we we just need to have, set up some working session with over the coming weeks and then, sort it out Okay. Thank you, Sanjay. Thank you. Alright. But that, let's go through the metadata model. We've got 3 documents, that are working group drafts, and then will transition over to after those 3, we'll transition over to the new set of draft that have come in So I think Ben, your first Yep. So this, yeah, the the stack is gonna cover 5 different drafts. 3 of them have been adopted by this working group. 2 of them are brand new. And we'll go through each of them in turn. So you'll be able to hear about the details for each of these drafts. Go to the next slide. So I'm gonna start off by talking about protected secret metadata. So the purpose of this document is to allow the advertisement"
  },
  {
    "startTime": "00:30:01",
    "text": "and the MI interface to embed secret values, that need to be encrypted so they're not in plain text transmitted with the rest of the configuration. This can be used for things like encryption keys, and credentials, So we'll see an example of that, later when I presented that back about the logging draft that was recently submitted. I have a side there with an example of the my secret value object. So this this draft got a great review from Kevin. So I addressed a whole lot of that feedback there's a detailed reply on the mailing list addressing each of those items. The document has been largely cleaned up. And brought in compliance with those nets. We still wanna do some sequence diagrams in the document to make the workflow a bit clearer because the the plain textual description can be somewhat confusing. And then there's still the open question of whether or not to keep the FCI objects, those the the capability objects that merely wrap the MI objects So Kevin raised the point that they seem redundant. There's nothing in the spec that prohibits using an MI object as a capability type But I couldn't find any prior examples of that use. So It's not prohibited, but it's also not used anywhere as far as I'm aware someone can point out a place where it's used. So I'm not against it. I just want everyone to be aware before we do this, that it's without precedent. So I agree. I don't think we did it anywhere else because when the original spec were written,"
  },
  {
    "startTime": "00:32:02",
    "text": "you know, is all already pre laid out. I don't see any reason why we shouldn't it's just an opaque identifier as far as things are concerned. I agree. You know, we did use FCI.nmi. But, I'm fine with it. I'd rather not have the redundancy. I don't know if anyone that else has strong feelings. Yeah. And I I I agree with you. So the, like, the reason I drafted it with them AI projects was just to kind of follow the form of other capability types. But your point, is quite valid and You're right. The the objects are redundant. Anyone have any thoughts? If not, I would say go for it, Ben. Okay. Well, yeah, Then I I will, I'll eliminate those in the next draft then. Glenn says in the chat, I think the FCI wrapper actually makes it clear. S, Okay. Or maybe this needs some debate. Not just one opinion, but maybe we should take it to the mailing list. Yeah. I think I think separate that out into a separate email because the the response with all the other comments is really big. It is quite large. Yeah. Yeah. Yeah. Okay. Yeah. I'll I'll do that. And, anyone who has thoughts, we can we can keep a thread on the mailing list about it. Alrighty. I think that's it. Protected secrets metadata unless there are any other questions about this draft? Thanks, Ben. Gonna come up next. Next slide. K. So, cash control metadata This document's been kicking around for a while, certainly within the SVTA working group, And, it's now, you know, adopted by the working group here."
  },
  {
    "startTime": "00:34:03",
    "text": "It's got a lot of also a lot of feedback from Kevin. Thank you very much for that. We've addressed, all of Kevin's feedback, and that is, again, in a detailed, response on the mailing list just to refresh everybody's memory the key objects introduced here are objects really for the downstream CDN, to, alter, the cash policies coming out of a up frame, Sudan, and to drive its internal and external caching rules for how it passes headers through. And also ability to bypass caching and to set some policies about how to deal with stale content. And how to deal with errors when they come out of the origin and how you cash or not cash, when you do get errors out of in origin. Some of the significant changes, from Kevin, really clarification of a lot of the definitions of the internal and external policies particularly the as is, policy, which basically says that a downstream CDN needs to keep the essence of the caching rules coming out of an origin. But it need not express them using the exact same HTTP HTTP headers. There's many combinations of HTTP caching headers that affect say the same thing using just slightly different semantics. And we clarified that in the document. We also on the stale content cash policy was a bit of a of, Ponging back and forth between the words revalidate and refresh. I believe we we kind of zeroed in on on on one of those, and we did a little bit of rename to make it clear one of the properties that The failed revalidation delta seconds is the new name And that really is meant as a back off. So if a if a"
  },
  {
    "startTime": "00:36:02",
    "text": "upstream CDN. Excuse me. So downstream CDN is trying to revalidate an stream CDN. And gets errors, it'll back off for a period of time before it goes back and tries again. The document's been reorganized quite a bit to get all the examples in one place and to minimal examples with each MI object, added the Ayanna considerations, which call out the MI objects you're specified, fix some links, cleaned up references, So, we believe this document is ready to go and although I didn't put it in the slide, we'd like to see if this document is also ready for working group last call. That's it. Glenn. I Thanks I apologize. I didn't get a chance to read the updated draft. I did see the the email and that you guys it. So I'm looking forward to taking a look, but I think Otherwise, yeah, we can we can see how the current draft looks. I encourage everyone to go in and read it and and, you know, post their own comments, the list and then We can take it from there. Agree. I will also review these three sets of documents. I think we're ready to move on to the next one, which I believe is Alfonso. Thanks. Hello. Good day, everybody. Yeah, this, edge control metadata that was adopted by the group. Since, IDF117. And then similar to, the the folks, first of all, thanks to Kavima for the review of the draft that we presented. He he get a a bunch of comments, I will try to address all of them in the bedroom that was submitted, as a working group, document, for this meeting."
  },
  {
    "startTime": "00:38:01",
    "text": "I try to, hear, the significant change after Kevin mass comments, that that that could be relevant. But I ask please, be ready to take a look to the draft and please make us much as comment when you can. So from Kevin's comment, well, 1st of all, just, a line that this this document, defines a list of configuration metadata objects that are, meant for controlling edge access, to resources, in and a dumpster CDM mainly. So the, an app in CDN able to configure how, it works downstairs in the end to behave. So for some requests, without contacting, to the absence CDN. And there is some audits regarding how the dumpster CDN should manage the connection to the user that is making the request. So from the comments from Kevin, can add that from one of the audio that is a micros origin policy that is, used for, configuring how the Samsung CDN should manage the had a response header relative to course. There was some doubt about one of the property names that was call applied to all methods. After some discussion, with, in the working open catching working group, on this aspect, we have decided to make a a change not just changing or renaming the property. But, changing the the sense of the default behavior that this expected for this, a micro solution policy object, where and in the previous version, it was supposed that it will apply only to options methods, HTTP options method, And it was required this, applied to all message"
  },
  {
    "startTime": "00:40:02",
    "text": "property set to true, to be applied to every HTTP method. But the with the decided that it was a consensual that this, it was a better behavior where, by default, the course, the full response header were generated by the dumpster CDN. For all the methods and change this to pre flight only, property, whether an absentee CDN wants this, behavior to be applied only to options. HTTP methods. So, yes, not just renaming, but changing the default behavior. That seems to be, a concern so that could be more sweet of a Ford, after announcing CDN's behavior in in the in the productions and measurements. Although that change was related to the, sub object that is the access control or has a property called allow list that was defined previously an MI pattern match, but, as Kevin, pointed in his comments, really, the definition of this property was not a specific, pattern match based on just path but this including, it's it's a string that includes an HTTP Hima plus the domain name. So it was not matching the real definition of m MI Patent Match So we change the definition of the allow list to reflect what is really meant for, and to define how it should be constructed remove this reference to my pattern much. Other changes in the document is that we have reorganized the examples. We have, put us came in comments, a separate section for the examples. So it doesn't seem in the document that only, r4 the the API access control origin. So we have a a separate section for that. And we have other, added a new informatic sample sections"
  },
  {
    "startTime": "00:42:01",
    "text": "because the we we included in the draft version. Some examples based on AMI processing the stages, that is something that is still not, another pet working group document. But, we refer that to the SMTA documentation as is the way we did this is because this kind of examples where you select, some filter or how to define the, MI, allow compressed objects, for specific objects, that could be done using AMI processing the stages. So while this is still not a working group document. We refer that, an informative examples and linked to the sbta documents. I asked, sorry, I answered some questions, from KB about the necessary to send or, safe to distribute, and turn off the objects. That I hope sometime, Kevin is is able to to to read it and to see if Hey, agrees or not. Or we're gonna open up the discussion if you want in the mailing list. And we fixed, the Ayanna considerations, we review all of the links and link to the SVP documents where where necessary, cleaning up the normal from a different references. Also, which in the version of the XML to RFC, 2 version 3. Sometimes mostly is this, as in the previous, I think that maybe we can finish the discussion in the middle at least looking for last call, in this group. Thanks, Alfonso. I've I haven't had a chance to read do this one. I have all three of them on my reading list. I will take a look at the MTS STD question and and respond on the list. Thank you. Thank you."
  },
  {
    "startTime": "00:44:03",
    "text": "Thank you, Alfonso. It will's gonna go up next. Okay. So these so that I guess that the next three documents that we have here are submitted as individual Draftps, So go ahead. Well, well, hear you yet. Don't Will are you muted? Will we not able to hear you? I'll say that I did have an you with meet echo randomly resetting my input device. Partway through the session, and I had to go to the preferences to reset it. You can do that by clicking on, The button that's next to the leave room button on the bottom right of the bar Will is texting me out of band. I think he, is having trouble with the mic. So I think I'll I'll I'll go ahead and speak to this one. Yeah. We'll go ahead and do that. One second."
  },
  {
    "startTime": "00:46:03",
    "text": "It's a loud keyboard noise here. Oh, sorry. That was me. I'll refrain from that. Okay. Yes. So I'll go ahead and take this And, Will will just chime in on the chat if he's got anything. Yeah, so Will and I worked on this together. All of this is mostly his work. So, this is work that we had coming back a couple of years now. Had presented a large, draft with a whole pile of metadata objects coming out of SVTA. We're Since then, we've carved it up into pieces, as you've been seeing, This is now the piece that is, only focusing on this expression language, malmeditated expression language, and the expression language really serves a couple of purposes. It's to define expressions used for matching. These expressions always just return a bullion the typical use case for these is you'll see in the examples is really to met often to match against an HTTP header value or a query program to determine if you know, metadata such as caching rules should be applied. The other use case is what we're calling a value expression. And that would be used to dynamically construct a value that might be used to say, create or synthesize a response header or a dynamic response maybe pasting together a few elements of a of a of of the request, to synthesize some new response header for This is not a full touring machine. This is not a programming language. It's a very simple expression language for these matches and values. Next slide, please. Yeah. So this is, just this comes out of the, document. Just to sort of show the richness of what we've done here. The key variables here are rec and rest"
  },
  {
    "startTime": "00:48:02",
    "text": "with very common for the request and response. And this shows out in the expression language, you can access the request URI, the path, extract a particular query parameter from the path all the typical things one would expect in in know, web server HTTP request and response processing. There is a, set of built in functions as well that you can put in these expressions to do string matching, a regular expression matching, replacing, etcetera, pulling a query parameter out. That may be a very common thing in CDN world actually or open cashing world is to extract a query parameter when you're making a cache key things to this effect. Pulling particular elements out of the path is often very common. Maybe you have to pull one of the elements out of the path to use that as part of a cash key. Or, some other rule access controls may be driven off of this, for example. Next slide, please. Yeah. Here's a few examples of these expressions and some of them in context of some of the other work we've done just in the upper left here, very simple match expression, to match on request and just a, you know, sort of a synthetic example here of matching on the user agent and the referrer if you had that combination of matching is true, then maybe you could do something like accept or reject the response the request, for example, this is in the lower left here as an expression used in the con in the in the, along with, computing a cache key. This is from the cash control document. The one we reviewed earlier So you can dynamically set a cache key in this very simple example making it the just a force lower case of the request URI. Many, in many cases, CDNs and Opencap systems need to"
  },
  {
    "startTime": "00:50:01",
    "text": "create a synthetic key based on some aspect of the request this is how you can do it. And then here's a value expression and we'll see more of this in the next section in the context of processing stages where, we want to do what we're calling a a response transform, and we wanna add a header here's a value expression that concatenates a few elements from the request. In this case, the user agent and the host. Bit of contrived example, but it just illustrates the kinds of things one can do. Next slide. So, yeah, there is an error handling here for both pile time and run time errors, compile time errors generally would be caught at the moment a configuration, is provided to, you know, to a downstream to an upstream CDN, this would be in CDNI world. This would be know, as part of using the MI interface, to get metadata And typical examples of of compilers might be using it on variable name or an unknown operator, incorrect number of arguments to a function, that sort of a thing. And then at runtime, these errors can happen as well. You know, failure to allocate memory, any sort of error like this and and we just called out in the stand in back that that should result in a 500 error being return return return. Next, Yeah. So we also have defined a, fairly fine grained FCI object to go with this called FCI supported mail features that can be returned in an FCI capability advertisement for a given footprint like any other SCI object And in there, you can define specifically which mail, keywords operators, variables, and built in functions, wall sports. So you could choose to support just a subset of the standard. Next."
  },
  {
    "startTime": "00:52:03",
    "text": "Yep. So I'll pause there. Yeah. So Again, this work on the expression language is going through, many rounds of, of feedback and extension within the SVTA working group and we now would like to call for that being, adopted as a CDNI working group draft. So I'll pause there before we go to the next one. Hi, Glenn. I I have a couple questions. I guess one is I have I apologize. I haven't read the draft is the draft just for the FCI object, or is the draft for the expression language itself. Oh, it has both. So the draft defines the expression language It defines one MI object that goes with it, an MI object to allow you set a variable. From the metadata, and there's one FCI object, which is that the the the capabilities. We thought it was it was a useful to define them all together. In one in one document. Okay. And then I guess my other question that my follow-up is FCI object I understand is certainly within our scope. This the metadata expression language itself does not seem CDNI specific, and I don't know if is this something that should be, you know, HTTP working group or it's it's more HTTP specific, less CDNI specific from from my you know, cursory read of it, and I don't know if anyone else has any thoughts on that. I see Chris going to the mic, and I'll pause there. Chris. Chris. Chris Lemon's Comcast. So It's not entirely, generic it is not CDN specific."
  },
  {
    "startTime": "00:54:00",
    "text": "But it is in a very real way intermediary specific. I think that the tie to the intermediaries might make this a more interested invested and excited group of people to perform the work I'll let the question of whether it's in the charter to perform the work be other for other people. But work gets done where there's excitement. And because this is tied to being an intermediary on the internet, it's pretty integral to the concept of being a CDN. Thanks, Chris. Yes. You knew where I was going with the with the question, whether it fits in our charter or not. Sanjay and I, we probably need to have a discussion with Francesca about that. And maybe we just need to modify the charger, but if if if if If, folks think that this is an interesting thing. I don't know if also, you know, we should take it to dispatch or some other group and shop around the idea whether that makes sense. I don't know if Francesca is still in the room where if she has a thought, I see you're going with the mic. Okay. Hello. Yeah. Just to say, I don't have any additional thought. Yeah. Okay. Thank you. Okay. That that was my question. I I do think it's interesting. I think you know, if if this is the right place to do it, then then That's okay with me. Yeah. I I see the point you're making and and, yeah, I think I think it it warrants further discussion. And just we I didn't put it in the slides here, but we also did include in the draft to BNF there for the language. Okay. I see Sanjay is in the queue."
  },
  {
    "startTime": "00:56:00",
    "text": "Sanjay. Yeah. So so I think, I agree with you, Kevin. And I think we just need to take a look at the draft. And and if if it seems like the the motivation for expression is is more driven by the CDNI than maybe it might be a fit here, and that's what we just need to take a look at it. And And if it seems like the expression language the name, but but really in in principle, what if they're defining actions, commands that, CDNs would, make use of then, you know, that might be a fit here, but I I don't know yet. I see You have is next in the queue. Yes. So my take on this is that yeah, it might be the language more, fairly generic However, for the use case of a CDNI this is something that is, is is required. We can attempt to add many different parameters to the MI model, in order to handle all the use cases that potentially CDS would need to to handle. However, using such a language opens up this domain in order to be able to actually be able to describe a wide variety of actions on on the data. And so my my point is that it's required for city night type of, work. Even if it extends wide wider than the shotted up the That's good."
  },
  {
    "startTime": "00:58:01",
    "text": "Okay. Thank you. Chris. I realized as I sat down that I had missed an important point. This language is required in order for different inter me intermediaries to process things in a, in a transportable and interconnected way. Right? Like, this is part of, of a protocol agreement between components. And that that really strongly suggests to me that it probably wants to be in a group that is concerned with CDN interconnection. And and that's where my vote is. Got it? Alan Arlovich. So I I want to second is excitement. I think it's very powerful, tool. And, Actually, there's, some discussions we had even to extend it even further. I can see this as being more broadly, applicable I think as as sort of as a, expression language may describe, proxy caches more broadly than just was in CDM. Context but I think here here now, I think this is something that we certainly want build, several capabilities on top, and I I would vote for having this adopted. And potentially, if we can kind of look at broader broader context and maybe which will I kind of expect this to be therefore extended beyond those, core features have been proposed so far. I think we have been talking about it so far. But request response. I'll talk later about, named footprints I think we're we're kind of thinking about some extensions, to Mel, in there as well to include actual endpoint."
  },
  {
    "startTime": "01:00:02",
    "text": "But, I guess, once we take it beyond CDM, be more extensions So I think it can be extended, but for this scope. I think this is something that's critical for for for us, to pickup and and and do what's needed for the charter. Okay. I saw Rajeev in the chat also is in favor of extending the trigger if necessary include this work And then I see Alfonso in the queue. A fun day. Yeah. Thank you. Yeah. Maybe I say I'm going to say something similar to what other colleagues are are has been saying. If if if if my point of view is If it's not the language, this language, we will need any other thing. To, do what this language is permitting us in the context of the interconnection between an and a dumpster CDN. So a way that the AppSTIN is able to comfortable with the time stream to do what they want, to do with the request that the dumpster sedan is going to receive. So at. Making making this, expression language, generic, non generic, but that could be used in other context. I think it's shouldn't be a vaccine anyway. But for, in the people that is working in in this context, of CDNs, since pretty good for implementing in our systems. So I will go to to maintain this, this, draft or this language in in this group for that. Okay. Thank you Alfonso. Does anyone else have any other comments I think there's there's clearly support and enthusiasm for this work. So I think Sanjay and I just need to go back and take a look at how this fits in. Yeah. And the reason"
  },
  {
    "startTime": "01:02:00",
    "text": "to this slide is to show, yes, the language may be the syntax is is fairly generic. But these sets of variables and functions are quite specific to the type of HTTP processing CDNs and open caching systems and CDN interchange, aim for. Understood. I think we can then move on to the processing stages 1. Okay. Do you give me on? Did I little too far. go far? Did I go too far? Yeah. A Back back, Good. Okay. So building on the work, of the expression language is a thing we're calling processing stages And, this really is a meth a mechanism to apply metadata basically caching rules and access rules. At the various points, points of a HTTP request flowing through a CDN. And we define 4 specific portions in that pipe that I'll get into in a second of where these things can happen. Typically what what can happen at any of these stages Like I said, it's conditionally applying cashing rules. And those conditions, of course, are expressed through the match expressions that we just looked at. And the other typical thing happening is transforming requests in response And so we'll get into some examples of each of these. And the caveat like the expression language. This is not a programming language. However, It does have some if else constructs, but those are really structured blocks of metadata, and and not, again, not a full touring language in any way. Next slide. Okay. So the four stages that we're talking about here in can see that the illustration, client on the left or the source of the origin on the right, point a when the request comes in from a client"
  },
  {
    "startTime": "01:04:03",
    "text": "no surprise there. That's pretty common stuff. Point b, if if if if It's a cash miss. A request needs to be forwarded upstream. So that's point b as you as your point to make some alterations before you make a request to upstream. Point C is handling the response coming back from the origin. Before you put it into cash and then point d is pulling a response out of cash and serving it to the client. In the case that a cash response is being served, the flow would be a, coming from the client and right to D, serving it right back. So this client response stage does prevent provide an opportunity to alter responses coming out of cash before they go to a client can be very useful in a CDN context. Typical things, as I mentioned, that you would do with these flows would be applying specialized policies, transforming headers. You already talked about most of this stuff. Generating synthetic responses is also another part of this and we'll illustrate some examples. Next slide. Okay. Again, this is all work that we had originally presented a couple of years ago as part of the monster, draft we've caught up in the pieces. So you've seen this model before it's been find a little bit in in the in the year or so that's passed. And, yeah, all of this does fit in within the, generic metadata. Every object you see here is a generic metadata object. Effectively each of those 4 stages is represented as an object and each stage has a match group of if rules and then l for else if rules can be evaluated, cascading in order. And then at each of the stage is the easiest way to think about this is you're either going to apply metadata directly"
  },
  {
    "startTime": "01:06:04",
    "text": "you know, at this stage, set this apple, that sort of a thing or set this rule or you're gonna be alternating an HTTP request. You're gonna be altering the HTTP response. That's generally all this boils down to when you're altering and responses. Typically, you're either adding, replacing between headers. In the response case when you're altering a response, you might be a status code, or you may be generating a complete synthetic response. And, we have an example illustrating that. So, yeah, like I said, all of this does fit within the generic metadata, a framework. Next, Okay. So here's some examples, something that may be typical to do at the client rest request stage And here, we're using, a mel expression to, evaluate the user agent, in this case, to see if the user agent contains the word mobile in it. And in this, again, somewhat contrived example, we might say, alright. If the request is coming from a mobile device, we're gonna kill it and always return a synthetic response. And the synthetic response in this case, we're able to articulate, the headers. So just setting a content type, setting some cast custom, etcetera, that I just made up. Setting a status code of a 405, and then using Mel again, to synthesize a response body, which is a bunch text, if you catenated with the just showing some simple string concatenation here. To synthesize a response Next. K. Here's an example of use of this within this next stage in the processing where it's been a cash miss and we're forwarding a request onto an origin or an upstream CDN. And in this example, were adding a couple of headers and deleting a header."
  },
  {
    "startTime": "01:08:00",
    "text": "This is very common to alter requests before they go on to an origin. So here's a very simple example there. I'll pause just for a second because see something from Rajeev Rajeeami, just go ahead and try it chime in if you want, Rajeev. Yeah. But you add into your add in in queue, and then you can, speak Well, let let him go now or what? Yeah. You can go if he wants. Go now. Yeah. That's fine. We're on the queue. Colever you. Make sure you unmute yourself. If he's having trouble unmuting, maybe we'll Hello? let him come in a little bit later. Yeah. Alright. You you'll get your chance in a moment, Rajeev, so we'll keep going here. Next, You go next slide. There we go. Yep. Okay. Another example here we've showed is this origin response stage, you know, getting a re it was a cache miss, We went to the origin. By the way, we tend to use the words origin source and stream CDN sort of all interchangeably in some of these examples. But So it all is intended to mean the same thing. And and this actually is coupling now the processing stages. With the, cash policy that we that we reviewed earlier on very common use case here, and this actually also shows the match groups. So there's an if rule and an else if rule. So this sort of demonstrates the whole thing really in context. Where I'm looking for the origin response, If it's a 200 out of the response, gonna set cashing policies one way and I didn't get into the details here. And then, else, if it's a 503 or a 504, gonna set cashing policies a different way. This type of structure we see is very common as people started to use this in the real world. Okay. Next. Rajeev, go ahead, Rajeev. Are you good, Rajeev, with you, Mike?"
  },
  {
    "startTime": "01:10:02",
    "text": "Yes. I think you should be able to hear me now. Yes. Perfect. Now I just wanted to bring out the, a point very similar to what Glenn was making that this then becomes a very powerful place for us to implement, you know, lightweight implementations of other standards. So, you know, if we're running a system that supports this kind of open cashing, you know, framework. It allows us to implement other standards like, race data, proxy status, or potentially even CMCD and CMSD in a very lightweight way. To do both decisioning as well as enrichment of these standards without necessarily having to build new components for the Syrian infrastructure. Say, for example, I have an up I as an upstream CBM. I'm looking for a very specific type of enriched variable to be added to CMS. As it's going back down to the client. Right. This allows me to program downstream CDNs to add that enriched variable without having to specifically go to each each individual downstream CDA and then say, hey. I need you guys to build support for this custom specialized variable in your CMS or CMCD Stacks. Right. Yeah. We'd it basically gives a lot of control back to the con the person who's doing the configuration. And this could also be used for also makes it capable of us supporting upcoming standards, which may not yet be public now, like, streaming media tracing, I hope Chris is nodding in the room. But it it basically means that the lag between a standard coming out and us being able to support it is potentially as short as as the amount of time it takes to put a new configuration with the lightweight implementation of that standard together."
  },
  {
    "startTime": "01:12:03",
    "text": "So that that that's basically my point here. I just added myself in the queue. So I think the maybe what I miss and maybe we can just go on the mailing list on on on on on the part where I was not quite clear how the CMCD ties into this. Are you thinking of using the, expansion language to use for CMCD. I couldn't quite get it you know, how that would be how we could tie together. So so so let's say I, as a CDN, have in my at my origin and I'm looking for some specific variables which I'm I'm I'm taking the standard CMCD, and I'm adding a couple of additional variables into that. A typical example for this would be the project that we in of the SVTA around distributed tracing. Okay, where we added certain variables, the PMI and key of, you know, CMI. Which are now in CMCD V2. They're being proposed to be added as standard variables. Right? But in, during our test, we were working on CMCD version 1. It didn't have those variables. So we had to go and modify say the players at their end to, you know, extend their CMCD implementation to add these new variables. Okay. And we were using that CMCD transport to carry those variables throughout the entire workflow. And log them at multiple places. That we can use it as part of our distributed tracing workflow. Now think of a scenario similar to that. Where you're talking of extending by adding additional variables potentially variables with a slightly different type of processing, say, you want to, slice and dice your data points in a slightly different way and have it happen at the point where those data points are being populated into those variables."
  },
  {
    "startTime": "01:14:00",
    "text": "Right? And potentially you know, compute some derived metrics specific to the hop on which that request is currently flowing through and record that derived variable. An additional parameter in one of these standards. You could do all of that. Inside the mail, and then just tag that parameter on more modify the response and send it on its way. And you can do all of this without having the downstream CDN necessarily have to touch or change their CMCD implementation. Yeah. I I think there's possibilities here to use you know, because you can append tenders, for example, the CMSD, which is still in development with CTAWAVE, I could imagine you synthesizing some of the CMS response headers here, for example, or possibly enacting CMCD request headers and doing something interesting with them. So, yeah, I think And and, especially this is very interesting. Also at the client response stage, especially if you're dealing with things like, you know, requests that are being served from you may want to tweak or modify, say, the CMCD headers that's going downstream to the player. For each individual request, which may be different from the original value that you would have recorded at the time of sending out the first request in case. If you don't have this ability basically that value goes to every downstream player. They may be, that may be valid for certain parts, but then we have other parameters that you want to be unique per player. Okay? Or you want to be specific to the at the point where you're you know, timing. Like, for example, a typical example of this is calculated bandwidth. No. No. No. Typically in CMC, the calculated bandwidth is calculated by the player. Based on its measurement of bandwidth"
  },
  {
    "startTime": "01:16:00",
    "text": "going to its, upstream note that's serving if there was a similar parameter in CMSD, it's what bandwidth, the upstream node thinks it has. In the direction of the player. Now that would be something that would vary client to client, but would have been recorded in the case response, with with with the first one. So I've, again, this is just me thinking of the top of my head of potential parameters that you may want to change out you know, as you're sending it out, some of them, if they are part of the base standard, obviously, the downstream CDNs or or case notes CMCD implementation would take care of, but if it's a variable or custom parameter that isn't part of the standard implementation, having the upstream have the ability to configure how that is to be populated is something that I can think of as a use case, for this kind of an special language. Okay. So I think in the interest of time, we'll we'll just move on. We've got few more topics to cover. Yep. Thanks for that, Rajeev. Yeah, next slide, we're pretty much done here. Go to the next slide. Yeah. So you can see how the expression language and the processing stages kind of go together as a pair. I mean, they are independent but they the the main reason for the expression language was to power some of these rich things we saw on processing stages. Yeah, so we feel that, you know, this work is ready. We'd like to see it that is a working group draft. Already did notice one stupid thing in processing stages and the title the word processing has 3 s's instead of 2. So we'll go ahead and fix that next time. But other than that, we'd like to see if this work can be adopted by the working group as a draft. Thanks, Glenn. I think, obviously, there there's interest in this from from Rajeev, at least. I think this one is"
  },
  {
    "startTime": "01:18:01",
    "text": "I have a similar question with respect to, you know, where it fits. I think this one more clearly fits as an intermediary and is is more potentially CDNI specific, but also could be very generic. So so we should discuss that in the same someday and I should discuss that in the same, vein as the as the Mel I think I just wanna get a quick show of hands on on folks who support, you know, particular piece of work I haven't used the new show of hands tool. I see. Yeah. The hand means join queue. Right? Where's show of Sure. Hands up is on the top. Got it. Hold on one sec. Yeah. Alright. Did everyone get a show of hands tool Yes. Okay. And and by default, it itself, it defaults to no opinion. So if if you do have an opinion, either way, just click on it. To make sure that you're voice is recorded. There has been complaining and commentary on other meetings about that default to no opinion. I think that's gonna be changed. Yeah. Yeah. You you start out with, you know, everybody in the room is no opinion. So Okay. Yeah. I'll give it a few more seconds, but it looks like Both are still coming in 14 votes for yes, which is pretty good. So we'll take that under consideration. Sanjay and I will will discuss the charter, and then I think we can take it to the list as well. Unless anyone has any other comments, we are a few minutes behind. So I think we should go ahead and let, and talk about logging extensions. Thanks, Glenn."
  },
  {
    "startTime": "01:20:01",
    "text": "Thank you. Thanks, Glenn. Okay. So we have logging. Alright. Thank you. If you want, I can try to pass you the the, if you wanted to slide, drive the slide. Oh, it's only a couple of slides. So I think it's like it's like four slides, so it shouldn't be that big of a deal. If we could just go to the first slide. Yep. Okay. So logging, we already have, some logging Defined as part of CDNI with 7937 it has a very specific format with a set list of data fields, an atombasedindex doesn't really tell you how to retrieve any of this stuff. It just defines the formats. It's been around for a while, but It has proven to be insufficient to meet the needs of CDN operators. So as as part of some work in SVTA, We did a requirement survey. From across a a fair number of companies, including upstream content originators, CDN Providers and vendors of CDN Software to determine what are the current requirements in the industry for CDN logging. As part of that, survey, we identified, the needs to support different log formats, a bunch of a pretty long list of different data fields. And"
  },
  {
    "startTime": "01:22:01",
    "text": "modern transport mechanisms. So it was insufficient just to specify the formats. We also need the ability to advertise and to configure on the upstream to downstream side, how those logs are delivered. Both pulled by the, by the upstream from the downstream and pushed to the upstream from the downstream you you know, we need bidirectional support for transport mechanisms. In addition to all of that, We also need the ability to comply with my modern privacy legislation and regulations, so we require the ability to ophascate certain log fields that contain personally identifiable information. In addition to other values that may be sensitive for other reasons. Could go to the next slide. So as part of this work and putting this old draft together, and it was quite a long effort in the, you know, over a year of work. We've defined First, at the high level, a number of different file formats. So no longer are we limited to that ELF derivative we can now support the JSON whitespace delimited put a buff, and importantly, we can also support transmission of tarballs that contain multiple log files. And alongside those log files, we can also have metadata So you can have a JSON file that lives alongside a log file of any format So you can have a, you know, a new line delimited log file with CSV log log records, without any headers And you can have a file that lives alongside that that contains all of the metadata about that file. For instance, the a time range when that file"
  },
  {
    "startTime": "01:24:00",
    "text": "you know, that that log file covers any particular transformation operations that were applied against fields in that file references to external services that contain encryption keys. For fields in that file and that sort of thing. And that's completely separate from the log file itself. Though it can be embedded in the case of, the JSON container. We also, specify a laundry list of log fields. So the field definitions from 7937 were insufficient The this draft specifies A list of fields. Some of them, are holdovers 7937 many of them are new, the definitions are all, for the most part new. And then those are organized into different record sets. So the draft currently defines a minimal standard and extended that minimal set is kind of focused on the The smallest file size. So something like a billing use case where you don't need all of e extra data, that, the standard format gives you. And then we also have the extended format, which includes basically every field. So it's exhaustive. Once you have all of your your records, in a file, you might also want to apply those transformation operations I just talked about. So This works both ways. The downstream can specify a sequence of operations that have been applied to fields. So for instance, the downstream might truncate Network addresses, And, there's no option for the stream to receive the full network address of the client. That would be part of the advertisement"
  },
  {
    "startTime": "01:26:01",
    "text": "On the other side, the upstream might want to configure the logs that are received from the downstream with certain operations applied. For instance, encrypting sensitive data that should only be visible to certain parties. So these work both ways, the downstream can optionally support those mechanisms. So it's not not required. Pretty much all of this can be optionally supported inside of the advertisement. And then We have a number of mechanisms for shipping logs. So this draft defines support for s 3 SFTP and Kafka, alongside the legacy mechanism of that at Adam based index, which now also in this draft, has a a built in discovery mechanism that's part of the advertisement to, to advertise the endpoint for where to actually retrieve those log files. So if we go to the next slide, there's just an example here of what the logging metadata looks like. So in this example, The upstream is transmitting configuration to the downstream. To tell it to ship logs to a particular s 3 bucket name the file with the file names in a certain format. Using a defined record type. So those that record type during corresponds to a combination of our format and a record set So there is a there is a small error in this current draft, which I'll just point out which is that some of those those record type strings have, incorrect names. They they have a open caching identifier that's part of those that should not be part of that draft. So that'll get corrected. The other thing we see here in this example is use of MI secret value So that access key secret property is an MI secret value object."
  },
  {
    "startTime": "01:28:01",
    "text": "That contains a reference to a defined secret store, with the path to retrieve the secret from that external store. So that that's a use case for that protected secrets, metadata draft. Could we go to the next slide? So Despite all the work that went into this, you know, as I said, it was a lengthy effort. We couldn't we couldn't cover everything. So we've we've kind of put in the stuff we could get done, which is sufficient all to cover some very common use cases. You know, and fills fills a very big gap in the, the set of CDNI configuration But there's still a lot of work to do. So the biggest thing is supporting custom definitions, for formats and fields. And particularly derive fields. So you might have, for instance, geolocation fields derived from IP address or, operating system field derived from user agent, that type of thing. So those you know, all of that is not in the current draft. Everything you see on the slide here, but that stuff that's being worked on. So it might be you know, a future version of this draft, depending on when that comes versus when this how this draft moves along in the working group, or it could be separate draft that extend the functionality here in the same way this draft extends to functionality of 7937. So, I'll kind of pause there because that's do it. That that's the explanation I don't know if anyone has any questions about this draft. If anyone's actually given in to read through yet, I know it it's quite large and got posted at the last minute. Right at the deadline here. Rajiv, go ahead."
  },
  {
    "startTime": "01:30:04",
    "text": "Yeah. I just wanted to chime in with support for the draft and also saying that as, you know, these standards come more and more widely adopted and more and more CDNs and operators you know, and small case providers start getting interconnected you are going to have a need to have more automated transfer of all such most of it in today's standards would require a lot more manual coordination between the parties and, in my opinion, the biggest reason to have this significantly automated is for billing. Because, eventually you want an environment where people can use spare capacity and other CDNs and charge for you know, the actual traffic that they deliver. And doing any sort of billing like that. Is going to be impossible unless there is an exchange of data on what was actually delivered. I either. Yeah. And and I'll and I'll say that, Rajeev, that the That'll happen anyway. So, you know, if this draft didn't exist, then the problem is if The whole of this work still needs to happen anyway, it would just happen outside the context of No. If if this company didn't exist, every pair of parties would basically find their own solution to Exactly. Yeah. There'd be proprietary mechanism. For for all of the participants. Right. Right? Okay. I'm gonna throw up another poll really quickly just to see who has read this draft. I have not had a chance to read the draft yet. I apologize. I think, I guess, Ben, so your your proposal is take the draft as"
  },
  {
    "startTime": "01:32:00",
    "text": "is, there will be either additions to it as it moves along through the working group or possibly, you know, new stuff that will come. I I mean, I I think guess it depends on the timeline as you know, and what the responses from people who wanna contribute here on the CDNI side. Because work is con is continuing with a group on the SVTA that is building this draft. And that's gonna that's gonna continue. So whether you know, if if this one, you know, if we if this moves along, then, you know, maybe that that future work will just be additional drafts. If there's lots of contribution happening on this side as well, then, you know, we'll have to we'll have to merge it together and figure something out, I guess. Okay. Yeah. I I guess I guess let's see is my is my response to to your your question. No. No. Understood. I mean, I think it's good. This is the first step that's presented here. See who's interest as much, interest we get. Yep. Okay. Awesome. Thank you. And they'll close the poll. It's about half and half. There's a half dozen people have read it so I I encourage folks to go and read the draft. I will also go and read the draft. I think the the issues raised that you raised been are are important ones and and you know, the the original specification does lack certain capabilities which which understandably we meet. Yeah. I'm I'm I'm happy to answer any questions that anyone has whether you wanna ask publicly on the mailing list or if you just want private clarification, I'm I'm happy to make my self available to help you understand, anything regarding this draft, whether motivation or implementation. Yeah. And I I would encourage that those, you know, discussions happen in the meeting list because I think it'll be useful, if there are questions that people are asking"
  },
  {
    "startTime": "01:34:03",
    "text": "that'll also help us understand that, you know, what's the interest. Alright. Thank you, Ben. Thank you, Ben. Alright. Alright. So I think this brings us to the open mic session. And we've got a couple of items here. You can come up here too. Yeah. So I think I need to load I have the name foot. Okay. It's it's all together. Right? Yes. Okay. 1. Alright. For is all yours. Yeah. So, this is kind of a brief introduction of, cash management interface effort, that, we've been working on that the SVTA for less, so let's say, 18 months now, maybe more. So I want to introduce the concept and also talk about, plans for bringing, this effort to, CDNI. So, the kind of Cash management is sort of, an obvious topic, and there will some some history kind of within CDNI Literature NSVTA actually to try and, define this, what we find now that relacking kind of, practical, I, definition of, just industry standard interface for standard cash management operations. That, wouldn't enable ops from CDNs"
  },
  {
    "startTime": "01:36:00",
    "text": "to, do content repositioning, invalidation and purge of content. The the kind of benefit is clear is what is mostly now in the industry. Sort of manual or semi manual process. So, having such interface would, facilitate automation, I think also benefit to any automation would certainly, as a result benefit, scale. So more integrations would be possible. It could have been in the ecosystem was automated interface like that. The goal is kind of certainly to support, multi CDN environment, So that means that multiple DCGNs talking to multiple UCDNs, And, also We want to, kinda win in the effort to spend basically all types of CDNs even though kind of the the effort It's primarily driven by open cashing CDNs, but the goal is kind of to, publish something with the industry broad and would apply to public CDNs as well. Allowing sort of common interface to cover all types of CDN, in the ecosystem today. So that's kind of 1st and foremost. Second, second uh-uh driver is, I think we're looking at the use case where we have, regionalized CDMs So to enable kind of, UCDNs to manage content across multiple regions. Place content and manage cash. So imagine DCDN that has, multiple kind of sub geographies that it manages. The on the common umbrella. Like, next Mitsubation's case, we we we cover is performance optimization, So where UCDN would share some, cash object, information that will enable DCDN enhance the scale. It's, caching efficiency. To something that we call cash hits. We're basically a way to transmit"
  },
  {
    "startTime": "01:38:03",
    "text": "information about object without necessarily transmitting object itself. And cash management seems like a good good vehicle and framework to do that. And last, but not least, looking at highly distributed CDNs was at storage and limited storage capacity. So within cash management, there's, special support that's needed for quota management. So, ability to, define kind of a managed limited, limited storage and also a use case for catalog replication. So it's kinda as opposed to, let's say, traditional and mainstream, kind of proxy cash, also an ability to replicate catalog of objects to the edge. So that's sort of why next slide. Okay. I'll just do it here. Yep. So So, high level, interface architecture. So, DCDM on the left, kind of multitude of cash notes. We have an interface sort of, common interface, managing all of them cash notes. And the UCDN on the right. And, we envision kind of 2 types of APIs being exposed one is, trigger based up triggers based API. And, kind of, we are heavily reliant on CDNI trigger V2 effort, which was really, met the bill for everything we're looking for So, and this is a main API. What we see here is kind of adapting, CATV to, API, which is essentially is operations API. So API, which enables UCDM to ask the CDN to execute a synchronization on its behalf and and get results asynchronously. So the key, operations proposition invalidate and merge. What happens with triggers. Additionally, we we, adding additional 1 more API, which has Cash Bucket API"
  },
  {
    "startTime": "01:40:00",
    "text": "which is the API to enable kind of, cash virtualization. So we're adding a concept of cash bucket is the next slide. And, the concept is basically to enable DCDM UCDN actually to allocate through this API sort of cash subsets or containers of cash objects. And then match a configuration, to those cash objects. And that can by sort of, config subsection. So I can see specific, pattern match being, match to, let's say, to, store images in a separate set of content and I can manage, storage quota for that. Separately. So that's one kind of doing that by, I think, content type is one use case. Another is, footprint, where a buck so where I can allocate, for same even, path match or pet or match, I can allocate and match different cash checks, cash buckets, depending on the geography and I can therefore manage proposition version validate and cash, within different DCD and footprints, separately this way. So that's kind of this kind of a high level. This is, this is virtualization capability. Right? So I can instead talking about one ManolisaCash. We're now talking about variety of cash stores or cash buckets. Within the CDM. Can be managed by, by UCDM. Kind of the trigger API comes in the concept of a bucket. So we're not changing the trigger API in any way. Just that in the naming convention, we attaching this to particular bucket Like, when I want to proposition objects or purge, I will need to specify which bucket I'm referring to within the URL. The trigger, trigger API itself is it stays the same. We're exposing a a new API that enables to"
  },
  {
    "startTime": "01:42:00",
    "text": "the UCDM, allocate query, basically query, delete updates, those buckets. And then, within configuration, we can attaching my objects. To to, to cash buckets. So assigning separate subsections of, of configuration to these cash bucket, objects. Next slide. So, when I'm looking at kind of just list of features, so what cash management interface as a spec introduces. So, there's some, so, again, taking on and really, working heavily with CATV 2. Spec, so extensions in there that we're looking to do is kind of introducing kind of non playlist, objectless, So right now, CH speaks about HLS, HSS, and dash. So ability to specify a list of files through sort of media based, formats. We want to add other formats, so just ability to add a list of objects in plain text or JSON. We do introduce 2 new, 2 new types. For prepositioning, several, policies that we want to add. So one is preposition policy, everything that has to do with prepositioning Benwards, concurrency, this list of, I think, 10 to 12 properties. We have around prepositioning. How positioning can be done. And purge. So how do you actually interpret purge, triggers that's got 2 extension policies. Again, meet very nicely with the extension mechanism and framework built into V2. That's great. 3rd is scheduling. I think that's sort of a bit overlaps with time policy. There's an V2 right now. So we have some discussion whether this could should be a separate extension or the same extension, but"
  },
  {
    "startTime": "01:44:04",
    "text": "kind of, taking time policy kind of an extending this using I calendar. Providing more tools for UCDM to schedule those operations like, hey, I want to do this kind of every Sunday. I want to do this but and until like, end of the year, or per should be complete until then this time zone goes I calendar provides kind of powerful capability there that kind of goes beyond, what available in V2. Now, kind of, again, question is that is that to kind of an extension or addition to existing policy, or anyone, other than that, it's clearly an extension. 2 more things. Right? So, with introduction of playlists, we feel that triggers become easy to use, but also easy to break. So when you provide a manifest or a list of manifests, And when you kind of you need to provide back, more more information about handling. Like, okay. You gave me manifest UCDN. IDCDM downloaded that. And this is the objects I have derived from it. So we are in agreement. What is success because when when it was explicit listing, it was easy to see This is a list. I was successful or I failed. Many as a sort of indirect. So we're adding, proposing to add make a list of optional, object lists in the statues. Like, I succeeded and this is the objects I purged or I succeeded in these objects. I propositioned. And if I failed with some of them, here is what happened and why. So kind of, basically, more robust support for, playlist or object list operational risk triggers. We also want to, work with content category this is something that was existing in CGN Literature for a while, not really used because we didn't have really cash management, their effort. There is a kind of a subject in a trigger subject"
  },
  {
    "startTime": "01:46:04",
    "text": "in in the spec going back to the original RFC that the late, allows operations, to be applied to different, basic tags, right, and the mechanism there is there to create tags for objects in the configuration. Like all objects that are matched on the certain configuration subsection can be met matched with static tag called mi grouping. We want to actually do more, and I'll talk about it next. And, by and work with Stags, in the triggers. If objects are tagged, in more ways now that I want to purge, for example, specific asset or specific, quality, I can use, this, CCID as we again, existing mechanism, just just using it more. With object tagging cash buckets. I just, I think, talked about it. So so we want to have ability to manage specific kind of cash subsets instead of just one minute with the cash within the CDN. So, 2 more. So going on, object tagging. Obviously, taking a very important future. So kind of reality of cash management is that you actually manage a lot of So you what you don't want to do, I think, is just rely rely on URL lists or regular expressions. It's not very scalable, And what industry has been doing, you're actually implementing tagging in in private integrations, where, OpsM tags, objects using a header, so server key is is is what what have been sort of used. We want to adopt this mechanism and to allow UCDN to communicate to do to DCDN and say, Hey, I'm gonna send you objects kind of in the proxy chain or in proposition,"
  },
  {
    "startTime": "01:48:00",
    "text": "and I'm gonna have these response headers and you want to look at those response headers and use the values of those headers as tags. You can have multiple facts. So, for example, I can take it manifests. So let's say I have a collection of files on a health I can take it take it as video. I can take it with SSAD. I can tag it with, specific file types within the manifest Well, let's say here, that's a manifest. And all the manifests, the subtitle, and there's a segments and just provide the very kind of elaborate tagging And the way to do this, if we propose, is having a a new object it's kind of extends MI grouping. Hands and name, am I grouping extended? Which will enable staff tagging. And enable this kind of use of header. So I can use a header this header can be a standard one or specific headers that, DCD and UCD and agree on, And this will be kind of basically a metadata object, for that. Similar concepts, for priority. So if we want the UCDN, transmitting it to GCN, some information about object priority and saying, hey. You want this object that's popular. You want to to retain it and maybe don't purge it because maybe you don't see it, but it's gonna be popular. Or the other way around. Here's an object, but I think it's trash. Don't even bother cashing that. So, same mechanism provide a header that, will be configured and that header will communicate priority from UCDM to DCM. Cash hint. I mentioned it before. So a mechanism for, DCDM to cool down or receive information about an object without actually downloading that. So, the spec, prepositions, policy will enable will actually specify what, methods can be used to retrieve an object. And if UCDN allows a head method for the object,"
  },
  {
    "startTime": "01:50:01",
    "text": "is essentially a way for DCD and to pull down kind of the information about the the object size in these custom fields, including priority, without actually pulling down the body. And then DCM may decide later if they want to have this object based on information it received or just, or not. So Cashkin is a mechanism that that using head or optional HTTP method that, we are specifying and, last on the list as reuse of configuration metadata, very valuable configuration object that are, kind of used and are defined in the configuration interface. Specifically, this is, origin access information, we don't want to re re specify that again. In the triggers. So when UCDN comes and asks UCDN to preposition staff it, it may say, well, hey, you have these objects. Already gave you about how to access my origin. Please use that. So we are kind of, basically having a way to to, pull it in So, and highly so how do you want to bring it in? Right? So there we we see right now 3, maybe even 4 documents here. So one is that the thing, the core specs, we want to kind of That's the discussion that Sanjay mentioned to have added to the core draft. Which is not an extension, but kind of core capabilities. Is an argument what specifically will make it, but that's kind of my wish list. And we'll see what makes it out of this discussion. So there, which I think are core core features. Then we'll have, separate draft. We'll have the the the extension policies on top of those that are speced in the core draft adding looks like scheduling recurrence per position on Birch will be 3 more additional extensions."
  },
  {
    "startTime": "01:52:02",
    "text": "And, 3rd is basic cash management into kind of cash management, metadata and API. And I see maybe the cash bucket actually makes it in its its own, draft. It's I think it's it's possible that it'll be kind of separate because it says it's an object, an API, On top of that, and separately, we'll have am I grouping into my gush priority? So that that's the current plan and kind of we'll we'll see how we'll make it, yeah, kind of, make it role and I think the, core draft is something that we want to address now. Questions, comments, Good Chris Lewman's Comcast. Are you familiar with the cash groups and cash and validation APIs work that has been presented in the HTTP best working group. I'm not familiar. What is it about? Hey. It's a cash and validation in purge API. Along with some tags that help you figure out when one when one object, the that's the validation when the the Cash groups. 1, is some tags that help you invalidate or revalidate objects as a group. And the overlap here is significant and nontrivial. It makes me wonder if we're defining something that is for CBN interconnection. Or if it's just for management of a CDN in general. Particularly since the HTTP best working group is looking at things that are very, very, very similar. So that would be, I think, individual cash management, right, so kind of ability. So tool? No. So so the API there is is, a way for it's two pieces. There's a discovery"
  },
  {
    "startTime": "01:54:03",
    "text": "discoverability components so that, you can figure out where the, where the cash is but also are where the where the API endpoints are. But also a mechanism by which you can make an API call a particular format, tell an entire CDN to do whatever CD in magic it needs to do in order to invalidate or purge this particular URI. Right. So I would think that that the, you know, without looking at the body work, I think they but, actually, the it's not question actually to our effort. I think that's a question to CD and I was CI 2v2 effort. Because CA 2 actually talks about invalidation approach. Right. I think that's something that I think we need to kind of probably address right away. So, you know, we just probably figure out how to harmonize that yeah, sort of, because what we are doing really falls out of, like, taking all CATV draft and extending that, right? So so Bye. Kind of, So I think that there's that's, a coordination needs to happen. Yep. So, That's Yep. Wanna take it out. I think Kevin is on the queue as well. Yeah. Thanks, Chris, for bringing that up. We should definitely look I I had one quick clarifying question. With respect to cash buckets, and and so grouping. Are is there something that is in feasible by using URI pattern matching, or is it just that URI pattern matching is too cumbersome and that the grouping mechanism is more efficient. PureF after matching is potentially not even feasible. Things that I'll I'll give just one use case. And, again, that's actually been practicing the industry already. So it's not me. My opinion is that if you're looking at groups that are actually don't have a common URI pattern. Right? That's,"
  },
  {
    "startTime": "01:56:00",
    "text": "or kind of there's no easy overlap. So a great example, I think, was video is basically, manifests all the files that goes into manifest or even more complex manifest plus associated files that you have video and then chunks and then you have subtitles and you have the thumbnails. Right? So you don't have necessarily an easy way of actually combining them into any URI regular or or pack a match. As first. And you're kind of So I would say both and actually, tagging that enables, upstream to actually, create tags that are connected to actually internal workflow. It makes automation so much easier. So you can actually emit a lot of tags when you produce content. And you publish, you can admit those tags. It's mesically, and then you want therefore, to use them for any cash operation. Like, if, for example, I want to basically delete particular video asset. Right? Again, kind of, I think I think in in the in the interest of time, we probably have to move quickly because you have about a minute left, minute and a half to present your, next slide. So I think, unfortunately, questions that you have comments, please put them in the mailing that's a great place for us to make sure that, you know, communications continues. Yeah. And I'm happy to pick it up there. So, name footprint is kind of a it's second go. I think again, motivation didn't change. I presented this before. We need advanced footprint capabilities. I think actually I have new efforts I see in this VTA merging like multicast kind of want to use it. So we see that there's significant support, I think, for this. So, So the the draft date submitted expired. Right? So the is there anything Is there are the key message you wanna convey. Give me a few minutes. Next slide. So, kind of I I don't think it was really picked up, but as a Kevin, you you voiced some some a position to this. So what changed from since our initial draft to that? There some misc, syntax fixes at near, near proposing. If you looked at that,"
  },
  {
    "startTime": "01:58:03",
    "text": "thinking overall supportive of this. We want to add also instead of in addition to pull also push. So DCM capture push, updates on footprints for dynamic footprints. And we also want to support a new, actually, RFC that allow the CDN to self publish its own Jira information for its own is is on, footprint. I think the opposition or I wanna clarify important point I think there was a discussion about either some charter, and I'm hearing charter maybe not the big issue, but I think Alto is a big big thing. So Alto is not named footprint. And I want to really stress it. ELTA is a way for, access provider to publish its topology and cost and so on to facilitate request routing happening on a temporary. It can be CDN driven, like a multi CDN client steering, or it can be peer to peer. This is access provider talking to endpoints that are already have established that they live on that network and want to be network optimal. Name for footprints, is the flip is actually you have a UCDN trying to figure out which DCDNs can use and may have potential multiple candidates. And named footprints is a mechanism to publish those coverage footprints enabling a UCD and then associate specific customers with it and then potentially using calculator. Like, once I have selected, Oh, I want to work with this DCDN. I can maybe go with that inquiry the the associated outdoor that's available. The entrepreneurs come to come before. So that's that's there's no over Yeah. So I so I suggest that maybe you you resubmit version 1 and then we'll have an opportunity to take a look at it and then you know, have some discussions in the in the mailing list. So, I think we're almost at the time. So let me give a microphone to, Kevin, and then if there's any time remaining, I'll I'll time yeah, 10 seconds. Thanks, everybody. Again,"
  },
  {
    "startTime": "02:00:01",
    "text": "as always, please go and read the drafts. Please post your comments to list. Sanjay and I will look at the the adoption requests for the new drafts and otherwise, Thanks for coming safe travels, and we'll see you guys and everyone all at the next AhF. Sanjay. Yes. Thanks everybody. And please please review the drafts. And put your comments in the mailing list. You, everybody. Thanks everybody. Bye everyone. Take care. Bye bye. This is a quick ad for, anyone familiar with common access code and work. The and their your and Yes. From Yes, sir."
  }
]
