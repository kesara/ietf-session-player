[
  {
    "startTime": "00:00:04",
    "text": "Oh okay we\u0027re in business "
  },
  {
    "startTime": "00:03:05",
    "text": "sorry about starting a a little bit late because we actually have a very full agenda so my name is Aaron Falk this is the hot RFC lightning talk series I\u0027m happy that you all have come this is I think the fourth or maybe fifth time that we\u0027ve run this the idea of this session is to have a series of introductory talks to give folks who are doing something new in the IETF a way to get the word out and so it\u0027s especially good for things that cross areas are new to the IETF maybe coming in from the IRT F or a boss that sort of thing to just give a very short synopsis with some coordinates on how to get involved or learn more if you\u0027re interested we have about 22 talks tonight so we\u0027ve got a very full agenda still should come in under the two-hour slots so if you\u0027ve made dinner plans I think you\u0027ll still be able to to make them but the way that we\u0027re going to do that is through very strict time limits so we\u0027re using the large set time management method and so at the end of four minutes if the speaker hasn\u0027t concluded you should hear this sound at which point I\u0027d like everybody in the room to start clapping and thank our speaker very good guys have got the right idea now all that comes down to my ability to push the button correctly let\u0027s see on the material site you should find all the slides that you\u0027re gonna see tonight as well as abstracts that summarize the talks and include the coordinates for finding out more information so there\u0027s not gonna be any time for a QA yeah it\u0027s really intended to be something that\u0027s very concise give you the flavor of something new move on to the next thing I hope you find it interesting and so Brian if you would come up our first speaker and I\u0027ll get your slides up okay we all have you pressed your button yet okay so on the left you see some users on the right you see some services on the objective of what we\u0027re talking about here is to discuss a new way of possibly connecting the users to services I click - nothing happened thank you what anyway why entering the IP service is no longer a safe assumption in the internet they will "
  },
  {
    "startTime": "00:06:05",
    "text": "usually in middleboxes users want specific services they don\u0027t want IP addresses or URLs and I Spees want to provide some services and they want to redirect the user to other services that was the wrong one so what use the service type request turned on IP address to forward packets at the network edge we\u0027re not talking about the core of the network abstract a service as something called a service action type which is a small integer indicating the service is a very generic idea near the user the packets are routed by the service action type and not by the address and of course before you ask the obvious question right here each one of the available services which is how it turns out to work backwards so here are some examples of service action types reach ability on ipv6 reach ability on ipv4 discovery service computation service a storage service and there\u0027s a list of others in the draft packets are and the format derived from ipv6 this is a low-level protocol but there\u0027s a service action type instead of a destination address because users don\u0027t care about destination addresses and there are other goodies that look like a lair violation because actually this thing is intentionally a lair violation this entire code is probably not worth looking at more important there is a side meeting discussion on Wednesday morning 8:30 not in the church but in the room called not read AM we\u0027re also discussing other drafts that I\u0027m going to talk about in the second four minutes and I\u0027m done hello it\u0027s me again with the same with the same co-authors this is a bit more down-to-earth why are we talking about this in edge deployments of IOT in particular the physical MTU and the bitrate Oh in some cases extremely low that\u0027s well known so packet size matters a lot he edge routers the edge routers may be constrained themselves that has an other implications besides the problem of bandwidth and period header decompression and header compression had a decompression use resources 128 bit addresses used memory so for a certain class advertised there is a strong case for both reducing packet size and reducing the head of decompression and compression overhead what why are you doing by using shorter addresses murti on the shorter addresses not "
  },
  {
    "startTime": "00:09:05",
    "text": "transmitting unnecessary bytes and avoiding any fancy compression decompression algorithms at the level of processing the IP header how you define an address length n within a domain wall addresses within the domain or assumed prefix in front of that of 128 - n bits and there\u0027s lots of bit bytes and the headers that you can get rid of if you think about it and we use a flexible header encoding octet to tell the lowest layer of software how the header has been encoded so you might end up with a complete ID v6 header that consists of a low length NextEra hop limit and a truncated destination address because it turns out in the right conditions all the other bits and pieces in the header aren\u0027t actually any use and those are the bits that you expect the this constraint router to look at where six slow working group tomorrow and same side meeting discussion in Notre Dame on Wednesday end before we go to our next speaker I just want to let folks know that this session is being streamed live and there\u0027s going to be a video available on YouTube so if you want to point somebody to this there\u0027ll be YouTube coordinates and usual slap okay hello everyone today I\u0027m introducing a new technology called instant congestion assessment Network so what\u0027s a main target problem first the traffic in real networks especially metro network is always heavily unbalanced although we have ecmp or using built such kind of technologies surely they don\u0027t really work very well and second the traffic is always changing so fast and traditional traffic engineering technology cannot adapt the traffic in real-time so with the ICANN technology we can provide guaranteed never load-balanced in real-time millisecond level and as well as SLA assurance and high availability these actually share the same core technology but with different purposes and for the use case one the network imbalance we have already implement a prototype based "
  },
  {
    "startTime": "00:12:08",
    "text": "on commercial hardware router and according to our test in laboratory the whole network terpil could be increased up to 30 percentage which is a ridiculous resort and the PC principle of the icon technology that we use the I think controller to calculate multiple paths between each pair of ingress and egress router and after that the rotors will by themselves adjust the flows between the multiple paths based on the continuous measurement of the path congestion seach situation this is done in a very fast manner in millisecond level so welcome to join the discussion with more details in tears and RTG GG and you can also check the backup slides of this presentation and please feel free to contact with me with any questions thanks hi so Adam and Bob and I are working with various international standard setting bodies and government agencies on a really critical problem go next slide about yeah so it\u0027s just this a small unmanned air vehicle can very rapidly get close to a crowd or a piece of critical infrastructure without being observed on route and some public safety person armed with only something that he\u0027s likely to be carrying needs to be able to quickly identify that thing is it a friend is it a fall can we look up its flight plan maybe can we establish communications with its operator and know for sure that it\u0027s the operator of that aircraft that we\u0027re talking with this problem of mapping a physical location to a trustworthy identity seems to me related to the identifier locator split in the internet and where we\u0027re trying to go between a logical location and an identity and so we\u0027re looking at the use of hip to do this and I\u0027m gonna let a hip expert take the rest of the time speaking with us to an atom we\u0027ve worked out value of hits as the remote ID for you ace it provides a trustworthy identity to pair with physical and logical location data as you know hits our value ipv6 addresses can be used directly over the broadcast of broadcast media if that\u0027s what you\u0027re transmitting "
  },
  {
    "startTime": "00:15:08",
    "text": "like Bluetooth Bluetooth the five is one of the thighs for this with prove ownership using the high for the signature for mobility and multihoming so in case you\u0027re using multiple files on this particular you a would supported you can use the hip face IPSec for secure communication if that\u0027s what you desire need and we can come up to a secure registration of the full identity bootstrap on a first come first owned for the ID that\u0027s what\u0027s available there but it\u0027s not exactly what\u0027s needed for this case there\u0027s some work needs to be done the original design of hip talked about hierarchal hits I\u0027ve done a draft on this since then and because of ownership and other registry issues hierarchal hits will definitely be a value for this we need to have an expanded registration process of what\u0027s in the current on documents in terms of a federated registrated registration authorities to tying the various metadata the actual physical location and ownership and other information about the device some of the new crypto support which is out there taking advantage of seaboard where we\u0027re appropriate and since they keep on in the work talking oh ah look at hip as a whole off method that\u0027s we\u0027ve seen so far there will be other work to be determined as we go through this process but we feel that this is a very good fit of technology and a requirement situation and we have a sign meeting scheduled for tomorrow afternoon during the PM 3 time slot and it\u0027s in room C 2 for our side meeting and there\u0027s a mailing list that\u0027s right things main list TM - our ID at IETF core which is just set up today for the folks in the back there are a few seats in the front and a few seats over against the wall over there if you are trying to get in hello Sharon from mixer I wanna talk Sharon from mixer I want to talk to you about a cool problem and RFC draft that solves it it has to do with the sharing of physical information of a on the road between cars and it makes use of grid of the earth actually gonna go grid of the earth called h3 and an overlay network which can make those tiles of the earth addressable cordless so just as a background on the problem we distribute hundreds or thousands of cameras each "
  },
  {
    "startTime": "00:18:08",
    "text": "week to drivers for them to drive around they\u0027re paired with their phones they do it because of insurance in motivations and the insurers want them to do that but as a result we actually have tens of thousands of eyes crawling the physical space and the public domain in every major US city and because of the peering to the phone it\u0027s not just cameras they actually understand what they see with the eye and they are connected using a network so when we want all these mobility client agents roaming the streets to communicate what they see the connected car industry had two options for us one is the offline network tell us about like a stop sign that fell or started by a tree or construction zone which is impaired made out of permit but it doesn\u0027t tell you if that construction cone is generating problems right now or if that traffic sign is okay but the traffic light is out right now so there is a real-time Network option mostly for safety and but that\u0027s a peer-to-peer network so for example for safety situations not for something that I\u0027m about to hit right now but something which let\u0027s say I\u0027m driving a hundred kilometers an hour to a pileup or to a slowdown I\u0027m turning a corner in a junction in a city to a double parked vehicle and our unloading vehicle a tough situation for me to negotiate out of and the course traffic sees it clearly there\u0027s no clear way for me to get that information if the car that the last car just drove away three seconds ago and won\u0027t get the information or may get multiple and conflicting informations from cars I don\u0027t know and I don\u0027t want to know so the solution is to pack up all these annotations as you drive in and assign it to a tile that tile as a ID based on the location in the earth but also it\u0027s transit to an eID which is a lisp address which is now make it something I can send packets to this addressing scheme allows me to share information between let\u0027s say mobility car going here mobility car going there this cars is this guy cars future and vice versa they can publish and subscribe to it in tests we were able to communicate a red light bridge another four milliseconds a bit of a lab conditions between a camera on the junctions and all the cars approaching and affected by it so if you\u0027re interested it\u0027s discussed in the "
  },
  {
    "startTime": "00:21:08",
    "text": "list working group tomorrow and happy to have more participants [Applause] [Music] hi I\u0027m Ronnie Evan and on this car I\u0027ll present the open congestion control architecture with network operation for our DMA fabric the motivation for this work is for data center that they\u0027re hiding speeds that are making network transfer complete faster in fewer out it is short data burst require low latency while longer data transfer requires high throughput so these are two requirement there the our DNA is the common protocol in data center network however the congestion control is not optimized for different user generated interoperability allowing for flexibility running an optimized congestion method in the network interface card in having fast congestion notification to the sender can improve the our DMA data trend transfer it\u0027s common in a deficit of Network the TCP traffic is mixed with the our DMA traffic and the causes conflicts between priorities between them and what we\u0027re saying is there a better method that could solve the problems mentioned above while addressing interoperability so that our DMA traffic can be treated it more efficiently so we have two documents on the open control architectures the requirement document and the architectural document there is why not discuss the problems of the country mode direct memory access fabric congestion handling technology and the requirement for better performance and the architecture propose an open control architecture of host networks for the high-performance RDMA fabric to provide better congestion and the league for HPC and distributed storage application the architecture itself is seen in this slide there are there\u0027s the sender the reaction point in the receiver is the notification point but the switch can serve bosses the congestion point but also is the congestion point but also can provide notification so there\u0027s can be a net to me control Channel and of course they make to me control channel that will provide the information to allow the sender to response better and faster so the design configuration is provide better information about the congestion stay stay to the sender faster and more accurate from the network and notify the sender the reaction point from their network support it can support proactive "
  },
  {
    "startTime": "00:24:09",
    "text": "response from the notification point and support our DMA transport different to our DJ transport so this what we are talking about is something that would be transport agnostic and support multiplex the traffic of our DNA in TCP we did some already some experimental tests and we are having a side meeting on tomorrow in Notre Dame room and of course if you want to discuss it with me this is my coordinates thank you I am Condon and if we had coordinated better I probably would have gone just before Ronnie because this is very similar topic but I\u0027m kind of approaching it from a little bit of a more higher level not a specific solution Ronnie has some some drafts that that describe that solution someone talked about strat strategies to dramatically improve congestion control and high performance data centers so first of all data center congestion is different than the internet congestion I think we all know that a few handful of transactions can cause a lot coming in from the web can cause a lot of activity inside a data center so data centers have much different environment there\u0027s different bandwidth delay the switches are implemented different and small buffers high-speed links you know then different Internet routers there\u0027s a lot more homogeneity in the network design it\u0027s not so random the traffic is very concentrated servers and storage are all in close proximity and there\u0027s a lot of different the traffic profiles are kind of well known highly coordinated correlated and typically they\u0027re managed with a lot fewer people under a single management domain so all this means that these data center congestion the environment in which it runs is much different than the internet and we know we do internet standards here but but we also do have focused on data center standards DC TCP as an example so the data center needs low latency low overhead high efficiency and high throughput so one thing the data center kind of has in common with the Internet is there\u0027s this trend to do more over UDP something like we\u0027ve seen a lot of activity with quic for example so what if we you know could do something that that was more sort of quick like but not quick you know as heavy perhaps for specific for the data center and maybe we did something that was Datagram congestion control like but again focused on the congestion problems of the Internet of the data center it would need to be Hardware off loadable but maybe with less emphasis on security and crypto and all the threading kind of stuff that things have it would need to be really common congestion control as described in the previous talk and ideally we need to have the network visibility marking and signaling abilities from the network itself so the "
  },
  {
    "startTime": "00:27:10",
    "text": "ITF has this expertise so let\u0027s leverage and not leave it to the UDP application riders let\u0027s see if we can do something we know datacenter congestion is different the authors of these papers have done a lot of work on congestion trees so there\u0027s kind of two types you know in network and in congestion and it\u0027s constantly moving moving around in cast or in network we\u0027ve got solutions today such as ecmp ecn even even in a lossless environment ecn with priority flow control all of these have various pros and cons but they\u0027re not completely addressing the the needs that we see so some ideas of augmenting ecn with with a data center focus for a UDP layer you know adding more feedback from the switches in the packet headers perhaps you know marking delay inside packets so that we can get really fine grain view of what\u0027s going on being able to figure out is this congestion we\u0027re experiencing right now is it in network or is it in caste you know because maybe we would take different approaches being able to speed up notifications to the source so they can quench you know in a way that addresses it and then implementing fast mechanisms in the switch to respond immediately so so what like to do is discuss the technical approach and feasibility of these ideas in a side meeting so we have a side meeting tomorrow Notre Dame it\u0027s the same one that was announced and we\u0027re also providing remote participation for that and then we\u0027re going to be requesting a ETF mailing list as well so I think I made it we also have a whole bunch of references in this deck if you want to read them thank you there\u0027s room on the floor in the front if you guys want to sit down so high I will presume to walk showing but sure we can leverage an existing networking agents to build service from John Chang in most of her existing deployment service functional trains are controlled by a central control point which computable ideal placement of virtual functions such as IDs firewall and prepare for M raising some program since it creates failure and the network scalability issues it\u0027s oddly interoperable with resistant networks and it under exploit existing protocols or network for instance service function training program is mainly a routing program because you have to route traffic for a set of white bone between two before which medicine ation so what her purpose is to augment her entire entire gateway protocol and make a function aware you know in order to build solution path I will quickly "
  },
  {
    "startTime": "00:30:10",
    "text": "remind how integral from functions you have a gateway which are connecting networks shank combination and building a network view and based on what it a to compute routing tables word for proposes to bind some prefix through a specific function such as first file an IDs allowing to a useful waiting protocol to would function through the total flow through functions and to use any casings to to do AGP matrix to select the functions and other consequence you have a logical network view which is this one where you have a for instance pink nodes which represent for instance a firewall and in the two instance on the 200 tells will be will be different based of so matrix rated for two to be instance if you are interested in a walk where we are doing you can come to a conversation on Thursday and can discuss about that and you can also find the summer walk we have presented in existing conferences if you want Thank You Jeffrey from highways so the purpose of this talk is to find the people she had the same interests as with me too about the theory behind the networking so to clarify the terminology theory as a system of ideas to explain based on general principles so IDF is quite a unique we have many contribution from universities and we even have research am i ah TF but in my personal views there\u0027s a skill and gap in our networking area as a whole so our innovation and the design highly rely on experience I don\u0027t find a well-defined body of knowledge or a set of approaches that can help us to make design choice and understand the trade-off behind those decisions so I\u0027m not the only one have this feeling so these are very interesting paper from Jennifer Luck\u0027s folder Princeton Princeton University he/she coated the some doubts from people inside and outside networking community so is networking a set of protocol acronyms or a keep of head formats or we are just a "
  },
  {
    "startTime": "00:33:10",
    "text": "big a bunch of boxes of course Jennifer defeated as though all these questions elegantly but at the end of the paper she also suggested that we can make the question we ask more precise and the way we answer them more rigorous and the week maybe we can not so much value new problems over deep answers to existing questions we need to encourage more seller and the complete and the deeper research so why IDF so in one way this theory can help IDF to explain and predict the outcomes from new design and facing your problems and also it can help us for can help new generation to inherit and make their own contributions so on the other way why IDF or can can help so we have both rich and very successful experience and expertise in theory we have so many academic participants so why now now we are facing some new requirements such as deterministic and bounded Adelaide services so we may require more theoretical analysis than before so is that the other is imposing IP is proposed to apply Network calculus a kind of queuing Theory to the time sensitive networking problem so there are several useful reference of course this in one way is in one handiest and mathematical foundations and tours and on the other yes the theory of the Adhan hope the seamen proposed a framework long time ago I don\u0027t think I have time to adjust the details but if you are interested contact us me and my friend can learn from China Mobile thank you [Applause] okay this is about software management if you don\u0027t use these standards which is really the entire software industry outside networking so you you you know every every company starts the same way you write a little service we start including more services to do your function and then you learn about micro services it becomes this and of course you get this and of course you need a management plan to to make sense of it it\u0027s all so for each one of those little boxes this is what you have to do today you have to scrape log files to find out if the Services is acting incorrectly "
  },
  {
    "startTime": "00:36:11",
    "text": "you have to write some tool to generate config files deliver it balance the service ok sorry thanks if it has a REST API you have to integrate with that you find performance metrics any which way you can and if it has a security model you got to somehow integrate with that so every single service you have to do this with and um if it looks like a lot of work it is a lot of work but a lot of companies are cheating because they\u0027re finding recipes on the Internet to help them get a jump start or they\u0027re only mapping the pieces that they they think they need before they go into deployment and this is a problem because they find out after deployment they forgot something so clearly this is a lot of work and the standards for yang Andres conf solve this entirely but the industry as a whole and to give you an idea the scope of this problem puppet labs they estimate there are now more people in the management plane than there are in the data plane so more people writing software about software than the software itself solving problems so this is a very large problem and so in 2015 I became aware of these standards and wrote a implementation of the the yang and the rest comp specs in go I started there so I wrote a little my first project was this bartender and it has a Raspberry Pi and some relays and some pumps and it\u0027s got a little interface to make oh the animation work so but I didn\u0027t put it all in restaurants so there\u0027s a yang model for the bartender and you can assign a pump to a particular liquid and even when you make your recipe you\u0027re going through a rest conf and it was really no special tools on the JavaScript to get this to work rest comp really is designed really well to make it palatable to the industry as a whole which is what his design was so and I really like how rest comp has different modules so if you know amazon published a yang for alexa skill i could add that in and all of a sudden you\u0027re saying Alexa make me a mai tai so since then I\u0027ve used this in lots of different industries IOT schools malware detection the standards work really really well but of course that\u0027s only so good so when we\u0027ve arrived is when I can tell say Pedro duty which is a system for alerting you to say hey postgrads when there\u0027s a slow query paged me about it and I didn\u0027t have to involve DevOps I didn\u0027t have to program anything and this is all possible with the standards but none of these tools know about these standards or implementing them so I\u0027m really here to talk about this this problem in industry as a whole see if this problem resonates with anybody I realized I tip is concerned about networking but there\u0027s definitely a bigger hole and I estimate this is there there are actually 10 million developers this could actually help them out so and I\u0027m one of those because without these standards I find using "
  },
  {
    "startTime": "00:39:11",
    "text": "these standards in outside networking it really doesn\u0027t doesn\u0027t really solve the bigger problem so like I said if this is resonates with you reach out to me there\u0027s no working groups on this but maybe next ITF there could um that\u0027s it if the ITF is about anything it\u0027s about making bringing my ties into schools hi everyone I\u0027m here to talk about like aetherium improvement proposals and there\u0027s no time for introduction for just in jumping so as you may know or may not a theorem is the second largest cryptocurrency just based on the market cap there is a possibly the number of developers and tools that are based on that all right the first and hold blockchain DLTS theorem is a home for en su sitio naming services they trying to do that Etha TLD and also do DNS SEC in the blockchain also for IP FS or essential file system applications there are a lot of more apps there so I\u0027m mostly document looking processes here so etherium is one of the healthiest essential dev cycles within amongst the blockchain and cryptocurrency projects we see it far from the perfect from perfect some of the circle and challenges that essential decentralization requires a non-hierarchical in the Adamas cycle and it\u0027s really hard so they have this e IP which is in theorem improvement proposals which was inspired by bitcoin improve a proposal and that was inspired by pet Python enhancement proposals which that also was enjoyed by IETF request for comment and there are some aspects that we dropped on this path we don\u0027t know where exactly but like security consideration section on the IP it\u0027s not there I\u0027m really trying to put add it back and it\u0027s gonna be added in the next month probably so there is some other process this is like the process today I\u0027m gonna go quickly on on these and the slides are there for more details so after discussing in the forums and getting community support the EIP author would add the CIP there so security concession is missing there we\u0027re trying to add it there and then goes to a selected track so the track the core track is actually the consensus protocol and the protocol it\u0027s a really critical one it has resulted in Forks in the network and another controversy there are some others that look ERC if you have heard of tokens security tokens CRC 20 they\u0027re all in this track and there are some other things so the process itself has like four you could say five steps so when it gets a community support it gets the work-in-progress draft and basically they write these usually major major and if it\u0027s a quarry I peonies implementation the miss you thought I didn\u0027t talks about the proof of concept after that it does in the IP number and goes to a draft mode here the EAP author would discuss and further make sure the "
  },
  {
    "startTime": "00:42:12",
    "text": "draft to have any way that actually makes sense and it has some more support and after that it goes to last call this process every iteration takes more than around two weeks and it\u0027s actually the ends up with a call like a conference call and so here mainly they talk about if there are there are any security implementations and that needed to be checked your menu and test tests and it\u0027s more on a non-official one and after that if it\u0027s a courier pikas accepted and all the clients at least three of the clients there like four or five ATM clients need to implement that to get that actually in a final state if it\u0027s not core then it sometimes is standard it just goes to the public to find out state so this is overall what i just talked about and this is the first attempt as far as we know to visualize this and have something to show that this is the process usually and still even with this process it happens on github proposals PR full request everything happens there there\u0027s this form if they\u0027re your magicians that people discuss there and your magicians there for the EIP magician and also this is the call this is like a chord f call that actually the decisions happened there so why am I talking about this so I\u0027ve been involved in also write a process we need that our ITF people to find the gaps and missing pieces in this and in this process and we find modules I\u0027m open to any discussions and comments and this is how you can reach me and I would be happy to talk about anything but watching [Applause] hello everyone my name is Jim I\u0027m from Poway I\u0027m here to discuss what\u0027s the next step of young in I have actually a little bit of background from me I used to share so SM usm in office area who deliver young be the model for era VP in and actually we witnessed a young take off and a phalaris ship but we still feel there\u0027s some problem so that\u0027s why I bring these topical here and so young day tomorrow I\u0027ll get a lot of traction actually operator began to plan to employ a young bear model and but the the reason for that actually young actually not only happy to automate as a networker but also allow operator to peel the more agile service young actually can model the service from the top and also allow you to model the collaboration operation of the device allow you to configure the protocol on the device get a net with set hopper so usually the younger model you are "
  },
  {
    "startTime": "00:45:14",
    "text": "classified them into service layer model and device level model but also in a between we have resource level model they allow you to schedule results to meters as a service requirements from the top and also allow you to to to to program the networker actually make it up to nine will change and so right now in idea more than 260 young they motor actually has be developed in idea and more than 50 obviously and including a TA young Ben Amato and we also see actually more than 100 young did more working with each other proceeded in unite here so which have so many young male model and but the the the problem actually is you know we can reference the integrity vendor in the operated test report we can see actually Medical has widely adopted it but for younger the model still and early into a adoption stage so what\u0027s the reason behind so we see actually because many operate actually you know not engaging idea for this young data model development actually for some operator who already deployed these can technology may not aware I developed this young teen model even for the operator who actually know what I am doing but they don\u0027t know how how this llamada put together to deliver a service to fulfill the service actually so there\u0027s a critical cat actually they were leader the idea of young beta model actually like a sufficient input from the operator so to actually is actually one of the approach a way proposed actually we can define young they the model framework actually to have operator to how to indicate a younger model in the same namespace and so we have a chapter actually posted in OBS authority that will be discussed in okay say session on one Wednesday and try this chapter actually we work together with operators I try to fill this gap to help right operator to provide such guideline how to you know figure out how even a layer model can put together and in addition we we think you know standard work is not enough for some of these you may rely more coordination between okay okay I\u0027m full hon Baker and this is "
  },
  {
    "startTime": "00:48:25",
    "text": "the mathematical mesh oh so internet security is broken it\u0027s broken because users are finding security it\u0027s just too much effort and you can\u0027t solve that by asking them to try harder it\u0027s broken because applications are not solving the real problem I mean like looking at all the data breaches the data at rest breaches we mostly focus on transport and we\u0027ve not actually changed our approach very much since the pgpr days and the pam days we\u0027re still using the same tool box and we\u0027re still using the same limited number of operations so the most address is three core problems device management so you can glue all your devices together so they\u0027re worn gestalt contact management so you can connect all the people that you connect to together and have access to all their public keys on all your devices and a secure control plane messaging which is end-to-end secure and traffic analysis resistant Oh wrong so it\u0027s based on the principle of I\u0027m using more advanced cryptography than in Bruce Schneier book one key cryptography is great des you know you can do a lot with this but two key is better because you can separate out the roles of encryption and decryption if one is good and two is better why don\u0027t we try three four five separate the roles out more and we can do more cryptography and more cryptography means more security yes there\u0027s a bunch of small powerful concepts here I can\u0027t go through these at all but basically there\u0027s five basic technologies here and it\u0027s a grab-bag and they\u0027re all designed to work together but you can also use them a la carte in your projects going to be talking about this at sex dispatched tomorrow at 1:30 and this is the wrong set of slides it seems a she sent in I\u0027m about to start releasing this so if you\u0027ve got strong opinions on it please talk to me before I release it because the minute I have users I\u0027m going to start protecting legacy encode if you want to change anything tilt before I release the code there\u0027s a whole bunch of drafts and the drafts are based on running code that comes from the reference library it\u0027s all in MIT license or C sharp or that good sir and the objective here is to provide people with kind of like a psychic learn for cryptography if you look at the advanced in AI that\u0027s happened over the past ten years that happened after the AI people made it really easy for people to add AI into application with things like pandas "
  },
  {
    "startTime": "00:51:27",
    "text": "and scikit-learn so the reference codes and attempt to do that\u0027s the same thing for cryptography and you\u0027ve got all the same goodness of blockchain pkcs7 PGP x.509 and so on but in a much smaller library because if you make all the systems use a same unified approach you can get rid of a lot of code I\u0027ve got rid of two-thirds of the code over the past two years so meetup so we will talk about sex dispatch tomorrow at 1:30 please be there or talk to me afterwards thank you I\u0027ll upload oh and there\u0027s also going to be podcast explaining each part of this on the web I\u0027m either Luba chef and I really want to talk to you about law packet loss detection in encrypted protocols I\u0027m looking at quick alright I\u0027m a transport guy I love to think of my networks as just dump pipes but really for them to be a dump pipes there could be somebody inside that pipe who is looking for leaks and can find and page them quickly if it\u0027s senior TCP flow in the pipe it\u0027s pretty good she can look at sequence numbers at numbers figure out if there is leak see it if it\u0027s upstream downstream if she is looking at a quick slow not as good there is no really no bids to look at to see if the respect at loss so it\u0027s a I think it\u0027s a problem and there is a propose a solution that uses two bit 1 bit is a cube it stands for square signal it\u0027s very simple sand that\u0027s an essence 64 when you send in packet 64 of them come zero cubed 64 one 64 0 so forth the other packet the other surahs are bit is an else for loss event a bit and it is set when there\u0027s a special unreported loss counter which is greater than zero and unreported loss counter is maintained by the sender when there is a packet that the sender sent and the Penn center deems it lost it increments the counter when the packet with l1 is sent the counter is decremented so if you can see the picture there are two packets in red they\u0027ve been lost about one or TT to one or two or later sender determined they\u0027ve been lost and it sent two "
  },
  {
    "startTime": "00:54:27",
    "text": "packets with l1 okay how can we use that how is it useful so end-to-end loss is pretty simple it\u0027s just a fraction of packets with l equals one bits that absorber observed upstream loss is basically how many bits with a particular Q value are missing from a block once you have downstream and upstream loss you can figure out when you once you have end-to-end and upstream loss you can figure out the downstream loss pretty cool so it\u0027s cool in theory but we decided to test it in practice Akamai\u0027s implemented a scheme based on this in our deployed servers and we\u0027ve been serving quick traffic to some orange and users in a number of countries for for some time and there is data for it actually real world data not simulator or anything else and plenty and if you are interested I hope you are but if you\u0027re interested if you\u0027re an operator or have thoughts about it please see us will be a here Monday tomorrow 8:30 to 9:30 for a side meeting and we\u0027ll talk about it in TS vwg on Thursday that\u0027s going to be focused on protocol details as well as privacy and ossification risk and then on Friday onmyoji will actually present lots and lots of data and talk about it and of course you can talk to us Thanks [Applause] [Music] Rodney I\u0027m broadened I want to talk about zero is not must be zero reserve does not must be zero we all know about these common words that are used throughout our RFC\u0027s there\u0027s a word I\u0027d like to add to that list and that\u0027s the word reserved because it is interpreted differently at times it\u0027s pretty frequently used it\u0027s poorly documented there\u0027s different ideas of exactly what it means and how it\u0027s used depending on in what context it\u0027s used this is is become a problem when it\u0027s when when reserved is treated this must be zero by a receiver and some future thing has come along and go that\u0027s not reserved anymore I want to use that for something else and somebody goes nope that must be zero we\u0027re gonna throw that packet away it\u0027s no good "
  },
  {
    "startTime": "00:57:28",
    "text": "we\u0027re repeatedly running into this problem in protocol implementations in software and almost anything that uses the word reserved so I\u0027m basically trying to bring the idea that we might want to clearly define this thoroughly define the different contexts that it can be used in and what it means in those contexts if they\u0027re this is this is gonna be a one-minute talk if there\u0027s any future discussion if people want to try and talk about let\u0027s codify this let\u0027s make an RFC out of it I\u0027m available I\u0027ll be here all week there\u0027s my email address I\u0027ve got a couple minutes if anybody wants to throw anything out about it right now we can do it do I hear you can I hear a second on that motion should we should I start a draft okay that\u0027s what I wanted to hear thank you Oh hit one enter first lightly hello everyone my name is Stuart Cheshire and some of you may know I\u0027m the creator of zero configuration networking and dinner service discovery and what Apple calls Bonjour I\u0027m sure everybody knows it\u0027s used widely and Apple products what a lot of people don\u0027t realize is it\u0027s now in most Linux distributions it\u0027s used by chromecast it\u0027s on Android and it\u0027s starting Windows 10 it\u0027s even in Microsoft Windows anywhere in your software that you have somewhere for a user to type in an IP address or a host name you can use DNS service discovery to give them a list of options to choose from instead if you have iPhones here you can tap on AirPrint and you pick the printer you want there\u0027s no where to type an IP address if the thing you want doesn\u0027t show up you fix that by fixing the network not by typing in IP addresses on the client devices traditionally this is used peer-to-peer multicast what\u0027s great about that is it requires no infrastructure you just hook up two laptops with an Ethernet cable no switch they can discover each other two phones using peer-to-peer Wi-Fi no access points they can discover each other services that\u0027s great for small networks but it\u0027s inefficient on large networks because it impacts every device on the network even the ones you\u0027re not talking to you right now it\u0027s slow on Wi-Fi because multicast is sent to low rate and multicast SAR batched with the beacon so there\u0027s high latency it\u0027s "
  },
  {
    "startTime": "01:00:28",
    "text": "wasteful of shared wireless spectrum and it\u0027s unreliable because it\u0027s not acknowledged so you have to retransmit which makes it even more wasteful of that precious wireless spectrum with these slow transmissions so we want to discover things that are multiple hops away without flooding the multicast and if you do this with your iPhone today you send a multicast but the printers not nearby we solve that by adding a Discovery proxy your device now makes a TCP connection by sending IP packets multiple hops through that network the discovery proxy can then do the multicast on your behalf and send the answer back you discover the printer you can now make an end-to-end TCP connection and use that we\u0027d love you to get involved you can join the DNS SD mailing list you can check out the code from the IETF hackathon we have an open wrt package for this little open wrt router in about five minutes you can add a discovery proxy to this and have one running on your own home network we\u0027ll be showing this at the hack demo happy hour tomorrow just a cross over there so you can come and see it working for yourself and of course come to our DNS SD work group meeting on Thursday thank you shooting from Maui today I\u0027m going to introduce you one of our new work is a application-aware ipv6 networking so first about the motivation I seen tonight he involves we could say we have already experienced IP the first generation but they are still some challenges for example the isolated the networked islands of the limited program program programmability and most importantly and the network is still on its own and the application and the network are isolated at the carpet and now we have SRA six we could say we are entering a new generation YP the second generation and I sorry six has its own mission and first it is a based on ipv6 so it has the affinity to IP so it could be much easier to integrate the network domains and also it has the programmer ability so it has the programmer programmable fields so you could convey more information from the applications "
  },
  {
    "startTime": "01:03:29",
    "text": "to the network so in that case you could integrate the application and the network make them to work together so here are the ipv6 extension hiders we have the hop by hop and destination options hiders and also the routing header i sorry choose one of this so we have the arguments fields and also that he are we you we could use to convey some information from the applications and that are the foundations for the application aware ipv6 all eyes are basics networking we call it AP + 6 so basically we are actually make use of the ipv6 extension hiders to convey some informations from the applications into the network so the network could make the fine granular traffic operations to do the for example the resort network resource assessment to guarantee the SLA so it could be applied to for example the fixed mobile broadband like the - b2c scenarios and also the mobile broadband and for the solution side we could have the host decide solution that is the application directly put the information into the ipv6 hiders all it could be the network side solutions that is the network edge could attack the application and provide the information about the application and can wing it into the and we are we are going to have a side meeting on Thursday Thursday morning and we have the agenda you could refer refer the related drafts we listed in the side meeting wiki okay thank you [Applause] we\u0027re on the backup USB stick I don\u0027t know why sorry ok yep great my name is "
  },
  {
    "startTime": "01:06:35",
    "text": "Joseph Potvin I\u0027m the executive director for Excel rhythms foundation some colleagues and I have initiated a project called an internet of rules I\u0027ll say right away if you think it\u0027s a terrible name that we should not be calling what we\u0027re doing that please let us know I\u0027ll restrict this to the why and the what of what we\u0027re doing I could explain how there\u0027s running code behind this we\u0027re doing alpha testing right now but I\u0027ve had a very interesting conversation over the last two days as part of the hackathon and there\u0027s lots of different ideas about and good ideas about how to do this next so very happy to see what Rodney was talking about a few sessions here ago we\u0027re actually working on the generalization of how words like must must not required shell and so forth actually get deployed so if you can imagine any IOT implementation and let\u0027s say there\u0027s some Court decision in some province or state and that\u0027s gonna affect privacy rules in terms of how data moves around from in to all sorts of IOT devices exactly how is that new rule going to get deployed you can even say how it\u0027s going to get deployed through the equipment providers how is even that rule expressed and say English or or Spanish going to get deployed to the 45,000 suppliers of these IOT devices this affects issues in money finance Commerce Tax international trade machine control systems internet-based networking whatever it is the gap in this space is so huge it\u0027s hard to see so it\u0027s hard to communicate this sometimes because most people are looking for little gaps this is an enormous gap next so the problem is enormous Lee wasteful error-prone redundancy each of you who is not from Canada when you pay your hotel bill right now you\u0027re actually supposed to be zero rated on the value-added tax but you\u0027re going to pay it and if you were to try to claim it back on the way out good luck to you little rules like that come in and they were just simply not deployable today that\u0027s tax but any of these other domains you have the same kind of problem it requires a domain-specific language which we\u0027ve prototyped right now and not prototype we\u0027ve actually implemented an alpha and an optimized algorithm search we\u0027re not dealing with if-then statements we\u0027re dealing with given X facts con has a context when there\u0027s an input fact for a circumstance then Zed ought to be the case so these are just three facts next the actual software we have deployed begins by interacting with an API there\u0027s a small component piece and auxiliary piece called lichen you can use it or not use it it\u0027s a it\u0027s a reference implementation create your own if you like roll your own that provides the context FAQ and the input info fact up to the server in the server is a distributed set of servers with the collection of "
  },
  {
    "startTime": "01:09:38",
    "text": "algorithms which implement the rules and these algorithms are simple declarative tabular or tuple oriented programs we deliver those back as output facts we do not inject them we stop at the point of delivering back the fact there that there is a rule and here\u0027s what it is and next place so excel go that domain-specific language it\u0027s think of programming in terms of control tables decision tables and so forth with a few reserved words very very minimalist it\u0027s deliberately not turing-complete and it uses all any standard schema when it comes to identifying what industry it is what what jurisdiction it is what product type it is next please intro Libre sorry notice I okay that\u0027s the search engine and then next slide I\u0027m presenting in this room on Tuesday thirty [Applause] [Music] working again hi so I\u0027m gonna talk a little bit about multiple provisioning domains a term that you\u0027ve probably heard and maybe know what it means but I think a lot of people don\u0027t so hence the talk so the point of this is back in the 1990s you had a host it was probably sitting on your desk it\u0027s connected to a network it got DNS and IP addresses somehow from the network and everything just worked that was great good times times have changed and so recently and you know certainly in the 20 teens and even before that it was not uncommon to have a host connected to more than one network typical scenarios VPN is a classic typical scenario but a less well less well understood scenario is when you have a host is connected say a phone for example that\u0027s connected to your cell service provider and to a wireless network which may have a captive portal on it you don\u0027t want your network service to suddenly stop because your connection to the captive portal network so things get a little more complicated when you have to deal with use cases like this that\u0027s a typo but anyway so anyway so so the host so if a host looks up a service using using using the DNS "
  },
  {
    "startTime": "01:12:40",
    "text": "server that it got from from network a it is and then tries to use the answer it got on network B if that service is actually only reachable on network a it\u0027s gonna fail so we need to be able to associate networks we need to be able to associate things like DNS servers and IP prefixes together and of course in the 2020s things are even more exciting this is starting now but but you know you can see there there are routers that you can buy that have both a connector for your ISP and also a cellular backup and you\u0027d like that to be able to work and you also like your devices on the home network to be able to distinguish between the two providers so how do you do that the answer is with provisioning domains the provisioning domain is a connect collection of configuration information that\u0027s known to have come from the same source so in the previous example where we had network a and network B networking and network B were both different provisioning domains and similarly in the 2020s example where we\u0027ve got provider a and provider B those are both also different provisioning domains so how do we communicate with this to the hosts in the 2010s usually we would just notice that we had two network interfaces and so we would be able to set up an ad-hoc provisioning domain we would just assume that information that we got on interface a and interface information that we\u0027ve got an interface B are not interchangeable and and we would just do that automatically without being told that doesn\u0027t work so well if you have a border router and you\u0027re behind the border router and the border router is connected to two different homes so in that case we need something called an explicit for visiting domain and so work has been going on in the ITF recently to make explicit provisioning domains happen so the original work was done in the myth working group we produced a document called the multiple multiple provisioning domain architecture which explained the problem that I just explained to you in quite a bit more detail and more accuracy but didn\u0027t actually solve it and then just recently a number of folks in the interior working group been working on a document called draft and area providing domains discovering provisioning domain names and data so this is using an RA option to explicitly state that this prefix and all the information about this prefix is in its own provisioning domain which has this name and so that work is almost done I\u0027m mostly telling you about this because I think it\u0027s really useful and you want to know please come to inter [Applause] Spencer so Spencer Dawkins and talking a "
  },
  {
    "startTime": "01:16:02",
    "text": "little bit about performance implication of path characteristics this is a Rube Goldberg machine which actually turns out to be a pretty good implementation of what I think a lot of their work paths look like these days so how we got here we did a follow on to the tcp over satellite working group in 1997 to 2000 talking about very long RTT interaction with slow loss recovery we I brought a proposal for a TCP over cellular to the IETF and the ad suggestive structured approach instead of doing TCP over food links Aaron and I co-chaired the pilk working group 1999 to 2004 and we had specific recommendations that we issued as BCPs most of them for specific link characteristics and that was adopted actually by web form version 2 of life was good for a while things have probably changed since 2004 a lot of stuff is on here there\u0027s actually probably more things that have changed that then I didn\u0027t put on the slide things like CD ends and stuff like that but you know it\u0027s been going on ever just to pick one of them well weren\u0027t thinking about multipath at all we were thrilled we could get one path to work so I\u0027d like to do at ITF 105 we had a excited meeting and went out at ITF 104 in the coat lounge and that was helpful so I was going to another one of those meetings but I\u0027ve also been told I could have been the Panaji research group and they\u0027ve been thinking about petha were now working I\u0027d like to talk to them about what is engineering and what is research so what\u0027s ready for the ITF to make recommendations for and what\u0027s not ready for the ITF to make recommendations for independent this that wimpy no chance meeting the thing so like I say the thing I\u0027m saying here that I need to make pretty clear is that I\u0027m talking about I\u0027m talking about producing BCPs for protocol designers because we still get a lot of product we still get a lot of proposals from people who are trying to solve specific problems with well-meaning ideas that the transport community has identified problems with a long time ago but we never write those things down my favorite one was you know if you read my PhD dissertation from 10 years ago with it you would clearly say that and that was the best route that was the best recommendation we had I "
  },
  {
    "startTime": "01:19:02",
    "text": "think the ITF has done better in the past I think we could do better hope to see you on Wednesday morning and Thursday afternoon so for those of you not keeping track we\u0027re down to the last three talks if you\u0027re thinking about dinner maybe a little bit hungry we should be out of here in about 15 minutes so you can start making your plans but our next speaker is use out to talk about loops only have a single page yeah yeah so we should we should finish with much lesser than 50 minutes I only have a single page here and I\u0027m gonna give a simple okay announcement on the loops path because this is one of the very first sessions of ITF so I want you guys who were possibly just here and with your jetlag aware that this time the session starts from 10 okay so tomorrow morning 10 o\u0027clock we are going to have debuff loops which stands for the local optimization on path segments okay the pet okay give a very simple description the path of a long-haul Network can be naturally or purposely partitioned into multiple segments via possibly like tahno stitching so loops aims to provide a loss recovery locally over some specific segments so that\u0027s the basic idea of loops so here are two pointers of the drafts so please read them and please join us tomorrow morning 10:00 okay thanks [Applause] so I\u0027m Tim April I\u0027m here to talk quickly about the DNS transparency project um many of you are probably familiar about how DNS works it\u0027s pulled a system where there\u0027s no way to currently get a push based notification to arbitrary end-users without having to arrange something with the DNS provider this means that any short-term changes in the DNS that aren\u0027t being actively monitored well will get missed and there have been recent attacks if you look at if you were to go in google for sea turtle or DNS panel as you can see a whole write-up on some of these attacks that took advantage of the some of the weaknesses in that in the current model this project is proposing to create a system where there\u0027s a push or generating a push based model where we get data from registries and then propagate it out through a pub sub sort of system to the end users that are interested that could be a registrant it could be a user all sorts of things like "
  },
  {
    "startTime": "01:22:03",
    "text": "that and this would get hopefully real-time updates from as many TL DS and then possibly later on second and third level domains as possible and then it\u0027ll aggregate that and ship it out to whoever wants to get it in hopefully real-time or near real-time formats there are whole bunch of people involved you can talk to any of us I think there\u0027s only two of us here this week but the two of us that are here will be here all week we\u0027ve also been working with some people from a couple different governments around the world to try and figure out what exactly the consumers need and then if the things we\u0027re looking for right now if you\u0027re a registry or registry operator would be interested to talk about possibly what we could do to get data if you\u0027re a registrar or authority operators we\u0027d be interested to talk later on about how we can get some of your data if you just want to see we have a very simple web page up there and we also have a form where you can fill it if you want to get more information as we get more data than ships out we\u0027re in the process of trying to stand up or merge with a be taken under some other existing non-profit an independent agency or an organization so we can have a independent status build something that\u0027s hopefully available to the community at large and we\u0027re hoping to make it free to end-users so there\u0027s the link if you have any questions find me this week I don\u0027t want to stand between you and dinner all right thank you so the last session there less talk is mine so I know some of you know about this and been participating in it but not everybody maybe so this is kind of a hobby law side project I\u0027ve been doing at ITF meetings which is to try to do a little social event that\u0027s modeled on the sitcom outrageous opinion session and it was the ideas to do some satirical talks I was calling it bad idea Pecha Kucha for a while trying to generalize it to not strictly be Pecha Kucha format we\u0027ve got several folks signed up now and I saw a few come into my inbox during the session so I think the list is growing it\u0027s Thursday night at 9:30 in Duluth which i think is the room right next door to here if you\u0027re interested in giving a talk you can do a Pecha Kucha which is a very structured twenty slides each slide is up for 20 seconds should be mostly text free yeah or you can just do a short lightning talk it has to be less than seven minutes and the way to get time on the agenda is to send me an email with a talk title and and then I need slides by six o\u0027clock on Thursday so everybody\u0027s invited there will be some beer and I hope to see you all there and thank you for coming here if you have feedback about this or the Pecha Kucha talks please "
  },
  {
    "startTime": "01:25:04",
    "text": "send me an email I\u0027m always happy to get feedback so thank you buddy go have dinner and enjoy the week [Applause] [Music] "
  }
]