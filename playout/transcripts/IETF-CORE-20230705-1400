[
  {
    "startTime": "00:00:45",
    "text": "foreign past you already have the link to the minutes in the chat please help out taking notes though Christa and I will mostly take care of those hurricane and high Esco"
  },
  {
    "startTime": "00:02:35",
    "text": "so we were wondering whether there should be waiting music wise for a meeting to start and I think that hearing the occasional Mouse click is very reassuring and completing these places the need for waiting minutes we can sample these things and have those as an actual waiting soundtrack the traditional that's the audience sinks the Jeopardy music while waiting [Music] whatever I really want Christian keyboard involved [Music] okay let's give one more minute then we'll start I think you can start doing the Jazz slides shall we yeah all right then uh let's start how come"
  },
  {
    "startTime": "00:04:02",
    "text": "co-working group last before it f117 uh I am Marco Michael Cesar and Jimenez and Kirsten Mormon and as usual the network applies will be recorded and Reveal Your iprs if you have any it's not just about that it's awesome especially about our code of conduct so be nice and professional to each other uh we have a pretty packed agenda today especially compared to past entry meetings um as recording for a while now uh we have an entry for corkov for the core c then comma document then we couldn't make it two weeks ago so it comes today a discussion on attacks on Co-op input from Christian and John uh Martino gave an update prey itf117 on the answer Co-op and time allowing but I think so uh we can also have a discussion that was also originally planned for two weeks ago um on non-traditional responses input monster from Carson and Christian and and then let's try to save a few minutes for the end just for a quick announcement um on next core events uh in the coming weeks and months any agenda bashing or more input for today I heard none we can start with con with karcom Kirsten okay um yeah so I have some 11 slides um but I'll do this quickly in the first few slides are just uh repeats anyway so just in case you're wondering where we are we have four cargoon documents in the working room the first one is RFC"
  },
  {
    "startTime": "00:06:01",
    "text": "defining the encoding the second one defines how exactly to do the city location uh for that encoding to be efficient the third one Maps Yang to co-op uh using the Yang sibo encoding and the fourth one which is not on the list today um is the uh Yang library or concise form of the Yang Library so we are still working on revising 20 which was pushed back to the working group so we can complete some work on this and it turns out this actually was necessary we added Global file status and passage status to make the Sid documents be more um indicative of what they actually are and right now we are trying to complete this work but we would need a version of pjang that actually can be used for generating our examples and it turns out that's a slightly bigger construction site than we thought um so there are a number of folks of peeing um the the mainline version doesn't actually generate the examples that we are using so there apparently was some manual editing and of course that that's not really attainable situation in particular since we don't really have any validation uh mechanism either so one way of being sure that that what you have is structurally sound is to generate it uh the other one is to validate it but if you don't have either that's a problem and that causes us to find more and more"
  },
  {
    "startTime": "00:08:01",
    "text": "issues each time so the the one thing after we have cleaned up Yang um the one thing we actually need to do is make sure that we have since for the remaining identifiers that we identified need to have since and that is probably just this moment of rubbering but the the consolidation in front of it is uh kind of dwarfing uh this effort there are also some small editorial items that need to be done which I I didn't focus on yet so yeah validation is the one of the bigger open items that maybe we can look for some ideas how to do this so the the set of issues that that we need to work on uh one thing that already is fixed is that the RPC parameter SIDS uh actually needs input and output in the strings in the identifier string so that's actually fixed now um the Ping implementation doesn't generate a dependency Vision section this is completely missing I don't know what needs to be done to to get this or if it's not really uh implemented at all um then we have some serious plural so so there are things like items and assignment ranges being generated but the young names item and assignment range that's a per annual problem singular plural um and then I don't think that the being implementation reflects as a structure so we are missing and embedding [Music] and finally all this it's generated are"
  },
  {
    "startTime": "00:10:02",
    "text": "numbers but they need to be strings because they can be un64. um so that's uh just a small summary of what needs to be fixed on the being side so what I think we will do now is continue with the peeing uh work um so next step will be to get the laws uh patches in there and then maybe the patches from from his grad students um and uh yeah we are obviously not going to have this completed uh early enough to to have the discussion this week uh so it seems like we will have to wait a little bit a little bit longer before we can submit and do the working plus call but I hope we can still do this in such a way that we can discuss it at 1 17. so work is remaining there is a dependency slowing us down but we have control a limited amount of control over that dependency so I'm not really worried here um it's just a delay the other document is the comma document which tells us how to map a car conf on on Co-op so just like rest conch was a mapping for http is doing that for Co-Op and doing it for sibo as well so it plays both the role of 7951 for Json and 8044 HTTP in in one document minus the parts that are already done in 9254. so we went through working with last call a while ago then we decided we want to do it to have some simplifications"
  },
  {
    "startTime": "00:12:00",
    "text": "and we completed the simplification there and Dash 13. but there is one remaining issue that I want to briefly talk about today which is the way we use post and that that's a bit surprising because uh the the simplications brought new focus on the way to use Fetch and eye patch but yeah we apparently didn't look at post as much in that process and and we probably need to um so what we need to do apart from the posting is um the media types that we Define actually are not silver media types they are civil sequence media types so we have to change the media type names that that was easy so it's already done in the editors copy and we have an example India that is under headline RPC example but it's actually not an RPC exam but it's an action example uh so we have to rename that which is also done in the editors copy and add an actual RPC example probably uh because you want to make sure that people who want to do our rpcs understand how to do that now the the question that came up when when juggling these examples uh was uh does that this actually work and and is it uh actually concise and let me show you what's in the current uh document in dash 13. so this says we are posting to the data store resource an example name of which would be C and um we are posting a Yang instances sibo sequence but in this case it's actually just one element so it it's actually if there were young instances of Seawall"
  },
  {
    "startTime": "00:14:01",
    "text": "this would also qualify but when you then actually look at the example we see a sibo sequence of two items the identifier and yang data um map and that's definitely wrong because uh the we are supposed to have young incenses which are instance identifiers as map Keys uh going to um a map that is a young data object so so this is definitely wrong but it's pretty obvious how to fix this but when you actually look at this there's also something quite striking uh why are we repeating this the Sid for the actual rpco action that we are talking to and we already have identified that probably as a mistake and have made one slide that summarizes all that based on an example from from the rest conference the 8040 we probably should be using that example so so people who know restaurant can can find their way um so what what we see here on the left side is the RPC uh request and and the second further down uh an action request and essentially the the difference between an IPC and an action request is that an action request identifies a specific place in the data tree that the the RPC is applied to so it's kind of a method in the invocation uh while rpcs are just generally going to the server and we probably don't need to to separate these uh this is really just do we have any additional parameters like"
  },
  {
    "startTime": "00:16:00",
    "text": "the is null is zero I'm sorry uh for the interface ID and in the action example we don't have that in an RPC because we are not identifying a place in the data tree um so we have to give the name of the the rpcl action which we can do with a sid in this case the reboot sit for the reboot RPC and the interface reset search for the interface reset action and then something weird happens in 1840 um there is a interstitial here which is the Sid of the input part of that RPC or action and uh it's not at all clear why that is needed so the reboots it would be the sixty thousand two from from the previous Slide the input set would be sixty thousand four or something depending on what what set it actually gets and then in that we would get um the various parameters like delay message language for the message and so on um so uh looking at that I'm essentially forced to propose getting rid of this uh inputs it thing because it's very clear request will have an input Sid and a response will have the outputs it cannot be any different from that so why are we sending this this is not at all clear and the the routing in the the Yang Sid space is already done by the operation Name by the IBC name action name like reboot and and interface reset so there really is no point uh putting that's it in there so this is a proposal I'm making to to"
  },
  {
    "startTime": "00:18:01",
    "text": "further simplify rpcs and actions I'm not sure that anybody actually has implemented these things um so I'm still looking for an implementer that we could talk to to find out whether that creates any uh problems but in the end this just means uh there's one less um actually completely redundancy implementations have to remember what it is and have to check and we are saving a couple of bytes maybe three years old okay so this is a technical change that we have generated by actually examining this and we are currently discussing this between the authors and a few implementers and hope to have something for for the list to send to the list this week So based on that uh yeah we are also late with this timeline um we definitely want to use the progress from the Sid work in this draft as well so we we want to generate the Sid fire that applies to this draft uh using PA and not by hand we want to use any validation progress that we are making um we want to fix the to-do's on the previous slide and make the post format decision I just outlined and then we can do a working request call and again yeah before or after 117 but we definitely want to discuss this at 117. so that's where we are with these two documents and then of course we want to finish the Yang library and get to the item that is frequently requested which is not only having a efficient encoding of this structure"
  },
  {
    "startTime": "00:20:01",
    "text": "structure of a Ying data item but also to get binary formats for things like IP addresses dates and so on that tend to be very bloaty when when all the structure on that is so concise with yang sibo any questions okay okay you may want to bring uh also Michael Richardson up to speed yeah just because he hasn't participated in the very recent discussions as far as I could see well he I I had him added to the of his discussion so okay thank you okay uh looking forward to the next steps on discussion San Francisco or online uh if there's no comments or questions on this well there is one comment from Esco on the chat which I I will take care of oh yeah correct good catch okay then we can move to the next one I think John will present are you gonna bring the slides up or do you want me to do that As You Wish can you otherwise we can give you control it's just the same yeah I think Carson is doing that okay so essentially this comes out as some discussions the net and they're just really trying"
  },
  {
    "startTime": "00:22:02",
    "text": "to highlight some of them some of my thinking um I accept my thinking is never 100 pure there's always a flaw in it but just to bring this up and get us thinking a bit about this so if you can go to the next slide control you have control just press the right arrow white Arrow okay yep thank you okay so just there's some block two responses uh questions and thinkings token manipulation and some clarifications which I think a lot of people keep stumbling into as to what actually we're supposed to be doing under these circumstances okay so just taking a standard block 2 response without using request tag or e-tag I've got it documented there but the and all that's happening here is uh the requests are being reordered as they come in by the foe um this really is dependent on whether the server does kind of a lifo or fifo uh kind of response when he's doing his lookup and so the attacker can change his method depending on whether he detects the the server is the fifo or the lifoot method whatever but essentially What's Happening Here is that we have the two requests for initial bits of data in concurrent and then there is a request for the next block of data but the server has no knowledge of whether that is against the first request T1 or against the second request T2 makes a decision sends a response back but could be sending the wrong data back and at that point the client as far as he's concerned he's received data he appends it to whatever and deals with it but the data is corrupted that's when we're not using uh request or etag we can be using e-tags to determine whether the data coming back is part of the first request or part of the second request um but the challenge here is that the server may elect to send the next block"
  },
  {
    "startTime": "00:24:00",
    "text": "of data against a request that has not yet come in so the client when receiving it he sees that the etag is not quite what he expects what is he supposed to do with that response so he will be expecting an e-tag of 12 to come back if you got back the right data he's asking for but it comes back with a knee tag of 11 giving a block that he hasn't yet asked for so just using e-tag only creates problems on block 2 responses if we go and use request tag which I think was a wonderful invention then it's very simple for the server to realize or work out which request has come in against and therefore send back the appropriate response back to the client but the only comment really on this is if we do request tag only because etag is not being used we can't detect or the clients cannot detect that the data has somehow changed on the server since the previous request you can't see that it's changed because etag is not getting updated foreign tag always gives us the right block coming back but the challenge is that the client has no knowledge of whether the response is going to come back as a block 2 or just as a single response so should we be sending request tag with every request which is supported in RFC 9175 or should we be doing something different it's creates an unnecessary overhead yes it can be small a few bytes but if we're talking about dtls it needs to be larger to kind of make it more unpredictable in terms of trying to analyze what's going on it is actually required in the RFC 9177q lock logic that the request tag is there with every request but the challenge if we don't use request tag if multiple requests are active the server can use the select the"
  },
  {
    "startTime": "00:26:01",
    "text": "one response we have a problem there so and how to mitigate this we could send a request tag with every request we can stop the client doing concurrent different requests against the same resource but with different parameters but we cannot control the N start equals one because there are multiple blocks to be returned uh it may be that we need to think about perhaps a new signal from the server in the response that says you know you haven't given me a request tag but you're going to need this in quotes request tag to ask for the subsequent blocks of the same block same sort of payload of data but how can it be done at the moment request tag is not allowed to be in the response should we be allowing that in a response overriding some of rsc9175 or do we need to be thinking about a new block 2 option that has some sort of embedded request tag as generated by the server for the client to use to get to these subsequent blocks and so that sort of is is is questions that selected posters don't I don't have any real answers to that but I don't know uh what people think about that is that there's any kind of feedback at this point on that um I'd like to say something here but um I'd like to let underscore first here I was wondering whether we could go for this foreign would practically mean that the request has to be sent once more I guess that's what I'm wondering about okay there is no way for the server to detect whether the client is using the"
  },
  {
    "startTime": "00:28:01",
    "text": "absent requests tag intentionally like it is you doing the request tag mechanism and determined that it doesn't need a request tag for whether the client just is not using request tag at all in which case the echo would might not might not be doing too much either so I think the the best approach here I mean the personally I think that not sending the payload in requests where there is no block one fragmentation but a block one but a request payload was a mistake and I actually I thought it went differently and only after John brought this up I found this and consequently uh 9175 is incorrect here because it is built on my wrong assumption that the request payload is not sent uh that the request payment is sent again yep now that it is not sent again I think that the the good mitigation here would be just to send request tag with every request that has request payload and may have response payload but to make ample use of all the provisions that are in there that allow the request tag to be absent in most of the cases as long as you're not using vtls yeah it's it's yeah it's difficult to try and mandate something or encourage people to do something um okay yeah so I always call can help a bit here other people want to use dtls for various reasons uh back in my old dots days everything was DT less but it's yeah it's not straightforward but it just is yeah the service somehow signaling the needs to do something there is there is yeah well I guess if the client gets back a block response he then can determine oops I should have"
  },
  {
    "startTime": "00:30:00",
    "text": "done a request tag and then go back and re-ask the the request Again by using the request tag so the cash key gets updated on the server I think it's the operation I mean your examples do use posts so the operation actually does get performed a second time yeah okay okay but if you use fetch it's slightly different yeah yeah for fetchets for Fetchers and when users of dtls already had to start sending a bit more data with the 9175 Mandate of not reusing tokens so since and and there is not too large I mean there is only this this only effect request where there is both request payload and response payload and then sending a request tag for every such request I think is not too much of too much of overhead in Institute for for ttls users I mean they would just they would just be incrementing a number there and that would be like uh two to three bytes yeah you only need a request tag if you plan to have a multiple requests outstanding I mean not not in the instructions but in the sense of having multiple blockwise activities going on at the same time no yes no okay it's okay but the challenge is that if you then okay a client you could control but their proxy may be asking multiple requests on behalf of multiple clients a proxy is a proxy is not covered by by dtls on proxy is kind of acting independently anyway so since a proxy cannot guarantee that just it just it only has one outstanding"
  },
  {
    "startTime": "00:32:01",
    "text": "um blockwise request it will always have to send a request tag the thing is it doesn't help to not have outstanding requests because you might be injected an earlier an earlier request might be injected again into the into the stream so that could be a re-transmission of a message that was black hole earlier so even if you are not doing any concurrent requests you could still fall victim to that attack great okay I don't know that we need necessarily a definitive response now but I think it's something certainly that needs to go into the draft RFC into which drought well the the crop attacks draft sorry yeah we know we not only yes it does need to go in there but we also need to think about where do we fix it sure I know I've certainly fixed it at my end by sending a request tag every time apart from a delete I mean it's it's on it only needs to be said if there is a request payload and um and the method yeah and the method is not deleted yeah so they would also make the drafts under struck right second place that would make the draft standard struck I don't think we would fix it in club attacks because Club attacks was split"
  },
  {
    "startTime": "00:34:00",
    "text": "out from from uh from attacks I know it was also split out from um from Echo request taken token processing um to have the normative stuff in there and then the motivation in a separate document so the direction I'm thinking is a very is a very short small document that updates um 9175 and says that this not only applies to requests the all everything that was said about request tag and when you should use it not only applies to requests with the fragmented um with the block one fragmented request body but also the requests that have a body and the recipient cannot be sure that the response will not be fragmented yeah that'll work I think yeah we certainly have in that 9175 the ability to be able to send a request tag without block one change yeah and I think that was an artifact of of uh proxies um handling it right um it could be I certainly I ran into it with a client of mine who had this issue and just couldn't get the right data back yeah it was definitely a good thing to have a change there yeah and it might be that in the review process I missed the point where this where you already brought up that or just applied my wrong understanding of of clockwise transfer to it sorry for that that's fine I think I also may have partially confused you looking but back at an email Trail about two years ago I gave you an answer what I thought was the right answer to your question but rereading your question you asking a slightly different question so I may have sewn the confusion there as well"
  },
  {
    "startTime": "00:36:02",
    "text": "anyhow I think now we're in a position to fix it yep my impression is that every additional signaling that we would introduce uh would not be any Slimmer than adding the request tag to that particular class of RPC style um requests other than if the server with its generated request tag added it to the block 2 response because he knew that there wasn't a request tag requesting it uh not the thing thing is that could also happen on on proxies and then things do get a bit complicated okay so I'm thinking of a case where a client is sending a fetch request um server is sending a big uh say one kilobyte response and then the proxy says hey I'm on a six little paneling um I'm gonna fragment the response and then suddenly like I think this makes things more complicated than it's but it's an option to have another look at but I think it's more complicated okay fair enough certainly a simple set of words as a guidance is a good way forward which is use request tag unless you really don't want to okay should I move on or please yeah yep okay so um just comment on the attacks is that without the request tag we've talked about that and without the e-tag it's possible that data can get corrupted from the client's perspective without the e-tag is because the server has gives you half of a watch of data which is then updated mid-flight to something new in the e-tag doesn't change because it's not been given there and this is another comment and start equals one serialization can be broken by the man in the middle foe causing"
  },
  {
    "startTime": "00:38:01",
    "text": "trouble it comes out actually better in a couple of slides as further on okay so token manipulation is something else that um sort of came out of the woodwork of this essentially here is that the client thinks he's doing a request to request one with using token one and request to request two using token two the foe changes the token so that the services the request to with token one and so on and request one with token two and responds accordingly and as far as the client's concerned when he matches up token one he gets the response to data instead of the response one data so this is General manipulation of some guy sitting there in the middle and uh the same thing can be done with con but here is that the the foe in the middle is getting a bit smarter and so he's getting around the end start equals one issues by acting back uh the con request so as far as the client is concerned everything is uh is not a piggyback response at this time he is going to get a uh subsequent once coming back he then replaces the tokens moving Upstream the response comes back which is now act and again the foe changes it while this because it's a delayed response we need to send it back as a con and then drops the responding act so again just even with cons it's relatively easy for a foe to do token lip relation and get around the end start equals one kind of block which most people will be challenged by um so it's kind of the attack that comes out of this this works with non or with con end starts greater than one which is to me got a whole load of other headaches if you go down that route um and then again con if the switching the acts and cons uh OS core does protect this as an end-to-end because it doesn't care about tokens being changed as it passes through proxies and what have you because the request response is probably matched but dtls doesn't do any"
  },
  {
    "startTime": "00:40:02",
    "text": "protection there if the foe is some sort of Road proxy or he's done some successful man in the middle interception of the uh the details sessions so there's two completely separate DCS sessions one back to the client and one up to the server and so again someone's commented earlier is um mitigation against that kind of stuff is to use OS core or and certainly do not use no SEC against that type of attack but it is a different type of attack that's out there I don't think there's much else that needs to be said about that but I think that sort of thing should be in the co-op attacks document and some clarifications which is uh part of where Christians and I think I probably initially stumbled back in time is of a request using block one triggers a block 2 response the request for the next block as per 7959 is that uh leave out the block up one options which implicitly says don't give me any data including that and just use the block 2 request for the next block that you want coming back so essentially is that there is no data that passes through on these request for the subsequent block uh coming back from the server and the same is true if observe is being used as far as that is concerned an observer Quest using block one and then somewhere subsequently the client decides to deregister it it has to send the entire original data is my understanding including all the block ones as I read 7641 3.6 but a cancellation May trigger a block 2 set of responses and what still is currently unclear in my mind is should the client wait for all the or go forget all the block 2 responses to complete the deregister process so that the server can completely do stuff or do it it's just the first block coming back"
  },
  {
    "startTime": "00:42:00",
    "text": "sufficient to acknowledge that uh the d-register has actually successfully taken place and I does anyone have an opinion on that well I sure have an opinion on that um which is uh that it's completely voluntary to get the rest of the blocks for for a response um so if um if the First Response already gives you the the code that tells you or the the server has understood that you register then you're done you don't have to get the rest um I actually had a comment on a previous slide on Slide 12. um I think it's um it's really important to distinguish um attacks where we thought that that the quite a bit secure and it turns out it isn't in the presence of an attacker that do something specific um from additional ways in which an attacker that already can can do a lot of things can do even more things and I think this uh discussion about token manipulation really is something where we already have lost because we have a rogue proxy um are we we have no segment so we we didn't have security before this attack uh became known so I don't think it's in the same class as as the other attacks like the reordering attack we talked about before um so I think it it's very different not piling up more ways to abuse an insecure situation uh even a different way this is just"
  },
  {
    "startTime": "00:44:01",
    "text": "confusing we should tell people when they actually have to do something specific because they thought they were secure but the attacker can do something that is surprising uh maybe for for people who thought they were secure sure it's it's um it's kind of in one sense alerting them to them that they can be they haven't or someone hasn't properly thought through the security model and what are the effects of a malicious actor doing stuff um but yeah it's you know token manipulation you know someone couldn't say well I've unlocked my car but that's been manipulated to follow on with the Locking of the car and then reversing them around and yeah you get uh you get this great potential there for creating real fun and games but yeah but the the wrong proxy could also change the data to just say yes of course you have locked your car yeah and um so that's nothing new no but it's just the okay the OS core end to end Trust um certainly mitigates a lot against that sure but again that's independent of this specific attack because a rogue proxy can always change your data yes true okay it's coming back to the cancellation and you say we don't need to get the rest of it there will be a cash key somewhere for that Observer quest which has not been because all the data hasn't been sent back and so you may get a memory starvation attack taking place on the server unless there is some sort of timeouts or garbage collection of those cash keys for for those pre-existing observed requests the server has to always expect that a client may not keep fetching uh the full"
  },
  {
    "startTime": "00:46:02",
    "text": "rest of a resources true that that is that's already very explicit in 79 959 so there are two kinds of local responses one where the server sends a 2.31 uh back which means this thing is still active and one word sends like a 205 or whatever the the success response the actual success response is and if I get a 205 on my first block then I would consider this request done okay and so just the the garbage collection just needs to leave it lying around a little bit on the server in case there is a request for Block yeah number one or block number two yeah following this one okay thank you for that so to say thank you any other questions thoughts I'd just like to pick up that point of of having those two or five brothers two three one uh responses to re-emphasize how I think we should fix we should consider fixing block wise um with in this interaction case uh to just send request payload again because fetch Works fetch could do all this two or five um stateless server thing but it can't because the request payload doesn't get repeated so we I think we're losing out a lot on on what fetch can do because um blockwise behaves that way and I don't know what our upgrade path there is but I think we should seriously consider that"
  },
  {
    "startTime": "00:48:02",
    "text": "okay so the if let's say the French request has six blocks to send Upstream and then we start getting block two responses we're going to have to repeat sending those six requests every time so that there could be quite an overhead or no no no no it it would it would be fine if if there is block one um if if there is block one splitting and there is um and and and the block one cannot be processed independently as it can only be done when there is no actual response um then yes the server is stateful and it won't get around this um but many fetch requests will have the fetch payload fit in a single request payload right and the response not and in those cases repeating the fetch payload has a large upside that the server doesn't need to keep any state around it can just process the request one more time generate this other view of the response rather than keeping the state around I concur with that so if essentially if everything fits into a single block that's fine and the challenge could be if it goes via a proxy who says yep I can accept 1024 on my left but I can only do 64 bytes on my right that that would still be fine because the proxy accepts the request with 1024. and then keeps that state around to clock the the uh to to to send to send it on in those small chunks right but then when there's okay yeah okay the proxy needs to be aware of blockbust transfer that's there is no way around that sure yeah on this topic and More in General on the clarifications on the previous slide is that all material intended also for um Co-op attacks or for somewhere"
  },
  {
    "startTime": "00:50:03",
    "text": "like again um corcor I don't think it specifically attacks but it is uh it it it's because it's because all the rfcs came out in a particular order and blocks came after observe and fetch came somewhere in between I think it's uh everything just gets in a mess as to what am I supposed to do under these particular Edge case scenarios and hence why I just put this down here because you know Christian's confused I think I was confused in early days and I'm sure one or two other people are likely to be confused as well they can be selective updates to observe and blockways we do have a correction and clarifications document yeah that's one venue for sure what do you think Carson I think you are the main maintainer of that initiative well it's currently not a regular document right so if we want to give it some status at some point then we would have to think about making it one okay for now we shouldn't lose track of this slide in particular yeah so maybe just submit a PR right yeah yeah okay so who's going to submit the pr because if I'm happy to do it but I need to know what to do it against"
  },
  {
    "startTime": "00:52:00",
    "text": "well I guess you weren't opening an issue that's that's very easy yeah I think John's question is where's the repo and I'm just trying to to find out whether I can find out and then I might be able to give the answer foreign somewhere it's good it's nothing custom repositories but it and it there is one action icon that I think I will have to take that is to prepare a very short seven nine uh 9175 update so this should be in the core working group Repository it's already in the notes maybe I failed to unmute myself"
  },
  {
    "startTime": "00:54:28",
    "text": "okay so does everybody know where to put what who's going to take the responsibility of doing that John if you have the issue Square in mind can you open an issue per bullet point um okay I yeah I need to go and find it so if someone just points me to where it is I'll you know oh sorry it's in the notes oh it's in the notes okay sorry Christian put the link online 140. oh so it might uh yeah oops so I missed that all right okay I'll put something on there yep no worries yeah I think it's prescribable one issue per bullet point because they uh they're of course related but still yeah well enough separated thank you yeah I'll do that uh post this thank you okay otherwise I think I'm done thank you very much thank you uh Kristen you have preliminary notes in the notes uh I guess you covered all of them if not please please raise them"
  },
  {
    "startTime": "00:56:03",
    "text": "you are muted just in case you're trying to say something uh to make mute buttons um yeah all done already removed okay great so I think we're done with that thanks Joe for the preparation appreciate it yeah sorry I couldn't do it two weeks ago no problem at all thank you again okay uh uh so next is Martinez I uh you need to slide yeah uh I think Jonas tooth Liz or I can and then give you permissions okay um there we go yeah okay then um yeah uh I wanted to talk a little bit about DNS over Co-op and our progress again um for those in case someone doesn't know what I'm talking about um again we want to encrypt a name resolution for iot devices against eavesdropping and for that we want to use Co-op namely DNS over Co-op so we can use encrypted communication and the clockwise method and also share system resources with the co-op application um some good news is that um we finally have a paper on this published and it Conex 2023 and there's also a preprint available on archive if you want to read into it already uh how does our doc draft there was a question by the chairs relate to the dnsc board draft we also currently discuss in the sibo working group um the draft of about DNS of a Corp it"
  },
  {
    "startTime": "00:58:03",
    "text": "just introduces an application DNS message format which a Content format which is basically just mapping the media type from HTTP DNS over the https so it's a classic DNS wire format and easily transferable to other DNS transports however if we work in the iot sometimes things are not small enough even when we use the classic name compression that we have in the DNS wire format so we decided to go for sibo-based format which is application DNS Plus sibo as discussed in the draft um which reduces the message size even more and if that isn't even isn't enough says optional support for practice eboard so that we can even have even smaller messages but the idea is to still use application DNS message as a fallback either if the client or Server doesn't support the sibo format or what can also be the case if the sibo format is for whatever reason actually small or larger than the DNS wire format um no okay uh so what changed since we talked about the draft since itf116 we didn't publish a new draft yet but there were some work happening on GitHub um we clarified that the the DNS over Co-op is orthogonal to DNS over HTTP and in what way we recommended that the root path should be the DNS resource pass we set an ID for the application DNS con message format namely 3535c5 so you know three five three five three so we have somewhat that remembers"
  },
  {
    "startTime": "01:00:01",
    "text": "you about the dnsport we rationalize why we do all the TTL rewriting we talk about in the draft and we also added a section on implementation status so if you want to read about our implementations you can do so now um custom was asking what I meant with authorinal um diagonal means it's just not like 100 compatible like uh you can't just map DNS over Co-op to DNS over https is what I mean by that um so does this clarify your question okay um then uh there are still some open discussions namely on the mailing list in cooperation with DNS Ops thanks to benchwartz again there um because there is uh still some discussion ongoing about FCB s VCB DNS records um where we may need to allocate an alpn ID for Co-Op over dtls um there's also GitHub issue on that um uh and the co-op I uh there's already a co-op ID for Co-Op over TLs but it was never mandated for details and Ben also recommended to keep this for TLS only and have maybe a new ID for dtls and there is nothing on SV CBS for Oscar ad hoc we started some discussion on the"
  },
  {
    "startTime": "01:02:01",
    "text": "consensus on that needed um and even though they are especially because they are orthogonal there is some translation needed between doc o d o h uh maybe when we have a co-op to HTTP proxy um or we just say hey this is just a DNS forwarder and it keep it treats DNS over a HTTP like any other DNS transport but the main question here is to the co-working group how to translate fetch to http in general maybe we answer this in the document or maybe we do not Marco Martina have you checked the query method uh uh which me do what do you mean by query method in this case I'm looking for the right document but HTTP is defining a query method okay they won't say that okay maybe I have a look into this um if someone can give me maybe a link I lost track of the exact status of that document but um I'm just afraid it will not help with this issue because even if we Define that fetch should be translated into into query in an update to the proxying document then this will still not make Doh use Query so it's it's not helping here so I'm not aware about the query method I know about search um I now I understand what you mean by query method also iPad custom you first yeah so that has been stuck in in the"
  },
  {
    "startTime": "01:04:00",
    "text": "HTTP world since uh RFC 5323 and I'm not sure whether we can count this on ever getting unstuck I mean and the other problem is now that I know what we're actually talking about is uh for Doh there are very specific methods defined uh get and post so I don't think we can use the query or the search methods so they need to be some decision or some definition on how to translate it if we want to go that route so um yeah but I think given that given that the times are already the TTS are already not compatible we can't go that route anyway even if there were a defined way of translating a fetch so okay then we should just state that um like it's fetch it can't be translated anyway even if it were so we're not translating it a Doh server might have an easy time implementing doc as well um but doing a doc prox doc can't be done just by making a reverse proxy to duh okay then we just specify that I guess um okay then the other thing that is still open is a GitHub issue which uh given the discussion in the previous talk I'm not even sure if this is applicable anymore um so it's basically about when we use Doc in the unprotected case so if for whatever reason we can't use crypto and but we want to have the feature set of Doc like blockwise transfer um and uh currently the draft says that you should not use is that the mid of DNS then to zero to prevent uh response"
  },
  {
    "startTime": "01:06:00",
    "text": "proofing um and uh uh questions there said that we could maybe still use a caching advantages by setting mid to zero if we rely on the co-op tokens um customers what to say something what is mid the message ID in the DNS header ah the DNS because you have a message ID in Co-op and yeah I'm sorry maybe I just copied the title of the issue and uh yeah okay yeah maybe some a little bit more specific would have helped yes I'm talking about the DNS message ID thank you so uh yeah the question is if we still could maybe use mid 0 and instead rely on the tour to co-op tokens but a little bit from the talk before I'm not sure if this helps or if you can rely on that I I think we can rely on the token because everyone who can spoof the token can um DNS is a bit defensive in that they assume that hey maybe you could um you could um want to defend against parties that are blindly injecting stuff um but Co-op generally does not really try to to work on that and like taking if you're worried about that take a non-trivial token but the message ID can still be zero the the mid in the in the DNS sense okay I guess then uh I guess a message in the chat okay yeah um yeah I think uh regarding Esco Esco was said that noted that the DNS identifiers just used ID uh I've seen"
  },
  {
    "startTime": "01:08:00",
    "text": "both to be honest yes in the RC it's just ID but um yeah um but it's also saw like in DNS literature the term mid okay yeah thanks for the clarification [Music] okay but in in the document it will be clearer what message ID we are talking about um yeah um so I guess we then go ahead and just keep MIT to zero and rely on the co-op tokens instead um and clarify this in the draft um so the question now remains what do we need from the widget from the working group to prove process progress um and yeah basically the things we discussed here already is the guidance on how to translate fetch to https we don't do that and also like a statement or some action item on the service B records above with escort or Co-op over dtls and of course there's always more feedback it's always appreciated um anything especially on the second point would be interesting Esco yeah just checking uh it works so it's not on the second point but some feedback was on the basically the content four band number you could actually just request five three for that um so yeah the yes uh oh I didn't I didn't tell talk about this yeah but uh five three uh in my mind would be the better of content format for the sibo format because then we can"
  },
  {
    "startTime": "01:10:00",
    "text": "uh benefit from the shorter ID yeah you could still use three five three further uh application slash DNS format yeah exactly yeah okay if the length is not so critical then you can also use you need three five three or five three three or something five three five three maybe well 5353 is in the space that we try to keep available for an experiment that we haven't really gotten to yet yeah she was my first pick too but casting already back there okay yeah maybe also a good idea yeah yeah or at least something that is in the lower space I think that's reserved for uh let's say ITF specifications new specifications make use of performance and yeah I would personally go for the single five three but if you say you want to use that for something else in the future then yeah okay that's also fine you can also go for five four huh just plus one like I say then go four three five three [Music] any more feedback why not five four then because there's plenty of bytes uh still there I would say well I don't agree you don't agree okay and also I I I I want to keep it mnemonic with the DNS numbers and I think five four is a little bit more confusing in that case"
  },
  {
    "startTime": "01:12:00",
    "text": "yeah then okay something like 533 then could be a for example use that yeah also something with threes and fives can we make a decision uh in the draft yeah yeah sure that's fine thanks okay um so if there's no more feedback um I go ahead with the next steps um yeah I try to address a feedback of course and uh before the draft get cut off we will publish the version 3 of the draft and if you again have any uh more input on that of course it's always welcome thank you ask who you still here you still have your uh and raised you want to say something I guess no okay uh no more comments in the chat here so I guess that's it uh looking forward to the next question yeah thanks Martina uh yeah you're welcome so we have about 15 minutes or so left for uh non-traditional responses and Christian I guess you caught up from the latest interim and the short discussion we had there uh from the minutes but you have prepared something here now um yes the um I I hope I got everything on the on the last items minute um so basically what I would like to achieve today is to get a rough feeling of the working group of whether this is a direction the working group is uh willing to support um background is um so this document is"
  },
  {
    "startTime": "01:14:01",
    "text": "a an individual document by Karsten whom I've joined as an author in the in the Dasher one version and the original direction of the document was that it would just um describe Define a few options for things like triangular responses and responses that are pre-configured but see what they are the response for um in in dash one this is being generalized to not only describe such options but to Define what to to to to flesh out the general concept behind them which is not only used in those options but has been in use since the start of of of Co-op for example in observations or in in not in response to multicast requests but all um is seeing an increase in in such options now in for example with um multicast proxies or also in in in in the Q block options which also solicit multiple responses now what I think we should do here is um and Dash o1 goes some part of the way already is one uh Define that General concept and I think the very short version is every response that is not a single response to a single request is some then that is not that one response or if there is not just such one response that is a quote non-traditional response and two then go on defining how or describing how one defines such options and what general General guidance is processing those options because um we're seeing a lot of them and authors of each single of them will be"
  },
  {
    "startTime": "01:16:00",
    "text": "tempted to reiterate on the same thing such as we're responding on the same token um we are not interfering with flow control or we are interfering with flow control but I think the general cases we are not interfering with flow control General crop flow control still applies and and give a set of such rules that can then be uh quote uh not quoted are referenced when a new option is introduced and I think this is both helpful in keeping the specifications clean and in keeping the implementations clean because the implementations can then say we have a request we have a mechanism of doing a request with several responses and this is the general API and then if you're doing an observation or if you're doing um a block request that has multiple block responses then this all is happening through the same mechanisms and there is not one mechanism in another another tact on top of each other and whereas yes that they would need to to interoperate because the general rules that are set out here would allow multiple such options to to uh to just cooperate um the intention is not to redefine observation and multicast and response to multicast requests um here because that would be updating a whole lot of documents and would mean generally these things already do work there is an appendix that describes them in that way but this is purely informative and if it so happens that at a later point in time one of those documents does Abyss it might be perfectly feasible to use new terminology but that's not the plan here so um is that extension to co-op something that the working group could get behind"
  },
  {
    "startTime": "01:18:14",
    "text": "there's a plus one obviously in the chat from Kirsten uh yeah again as an individual I restate this is useful and it's more to clarify what what happened is happening anyway just in multiple documents that can be otherwise difficult to track so I support this record also one aspect of the question I'm especially seeing for example John in the room is also um do you would this help you implementing those things in your in the implementations that you're that you have written or already say this again is this something that you think um would help you implementing uh would help uh would help along implementations of uh of Co-op that could you make use of this in implementations that really is down to the peoplehood doing the implementations are kind of providing more of the kind of Library support in there um yeah one of my challenges is that I supposed to retired about two years ago and haven't yet so I'm supposed to be winding things down but um there's having a structure in terms of what's there in the responses does make sense to me because then you can key off that a lot easier in terms of what you're doing"
  },
  {
    "startTime": "01:20:00",
    "text": "just as one needs to agree what's what's sitting in there or it's making proper sense Etc thanks and Kristen before you were using often the word option and I wonder if you were referring to options alternative incarnations of the concept or Co-op options probably both because the document is actually defining also pop options um I'm I'm so I I think I'll have to take a step back here um I think and and it's also in the document uh that every every request that solicits non-traditional responses uh we'll need to indicate that somehow because essentially it will be keeping that token open in some way in many cases this is happening through options but it can also happen through components of the header or other contexts things so for example um a requests looking at requests multicast addresses through the lens of non-traditional responses there it is the destination address of the request that is keying everyone to the fact that the token will be will be used with multiple responses um when when a message is set up through as a phantom request for multicast notifications that is also a key that that there's something going on but it doesn't need to be in a co-op option okay and but thinking of Co-op options you mentioned in the previous discussion and I tried to to quote you"
  },
  {
    "startTime": "01:22:02",
    "text": "um at the latest Internet meeting a possible further Co-op option that you had in mind um as an even more General alternative that can be used to the current option the finding Groupon proxy for for that sort of opting just not giving a Time indication but rather acting as a on and off switch it was something like that yeah you will I think I think we it I think it will make sense um to have uh one or a small set of relatively General um setup options because those would need to be proxy unsafe whereas then whatever describes the characteristics of responses could be safe to forward um all um so for example if we were to introduce a mechanism to the the classical clockwise responses that allows the server to respond with multiple block 2 options are block 2 messages then we could have a proxy unsafe option that says and by the way you may send me the next 10 blocks but then that option would be only for this purpose whereas if we had a more General option that says and by the way you may send 10 blocks and maybe some additional options says and by the way and please do and please do really use that to send blocks um sorry so the one the critical up uh the the proxy unsafe option is keeping the token open for some time or some number of messages or until some condition is met and then other options would not be under the pressure of being proxy unsafe this is especially important when"
  },
  {
    "startTime": "01:24:01",
    "text": "looking at what options are inner and outer in the oscore sense because the please keep the gates open option needs to be outer because the proxy that is not participating in oscore needs to be aware that there are multiple things coming in but we don't necessarily want to tell that proxy what it is we're doing are we doing multicast here are we sending uh doing a large block transfer um in a block transfer that's not supposed to be visible to the block to the proxy so having a general purpose option would make sense whether we have should have one or three of them like one for eventual consistency which is already observed one for um open until further notice and one for open for this and that many messages I can't tell yeah or or at least you want to say that proxy as this as possible for example not tell for how long whatever is going on is going to go on you imagine the use case of that kind by the way a few weeks ago then we also try to capture in the minutes two weeks ago okay it is still the same document of course but you are clearly targeting um a revision of its scope of course uh do you plan um yeah a revision incorporating that new scope uh basically in the next few days for the cutoff or so um I have a list of about five uh five documents one down four to go uh open and I don't know if I will manage to update something here and frankly um this is so I think what should go into the next update of this is a bit of implementation experience um I do have basically two Co-op implementations where I'm considering"
  },
  {
    "startTime": "01:26:00",
    "text": "pivoting the implementation of observation Etc onto that track um hearing that I that that there was positive feedback out of the working group I think it could next step for me would be to um to to also gather that implementation experience and then feed that back into next iteration so not planning to present on on 117 and I don't think I will have an update um in time for the cutoff custom yeah I think this might be a document where um submitting it on the Sunday of the ITF also would work and in addition that comes uh uh in the aob section yeah we were considering having uh this is one of the main topics for the site meeting yes booked for the Friday of the ITF week wherever we are with this topic I mean can be again an open discussion like this with more time available or concrete discussion on a submitted draft the things it will be easier to do the Friday meeting if we have a document that already has some some updates in it totally thanks for the work you're putting on that already Christian Karsten all right then I'll try to do an update in time for the for after the cutoff let's organize this sounds great any more input or comments on non-traditional responses okay if none we are the aob and we quickly touched on most of this actually"
  },
  {
    "startTime": "01:28:00",
    "text": "so we are meeting in 20 days from today on Tuesday 25 or two hour session um in the morning of San Francisco mid late afternoon or late afternoon in Central European Time Zone and then we have uh already booked a time slot and a physical room for a side meeting of core uh that's the last day of the ITF uh meeting all considering the main meeting agenda and room availability and so on uh but we reserved everything for uh well the same time slot basically the morning of San Francisco in the late afternoon in Europe um we have a link to miteko available to use as this it was created uh hopefully it works fine uh otherwise we'll use within Beauty as a fallback and uh yeah the idea was to mainly discuss uh non-traditional responses there I think we'll have something to discuss of some kind but any other topic that can fit also following the course session uh can be considered um and finally we were thinking very ahead of the next series of corinthory meetings uh post itf-117 and we have a very very tentative calendar uh just keeping the same cuttings as now uh on the odd weeks uh same day uh same time um it's just something first of all to confirm with the uh the chairs of seabor to be sure we keep interleaving uh I don't know Christian if you can at least confirm the intention uh to keep the same Cadence in seabor uh otherwise we'll we'll check better uh also made with berry yes the intention is to stay within the within the killing food we have had okay we'll open a thread with you I'm"
  },
  {
    "startTime": "01:30:01",
    "text": "better than uh if Barry also agrees then we'll raise this at F-117 further confirm on the list and there's no big problem we we go for it um there's one particular plan day where um cars and I are not available but as long as time is available it should be possible to have the the meeting anyway okay uh anything else you want to mention last minute if none thanks for the great work uh see you at RTF 117 okay thank you thank you bye-bye thank you thanks Richard and Christian for the minutes appreciate it yeah no problem thank you all bye-bye [Music]"
  }
]
