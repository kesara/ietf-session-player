[
  {
    "startTime": "00:01:17",
    "text": "I'll give her in one more minute, and then we'll get it going."
  },
  {
    "startTime": "00:02:13",
    "text": "Alright. Welcome, everyone. This is CCPL. Not here for TPM, then you're probably in the wrong place. Yoshi, Michael Texan, or on the conference. Here's the note. Well, you are likely familiar with it, but it's the start of a new session. So you're not, please take a close look. As usual, the session is being recorded. Andrew has kindly evolved to be no volunteered to be nuke Okay, Kurt. Thank you very much, Andrew. She's gonna be jealouscribed, And as a reminder, use draft TCVM as the name for IDs, you publish them, next slide. So for agenda, I'm gonna start off with 15 minutes, but the working group, and status on documents, RC, 6937bis. It's gonna be discussed by Neil to be accurate request, do another update on that. Than 10 minutes for individual drafts, but service committee. And then there's also 20 minutes for Ghostax. As you can see here, the working group draft payments currently in progress. How about are the ones that we're gonna do updates on today? And I think that's That's it for yourself. Yashi, you wanna say something about ROCE 937bis. Okay. Yeah. We have a presentation 6939 Bistroft today. Basically, we have been running working group to go on this route for time. So I think, you know, today, I"
  },
  {
    "startTime": "00:04:00",
    "text": "we can discuss if we can conclude this working with us to go or not. So from, then, yeah, just what's, result of the discussion right now. Yeah. The Accord EC EDU graph is also after working group last call. N I had some final Questions suggestions regarding the text, describing, offload. But I haven't heard from the authors yet. So The authors might want to consider answering After that, we will have TCP generalized DCN stuff. Go ahead and pull the working car. Can TCPEDO and activate. I'm on the first one is an RFC editor queue for know, 500 and days or more. So that's usually Okay. That means we can go to the first presentation, Alright. Okay. Great. me? Are you guys able to hear Perfect. Great. Yes. Okay. Alright. So today, I'll be talking about proportional rate reduction for TCP. This is work. That I've been joining recently and that's, a long time effort started by Matt Mathis and, Dita and Yuchang at Google. And I'm just helping out with, with some recent, updates to the draft. Next slide, please. So, just a quick"
  },
  {
    "startTime": "00:06:00",
    "text": "overview and history here. Proportional rate reduction for TCP was first published in 2013 as an experimental RFC. And at that time, it was only implemented for Linux TCP. And this was, of course, well before rack. And so it was implemented without a rack TLP. And PRR, you can sort of think of as a mini congestion control that runs only during fast recovery. And, at a high level, the idea is to send packets at the ratio determined by the congestion controls, sealant reduction. So for Reno where you cut the c 1 in half, it'll be using that proportion for Cubic where you cut the CUNs to point seven times the previous sealant, it'll be using that proportion. And if the amount of in flight data drops below the SS Thresh chosen by the congestion control then it will use 1 of 2 modes to decide how aggressively to increase the amount of in flight data it the draft uses the terms, slow start reduction bound, and, conservative reduction bounds to describe those 2 different modes. And, the in the original version of PRR back in 2013, the implementation had to pick between those 2 different mechanisms. So an interesting fact actually is that a flow that mostly operates in fast recovery So, for example, a, a video flow going through a cellular provider that police's traffic might spend a large portion of its lifetime in fast recovery. And in that case, the c one of the connection is actually mostly controlled by,"
  },
  {
    "startTime": "00:08:02",
    "text": "PRR rather than Cubic. And look look at a packet trace, you basically need to think about, the PRR behavior in order to understand what's going on. Next slide, please. So, 6937bis The idea here was that, in 2021, we, as a community, realized that we it's been 10 years since 6937 was published. And at this point, PRR is pretty widely implemented in the major TC piece stacks. It's default enabled in Linux freebsd, deployed by Netflix. And in Windows TCP. And so the TCPM group voted to provide and publish this as a standard RFC. There's a link there to the the current version of the draft. And, the main revisions, since 6937 that we've previously discussed. Include some algorithm refinements So the main and refinement and the most interesting one is that The algorithm now includes an automatic heuristic that automatically chooses between the 2 different techniques for handling the case where the amount of in flight data is below SS Thresh. So that it automatically, determines how aggressive to be. Based on the signals it's getting about how whether the connection is making good progress, without causing additional losses. The second main change is that it specifies that upon entering fast recovery, wanna make sure that we force a fast retransmit there are some edge cases where they wouldn't happen That's yeah. So that's the second one. The third one is that we specify, non SAC"
  },
  {
    "startTime": "00:10:01",
    "text": "support. What should happen in the case of connections that don't have SAC support and then finally, it specifies an approach that's that has improved handling in case a connection has experience higher network reordering than the default. And in that case, there can be a fair amount of data that's been electively acknowledged before fast recovery starts. If, for example, you're using rack TOP to adapt to reordering. And, all of those, have all of those algorithm refinements have been in in Linux TCP for a number of years. I'm not sure which other stack have those variants, but but these are all very well tested and and widely deployed at this point. We also made some editorial clarifications, that are described here. You know, we don't wanna slow start an x that trigger the the 6675 last resort mechanism, it clarified the relationships with RFC 6,675, and, 8985 rack tlp. And then we removed the experiments section since that's a bit obsolete at this point. Since, for example, the baseline algorithms don't exist in the Linux code anymore. So it was hard to rerun those. Next slide, please. So this is just a quick summary of the changes between the version 4 of the draft, which was the version at the time we last presented this in July of 2023, and the current version of the draft, which is version 8. And the good news is that there have been only really very minor changes between 4:8. And so I I'm hoping that we can today, perhaps, come to a consensus about"
  },
  {
    "startTime": "00:12:01",
    "text": "concluding the the last calls now or soon. And then specific changes, we wanna go version by version. In version 5, we basically just updated the recover flight size initialization to more closely match the Linux, implementation. And, then in on the list, Richard, Sheffanager, gave us some good feedback that you know, the it's it's It probably makes more sense to stick with initializing will cover FS, flight size to pipe, which a high level is makes a lot more sense in terms of algorithm behavior. And you know, and we agreed with that, recommendation. So we we did that in version 6. In version 7, we just restored some prose, text, about that initialization initialize and recover flight size to pipe. And then we added a reference to Janney Host, sitcom 96 paper, that included rate having, which is you know, a core idea that, PR incorporates and and expands upon. And then in version 8, there's some minor minor editorial changes and that's pretty much it. And that's the last slide. So hopefully, we can just pick up on a discussion of where we wanna go from here. And, take whatever advice the chairs wanna offer here. Thanks, Neil. It doesn't appear we have any Any questions? Oh, you're he? Yeah. I just curious about the implementation status. I think Phoenix already support 6939 biz draft."
  },
  {
    "startTime": "00:14:03",
    "text": "And they are according to Richard, I think, previously is also supports 69 37 pissed draft. But, I just direct no history as a implementation does support this one. S nobody knows. I think you're correct of freebsd, but I can't. Don't know about any other matters. And they're being able to put this one. Right? Nail. Sorry. Could you, could you say again? Linux already support everything. Describing 69 subsidies. Yes. That's right. Okay. Can it also uses recover if it's being initialized with the pipe? No. It so Linux, For that initialization, it it initializes recover flight size 2. To the, the actual initialization is to the congestion window. Because the this sort of gets back to the the, related question a long time question in this, working group about when, you enter a fast recovery should you pick the slow start threshold based on, a multiplicative decrease relative to the congestion window or a multiplicative decrease relative to flight size. And, you know, the standards all say this should be versus flight size. But"
  },
  {
    "startTime": "00:16:00",
    "text": "the experience in the Linux community, including with Google and YouTube, is that setting the sealant in recovery as a function of flight size is is way too conservative and leads to unusually poor performance. And so Linux for many years, at least say 15 years, maybe maybe forever. Has used, seawend as the basis for the month it'll decrease. And so this is kind of a an area of the PRR implementation where there's some where the implementation is sort of affected by that decision but we sort of con consider that in implementation detail that is related to that design choice that is sort of a little bit outside of the scope of PRR, and we don't necessarily wanna open that can of worms in the PRR discussion. So we thought it made sense just to to document, the initialization of recovery of flight size to pipe, because it's a theoretically cleaner approach, and it's a minor difference in behavior. Relative to the actual Linux implementation. Okay. Thanks. Martin Duke Google with a rapidly disappearing hat so Are there any open issues or or or what what are the next steps with this draft? Are we As far as I'm aware, in the draft itself, there aren't any open issues. But you know, whatever the chairs are recommended at this stage makes sense to me. Please do. Is no outstanding comment. And the doughnut is very stable for now. Cool. Let's ship ship it then to mirrors. I had to pin out what day you pressed the button. Thanks."
  },
  {
    "startTime": "00:18:09",
    "text": "I I I would actually tend to agree that it seems like this is is quite a ways along. And, maybe the other question is, What what is the reason that we would not move this along at this point. Like, does does anyone have other objection? Like, or they want more implementation experience? Like, is there a thing that people would want before I move this along? Or or is this just we're saying yes and heard very quiet responses. So I'm gonna assume that That's probably an indication we should move it on I think so. Thank you, Neil, and let's see if we wanted to add anything else. Think cross that? I think we're all set. Thank you so much. Thank you. Okay. Hello, everyone. Name is Carlos Gomez, and I'm going to present the last update of the draft entitled TCP read request tar option. Mike author is John Krograf from the University of Cambridge. Next, please. Michael's actually, Thank you. Yeah. So first of all, reminder on the motivation for the draft delayed that. Is a widely used mechanism, which is intended to reduce protocol overhead However, it may also contribute to suboptimal performance in a number of scenarios. Such as so called large congesting windows scenarios meaning a congestion window size much greater than the MSS where saving more than 1 of every 2 acts may help improve performance"
  },
  {
    "startTime": "00:20:02",
    "text": "and also so called small congestion window scenarios, meaning a congestion window size to the order of 1 MSS where delayed acts may incur may limit congestion, window growth, and so on. Next, please. So this is the main tar option format. It carries the r field which indicates the agreed requested by the sender, meaning the number of data segments after which a receiver should transmit an ARC, and then there's also the special case of r equal to 0. Which allows to perform a request of an immediate act. From the receiver while keeping the steady state value of r. Next, please. On the status of the draft, it was adopted around 1 year ago today and presenting and 4. Which mostly aims to address the comments that were received during the last IETF. Thanks, please. So let's go through the updates in 4. First of all, there was a major command by Bob Risco. That it would be good to clarify what's override star and what is overwritten by star. So there was some discussion and, contributions there from Jonathan and Gori. And the conclusion was that it would be good to add a general statement if possible, and then also to perform survey looking for specifications that may, provide rules on when to generate acts. So regarding General Steven, we have added at the end of the introduction in the last paragraph that TAR allows to override the delayed x mechanism from RFC 2. Well, complaining with the maximum delay of 500 milliseconds, And we've also added that, however, standard struct TCP specifications other than RFC 1122 and some informational specifications that command or mandate triggering acts in special conditions"
  },
  {
    "startTime": "00:22:02",
    "text": "prevail over time. Then we point the reader section 3.2 and appendix b for further details. Section 3 to 2, describes the receiver behavior in TAR. And appendix b. Next, please. Appendix b contains the result of the survey that we have carried out we have looked at around, 100 documents looking for content, specifying rules on when to send eggs in special conditions, So, the result of those documents which contain such, kind of rules is in appendix speed. And, of course, if anyone detects anything that we have missed, please let us know. So of all, regarding standard straight documents, the first one is RFC 1122. Which specifies that the receiver may send an act in response to an out of order segment that was intended to support the biden experimental fast returns meet algorithm. This was then, increased in RC 2018, it the May was in Chris to shoot and also it was indicated that the act had to include the selective option for every valid segment that contains new data. And all this was, reinforced in RFC 5681. By stating that a receiver should send a duplicate immediately when an auto order segment arrives. And also, receivers should send an immediate act when the incoming segment fills in all or part a gap in the sequence space. So as you can see, color green, this content was already covered already part of section 3.2. Of the TAR specification. So we didn't have to perform any action regarding actually the 3 out of is indicated here. Next, please. However, there are 2 other standard track documents that were not covered yet in the previous version of the draft. The first one is I've seen"
  },
  {
    "startTime": "00:24:02",
    "text": "5961, which tries to provide protection against an off path attacker that may want to reset an existing TCP connection. And, the texting 5961 is that if, a receiver gets a segment with a reset bit set the sequence number doesn't exactly match the next expected sequence value. Yet it is within the current receive window, then the TCP receiver must send an act, is called challenge act, which will help determine whether the other endpoint is which a truly attacker or not. So, this text was not covered yet in 3. So what we've done is we have added explicitly this texting section 3 to 2 in the latest version 4. And also there's the draft, the accuracy and draft, which also provides some rules to generate acts in some show conditions. There are change triggered acts where an accuracy and data receiver should meet an act whenever data packet mark CE arrives after the previous packet was not and also increment trigger attacks where an accurate ECN receiver of a packet must meet an act if a number of CE marks have arrived since the previous act. So this was not either in the previous version of TAR. So now we have also included this, especially is as part of the behavior the receiver in section 3.2. Next, please. Also, in in the appendix, we have included informational documents we have found 2, which are relevant here. The first one is that I've seen 5690acc cc, which, as you may remember, was already cast in the tar document in appendix A disappendix aims to clarify the similarities and differences between accuracy and power. And FCC aims to perform congestion control for acts. Whereas Tara is a bit more generic and perhaps can be used as a tool for that."
  },
  {
    "startTime": "00:26:02",
    "text": "Also Tara has, the special feature of requesting an immediate act any way, we understand that, there is no further action that we have to do on the our document regarding this RFC 5 619, And then the other informational document that we understand is relevant here is RFC 8257, which describes, data center TCP. It has some rules to generate action special conditions, which were not covered in the previous version of the tower. Document. So the rules are indicated here when, receiver gets a packet with the C code point set and the variable called dctcp.c is false, then the recipient must send an immediate Also, if the c code point is not set, but the variable is true, then the receiver must also send an tag and also a receipt of me choose to send 2 acts, one for previously and acknowledge packets and another one acknowledging the most recently received packet. So we've also added, this content these rules explicitly in, section 302 in the last version, of the document. Next, please. And regarding experimental documents, we found that RFC, 4782, which specify a quick start is relevant here. The document explains that a sender using quick start may produce a sudden increase of pure acts the document also explains that in the absence of a mechanism for act congestion control, TCP receiver could limit its sending rate for acts sent in response to quick start data packets. And then a formula is given in the RFC to determine after how many if data segments, the receiver needs to transmit an act. We understand that TAR can be used to allow a quick start sender to request the upgrade to be used by the receiver. And we understand that"
  },
  {
    "startTime": "00:28:02",
    "text": "we don't need to perform any particular action in the tar document related with the quick start out of sea. Next please. So summarizing section 3 to 2 has been updated, that's the receiver behavior has been updated to clearly and explicitly include the rules regarding act generation from these three documents, RSC 5961. Which tries to protect TCP in this case from, off path attackers. 8257, which is a data center TCP and the accurate ECN draft. Also, there was, common by Gori that prompted the the last point, which is that, after explaining the general behavior that, the tar receiver should send, an act after our data segments received, Then we've added that the receiver's count of data segments received from the sender is reset every time that the Nakis sent for any reason. Next, please. Finally, there was another common by, regarding what happens if the receiver window size changes, that's because the sender, there's a rule that it must not request a value of r greater than the current receiver window size, but then what happens if the receiver window size changes? So we've added some text, intended to address or explain what happens in the perhaps short time during which, there is a bit of this synchronization there that the sender hasn't yet realized of the receiver window size change. So, in the section 3.1, which describes the sender behavior, we've added that if the receiver window size has increased, and the sender doesn't know yet Anyway, the sender will not request, and our value corresponding to an amount of"
  },
  {
    "startTime": "00:30:01",
    "text": "data bytes to be acknowledged at once greater than the current receiver window sign. So there is no issue here. And, otherwise, if the receiver window size has decreased, and the sender, there's no yet. Request of an R value leading to an amount of data bytes to be acknowledged that once greater than the current receivable window size will be any way ignored by the receiver and that's based on previously existing roles in 3.2 in the previous version. Of the And finally, we've also added in section 3, the 2 draft. about on the receiver side that if the receiver window size decrease us to a value which is lower than the amount of data bytes to be acknowledged at once for the latest are requested. Then the amount of data rights acknowledged at once by an act to be sent by the recipient DCT must not exceed its current see the window size. Next, please. So, well, that was everything from my side. Don't know if there are maybe questions or comments Hi. Hi, Reese Engelhardt. I'm just curious what's the implementation arrows of this. Yeah. At at this moment, I'm only aware of some prototype implementation that actually was led by, Michael Tookson, for freebsd. So any further implementation activity that anyone is aware of, Please let us know. Are you engaging with implementers at all? On this hackathon project kind of thing. Not usually, but yeah, perhaps I may have to engage as well in this kind of activity. Sorry. This thing takes forever. Martin Duke, Google."
  },
  {
    "startTime": "00:32:01",
    "text": "The, To what extent do we think data from The quick experience with this is applicable. Terms of, like, performance and tuning and all the other stuff. I know that's not your draft, but The author of that is nearby. So if either of you, you could answer that, that would be great. So, well, I I haven't performed like a detailed study about that, but my kind of immediate reaction would be to say that it should be quite applicable I don't see, like, fundamental differences, actually. But perhaps there are details out there that maybe We might to double check. Antoinette is an individual contributor as well as author of the or one of the offices of the act frequency drafting quick. Think for the most part, it's applicable, but there's an some critical differences, about speed and how implementations in particular, things like how we'd gone through and spoke with GRO, another kind of receive off load and aggregation. These can greatly reduce the number of acknowledgements and in real world applications you know, obviously implementation event, but at least I believe in Linux. And so The marginal gain of this Might be smaller, I guess, would be one thing to to point out. But I think probably the end tuning you would want would end up being extraordinarily similar. That'd be my comment. So so it is going to be different. Some ways, but I'm not sure if the end results reflect what kind of parameter optimization values you'd wanna use ends up would end up being meaningful meaningfully different or not. I guess what I'm getting at is, given that this is not we're gonna have to have a make a decision about this document before we have, like, wide deployment variants. And so I I one part is, like, Is It doesn't have to be as beneficial as quick."
  },
  {
    "startTime": "00:34:03",
    "text": "For the reasons you described, but the direction should be Right. And I guess the other concern is a safety one because, obviously, a bit of box is all kinds of weird things to TCP. Are we, are we making something really unhappy in the network with this can't happen in quick. And I don't know if you have any insight on that. Not aware currently of any particular danger anyway. Yeah. We've been trying to to be careful about, not to break, let's say, the the basic synchronization between sender and receiver not to kind of damage, communication performance. I mean, like, for example, it's been a while since I've dealt with, but I'm aware that at some point, there have been, like, finners deployed in the network. And, you know, if, like, they're thinning the if we thin the accent and they get thinned again, that could be, Not so good. Anyway, don't expect you have an answer on that right now. I think there's some things to maybe consider and look at, and I think I That's the safety concern that would maybe be the major obstacle was something like this moving forward. FX. Yeah. Thanks for the comment. Yeah, we're going to think about it and consider that for the next date. Thank you. Sorry. You're next. Yeah, Isis. Can you hear me? Yes. Bye. Wow. Long delay. So, I was gonna chime in on the same as Mark really because I think the difference between t in quick here is that there are devices in the network Some of them might be old, that might be more worrying, some of them might not be old. But they try to control the act rate in the network for TCP"
  },
  {
    "startTime": "00:36:02",
    "text": "And good news is for quick, they can't do that so they don't. So I'm kind of for the data which shows how the interact would These proposals I don't know how we get to see that data to be confident that what we're doing here and implementing this actually works in the networks and doesn't make it worse. You have a plan for how you might get that data? Well, there is not a plan, but, yeah, definitely set data would be great. The the document intended status is experimental. So, also, Yeah. Let's say that, it would be good to experiment with this and obtain experience based on that. Yeah. Let's see what we can come up with. Let's also I'd like to maybe, make a call to anyone who might like to engage in this kind of effort to try to to deploy, implement form experiments, maybe you can get in contact with with us, the authors. And, yeah, let's maybe try to to get, this kind of data if possible. Thanks, Rory. Matt, Yes. I was Just starting an investigation where I'm looking at act interarrival times. And I've I've been Using for a long time about the potential for multiplicative act thinning or their the polls digits in the past, pretty much the same problem that other people are mentioning. Multiple parts of the path. Where people send the ax. There is a single sentence in doxis, which recommends acthining. It doesn't specify it at all, but it's in the standard. And So I'm very worried about this. Luckily, I do have a data"
  },
  {
    "startTime": "00:38:04",
    "text": "measurement lab has got a run right now of about 4,000,000 tests a day and Almost all of those tests have peak gaps. And I'm actually harvesting those peak apps for information on on act processing, ARC, acronym, arrival. And I would love to talk about some of this stuff out of band. So Thank you, Matt. That sounds extraordinarily promising. I appreciate your, your help. And it's a global 4,000,000 test a day. Okay. Alright. Thank you. Yep. I think that I think that's it. Did you have anything you want that's you want from the work group? Look or not. Okay. Very much. We appreciate the update. Hang on. Hi, everyone. Can you hear me? My name is Krishna Ting from China Telecom. And, my talk today is service authentication for TCP based application. And the is our, draft And, if you are interested, please feel free to review it. Next, please. And, my presentation will run below as per clothing background and motivation of this draft and, considerations of the existing solutions and the proposed distortions and further actions. Next please."
  },
  {
    "startTime": "00:40:05",
    "text": "And, as a number of customers and so race requirements continue to rise. There is a pressing need for network to be more flex and responsive. And cause a prefiguring, allowance service to be deployed cross Wara's Resort post However, this also introduced challenges to efficiently directing cost from traffic to the optimal service note especially when multi No. It's sure the same and cost type you addressed. The dynamic The dynamic nature of network Stitchards and computing, resource post a challenge. Traditional my third of traffics during rely on the teachers connect term tables, which are unable to adapt to rotum trains. This kind of results in suboptimal, routine decisions. Led to the great customer experience. Additionally, load balance shares deployed in front of fiscal service can come both to max during pick, pick traffic parts. Next place, mattaining arts, Large protection tables in network device for is customer flow flex flexible and transpo, a particular for a large scale service deployments. Over traditional redirection, mister, like doing a re retraction suffer from crutcheon ice rose. Constant licensing, directing traffic to a little, available source. This information is"
  },
  {
    "startTime": "00:42:00",
    "text": "ultimately, in parked customers that is and the service reliability So, to address this challenging process, ocean for the, service advantage between client and the service, one newly formed option, which can realize, comprehensive scheduling based on real time network status. This solution eliminates a need to maintain customer based the connections, digital tables for network device. And, improve the flexible and scalable of, And large scale deployment of Anika's service scheduling. Next, please. So in our considerations for optimize network traffic management we've identified several limitations in existing solutions for example, in load balancer, and, well, effective for the JPO team traffic load balancers can come both to knocks during peak usage part. Impacting our real network performance. And the director traffic and direct traffic re redactions and traffic cartoon between the clients serve awards, bottleneck of load better serve. And new amp TCP it enables us to send package to belong to 1 turn over, different parts, but it is confined to the I'm, I'm participating for more. So we want to find one solution that can match such requirements a more general manner for TCP based, application. And, HTTP"
  },
  {
    "startTime": "00:44:03",
    "text": "directions. This method primarily involves communication between clients and service and, does not provide real time optimization This is based on network and consulting resource teachers. And, dear, I, sir, Redirection, change to the ice recourse take time to, prop per package affecting customer experience due to potential delays in sizing updates to our location. So, we proper a solution to address these limitations. And that place, Next place. And, the procedures for the server authentic solution and the transmission process of package are showing yin, in the pictures The proposed service advantage solution involves the following steps Is the social a new flood as AF is requested for identify the sender's port, DCP, surrace, affinity option. And the first customer agent A request to package to the ingress router already with a swine and the SAS flag such indicating sports, for the TCP storage of Fintech Auction. The destination address is the site to the uncast fuel source of the service. And then, Inqurest Rotor, are you evaluate real time network and computing resource deter to determine the optimal, sir service note"
  },
  {
    "startTime": "00:46:01",
    "text": "for customer authorized, such as the note behind Richard And does that if the select service notes supposed to dissipate, source of anti affinity option it includes its IP address and port information. It's a SAP Fund, A filing package of the connection response message, message, message, message, message, message, And, Customer a establish, connection to this perfect specific service notes or drives providing the response. Maternal Arts And Duke Communication And throughout the entire process, network device Only need to broadcast the information about the computer network. Enclosing the any cost IP, address the terms of service note under specific address of service note. Was this information optimized the scheduling of community networks resource can be performed ensure efficient service delivery based, real time network and, computing resource teachers. And next place, And, you have a drive It's y Okay. At 9 of some can mess the demand of, source of So, with the funds 2 new TCP options. A previous survey is authentic. And, A few Willow service event option, and use the pick"
  },
  {
    "startTime": "00:48:00",
    "text": "pictures, you can see the encoding of some and some, different There's options. Carding is a TCP fun package. Sending by a service note. As a dry cousin must be the address owned by the service note. After receiving, receiving the TCP phone package, if this GCP option is included in the package, the customer will establish the connection to the address pizza for cheeses of in this option option And next, please, in source of interest, the risk of 6666 traffic head jerking up. Did you owe us a tax post significant concerns, attackers may exploit a source of anti flag, I say I by sending TCP pass Package to service note, potentially getting access to the any cost that you address and the launch in legal activities or GDOS attacks. So, to mitigate this risk, indeed US attack provision We will be implementing a fiber as a protective barrier infers at traffic resizing source note undergoes thorough filtration before, reaching its destination. And, this proactive measure have to vote potential, digitalized attack by filtering out malicious traffic. And, first served serve information security users and started to access in the network and undergo assortation and the verification. Process to prevent"
  },
  {
    "startTime": "00:50:03",
    "text": "Authorized access and information struck down the store. This means for such only legitimate teacher in touches, granted access to sensitive serve information. And furthermore, press solution offer comprehensive defense against the virus network attacks. But I leverage this security models in conjunction with 5 firewalls, constitution, bolster, network defense against common and emerging threats. Safeguarding, integrity and availability of us Paris, next, please. And, that's a main concern of this presentation. And, Anna, comments, please refer to contact us via email. Thank you. Ian Swepp from Google as an individual, contributor, not chair. First question is, why would we not why is this the right layer to be doing this. In particular, like, if you're already going to have an authentication mechanism, why not do this inside, like, the TLS encryption envelope where A number of the attacks you mentioned I think would be, at the very least, massively more difficult okay. That's a good question. And, I need to consider this So come a college from and Johnson answered first Thank you. Sure. Yeah. Thanks. A couple of comments. So"
  },
  {
    "startTime": "00:52:03",
    "text": "Why are you using a flag and the zoom and why don't you just reuse your option. That would save a flag, I guess. Regarding the options. Why are you using reserved fields? Why don't you put the part number there and You have alignment and, Don't decrease our fields. And the last question is, Have you tested this with some sort of middle boxes? I mean, a soonfin exchange is not Looking very Cummen, okay. And, This question can my colleague convey concerns first Okay. Go for it. It's Is Hello, Alex Meinta. I think yeah. And I'm not stomping on it. Oh, yeah. Adrian from Taicom. I tried to answer one question, a user flag just to use the result field to define my new flag try to single. That is the customer supported you'll say options. So the Once, sorry to see what this the the TCB seeing since single is this flag set, then the server can send the newly address to the customers. So"
  },
  {
    "startTime": "00:54:00",
    "text": "We we we just want to keep the TCP connection very quickly to finish the it's a collection. So why can't you instead of setting the flag, Hi. Put in your option. Indicine, Without an address, Oh, no. The option either carried either, send back from server to the customer from server to a client. Send it send it from the client. Without an address, just as in indicator want to do this. Oh, you are you are saying? To the flag. Yeah. Okay. You say you see your sessions that you the customer is saying the option directly to the server. And we and do not use the flag to, you know, to find a new leaf flag, Just use the flag you have. Just use the option you have, but without any Elio. Okay. I think this is the 1. We we can consider this suggestion later. What about the middle boxes? We have, we have an to some in the public network and, if the if the store uses the public address, there is no question to pass the middle box, Yeah. We held justice, we held down some implementation for this is, trapped. But not test all kind of the, you know, box There is no there is no problem encountered in our testing scenarios. We did not test the all of the the all all kind of the middle box. Mhmm. Okay. Mhmm. K. And the"
  },
  {
    "startTime": "00:56:03",
    "text": "I'll explain the units of it. I think you know, because the the network of onto, optimize the traffics based on the network status. So We we, obviously, we will deploy the any customer service and the net the entry the 80 point of network command can do the optimize selection for the traffic, sir. So, we compare our solutions such as the CPM base and the DNS, there is no no suitable solution to to solve such problems And, if there is if the TCP did not spot the it's affecting the application there, the the device with the network must must have stopped many, many, many, many table, same the same number as client. So it we think resolution is not not not a deployable, cannot deployable. So we prefer use this kind of the and the on our An error, and setting the the quicker has similar mechanism. To for the server, migration. So I think but the TCP had no such a mechanism. So we think we need such a mechanism to, to meet our requirement Okay. Thank you. Alexander? Hello, Alex. I'm talking. I'm kind of still feeling sort of a bit new to this. I've been flipping through the mailing list. It does feel a bit like this has been done at the wrong layer. I'm one of the scenarios, another possible solution is to do tunneling between your service notes, that would avoid problems with"
  },
  {
    "startTime": "00:58:01",
    "text": "everything that you described in your slide there, a lot of any cast deployments will tunnel between service nodes if they need to if if the traffic landed in the wrong location because of wider, wider, network topology changes. Has had was that something just considered and not on the decre in the present in in in the draft, or is that a non option for you? You your your system that we use and tunnels, tunnel services to account account police is the requirement. As a solution, for if traffic is landing at the has been determined to now land at the wrong any car service to Tunnel 2 It it's like between the service nodes, your service mesh, why not just steer and reroute the traffic to the other service node. I understand that my you might be looking for a shorter latency. But then if you're redirecting the person anyway at the TCP layer, you've kind of lost that the the advantages of any cast in the first place So I'm trying to understand why you would just not do tunneling behind the scenes behind the curtain, and get the traffic to its right place. Until you had an opportunity maybe to, redirect the client to a narrow node through another method, if that helped you. I'm trying to understand why you would do this in the TCP layer rather them behind the scenes or as some other people have suggested at a different layer. Like, if this is HTTP, I mean, we talked about redirects, but, or whatever reason they don't work here. Because, you know, kinda, many applications that not based on the there is are"
  },
  {
    "startTime": "01:00:00",
    "text": "TP. They just use the TCP. So we is the one to make the solution more general. And the and the second consideration is Yeah. The first selection is made by the network, network device, based on its top logic status and the network network network needs. And, But, run the network change, the, the service that we will be directed to other either service in order. So we don't want we want to keep the service affinity. So lean, lean, They went to the the the client use You have your address to connect to the server. So there there is a phase for the, Odessa Odessa transfer. So first, the client, the client connect to the any customer address of the server. Then transfer to the 0 address of, it's of the servers. So after the transfer after the, transfer. The service of your the connection of your We will not be trained either. Based on the network topology change, So we we we we we call this the service affinity. Yeah. Come. You. I would like to I Oops. I I think Sorry. Sorry. Maybe I'm, explain not very clear. So, if you have a question or comment, we can't discuss on the My list, I can explain. I am more clearly Of course. I'll do that. I I I've popped an email onto the list, and we can hash it out there. That'd be fine. Yeah. I would I'll I'll go through the remaining two people. Thanks for your shinglers. I'd like to get on to the next presentation because I I I'm wondering if it might have a fair amount of discussion afterwards as So, oh, Yashit, did you"
  },
  {
    "startTime": "01:02:04",
    "text": "I guess Lars. Yep. Matt. Joshua, go first. So I have some the security concern with this draft. So, you had mentioned that, you know, We can use, you know, Some bacon, that's you know, prevent those attacker traffic hijacking But, is this optional or is this mandatory? Because, you know, My concerns, if we use this proposal as it is without any Nick Isum, Nick Isum, I think it's the deal scary. Because, you know, all I need to inject is just, you know, him take the pain packet. Just land back If I City. Injecting this Packed impacted then I can redirect audio into my logos. And then then after that, I can do whatever I want, So I just have a direct to have a security concern, and then you need to think of So if you I think I need to, enhance, you know, but kind of security and the kinds that you need, for this approach. That's my opinion. Yeah. We have discussed the the the security research member with a prop with a possible solution for our proposal and they told us that there is there was no Circular Circuity enhance the solution. So, I don't know. You is there any person in the TDPM can give us guide for the, security enhancement solutions. Are eager to get the profile from, CSM from ours. Good Thank you."
  },
  {
    "startTime": "01:04:06",
    "text": "Hi. Lars Eckhart. So I I think we've seen presentations of this draft several times at various ITFs. And My memory is far from perfect, but I think the issues that are raised are more or less the same. Time and time again. And I I'm kind of wondering if we sort of reach the end of the road for this traffic, because I I don't really see a progression here at the the group gives feedback that maybe the the approach here is sort of, something that is already level and then security issues and other things. But once come back and say, no. We really want this. Right? And then sort of it seems like we're going in circles here. For a while now, and we gotta sort of figure out a way to break that circle. Thanks so I appreciate that. much. I locked the queue, but does anyone at rather the chairs have anything else to add before we move on? Thank you. Good morning. Upload. Can you folks see me? Very good. Yes. So, name is ma'am, and and good afternoon. Germany, my From and I'm a security researcher at the Cispah Animal Center for information security, Germany. I'm presenting joint work with my PhD student. Yifeng Pump. And the talk is about a phenomenon. We dubbed ghost acts, And it is part of our research paper on TCP spoofing. That we will be presenting at the I triple e security privacy resulting symposium in May this year. And one primary front I'm new to the format of IITF meetings, so I might not use the same terminally as the regular tennis are used to So please excuse that. Next slide, please."
  },
  {
    "startTime": "01:06:02",
    "text": "When thinking about, spoofing in, in TCP, you know, you normally think about, GCP injection attacks. Which is the most difficult attack that comes to mind. And in this example, an off path attacker tries to inject payloads into an established TCP correction. For example, if you look at the example, figure at the bottom of this presentation, you'll see that there is a client at FTP client that has a connection to an FTP server. And an attacker tries to inject malicious FTP commands into this unprotected TCP connection. For example, by deleting in order to delete the file on the on the file server. To this end, the attacker has to know that the connection exists, including the client's IP address and soft spot information and so on. Furthermore, the client has to adjust certain TCP, characteristics such as the relevant number, and the sequence number to specify in the spoofed requests. In the presentation, I would focus on the tech act. So the acknowledgment number that the attacker has to choose in order to spoof, as in some scenarios, the, the sequence number, is actually known to detect it right away Unfortunately, you look at the, typically, the, the main basis TCP standard are C9 to 93. It is quite tournament, on this handling of, acknowledgment numbers. Suggesting to accept any agronomical number, which is more or equal to the next, next point. And this doesn't provide much protection against brute hosting attacks, and hence attackers can easily find acceptable enrichment numbers in the standard TCP. Next slide, please. Hence, RSC 5961 shrinks the range of acceptable eggnumbers by considering spoofing attacks, which significantly lowers the chance"
  },
  {
    "startTime": "01:08:00",
    "text": "that the attackers find an acceptable bank number, by brute falsely. That is, instead of just checking, that, the ownership number is smaller than, next the ARC says that the acknowledgement number should also be at most one send window back. In order to be acceptable otherwise should be rejected. So if you look at the representation of the sender's GCP state, at the bottom you're gonna see a couple of green boxes. That show bytes that, were already sent and were acknowledged by, by the other, by the recipient, Then there is a couple of yellow or ocher boxes which provides that our sent we're nothing on it yet. Being pointed to the, being pointed by to the by the, UNA pointer. And then there is gray boxes that will be bytes to be sent next being pointed to the next quadrant. So in the figure, you can see which electrons will be accepted, which is up to send next, which makes sense. And and down to, send you an a minus send window. Means that we do have for this example I think about just 7. Wise to be acceptable and and if they're specified as the in order for number. In the X segments. This explicitly includes some of the green bytes, meaning those that were already already been acknowledged enhanced tolerance, duplicate. Acknowledgments. And this is Exactly the region, which can become problematic, if you consider it a fresh TCP connection. Next slide, please. So if you look at a fresh, TCP connection, You have no dates no data to be exchanged yet. So the UNA pointer is, equal to the next pointer. And there simply has not been data, any data being sent yet. Unfortunately, In this example, the duplicate x are even known in this case, even though there's actually nothing to acknowledge yet."
  },
  {
    "startTime": "01:10:00",
    "text": "So if the attacker chooses, to spoof acknowledgement numbers from that red remains here. Which is the same as the green range, the the the window range before in the previous slide. But this time, trying to acknowledge data that wasn't sent yet. And, that she if you look at the to our C center restrict the range of acceptable pack numbers can see that both are received 59 and 61 and and 9293. Do allow for such engrossment of the data was actually not sent, which we are gonna dub ghost tags in in the presentation. unfortunately, this has consequences from a security perspective. Because these loose, egg number checks enables attackers to inject data into, especially in newly established GSP connection. Which eases, both TCP injection attacks but also, IP spoofing attacks in in TCP. Next slide, please. In order to guarantee that one of their, spoof segments hits an acceptable acknowledgement number Tigers just have to brute faults, take numbers based. By incrementing the acknowledgement number, they specify by sent window. So, that means the large send windows does reduce the complexity. Of proof of forcing of fresh connections. The Turkish just have to try 2 to dollar 32. So 4000000000 times divided by send window times to hit an acceptable x value. If you consider a very large window of 1 gigabyte, for example, this ultimately means attackers just have to try 4 different segments, and one of them will hit the correct, into the correct sent window. And in, in this example, the attacker, just device experace in the three parts. And the second injected acknowledgement number would hit an acceptable acknowledgement And, unfortunately,"
  },
  {
    "startTime": "01:12:02",
    "text": "Those goals act with only ease injection attacks. In, in fact, in our research paper, we mostly focus on TCB spoofing attacks in which the attacker aims to establish a peace proof connection to a server and then send payloads on this spoof connection. Thanks. Bye, please. So with such kind of TCP spoofing, attackers aim to evade any kind of host based authentication. This could be an attempt, for example, to evade the firewall that allow list, certain IP ranges or client piece. Or it could be also, attacks that are specific to certain application, their protocols. So for example, we showcased how an attacker can send a piece boost spam by bypassing the standard policy framework SPF which aims to enforce that only certain network ranges can send emails for a given center domain. And, therefore, this leaning way of of allowing those acts actually, does ease some of the attacks against indication protocol just send and spend. The two figures at the bottom show how these attacks could work. On the left hand side, in in stage 1, The attacker first has to brute force a TCP handshake by by guessing the correct several chills and eyes in. And and, yes, this is complex. Right? In the worst case, this means that the attacker has to has moved 4,000,000,000 packets. In a way with current network speed that is actually, very viable. And once completed, In the second stage, the attacker that wants to use this spooked connection in order to inject pales into this herpes spoof connection. And, unfortunately, Ghost acts are particularly held for you. Because attackers, only have to guess the valid, sent window. And increments the management number by a window every time. This example, we know this hand window is, 16 bit large."
  },
  {
    "startTime": "01:14:04",
    "text": "Which means that we only have to, try to the ball 16 times in order to hit and for its economic number. In contrast, if you would forbid such GoSacks. It would significantly increase the complexity of injecting a piece of payloads especially into fresh TCP connections. Next slide. We started, which of the TCMP static are affected by, by goal stacks and found that most major voices actually are affected. So we found the behavior to present in in Windows, Linux and, the 2 major whiskeys. And all of these operating system would find would would accept such goal stacks? With a little thing and help, from Michael. Thanks a lot for this. We also worked on packet drills, which, you can find the github repository here. In order to transfer this. But, anyway, all the break systems are actually affected by, the attack I should mention that the attack at the application layer protocols, of course. So if you have any authenticated or encrypted connections, for example, TDoS or T PA or whatever. You're less affected to the attack regions. In in that case, attackers have to either complete a much more complex handshake which they cannot, or they have to inject, as secure data, which which they also cannot due to legal case. Next one. Nevertheless, we reach out to, the devices in all through, start a mitigation effort. And the first to react was Linux. Which, mitigated the attacks by dropping Ghost X. And to this end, Linux release is referring to RC 4898. In which you do track some statistics about TCP connections in particular,"
  },
  {
    "startTime": "01:16:00",
    "text": "Here, the number of bytes that were already acknowledged by the other side. And the next therefore can now use this information in order to restrict the range of, acknowledgement numbers that should be accepted by by the the, the sender of the data. So as you can see here, the green parts of, of the criteria It's no longer checking whether, the entrepreneur is, UNA minus 10 window, but now it's checking if the, if the ownership number is sent you an minus min send window or bytes act, which means if there have to be no bytes act, then the account number has to be exactly the and next pointer, which then goes back to, I'm guessing the one in 2 to the power of 32 Possibilities which are correct. Next slide. So to summarize, we we've known that there's ghost acts, which are notional numbers, within the same window that acknowledged unscent data, they use GCP payroll injection, especially for a piece booked TCP connections in which the attackers control many of the other things, including sequence number, And we we also found that major arrests are affected by this. And, that the reason why why we're here presenting this to you folks is because we are actually interested in in learning if this is something that that you think should be address in the standards. Because I think it will be fairly easy to add an additional checking the standards to get rid of go sex, but also, you know, given that times are actually fairly old, I hear very little experience in how we could approach this. So, as a let me conclude this topic with an open question to you folks. You think we should address this in some standard? And if so, I'm I'm very open for your help. So thanks a lot. Thank you."
  },
  {
    "startTime": "01:18:03",
    "text": "Does it oh, Michael. So I think this This is, I don't think we need an RFC for this, but it could be done as, As an a router or something like this for, RC for 5961. And basically, the the Linux implementation has has, changed condition. Which checks, for injection attacks there. If we go down that path, I'm wondering for 5961. There there are IPR claims. So Changing this changing that condition. That's that. How does that relate to to that IVR stuff? Some from the Linux community here. How they deal with this. Because in BSD, we we we allow this kind of stuff to be disabled. Yashid. Cover. Okay. So, yeah, I Yeah. As possible, I would like to appreciate for this presentation. This is very interesting. Findings. Thank you so much. For bringing care. So I have one clarification question."
  },
  {
    "startTime": "01:20:00",
    "text": "Which is is this know, vulnerabilities only for it's the beginning of this TCP connection. And then other party is okay. That's what I would like to clarify first. So, yes, I mean, our research paper goes a bit further in in the bill to show how we can more efficiently spoof the TCP handshake But, I think our main takeaway in the research is actually that yes, you don't have to be they're accurate in sending the correct acknowledgement number in the spoof payload try to inject into their connection. So I think that's the main takeaway. So we mainly actually focus on the Marcus, Singup. Right? I So so we, we actually divide the attack into stages. The first one is the, The soon act in which you, which you don't have to guess any, in order to remember by the other side. And then, we we have the same whitebuffers group and with the second segment useful is the act, the final act, In the handshade? And and that part, we just proved false. So then we, in in the worst case, actually just show that you need 2 to above 32 different, spoof x. So the important part is now passed this logic. So once you do have NIP spoofed connection. Then, at this part, it goes back a complete because then you can use the go effects in order to inject IP spoofed, content into the IPS booth connection. So that's where the, goes correlippant it's actually passed the tiscreen rate. Oh, so I think I missed the part. I think I need to read the Jets before But, Yeah. I think, you know, That's For reason, you mentioned that you we have to keep statistics. Right? And then some implementation may no one do that, then I was wondering if there is other way"
  },
  {
    "startTime": "01:22:03",
    "text": "to, you know, mitigate this issue. Yeah. It's it's it's a good question. So we we thought of a few, you could also reduce the the window, which you accept acknowledgement numbers. Anyway, I think the the the there's more safest very end is really to track how many bytes we're encouraged by the other side. And, yes, this include some logistics key things. And I think all the other approaches will will it have problems in the long run? I see. Thank you. Thanks. Corey? Yeah. I was just wondering if you were intending to write a draft on this. Or whether it was something we had in Iraq far. So it's pulling up from Michael, but I loved the talk. It was interesting to see new new problems emerging. And I'm sure the intent was always not to do this. So thanks so much for bringing this here, and let's figure out how we document this and somehow into our record of how to do this well. Thanks ever so much. Are you planning to write a draft on this? So as I said, it's it's not really outer we have no experience in that. But we're very open to. So if if you think that's That's really applicable here. I think you're paying me could both go ahead and and write, at least a draft, which industries this problem, and also shows a couple of solutions out that if if that's of general interest to you folks, I'm I'm happy to Yeah. I would speak to the chairs, but, I would think a very short draft would be a helpful document just to have to discuss"
  },
  {
    "startTime": "01:24:03",
    "text": "and it could really be done quite easily. So I'd encourage you to think about that and talk chose, Thank you. Kyle? Yeah. I think this is great work. The one thing I just wanna add, when using TLS, for cases that are using TLS CRTT or, early data I don't think that will provide protection. Against that, and I suspect this is not, a property that people generally consider when enabling, TLS early data. So I do think this is important to, try to mitigate. Yeah. Thanks, Kyle. We we think so too. So we currently look into, into future problems that may arise out of this and definitely deal as 0 to prime is one issue where you're currently looking. I can't confirm it's it's it's it's probably problematic. Yeah. Good. Angie? I just mentioned I just want to mention that I basically agree with but scoring says, you know, if you, you know, prepare some kind of short draft, Dolby. That's a person, I think. Without chair head. Wonderful. Thank you very much for bringing this to us. It was a really interesting presentation and started nearly nicely I certainly wouldn't. I appreciate it. Thanks for having me. Unless anyone has anything else. I I think that's we have for today. Yep. On the chat, there was Someone asking for"
  },
  {
    "startTime": "01:26:00",
    "text": "yet. Right. GM. Com. You have you only have a 5 minute. If you want, So the question is, John, on on the, status issue? So the persons were asked about, p TCP, NMP quick. Yeah. Alright. It just depends now. If not, I would say we can close the session. Yeah. Brooks. Correct. Oh, wait a minute. Now Okay. You only have 3 minutes by here. You can try it. Okay. We can't hear you if Did you wanna address the question, or should we end the session? There is someone in the queue. There is. Okay."
  },
  {
    "startTime": "01:28:01",
    "text": "Maybe it makes sense to follow-up on the list. If if that ends up being a productive conversation. So thank you very much, everyone. And We will see you in Vancouver, I guess. Mhmm. Thank you. Bye. Hello? Oh, okay. Yeah. No. Mission is closed. I wanted to introduce my work about TCP it PTC and the you know, my idea either come come combine, both MPTCP and amp you quick. And, we did some work. How about her? I suggest you can read my draft I wanted to Okay. Replace my drafted in our worker group. Could you please give me some get the chance. I I say that. I think that my dropped her URL. Hear that chat area. Yeah. Not only chat area. You can send, you know, URL to the TCP and mailing list I think that's more use That's more effective. Oh, okay. I I will say that you may at least I wanna wanna put in a way is the next time we check-in our Garupa the next meeting, I wanted to enter. The meeting in our group. Okay. On the mailing list, we ask for request for agenda items."
  },
  {
    "startTime": "01:30:01",
    "text": "About, I I would say, 2 weeks before the IETF meeting, Respond, and we will see if we can schedule a presentation. Okay? And, by the way, next meeting is dry. Yes. K. It's game 5. Seems to the it has all the issue, I guess."
  }
]
