[
  {
    "startTime": "00:00:10",
    "text": "Alright, guys. If you wanna Everybody can Start to getting their seats. 9:30, we're gonna kick off. Yeah, John, I see you're on. You wanna say hello and get us going? Absolutely. Yep. So, Thanks very much. Chris for being in the room. And, Great to great to have a co chair at last. So, Hi, everybody. Hey, Ari. See you, Waving. Thank you. Yeah. Good. So, let's let's get cracking. A slide, please. So as ever, it's the end of the week. I'm sure you've seen seen this many times, but the note well applies just as much in in skit as every other group So, please do make sure that you conduct yourself in an appropriate fashion with respect to patents and IPR. And submissions that you make in this meeting, Next slide, please. And, of course, also in the way that you interact with everybody. Is typically a pretty lively Mike type meeting. Everybody's usually pretty cool, but just a reminder, you know, if somebody says something you don't like, then debate the point, not the person, and so on and and generally just be excellent to each other. If you do have an issue with anything that happens, either in this of course, the ICF at all. You can, of course, contact, us as chairs or or any of the other officials of the IETF and and report that. And I'm sure we'll"
  },
  {
    "startTime": "00:02:01",
    "text": "to take it seriously and get it sorted out. So slide, please. So everybody, I think, again, it's the end of the week. You must know this by now. But importantly, if you don't, for whatever reason, sign in using the on-site tool. Please do scan the code for the blue sheets. We need to know who's attended. It's useful for all kinds of reasons. And so, yeah, if you sign in with the on-site tool, that could easy because you just get, automatically registered, but, if you, can't or don't want to do that for whatever reason. Please do just scan the blue sheet, on your way out. Slide. Here are the resources. I think you've got those. Let's, skip this slide, please. So note taking, the usual usual thing. We need to take good high quality and complete notes from these meetings. I will be trying to do that, but, I am speaking for a little bit of this meeting, and, it's pretty hard. One person to capture and if they everything. So is there any volunteers in the room to take AJ, I see you in the queue. Recognize AGIA Stein. Alright. Steve raised his hand as well. Perfect. Well, that that's great. Thank you. Yeah. No. That'll be great. So if you can, get on the, on the hedge dock, and I'll I'll see you there. That'll be fantastic. Thank you. Slide, please. Okay. So, here's the the agenda for today And then We have the welcoming introduction, which we've just completed. In a bit under the 5 minutes. So, this is the vendor as posted."
  },
  {
    "startTime": "00:04:05",
    "text": "But just to, give an idea of what's coming. So a bit of an overview mostly for newer folks, but we've got some updated diagrams and and communications tools that Steve's gonna go through, which are quite nice. Ori, done a very good job of, pushing the documents along, give us a bit of an update on the official status of those, Hink is gonna walk us through all of the PRs and such that we've had. There's been a lot of, a lot of work in between 118 and 119 it'd be good to go through go through those. I'll talk a bit about scrappy, which was introduced at 118 and then, talk through the, a thon as ever, which has had some some pretty nice results, bit different this time to to the last 2 or 3. So, also a good thing. So that's it. And then we'll take aob, at the end. So, I think that's a good time to hand over to Steve unless Roman actually wants to say something at the mic. Hi, everyone. So this is Roman Genelu. I guess, Skid ADemeritus, has So so I wanted to come up to Mike for a couple of a couple of thank you first, I want to introduce, wanted to introduce everyone to your, your new incoming AD, Deb Cooley, who is kind of online, you should be very happy. You got you're gonna have now someone much better than me more knowledgeable kind of in the area, and she's gonna help you kind of tremendously to continue to advance at work. And then the the other introductions I wanna say is, again, an outgoing thank you to Hanes who helped get us started from the very beginning through the BOPS and kinda ran us for the 1st year. K. I wanted to welcome our incoming working group chair, Crenna, Chris. Thank you for your willingness is to serve. Thanks everybody. And, John, thanks for holding the steady hand for through all these transitions to continue the of the work Yes. Steady hand, even though it's Friday."
  },
  {
    "startTime": "00:06:00",
    "text": "Alright. Thank you, everyone. Thanks, Raymond. Hello. Thank you. So, Oh, yeah. Great. So hello. I'm Steve Lasker, with Data Trials. I'm gonna talk about what we've been doing with Skip. As So first of all, you know, when we started Skit, we made a statement which will talk about but basically the supply chain, integrity, transparency, and trust. Keywords, will define a set of interoperable building blocks. The focus on interoperable. That will allow implementations to build integrity and accountability into software. Supply chains and to help ensure trustworthy operations. So there's a couple key pieces in that. of Iroperable. That was one of the main pieces is there's a bunch of these standards already evolving, already existing, How do they interoperate with each other? One of those building blocks that interoperate each other and integrity and accountability. Well, integrity is effectively doesn't is it changed? Can somebody go mess with it over time? And if somebody does, we wanna know about it. Right? We can't prove that something doesn't change. We can prove that if it was changed you know, we know that this is what it was at a certain time Accountability is effectively who made those statements. Are they accountable for those making those statements. Are those statements accurate? That's not the point. The point is who made the statement and when did they make them? The software part was a scoping conversation. When we started Skit, there was a lot of interest in hardware scenarios as well. We agreed we'd start with software. Get that one done. And then come and add hardware as needed. And then the trust where the operation is not necessarily, again, that everybody's making accurate information. It's been making it's"
  },
  {
    "startTime": "00:08:03",
    "text": "are they coming back and fixing the information if there's a problem with it over time. Are they accountable for, the statements they make? And new statements they can make around something as they learn more information. So when I think about the Oh, that's interesting. There's no animation. The this became a PDF. Ah, yes. Okay. Alright. Fine. It was built to know that the end result was gonna happen that way anyway. And John helped me It's it's okay. It's okay. So if I think about this, we think about identity and identity is making a statement about an artifact. What the identity is and how it's represented is not part of Skit. We started with a little more focus on it, and that became the spice working group. So an identity is making a statement But what are the types of statements somebody can make? Again, not the charter of skit. We wanna make say that payloads are opaque. Doesn't matter whether it's an s bomb, whether it's a a contract, whether it's a CTPA manifest, if it's a statement about the weather, that content type is opaque to skip. We're just gonna make sure that the statements you're making by a certain identity. And then about an artifact. What is an artifact? Could be a binary, could be the weather, could be, or city, could be a statement about the city of whether It could be anything. There's an identifier for the artifact. That's all that matters. And skin. It's the correlation of the 3 of those things together. The statements are stored in existing storage systems. Even the storage systems aren't part of skit. You might already have a place you're storing this content. We just wanna make sure that an issuer can make a statement about that content at a particular point in time, and that gets packaged Into an envelope, and then registered with the transparency service."
  },
  {
    "startTime": "00:10:02",
    "text": "So it's packaged up, submitted, And then a transparency service will evaluate the issuer It doesn't evaluate the content. If I in the United States, if the way notary's work is I go and I wanna have a piece of a document notarize that I am making that statement. I have to prove my identity That notary doesn't look to know if the contract is valid. They're just, proving that I am making that statement. About an artifact. Later on, if that goes to court, the Court will argue the validity of the contract, but they won't be arguing the validity the identity. That was already proven at that point in time. So it gets registered then a receipt is produced. The receipt proves that that statement was made by that issuer at that time. Does it mean the statement is accurate? Just means the statement was made. Now that statement is that correlation of the 3 is really important. I make a statement that the weather in Brisbane is awesome. The artifact is Brisbane. I am the issuer. The statement is the weather is awesome. I come from Seattle. The weather, you know, this is actually pretty pretty good that it's a little warmer. So somebody like, wow, he must really like it because it's known to be hot there. Somebody else might think the weather is way too cold here. Right? So the reference is the identity is making the statement. If I go to the Internet and look for some information, you wanna look at the source of that information to know if you wanna trust that source So that's kind of key to that trifecta of information that comes back. No. So the receipt is produced I made that statement at that time. Verifiers, what we call relying parties, a verifier and auditor can come back and say, What statements were made about this artifact? What were the receipts? What was the receipt for this statement at that time?"
  },
  {
    "startTime": "00:12:01",
    "text": "So you can go back to it and get that information as well. So it's really good because I could also say what were the statements made about Brisbane. Brisbane being the artifact. Multiple issuers have made statements because there's a subject that identifies the artifact. So okay. Very different to see this built out already. Okay. So if we look at this more closely and we just focus on the top right corner, An issuer is the identity is making statements about the artifact that gets caught up in the CWT claims. So imagine just those two blue lines on the right are now drawn and issuers making statement about an artifact The artifact has an identifier which is captured in the issuer. What is the identity type? Don't care. Not part of skit. You you define an identifier, and that's how you can correlate it with your artifact. Issuer types, again, we're not trying to be this, the answers for all identity types. Will look at Spice to come out with that But we capture that as an issuer. Or, yeah, I like the pressure word. So we cringe. That information is now captured in the protected header. And if you look at that, the CWT claim is the only required property in the CWT header. And the others are optional based on the type of identity you're using. We've been discussing how to be more, prescriptive around when to use which because having all optional makes it a little confusing. Talk about that in the hackathon. I'll put That all gets captured up into an envelope and you could see these captured together. And the payload is put into the envelope The payload itself, again, we're not being storage. Just the payload. The payload could be a pointer to where that is already stored, detached payload. That's just under the content type."
  },
  {
    "startTime": "00:14:01",
    "text": "We do capture the content type in the, protected header. So you can figure out what are these s bombs? Are these contracts? Are these you know, in total out of stations, it doesn't matter. That's just it's a hint to help you figure out what that content type is of the statement. So that's basically it. All of that gets packaged up. You've got a cozy sign, one envelope gets submitted to the transparency service. And now identify, issuers can make statements about artifacts. You can prove when those statements were made, doesn't mean they're true. It doesn't mean that they were it it just means that that's what was made time that issuer could come back and say, hey. I learned something new about that. So now on Wednesday, here is my statement around that same artifact. So you can get the collection of statements for that subject that artifact as well. So that's what I got for now. Sinks. Let's see. Corey, you're up next for the documents. There we go. Right. So, we have a Unlike most, software supply chains, we have a fairly simple dependency graph. Our architecture is the primary document, and it is related to our use cases and to the scrappy API. So and, you know, started work on use cases as soon as the working group was chartered. And we've used those use cases to kind of feel out the relationship between the signed statement and the receipts and how many, you know, multiple receipts. So use cases of how thus evolve the architecture. They've been doing their job. And the architecture is getting"
  },
  {
    "startTime": "00:16:00",
    "text": "to the point where we're feeling pretty good about it. So now our we're starting to focus on the the restful API for interacting with a transparency service. I wanna say on the on scrappy and this restful API This is just one way that we've discussed interacting with a transparency service. So the, the core protocol message envelopes are are really the the the focus of Skit the signed statement, The receipt, and that they're a combination potentially a signed statement with multiple receipts for multiple independent parentcy services. We call that a transparent statement. And those are all in the architecture. This scrappy rest API is just a simple HTTP interface. It's one way for you to submit a signed statement. And retrieve a receipt and then we have a series of optional endpoints that were looking at that are kind of adjacent to the core skip operating functions that we think are helpful to explain, issues regarding, looking up identifiers that are related to the signed state men meant issues regarding, retrieving receipts over time, those kinds of details. That's basically it's basically it. Any questions? I guess, one additional comment I'll make is that receipts are, you know, effectively a cozy structure. And so there is document that I presented in the cozy working group, called cozy receipts, And that's the sort of envelope layer construction that architecture relies on. So, technically, there's a dot dot dot to the cozy working group draft from the architecture."
  },
  {
    "startTime": "00:18:00",
    "text": "Because of the r skid architecture takes a normative dependency on cozy receipts. So, Ori, just as a chair's comment, what's the status of the of cozy receipts. Yeah. So, in in this, IETF, presentation on cozy receipts, I noted, I think with, I think the document's looking pretty good. It's almost ready for working group last call, but of course, that's, you know, for the chairs of the cozy working group to address. There's one, substantive issue that still kind of, I think consistency proof. So we have an issue filed for that in the the cozy working group work item and the Kosi shares were, wise enough to ask for reviewers to look at that issue of consistency proofs. And so I would like it if you might also call for additional reviews of the consistency proof so that we can ensure that that cozy receipts document is is progressed at some point. I can provide a link in the chat and then the minutes for folks who might wanna review it The the thing that I, you know, It's sort of unfortunate. Skit only relies on the inclusion roof today. So in Skit Architecture, we've not really looked at the utility of the consistency proof because most of the time we're thinking about proving that a sign statement is in a transparent not necessarily proving properties of the transparency log. Such as a depend only property, or, privacy properties from like VR indexing and Merkel trees or, you know, other fancier stuff. So the the cozy receipts document has advanced capabilities. And the one that Skit's really, really using is the inclusion proof, but the consistency proof is kind of holding the document back Thanks. Oh, Yaron."
  },
  {
    "startTime": "00:20:01",
    "text": "Hey, Ron. So for a quick clarifying question, is the working group only about envelopes and APIs, or is the semantics of the statements also in scope. It's a great question. The semantics of the statements are not really in scope. We do have a media type, extension point where we kind of defer a lot of interpreting the details of a given sign statement. So if you see in a signed statement. This is an SPDx, you know, Jason S bomb. Then you know from that media type some of the semantics of the payload itself, However, we do have the issuer and subject claims in our envelopes, which are important to understand in the context of the supply chain Well, in the in the context of understanding who issued a receipt or who issued a signed statement, Thank you. Alright. I'm gonna Advanced. Hank. You're up. I'll also try this again. Smucks might This is Hank. Oh, that's my monitor. Wonderful. So this, we call the slide, a recap slide. Because we, are talking about some of the work we've done. Since, IETF 118 next slide. You do? It's hiding in front of me. Okay. So, The title says shaping a simple card document. We used as well, used as a long term."
  },
  {
    "startTime": "00:22:04",
    "text": "The architecture document because a lot of supply chain requirements from the use cases for example, but also from participants, regular meetings, put a lot of items into the document. And it became, clunky. So, call this a kitchen sink. So we were cleaning up that kitchen sink. And while doing so, the whole kitchen became a little bit messy. All the furniture had to be replaced. So That was the reason why a lot of the documents, how the parts, why the, issues by itself are relatively simple. Had a lot of cross relationships. And, this is just an example And I wanna wanna highlight that the term clarify is an euphemism? We we we we structured and some of this is reclarification and some was work in progress. So first of all, what involved that there was already, always comment, we ripped out the core concept of receipts. So they look like and the work in progress title for that is cozy receipts. And, you will see how the title ends up. But in principle, it's the core And, the more important thing is it can profiles through what we use as a skit receipt. The reusability of the concept is so general that, actually definitely belongs in cozy and and the important part here is that we profile it. And with profiling, we mean both adding constraints to it. As well as augmented with more semantics. I personally don't think that is what profiling is, but I've been educated in the ITFS as profiling. So, that is what So now, the skit architecture profiles. That cause you received I wanna say that's a working post post assignment. And,"
  },
  {
    "startTime": "00:24:01",
    "text": "Then we have done some other things here. So this is just a eclectic list of items we've been working on. And if I could, one of the items is that the transparency service is defined by the detector document is, of course, giving you back a receipt But, we wanna do this at scale. And imagine very large supply chains, even if we work cozy and small message types, there might be same, some a, some, you know, Chrissy the Eastern operations here, because you might put thousands of those in there. And the receipts you get might not be coming immediately with the first sign statement you put in the transparency. So is that some behavior that's important for scalability. It's also a feature that has to be highlighted, so not to artificially constraint implementation design. And this is the most important thing because Skid is supposed to work with various application designs and systems above, like making use of semantics that, for example, go into statement. Transparency. So then you understand as a service what the statements mean to some extent, that's not the job of the skid working groups architecture, but, you know, of course, have to think ahead make that possible so that a string operation part for example, one output of that. Terminology simplifications also Phinism. So we removed the consumer concept because in supply chain it means something is that in the architecture, in the the so that is gone. We have relying party now that makes a little more sense. IETF, I think it's very fine. We have verifiers that are not defined but used So all of this is like in a different state of, of being, implemented in the document. The simplification that is happening there is basically based on a lot of consensus calls and trying to assess what is really some of the the best terms here."
  },
  {
    "startTime": "00:26:00",
    "text": "Not confuse people and again profiling. The architecture document itself can be profiled for other things. And then not to conflict with other terms coming from other supply chain domains. Think that's the most important part. There's a mic in a queue, I have time for questions at home. I'm already moving up to 2 minutes. I I was gonna wait a moment to you got to the end, but just a quick question. I think this is the case, but I wanted to confirm with the terminology simplification especially with things like verifiers and relying parties. Is that aligning with mis definitions and things like that that we see else where in similar related types of role definitions because this is something that's caused a lot of confusion for folks in the past. And other working groups where we use a term that has a definition elsewhere that's broadly adopted and used, with that. a sense of No. So what we do here is qualify, terms. We must if there are so many words. I mean, we can't just make things up. We call it a blue bar, but but we're not doing that. So it's a verifier. And, we have to qualify that and prefix it to some extent, or maybe go over the terminology sections. Hey. Look, we know there's something here in rats something else. Here means this. And parties in general are relatively, very find. So I think that is something we do not have to touch. Consumer was sold contentious that's out. It's it's just, you know, all over the supply chain and even in the, in the internet protocol domain, it's it's just not a good word term. Justin, Justin Richard, naming things as hard. And coming up with terms is difficult, especially in an architecture space. You're doing the correct thing in in terms of, like, qualifying it, like, as used in here, this word means this. Which is what we do in the nest documents and what I told the 3c on this very topic."
  },
  {
    "startTime": "00:28:02",
    "text": "And, because we, in this 863, we do use fire, tuning a very different thing Yeah. From what's here. used But it's still a thing that verifies. And so in both is it makes sense to call that role verifier. Yeah. And we're never going to get away with the, away from these clashes, universally. So I, I encourage you to continue with the qualified usage something that, has been helpful in other spaces is to call out other known common usages, in an appendix or something like that. Like, hey. By the way, this term is sometimes also known as this. And sometimes you hear this word and it means something else over there. Just to just to disambiguate. Yes. That is an excellent suggestion. I think we are, on that route, actually. There's a there's a a nebula note called an issue check. So maybe maybe try to keep track of those things, but thank you. Exactly their problem. We have it's not as bad as attestation. On a session Oh, well, assertions are claiming the ITOT says. So Go to go to or off. However, explain that. And, so sorry. No. It's really bad. But so really, qualification also can lead to weird weird terms if you have to, like, prefix over 5 other terms. That doesn't work. So then the, what Justin just said, the the the the terminology section becomes very important and the appendix is to, to clarify what where what the history of this mess was. Outsole. Okay, I'm using uptime, x509. So we started with, another identity concept to, which should be a gateway function to, I wanna say identity document, agility, and there was a distributed identifier. But, well, the document we would have to rely on from WFCC is"
  },
  {
    "startTime": "00:30:01",
    "text": "Not as useful as we thought. So we will do the, continuous work that is done in the IETF, especially coming causing working group and referring to XO49 continuum, which is actually a good thing because a lot of the supply chain people really understand their PKX and, a little bit less, afraid to, change something that have not used before. The installation of the append only log gloss over, it's very important to know, understand how to set a at, verified data or such a app. In this case, it has to do with some rules some steps have to be be contacted other steps. I'm not going into details here. We redefined the auditor role had a very big important uh-uh spotlight on it in the architecture. It's, it's yet another relying party that has special, meaning And so, we will we will continue to work on that. The clarification of heat and subject is an ongoing topic, in my opinion, So again, clarification might, to some people, I mean, different things. But it's something we, we basically have an ex, installed by by Steve and Ori already that is about understanding you'll pay content. That is worked with, here. And so, So because we can't, do the scope creep of looking into the actual, statement. The subject feed us upon here, Orie. Since you mentioned the feed and subject is an ongoing discussion, I just wanted to kinda come to the mic and state you know, opinion on, like, why it keeps being an ongoing discussion. So you know, in our sign statements, we have issuer and subject And the subject identifier in signed artifacts like CWTs or JWTs, it's always like, you know, It's it's The subject identifier is"
  },
  {
    "startTime": "00:32:00",
    "text": "from the position and opinion of the issuer. The issuer defines and selects the identifier they want to use for the subject. Subject is not a global identifier in those systems. It's a issuer specific identifier. It's chosen by the issuer. This has been a continuous problem because we often want to talk about this, software vendor or software partner over here are both talking about the same software artifacts. But they're distinct issuers. They're using the same subject, And that's what's led to the feed conversation being challenging. And if folks in the room have a experience on this particular issue or subject relation or finding many signed artifacts all about the same subject, but from multiple issuers, and you could help bring clarity and resolution to this feed thing so that stops being an ongoing conversation, I would very much welcome your comments on the lister you know, at any time, basically. Excellent. I have a comment right now. I think that, feed is a structure that is going into the application of Sketch not the architecture itself. You can construct something like a feed you could use an atom feed and created from the data from the data available in just going shooting from the HIPAA, from the data available in the script defined structures. So, so it might be an application Leah, Leah, definitions. So it might be a protocol specification based onskett and maybe we move it there, Justin. Justin Richard. So we without comment specifically on feed as a, as a structure or, or where this thing belongs. This is a topic that's been brought up in many different spaces. The fact that, issuer in subjects need to be paired many, many different times. And there's, there's a bunch of things that you can cite. Nist 863 c is a good one."
  },
  {
    "startTime": "00:34:03",
    "text": "That's what we did with the Gannett protocol is just say, Niss said it was like this, so do it this way. But, you know, there's there's others out there. This is this is not a unique problem to this space. Yeah. And I think I think the pairing of of, that is not contentious anymore, I guess. Preparing of, subject and issuer is something that is now mandatory as you might seen in the CDD. So that's happened. Still feeds are a little bit more frosting to the problem, and I think that frosting might be different document. Hi. And, Mike, Mike Burrock. I I noted this in the chat, but I I think kind of concurring with you that maybe this application layer or secondary build on I think from a not blocking architecture, and let's make sure we get core architecture out, it might be good because there's weird stuff involved in feeds. If that could be handled as a separate document that certainly simplify advancing the architecture to the point where we could start to test it a little better in production. Cell itself. So And then there's a cool trick that we have a use case document that we might never publish. We could also, derive, very concise case examples from them, and then they might mention feed and then we go from there. So then, again, there are many ways I say I'm not worried. It's just work. That have to do. So, it's not entirely clarified. We deferred federation, because I'm using it very much time here right now. AJ. Hello. AJ Supply Chain Consulting. What do you mean the use case document that's not gonna get published? It's undecided. It a little bit of do. It depends on shares an AD opinion if it's worthwhile. I think there's a lot of good stuff in there. And it might get hidden away if you just let it expire. Okay. Friend."
  },
  {
    "startTime": "00:36:02",
    "text": "So that was a that's a good idea. That's a bad idea. Okay. I mean, I couldn't hear both. Yes. I just Okay. I just I just heard you say it, and I understand it now. And without having formed an opinion thinking that's weird. I'm gonna say, okay. Well, this is the okay. This is not And I'm gonna go Yeah. to us, the working group itself, the members can have an opinion, but we have to get some I mean, at least consensus in the working group and then permission, actually, I guess. I so the so speaking as chair, there's there's questionable value to publishing, use case documents, their longevity, what they are for information, you know, kind of ongoing. However, you can extract bits of use case and use them as introduction type material into following documents, if you want it to explain motivations for particular design choices in in other work. But a use case document itself the community questions the long term value of kind of staying that, you know, up putting that as an RFC. On the other hand, it will live on as a you know, expired document within the working group, it it it can still be found. Audi. So I concur with our share. And also, We did run a working group last call on on that use cases document before before. So just from, sort of process perspective. I don't recall what exactly the conclusion was for that, but, you know, perhaps we wanna update the milestones or you know, make it clear what the working group intention is on the document. My understanding of the conclusion of the working group last call was that we wanted to settle the architecture and and scrappy pieces so that if we were to publish the document, it wouldn't immediately become inconsistent with the architecture as a whole. So that's I think why we did say we're done. Working group last call finished."
  },
  {
    "startTime": "00:38:01",
    "text": "I don't remember exactly what the conclusion was. So the the document has to live long before anything is decided, then the architecture is true. Still, I think it's viable to highlight that, doing a eclectic selection and a a compression some of the child is useful. I've seen that before. It works pretty well. And it would be, a place for the future discussion. So, sorry. Oh, John. Hey. Sorry. I didn't see that. Hey. Yeah. Just to confirm. I do remember what the outcome was of that of that last call and it was substantially as, as you said, Ari. So, the, yeah, the, the most substantial comments on it were that it was waiting for things and they architecture to settle down. So let's let's try and fix that first, and we, we put it on ice Okay. Now I'm really fast now. We deferred federation. Federation means things working together. It's kinda based on the receipt stuff we wanna build. I think it's working out, but it's not for now, it will be an additional document to the architecture. Remote statement signing currently is in because that is something that really, really, really connects the supply chain enthusiasts that that want to use building blocks skit is very, very, There's that you can really see the use Does it belong here? Okay. So, these are the last two items I'm I've taken up too much time already, but but, we did a ton of work and the, the call document literally looks like a court document now. There was some contentiousness about stripping so much out about the the general understanding it, it is not gone. We will just go to adjacent documents that have specific purposes. And that's basically my final statement here. Had 5 minutes. I guess this was not 5 minutes."
  },
  {
    "startTime": "00:40:01",
    "text": "Okay. Any questions? I mean, you had a sum, but, You can put them on the list or can join our, continuous meetings. They're fun. Sometimes we are we are really talking about the same thing. Again and again, but it becomes better. So, I will hand over to John, that's easy. He doesn't need a clicker. I'll need a I'll need a remote clicker in in in in the form of of Chris, I think. Thanks, Hank. And by the way, you got in the second The agenda, you had 10 minutes. So, They're all they're all good. Great. So, Thanks for the slide. So just quickly for anybody who doesn't know or remember what is scrappy and why. It was always part of the original charter and, workgroup outputs statements that we would make, a sample API, and I think it's always been understood, and written down, as Ori said, that this isn't the standard that thou must to but rather an example of an interoperable way of interacting with these with these services. And and really the whole The the real purpose of it from a a charter point of view is to enable interoperability and make sure that we can have some common test cases and and common way of of people interacting with with these things. In order to create the artifacts that are normative and and core to us in the form the statements and receipts and so on. But as a nice, Side effect, there's nothing better to go along with your rough consensus, then some running code. And sorting out the the fine edges of what in scope for the for and what's an adjacent service, what's an application that is called"
  },
  {
    "startTime": "00:42:00",
    "text": "is there a difference between feed and subject, for example, which I assert that there is we can sort all those things out. So that's why we're doing that. So slide, please. What does it do? It's defining HTTP APIs. So, restful ish in fact, very rest of all, for things like posting sign statements, getting receipts, getting signed statements and and and so on. So this is a kind of content slide, I'll go into detail, next. So slide, please. So, and forgive me. I I appreciate there's a accessibility problem with putting images of text in the slide, but of course, everything's in glorious ASCII in the, the main documents if you want to, read or download those. This made it easier for me. So there are only 2 mandatory endpoints, so far. It's a it's an early document. But, the only 2 are an unauthenticated attempt to get the transparency configuration. So it's and service configuration, which help with some of the discussion we've had with you know, registration policies, which was a a a big deal for the last 2 IATFs. And understanding easy interoperable simple ways of, things like getting very public keys and and capabilities and all that sort of thing. So a way of interrogating a service and seeing if it's right for you. And the other one, of course, is the, the ability to register a statement because that's essentially, the most fundamental thing that, that Skip does. So that's it for the, for the main thing. For those of you who've been following on, the very beginning."
  },
  {
    "startTime": "00:44:02",
    "text": "This kind of looks very similar and kind of looks very different from what we had originally appendix of the architecture document and then what was implemented. In the the emulator that's in in GitHub, but the entries, terminology and so on, that's all all the same. And the principle of having, long running asynchronous operations, that's all the So if you've been following along up to this point, some of those sort of core principle are very familiar and remain. And we've just updated things to, to match the new clarifications as as saying put it in the in the architecture. So slide, please. So this is an important one, to bring out that I think people might be very interested in. So something that, Steve has mentioned, but I will I will re mention is that there's very important principle in Sketch of of not really trusting anybody as far as far as you have to. And that includes the transparency service. And that includes the parency service potentially now or potentially in the future, and so issuer statements are signed by the issuer before they go into the, transparency log, And part of that allows you to identify them and and see who coming from and check whether they're actually allowed to make statements. But it also has a very strong property that it prevents the transparency service from forging statements on behalf of other people. So we've got a nice 0 trust thing where there's a key at one end that signs the issuer. There's it. The other end notarizes the two things together give you a very strong sense that this thing definitely existed and was stamped. Now We've actually had, I I won't spoil the hackathon section, but, it some of the experience of the hackathon and other stuff."
  },
  {
    "startTime": "00:46:03",
    "text": "Is, that it's difficult for some people. It some cases to organize that, that signing on the client and so we're proposing a an optional endpoint that would actually allow the transparency service to sign kind of on the way through on behalf of. An an issuer, which has many, benefits from a sort of convenience point of view, but, of course, adjust the security and trust calculus a little bit. Ori, are you still in the queue? He he just dropped. He was answering a message and that that Okay. Great. So so that's an interesting thing, and I think that's a that'll be a great thing to get comments on whether we want to have that kind of, convenience. I think it's a great idea, but, yeah, it does come with interesting calculus. So, slide, please. So then there's a bunch of options for statement resolution. Again, these are seeking, to answer a number of the very frequently asked questions or frequently made comments in our in our working group meetings, about the role of retrieve or search, for the statements that have been made and registered. So, at its very raw heart, all that you really need to do with with skitt is to get a receipt and stash it somewhere next to your artifact, and that's enough. But of course, as soon as you have supply chains of related parties and people interested in this kind of stuff. They then actually, you wanna be able to find them. So so these are a variety of of things to support that sort of searchability and retrieval of statements that have been made either."
  },
  {
    "startTime": "00:48:00",
    "text": "By by yourself, by the issuer, or indeed stuff that you're trying to, to verify yourself. Slide, please. And then a couple of identity management ones Ori's just put in the chat for those who are able to watch the chat at the same time. A little note, about this, but, there are 2 optional endpoints. As well to help you resolve issuers, work out who you're talking to, and and there are a variety of good reasons for that. Or you're in the queue, so I'll let you up. Yeah. So this one, I will come to the mic to to say something about, In the in in the spice bot, we talked about an endpoint for discovering issuer keys and or metadata and issuer capabilities. And this is An example of doing that for the transparency service as a service provider are discovering the services keys, the services capabilities, those kinds of details. And in I think, you know, in Spice Spa, if I mentioned, OAuth already has ways of doing this for their credential use cases. So for discovering an OAuth, SDJW TVC. They have a set of metadata endpoints that look pretty much exactly like this. But only for OAuth, SDJWT. So I'm just calling out, like, you know, if this look looks terrible to you, we didn't invent it. We're trying to align with what folks within the IETF are doing on this front And, you know, one of the key, you know, important differences between what Skid is doing and what OAuth is doing, what Spice is doing, so that Skit has a an opinion on format for sign statements. We're we're we do cozy here. So, we need to be able to discover keys that can verify, cozy sign statements and cozy receipts, We don't necessarily need to only represent keys"
  },
  {
    "startTime": "00:50:00",
    "text": "in cozy. You're looking at Jason. So, It's a it's a it's a important topic. We wanna get it right. We need to collaborate with the x efforts in the working groups that understand how to do this key discovery stuff, to make to make it possible to verify sign statements and receipts regardless of which key material or in what trusted hardware, you put that key material and how did you export keys and all of that other stuff. Thanks. Thanks. Yeah. It's very, the important Great. thing for us to be able to do clearly to, evaluate these, these statements and and demonstrate that they've been evaluated, 2 or 3 or 4 steps down a a complex supply chain. Which is great. And the last slide, please, chair, just to, bring us in. So there is also, issue a dead resolution. Endpoint. Those of you, again, who have been around for a while will remember those heavy use of, of deeds early on, and indeed a couple of, couple of generations of of hackathon entries have have made use of did resolution and and so on. This endpoint is currently listed, marked as deprecated, in favor of some of the other stuff that we've, that we've done and, of course, because you wanna persist with this, it can be done in other ways. You can be done out of bed. It doesn't necessarily need an endpoint in the transparency service. So better to better to do it in the the consistent way that that Orest just just mentioned at the mic. So this is still here. How long it will remain will will be in part up to, reviewers and and and authors. As we go forward. Thing."
  },
  {
    "startTime": "00:52:00",
    "text": "That, currently planned to not not not be there for very So that's kind of it. That's a whistle stop tour through what's what's their long. clearly, there's lots more. I think, Hank's coming up. As Hank approaches the mic, you know, clearly there's lots more in there. In lots more detail, and we've got all of the example return codes and everything else But I just wanna give you a flavor of the the coverage and encourage everybody to, start reviewing and and participating think. Yeah. Hi. This is Hi. This is Hank. As a tip to the top head to the HTTP deer Thank you for early reviewing API content and documents. That's really great. Thank you. Darren specific here. There is now, Standard 97, and, heard the term endpoint like 150 times in this dialogue, and it is deprecated. And maybe we should use the term resource now. That's just because, they really made an effort and and came to us and that was nice. And so, So, the the the very, very, it's like certification chain. Certificate chain. Sorry. That's a certification path today. And, and API endpoints probably are now API resource So that's just a knit. But, it will never change if we not, think about it. So that's why quickly, bringing that up. Yep. Thanks. Thank you. On on both points, actually. Yeah. It was a a really good review from AC feeder, positive as well in in most parts. With some some good feedback for us to implement. So, that's promising. So just a couple of 2 more slides left, much more, administrative stuff. So, obviously, we we created scrappy"
  },
  {
    "startTime": "00:54:00",
    "text": "by removing it from an index. It didn't really belong in, in the architecture. So versions was really just a cut and paste from an appendix from the the architecture document, but 1 is a much more consciously updated, version. So this is the one that we want to, to start working around and, there's the link. And if we get the one more slide, please the earlier we get review, the better So, anybody who's interested, please, raise your hand or make a sound or put something in the chat, or indeed just come back to us. Later on, but, Thomas? Was reading my hand. Oh, Thomas has left the queue. AJ. I was just raising my hand to say I'll review the things. I'll make a note, but That's notetaker. It's ironic. I should stop doing things. Also write that in the notes. Excellent. Thank you. Yeah. So So Monty will review you. For the notes, Put in month is May. Brilliant. Thank you. Thanks Monty. And yeah, as has already been mentioned a couple of times, but we need to turn, great ideas and spec into tests and working code, one of the the focus areas for this is to make sure that it actually does test interoperability core normative. Elements. They're in, and in particular, Kozi receipts. We we are aware of, number of different formats already that that may or may not be closer or further away from the cozy receipts back as it is. So be a really good tool to, to get us all aligned Sorry?"
  },
  {
    "startTime": "00:56:01",
    "text": "Thanks. Ori Steele. On the topic of, tests, test suites, how that You have an awesome keyboard. On on the topic of, test suites, we had, we have I suppose, some open some some Python code that we use to do emulation of early skit architecture sort of components and that, code is sort of done what done what code does. It's drifted away from the architecture a bit And so one of the things that I wanted to ask you know, folks in the room with experience on is We we're thinking about doing a kind of a test suite for scrappy that had some sort of, ability for vendors to show conformance for their implementation against the scrappy API in particular to show of these optional endpoints, does anyone care about the deprecated one you know, it'll be cool to see who uses what components within, the the the resources that, we, that we have defined. And I'm not sure how, how how the IETF likes to handle that kind of test suite. Process. So If folks have guidance that they would things that the way that they would like us to manage our test suite process for scrappy I'm very much interested in, I'm happy to write code and do whatever the group tells us to do on that front I think we need to do that, or we're not gonna have very much success with scrappy. So, I'll I'll let my ADs tell me that I'm wrong, but my understanding historically has been the way those kind of test suites get used is that after you advance a document on standard track, you do an interop, you then document that you did the up and you use that to, provide evidence that there are multiple"
  },
  {
    "startTime": "00:58:02",
    "text": "kind of working, compatible implementations, and that that then is used to kind of advance it from proposed standard towards standard track. But there's a whole bunch of people who probably even have more history and IETF who are gonna You know, give alternate versions of possibilities here. Michael Richardson. What you said is essentially correct. The other possibility, it, that it you might do a revise the document and throw away the things you didn't test. And you may just show up 2 years later and say the ISG change the status of the document. Here's some evidence. It was perfect to begin with. But the thing that actually I was gonna respond to, Ori, is that there's an increasing commonality of now actually publishing a second, information document. With traces. Of protocols two things. So TLS has done this. Ed Hawk has done this. There's 3 or 4 other other places where this has happened. And so if you wind up with factors. I think that makes much more sense for key exchange protocols or or a key agreement protocols, where you need that but You can also include examples fully worked out examples in your document ideally with the private keys of the the throwaway private key so that everyone else can actually generate the same thing you did from the same algorithm and the same stuff and I really encourage that you do that because one of the problems that we have Historically, we had, like, like, we had a back in, like, 1997. We did, like, an v one interop test, everyone who showed up for those meetings or those events got their stuff working and the people that tried to implement 4 years later, We're like, because they couldn't get debugging out of other implementations. To find out what they did wrong. And so I think that's the real value of having them is is the people that"
  },
  {
    "startTime": "01:00:02",
    "text": "weren't here today, but rather we're here in 3 or 4 years. And they're gotta implement this by next Saturday. And this makes it really good for them. Yeah. I In addition to what Chris said, which is, an option I organized a couple of, intro events. And those are all sort of you on your own from a sort of, like, there's no process in that sense from the IETF point of view. Like, we We created the interrupts and we met and tested That costs a lot of time and resources to do that. In in the OS Group, some of the folks are here we worked with another adjacent organization to actually pull off some, some, or write some best food, which cost obviously money and someone has to maintain them that's the tricky part, writing it once is one story, but then maintaining it is a separate game, And so but that's actually, I guess, what you really want and that, but that is not an IDF, task So you have to find some other when you To pony up the money, to have people sort of continuously work on it. And that's, That's a little bit of effort. So thinking about, like, where this could be taking place or having automated desk suits and maybe there's something to learn from the test suites that were developed for OpenID connect and and folks are here so you could talk to them look at the code and so on. So that would The path I would go Thomas? Hi. My name is Thomas Howe, and I'm working with the decon Working Group, and the intersection between what we're doing with conversations and what you're doing here at Skid is really hard to mess."
  },
  {
    "startTime": "01:02:01",
    "text": "So for instance, the Vecon, the virtual conversation, could be this could be signed I'd be, have a we could be the statement that you sign or take one of your documents and attach it to the conversation that we're representing. And when you're one of the parts about that from for at least my work, Lots of your peep reasons people use Vcons the work that I'm doing is and tracking people's conversations as they go in and out of of, you know, Scary things. So I've I just love this work, and I think it's really great intersection, Hi, Roman Tinulio. I just get Sk skid, enthusiast, and outgoing, if anyone else wants to say if the mic say something in the mic, please come up. I just wanna I'm just gonna pause here. Alright. So AD was said kind of three times, and so that means we puff and appear in front of the mic. I I think the key question is, Hana summed it up very well, which is we have almost infinite flexibility to to to do something here. There's official process. There's kind of unofficial process, but the process will flex to what the outcome that the work group wants. I think kind of the key question I would have for the working group would be what is the durable artifact you wanna see and how durable do you want it to be? There's certainly sufficient precedent in a lot of working groups that motivates you wanna publish text vectors on the RFC stream, by all means, Do you wanna do interrupts officially, unofficially document those results you can publish it to Akama and it not gonna publish. So I I would advise kind of the working group to do whatever is the interopting kind of support and the implementation do that and also at the same time think about where do you want the results to go and how durable you need them to be and the process will flex for you?"
  },
  {
    "startTime": "01:04:03",
    "text": "Great. Thanks, Raymond. That's, lots of lots of options. I think we take take most of those. So, moving swiftly on, next section, is also starting with me. So slide, please. I just like to show these. I I have a collection of them from the last 4 ATF. So I hope you all got your stickers. But slide for the for the the content. I don't think this won't take too long. So I'm not sure what happened to the picture of the the local hackers, this time, but we always have a a picture of our hackers for me, as you can quite clearly see. I wasn't able to travel this time, but I was up all night in a in a rather cold Cambridge fueled by alcohol free beer and a rather skeptical looking kitten, and AJ similarly on his second or third bottle of cold brew, cracking away at, keeping this thing going. So we had a few different things to do. Again, a bit different from recent ITS. We've normally had sort of one big target and really hammered on one thing together. This time, we've done 4 slightly different, things. So if we press the button, I'll do mine first and then hopefully hold over to to others. So for mine, I'm very keen to make sure that scrappy does its job and does it quickly, and that means defining the the API that means getting back to a position of having some good solid running code to prove we've done the right thing, and and also making sure it actually proves that the architecture easy, you know, is in a good shape and actually define something that we like So rather than writing code this time, I just wanted to make sure that we have proper official an easy ride on the the official route, and there's"
  },
  {
    "startTime": "01:06:00",
    "text": "lots and lots of rules about writing RFCs, and one of them is the, 3552 about having a comprehensive. And sort of consistent regular security consideration section. So, I've done that over the weekend and, I think it's pretty decent. It is it's had a tick, and and I think it's if I saw the text message correctly, I think Orie's just merged it during this meeting. But, yeah, starting as we mean on, to go filling in the official sections and making sure that security considerations are extremely clear for this thing. Is important. So, that's what I did. And I think it's, I think it's a useful thing. So can take a look at that. That was me. So if you hit the slide please. Is Corey I see Corey are online. Are you able to, step in and talk about this, or shall I, do it. Oh, yeah. Yeah. Well, Let's see. Okay. Is this, okay? Alright. Yeah. So I'm Corey Bonnell from Digisert. I was working a bit on the hackathon, this weekend on integrating digiserts, what we call the software trust manager, product. Basically what we use for code signing. You know, users can store their private keys in the we generate code signing certificates usable for authentication code and other code signing. Platforms. And we'd like to tie this into, what we're developing here at Skit. So, the actual work of using, you know, signing a skid statement with a private key being stored in a remote signing solution isn't terribly interesting. But what we have in the what we did in a hackathon I thought we had some really great discussion in terms of, coming up with what exactly we want in the skid statements you know, how do we represent identity documents? So"
  },
  {
    "startTime": "01:08:00",
    "text": "what we have We have a a github repository with the prototype implementation, what we have is, we basically forked what data trails has for their skid action, tied in our signing solution into it. So what we have is the skip statement signing. And then submission of the signed statement to the the data trails transparency service. So a lot of the discussion, was around, as I mentioned before, the integration of, Skip with existing identity document type namely X 509 certificates. So initially, before I walked into hackathon last week, I implemented, X 509 bids to represent, the identity document and they, that did not, go over very well with the hackathon. So we discussed alter alternative approaches namely that we'd be using the, X 509 thumbprint in the protected header. This is basically the, Shaw 256 hash of the identity certificate, which would be the identity document. And then also, in the absence of other discovery mechanism, for the identity document. We wanted a way for the the certificate chain to be readily available, to clients. So what, we did is we added the X Five, chain basically the identity certificate and the issuing CA certificate in the unprotected header. So what this does in the case where, there is a, a way to retrieve this inform this, certification path from transparency service or some other mechanism. This information can be stripped by the transparency service. You know, it's just entirely unneeded data. But at the same time, having it neon protected, header, in the absence of such a service, provides, the relying part of the necessary information to validate the signature on the,"
  },
  {
    "startTime": "01:10:00",
    "text": "on the signed statement. So that was kind of the approach we took we kinda made some opinionated choices on some of the values in the, in in the headers, for example, the key identifier is basically a an opaque, do it we could probably actually remove that since we have the X Five thumbprint and the, One notable difference from the guidance in version 6 of the architecture document is that the X Five Chain is currently specified as the protect within the protected header. As I said, we moved that out of protected header technically not in alignment with the document, but it sounds like there's pretty good consensus that It probably should live in the unprotected header and the draft should be, updated accordingly. So this is kind of the work that we had. Again, know, tying it up with a, with an existing remote science service, not terribly interesting, but, you know, hopefully this provides a concrete example that we can build upon and kind of refine the the various ideas floating around in terms of how we represent identity documents within skid statements So, they wouldn't have any Questions? I don't know unknown's in queue. if the So Oh, that's Yeah. I didn't pay attention to the the hackathon you were doing on the, on the next table, because I was busy doing this other stuff, you didn't let the trend. So the security model, is if if I try to summarize it is you have, the developer presumably sitting on his machine and then when he creates the the statements, which need to be signed He Somehow, how does it get those to your server where it's sort of delegated signing take"
  },
  {
    "startTime": "01:12:00",
    "text": "place. Like, how is that interaction going to happen? In general Yeah. So right now, the GitHub action currently has integration with API for our signing service. Okay. So did you get up, would, use well, that's part of the that's what you did at the at the at the hackathon. But in Like, that's presumably not what you want to do in a like, going forward. Right? Right? Like, you know, real product, you probably want to do something different. Right? Or is that is that really they, they, sort of the end state you want to accomplish just with a better software quality Yeah. I I think, I mean, at least in my mind, the the analog there of, you know, CICD pipeline, you know, generating the half of hash of the artifact. That's, that's being signed and sent to this the service for signing. Is, you know, that that's already an approach that's well understood you know, widely accepted. We were thinking that we would take that approach here. If there is alternate solutions, you know, we can definitely discuss. But there's no you you wouldn't have any sort of specific use, developer involvement, like saying, okay. Now you need to sort demonstrate that you possess any possess anything, or you can of sent to anything. It's just you know, like, I could include my web. Like, the the CICD pipeline could happily include anything else, and it would just upload and sign it and everything would be cool. Versus having a model where they develop by actually like, sits there and says, now that's what I think is ready for pushing up to the to the lock. Is that Like, I'm I'm I'm wondering what the implications of the the security model out with that delegated approach. That's something I'm trying to wrap my head around. Okay. No. That makes sense. So just as we have a moment, Huddl, can you go to the mic and say your name? Yeah. It's supposed to be the name that was shown on the screen, Hopefully, it wasn't shown a queue."
  },
  {
    "startTime": "01:14:01",
    "text": "Hannah Strivink. Yeah. You didn't enter the queue. I Roy Williams. This this approach of delegated signing gets into to predicted rings of of labs and and so forth. The the approach is being used well within Microsoft to to say, hey. Anything that exits our bill clusters has to be signed. And so, therefore, the signed content goes up to to a skip receipt to to to give it the the extra part. But but Having to sign all content as you produce it is the only way to protect a lot of it. The delegation mechanisms and the boundaries we have papers on how this is done and created is is part of that group that's that's talking about this, we can take that offline. Panet, if you wanna go Yeah. We can definitely talk about it through further, but I think the approach being, taken here pretty well adopted throughout the industry. Yeah. Steve Laskar. So, I think to harness, I think maybe that's what we're saying also is the during the build, whether it's CICD or other workflows, you're you're testing the software wanna create an attestation that it's been tested and pastor failed or that an s bomb was created So that is the kind of thing that you could and you wanna put an identity to it you don't want the key in the build system. So you can use remote signing services that create that identity, then you're registering that. That statement, which is the S bomb, the attestation, the test report, Whatever it might be. I, Orest Steel. Basically, what other folks have said, but I think The key thing to think about here when you use remote signing for, you know, build build server artifacts is the the, like, honest you're asking, like, what happens from a"
  },
  {
    "startTime": "01:16:00",
    "text": "security perspective, like, what's the threat model there? I'm gonna compromise the remote signing API. I'm gonna deal to signing capability, and then I'm gonna impersonate signing from the build server. And the alternative version of that is I'm gonna compromise the build server. I'm gonna do signing look locally on the compromised build server. And, you know, in in in both of those cases, like, you're still ending with assigned artifact that's representing some supply chain scenario. It's just one of them I had to, like, break into your remote signing API maybe had like a whole bunch of other factors and other authentication and authorization schemes around it. Versus the other one where it's like I had to get, you know, root on your Jenkins box blah blah blah. Sorry for mentioning Jenkins. I I I just wanna say, like, I I've I've I've worked to secure, like, build servers in in with with a number of different technologies over the years. And it's really important that So I wanna sort of almost push back on the emphasis on remote signing because sometimes you're intending to co locate your signing keys in a specific set of trusted hardware. And you really don't wanna be calling out into, you know, the middle of nowhere depending on your deployment model. So apologies, you know, for mentioning specific vendors. And and I, I think remote science is an important component in this, but it's not a universal solution to signing binaries, you know, generally in supply chains. It's appropriate for some use cases and completely inappropriate for others. Thanks. Yeah. I just wanna echo what Rory says. You know, I mean, I think the remote signing that type of solution is great for smaller development shops. You know, they don't necessarily have the expertise to run their own HSM and, you know, maintain that. So having the ability to kind of delegate and delegate that responsibility to another provider provides a lot of security benefits. But then at the same time, a large organization that does the maturity to to manage their own keys. You know, there's definitely flexibility there"
  },
  {
    "startTime": "01:18:01",
    "text": "use a local signing solution. So, Alright. I think that's it. Unless there's anything else? Alright. Thank you. Oh, thank you. Thank you very much Corey. It's Yeah. Yeah. Yeah. As everyone said, it's a great option to have, for some people it's the right answer. And it kind of proves the point that, what we've done so far in Sketch kinda works. Good. Ray. Yeah. There we go. Ray's coming. Excellent. Clickers, there if you want to vest lines up. No, I'm gowed This is one slide. Hello. My name is Ray Lutz. I'm with Citizens Oversight. And I'm focused on the election in, integrity area. And, of course, they have software, systems like any other software is gonna fit nicely within the paradigm that's being used in Skit so far but also there's an opportunity to secure the data. Of the elections and trying to get every single election so cured is any step that we can take forward will be a step that will benefit us because they're doing nothing right now. So step 1, and as I see it is to, kinda forgot what I said here. There's a monitor right there. Oh, here's the monitors. So Thank you so much. Okay. we're trying to get jurisdictions on board and and by jurisdiction, I usually mean counties. And in the United States, there's about 45100 Counties. The goal is to get the data that they're currently producing to be, reduce a hash manifest file on all of the different files that are included. And a hash for each file. And then get a hash of that, and that's what submitted in this kit. Us to do that. Of course, there's the the little thin layer that we need that's kind of missing perhaps. Which is that they need to also have a certificate that they can then sign it with."
  },
  {
    "startTime": "01:20:01",
    "text": "Don't know how far away they are from Having that normally, in these jurisdictions, but I anticipate that in many of them, be just as far away as as, so many other people are of just having us it get ready. So we'll have to have a thin layer there to accomplish that. And my real goal here is this level 2 which is to actually secure every single ballot image that's created and scanned and have the private key within the scanner sign that and then be able to follow all of those images back to that original a private key to the signing process. Now in this area, there's been the question that's been kind of taught around. I've been a little bit researching with hackathon. And, of course, if anybody has opinions on these things, I'm happy to to really have your involvement and and understand what you're you might have to suggest, but is how to exactly get those private keys back. The public keys from all the different scanners. These are air gapped. It has to be through thumb drives. And a process that is a very minimal one turn around, you know, we send a thumb drive comes back and I have the private, the the public key of this of that scanner that then can be published before the elect and submitted to skit and then we have all of the public keys of all the scanners, which then relate to what they've signed when it comes back. And at the end of the day, my hope is that because we produce auditing, ballot image, auditing solutions, we can take all of the ballot images and then we can avoid the question of are the ballot images actually the ones that were created by the scanners. Of course, there's many other questions about whether the ballots that were scanned were correct and are the photos were correct, etcetera, etcetera. But those questions aside because that"
  },
  {
    "startTime": "01:22:02",
    "text": "kind of out of scope. But the goal is to create really enticing technology that will be easily adopted by these, jurisdictions. And and and and accomplish change. I guess that's it for my my overview. Questions. Hi, Roman Jnitto, your, AD Emeritus. Just as a public service announcement, I am thrilled that there's excitement about get in a lot of different applications, but I'll repeat what I often say at every meeting that the charter very narrowly scopes as to software supply chain. And as your card AD, as your current baby, I will say the same thing. Okay. Thank you very much. So, John, you wanna walk through this? Go ahead. I don't mind. You can take it if you like. You're probably more familiar with it, but I do have some thoughts on the last call. Good. Well, okay. So we'll leave we'll leave that for the for last time. So Yeah. Just a a quick, summary. This is much for the benefit of the the tape and people who are downloading the materials as as being in the room, really. But just to remind people, the, the the use cases document, which contains a lot of useful information, but probably won't ever come on RFC as we've we've just discussed, today."
  },
  {
    "startTime": "01:24:01",
    "text": "In the place where the link is the architecture, lives in that place where the link is currently on draft 6, which is the the fruits of all that immense hard work that, Hanger presented earlier than very great thanks to the effort. It is ours of a very concerted effort from from the author's that that's gone into that. So it's really, a very, a very, big improvement over last time. And then the next focus, as we've already highlighted is to get on with scrappy and and make prove the things it's supposed to prove. So, it's a good opportunity to host a fun hold over to Chris. We are hoping to focus rapid, in no small part because we expect the architecture to go to call and kind of be done, now, but we've noticed there are already a couple of issues been opened just in the last week. So need to think a little bit more Yeah. Actually, so on that exactly on that topic, I I guess we're anticipating an 7 in in the So can the authors provide what they think as a rough time frame such that they might have one in mind And if they don't, that's okay too. 2 2 weeks 2 107 or something to that effect? Okay. So I'm willing to start the last call on the list, with an o 7, but I'd also like to get some get some reviews, honest you're willing to review you know, architecture. So I'd like to get some kind of reviews on the list. We'll note that Haunas was going to provide at least one of the reviews. I'm looking for other folks in the room who might be willing to to provide that if you guys could, send a note to either chat or the list"
  },
  {
    "startTime": "01:26:02",
    "text": "to do that, that'll let us kind of of Great. So that we can kinda do that. That's really the kind of conversation I want to have. I mean, obviously, we're not quite there yet. And, also, I will note I like to coordinate with the cozy, Chairs, and just to try and figure out what the because we have a normative reference to to a document that's hopefully going to last call there as well. So we can still do our last call and advance it. But it may block publication until that document, and I just wanna make sure we're aligned with them. If anything happens that either of the documents go off the rails, not to create kind of future problems. Alright. Alright. Thanks. Thanks in the queue. Yeah. Oh, hey. This is Hank over my car to the next topic. Doesn't really matter. I just want to mention that there is Easter holiday soon. So whatever you say is happening in 2 weeks it probably will be Easter account. At my kids. So, yeah, So I just add 1 Easter holiday to the time frame, and I'm more comfortable with anything we just said. Sure. Yeah. And, obviously, that'll and I'll be I'll be monitoring, you know, working with the authors and and kind of monitoring list and but we will put out a call for, for some reviews, etcetera, and start that last call when when that that document update is available. Anyone else. This is your time. If you haven't spoken at the mic, you wanna get your picture and and your name and the notes, AJ's up again, I think."
  },
  {
    "startTime": "01:28:11",
    "text": "I was on mute. Sorry. I was making a joke. I said for the record, I raised my hand, Chris. Before you talked about being self serving and I've been in the notes in this meeting and countless others be self serving before it was asked of me. One of the Things that has come up. Is there adjacent efforts That are not exactly in the IETF. It seem Increasingly important. I'm not really sure what to ask of the group or how it could seat, but it seems important that we look at people that are working on the older I ETF RFC version of transparency systems and this new emerging thing That has a name, I believe, called lite logs. Not so much to say whether it's good or bad, but to compare and contrast the to see how divergent it is from Skit and whether there is value there. I know some people had talked about that and on one meetings. I don't really know how that would work in the context of of draft or specification work, but I think it's something worth calling out and doing, and I just wanna put it out there. Hey, Jay, before you before you get off, is is that at an enough Another SDO who's It's not even in an SEO. It's actually people that are part of a group called, Ori is probably gonna is gonna is gonna compliment this comment or not if I'm if I can shut up now and you're gonna away. Okay. Or he will explain. My I have I have got my name on record and I'm done. Thanks. I I did try and raise my hand in the queue or a steal. They're, there's a number of technologies that have evolved in the transparent space to provide a sort of substrate for transparency services for different verticals. So"
  },
  {
    "startTime": "01:30:00",
    "text": "Some of these tools are used for certificate transparency. Some of them are used for key transparency. We hope that many of them will be used for software supply chain transparency. And a lot of that community work is happening, you know, under the general term of, you know, open transparency services or verifiable, transparency logs And I I think I left at least one link to this work in chat, but, There's a lot of open source work. That's emerging and some of it is is directly compatible with cozy receipts document that's creating the, a transparency log structure and sort of cozy infrastructure to enable other types of those open source projects to register their proof formats. It would be really, really awesome to see some interoperability at that receipt layer. So if you're an operator and you're running a transparency service, or you're compatible with certificate transparency 1 or 2. I know there's details there. And you're interested in in doing interoperability testing with get receipts and you have a, a transparency log that you've already you're already committed to, you're not moving off of it. I'm happy to chat about what that mapping might look like, and I can help, sort of see if there's a way to get those pieces connected. And thank you to AJ for mentioning the extended open source community, which a huge part of securing software supply chain. We've got to work together if you're using any of these tools, transparency log tools in the open source community, I'm always happy to chat. Thanks. any any participants can If can you reach out and point folks to to this, group that you know, even if we're just you kind of inviting the hackathon or, you know, some kind of other way to collaborate, we would appreciate that. Generally, the IETF takes onus on coordinating between other SDOs, but we obviously don't take responsibility to coordinate to people who submit Random code."
  },
  {
    "startTime": "01:32:01",
    "text": "To GitHub. So, we're happy to have kind of, more coordination, but you folks have to be willing to participate where a volunteer organization So, I mean, thanks for that update, but we don't necessarily organizationally have a solution to that. Hank. I mean, as soon as you can get Yeah. there. Okay. That was that hurts. Go to the doctor, man. It's been a week. In many ways. This is Hank. So in rats, we we started to incorporate some the supply chain open source work and, it's early work. But it seems to be possible to find common ground. If you talk and understand each other long enough. So, so explaining each, each arts concepts and then, but, like, pinpointing them, if that can happen here in Sketch, that's great. But, there must be, the, the time and the energy on both ends. To do that and, for rats to talk like a year to arrive at that point, that that we found someone that is really interested and and that has the time to to explain things from the other side of the, of the, this is called, this is what the reference integrity manifest stuff. And and it is, it is from the open source work. And and they have semantics. And now we are working on on integrating them, but but the that's learned here is that you need the right individuals that have the time and an open source, you know, if you're already a maintainer and doing the thing that you do, That is nest not necessarily the thing you can do too. So, so Yeah. Yeah. I'm I'm happy to give everybody back 20 7:26 minutes of their day. No other business. Now the agenda is only Thank you. This So,"
  },
  {
    "startTime": "01:34:01",
    "text": "If we're if we're done, then thanks very much. Everybody. See you in Vancouver on interim before that. Amazing. Thanks. It's alright."
  }
]
