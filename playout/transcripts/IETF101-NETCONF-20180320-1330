[
  {
    "startTime": "00:01:37",
    "text": "no I think ready to get started this is the net Khan working group if this is not the session you want it to be in this is a good time to exit okay so this is an IETF meeting we run using the node well just mean essentially everything you say it microphone is considered as contribution please be aware of that the blue sheets are running around please sign it and then pass it back if you see others walk into the room try to get them to them as well somewhere in the middle or near the end we\u0027ll move them around the room again holding them up in the air raise your hand if you need to sign it well you\u0027re not here at the moment so how would you know I just said that we should have minute takers can we ask for some volunteers to help us take minutes on etherpad volunteers for taking minutes thank you and I guess we\u0027ll also so we have to jabber beyond jabber I can and I actually we should have a jabber scribe near a microphone can someone be jabber scribe okay thanks and can you see the microphone will be able to see people\u0027s badge isn\u0027t read okay I\u0027ll try to speak louder I guess he was just wanting to make sure that you\u0027re in a position to see the nametags so we will be using the other pair for taking minutes there\u0027s the agenda it\u0027s been posted when you need to come to if you want to speak and come to the microphone please begin by saying your name and and make sure you only use the microphones don\u0027t try to shout from your chairs there will be people that are joined in only using meet echo and they have to be able to hear you so first off I think everyone here is probably seeing the email from this morning we did get the Charter approved this is essentially what we discussed on list about a month ago there were minor changes to address some isg concerns and if you take a look "
  },
  {
    "startTime": "00:04:41",
    "text": "at it and if there\u0027s any comments that you want to make bring it to list it\u0027s the status of current chartered working group items since Singapore we did publish 6536 biz it\u0027s now RFC 83 41 congratulations to the authors we also have a large number of documents that are in progress just going through this quickly so we can give some chair status for each of these first is the net comp event notifications the last call issues are still being discussed on the list we\u0027ll have presentation today the NMD and in MVA net comp and MBA rest comp drafts are both ready for Shepherd right up then there\u0027s the notifications messages draft which will be presented today there\u0027s the rest cough notification draft also presented today 78 95 same with you and other nmda drafts they\u0027re ready for Shepherd right up subscribe notifications the last poll issues are still being discussed the UDP pubs channel it\u0027s not on the agenda due to there being no discussions since it was last published and but it was updated I think this past Monday right yeah yeah when the submission cutoff was released or you know if there\u0027s no discussions I was kind of wondering about that update I think the constants of the update it is it is a working group document right so I would expect that you know anything that would have led to an update we\u0027ve been discussed within the group if there was no discussions then plus I think there was an update in the draft that was probably not reflected on the mailing list right right so I\u0027m thinking so just as sort of a broad statement everyone should be aware that changed these are working group documents that they are owned by the working group it\u0027s really just editors that are performing the updates but they\u0027re doing so at the behest of the working group so please be sure to run ideas proposals for updates to the work group mailing lists and discuss in there and then based on those results update the documents and be sure to update the documents before the cutoff so you don\u0027t have that issue up next is the gang push which will be discussed today and it\u0027s your touch draft which is ready for Shepherd right up there\u0027s also the more more chartered working group item so these are all that keystore and related drafts none of which were updated due to the editor being busy help would be greatly appreciated here the editor told me if anyone is "
  },
  {
    "startTime": "00:07:41",
    "text": "interested in working on these documents it would be fantastic if you could help with them we get them done faster status of non-charter items they\u0027re actually a number of individual documents that have been recently presented and they\u0027re all on the agenda for today and for and then now for the actual agenda there will be 15 minutes for proposal for refactoring the keystore model 20 minutes and maybe a little bit more I think we have some extra time at the end of the schedule so maybe a little more for discussion to discuss the update updated comments for the yang push and related drafts and then there\u0027s a number of all the non chartered work group right of documents 10 minutes each for those with lastly it\u0027s not on the slide but there\u0027s lastly there\u0027s 10 minutes of spare time so maybe we\u0027ll use that okay hi I\u0027m Kent I\u0027m first so today I\u0027m going to present a proposal for refactoring the keystore model as you just heard the editors and myself has been very busy so I haven\u0027t actually updated the whole keystore friends drafts but there is this comment that I think uragan made quite some time ago about you know making sure that the modules actually the names of the modules are reflecting what the r4 and that the scope is you know as they should be one of the things he asked for was to remove the private keys the storage of the private keys themselves from this global container configuration container and so that update was made in the zero for which was presented in Singapore last time and but in doing so the keys are no longer stored there and so when the questions becomes why do we call it a key store module when it\u0027s not actually storing keys and so the whole presentation here is to sort of go over how we might you know fix that problem and by doing so doing so by introducing maybe two new modules okay so the keys for module was primarily modelled at for the keychain access mac OS utility I\u0027ll be it without any encryption to protect the private keys in fact the module was "
  },
  {
    "startTime": "00:10:42",
    "text": "originally called keychain but was later changed to deconflict from the keychain module use by the routers routers the primary goal of this module was to centralize the configuration of trust anchors the thinking behind that was because the same set of trust anchors would be needed for authenticating NBI clients you could have the same set of trust anchors regardless the NBI clients were net off base or restaurant based or just how the same said to configure your trust anchors in one location and then refer to them where you need to so that was the primary goal centralizing the configuration of private keys was added primarily was added primarily to eliminate needing to have the same gang everywhere so if we hadn\u0027t had the centralized centralizing with private keys then everywhere you wanted to have a private key you copy/paste the same gang into your game to your local gang module but then notice noted that it\u0027s uncommon for implementations to centralize private keys this way because the compa that you\u0027re made thus the top-level keys container was converted to a couple groupings and all the client server modules were updated accordingly but then this raises the question why it\u0027s called a key store so the proposal is since the remaining protocol accessible configuration is solely for trust anchors than renaming the module to trust anchors makes sense however the module also defines groupings that are used for the private keys talked about in previous slide which is nothing to do with trust anchors and should be moved into another module seeing how this module will define a number of crypto related identities and typedefs this module could also be called or could be called ITF crypto types which we similar to other types modules so we have in RFC 69 91 IETF yang type and I I think it\u0027s sexy plural I and I Tia inet types and then in RFC 60 to 90 for there\u0027s ITF routing types so that IETF crypto types might be making sense it seems like the time has come we didn\u0027t do it before or no one we didn\u0027t have the use case for it but now we\u0027re beginning to define a number of data models which are configuring and security parameters the current contents of the ITF crypto types are as is as follows essentially five different things that are in there there are identities for hash hashing algorithms identity is for key algorithms these would be asymmetric key algorithms type deaths for asn.1 structures groupings for private keys and their associated sort and a notification for notifying when a certificate is about to expire and all this is just a subset of what would be needed to support the keystore and Friends drafts or all the client-server modules that I\u0027ve been working on some "
  },
  {
    "startTime": "00:13:43",
    "text": "issues with this though is that I think cryptology is a big area it seems like the current IT crypto types might be just scratching the surface in the interest of time it would be good to publish just the subset needed immediately but we need to know what the endgame is now so that we can structure it correctly um and so that kind of leads to the question should I tip crypto types be refactored further the two groupings for configuring private keys seem like they might be better off somewhere else because they are groupings and they\u0027re very much specific to how you create private keys but you know normally the types modules are just creating that identities and and tech toughs I do believe that in the ITF routing types they also have groupings but their groupings are much smaller than the groupings that were I mean the groupings that are currently in IETF crypto types also have action statements on them so they\u0027re a little bit more than just a simple grouping secondly the notification could be pulled out maybe even delete it because I mean the notification is to alert others when answer ticket is about to expire though where would you put that I mean it doesn\u0027t you wouldn\u0027t necessarily do that just because you\u0027re having some trust anchors you know so is it seems like that might be a module ooh all its own or just simply delete it and let\u0027s not worry about it for now and then lastly maybe the asn.1 type types could be factored out something like ITF a sandal or a sn1 types because those are all kind of the same you take amazed in that warm structure you say cedar encoded you make it you know it\u0027s a binary the base type is a binary and then you know you see you have a name but you can imagine there\u0027s a lots of a s and dawan structures so you can imagine in the fullness of time there might be 30 or 40 50 these kinds of things so some options would be keep ice I took east or as it is but maybe rename it to what is the question switch to the two drafts that are part of this agenda with no more refactoring get advice from the security area first to see what the end game looks like and also for the parts that we do need now how should they look so when you start talking about identities for crypto algorithms and hashing algorithms I\u0027m sure that they have a lot to say about how they should be named and structured and I don\u0027t have any other options to share this is my last slide so at this point them do does anyone have an opinion in terms of which approach we should take oh hi Frank chef Robbie and thank you to bring this draft and that discussion here I think a person I think that this work is was it was y22 and I\u0027m from the security area and I think I have some knowledge about it so so just "
  },
  {
    "startTime": "00:16:46",
    "text": "under your very only question yeah I\u0027m I\u0027m willing to contribute to things I felt it may be to continue this work but and go back to your questions here I think you have no justice just the last page you have several options I think my personal my my my personal feeling is that country because from your current draft I I can only sing a very simple start for for this historic technician I don\u0027t know whether you want to more include more crypto of operation or configuration information for into this mode so so so because those those lost edition we are we are resulting the last the later hallway defined a how it defined from the security aspect how many classes we need or how many organize these modules so it\u0027s a little bit only to do to decide to just to keep the keystore draft or splitting - to draft so I think the option 3 is more reasonable right now and we can discuss more based on this first the draft and what is the other we need and how to organize them then we can decide you know how to push it a further work and so so I think I need to have more discussion with you of life about what is your current idea of of of what should be included in this crystal motor in addition to the already existing content right because I can see that if we if you want to a country you only have so certificate information and the private key information but if you if you are - you need more information such as a symmetrical cryptography the and the hash function and the random number generator or something I don\u0027t know if it\u0027s in your plan so so we can discuss and decided how to process later so that\u0027s my person idea yeah I won\u0027t help on this work first thank you for offering to help and secondly with regards to trying to understand how much more we need to do we did try to get an early review from sector from security experts we\u0027re hoping for them to be in the room unfortunately had conflicts with another meeting but I think Inglis is going to give this presentation in a SAG working group on Thursday year second year you are right yeah we we I\u0027m the author of a I just forget that part and also of the second ascent several drafts in second working group which is also talking about the the security "
  },
  {
    "startTime": "00:19:46",
    "text": "security baseline configuration and operation stages for piece line of the security part of the network devices I think there are some overlapping oh there are some similarity goes like that yours so I think we we need to we need to work together or which part should be here and which should be there and how to work in a consistent way so yeah yeah that you\u0027re right yeah absolutely yeah can I give you have people behind you or also ready - okay so Rob Wilson Cisco so my perfect choice I called like option two here I mean I I think it\u0027s okay to change things in a simple way but don\u0027t do too much I think in terms the discussion that\u0027s happening there I\u0027m concerned about us spending a long time trying to get to a perfect solution and I would rather try and get some of this stuff out and published now as models and then revise it and and otherwise we\u0027ll never actually get these things published so I\u0027m more keen to actually try and get stuff finished quicker and then revise it with extra stuff later very great Cisco I like option 2 as well I support this work going forward one of the things to consider in looking at your draft it doesn\u0027t refer to the trusted computing groups definitions of trust or anchors and integrating with what the definitions are - Chris Cooper group might be a good addition and it might impact how you actually define the anchor in the trust okay that\u0027s good comment thank you Tom batch echoing what will Milton get on with it in your introduction you mentioned some drafts that not much it\u0027s happened to lately in particularly Lissa don\u0027t answer the ones I\u0027m struck by how well those were progressing and then we refactor them all and since weary fact the more they seem to grind to a halt so I\u0027m against refactoring I\u0027m against I\u0027m chairing just get it out publish it we can always have a nice batch of the charioteers to this time we\u0027ve got some experience yeah Tim Carrey Nokia I think I concur with the fact that we\u0027d like to move this thing along but more importantly when we talk about an option to and you switch to these crypto types what I didn\u0027t understand when I when I looked at it was particularly for the for the SSH keys I didn\u0027t see how the referencing would happen with the with crypto towards the the pinned anchor sites I wasn\u0027t quite sure if I\u0027ve got an SSH key how that related to the crypto modules because I think they kept that in the trust anchor modules but the actual key realization was in the was in the trust anchor okay we made a mistake the trust anchor module does not currently have the it\u0027s not importing the crypto types module but it should for for instance the typed F for the CMS structure and the ex-59 structure which are being used inside the trusting trust anchors module "
  },
  {
    "startTime": "00:22:46",
    "text": "so I didn\u0027t see how the referencing happened between for the SSH keys between the between the types and the in the pinned keys at all I didn\u0027t see a reference between the two modules that\u0027s what I missed something that\u0027s why just saying I left it out by accident I\u0027m sorry I I left out the reference from a trust anchor module to the crypto types Molly\u0027s gonna go Trust Bank or to crypto we just missed the reference right okay cool thanks okay thank you hey Eric I think Europe well you just did slides it\u0027s not communal okay so you\u0027re having a little bit of technical difficulty with bringing this presentation no different presentation is it from the prism tapes yeah I think we\u0027re there yep thank you very much I am Eric Voigt behalf of myself Alex Clem who\u0027s right here and and many other people who have been involved over the last few years on the subscription drafts we\u0027ve been trying to progress three of the dress towards were last call you see a lot of emails on the list with a lot of great comments and I want to thank quite a few people the room I gonna throw a few names out I\u0027m gonna miss a lot of them people like Kent and Bala\u0027s and Martin and Andy is part of the yang doctors and Keegan and again I\u0027m gonna miss a lot of people but we\u0027ve got a lot of great comments on on the last call at this point I don\u0027t think there\u0027s anything that seems insurmountable we\u0027re gonna be talking about where these first three drafts are in last call and we\u0027re going to hit a couple of the "
  },
  {
    "startTime": "00:25:47",
    "text": "issues that we see on the list we might even be able to resolve a few of them pretty validation on the list but again I\u0027m speaking on behalf of myself Alex and the others trying to get these to last through last call so first thing we\u0027re to do is address the first three drafts with event streams young data stores and then the net comp transport now on the net Kampf subscribe unifications working group last call we\u0027ve done a number of changes such as requests to make it work like fifty to seventy seven with the filtering event records within streams based on permissions and that actually has some interesting implications for some people over the core working group who who have a different construct that they\u0027re looking at but we\u0027re going to go ahead and follow fifty to seventy seven we\u0027ve had security and considerations update based on trying to match the templates putting together by net mod obviously some stuff like treaty i a-- grams referenced reference numbers used for the state machine figures breaking out configuration replay and its own sections there\u0027s been a lot of things which which have been proposed on the list none of these are actually going to be considered closed until we have a chance for people who made the comments and or when the comment on the on the proposals have a chance to get through those as part of last call there\u0027s still some unresolved issues we have some slides coming up that go over several these that came up from people in the room and of course there\u0027s more things that could evolve a p-- existing discussions for example the yang dr comments are almost complete there again not huge items coming out of there but they could drive some more great items as well in terms of review question one and this is one that that martin identified and i think it\u0027s a good point the question was do we you want to use integer so i do we say integer do we want to use a string object sorry as an index for a receiver instead of using address + port the current draft has address in port but that makes it difficult to go ahead and augment or add new things such as leaf rests to other drafts where you might want to identify other receivers so i don\u0027t think that anybody right now is going to say they want to continue with address port the real question to open to the group is do we want to have the name as a string under receipt for probably yes and do we want to have a dress import as an option to be populated into the into the receiver or do we want to just allow people with their own augmentations to define what receivers are so in talking about this with some people offline and online the proposal is a preference for option two which would use names a string but but we\u0027re certainly open to whatever gets the the working groups preference we\u0027re just trying to record what the working group wants to do here Martin yeah more conducting so should we discuss them "
  },
  {
    "startTime": "00:28:48",
    "text": "less you go yes he says you want to discuss the issues now we can I mean this is trying to give a an overview but go go into the details if you want to some early consensus I would prefer option three and the reason is that NAT Kampf botnet cough and rest comfortable home has another way of doing this the sorry that is the net confer risk of client and server documents that can work so if we also had Addison port down in the receiver list it would be redundant at the best or otherwise what would it actually mean how would you use that as important the receiver the question is you always need something something more right like authentication information and stuff like that it certainly can be a leaf ref to other receivers as defined in those other working groups is I think that\u0027s makes sense I do know some people who do not want to reference the external groups and just want to go ahead and configure address and ports so I see it as an end rather than an or that people can address with address and port other people can have leaf rifts and that there\u0027s no reason why receivers cannot have multiple things and what I\u0027m hoping and against it\u0027s a strong preference is that we allow augmentations so that receivers can be defined in many ways you just take the set of them and they at least two receivers right I mean option three isn\u0027t isn\u0027t complete on its own obviously it\u0027s just a name so it can relies on augmentations in the future and yes if we actually had those other documents published I would suggest that we had references here to those other documents but we don\u0027t have that so that\u0027s why the option three is just right open but I still don\u0027t understand how the address import would actually be used yes but the question is you can still argument option two to also allow leaf refs there so yeah but then you would have both right so you could you could specify a name and you know possibly not called home information and their reference to that and also a dis importand what what does that mean I think even address import you can augment for those transports that just need a tourism port whatever that would be that\u0027s no transports that we have here right again we can we can close either way I\u0027m happy with whether whatever the working group says it seems easier but again if people just want to have one or both yeah whatever that working group thinks but any others all right so again we\u0027ll resolve it but again there\u0027s just a premise it\u0027s just a preference this is Alex Klem so what is the problem I\u0027m creating with you what is the process for us to get closure on this but I feel similarly by preference format that is an option tool I think "
  },
  {
    "startTime": "00:31:49",
    "text": "actually having address and port I think many many users will need it and I don\u0027t see an issue with over specifying specifically with that but that being said if option three is a preferred one that\u0027s right oh but we shouldn\u0027t but we need to get to closure so I think just start a thread on the list and see how many people like one or the other or other questions but this has already been discussed in one thread right okay well I mean ideally we take each of these threads and run them individually to ground so if you can keep the comments within the existing thread and I know that a lot of people did reply all all on my original you know last call thread but if we could spin them out into each of their own threads and then dry them each to ground that\u0027d be great I will be happy to spin this a second issue is the question of subscription state notification extension currently there is a subscription state notification which makes sure that the the state notifications do not get picked up by things like the net cop stream and state notifications really only go to the impacted receivers now with that extension you go ahead and allow the notifications any marks they get extracted the option if you don\u0027t have that stigma fication is to to actually put text in or some mechanism to identify each notification as being excluded from the net cop street I think the current solution makes the most sense I don\u0027t know if there\u0027s anybody who who wants to propose that we get rid of the the extension arguments right so we\u0027ll continue their third question is dscp the dscp which is identifying the the transport coding the which would be going across the transport should it be it\u0027s an optional feature on its own or should be mainline right now the current is that all the QoS features are in their own optional feature the question is should the SCP be its own individual feature or is it so simple that that we just move it back into into the mainline as an optional feature I have no preference on to how this is done I don\u0027t know if anybody has a strong preference I think it makes the most sense to either tection one or three just for reducing the number of features but again I\u0027m just opening to the working group if they have any strong opinions now all right we can take it on the list again salute whatever people want last one for at least back to a previous one sorry Jason stern just more general question about the dependency functionality am i right - if I understand that it really "
  },
  {
    "startTime": "00:34:51",
    "text": "only kicks in if you have something queued on the output of the publisher correct and then you would like kind of artificially delay sending an update while you\u0027re waiting for something else correct and how do you know that you have to wait how do you know something might be pending it\u0027s only if something actually is pending that yes it\u0027s a D queuing thing it actually matches directly to hell HTTP to DQ\u0027s multiple streams and that if there\u0027s a dependency one stream to the other a will it will go ahead and send that other stuff first this is really for people who have very large set of objects which are being sent but you also have a very short events which have priority we\u0027ve the real goal is just to be able to provide an indication for the transport layer should it be capable of it of pre-empting one flow in order to insert a more important subscription flow with them okay so so you see it almost as like a a strict priority mechanism that if you have a whole bunch of things queued you want to let some that certain events go first yes and the text has been tweaked to pull away a normative reference to the HTTP to QoS and now at the latest version based in the comments is a better text description again we can nail nail that down okay last one for gang push is what is the write names to use within the yang data containers right now what we have is established subscription yang data error stream proposal was there that we should actually rename it to something like stream establish subscription error info again well salute either way the question is do you want to have - info at the end or or not it doesn\u0027t matter to me I think some people have stated a preference for option two if there\u0027s no disagreement you know we can just rename it to option two there\u0027s no no reason why we can\u0027t do that kang-cook so that\u0027s that\u0027s it the result quickly now and yang oh another question sorry distance turn I question back and one of your earlier slides you\u0027re talking about some changes to authorization so kind of two questions around that one is what what what direction you\u0027re moving as far as granularity of dealing with authorization because in the current draft you mentioned that you kind of don\u0027t dig it within an event and filter kind of sub parts of a notification out yes with with events basically you can either do a pass/fail test and the text has been improved you do a pass/fail test on whether that event goes on that stream goes to that receiver so if the event contains multiple Leafs from "
  },
  {
    "startTime": "00:37:51",
    "text": "around the data model and that receiver is allowed is not allowed to access you know leaf three out of five the idea is that you would filter out the entire exactly update okay we clarify that there is some clarifying text and the text that makes it a very different mechanism than for yang push one of the reasons to differentiate from yang push basically either get the event or you don\u0027t versus the Ankush where you do a filtering at a granular level yes okay and then the the second part my question is there\u0027s a there\u0027s been some discussion of mentions about if if authorization rules change during life of a subscription you\u0027re supposed to kind of go in and take those into effect immediately so and it talks about in the draft for example that when the authorization rules change you may have to notify the subscription subsystem with that update so it can take the new rules a new effect but I\u0027m kind of wondering how that would work if you are using some sort of remote authorization like tacacs or radius or something for this type of thing because you\u0027re not going to get notified that rules have changed correct you have to understand who is using what rules and there are several ways you can approach this talking to Andy Berman in the beginning there certainly you were allowed to go ahead and install new rules if you have them if you don\u0027t have the ability to do that you can kill a subscription and force it to restart so the rules load the first time both are acceptable mechanisms for accomplishing this I\u0027m not sure if that addresses my question it\u0027s more it in the middle of a subscription the middle the life of a subscription if your rules are up on a remote server I know I don\u0027t know if there\u0027s I know there\u0027s no standard right now for nak um you know rules being provided by TAC acts or Reyes but presumably we\u0027re probably moving in that direction at some point or operational one have centralized management of the other authorization rules and it will apply subscriptions so how is the the publisher the publisher is not going to know about a change to those rules halfway through a subscription correct there\u0027s no nothing new in this document which gets into remote acquisition of the rules it assumes that the rules are known by the publisher and/or GAC to them so the and is sonice raishin is out of scope it assumes that the publisher can learn about a change to the rules yes because it says in here that you\u0027re supposed to take into account any changes of rules yes so I don\u0027t see how that\u0027s ever gonna work with remote rules we we can start a thread all offline but the goal is there has to be a remote rule thing whether it\u0027s subscriptions or non subscription so so I think the mechanism for remote rule management should be common across whatever set of things we have beyond subscriptions okay so you\u0027re leaving it outside the scope of this but you think there\u0027s a general "
  },
  {
    "startTime": "00:40:52",
    "text": "problem where we have to somehow notify publishers about changes to authorization rules if they\u0027re remote yeah and not just a publisher any any that call for a rescue F datastore okay Mike\u0027s alright so I think we addressed for going to a working group last call I didn\u0027t mention Rob Wilson before but he also had some good comments we\u0027ve made from version 15 version 16 so far unchanged amp ting period there\u0027s other minor items being worked and Alex\u0027s is the process of spearheading their reply comments on that also one thing that\u0027s highlight is the unchanged capability marking has been deferred to a future draft ballast is talking later in the session about alternatives for this needed capability beyond that going to neck confident confident medications working to the last call I think the numbering is off it\u0027s actually nine to ten and we have tricks to non-normative a script uploaded to validate the examples and get a biggest unresolved issue is that there is a question of what\u0027s in the abstract and info multiple proposals are out there what\u0027s their will salute whatever people think is the appropriate way to include it it\u0027s it\u0027s fine with us however that gets broken out last things net comp rest come from note if there\u0027s been minor tweaks and many updates are needed we\u0027re waiting to focus on this after the the complete last call people of course are willing well welcome to make any comments any time but I think that once these first set of drafts complete work last call we can start to get an arrest combination to you to transport I ask a question about that I on the previous slide when you\u0027re talking about to the script to subscribe notifications no you don\u0027t actually go to the previous slide but you were saying that um the DS dscp option was effectively identical to H to be two mechanisms or very similar writers modeled after kind of actually that the D of CP the waiting okay but my thinking is that I\u0027d you know because of that maybe it would make sense for us to look at this rest cough no notice trapped we don\u0027t know so we have to take it to last call but at least understand that you know I have for instance two-week review of it or something like that before we complete the last call of the existing drafts or does it make sense and could I just worry that we might be missing out on I mean how sure are you that this is implementable is the question that oh I\u0027m sure that the the waiting and the and the dependency are implementable because it\u0027s a direct mapping to what\u0027s an HTP to so I\u0027m not at all worried that that is going to be an issue we have early code that doesn\u0027t it\u0027s just a straight mapping into existing constructs okay "
  },
  {
    "startTime": "00:43:52",
    "text": "and then the second question would be how long do you think it would take to complete this work when might not be ready for less cool yeah the hardest part and it\u0027s been a hard part for a couple of years now is that we\u0027ve been trying to enable that seamless transport of G RPC across this and we\u0027ve done some tweaks a couple years ago to allow G RPC to be transported over this draft for example moving from a get to a to a post model and we\u0027ve never really gotten the validation from others that we can make sure it\u0027s seamless with with chair PCOR blocker really has been if we want to make sure GSEP G RPC gets transported seamlessly we don\u0027t have anybody who\u0027s willing to validate that this is a her and that\u0027s been a blocker for a couple of years now so that\u0027s not the problem it\u0027s it\u0027s not we got slowed down because we couldn\u0027t validate that firm requirement okay okay net cough notification messages there\u0027s been an update and two big changes is there\u0027s a reduction of two header message formats to one we could always break back to a two later but working with one seems to make sense until we we find that people want to split back to two that\u0027s for the biggest part the other part is that we\u0027ve been having discussions with people over in core and Komi and with signatures and there was a desire to go ahead and make signatures a footer rather than be something in the header the reason is that when you sign something you want to explicitly sign the header and the body as defined in the footer so people have asked to go ahead and move the signatures as a separate footer in order to make it explicit what is being signed we expect additional updates on this based on stuff going on in comience Ybor but this is is the probably the biggest change other upcoming dialogues beyond that is that there has to be something on the capability of receivers people like mahesh have seen this with some of his work in history is that we starting to get to know have to know what is the capability the receiver when we\u0027re trying to push stuff to it so that\u0027s one other thing I expect to be in the dialogues in the coming weeks and so okay sorry a couple comments so this edition of the footer I think I\u0027m it\u0027s a good idea but I think this is an example of something that\u0027s been added without mrs. Flay going for the working group a proposal that was brought to that list say I looked for it on the mailing list I couldn\u0027t find it all right so just be cautious going forward all right that\u0027s a good comment I thought Hank and put it out there on the list if he hasn\u0027t then then I will work with him to to do that he\u0027s gonna be pretty the next draft but I certainly don\u0027t want to do anything that\u0027s not in the list and Hank is about to do this update okay and my second comment is it was a contributor I think you need to change your import from being the rest cough yang data to yang data extension "
  },
  {
    "startTime": "00:46:53",
    "text": "the new draft that was just adopted by the net mod working group right so just one quick question have you looked at the size the data for these sort of telemetry notifications relative to say what gr PC would generate so I know that I\u0027m Rob\u0027s going to be late I think and he was talking to router work Europe how they\u0027ve tried to optimize the size of the messages to be as small as possible to get the most States rough so just wondering if there\u0027s any competitors I just see there\u0027s a lot of fields up there I just wonder is that remiel off to overhead in terms and size semester\u0027s absolutely the question is what is the overhead this implies most of the objects in here are optional and again the people who have been pushing this again are in the sea bore side of things so the the question of efficiency is is going to be one that is mostly relevant based on what Hank and seaboard and Coby people have been looking at I am believing that the proper way to at least spec it is to get the fields identified and later we can go ahead and say do we need a single bundled message and look at efficiency that way and identify the standard headers that are there so so there has been some work a while trying to get down to the standard fields that are identified before doing a detailed analysis and that detailed analysis would probably be for specific transports rather than general yeah I think it\u0027s just be interesting to see what that size difference is absolutely great yeah so Rob Shakir Google I think it\u0027s fundamental to how to do that analysis that was like oh please oh sorry maybe I\u0027m not tall enough for this microphone and I think it\u0027s fundamental to do that analysis what we\u0027ve found with designing alternate solutions to this is that we\u0027ve refracted a few times due to getting that efficiency actually the deployability of it depends on having efficient efficient encoding and even it\u0027s also probably not really technically correct to say what GRP sees as a general thing encoding is because the that you can design in different ways that we\u0027ve gone round analysis of self-describing formats we\u0027ve done mouth value with compression and kind of got to a few different approaches that give you could be better scalability so I we I can probably share some of that analysis of interest just one last comment the version three really was not intended to be a separate version three was supposed to go into Hank so shortly we should be having a lot of the discussion so apologize for uploading it before the discussions and completed great thank you Thank You Igor "
  },
  {
    "startTime": "00:49:57",
    "text": "okay thank you thank you my name is Inigo Riskin I\u0027m from Hawaii and this is basically effort of young whose design team one of the things that we are we were discussing on our bi-weekly medians and there are my co-authors on the screen and we basically also discuss this idea with other folks like Joe Harper and Angie Biermann and Rob Wilson basically basically many people were involved so I just want to warn you that this might sound a little bit strange okay so we present it for the first time please be open-minded okay so basically the whole thing what is all about that proved to be very successful and useful tool for use cases when a client can control network in interactive way basically the client asked for certain configurations then basically pick up certain data States analyzes data States cause on our pcs whatever then ask for more reconfiguration so forth right so but the client cannot micromanage the network every single behavior right so there are always things that network has to perform while client is not looking so what we are trying to do is is there any way to control the behavior of the network when it works autonomously but still provide a way for a client to say something about how this behavior has to be done okay so and that\u0027s the objective basically is to control closed loop automation by configuring standard hicieron condition actions and pushing them to the server hook them to define and specify two ends and basically pick all this request for reconfiguration : RPC getting data into these little scripts hukum to the events and condition their execution based on current or historical data states okay and basically what we are not trying to do is to you know invent a new scripting language or scripting environment our "
  },
  {
    "startTime": "00:52:57",
    "text": "goal is just to standardize a simple way to configure this given condition actions statements and let\u0027s Sarah whatever he can do proprietor lots of proprietary in order to trigger this executive execution at proper time so for example if the server supports a Python or particular junior script out a script environment it is possible that the server will take the configure TCA and generate out of this you see this little script and to look at them at proper times but basically this is how this is done it\u0027s outside of what we\u0027re trying to suggest okay so the good question is do we actually need such a serious at all and what we think is that there are use cases where it is actually quite useful but to do like for example that could be events in the network the responses - - which could be very well understand before those events happen and the client may simply say you know what in case you see this event please check space ABCD and all of this if this please do those other configurations for me let me know if something happens but otherwise don\u0027t bother me so this would be one thing right the other interesting use case is that sometimes there are simply no time to waste on network or client communications right my favorite technology is that say if you have if a battleship is torpedoed you know the crew is not expected just to report this little telemetry to the central control and wait for instructions when things will come there but the ship goes down right so the same logic may apply to the network say whether the connectivity is restored within say 40 milliseconds or we don\u0027t say 30 milliseconds may mean 10 millisecond difference and for a client like a high-frequency 3 there it\u0027s literally may mean like millions of dollars the other thing is that are what we think that the controller could be more scalable and take care of much more details and you know things on the network if the controller can delegate certain you know decisions to subordinates right so for example say me I\u0027m human right and if I have to control my blinking breathing and digestion I would probably would not be able to give this presentation and listen to your commands right so so it\u0027s just like "
  },
  {
    "startTime": "00:55:58",
    "text": "whether you want to have SEO and which controls every single member of staff or you have you and it has his lieutenants and whom it can delegate certain you know logic to and certain decisions to make while taking care of like a high-level decision now and finally there are many interesting application that can simply form like a free program all logic and push it to the server and have executed to see what all kind of what-ifs for example within the ECA you can configure some little skill basically saying if these things go down what happens right if any link on the network goes down what happens which services will be protected which will be recovered which will be not protected or whether maybe it\u0027s too fearless emergency so things like that could be done if the client has a way of you know form some program or logic the logic push it to the server and sharor just supporting the model and me making it possible to interpret this volchok and knowing nothing else could actually readily provide such goals ok so ok so basically he sees have like several components one important component would recall policy variable it\u0027s maybe not a good name but this is something that we want to call the ECA State CST it is some result of condition evaluation or action execution or tell that you can remember and use in condition immediately within the same ECA or maybe it between essays right so for example if you want to condition a certain action like reconfiguration based on not a current data state pass a median data state or certain period of time or the rate of change or velocity the change happening right then the PV would be the place where you keep evaluating and keep modifying this video and then you can use in the condition expression and policy variables are we defined they could be just like C variables that could be global or local and local could be dynamic or static say the local pee-wee\u0027s their only scope to a particular CA and they are not accessible from other "
  },
  {
    "startTime": "00:58:59",
    "text": "particularly CA and they cannot be accessible from outside of this ECA and the global views are those states that could be shared between ECA so one is hit me for example computer update this state and others can use in condition expressions to make decisions eager can speed uploaded Rick Tyler Evers a lot of this are really support this work we I some works going on in the DTN working group which has been brought in by some of the space guys because although they\u0027re not using net comp and net mod for this they\u0027re already doing this with existing spacecraft you can imagine you launch something out of Pluto you need it to react to events and manage it itself because your round trip delay is quite long so there\u0027s a whole body of work that is already at the IETF on this I\u0027d really like to get together with you because we\u0027re doing it without that net Kampf richness I\u0027m really wheel and I\u0027ve mentioned it to Kent and various other people Rob for example we\u0027d really like to take the work we\u0027re doing on ECAs and make it fit well with the Netcom from the young models so i think there\u0027s some real crossover it is a very complex environment there\u0027s lots of rabbit holes to shoot down but I think if we can scope the use cases down to something manageable I think there is something worth doing here so if you want to grab me afterwards I can point you at all the work we\u0027ve got already and try and get some alignment so I just I would like to finish that because what we\u0027re trying to do is to actually to scope to not so much thing they\u0027re called but too young and all the conditions and actions that we allow in DCs they\u0027re strictly exactly the same that the client has an access to if the client would do it interactively okay there is no it\u0027s just like your usual get data edit config all RPC make a subscription remove subscription Center difficult stuff like that and nothing more than that so it\u0027s just basically taking whatever client can do interactively and just by them in this little script so that\u0027s why I hate the policy award because as soon as it is pronounced it seems like to be a course on ITF everything to those policies it inevitably feels so so far that\u0027s why it\u0027s maybe a proper call it\u0027s like a easy escape but but that\u0027s another story right so so again you see is is has like three components except for PBS its "
  },
  {
    "startTime": "01:02:00",
    "text": "event condition and actions event could be anything that basically it\u0027s either explicitly defined by one of the models that server supports right or it could be a subscription as a young to subscription or smart filter subscription basically what we\u0027re interested in is that just the trigger the spot recur and in basically that\u0027s why we think it\u0027s a general generalization of and push that this trigger does not trigger a notification in like in case of young push for a smart filter instead it it does something else what like for example network the configuration but otherwise it\u0027s basically the same as the trigger or explicitly find the web now condition is it\u0027s a logical expression physically are just one minute so condition is a logical expression which is either a really related to true or false and it could be either express as an XPath expression on assumption the server supports XPath expression or you can build up from you know simple comparisons and here are upto a logical expression and last thing the again the actions are limited so it\u0027s not anything you can do it\u0027s only limited to your traditional like napkin style it config get data call RPC things but for example unlike Smart Filters in the notification you can set not just a current data state but for example historical data a state or any derivative of that so because we have this a luxury of peas to provide right and and you can obviously you can share conditions and actions between yes and you can actually change yes one after another and call one is a is from the other that\u0027s all yeah thanks a question Tim Kari Nokia just a couple comments one is I don\u0027t know as Juergen seen that seeing what you\u0027re doing with respect to that is he weighed in at all do you know your control order he\u0027s online but so the reason why I asked that was because an L map they created a gang model already that did similar types of things and so I\u0027m just wondering if there\u0027s a duplication here that that can be reused the other question I would have is I know that in the net mod group there\u0027s the finite state machine model and I\u0027m questioning whether this is the duplication of what they\u0027re doing there I\u0027m not saying I agree with brick that you know this is important work I\u0027m just wondering if it either hasn\u0027t already been done or hasn\u0027t already been being done somewhere else in the net mod on one of those two things right so I I didn\u0027t talk to you organ yet but I did talk a lot to ng beardman and and basically his opinion "
  },
  {
    "startTime": "01:05:02",
    "text": "that\u0027s exactly how she sees policies based on that wolf young okay so and say he in his opinion this is like a simple way to actually push policies whether we call it e CS or not and it\u0027s just taken all the riches of then that conn-young modeling that already is in place and just them in a programmatic way right so I like I guess my my statement or my comment it is is that before you get too far along there I go look and see what the L map guys did and also what this sort of the the L mile they\u0027ve already done it as part in RFC it\u0027s the information model that includes same type of a same type of approach to do it and it\u0027s been tied into the I ppm work for performance monitoring and you know Diagnostics and stuff like that that you need to do these actions all right Wow and it\u0027s got the workflow engine in there as well as the work that\u0027s happening on a net mod for the finite state machine sure and I was gonna mention the same thing that you really need to take a look what\u0027s going on in that mud I\u0027m working with the finite state machine draft that\u0027s there that\u0027s been presented in the very next session so you may want to go to this this work may go there I\u0027m not sure if it fits the Charter in its working group just a quick Rick Taylor quick point to the chairs I think that this the fact that this work is sort of cropping up in other working groups who sort of have a need for it I think either Netcom for net more time probably net mod I think need to own this to stop us all inventing it in our own working groups again slightly differently because you you look at their conference a oh well hold on I can automate some of this and then we\u0027re here again so I think somebody needs to grasp this and own this properly so thank you all right I will be talking about binary encoding really although the title says binary encoding the idea is that it we want to introduce the concept of being able to negotiate an alternate form of encoding so one of the proposed parameters is to say that the URI would allow you to specify a comma-separated list of encoding so one of the suggestions coming mainly from Martin was and that this is something Andy had also proposed is instead of having a separate activate that both the client and the server advertised the list of encoding the client does it in a its preferred order where the server does it "
  },
  {
    "startTime": "01:08:03",
    "text": "in a random order and the client just picks whatever the next encoding is that it likes and it\u0027s sensitive in that format and we are willing to adopt that and drop the idea of activate so what is being encoded so there was a bit of a discussion around whether it makes sense to do encoding above the messaging layer or including the messaging here so this is relating to figure one in RFC 6241 there are of course pros and cons of each if we go everything above the messaging layer which means keeping the RPC in the XML format you don\u0027t quite get all the benefit of encoding say in a binary format because you have to do base64 encoding the disadvantage is that now the messaging layer has to be defined for every encoding mechanism so this is something we we can take it to the thread but then in comments on what would be the preferred method next are these suggestions on encoding formats there are several that are be that people have suggested I just listed a few of them the question the first question is I think that Robert Wilton asked us how to track her visions of an encoding format I think the answer coming from Martin was well it will be just another string specifying the version number the second question related to do we need an identity definition for each one of these encoding formats I think again Martin responded and said that we don\u0027t necessarily need it if it\u0027s registered in IANA it\u0027s an encoding format next restaurant support for encoding we currently list yet the capability and and maybe it\u0027s my impression but I could get it wrong is that the content header in restaurant would allow you to specify the encoding that is being used now if there are other implications as a result of it that we need to be aware of I would love to do if we need to know or if there\u0027s anything else that from an importing we need to specify in the draft itself question on notifications support for it certainly talking to Eric about what the impact of the change in encoding format is the idea is that the time we change it for net in the net concession would also impact the publisher and the idea is that within "
  },
  {
    "startTime": "01:11:03",
    "text": "the subscribe notification we a the publisher specifies the encoding that they are going to use right did I get that wrong correct okay as a contributor I think that depends if it\u0027s a dynamics description versus a configure description with a dynamics description you pass the encoding as a parameter of the configured description both encoding and protocol the the bigger question when we were talking we\u0027ll get back to that was it\u0027s not just for subscribed notifications it also impacts fifty to seventy seven as well because it\u0027s not used to being able to handle changes to notifications underway so the breadth of what\u0027s impact it includes dynamic if there is a change after the subscription has started alright so I picked on the fifty to seventy seven maybe the agreement is that we won\u0027t be able to support fifty to seventy seventh group all right from next steps perspective it\u0027s to update the draft reflecting some of the comments that we have already received on the mailing list and then ask for adoption once we have updated the draft questions you have a comment on the on the net called drafts about the encoding can you speak up okay so can you go to the next smile maybe yeah so if you just encode this stuff within the RPC so first of all if it\u0027s a binary encoding you would have to somehow base base encoded base64 encoded or something that\u0027s correct right so then you would have the open RPC tag and then a blob of base64 data on them and the tag so that doesn\u0027t match the XML schema defined in 72 forty-one so you would have to have a weird XML or your XML parser would have to be prepared for getting data that doesn\u0027t match the schema and decode it and then do something about it okay all right so I think that the only way that would work what would be to actually put the entire session in you know binary coding and do that including the message there okay and that goes with I mean you have the same issue with notifications and so on it you just change the encoding of the notification body you know within the XML or JSON it\u0027s gonna be it\u0027s gonna be tricky okay right I\u0027d be I guess what was influencing us was the fact that she bore for example doesn\u0027t necessarily talk about the messaging Claire so we\u0027ll have to in addition now define the "
  },
  {
    "startTime": "01:14:04",
    "text": "messaging layer for say see more as an encoding format Rick Tyler this might be a naive question but if you\u0027re changing the coding including the message layer and I take your point about if your base 64 encoding binary within your XML fragment and you haven\u0027t got something that validates until you post process the internals and then run it again it\u0027s no longer net conf it\u0027s another yang supporting configuration protocol like restaurants or Siebel comp for whatever so why have different encodings for net comp why not just say we\u0027ll do a binary pump probably has to do with the adoption of Netcom protocol itself and the need for a more compressed form to transmit the data okay I think you said it but I mean rather than switching the encoding switching the protocol yeah yeah I was actually gonna respond to that Jason Turner because I think I think the intention there is that you\u0027re still encoding the OP our pcs and all the operations they are neck off so still net comp is just in a different binary encoding yeah sorry just responding Rick again the rest confer is pretty much worked example of that it does pretty much everything net golf does it\u0027s just got a different name and a different encoding but it\u0027s it\u0027s still the same old are pcs and it\u0027s the same shape protocol you know we do the same things I perhaps it\u0027s just semantics but I don\u0027t see the point of just encoding the content and leaving the messaging in the original encoding but I\u0027m all in favor of keep the shape because we all know how this works let\u0027s not invent something wildly different but I think we\u0027re having the problem in the wrong place she can and be interesting to see for the for the binary encoded approach however and I\u0027m having to do some unmarshal in of basics for Oh ever ends have been what the performance of the underlying transport is at the same time right so this is kind of oh well we\u0027ll make the message pay the mortgage if we\u0027re in single stream SSH lend it like I\u0027m pretty sure that you\u0027re not with the throughput limit is not going is not you\u0027re gonna run into the throughput limit of the transport any large data set anyway so that point in debating about exactly how we encode this thing it\u0027s all them the point we should maybe just design a protocol that works okay so couple commas first as a contributor I think that the desire for wanting to binary encode the data is primarily for high throughput or metabolic messages mostly telemetry analytic type data which makes me think about the "
  },
  {
    "startTime": "01:17:07",
    "text": "you "
  },
  {
    "startTime": "01:22:28",
    "text": "any change clarify the relationship with a young coach Maxim chart actually in young coach athlete defines a push change update education this is a actually application specific notification so we compared this application specific and education with the non-repeating with defining our child actually we can see the three main difference the first days well push change updated they focus on that pot separate is a subscription basis that means that they only can be used to send a post subscription based or contents and you go by the client and for the the notification we defined in our child actually they can report the data change event associated with the market subscription of the receivers the second change here is the push change operator actually application specific girl and but the napkin paper change actually is the general general hovers notification so no need to tie to any submission ID the last change actually is for push the change update early focus on pushy entire or poaching with the datastore condoms at their for the networking we defined in this job actually they can report data store metadata like who make the data store chain you are at the name a specific location or face other configuration changes that\u0027s errand-boy just to another thing worth adding in the differences is that the the push change update is a gang patch operation as well so if they finds a delta to the data store rather than the objects yeah okay I think for next ever I just wanna cater to feel the sense of the this idea from the room and we could decide where whether they fit into this we\u0027ll help whether we need to extend out this kinda medicine yeah that\u0027s all so Tim Carrey Nokia well I guess you guess you got one thing for sure that we kind of missed when we did the nmda you missed the data stores in 60s so my question is is that why wouldn\u0027t this just be a biz to that RFC instead of a new RFC since that\u0027s the approach that we\u0027re taking with other pieces as we\u0027re correcting for nmda we just busy I\u0027m asking it\u0027s a good question I don\u0027t think we need to answer that right now though in terms of like bringing this into a working group we first need to discuss it on the list some I mean "
  },
  {
    "startTime": "01:25:28",
    "text": "there\u0027s this draft just got posted near the end of February and there\u0027s been no discussion on it yet so I know we\u0027re presenting it here but we need to take it to the list and discuss it more there but if we were to move forward with it then that could be something that we dismiss Thanks it\u0027s an option Rob Wilson Cisco so I think I\u0027m looking this I\u0027m just wondering whether actually the yang pushes a better generalized mechanism to doing this so I question whether this is required I think is my thought so Robert Robert it is a notification and notifications are pushed three and push okay to clarify and I think that I wonder whether you want a single notification to say that the configuration is changing the operational State datastore or whether it\u0027s better just to have a generalized subscription on that date sort of configuration nodes and then you get told whenever any conflict change happens you get given the diff the patch anyway so I this feels like this was before you had things like yank push this is summary card coding a particular notification I feel that subscriptions and yank push is like a generalized mechanism that you can just choose to subscribe to whatever you want to and should this be just one of those things does it need to be special cased so to answer Rob\u0027s question a little bit is is that I see this as two problems right one is broken RFC right because you got you missing the data stores that are explicit in it so fix the RFC the second is that you get a new notification right and the question is is that new notification do you need to do you want to tie that to a push mechanism or do you want it to use the generalized notification mechanism that would be you know fifty to seventy seven or something like that and I think that can go on the list but fix your RFC and then ask if you if you need to have a new notification mechanism to be part of a stream and I think you know then that could be its own own draft or maybe in part of the biz but you know certainly fix your RFC by Ericsson I see value in this that you are trying to transfer the who changed it and also say some other meta data for example origin could be changed these are not present in yank push on the other hand you are you are missing the subscription you are missing the filters you\u0027re missing store configurations you are missing a lot of things and if you start pushing all this data with additional metadata that will be a lot and I don\u0027t I don\u0027t see it worth duplicating really the functionality I "
  },
  {
    "startTime": "01:28:32",
    "text": "think the narrative out here actually is focused on the more internal but therefore she defined a young boy just after they pushed the biggest all contents out yet they didn\u0027t include many parameter but III think here we try to generate this panel application so these are different powers actually cuz I mention okay so Thank You Jen if you could please take some of these questions - let\u0027s start thread so on them and and then we\u0027ll close them they\u0027re great and now Rob thank you so I\u0027m going to talk about GMA which is a an alternative to the Netcom I was asked to come and present here after submitting some wider after we submitted this draft and have subs talking in RTG WG and the motivation for talking here is what to form the ITF about the development that we\u0027re doing and and the implementations of it particularly as this alternative feed some of our development and deployment experience back we have this introduction some scale so we\u0027ve kind of been through a bunch of iteration of making it work and it kind of feeds back to some of the binary encoding discussions and comments I was making and invite anyone who\u0027s interested to contribute to open source projects in terms of specification and code and when not asking for adoption here so I\u0027m sure it would be controversial if we were so we we\u0027ve maintaining this outside of the ATF and we would we\u0027d like to keep it that way right now so GMA is a protocol that\u0027s used for both configuration manipulation and state retrieval from a device it\u0027s all the data that\u0027s handled then it must be described using a path that consists of a name and map of strings of attributes and there\u0027s no requirement for that to be yang modeled it just has to conform to a tree that looks that has those attributes and we wanted to do that to make sure that there was some flexibility in the modeling language that we could be used for payloads and it\u0027s built on top of G RPC which is a framework that the Google open source and it\u0027s managed in the CN CF it\u0027s an RPC framework that uses HTTP to is the transport so it\u0027s it\u0027s coefficient streaming involved in it there\u0027s the the RPCs that you can describe in the upper co-writer user request response or service dreaming client streaming or bi-directional streaming so where both sites can can send their multitude of messages the multiplexing of those are pcs is over a single IP Channel and the the kind of implementation looks after a lot of the channel management for you and and so as the producer of data you send on to multiple channels and HP to transport certain delaying multiplexing in our management is looked after "
  },
  {
    "startTime": "01:31:32",
    "text": "service definitions are in Java C written in in products bar so the genome is specification is and the encoding that\u0027s used on the wire is is proto inside of that indiana my then we have a bit like the encoding you know that we\u0027ve been talking about earlier the same thing and can encode into binary values which are part of a binary serialization or JSON or ascii text etc so jenamae has for our pcs it\u0027s relatively simple and it\u0027s got a set obviously which does the manipulation of the writable state of the target so this is that this is has a simplified transaction model on top of the the the way that the one in it compacts so we assume that the we require that the client pre stages the Save Changes they\u0027re going to be made in a single transaction and then sends that set message as part of the unary set RPC to the device the device then applies the entire set of transit set of changes there within that that message or rolls them back and we found that this gives us a bunch of simplification on the client side we don\u0027t have to keep track of multiple candidates there happening or long-lived candidates and in in our change workflow and in the change workflows of those that we\u0027ve worked with on this project it\u0027s it\u0027s as soon as the machine is making this configuration changes and really get bored and walk off in the middle of changes so it can be trusted to have compiled the set of changes that it wants you to a single transaction the SUBSCRIBE RPC is then is a streaming RPC from the target which will call that the network element the device to send state to the client we have immutable subscriptions so they\u0027re created with a particular mode in this particular set of paths they can\u0027t be changed during flight and they there\u0027s three different modes of those those of those subscriptions to have a stream which is a long-lived push from the device so the client the client opens a connection subscribes to a set of paths and for these things then the target continues to update those paths according to either events or okay news based sampling we have a poll so we\u0027re in for the paradigm where we would like a client or to still be able to request when it gets sent data and then we have a once which is an efficient way to do a get without requiring the target to be able to marshal all data on so since you start an iterator and you walk through the tree and use you advertise everything that matched the paths that you\u0027re specified streaming data as I mentioned can be sampled so where the device takes a sample every n-no seconds or whatever frequency is specified in the in the IPC and then sends a value or it can be unchanged that\u0027s when the value changes a notification sent it sent or a mix of those so we have this mode called target defined where basically the either the data model or the type of the that the server implementation determines how best to send a certain leave so in that kind of case if you have a counter then it sent us a sample version if it\u0027s if it\u0027s something that\u0027s an event base then it the Target Center as an event and that gives us the most efficient way to be able to to choose how to to allow the target to choose how to to optimize for the the tree that it knows about and "
  },
  {
    "startTime": "01:34:34",
    "text": "Indiana my and particularly for subscriptions then the target always time stamps the the packet so this gives us the ability to rather than SNMP where you have oh I pole at time X and then I don\u0027t know where I get a response at time Y by have to assume that the the sample came from time X the the timestamp at the device tells you exactly when it was taken so you know you can continue to build a more accurate graph and some of our telemetry it\u0027s particularly noticeable when when you compare their telemetry data to the P date since it\u0027s just a quick clarifying question you said time stamp to target your reading counters from the hardware is it the time stamp you want the counters read from the hardware you expect always when they get put into a message and sent know when it was taken from the hard way so it\u0027s when the value changes is is effectively when you\u0027re looking for so when it when the value changes or is read from somewhere is the quote it\u0027s close to what actually changes what you\u0027re after right so if you that way if you have more you know caches inside of it device you can still maintain their cache you know okay it was taking at time X and the client even whenever the client comes to retrieve it it\u0027s able to determine what the when that sample was from equally if you\u0027ve got leaves that are populated with you know likely bgp session that went up or down if the timestamp is when that happens so when a new client comes along its able to say oh it does happen time X you know many many moons ago rather than it was a new event occurring right then we then have to to other our pcs a get our PC which is designed to be a snapshot of state at a particular time it\u0027s particularly using the configuration scape retrieval where you know you want to serialize the configuration into a message and send it to the to the client and but we\u0027ve we\u0027ve kind of debated and there\u0027s some talk in the specification around the scaling implications of this if you have a large set of data to be able to just a realize there can be some it\u0027s not sufficient just putting them into these individual notifications where the targets able to choose how to serialize for performance and then we have a capabilities RPC which is just used to understand the both of encoding so we support post buff and an ASCII and JSON as I said and then the models that the device supports so this allows you to know what schemas you need to to understand why you mentioned that he yang is not required so do you have any other means how to communicate the model supported by the target yeah so we have we have models that we\u0027ve written in prose above so we have for further the encoding efficiency we actually take a young module and we can machine translated to protopathic gives us a way to build serialize directly into binary protocol on the wire but "
  },
  {
    "startTime": "01:37:35",
    "text": "yeah then we have parts of the schema that are written just in proto for particular things Jim Carrey Nokia I\u0027m curious when you say you do the civilization from the from the yang into into the protobuf how do you deal with all the semantic elements is that take into account because you can\u0027t do that and protobuf right it\u0027s all syntactic right so the the schema is if we have this debate in nazi of UT\u0027s well it\u0027s if the for schema validation and for compiling the data tree and validating it then we do it in data structures that are aware of the yang it\u0027s an item proto and then they have proto that\u0027s then the proteins just is used in those cases just on the wire or so it\u0027s all syntactic you lose all the you know all the semantics that go into the richness of the yang right yes so you can that we have libraries that serialize and deserialize from proto back in to data structures that are able to do to do theater - at point you lose the rich rich so the module or you just reconstitute you assume that said the definition of the modules right like if you\u0027re dealing with the winds and ifs and stuff so you\u0027re trying to reconstitute it at the back end it\u0027s not on the wire you get as both ends have to have the end so I think it was separating the use of approach versus schema language and the proton yang is a schema language from a serialization so we have if we write to schemer in prototype then yes of course we don\u0027t get those things because proto doesn\u0027t support that if we write the schema module in yang then as long as there\u0027s some code RT you need both ends have in the yang so you can reconstitute that semantics okay but but we I mean particularly for telemetry we haven\u0027t really seen that there\u0027s a huge value in having the collector layer have any awareness of the schema because it can\u0027t really do anything right it\u0027s like a value gets sent to you and it doesn\u0027t comply with the schema it\u0027s not really like you can you you\u0027re not going to say oh no that\u0027s bad telemetry please send me something something different so having that split of not having time having data structures that are not schemer aware in the right places has given us quite a lot of ways to optimize for those high-volume cases without having to carry a bunch of metadata around okay and one of the things that we\u0027ve tried to do is make the the genome I suspect as minimal as possible in terms of having only the things that we think are common common across multiple use cases in the spec and then have this way to to extend the protocol so it\u0027s something that can be extended by you know both the core team as well as just opening a github issue and adding to it the extensions are a carried per message and we\u0027ve using them for things like proxying so where you actually talk to a target through another another proxy because it\u0027s outside of the same trust domain or in some cases we have master arbitration between different writers so two writers do a master election and they want to know which was the latest only the one with the latest election ID should be allowed to write in a splits brain scenario and so these these extensions are carried from message so some of them are relevant obviously to only set RPC but it they can be carried in any message so that the protocol can be extended we have both well-known and "
  },
  {
    "startTime": "01:40:35",
    "text": "extensions that are which which are defined within the within the spec as well as registered extensions whereby an ID assigned to them and the contents are opaque for for arbitrary extension we we\u0027ve tried to keep it such that these are only used where the existing our pcs function is really being extended it\u0027s not new functionality or fundamental change to the RPC because in that case it\u0027s better to run multiple services so that we have to find expectation as of this two so you can run multiple GRC services on the same port and and have these extension our pcs being listed this separate service it\u0027s something to speed up may be good I think sometimes something I\u0027ve kind of mentioned this is this is something that\u0027s critical for the for the fidelity of the flama tree which is important to us we\u0027ve been through a few iterations on encoding of values so we started out with Jason encoding values and found that this was this introduced unnecessary complexity because things like integers becoming strings meant we had to it then unmarshal them back into what they should be so we\u0027ve now adopted using native native protobufs types for encoding and mapping things like decimal 64 which don\u0027t have a have approach both native type and on into specific messages this was the point that I was making earlier about on the wire efficiency the volume of data is is pretty huge on on scale systems cures and interfaces even to just that set of counters is a large amount of data and things like the BGP ribbond device rip end up being large as well so we\u0027ve had a couple of approaches both through prefixing of data so being able to build a notification that has a common prefix across all the paths in it and then use of the generated prototypes on the wire as the to be able to aggregate sets of data gives you a significant significant advantage on the wire and that that\u0027s turned out to be one of the the scaling limits that we found in the system is is how is the amount of data that can be transmitted through through their job we see on running on the network devices a development approach I\u0027ve kind of talk to this we\u0027ve got specification that\u0027s in github then there\u0027s reference tool implementations which we\u0027ve open-sourced so there\u0027s a CLI tool that we that we use for interacting for device there\u0027s a target there\u0027s a fake to be able to you know test implicit implementations against it for that for the device and telemetry collector implementation it\u0027s mostly open-source it\u0027s almost we\u0027re still in the process of getting the last few parts of it out and we have a reference server implementation as well and we\u0027re thinking we\u0027re starting to also develop myself combines tests that will be run written there will be open source and published such that try and build an ecosystem so that people can actually just download this and run it rather than half the kind of overhead of directly trying to develop I think a bunch of things themselves and his for future posterity a bunch of links to some of the things that I\u0027ve talked about alright thanks for uh we don\u0027t have any time for questions in else "
  },
  {
    "startTime": "01:43:54",
    "text": "thank you so yeah I\u0027m I\u0027m Alex came from Huawei I\u0027m presenting the update on a smaller graph comparison of nmda data stores updates from the last ITF 100 if not run on a run basically again just to recap this draft defines basically just one RPC allow us to compare and in the a data stores basically the issue is that given that there are multiple data sources data source with data values propagating between them there\u0027s the issue and what happens maybe when when finds data values don\u0027t propagate correctly or take longer time to propagate how would you how would you be able to troubleshoot those other things so really for those items believe it\u0027s convenient to have a comparison or discrepancy detection or differing basically type of operation so a couple of discussion on this son on the mailer and based on this basically posited just yesterday actually in Eurovision with a number of changes one thing basically what has changed and since Singapore is we added examples into the draft also there was the discussion concerning should this be called discrepancy detected or something else so baby be removed the discrepancy detection comparison and dipping to make it actually clear in simpler if you will and then there is one feature within this which was an option feature before concerning a dampening feature which basically and was intended to to report differences only when they persist for a certain amount of time so it could basically specify the only bit even when you see a difference done true probably immediately only when you see this persisting for some period of time feedback was from the was on the mailer to rather busy move this out so this basically what we have done actually right still consider this personally actually is an interesting feature but believe this is not put into the into potential futures another feedback was to also mention the possibility of applying in addition pre-filtering step to exclude data from the comparison which is not within the scope of both data sources now basically also added into the draft and that it\u0027s basically pretty much all so basically I guess the things where we are now basically we need to confirm the removal of the dampening as a feature I think from the mailing list discussion it seems that there\u0027s basically the consensus of the working group to do that one other item that should be added this was based on a poet actually who made that comment was busy that we need to add a reporting of the original discrepancies okay when there is it this when there is a difference and that is detected it is useful to include for instance in the "
  },
  {
    "startTime": "01:46:56",
    "text": "operational data store what was the origin of that which can again help bizzy\u0027s explain what is going on so that is something that will be added and and finally making this still in the individual draft what we\u0027re hoping you want to ask us if this should be adopted by the working group all right ed and I see Lou getting out so I\u0027m the question of what coop adoption maybe Lou you want to say sure so what new protocol mechanisms are being defined in this document so it\u0027s again what new protocol mechanisms are being defined here oh this is actually go to the backup slide basically this is a this is defined as an arc we see inside a yang module okay they finds in obviously just to just to compare solid applies to anything that you would run yang I\u0027ll proceed with all right yeah I think it\u0027s great function very interested in it but it\u0027s not clear to me why it\u0027s in this group versus that mod since there\u0027s no protocol I guess I\u0027ll be more example said as the burger again I suggest we bring this into net mod and present it there and ask for adoption there okay I guess the question is which workgroup should go to I think you have a preference for this working group cause of all the yang push and related drafts but to lose point it may be better suited for that working group is fine I mean I don\u0027t think might call we don\u0027t feel strongly either way so if this moved from that not sure well what is the problem there I guess is then the isn\u0027t the question for one it won\u0027t be then we won\u0027t make the adoption okay well that\u0027s the room then just a show of hands who\u0027s read the drafts okay a fair number and of that group of people who believes it should be in this working group versus or like raise your hand if it should be in this working group okay raise your hand if it should be in the net mod working group all right should go to the net not working group okay thank you Kent or chairs can I ask a question about the last one you know one minute okay I\u0027ll note that we have time on the agenda in net Maude shall we take this up in this meeting think about it I\u0027m bothered anger from Erickson and I\u0027m bringing you a little problem that was pushed out of yank push to make the main drafts progress faster but is actually part of that problem space so we have "
  },
  {
    "startTime": "01:49:59",
    "text": "the unchanged capability in the ank push but we which means that in changes will be immediately notified whenever they happen but we know that implementations will not be capable of sending on change notification for everything there are a number of reasons for this some objects like counter can change very frequently maybe the changes are not meaningful like a small temperature change but I think the most important is that maybe it\u0027s not always implemented for every object that we monitor it and we immediately notify changes about them and in some cases hardware limitations might also they are also if I am on a bigger author than I can send notification about any change if I\u0027m on a smaller out there with limited resources maybe say models I can\u0027t do that but practically this means that although I say I support unchanged notifications specifically I\u0027m allowed not to send notifications for anything that means that client and network management system cannot really depend on it because yeah maybe this one interesting object was not implemented for own change notifications then how can I use it really and and I\u0027m a so metric want to depend on these so they won\u0027t need to know will I or will I not get not we unchanged notifications for specific objects relief or whatever so let\u0027s document it and there was a proposal based on yang expansion statements in the yang push draft that didn\u0027t meet with everybody is liking so the alternative based on some of these requirements is to reviews a yang module and the main point here from the requirement is that this information which specific data nodes will send only change notifications is both needed both in implementation time and run time most of the time evander already knows that yeah I won\u0027t send unchanged notification for counters but I won\u0027t change notifications for I don\u0027t know configuration or let\u0027s say BGP peers or changed yang modules are changed there\u0027s some other big changes also some of these items let\u0027s say can be changed also in run time let\u0027s a new yang feature can be switched on in run time so now I need to know and and that would might mean that I sales and not unchanged notifications for different objects so there is separate need for implementation time and runtime "
  },
  {
    "startTime": "01:53:00",
    "text": "information about this so that\u0027s why I propose that we use a yank module to document which objects will send notifications and with the coming draft that I\u0027ll present in another hour about yank instance data and how to document yank instance data that will allow us to have design or implementation time documentation about the same thing so what I am really proposing is a yang module or that would extend the angle ITF yang library that contains the these Netcom are not vacation capabilities it will have a set of data so default capabilities for each module do I send notification on change notifications about that module yes or no and if there are some specific object specific data nodes that behave differently than the yang module default then I have a possibility to to mark those ones as well in the notification capability list with no selector and the change notifications and this last one is just an example of how this would be documented in design time using instance data so what I am asking is that we need we have a problem that needs solution that\u0027s already documented in the yang push draft and defining a yang data module for this small yang data module for this would be a simple solution that supports all the requirements that I see it so I would like to ask for a work group adaption for this draft so I don\u0027t think it\u0027s appropriate to like pull for I think it\u0027s important work like to say it was pushed out of getting push but this draft was just submitted into February and there hasn\u0027t been any discussion on it yet and also I believe the set of authors are currently very busy on a number of working groups are documents that we really should probably see the completion before we bring on any more work to that group of authors so perhaps we should take this to the list just more discussion and then see a little bit further down the road if we should adopt it actually we have offline meetings with those outdoors and most of them self supported it\u0027s actually all of them I\u0027m sure they did the question is do they have the bandwidth to actually work on the document I expect that I will do the major 80 of the work but that\u0027s a question okay this is chaiienging from Huawei though I have read a job so this job to address the problem of identifying which objects unchangeable sketching a sport or not so "
  },
  {
    "startTime": "01:56:01",
    "text": "you set a small object changes are frequent and meaningless I think a weather set change is mean for an order it\u0027s dependent on with your application and a user needs so during the your time the value of object changes frequently might be incurred in interest to some users so what what I mean is that for running system then I need a switch is that I\u0027m changing notifications auto or not can be switched really I think if it\u0027s based on the user then the user can use the subscription parameters to define it this is more about is the note capable at all to send let\u0027s say octor in octet Scouter notifications so it\u0027s really server capabilities just briefly comment regarding when we like I think this work is because it was pushed out of the yang push I consider this celebrating part of that overall body therefore responding to the question do we have the bandwidth yeah I think will will will will make the bandwidth Yogananda on jabber has a comment the question is whether this is the right solution for the problem there was a small simple solution with yang expansions that was not supported I think this is a good solution for the problem they\u0027re not clear the contributor I believe is a key problem right I would like to have unchanged for every single variable I have in in a router even counters right because some of the counters are important here is the counters number the reset on a bgp session i care about that right so i think this is a very important work we\u0027ve also have the same problem in jena my and and the the solution we\u0027ve taken is a little different the so we\u0027ve got a way of annotating in the schema whether the expectations to say okay this this should be sent unchanged like the in objects counter yeah probably this is true permissions and unchanged but each beep si should stay this should be sent on change but we in we haven\u0027t got the sort the the proposal you have here of open the RPC and but just don\u0027t conform to some of the the request of the client we don\u0027t take basically if you try and have an unchanged subscription to a leaf that or to a set of leaves where it doesn\u0027t cut it\u0027s not possible for the device to do it it just fails the subscription and we have this target defined mode that says the client actually doesn\u0027t mind how it\u0027s set and that the the problem here is that you ain\u0027t enter a whole world of complexity if you accept a subscription whereby where you can\u0027t actually meet the request so it leaves a whole load of compliance and and functionality to "
  },
  {
    "startTime": "01:59:03",
    "text": "solve undefined in the implementation so I kind of preferred the approach of failing if you asked for a subscription that the noda isn\u0027t able to honor just failing and not opening the RPC at all and not starting streaming originally this was information was in the schema but not everyone liked that then some people said that spec change drying time which objects I support or don\u0027t support absolutely so the the the annotation in the schema is really to say what\u0027s what\u0027s the practical like there was the recommendation or what\u0027s the the way that the scheming that knows about this data should send it the bigger question I have is whether you want to go to this complexity of having of accepting an RPC that you can\u0027t actually honor the the parameters of because that\u0027s what you\u0027re talking about here you\u0027re saying and someone asks you unchanging you can actually do it not really because what I\u0027m saying is that I accept I say the subscription request for everything but you have to understand that I say everything then I mean everything with these exceptions so I\u0027m limiting already what I\u0027m promising you but then the the actively our PC is not so the way that we\u0027ve solved this is they have this targeted find mode which says actually as the client I\u0027m gonna let you choose how to do it and then you you based on the knowledge Lee implantation which doesn\u0027t have to be communicated and in band to the protocol say what you\u0027re expecting if I specifically asked for an unchanged subscription to a leave so let\u0027s say I\u0027m trying to subscribe to this in octet counter just on change you\u0027re going to I\u0027m going to subscribe you\u0027re never going to send me anything you probably was better to just not accept the subscription so it\u0027s very clear to the consuming system that it wasn\u0027t able to the device wasn\u0027t able to honor the contract last question so Ruggles and Cisco that\u0027s actually a question for Rob so what happens if you can generate Liana change subscription the notifications but you\u0027ve got some quantum quantizing halflings you might have to change generated notification say every 50 milliseconds so how do you get that information to the client that you can do or Chum change but you can\u0027t don\u0027t change them every event is to some limitations to that so the thing we asked we\u0027ve asked a lot when we add things to Jenna Mize what is the client going to do so if you communicate that to the client it\u0027s like oh if it hasn\u0027t got anything you can do about that\u0027s that\u0027s all you can really do so there\u0027s no real need to have that in the protocol it is more so that they aware of what service they\u0027re actually signing up for is that does that have to be validated at this time like what how does it how does it actually react to it so that\u0027s a design system design time at the annotation right implication so we don\u0027t need to carry all the implication the considerations that the system design protocol the protocol doesn\u0027t essentially need to carry them actually this is yes this has been no no small part about system design because we said that the implementation time information is needed as well and that\u0027s this is this "
  },
  {
    "startTime": "02:02:05",
    "text": "is the way actually to provide that one to the implementation time thing I think is definitely a good idea too I\u0027m just not sure that it\u0027s it\u0027s required at opened all right I think we are anyway over time so this essentially closes the napkin session yeah how long\u0027s the break okay yeah so that nut mod session starts in 18 minutes no it\u0027s in yeah but the net mod session is in blender him there you put that into the poker yeah hey what\u0027s up "
  }
]