[
  {
    "startTime": "00:00:06",
    "text": "Yeah. Yeah. I think Would be good to have somebody You can do it remotely as well. Thank you. Just have to, you know, mostly focus on the decisions and outcomes of discussions. You don't have to get every Uh-uh. Word that is spoken, so Alright. This is the privacy pass session at, IETF 119. Hopefully, you're all in the right spot. Let's see if we gu, Alright. You should be familiar with the note well by now. But this is, You know, kind of outlines the rules of the IETF. With respect to intellectual property and also with respect to how we treat one another. So Please be familiar. There's also the note really well, which, goes into various Expectations of conduct. For a meeting tips, please, if you're in the room, Please sign in using the online tool, Or on-site tool? So that we get an accurate count of people in the meeting and so that you can join 2. If you're a remote participant please, you know, mute and,"
  },
  {
    "startTime": "00:02:02",
    "text": "Turn off your video except when you're chairing or participating in the discussion. Let me just also introduce myself. I'm Joe Saloway. And I'll give, Ben a chance to introduce himself and she's participating remotely. I have Ben Ben Schwartz. I'm also Coachero's privacy pass, but I'm participating remotely from New York your audio is a little bit low. Alright. Here's a list of some of the other resources. And now we get to the good part here, which is our agenda for today. We'll have some Brief update of our some of our core documents. Than a discussion of some of the newly, accepted work or adopted work in metadata, we'll look at some new work that, Watson Led has proposed. then And will have a, some discussion, led by us Steven Valdez and Martin Thompson on kind of privacy pass and how it's interacting with the web as a whole. So that should be interesting. Does anybody have any other items for the agenda earning agenda bashing that needs to be done. Alright. Then I'll go through just a a brief summary of where we're at. The the core documents, I believe, are all in the RFC editor now. We have a document and working group last call."
  },
  {
    "startTime": "00:04:03",
    "text": "Which is batch tokens. Unfortunately, I think the document has spired a get the authors to submit a new one, but you can still put in your reviews I believe that Last call goes past the IETF week, we can ended if necessary, but please take a look at that document So next is, Steven, do you wanna give an update for a key consistency? Let me see. Can you do that again? I think I Double select there you should Hi. I'm Steven Weathers. I'll be giving an update on the key resource consistency draft that we adopted guess, a couple of months ago. The general idea of this is we'll go over the big open issues that have questions up would be good to to get the working group to get some input on. There's particularly some things around client fetching patterns and how you Consider authenticity. Versus what we're getting through this safety, which is the consistency, than just the other issues that are mostly editorial and then next steps for this draft or really at work. The first big issue that we need some sort of resolution on is that The draft uses binary HTTP to in code and encapsulate the resource that we're trying to be consistent about, currently just encapsulates the whole thing all headers. It was brought up that you'll only really need to encap like the contents and maybe some other headers. Content type is the one that was brought up. It's an open question if there are other headers we think are valuable to calculate right now, or we should just dropped to"
  },
  {
    "startTime": "00:06:01",
    "text": "doing those that one header in content, content I don't know if folks here have strong opinions in either way. Uh-huh. Yeah. So, Martin Thompson, mate, I think I made this comment. I will observe that if you only care about the content, You can just hash it. And have, digest field coming back from the consist consistency check, which is pretty nice. Aside from the potential for header fields to, change the way in which that content might be interpreted So I don't think you need to worry about content conings or anything like that, but you you may wanna make sure that It's the right Jason Verint, for instance, in case there's been some changes in the way that the the different, Jason payloads get interpreted, for example. So, I would be I would be comfortable, I think, with with just A head request. On on this one. If there's a recommendation that, that use digest fields and, content type. Which is not what is in the draft at all. Yeah. But, I think it achieves the goal that we're looking for, which is that you can confirm that the content is the content that you expected. Yeah. This gets in a little bit into the later slides about authenticity. But, yeah, I think that definitely would be a simplification for, like, certain ways of shaping this. Then maybe we should open that up as a separate issue from the final recipe question. Seeing no other comments on this issue. The next big issue we have is configuration rotation. This is a problem of If the consistency, the mirror has cash like the resource but the client has either got in a more recent"
  },
  {
    "startTime": "00:08:00",
    "text": "resource or got it in a slightly different way, there's gonna be an inconsistency that shows up in, like, This isn't actually a malicious attacker, and figure out how we resolve this see whether, like, the client has to be retrying and refreshing if we have some just leave it up to the application and leave some security analysis or do something else. I think on the thread, it's mostly leave it up to the application layer. Not have strong opinions in the consistency draft itself. But if people have thoughts other than that. I think that really, there is a lot of, like, intricacies depending on the application, so it's solving it hear other than giving, like, best practices maybe out of scope. Seeing any, so I I don't quite understand how you get into this situation. Are you saying that the that the origin copy of the resource changes before its expiration time? Is that the the situation you're talking about Well, I this is something The origin server puts something out. It has a freshness think time of an hour. Half an hour later, it actually changes content. So now the cache copies don't necessarily agree. Yeah. If the mayor saw a longer lifetime, then we actually happen or that the client saw, or, like, if the client's always just getting the latest one, which is separate from lifetime. So if lifetime, it doesn't actually mean how long it's getting served, which you can imagine with, like, some origins surveying and overlapping lifetimes. Yeah. I mean, my my view is that That is like, like, like, not a supportable configuration. We we can't like, if we We can't really allow that. Because there's no way to Check the consistency anymore. There is no consistency. Right. Because some users may be accessing the the accessing the resource through a an intermediate cache. So you you've failed consistency at that point."
  },
  {
    "startTime": "00:10:01",
    "text": "Oh, but Yeah. So so, Ben, I think We can't avoid this either, and that's, I think, the the key question that we we have in front of us is that At some point, we need to allow for the possibility the config might change at a resource might change. Alright. When these are not permanently immutable, at the point that it changes, there's gonna be a bunch of cashes out there that are exist for the purposes of doing consistency checks. That will have out of date content. And any client checking with those at that point will find that they don't have the right content. And That that's just hard. It's it's possible, perhaps, to to solve this with having multiple resources and having consistent mirrors of each, and so you suggest you you have clients switch between 1 1 of 1 of 2 for instance, and then consistency is achieved with Either of those 2 resources, that might be might be one one way of dealing with this sort of problem. This is a problem we have in a lot of other contexts as well. Terms of just how do you upgrade a protocol to support a new algorithm or something along those lines. I, I think we need to have some sort of mechanism for solving this problem. Yeah. Though, I guess with that approach, even If you have multiple, there will always be a case that you have the worst case timing and every entity here is gonna be, like, inconsistent with each other. And even, like, if you don't allow overlapping, and, like, lifetime is exactly how long a service like, handing a thing over, like, Time is a falsehood and Lake. Different resources or different entities on the network may believe the lifetime expires at different times. Which, like, is completely okay behavior mostly, but we'll introduce these sorts of problems. And I don't know if you wanna say you have to have perfect caching, which seems part So So on on Martin's point,"
  },
  {
    "startTime": "00:12:01",
    "text": "do think that there is a might, like, like, like, like, like, like, like, like, In in theory, there is a discipline that makes this go away. And that is to say, If you put up the if you serve the resource with a cash lifetime or the a freshness lifetime of 1 hour, then you've committed to that resource for 1 hour. You can't change it. If you want to change it, you have to wait until all extra copies have expired. And then, you know, then you have an opportunity as the origin to to change it. And, yes, this then leads into this other ladder thing that we talk about separately, Chris, it sounds like this is a common out of problem. I think, has enough sharp edges. Maybe it is worth having at least more language in this draft. We can't solve it for, like, all application use cases, Because I I think this is just like there's even more sharp edges that not be obvious to applications built on this. T. Both. Yes. So I think I agree with Steven, it's mostly like a wording in the draft. You might have the origin send the resource for, like, with a cash lifetime for 1 hour. And then the consistency proxy can actually do again for 1 hour per the draft. I think the issue is, like, with this intermediary cash lifetime, which, like, kind of visually extend. Lifetime that the origin sent initially. That's that's a lack of a wording issue in the draft. Seeing no one else up to next issue. We have Is someone similar in terms of expiration. There's a problem of if We have these sorts of lifetime things and, like, a lot of clients their lifetime and their resources expired and they're, like, getting new ones. This is a lot of traffic going to the consistency matter. Maybe some solutions are a thing where we only do head requests because we only care about the digest."
  },
  {
    "startTime": "00:14:02",
    "text": "Other things are having some logic for clients checking at different times that are not related to their lifetime. Or this latter strategy of where you're served multiple resource versions of the resource overlapping lifetimes, I think parts of this probably go more towards application layer, but some of that at least, like, needs to be specified so that consistency matters, no what sort of traffic patterns they're gonna experience. And, yeah, maybe there's a there needs to be a more look at, like, what is exploration really mean for research consistency, the graph compared to what we currently have Any comments on this one? Too long to switch tabs. This is related to the previous discussion about having having a fixed lifetime. If you have If you have the resource commit for the for the hour. If you try to ensure that there's there's a there's a clean breakpoint at which the resource is not longer valid, Then you have guaranteed a thundering herd of that one in time. And, I don't wanna have that happen. So let's not use that solution there. And, Otherwise, Yeah. Most times, I think the the natural Access patterns of clients will ensure that you don't get a thundering herd. But, but, will have to ensure that you don't create any synchronization mechanisms. And that previous solution that was suggested by Ben, I think, does create that situation. Let me go into the next issue. So there was a comment brought up that because our like, clients are directly accessing the mirror. There's a client IP leakage. Some solutions might be requiring multiple errors in your application. So no single"
  },
  {
    "startTime": "00:16:02",
    "text": "mirror will see all the clients, or it'll be spread out across a larger set of pools. This probably is just some privacy language in the doc, and, like, we don't actually need to solve this. Not curious if people have other thoughts of, like, requiring HTTP or, Other or requiring larger pools of mirrors, If not, we Next issue is it came up during the, adoption call. This is mainly about how the current graph mostly focuses on the mirror being like the place you fetched the resource from and could probably just trust that, and it'll be fine. This isn't actually true because the mayor is only giving consistency and not authenticity. Doesn't prove that the resource came from where it actually said it did. Think different applications will see this in different ways. There's applications like main privacy password, the keys are coming in as part of the, challenge. So you already have the real resource. You're just using the consistency to compare against that. The other applications may wanna explicitly call out that they have to do a fetch to the origin. The question is, what we write in the draft? If, like, call out this is as a problem. Require that you do this origin fetch, which I think makes, complicates the privacy pass story. Or if we just leave it in security considerations, And real like, let this whole content binding be like a thing solved in the application layer. I think we'd probably lend towards the mention it as a thing in security and not, like, enforce anything just given that, like, our main use case for this wouldn't wanna do an or separate origin fetch. Wanna use the keys that it already go. Through the get protocol. I guess, Martin's probably the you have any helmets here since I think you're the one who brought this up. Otherwise, That's a reasonable approach, Yes. So the reason that I brought this up was that the draft talks about the second request that you make, basically said nothing about"
  },
  {
    "startTime": "00:18:01",
    "text": "the first one that you probably need as well. And so just just put some text in, I think, was really all it was was requested. Sounds good. Then there's a few other issues on the Repo, a lot of them, I think, are wording or clarifications. Some of them do overlap with this systems, your life hunting thing, hopefully resolve those as resolving the previous issues. If any of those turn into larger discussions, we'll bring it back up to the so next steps, I think, are resolve the issues or dig further into the issues mentioned that today's discussion There's a couple of other comments, including, like, Martin's, proposal about doing digest instead that maybe we should open up some issues about in have discussion about on the list or on the GitHub. The other question is about implantations and if there are any plans for folks to make up implementations. I don't know if there are any immediately, though. I think There's been various mumblings of folks interested in doing something in this space. I think that's it for this draft. K. Any other, questions or comments? Ben, k. I just wanna emphasize that this this topic of, like, Whether The whether it's permissible for the origin to have essentially multiple outstanding inconsistent copies of its resource that are all fresh simultaneously, Is, I think, like, very fundamental, to this dress. I'm not saying that Like, it must be one way or the other way. By, by, by, The whole logic of the of this protocol, is built on some assumption at that level. So I think I think we We need to Be very careful about what we what we say there. I think"
  },
  {
    "startTime": "00:20:00",
    "text": "if we'd have it all agreed on the same mental model there, then We need to pin that down very clearly. Yeah. Yeah. Okay. Thanks, Steven. See, we did have a little time reserved for some additional discussion additional additional proposal for rate limit, tokens, but Watson doesn't have a thing prepared for that now, so he's gonna bring that to the list, or I think he may have already. So but he'll refresh it so that we can have that discussion on the list. Do you have, anything you wanna say, Watson? Yeah. And so there there's been an email already, and send another one after the meeting explaining with with more of the content and sort of explaining the main differences. Thank you. Alright. Next, I think we have, Scott up with, talking about, some of the various metadata extensions. Do you wanna ask for slides, or do you want me to, Alright. Yes. I'll just ask for the slides that I submitted there. You should have control. Cool. Alright. Short slide deck today. We're really just reviewing the couple drafts that have been adopted at this point, as well as, suggesting some future areas of work and and where we can kind of dig into on this extension space, bit of inter on, Scott Hendrickson, I, worked at Google,"
  },
  {
    "startTime": "00:22:01",
    "text": "a bunch of folks have helped with this privacy bass extensions work. I'm just presenting. So Chris Wood, galsamjad Kevin Yo, Steven, Steven Valdez, and a few others. So thanks everybody for your work. We'll hop right into it here. So so far, we have 2 drafts that have been, adopted into privacy pass. We have into the property's passport group. You have the off scheme extensions draft, which really ads, spot for us to be able to pass some extensions, in privacy pass. And we also have the private space public metadata draft, which is a mechanism for passing privately and publicly verifiable metadata within privacy pass. So With these 2, we now have a mechanism as we presented in, I believe, IETF 118, maybe 107, to pass around metadata. Through privacy pass I'll talk about a use case in the next slide. Some common feedback that we got when, adopting these drafts was metadata opens up the ability to identify more clients if we're not careful or individual clients. If we're not careful about Oh, how the metadata fields are controlled and how they're used I'll give some examples of that in the next slide as well as how this could be protected against. We also need to add more consideration of this into the privacy discussion of the drafts themselves, Also, common review feedback was, some reference libraries and code, around extension crafting would be useful. As well as, test vectors for the particular variance of the crypto that we're using. So we plan to"
  },
  {
    "startTime": "00:24:00",
    "text": "address all of these in the in the drafts. I would encourage if people have taking a close look at the drafts, please do. I'm sure there's a lot more that we can improve on, in that So I actually wanted to go through an example of how we are using extensions in the Chrome IP protection project. I think this provides a useful ground to talk about the expiration extension specifically. I'm gonna run through all of the individual extensions that we plan on using for Chrome hyperprotection authentication. If you're not familiar with Chrome, IT protection, based on what we're doing in this project, is, we're gonna be proxying a subset of requests, in in the Chrome browser, this session is not the one where we talk about exactly how that works. But we do have an authentication mechanism that ensures that, clients have met some reasonable bar we use before using our set of proxies. We have 2 proxies, they're speaking mask. There's a whole other IETF session about this. A proxy a, we call it, which is the first proxy in a proxy b. You need to provide a privacy best token in order to, to authenticate to either of these So those, essentially, are gonna do public are gonna do token verification and then inspect the public metadata to make sure it needs some constraints they expect to see their This is the set of metadata that you'd see on the tokens that we're providing at these proxies. And I'm gonna go through it one by one now. So we have an expiration time stamp that basically says after the timestamp listed in this expiration on the token, the token is no longer valid. We have a geo hint that allows us to present a reasonably correct IP address for, the user We have a service type, which In this case, is always gonna be fixed to a single value Chrome IP blending. We have something called debug mode, which lets us override some geo constraints if we need some things out."
  },
  {
    "startTime": "00:26:00",
    "text": "It's really a developer specific option. And it will always be fixed to, a specific bit, for production users And we have proxy layer, which basically says, hey. I'm this token should only be good for, a proxy a or proxy b? Can folks in the room just let me know if I can still be heard. I saw Nick's comment. On the chat. We're good. Okay. Nick, apparently, it's harder to get bites to you in New York City. In New York City as well, and it is to get them to Australia. So as we could see in this particular type, harp, Now if we go back some of the privacy concerns that we have on this particular, draft are that, you know, if you add many bits of entropy at a particular token, maybe we're encoding a a geo that is too specific to a particular user. User's gonna lose privacy. Because even though we're, we're applying blood signing, to the tokens, when we go to the validate the token, if the geo It has something very specific like my home address and I saw that both at the token issuer and at the token verifier I won't be so private. But if there are many users, like, say, maybe there's many users for our appointment in New York City. I'm just putting New York City and that geo, that may still be private. It's really up to to the deployment, how many users we expect to see in, particular geos we have As we look at the layout of, of Metadata here. We can see that service type debug mode proxy layer are all essentially fixed bits the Chrome client can actually check that those bits are set to a particular value in production. So we're really just concerned about geo hitting expiration time stamp here. Do you hit, as I said before, we do have ways of limiting the metadata available in this particular case, we would have a well known set in North America planning for 800 or less, geos. And if you're talking about a very large deployment, like the scale of all Google Chrome clients, that may be acceptable. It really depends on the privacy parameters of the,"
  },
  {
    "startTime": "00:28:00",
    "text": "particular deployment is looking for, on expiration time stamp stamp specifically, we also have, ways to round the expiration such that we think that, there'll be many users in a particular bucket of expiration timings. This allows us to have tokens that are still valid for a shorter period of time than full curation cycle. Maybe a week or 2 weeks. While still giving users, a sufficient amount of it's so same. We have precision rounded here too. I don't think we've decided on exact value, but it's, like, 4 hours or 8 hours or something So you have tokens that are Val, valid for a much shorter, period of time. Than the full curtation cycle. And in fact, our deployment can change this dynamically down to a preconfigured minimum, that the Chrome client would validate for. So this gives us a degree of flexibility, without having to change like our full curations. Set. So that's a little bit of an example of what we're doing in the chrome eye protection project. So I wanted to dig in a bit more into the expiration time span stamp specifically because as we can see, We have 2 drafts adopted so far. None of them are actual extensions. So some folks give us some feedback that it might be useful to also adopt an extensions draft, to to work on in conjunction with the the core drop, like, mechanics, for adding extensions, I agree. And I think expiration timestamp is a great example of this. Of the cool things about expiration timestamp is it allows you to decouple the configuration for how long a particular token is valid for. From your actual curitation cycle. Saw this as a key reliability constraint. If you are not in a not style deployment, So in our particular case, we we are not actually in multiple cases that we've deployed, we're not using nonces."
  },
  {
    "startTime": "00:30:02",
    "text": "So this allows clients to cash their their tokens for a period of time. There's no initial challenge. In this particular case, it's very useful. To Be able to set some shorter expiry window on the token? That's not the full key rotation cycle. Especially if you can't, necessarily trust that your client code behaves a certain way. So in our case that, we we kind of saw this as an opportunity to deploy an expiration time where we can actually adjust dynamically saying, token will be good for, maybe 4 hours, but the next token we issue and maybe it's only or 2, because the constraints in the field have changed. Always in one curotation cycle. Very interested to hear what you have to say, for lots of non ounces. For So there is a draft spec available for this. It's linked in these slides, and we can send it out on the on the mailing list as well. And I I I would Appreciate it. Folks could take a look at the expiration draft that we have there. So simple set of next steps, and I'd like to open up for some questions here as well. I think we should continue iterating on the two drafts that we have available. I would like to consider, also a drop the expiration extension, which gives us nice space to, to work with, along with more custom like I presented, that probably would never be adopted, and that's, that's the, you know, the intended the spec there. And then I think we should also go over to the CFRG and request an adoption of the request another adoption call. For the partially blind RSA, now that it's being used in our draft here. Thoughts questions. Steven? Super Bowls, Google. I agree that we need one of the extent, like, a particular"
  },
  {
    "startTime": "00:32:02",
    "text": "extension draft to be able to, like, think about how the other drafts work, and I think expiration makes sense here. I am worried that, like, we now have expiration in this metadata. We have the expiration of the keys for the tokens. We have the lifetime of the cash and, like, are a lot of intersecting things that I'm wondering if somewhere we should, like, be thinking about this and discussing that inside privacy pass because leaving it to each of the drafts and having to align all that seems a little bit complicated. I don't know where the best place to actually have the discussion though is. Tommy? Tommy Polyapple. So I I have one thing that I was gonna get up here before, but 1st in the chat, I wanted to a comment about nonces. Wanted to clarify because I think you made a comment at one point that you're not using Nance's I I My interpretation of is that that is that you're not using redemption contexts. As part of a challenge, but every token still has a nonce in it. Correct. Your debt's not, and you can get Okay. Yeah. It's not bound to it. Yeah. Sorry. I'm using, the way my brain thinks about the way that we should talk about it with the spec. Okay, cool. Alright. So that for this, I I think we should adopt some extension It's I guess the expiration sounds as good as any, any to do that with, and it's Pretty concrete. So sure. I'll need to think more about the details on that. I did have a question overall. From The use of extensions here and How applicable are they to Yeah. Kind of ad hoc scenarios like what you were talking about with the IP privacy solution that you guys are doing or, like, what we have for private relay when you know, essentially, like, but The client and the service infrastructure all know what they're doing together in in so in that case, yeah, it's very easy to say, I expect All of these extensions. I know I support all of these extensions."
  },
  {
    "startTime": "00:34:01",
    "text": "And it's all gonna be one big happy family. Versus a case where a client can come along, get a token challenge, or, you know, see tokens with extensions that they don't know about. Yeah. Just like, what is the right way to think about the applicability of extensions to scenarios where Like, How much do I need to know does the client need to understand the semantics of expiration in order to use it. Because if I don't understand the semantics, they're potentially very scary. Yeah. And I think this gets into the Just the technical details of, you know, does a client have the support for handling, that particular extension, it obviously needs to. You know, there's an there's an issue open on one of our github repos around The ability to challenge for a particular extension type or a set of extensions saying, like, I would like you to provide a token with with, with this set of extensions that might give a nice opportunity to help clients handle those. But certainly there are going to be the the requisite code in order to fulfill The the set of extensions being requested I'm I'm not sure if that entirely answers your question, but is that helpful? Is that a helpful way to think of of the problem, Tommy. Yeah. I I I think that does Help. Yes. I'm right. The client does need to understand it. It makes me think, and I know there's discussion later about, like, applicability on the web and stuff. That Also, in order to make sure that we are not segmenting user populations based on what extensions they support and know about that and We we, to some degree, want profiles of"
  },
  {
    "startTime": "00:36:02",
    "text": "like, there could be a web profile of saying, like, here's a set of extensions that's appropriate and you want all users to use it together. Because, again, like in the case of bespoke proxying situation like, what private relay or what your thing does, we can just say all the client in this population all do the same thing, and therefore, it has nice properties. And it gives us that ability to say for production clients, this bid is always 1. Things like that, right, that are just, like, simple safety encodings. I I'd like to see, yeah, what are the ways we can replicate that model Mhmm. Going forward. Yeah. feedback. Yeah. That's good K. And So it looks like a lot of these extensions you've mentioned are basically proprietary They're they're very tightly coupled to some internal details of your of Google system here. I wonder how you feel that meshes with the IANA registry setup. That we have right now for extensions. And should we consider some other kind of name spacing or registration system to acknowledge this idea that actually A lot of the uses for extensions are are basically highly proprietary and, and maybe shouldn't all be mixed into one big nature. With the with the form registration requirements. We actually have of text in one a bit of the drafts that, that hits on precisely this, where we basically just say you can squat on, a a particular extension ID but you may have to move your system if something standardizes on it. That was our way of handling this overlap. I do think it's a good point though. Like, if the vast majority of extensions are going to be or we expect them to be private or use case specific. Like, maybe we should have a better system for handling this, but I also think"
  },
  {
    "startTime": "00:38:00",
    "text": "the standardization process takes time. Unless it's pretty easy to dodge around on this type of, like, ID, overlap. So we weren't super concerned about it even in our case, for example, we just picked a big number and moved on with k, Nick. Nectarescdt may maybe this prietary question is is getting at the concerns I've previously expressed on the privacy implications here. I I haven't been clear on how the client chooses What? Expiration, you know, what what expiration at once or what expiration it's gonna get or or what what it needs in order to used for the service that the draft doesn't define any of that. Is it just Well, of course, it's it's proprietary. And and so like, There there is no way that you can do it without preconfiguration between the the client developer and the service developer, or or is the implication that like, no. This is going to be Expiration in in general if you want to use a privacy pass token with any service. Yes. Because it because it seems like the privacy properties are going to depend Dramatically, like, like, completely on then then details of of how that non standardized piece is worked out. So Yeah. I think this we is hitting on. How how need to protect privacy here. Or not, or not, Yeah. Thanks, Nick. I I think this is, hitting on Tommy's point as well, which is in the case of, a non proprietary deployment where the client, the a tester or, sorry, the issue we're in, verifier of all agreed that, like, are the parameters we're gonna"
  },
  {
    "startTime": "00:40:01",
    "text": "It must be rounded. The expiration time stamp must be rounded to this number. On on, like, this UTC alignment, For any public deployment, would also have to be agreed upon And so we may just pick some big value and say, like, oh, it has to be rounded to a or, multiple days. With with this alignment value, and that would have to be part of the the negotiation process. That would be occurring that Tommy was alluding to. Think we have to do more work there to make sure that this This set of extensions works not only for the proprietary use cases, but also the public ones. Please, but you do intend it to work for the public And that's that is the intention here. I think we should find find a way to make this work for for all you just as a private spouse. Like, this particular extension, in my opinion, is very useful for for a deployments support, if we can find a way to make it work, Okay. Thank you. That that does help me understand, k, Steven. So to Ben's point about, like, there's a lot of private extensions here, and that's gonna pollute the namespace. I think, like, having a private use space, I think, would be pretty valuable. Like, you know, that only gonna use these sorts of tokens in this sort of, like, use case and you're not gonna mix it with other things. I think the approach of, like, choosing some and then hope it doesn't intersect with other standard nice things that happen like 10 years. From the TLS flashbacks of having random trash show up when we were doing 13. I think that's not really manageable. So maybe this is, like, private use numbers. So I think other things have done it that way. Yeah. We actually think we had it set up like that originally. We had a block that was all private use, and then we we changed it based on, some some review feedback. So I I have to go consult a review feedback to see why we changed we could see if we could change it back Okay. And thanks, Scott."
  },
  {
    "startTime": "00:42:00",
    "text": "Cool. Thanks a lot. Alright. I think what's in Europe now Do you want to propose work the slides or should I? I think it might work easier if you share them to meet Mhmm. Mhmm. Mhmm. I can try it from my end if that would be preferable. I have it. Just tell me when you need to advance. Alright. Thank you very much. Alright. So I'm introducing draft flag privacy pass, VBS01, some other authors whose names did not make it onto the the tracker copy, So privacy pass started off encoding a single bit about the user. And there was some close coordination between the issuer and verifier about what this meant. Public made it that changes that. We've just spent a lot of discussion seeing some of problems. Some municipal trade offs. If you encode too much, there's a privacy impact. If there's too few, then the origins that are verifying this and relying on the information included, aren't getting the data they need. And This might be a manageable thing if the client, when it's getting the token, knows a exactly where it's going to spend it, and it was exactly where it's going to need But as we just saw in the q and a from the last presentation, a open system that even then it's hard to and we have origins wanting different data, There's an inescapable tension between playing everything in and putting the minimum in One solution. So the issuer can give an anonymous credential, you've picked the, CVS04 car car image look like, central for scheme, And we put the user agent in charge."
  },
  {
    "startTime": "00:44:02",
    "text": "Has a credential. It can decide what fields to reveal or not reveal depending on the origin needs. The issuer can can cover the whole attribute space. Without an impact to privacy. And the user agents are the ones that could that that can determine what the privacy impact will be and say, okay, we're not gonna show that it feels too sensitive, etcetera. There are some challenges. So privacy pass, you usually have one token usable once only. Somehow we need to achieve that here. It's a little tricky. There's some ideas there's a BBS preferred for a link to ability ID again there. Origins somehow need to be able to advertise what publicly they want, and Yeah. So those are some of the that's really the big, big, big two challenges. For pulling it in. There are some alternatives. You can pick other schemes, you know, we can talk about what the merits of those schemes were. You can't really use the the the credentials that people see are using stuff with SDWT, because of the blind signing. That makes it really hard. You you can't just throw in the blind signature and say, okay. I'm gonna have hash. I'm gonna reveal things because the hash is a linkable thing. Question and then there's some questions we're working with. Is this problem that needs solving. And if it is, is this the way to solve it? And then, you know, I leave it to the chairs and they work figure out if we should pursue this as a things are put out. Floor is open."
  },
  {
    "startTime": "00:46:13",
    "text": "Alright. I'll I'll buy it. Madden Thompson. What Watson One of the biggest concerns I have with a lot of these things is just that that first bit You, you know, able to hide that first bit are you The fact that you have a token Or you the fact that you have something that's been signed Right. Yes. You can't hide the first bit. I'm concerned about the first bit. The fact that you've hidden all the other stuff and behind whatever all configuration and whatnot. That's great. I I really like the BBS signature stuff. I think they have a great deal of applicability. I think that in some contexts, this will be a distinct improvement But there's a narrow gap between context that can't tolerate the one bit Potentially, we'll talk about that later and context where the additional bits, plural, do not represent a significant challenge for that particular deployment. So you think about, the stuff that Scott was talking about earlier, I'm I think I'd be totally fine with all that stuff being just in there. Now it might be the case that the the partially blind RSA stuff is just not as good as BBS. That that's like a, a real good argument, perhaps, I'm not sure Yeah. Tommy Polyapple. Yeah. I agree with what Martin says. Like,"
  },
  {
    "startTime": "00:48:00",
    "text": "I like this. I mean, I I am not a cryptographer, so I I want you other people who are more familiar with BBS to talk about the application here. It seems to be cool. It seems to have nice properties. I think potentially from a motivation standpoint, you know, just adding it, to the zoo. Of things and specifying how to use it correctly in this context is Nice, And there can be reasons to prefer using this when you were creating new bespoke deployments or upgrading them that they may prefer to use this. And I I think That is one way in which I see the kind of registry and the zoo of different token types evolving, is just to say, Hey, we have better, more efficient ways or more interesting ways to achieve these same things, separately from the the question of, like, when is the safe to disclose bits. So I I think we should pursue it. I I think you should continue to do this and, like, think we should work on, this document here. But then there's, yeah, maybe I'm making it boring in terms of, like, here's how you use this crypto here, and then have been broader conversations about when you should use what types. Separately. From us, Any other comments or questions, for Watson? Alright. So I'd Seems like there there is some interest, In in this But it's not quite clear how much at this point. But sounds like something we can continue to discuss"
  },
  {
    "startTime": "00:50:02",
    "text": "to see where I think we We're still kind of unsure as to where exactly you would get to the most benefit Nick, And, Yeah, Nick Doty. Sorry. I'm I'm still trying to understand the the particular proposal and the implications Is is the idea that, like, this would to to the work going on and and, you know, Spice or verifiable credentials or something. This would this would give the property of unlinkability. We even if the issuer and the verifier collude. Is that Is that what we're trying to And then and then select disclosure on the attributes. So leaving the whole space mess out of it. Proxipass already has a linkability why it does the blind RSA thing versus just sign a message. What we're trying to achieve is selective disclosure. We're we're trying to avoid the issue where you need to have everybody in the deployment agree exactly what the public metadata that's presented will consist of. Same with same with and it's exactly what's issued Is that a big constraint once you have multiple parties with different needs? Right. I I think I was just trying to compare against from from the other side where there there are selective disclosure puzzles out there that don't have the unlinkability in you're trying to say, well, we could take the unlinkability from privacy pass and add select a discussion property. Yeah. I think that would be a way to think about it, but this is really aimed at sort of the The place privacy pass fits in fits into the"
  },
  {
    "startTime": "00:52:03",
    "text": "rest of the things versus the way that space tries to fit in. Well, is there some reason? I'm and I'm sure you you all know that's better than I do, but is is there some reason that this wouldn't be applicable to All the credential data. Applications, applications, Come watch next dotatfnlflog sewing similar in spite Okay. Well, I'm definitely supportive of that. I did. Hi. Benchworks. I just want to, so it sounds like there's a a wide range of of interesting ideas Here, I just wanna point out that The group's charter has a lot of language in it around tokens? And metadata, And so if what you're doing is small amounts of metadata on tokens, then that looks like pretty much what's in the charter. But if what you're doing is verifiable credentials with unlinkability, then that might might not be in the charter. You might have to think harder about Then I mean, the thing is once you start adding public metadata, the the the token unlinked to World Financial thing. It's It's Symantec. We can we can put the capsid to keep it as small as So yes, it's there's there's no, like, hard line between these things necessarily. But, for example, if your solution fundamentally has, like, one of the very viable credentials, systems as a building block and is is, like, glued onto that, then you know, that that definitely changes the Question of where the work should be done."
  },
  {
    "startTime": "00:54:04",
    "text": "Nick, are you still in the queue? I you're think How about Scott? Yeah. 4. Yeah. So, I am not an BDS expert. I I would like to learn more but it does sound like this could fit quite well with the extension negotiation problem that we were, chatting about earlier, and I I just intuitively wonder if there's a a nice fit there. So if we feel that, extension negotiation for the Public protocols is something we wanna solve. I'm wondering if this selected disclosure bit of BBS, is a really elegant way of solving those. I I think we should stay more engaged, and that might fit as a natural use case. For, for the BBS proposal if this is in fact something that is useful. For that space because obviously with the way that we've defined, public metadata using, blind signatures that negotiation part, would be more complicated. You would have to kind of do another round of issuance or or do all the negotiation upfront and then do your issuance. So definitely interesting stuff here. And I think maybe if we could combine the use case with the the the tool here, we could have something quite productive. Yeah. I I I think so. I think it does address that issue of negotiation. Okay. Great. I think we'll we'll we should have some more discussion on this. It sounds like there is some some potential, uses for this? Next up, we have, Steven. For our discussion on privacy pass on the web."
  },
  {
    "startTime": "00:56:11",
    "text": "So this will be a brief overview of privacy task SK APIs on the web. Is the first part of a discussion that Martin will follow-up on. So we'll save, like, actual discussion for after the presentations, it's a quick overview. There are really 2, 2a half major use cases of private pass our privacy style APIs, and I won't get to why it's style the first is private access tokens, which I think is one of the more well known ones. It relies on a split, a test issue, a tester model, and is One of the reasons we have the rate limited token spec if this is currently deployed, The other one is private state tokens, which isn't quite private pass, it doesn't do any of the authentication. Stuff that we have in the off docks, that does is mostly based on the the LP draft draft. There are a few bits where it's using the best back in a way that the batch spec isn't currently defined, but think hopefully we'll resolve those differences. Then I think would want to move to something like the consistency mirror thing for distributing keys. I think we probably won't ever pick authentication scheme part of things, but maybe if there's, re issuers that want to use that, that might be a thing to look at in the Sure. Also did have private metadata, but we ended up removing that in the version that's currently shipping. The 3rd version is the thing that Scott talked about, which is the IP protection, use these blind RSA token and the metadata drafts in order to have some amount of data on those tokens. So in early systems, the attester issue ecosystem really cuts down into 2 different problem spaces. One of them is you have a single or set of attesters. Parties that you The client then you pretty understand they have, like, fixed meetings. You know, you can probably trust them, and the client have some guarantees about what's going on with them. The other one is this arbitrary tester ecosystem, which is what"
  },
  {
    "startTime": "00:58:00",
    "text": "private state tokens users where you have a lot of attesters slash issuers for private state tokens, it's a joint they're basically the same thing. So you can't really rely on the fact that you have a small well known ecosystem you have to do things like limiting how many issuers are used in particular contexts, for PST. This is based on, like, how many issuers a top level site is allowed to use. But a lot of this, like, the fuzzier meaning of tokens and the fact that you really only have these mitigations at issuance and redemption time, I think, add complexity to what we can actually say about the privacy there. So a chat some challenges are have all these members in the ecosystem that are interacting on different websites. How do we reason about that. How do we limit that? Can have these sort of hard limits if you're only allowed to use a fixed number of attesters but then you run into things where chosen your attesters and now you're stuck with them and other parts of IHF, we've seen that these sorts of shotguns are really terrible problems and would be nice not to have them another thing we have is because have a bunch of testers in the ecosystem. We can't do things like private access tokens does. And the redemption context link where you always just, like, do your issuance right when you're doing a redemption and use that as a sort of fresh disk guarantee and binding to that context. We run more into the problem of you were an issue, right, when you're redeeming, you're going to have bigger timing attacks just because you might have a love smaller attesters and smaller issuers that Like, they only see 10 people visit them an an hour. And these sorts of timing attacks get a lot worse here where, like, your ecosystem is sh built in the shape I think in terms of the meanings of tokens and, like, the value that you have within tokens, I think Martin's discussing more about that in the next presentation. But, yeah, there's a bunch of open question that the future work that we sort of, like, made arbitrary decisions on on these API slides, some of them maybe we can solve more broadly within privacy pass and some of them we just might have to leave to the applications. A lot of it is how lots of insurance interact within ecosystem. Also how ecosystems interact. Like, if you have multiple things that use privacy pass in, like, different layers. There is some amount of, like,"
  },
  {
    "startTime": "01:00:01",
    "text": "privacy issues there that probably we should think about. There's how we be technically classified tokens, which will be the rest of this discussion, and I think the meaning of tokens changing over time Like, even if it's a well known meeting, I think that adds extra entropy sort of to the token because, like, even if it's the same key, like, you could have a bunch of keys on one day and a different set meanings for the so those same keys on a different day. And It's sort of mentioned in the current draft, but not to, like, a very deep degree, And though it's not clear, like, maybe this is some architecture s stats draft that we wanna add or something else. Yeah. That's for the overview and much using Do you want me to no one ever has 2 devices. At No one ever Oh, oh, Look at that. Blank screen. Alright. Alright. Well done. Try that again. You can start it up. It'll take me a little while I don't see any in yet. I'm I'm pretty good. Oh, yeah. But but use cookies, ask slides, k. You should be in business is him. Such a tiny little window All right. Alright. I'll try to make this quick. So we can have some time time for discussion. There's a lot of material here I'm gonna skip over of it as we go. The interest of, talking more. Or you're talking more, me talking less."
  },
  {
    "startTime": "01:02:01",
    "text": "So I spent a bit of time looking at this one. There's a write up that they can provide a link to, My interest in is in how privacy passes built into web browsers Stephen already talked about the the 2 major deployments. Are we not talking about cloud players privacy pass browser extension. For various reasons, that has most none of the problems by and large that I'm talking about here, because there is there's an decision of the point. Someone installs that extension, to more or less, trust cloud player to to upright it. And and we'll, as we'll say, that's that's kind of important. So Yep. There we go. So, Just to sort of put this into perspective a little bit, we have 2 basic auth authorization modes that we we talk about. Here, and and privacy passes kind of novel in this respect because you only get a a sort of loose coupling, between the the thing that you use to authorize and a person, It's really a group of people have the same or indistinguishable distinguishable, the same, tokens. And that forms an an amenity set. And the idea is to make that anonymity set as large as possible. So that you can provide the people in that set some degree of privacy. And timing, bunch of other reasons it gets complicated, so you make them even bigger again. And then, eventually at some point, you have something that that works reasonably well. And the whole point of all of this is that a lot of the uses of privacy pass rely on having very low activation energy. You don't wanna get into a situation for instance, if you're using these 4 if fraud purposes for advertising, you don't wanna go asking permission for people to to put a token in the browser. You don't wanna have a whole bunch of"
  },
  {
    "startTime": "01:04:00",
    "text": "friction involved in a lot of these scenarios. And and the VPN case is a really great example of an application where it is it's low stakes authorization. And so, privacy pass is entirely appropriate for that. Now, of course, because my phone went to sleep, I have to wait for it to reconnect. Wonderful. Crypto here doesn't eliminate the need for trust. It just reduces and shifts it around a little bit. So we all know this. So we'll skip past that one. Now, the idea is that if the privacy is good, We don't have to ask difficult questions. Right? Right? But what we're doing here is we're trading the fidelity of the authorization signal for the availability of it. Essentially, Yeah. Next next nodding here, it it it it is is thinking about this one a lot as well. So, here's here's the key problem. The presence or absence of a token carries a bit of information. And the timing of the arrival of that carries some amount more, information, And there's some amount of extra information that's that's available in the context in which a token is presented that also carries information. Now. Information might not. Be useful. But when you're designing a system that uses privacy policy, you need to account for these information leaks. And with with loose bindings, you don't necessarily get to to narrow, things down without sort of pulling on that, on that privacy constraint a little bit. So, we talk in the specifications about binding to a particular origin. Binding to a particular usage context, and and you saw, in Scott's thing binding to a, a narrow point, window of time,"
  },
  {
    "startTime": "01:06:00",
    "text": "buying into a particular, proxy instance binding to a bunch of other things. Now, of course, the more bindings you put in that smaller the anonymity set. And so there's a bit of tension there. And is a deliberate choice we make when we're designing one of those systems. As to, how much privacy we, we, we wanna provide. You wanna Ask your question, Tommy. I don't I think I probably skipped over something or or fumbled it. No. Just if you go back a slide, just To to noodle on the the, like, the target origin scoping. Yeah. At least for how we define it, in, like, the normal types, if you're not adding some extension, It it's generally, like, the the origin can choose to say, like, I want to scope you but, like, that that bit of information is only ever seen kind of buy the origin in the client itself. And from the perspective of that origin, That anonymity said is the same it would have seen Otherwise, No. No. Not necessarily. If you think about the if if you have 2 origins, and they both accept the same tokens. Then the anonymity set is the set of people across that that that access both of those origins, Whereas if you wanna bind it to your specific origin, if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if if Prevented the the expansion of the anonymity set across origins. But if but if in my challenge, from my origin. Yep. I can I 2 options? I can say have need to give me a a token that is for my origin only or one that's for anyone. You know, I have But in either case, you just give me one token that I have no way to correlate to anyone else. And I just kind of made a choice. And so, like, by making that choice, you are the origin knows, like, it'll just get that type back. It doesn't know which one you were in. Yeah. But the the the set of people the present the origin bound tokens to you form an anonymity set. But they have it is the same people who would have presented in the other case."
  },
  {
    "startTime": "01:08:03",
    "text": "Okay. It size. Maybe I'm wrong about this detail, but It's it's it might really doesn't change the language Yeah. So We have this system. We have a a number of different actors in it. Making some presumptions here about the attack that people trust themselves, so maybe you don't care about that. But there's a bunch of, There's a bunch of decisions we have to make in any deployment about who trusts him. And That's not. Bidirectional, in each case, there may be some amount of trust flowing in one direction, but not the other. And we have to have to think about all of that. Through here. Makes it a little bit complicated And then we're back to the one bed thing. Question is, what does a bit mean? So from the perspective of the client The meaning of that bit is essentially unknowable. This is one of the one of the ways where the additional metadata in the baby proposal is good because then the the meaning of that information can be known. The meaning of the bit is essentially unknowable. So If you think about it and a tester may receive a bunch of information about you when Astraneta Station, and it may pass some of that information along to the, the issuer. We sort of trust that they don't. But but It's always possible, and that information could be bound up into that bit. Now most of the time, it is exactly the sort of thing that you might Expect, to be passed along. It is, this is a trustworthy person or some analog of the same. The same sort of area. But concretely, that that could mean anything. And this the design of your system and the and the trust assumptions that you have determine what that meaning is Maybe. And that's where we come to the problem. There are no guarantees. There's there's no guarantees about the the meaning of the bit"
  },
  {
    "startTime": "01:10:02",
    "text": "or even about the size of the anonymity set. Because we built the system where Dick could be just one person. Asking for these tokens and everything is set up correctly, Everything could work, could work, But it just so happens that within this particular window of time, there's only one person asks for that token. That person then becomes identifiable, identifiable, and there's nothing in the system. Would guarantee this. Apart from the trust that we have in the entities, that are operating. Right. And so that's where we come come down to everything. And So Just is key. But the web, Yeah. We don't really have a whole lot of trust. On the web. Did I skip a slide? Yeah. There's a bunch of options here. Ultimately, There's there's some the slide that I should have had in there, and I I realized I right, at this moment. Is that When we When we think about deployment to the web, we can't just have trust that cloudflare is going to operate their service. In the way that we believe. Yes. We might trust cloud player, but they can't be the only provider of this service, we have to have the means to at other people, now. How do we established trust in those other people. And There's there's attention between centralization, and being able to trust, the set of people that are involved in this and bunch of different decisions have been made. You will see that in apple solution, solution. Currently, there is only one attester. By my understanding, and a very small number of issuance. And that works. Because those actors are generally trustworthy."
  },
  {
    "startTime": "01:12:02",
    "text": "You can make an assessment based on the list that are operating. Which I'm not sure is public, but it's not exactly a huge secret. On the other end, end of things, Google deployed private state tokens, and any website. Conditional issue 1 of these tokens. And and Well, you know, If trust is everything, we've just given them 11 or 6 bits of information. That they can pass around between websites, which is I don't know. Might be that's something that you can tolerate. Tellurate. Cussantly, I don't think that's that's quite good enough. So Discuss. And I'm gonna sit back down again. Because I don't wanna be up here as if I am some sort of authority sovereign identity providers, Yeah. It's an idea that's been discussed. I realized that I had a I had a call with the folks at Google we were talking about all the different options, and I didn't raise this one. So it turns out that most of us have some form of identification document, that a government has given us, whether it be a driver's license or a passport or something similar like that. The existence of one of those things is, scarce resource. And it might be possible to leverage that. And then and then the signal is something that we understand, which is you have a government issued identity document with some rate limiting controls on that one, which we can go into the the sort of cryptographic details. That may be an option for us to explore. It's not privacy pass at that point. It might be useful for, things like, antifraud Yes. One question about the apple registration. So that's mostly for issuers, like,"
  },
  {
    "startTime": "01:14:00",
    "text": "still only have they wanna test her. So, like, bad acting issuers actually add as much of a problem to the explicit system since They don't they can't choose separate, like, reasons for why they're issuing tokens. Right? Right. Okay. So Sorry to jump the queue. Just to answer that, So, yes, currently, The default behavior is we have have The one attester, and for, like, the trust model that works well. And, like, As we were saying, like, if you want to make sure you have a large anonymity set. Like, you the the client essentially needs an advocate And the and a tester who you are disclosing information to kind of already have to have a trust relationship with them. In a good position to do that. We are relying on the intester to make sure that you where they are talking to is being used by many, many clients all know, the the issue same time, and there's not a timing attack. So the registration exists. Mm-mm. Really just as a way to you know, say, you know, do you have a way to forward. The tokens, is there a MTLS there? Then also to have essentially an entity on the books that you can guarantee the size of the anonymity set. Say, okay. There's this thing I know about. Are claiming they're gonna have many clients. Gonna check that many, many clients are going through them all the time. If you fall below the thresholds, then you could target people. So we'll stop allowing it to be used. With regards to the trustworthiness, of an issuer. At least in the model, that we've done with the, you know, the split tester issuer The The trust relationship There, that, you know, the choice you can make is that it is only the origin that's trusting the issuer. So, like, And they, you know, they presumably have some contractual relationship or, like, they literally, like, you know, the origin really is just the capture provider and the issue is the back end of the capture fighter."
  },
  {
    "startTime": "01:16:00",
    "text": "So if the issuer wants to downgrade its value, Then origins to just choose to no longer work with that issuer, and that doesn't diminish the value that other issuers have even if they go through the same tester. So I think from that perspective, you know, it, like, quote unquote works, I think the problem with that is, you know, how do you ensure that many other Attesters can enter the ecosystem, that it is not a situation where you have gatekeepers That's where, you know, Martin's suggestion of, like, you had the identity provider essentially be your attester That's a way to do it I think that's the problem I would like to solve is, like, how do we get Firefox on Linux having an attester that is reasonable. do that, Because if you Then I think it becomes more tractable. Hey, Scott. So I I think what I'm about to suggest actually requires what Tommy's alluding to as a prerequisite. But I I'm wondering if we have A lot of the tools that we need to solve most of this like, almost at our disposal. Like, we have key consistency, which is looking at a part of this how do we make sure that a client isn't getting you serve the unique resources We have metadata, which starts to define, like, what is client's particular animated descent. We now kind of It seems like we need a way to measure the actual vitamin mini size, which is the hard part of this problem. Right, right, right, because there are many ways when you try to build this where you end up with gatekeeper, There are many other ways when you try to build this, we end up with, like, a very centralized entity But if we could push towards something where maybe maybe it's an evolution of key consistency or something else."
  },
  {
    "startTime": "01:18:00",
    "text": "Where we can start to measure the animated reset size. I'm wondering if it does actually a pretty good job of addressing a a lot of these problems. And that's also a very good way of handling more dynamic nature of these public deployments Whereas in the in the private deployments, we can handle this, can handle this by just knowing, you know, exactly what our clients look like and what they do. So think this is an interesting area for us to explore in the future. Like, it's, not an easy space. Certainly, if with the goals that are just up on this screen right now, But but it we could find it to be, quite a productive route. It will require us to define, what are maybe not the exact exact parameters for an acceptable amenity set. But it will start to require us to define, you know, what are the bounds of a reasonable animated new set, which is new work for work for this would Thanks. K, Ben. Sir, I have 2 ideas that I I tend to harp on on this topic, and I'm gonna repeat, Now One of them is The The client's IP address is highly identifying here. And as a result, Any situation where we're really concerned about this privacy, in my view, we also are going to have some kind of transport proxy between the between the client and the origin. And that client that transport proxy is inherently Another entity with this kind of trust relationship. I I have to believe that it is going to make best effort to preserve my privacy here. And not just tell the the destination my IP address somehow. So I think we should consider that you know, maybe we already have an entity in the system that is trusted in this way"
  },
  {
    "startTime": "01:20:01",
    "text": "And we should leverage that then rather than trying to you know, build that same capability independently. The other thing I wanna to propose which is a little bit of an odd buy idea, isn't it? Is Instead of assuming that every issuer potentially leaks we've been calling it a bit of information. That's not quite right. But we've, potentially leaks information about the the user one thing that I when I do that I would like is to be able to have origins essentially attempt to redeem tokens from different issuers and potentially fail Until it succeeds. And then no longer be able to make further requests. So as an origin, I can stack rank all of my all the issuers that I've ever heard of from the ones that are most useful to me as a signal to least useful and walk down that list until I get a positive answer from the user, but I can't combinatorially check which subset of these tokens the user possesses, which might create a fingerprint. K. Watson. So I hesitate to put words in Martin's mouth, but I think a lot of the responses here are sort of missing What I understood to be part of the objection, which is it's not that we don't have a large and aninimities set or a swollen is we don't know the meaning of the bit It could be as innocent as you're on a browser that act does actually operate by a human, it could be a bit that has information where we would consider roadside passing it around and making decisions based on something really bad. So I think from that, In that context, we Nothing we have about, like, the attesters can limit the issuance, especially if you have didn't metadata"
  },
  {
    "startTime": "01:22:02",
    "text": "That poses a real challenge. K, Nick. Oh, you're Steven. Sorry. Think think think So I guess one difference between, like, what we're doing in PSTN and, like, also runs into a lot of the discussion shouldn't have, like, maybe you have like a trusted provider or the, operating system, the browser, things like that, is I think, like, for PS 2, we're trying to enable More generic use cases a way that is more privacy preserving than, like, the existing state of the world, I think, like, if we knew exactly what those use cases are, I think there are a lot more fine grained and, like, directed solutions to the space, even still using privacy pass, but having a, like, more concrete governance structure for those particular use cases, think it's a generic governance structure for, like, supporting wider, less fuzzier things that I think be useful to have, like, some solution that isn't just, like, arbitrary decisions by like, different parties. To Ben's point about I think having a list of issues and walking down them, I think you still reveal a lot of information by the fact that you The presence or absence of a token earlier in that list but like, is a huge amount of entropy of that list is pretty long. I don't know if that's a particularly great solution, at least in that space. K. Now it's Nick. Hey. Just want to, add a little bit of context here. Some of these ideas have works, worksplored in the privacy extension back in the day, including, like, Fido based at the station, which was implemented and deployed, I think, in 2020, as well as an OAuth based based based replacement for the CAPTCHA for the attestation. Which didn't end up working out for privacy reasons, but you may have an opportunity to now that"
  },
  {
    "startTime": "01:24:02",
    "text": "the newer mechanisms that are more privacy preserving exist. So, There were issues with both of those back then and imagine there still will be 2 and the the governance structure, is a is a really important question. K. Tbold? Hi, Timo from Cloudflare, working on the extension, that's actually mentioned. One, so sort of two points, I think, based on, like, Martin's draft is So, like, there's been some discussion, like, on the governance, at least for the the issuers. One thing that exists in current deployments is the governance and the issue that are trusted by clients is like implicit and, like, users, like, don't have a choice quite like able to configure, like, new issues like, be able to, like, disable them. And I think that's something that could be explored down the line as a way to actually, like, and force and, like, provide, like, more transparency in the trust and the issuers. That I'm being made and have some, like, informed choices. Another point regarding, like, the existing deployment models is, like, regarding attesters. Adestas have like, no API defining the current drafts in icing at least exploring the possibility of standardizing on what our testers provides should it be, like, the issue of the trust or, like, some sort of, like, message or bits. That they would assess, could be very, very valuable. To, like, ensure we have, like, a diversity of issuers that would trust these adesters. K, Nick. Yeah. When when these issues have come up in anti fraud."
  },
  {
    "startTime": "01:26:00",
    "text": "Contacts. I've been trying to keep a sort of shorthand list of, properties that I think we should consider. My current list is, rigidity, granularity, Freedom Consultation, and efficacy. I think that grainularity and and rigidity are are perhaps most relevant here. I think Martin and others have made the important point that, well, just having it down to be a single bit doesn't doesn't tell you what that bit is. But I do think it's still pretty significant. It's much easier to abuse a large number than it is a single bit. And, and it might be, and maybe where we should be getting to. It might be easier to accountability that it might be easier to, after the fact, have people evaluating the the system and trying to see if there is abuse. And that, if there are many bits, it might be very hard to ever uncover abuse, whereas, If you just have the a a single bit, but you but you'll use it in in this pathological way, that that we could try to uncover it. But but I also think, rigidity is the other type of protection that that for any system, I think we need to have some way to to make it work even if the user doesn't have the token. And and if we could actually do that. I think it would still be very useful for many of the use cases that we're talking because we're talking about trying to prevent large scale attacks. But but doesn't need to discriminate against individual users. So I I do wonder if we should could be sittering yeah, pre protections against rigidity for things that are low granularity. K, Mark. Let me go back this line that was you? Okay. Yeah. I'm I'm glad that we left it on this slide."
  },
  {
    "startTime": "01:28:02",
    "text": "I I, you know, I think this is the right place to focus, and and I gotta say I'm skeptical goal of the possibility that we here. That that seems like a very tall order. Especially without having the the the the the bad effects on the web. And and so, it was just interesting to me. I was listening to the other comments and and a couple times Consolidation was mentioned by Nick. Earlier there was mentioned in centralization, that reminded me of of something that we put into the centralization RFC a little while back which was when when you have the need to have a point of central centralization when when a protocol requires that, which sometimes happens, and that's legitimate. You really try and leverage an existing point of centralization rather than add a new one. And that takes me to the last line here that, you know, that that is a a interesting thing to try and leverage, especially when it kinda helps you you decide what that bit means. Maybe that's where we should be focusing. K. Tommy? I'm responding to Tommy Polyapple. I'm responding to, Watson's comment earlier which is very good, but I I wanna pause it and, you know, see if people can poke holes are more it. That the anonymity set problem Actually, is or can be related to the meaning of the bit? So, like, again, like, going back to the model, if you have, like, this split a tester issuer, If I as the client, the No. From the attester because I trust it. In this bottle, that many other clients are using it, And that's how I determine my anonymity set. Then I, as a client, also know that the meaning of the bit that anyone's getting out of this is essentially the common denominator between me and anyone else that anonymity said, going through that particular tester, whoever passed that check. And so Like, the fact that I have an an anonymity set"
  },
  {
    "startTime": "01:30:00",
    "text": "means that I have a population that it all get something equivalent, and whatever is common between us, Whatever was being attested to, big big comes the meaning of that bit. From that that particular client's perspective. And then you look at the origins who are redeeming those, Their view of the bit is based on the the set of all of those attesters, then essentially what is the lowest common denominator amongst all of them. So It doesn't quite solve all of it, but I do think we have an entanglement between knowing what our set is in our population is and the meaning of the bit. K. I'm afraid we're out of time. I think this session ends 4:30. So Thank you. I think this is a a good discussion. I think probably we we need to continue to, talk about this. So Thanks, Martin and Steven for, leading us through that. Yeah. There's there's some really There are stints There are certain screens. They're upstream government."
  }
]
