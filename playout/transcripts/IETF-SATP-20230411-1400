[
  {
    "startTime": "00:00:06",
    "text": "okay guys we'll give it a couple more minutes before we kick off just to see if anyone else is going to join us today foreign happy to get off now if if we're comfortable as many people as possible have signed in um we've got 10 in the room so that's fairly um a good number for our group so to start with I'll just run through the agenda quite quickly I've had no requests to"
  },
  {
    "startTime": "00:02:01",
    "text": "update the agenda from the template so it'll be our standard um what's on who's our Note Taker and invite some discussions and updates from the authors and then discussions of items and issues and that have come up in the mailing list I think the main one um I think Rama has been handling um I'm not sure he is um brilliant so Rama I'm probably going to invite you to to talk for a moment or two um on the iso 2022 standards that you've been working on as well as the other elements that have been happening so without further Ado can I nominate can I ask someone to volunteer as Note Taker please I could take notes thank you Alex appreciate that so kicking off then um Thomas would you like to um give us an update on your takeaways from how the working group went last week I look before gosh it's been two weeks so you mean the meeting in Yokohama yes well um I was hoping it would be an uneventful meeting and I think it wasn't an eventful meeting in the sense that there were no shocking revelations or anything like that but but for those who did dial in and and sort of got bored uh the purpose was also to provide some kind of a semi tutorial same explanation to many people who are new to this work and and there were some people in the room who are local Japanese folks who were new to this and that's why I went through the slides that you're you were already familiar with you've seen before um and I think in terms of action items a couple of things stood out uh there was a comment from John Levine about comparing with ISO 200 uh I had I need to set the correct way to 20 220 200 or 20 or something"
  },
  {
    "startTime": "00:04:00",
    "text": "like that uh and um and I think that would be a good idea for us to do anyway because it is a a n ISO standard that's being adopted and deployed widely by the banking Community uh and I think it's it's part of the you know open banking PSD um sort of development that's that's been happening so um I I you know I I know who's going to do that I mean I'm I'm happy to you know to to get help I'm happy to you know look at you know how we compare against uh that ISO 220 standard but I would need um assistance uh let's just say and um I think I don't know where we're gonna put the text but I believe Clarin was I think we thought would put it somewhere in the architecture document AI yeah I think that was what was suggested in the um working group was that they probably lived in the architecture document in terms of um other uh protocols that were out there that we were comparing to and why we feel that the iso 2022s um or however you pronounce it don't quite um cover the elements needed I think um forgive me if I'm wrong I'm thinking even Raphael or Rama have started that conversation and I know John's gone back on some of it great great thank you thank you that was that I was hoping that that we've already started discussion and I I I do know some people you know even you know on this call today you know at least their companies have people who are you know participating or even using that standard so that's it's a it's a good sort of you know Community to to answer the question um I think the other own the only other thing um is that I need to fix a typo in the message flow uh diagram I think this the"
  },
  {
    "startTime": "00:06:00",
    "text": "misnumbering I think two point step 2.3 2.4 needs to be relabeled but but that's kind of about it and I will do that today and upload it as version 17 of the message flow diagram okay that that's uh that's uh that's I what that's what I jotted down in my notes as as to do did I miss anything uh Claire was or folks no I think that was the main sort of takeaway I know we had um a fairly quiet session but we did have some new faces in the room which was which is quite um encouraging um I know that a lot of people struggle to make it due to the time zone difference so so thank you to those that could um did anyone have any questions about how the Yokohama working group went um or anything they wanted to add to the agenda I know we've had something um come through in the last 20 minutes and which of course we can we can come to in the end um from Rama so we can absolutely get around to that if we've got time anyone else have any um agenda knits to add um I guess so the only other thing on the Yokohama uh meeting was I guess what was the General reception um you you mentioned that okay people mentioned that we should compare with ISO 20022 but anything else in terms of was it was it positive did people understand the problem space I I had a you know private afterwards I met I met some folks um you know who are who were they when one person was there and and another person was from a different company but uh they are interested so so there's a bigger picture going on that's been going on for the last two years which is that you've heard all this news about um different um governments trying out you know exploring cbdc and cbdc networks but"
  },
  {
    "startTime": "00:08:01",
    "text": "there are several efforts that are trying to do multi-cbdc Network so what that means is that you have a like a DLP um that actually has multiple you know Fiat backed uh currency tokens you know running you know and it's a it's a private permission network of course needless to say so so some folks in Japan are looking at you know exploring that and the question I had as well like how does how does satp work there uh can um you know can you move an asset from you know one network to another and what would be the use case for this because because it's now um it's not like tokenized physical assets it is now um you know something like a like a currency a government-issued currency and and my my quick answer to that was that yes you know we could we secretly could do that and I think I was emailing Rama earlier that I would like to add a use case or sub-use case of the cbdc section in the use cases document to explain how this multi-cbdc could be addressed using satp hmm yeah I think uh Raphael had a paper on cbdc um in the context of satp or other satp in the context of cbdc's but yeah yeah sounds like a good use case to put in definitely Dennis we've got your hand up hello hello everyone uh yes I mean if we brought a bit the picture of that Thomas was just explaining maybe the case that we have fungible tokens both sides that are exchanged it's something that probably we should have a look at because we assume or maybe it's my understanding that in the flow diagram"
  },
  {
    "startTime": "00:10:00",
    "text": "that we have now in version 17. we have like creating and destroying assets which is okay for a non-fungible but we should probably see if there is some difference in case that we have non-fungible fungible assets sorry in The Exchange absolutely I think this speaks to sort of the the overarching scope in that our solution should be agnostic to whichever assets are being transferred so it's definitely worth making sure that any solution that we've come up with in the solution we have so far is applicable and it's definitely something we should probably check off um thank you for that Dennis then this is agreeing for review the the text thank you Dennis yeah um no problem that does bring me on to something else that was part of the agenda in the working group and I don't know how many people have been able to read the minutes um and some of the takeaways and one of those takeaways um Wes and I will send a communicator to the the working group to the mailing list regardless was to have a discussion we had a we had a vote in the room um which came away positive in terms of are the documents as is um ready for adoption now adoption for those that don't know means that as a working group we agree that the documents we have listed so far are the right starting point to take through the ITF process in terms of having it all approved having it peer-reviewed and then ultimately um agreed published and deployed so um we will put that on the mailing list so if I could ask everyone to come back and put a vote on that um we can then take our current um working documents and have them as official working group documents which is part one of the process which is part of if you want to have a look if you go on to the data tracker I think the um"
  },
  {
    "startTime": "00:12:00",
    "text": "agenda slides are still up there so you can have a look there's a there's a flow back sort of a process chart in terms of how documents are moved through the process and what steps they need to go through so there's a point of discussion um does has everyone read the documents are they all comfortable with the documents is there anything that people want to call out now um that would in their minds prevent the documents from being adopted as a starting point as is what's up um yeah so with the documents we uh I think a few weeks ago we talked about this vocabulary document that um Dennis and I have been contributing to and also Thomas and Rama um it's currently just on GitHub do we want to make it an official document as part of our I guess folder so we can upload it on the ITF website and included alongside the drafts or are we okay with just having it as an informal uh page on GitHub yeah so the working group does have an official repository which is a good place to store documents and we can have the repository moved there and then uh once it's typically we do that after it's accepted as a as a working document so Claire and I will start that call you know if the official call after the meeting ends and it'll take you know two weeks and we'll ask for input on the working group mainly list and I'm sure it'll be accepted but you know officially we go through a two-week process of of making sure everybody agrees that this is the right direction for the working group to go and these are the right starting documents and yada yada and then um yeah we can move that GitHub repository to the official working group one is definitely the right thing to do okay thanks Wes"
  },
  {
    "startTime": "00:14:06",
    "text": "awesome so if I go back to the agenda um if there are no further updates and discussions from the authors um happy to move on to the um item that Rama uh mentioned in the mailing list uh maybe maybe I can step up quickly yes please um updating the uh or suggesting some updates to core regarding error messages I think it would be useful to her for us to have a discussion on that um currently the suggested updates are on GitHub and I've shared them on the mailing list okay would you like to lead the discussion now or was that discussion you'd like to have on the mailing list I think we can take it to the mailing list yep if that's if that's how you would prefer to have the discussion absolutely would you be okay summarizing that the comment about the error messages just so they were all on the same page yeah so so the the idea is for us to come up with an error schema for all the messages that's a set B defines such that in case of failure the gateways can employ an error handling protocol currently we are only handling success cases and we want to handle errors as well so that that's essentially it I think that would be very variable that was a comment that was made in the working group I believe I can't remember who made it but there was a comment made about um what happens if it goes wrong so that might make it that would fit quite nicely thank you yep"
  },
  {
    "startTime": "00:16:03",
    "text": "well happy to hand over control then to Rama if you'd like to share your screen Rama so uh it's actually going to be Bishop who's also on the call who will present but just before uh we turn to that topic uh since you asked about the comparison to ISO 2002 uh I saw that um uh Thomas and John had an uh a short Email exchange and uh I I do plan to write something more substantial on the email on the mailing list at some point just haven't had the time since the working group but I will definitely do so so I replied to Wes after that after the meeting uh the main uh I think the high level takeaways that uh the iso 2002 is a it offers a standard standardized messaging format um now the semantics of those messages don't really cover the semantics that we wish to achieve with satp which is the extinguishing of an asset from uh in one network and the recreation of a of a basically a replica another so the message is in ISO 2002 are really um promises uh so in a sense they they serve a valuable purpose and we definitely need to compare with them but uh I think the this uh the difference between uh the iso 2002's goals and satp's goals are quite clear but anyway I'll write something more substantial in the mailing list sometime soon uh so what uh the item that I wanted to uh bring up in today's meeting was there's a paper that uh we wrote uh that was accepted at ndss uh 2023 that was held in San Diego about a month ago and the topic of the paper was a new kind of uh privacy preserving cryptographic mechanism which uh the need for which"
  },
  {
    "startTime": "00:18:01",
    "text": "grew out of our the research we've been doing in interoperability specifically how to uh permission networks can um establish a trust basis with each other given that they are completely opaque to each other and using uh decentralized identity infrastructure um so from that we we got to thinking about whether when two parties have a bunch of different uh certificates from different certificate authorities they they cannot private common at some common notion of trust if they know who their common certifying authorities are their common certificate authorities are but if they reveal anything more that might lead to a privacy violation so can we devise a cryptographic mechanism reveals only what's the in the intersection and nothing outside that'd be great so we think this can be applied to a lot of different things including the kind of problems that this group has been talking about satp and also the uh the view exchanges that have brought up uh as you all know so uh alternative to bishoc I think we can he can cover this uh within 15-20 minutes so we have a short version of the presentation more detail ah so Raphael check out the I uh posted the link on the mailing list just check it out thank you I can put the link here as well perfect thank you okay bye everyone hello so uh I will try to share my screen and see if that works first"
  },
  {
    "startTime": "00:20:09",
    "text": "can you see my screen the screen share is being started and if anyone else has got a different View s okay I will try again is it invisible now no this can you share the maybe share the full screen I don't know uh can you see it or is it still we have some problems the last time it was right does anybody remember how we solved the problem I think that was when there was a multiple strange happening at the same"
  },
  {
    "startTime": "00:22:01",
    "text": "time which we don't seem to be having now whereas do you know why we're struggling to share the screen oh there we go we've got it okay okay uh so yeah hello everyone so uh sorry for that so the paper Rafael the the title of the paper is uh private certified intersection and this got published in ndss conference this year so the idea of the paper as Rama mentioned is to uh find out a common certified between two parties uh in a privacy preserving way so to give give you an idea about how this can be useful let us go through one scenario so uh let us say that there are two companies say A supplier and a distributor S1 and SQL and these two businesses might need to collaborate cooperate on in something suppose S1 needs X and maybe S2 has that and vice versa is one might be able to supply something to S2 so ah looks like that the this can be a basis of a business relationship between them and they can strike a deal uh but the point is that uh what if one of the companies defrauds the other so and if associating with the other companies at all a good idea so that is the that is often the question that they face so uh so the way this question can be answered is by finding out if there is somebody who trusts one company and that that entity"
  },
  {
    "startTime": "00:24:01",
    "text": "is also trusted by the other company so is somebody associated with us also associated with them if the answer is yes then the deal sounds safe enough uh if no then so in in such a scenario the objective is to find a common entity uh who is trusted by both of them so here for example in this case there there might be some common entities like that so suppose government agency B is a body who is trusted by both of them but they need to find out that that indeed uh that is there is some entity common entity and we call this common entire trust anchor so this fine after finding out such common trust anchors the task basis for the deals can be uh established but only if these common trust anchors are revealed but while determining such common trust anchors it might happen that some other organizations such as say a political party aim who is trusted by S1 but not by S2 is also revealed so by revealing such crafted entities who might not be rusted by the other company or other organization it can cause a privacy breach so if a different certifier will was revealed then the deal may fall through or even worse a company might get some business Advantage by getting to know some of the private contacts of the other company so we can see that finding out such common trust tankers in a privacy Visa being way is a really important objective here so if you think about the broader objective of decentralized identity management in the context of"
  },
  {
    "startTime": "00:26:00",
    "text": "the wave 3. so the idea of decentralized identifiers and verifiable credentials are already getting popular so these two are the w3c recommendations and deeds or decentralized identifiers lets users create own and control their own identifiers but Deeds are not by default or by Design connected to any real world identity instead what can be used are verifiable credentials which are digital credentials which can be issued to bits and these credentials make claims about the deed holder and these claims these credential can be selectively exposed through a verifiable presentation process so there are issuers who issue verifiable credentials and holders who hold them and then the holders can selectively present certain credentials to verifiers but there is a problem in this entire process so suppose S1 wants to present a readable credential to S2 so this particular verifiable credential would have been issued by certain issue right so the issuad is the certifier who is certifying a certain Claim about S1 and S1 is presenting that claim to S2 uh so while doing so uh S1 is inherently revealing in in the process the processing is inherently exposing the issue of this particular verifiable credential so the certified is revealed as well as the clay and vice versa in the other way around also it will happen so whoever is presenting a verifiable credential first uh ends up revealing the certified so uh there is an intrinsic asymmetry in this procedure where whoever is presenting fast will end up losing privacy and our objective in this paper is to uh is privacy preserving symmetric"
  },
  {
    "startTime": "00:28:01",
    "text": "exposure of certifiers as well as certificates so we we try to answer this question that can parties owning certificates uh can parties owning certificates efficiently identify a common set of certifiers without leaking anything else so there are two parties and they have certain certificate so P1 and P2 are the two parties P1 has some certificates from different certifiers and P2 has some other certificates from other certifieds so the objective is to efficiently identify a common set of certifiers such that these certificates issued by those artifiers attaching to some Claim about the party is valid so the certificate has to be valid so PCI or private certified intersection we call the solution to this problem as private certified intersection uh allows two or more parties to identify a common set of certifiers while validating the certificates without leaking any information about the certifiers which are not in the output intersection so for example in this case certified D certified C which are not in common between the two parties is not rebuilt okay and uh we follow a trade model that participants can be malicious and they can tend to lie about their certificate authorities basically their inputs and they might want to deviate from the protocol that we propose and the additional goal is of course the protocol must be efficient enough to be used in practice uh so there are existing cryptographic Concepts such as private set intersection or PSI which is something similar which computes the uh intersection of uh two input sets without revealing the elements which are not there in the intersection so but PCI is something different to psi so if we think uh if you try to answer this"
  },
  {
    "startTime": "00:30:01",
    "text": "question can PCI use PSI as a building block then we will find out that it will only work if the parties are semi honest and not actually malicious if the parties are malicious then PSI using PSI as a black box will not work because private set intersection does not or is not sufficient enough to check the validity of the certificates and uh one what one party can do in that case is just input some invalid certificates from all possible certified signals and certifiers are often well-known entities so even if it did not have certificates from all those well-known entities it can put invalid certificates and PSIs incapable of validating those certificates uh so I will just brief over these terms so we came up with three variants of PCI protocol PCI any PCI any DC and PCI all so the main difference is uh a certificate can be on top of one claim or multiple claims so uh how do we uh so we we in some use cases we might want to validate one claim in some use cases we might want to validate all all the things so PCI any finds out common certifiers which at least at least one Claim about the parties whereas PCI all a test finds out common certifiers which attests all public claims about the parties and PCI any DC is same as PCI any but here the claims are actually revealed while running PCI so the values of this those claims are revealed but the value of the but the identity of the certifiers which are not there in the intersection is not ready so the certifiers Privacy is there uh so uh these are some of the key"
  },
  {
    "startTime": "00:32:01",
    "text": "contributions that we came up these are all technical contributions of the paper so uh we introduced a formal definition of PCI in the simplified usable composibility framework which enables using PCR building block for larger applications in a composable manner so if you can think of any application which needs the functionality of PCI where two parties need to find out a common certified without revealing the identities of their other certifiers which are not in common then PCI can be used and the definitions prove that it it can be used in a secure way and then we propose two practical efficient PCI protocol solutions for PCR using uh ecdsa signature schema and bla signal scheme so ecds is of course a very popular standard and BLS is now popular in many blockchain applications so in order to achieve these particular implementations we had a major contribution which is extending the speeds secret sharing protocol for elliptical pairing operations so I will just skip these parts uh we implemented two-party protocols for two-party PCR protocols for ecdsa as well as BLS certificates uh we also show that in in the paper that these two party protocols where two parties find out their common certifiers can be extended to in party scenario so in a multi-party PCI more than two participants would find out the common certifier between them without revealing the uh ones which are not in common uh so this is the overall flow of how PCI works so there are two parties and they have certain claims claim a b and then the these claims are attested by"
  },
  {
    "startTime": "00:34:02",
    "text": "different certifiers certified a certificate B here and similarly in this end also certific so from the input State we can see that this is certified a is common between them and there there are multiple claims involved so I am going to going through a simplified overview of the PCI all protocol which actually validates all the claims from these two parties so what happens is in PCI all the first step is to aggregate signatures from a certifier over all the games so this is only possible uh with BLS signature scheme where we use bla signature aggregation so these input sets are then reduced to one input for one Unix certifier and then this goes as an input to the MPC protocol which is an extension of MP speeds which is an implementation of the speeds protocol so here uh what the MPC protocol does is it actually checks the it validates the signatures input signatures the aggregated input signatures and only if the signatures are valid then the certifiers are matched and only the intersection which is the set of common certifiers is revealed uh outside the MPC box so the MPS outputs the common certifiers and no information about the other certified so in this case certificate C from second party and certified B from the first party rdb and to analyze the feasibility of using PCI in practice we actually deployed on implementation in uh in a global setups where we deployed our PCI instances in a PCI protocol in AWS instances and the instances are also fairly small so eight core CPU and 8GB"
  },
  {
    "startTime": "00:36:02",
    "text": "Ram which is near about what what commodity Hardware these days are and we deployed a parties placed in three data centers across two continents one in West Coast one in east coast and another one in India and we can see that uh for a growing number of certifiers the time taken to compute the intersection is actually fairly large in terms of second so it takes for a number of so for example here the number of artifacts is 100 and we can see that it takes 50 seconds or so so and if the latency is large so for example in case of when where one party is in U.S based post one parties in East Coast it takes 100 seconds but still it is usable in practice and maybe it can be further optimized further to reduce the overall time but we can see that with the changing number of claims so if the number of claims are increased then the BLS implementation of pcis are unaffected by the number of change in a number of claims in the inputs so if the number of claims grows from 1 to 100 the ecdsa implementation uh gets worse but for the BLS pciology stays consistent because of that signature aggregation optimized and that we did and similar Trends are there for the overhead so these are the communication bandwidths used for computing PCI for 100 certificates and changing number of claims and this is the memory consumption so from the memory you can see that it can be used in commodity hardware and the bandwidth is also reasonable so uh in context of the interoperability work that we were doing in Weaver so if so we were trying to"
  },
  {
    "startTime": "00:38:02",
    "text": "make two separated blockchain networks allowed to separate blockchain networks Swap and transfer assets and share Ledger data with authenticity proofs so this private private blockchain interoperability actually relies on the ability to prove and verify claims about Ledger States and consensus which then relies on the ability to verify the authenticity of signatures which are generated through the consensus process in each of these blockchain Networks so uh we came up uh with a two layer architecture where one layer is concerned about the transfer of assets and data from one blockchain network to another and we're validating those proofs but that depends on the identity layer which is concerned about uh thinking the identity information of the foreign networks so the keys and certificates on the basis of which the signatures can be validated and that then relies on the deed and verifiable credential specifications but thinking foreign Network information requires in a trusted way requires the presence of a common certifier and here the role of PCI is evident so in the identity plane PCI can be used to determine that common certifier in between the two blockchain networks in a privacy preserving way where the both the blockchain networks don't need to actually expose this its entire list of certifiers so there can be of course many future directions like implementing multi-party PCI and optimizing it further and then supporting many more signature schemes such as BBS plus Etc uh so yeah this was the overall uh"
  },
  {
    "startTime": "00:40:00",
    "text": "description of the paper and PCI and if you have any questions or if you have any thoughts on how this could be uh useful in practice in different projects so I guess Thomas has some questions yeah Thomas has a couple of questions I think uh just broadly thanks Bishop's a great presentation uh I was trying to think through Thomas questions but uh overall uh the the main role that at least we envisioned and which is where uh the the motivation for PC actually sprung originally was how do we get uh different networks especially of the permission variety to be able to uh discover and make first contact with each other so we uh we feel this has a role to play in the discovery part of it and just trying to read through the question so who can be the best issuers and Gary owners be issuers potentially I mean we'll have to think about that uh I think in our case the issuers when you're talking about issuers they are the issues of certificates so the certificates uh are being issued by entities that are actually external to uh the the the ledgers on which the assets are being maintained so the sort of neutral third parties in a sense um I don't see any reason why Gators cannot be uh is sure but you have to think through the plus model so so it's it's back to the original um VC model oh thanks be track that's an interesting presentation so so the the in the VC model an issuer says that Thomas owns this this asset in this network right and if it's if it's a private Network yeah"
  },
  {
    "startTime": "00:42:02",
    "text": "and so you know the issue could be a third party it could be a Gateway owner that says based on my reading of the you know network data yes this this person claiming to hold this you know address indeed holds you know this asset but but the the the question a you know bishak and Rama the idea is that you know I'd like to tell the world I've got this asset without revealing my identity yes and then come to this come to this network if you want to buy it yeah I think that'd be a great application I think it's in fact something that we should uh properly apply uh the protocol to and see what what we need to do to make sure to make that happen yeah great thanks for that uh Thomas that's where you want to go with this awesome well thank you so much for um the presentation and for sharing that Insight with us um can I ask in terms of context of the satp scope that we have currently um where you see this sitting is there something that um you're packing as as a potential kind of future road to investigate um or was this sort of a more kind of helping people inform their thinking just so I can understand the context of this just so that research in the context of the satp scope yeah it's more towards the latter I think this is something that uh because satp is uh you know we make a lot we lied a lot of issues like uh what is what exactly is the legal status of the gateways and so on right so satp is focused on a on a small portion of the uh of the asset pipeline uh when it comes to cross network uh interactions so this is something which we are we yeah we just want to inform the community about that there is research here and we have we come up with a novel"
  },
  {
    "startTime": "00:44:02",
    "text": "mechanism to achieve a particular goal and uh we may find it useful in the future yeah that's that's really easy I think Thomas has um put in the chat some ideas of how that could support our current satp goals so in terms of the the issue of the excitation going into the BC data structure um and again we can obviously use that to inform our thinking about how we might approach this moving forward would you say that the um approach that you presented um which was it was really in-depth so thank you again um was something that would be agnostic across any network type or was that be something that would be specific to Gateway to sort of blockchain gateway to Gateway no it we're trying to make it agnostic the only thing is uh I think they will have to um yeah they'll have to follow the existing uh cryptographic protocols and use well-known uh certificate formats so uh Bishop alluded it to an extension in the final slide about future work so we're trying to extend this to see uh to fit to verifiable credentials which are being standardized in the WCC so uh if we if you achieve that then we'll have a larger range of credentials uh that that can support this protocol but then again the the gate is you need to confirm to those standards the gateways you need to confirm to the WCC recommendations thank you yeah what Dennis said uh yeah that's true I mean it it is I mean we should not think like it is tied to dids or verifiable credentials the protocol itself is applicable wherever digital signature based credentials are involved and where we want the"
  },
  {
    "startTime": "00:46:00",
    "text": "signer we want to parties to determine the signal without revealing the entire list of signers of their credentials so uh we don't need to actually adopt uh the IDS for issuers but uh the if the if you are thinking that the issuers are signing credentials with digital signatures and of course the issuers would have their public keys and private keys and uh PCI would find out the intersection of the public keys of the issuers without revealing all of the issues so just to clarify uh then I think uh if one side is using dids and VCS then I guess the other side will also need to comply with the the same effect but otherwise what Bishop said uh you know it's more General in scope than this yeah correct so so in your view do you think that uh gateways could be issuers or it's not I don't think so but I mean just to make sure sorry Dennis who are you asking that question to yeah I mean to Rama sorry uh so in my view um issues may not be gateways so there is no direct link between gateways and issues right foreign [Music] no I mean the issuers uh if you're talking about certificate issuers they are supposed to be external uh to the uh to the asset majors yeah good yeah okay that's what I thought yeah wonderful thank you um I'd really like to say I would be interesting to see kind of the the suggested proposals for text in the documentations um that stem from that research in terms of how we might apply that for the satp um so thank you um with that in mind we've got a lot of minutes left left sorry"
  },
  {
    "startTime": "00:48:01",
    "text": "um it's the end of a long day after bank holiday weekend here so to the end of the day um is there any to bring up mention or feel they haven't had chance to cover off um whether in relation to to the presentation we've just had or anything else that we've talked about today one quick point for me actually yeah if you guys wouldn't mind sending a link to the slides to your presentation too or I don't think the ndss uh videos are recorded yet too but or published yet but that would be fantastic to send that to the mailing list as well some people find slides easier to read than an academic paper actually there is also a YouTube video that uh I will share the link I will post the link to that video on these great thank you very much Dennis you have your hand up one issue that I mean one thing that was related to the previous discussion item about error messages I was planning also to send out and I will do just after our meeting or on the the comment from Raphael I believe that in order to be exhaustive we should discuss I mean maybe model the S the city protocol using uh something which is not an instance diagram like the flow that we have here but more like a state modification diagram that captures all the different possible states of a Gateway that way we would be able to be exhaustive also in our error cases and eventually all they're all back cases as well um this is something that there was you know trying to make my from time to time I come back to that but I believe that in order to make sure that we don't forget any cases we should turn our modeling to State charts rather than instance flow diagrams but maybe that's just me I don't know what you think about that as a group"
  },
  {
    "startTime": "00:50:03",
    "text": "foreign would be useful um and Raphael is asking what type of model would we use for that any I mean we could use uml uh State diagrams or anything that is more formal than a normal flow the flowchart things but I mean it's up to you decide that would you know rather go with the state charts because they have some theory behind in the uml state charts but can that that's me I think that would be very useful to exhaust the State space in our protocol which we I think still don't have a very clear Vision on what can go wrong so that that seems like a good idea let's follow up on that so I'll post something on the uh on the group and then we can eventually see if we can have like a small subgroup um to do that if you want I don't know what would be your your views yeah a quick comment on that I mean uh the yeah I think some kind of an analysis would be very good I don't know if you need to be too formal about this uh we have two sides right and then you have they can be in one of it seems three states maybe more if we take into account errors we just need to I think pair them right and then we if we can can enumerate them should be a pretty short enumeration and then we can analyze them I think um uh but if you want to do a really formal analysis uh uh I don't know if the I mean we've been as Bishop mentioned we use the universal composibility framework for the for this protocol and we are trying to do apply that to other security protocols too so maybe that"
  },
  {
    "startTime": "00:52:01",
    "text": "could be useful yeah why not we can start uh the the discussion and then whatever uh you know suggestion that can improve that yeah will be really cool yeah that's that's a good idea because um yeah for sad core yeah we need a you know list of possible errors that error message numbers to be shown in the you know in the document um so yeah yeah and I think we need to to get there I think we need to understand like all possible you know States and so having some kind of a state picture you know would be would be useful thanks brilliant um so have we got that action captured Alex in terms of of starting a new conversation and we'll check it okay um anything else in the last seven minutes at all okay well I'm happy to call it there thank you everyone for coming along and the um contribution to the discussion it was a really good meeting um Alex I'm sure we'll send the notes out in um a short period of time and we will share with you and upload to uh data tracker for um oh we've got one more chat panels on it oh thank you Thomas okay cheers everyone and we will speak officially in a month's time obviously um we'll be using the mailing list between now and then to capture the decisions around adopting the papers and the new conversation about State diagram for the gateways thank you very much speak to them foreign"
  }
]
