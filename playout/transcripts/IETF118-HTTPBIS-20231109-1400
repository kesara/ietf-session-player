[
  {
    "startTime": "00:00:25",
    "text": "Tommy. Okay. Okay. This is HTTP. My name is Mark Nottingham. I'm my cochair, Tommy Policy, Don't tell him. Back. Okay. That was a different session, I guess. Tell me, Pauline. Is elsewhere. He'll be back soon. Oh, of course. You do. Good start. Good start. Okay. So, we have 2 sessions, one today and 1 tomorrow. Oh, let me open the right folder. There we go. Today, we're gonna start by discussing active draft So, compression dictionary transport, cookies, unprompted auth query, and retrofit. And then we have one other proposal or presentation about Cupac Steck table version TLS extension. And then tomorrow, we'll go back into active drafts with resumable uploads. Template to connect TCP cash groups. And then we have, a whole bunch of other topics tomorrow afternoon. Any agenda bashing. Okay. Don't have it on the screen, but hopefully by this part of the week, you're familiar with the IATF note well. Is the terms under which we all displayed here regarding things like intellectual property,"
  },
  {
    "startTime": "00:02:00",
    "text": "and harassment policies. We do take this seriously. So, please, if you're not familiar with it, look up IETF Netwell on your favorite Internet search engine. And finally, with the administrative work, we need to find a scribe for this session. Would anyone volunteer to do so? And, if you're looking at me right now, you're you're at risk. So, Mike, you you looked away. You're very lucky. Anyone. Look at all those faces. Oh, thank you so much. So there's a link in the agenda. And on the data tracker to a bark down environment if you could take notes there and, especially capture decisions and, the major points of discussion that would be much appreciated. And if folks wanna help out there, please do. Excuse me. So first up, we have Compression Dictionary Transport. And I believe this is Patrick, who's remote. Patrick, are you with us? Yes. I am. Well, let me get your slides up. No. That's not how you do that. Okay. Do you wanna request the presentation or shall I, Patrick? Yeah. I I mean, I requested Okay. I need to do something else to request I'd requested the slide share. Let's see. I think print preloaded slides. Okay. Ahead, Patrick. Alrighty. So just a a quick recap on what compression dictionary transport is. Basic flow is any HTTP response can advertise that is to be used as a dictionary for future requests. For compression specifically. It provides a wildcard based path matching, for the the URLs that are same origin that it will"
  },
  {
    "startTime": "00:04:02",
    "text": "apply for as a dictionary and the time to live for the dictionary to be viable for in the client. When the client at a future time makes a request, with a URL for a path that matches a path that it has spec for that has a dictionary, it will attach a available dictionary head or request header with a shot 256 hash of the dictionary contents as well as add the dictionary based, encodings to the accepting coding in, in this case, it's brought me in Z standard. So BR dash D and Zsc tdashd, for the dictionary variance of both of those. And if the origin or whatever the client is talking to, has a version of with the dictionary or is able to compress the response with the requested dictionary. The server will attach a hash the same hash. Of the the dictionary that was used and the content dictionary response header, which encoding it picked. In this case, Z standard with dictionary, and it will vary the response, based on the accepting coding and available dictionary headers to make sure we don't get invalid responses being sent to different clients, from caches. That's sort of where things are now in the draft as we've discussed it since I IETF117. There have been a a fair number of questions, issues, and stuff in the the spec in the GitHub repository. And so there's a few changes that are in flight as PRs that we'd like to talked about And so the first one is the the request matching the wildcard based path matching"
  },
  {
    "startTime": "00:06:00",
    "text": "there's been a request on the the client side to replace the custom wildcard, implementation with hurdle pattern, which is now a, what WG spec that at least on the browser side, they're moving towards anything that does URL pattern matching, to use URL pattern. So we have a consistent way to spec them. And to split the match into a path component and a search slash query pant prem's component, which would be optional in default to, wild cards to match all for the search. What those keys are is certainly up for debate. Happy for shorter names with, like, just match being the path and match search or something like that for the optional one. But splitting it provides more deterministic construction of the URL pattern rather than trying to imply it from a given strength and trying to decode which are special characters, which are not. And if it should extend into the search or not, the other one that we've added or we'd like to add is match desk, to match on a destination fetch destination specifically if the client supports it. So you could do something like have an HTML specific dictionary that applies to your whole site, you could specify a match path that's like slash star with a destination equals document and not have that same dictionary be sent for of the image requests and anything else that doesn't have a a different dictionary that applies to it. Not that it would be any harm to send it if the the origin didn't send it, support it as a response for that type, but it just makes it easier to do things like like wide HTML dictionaries. And then on the, variations we're varying based on the"
  },
  {
    "startTime": "00:08:01",
    "text": "the the requested dictionary and the acceptance coding there's a chance for blowing things out. For caches pretty significantly, especially with the old default of a 1 year time to live on the dictionaries. If you've got something that's revving versions of, like, a JS Library multiple times a day. You're gonna end up with cases where you'll have thousands of cash, partitions. So talking about reducing the default CTL to be 7 days since last set. So since last a request was made for a response that is to be used as a dictionary, not since it was last access to be used as a client dictionary. So you'll have it at worst case, a 7 day window after you last use that resource on your site. That it'll be available in the client. And to reduce very variations in the accept and coding, we're opposing sorting the The Woah. Percalls, the the the codex, if you would, so that they're consistent from client client, for clients that support the same encodings and for the dictionary versions of C Standard and Broadly to also require that they include support for the non dictionary versions just to reduce the number of permutations. Of possible accepting coding strings. Won't completely eliminate that you're gonna have clients that support different encoders than other clients, but for clients that support the same encodings. Hopefully, it results in similar accepting coding strains. And those are largely all of the issues that have come up and that are for discussions. So time to bike shed, which is what we mostly wanted to do here and see how people felt about the changes if there were other concerns."
  },
  {
    "startTime": "00:10:11",
    "text": "Mike Bishop. I see why you I see why one might want to sort the accepting coatings just to reduce to reduce variation and this one one less fingerprinting surface. I'm not clear why this draft would be the place for that. This draft is defining a new content and coding. Yeah. I mean, the the main reason we have it here is because this draft is including 2 new encodons. Which is going to widely increase the number variations. And so we were hoping rather than require all clients to always sort the encoding. Any clients that support dictionaries at least will have to support the encodings, but I'm happy for to not be part of this spec either. It's just since we're introducing new variations, I was hoping where I was thinking we should at least take some responsibility for reducing pain those variations cause. Yeah. It just it seems like beyond the But similar token. I understand the desire to have the fallback, and maybe that would be a good explanation. I don't really see a reason it has to be normative. If you don't have the dictionary, you just can't do that one. I I think there's none registered participant here. Yes. Timothy. Timothy, you remote. Does"
  },
  {
    "startTime": "00:12:01",
    "text": "I don't think I have anything I can do here to Last chance, Timothy, if you Press the button to Okay. Timothy, I'm gonna I'm gonna de queue you if you, if you can fix that, please, yourself back in queue if that's alright. Okay. So I put myself in queue next. Regarding the sorting of the accepting coding, I'm concerned about that because it's leaning into cash as treating accepting coding like string when it's doing very processing, and that's the wrong approach here. You know, cashes already have the ability to understand and and evaluate and and and normalize the cement based on the semantics that had and they should be doing that. I'm aware based on my testing that many don't I see that as an implementation problem. And I, I don't think we should be encouraging, this behavior because it's frankly broken. I'm not sure what you mean by Z Standard D must include C standard. If that's a if that's saying that you can emit z standard when c standard d is present. At Hello. The way around. Okay. I can repeat it. It's okay. Mike said the other way around. At least Correct me if I'm wrong, but my understanding of that is If you support Zscattered with a dictionary, you must also advertise or for Z standard without a ticket. Correct. Yeah. We're trying to avoid introducing, like, 16 new possible permutations instead of just two. Right. But but but someone who isn't aware of this, you know, an implementation that's not aware of this is gonna be less efficient as a result potentially, although Z standard isn't widely employed. So maybe that's okay. A little more concerned about the Broadway 1, I suppose. And and then reduced in the default TTL to 7 days. I know you have an open about the cash lifetime and time of the cash lifetime."
  },
  {
    "startTime": "00:14:00",
    "text": "Maybe that's worth exploring. Mean, in general, you, you said, you know, you're trying to avoid a cash having thousands of of entries. Appropriately implemented HTTP cash at least won't have that problem. It'll it'll you know, you know, to expiration, it'll, it'll, it'll, optimized based on its space constraints. So I I I This just seems a little preemptive, to solve the implementation problems and caches. I'm a little concerned about doing credit call Yeah. I mean, there's a a TTL that's set up on the use of dictionary response header And so it's really just about what is the default if it's not specified. And what's reasonable, for a dictionary where dictionaries are generally gonna be more useful for reengagements within the site. And so anything is arbitrarily fine. A year was leaning heavily onto the try and encourage as much dictionary use as possible 7 days is leaning more towards encourage dictionaries for a frequent users more so than, rare users. K. Could you go to your previous line? Flip. So with request matching, I I just had a couple of questions around that. I understand it, Earl pattern, uses some characters to denote you know, variables or whatever. That are valid characters in URI. So what's the approach to being able to to address all possible URIs, if you're using your portal pattern So as far as I'm aware, other than the the wild card. So there are believe Earl pattern has escaping built in for the the characters that are special for used when defining a neural pattern, but are still representable. Okay."
  },
  {
    "startTime": "00:16:01",
    "text": "And and my other Yes. We are specifying specifically that regex isn't supported, and Earl pattern has a way to specify that. Okay. Good. That actually goes to my next question, which was, you know, if this needs to be or or see it will be deployed where an intermediary needs to be able to evaluate this. You know, there's some efficiency concerns with stuff like projects. But as well as potential attacks. So that that sounds promising Thanks. Next up, it's Vlad. Hello? And also mentioned on mail and list that it would be nice, maybe to have an option to to to to Let's just give the hash. Yeah. Sure. Will the URL meet that? Just because from my perspective, is it and junior who was healed in call. I would like to would luness award, is we already have Mac is fedge dictionary Fitch, something based on URL and meet that. And yielding machinery, to find resources based on their hash is, like, Volvex to war and also reduces the scope. We could launch this possibly very Big change. Is Like, obviously, if it's a pretty shared dictionary, yes, wanna great waiver, for something dynamic for the less origin, involvement, you know, they have an option, maybe. To say, you know, if you wanna to use this dictionary because Yeah. I was trying to think of exactly how we do that. And so the one to one to a dictionary. And so we could have a client's when you the Right. But when you"
  },
  {
    "startTime": "00:18:02",
    "text": "when you supply when you supply the dictionary hash, you supply the URL that the hash always already went with, that might help, but you still need to verify that your current version of what is that that URL matches the hash of what is Oh, that's easy. Being requested. So I could see adding to the request, the the URL on the user's dictionary response, I'm having trouble coming up with a way that would be easy to deploy for origins, maybe something which is optional. No. No. Origins store is different. Like, if we're a cash for an origin, that's fine using the shop. Because that makes it just very I'm saying Most of our users, No one I think Right. And I'm now I'm just if You do it for them. On the user's dictionary response, is this where you'd want to have the hash of the dictionary as well so you could know to store it, with the hash Well, no. That's not this. Okay. So but you still have to validate 1st Right. It Yeah. But it could at least let you know 4 do a quick look up to see if you've already got this hash in cash than you do or do not have to do anything with this response and you can just pass it through, or do you have to evaluate storing it or not? Yeah. That's also that's long as we've got a URL, Okay. So mean, if it's just a URL would allow me to run shut It's 6. I probably wouldn't wanna You said it would be 1st and Vlad are you concerned about having a separate index that you need to look up in? Absolutely. Yeah. Yeah. So this is a find this is a common, consideration for for high scale intermediary developers, they they"
  },
  {
    "startTime": "00:20:01",
    "text": "very much are jealous of every bite that they have to store in index. Because it's memory, and it's overhead at that scale. And then you talk to folks like the traffic server implementers, for example, they have the same concerns. Okay. So I guess the the question I have then is on the client advertising, the dictionary, that is available to be used for a given request. With adding a dictionary, source URL here. Be sufficient to handle the cases that you're thinking of. A yes. But best if you also can with an ETA, spy like, before I ran the full shine, I know he took matches. Responsibility. So URL and a tag from the client to the just do like I can get my Yeah. It's just a normal request path for you. Yeah. It's a I just Okay. I mean, that like eat the You don't tell me trust it. So there there'd be 2, like, dictionary source and dictionary e tag. Errors. Well, possibly, it's just, you know, you can maybe specific file and uses dictionary. Which way you want it view. Like with the shower over Zorel, I think we're always gonna have to have the Shaw in there. No. No. No. I mean, yeah. Just a shot so you don't have to send the X-ray grace whoever does the Yes. Because URLs can be on. So, you know, I certainly wanna I think I'd feel safer just adding the 2 headers and having clients send them. Those two feel like Yes. I could increase the size of requests. Don't know that there'll be substantial enough to worry, but it feels like those 2 are easy for clients that are tracking the dictionaries already"
  },
  {
    "startTime": "00:22:04",
    "text": "to have metadata about the dictionaries that they include with with the requests, without Much complexity. You know, time think so. C 0 and pounds and as long as they're relatively stable header compression should do its thing. It's what next up. David. And actually just relaying Timothy Terry's message since you couldn't get as Thank you. So, had a comment and a question. So first first, I don't see a lot of details in the draft about how the dictionary is used by the different algorithms, maybe this is obvious, but it might be helpful to at least have references. So I'm was his first point. Okay. I'm I'm just I mean, I can probably linked to at least the shirt broadly the the APIs and CLIs for all of the, at least for Z Standard And Broadly have here, specify a raw dictionary as an entry point where you pass it, and it uses it as part of the compression or decompression context. I, don't know that I wanna get into details about exactly how that's done, but I can link it to the Broadband Z standard specs for that part. Thanks. And his question was, the motivation for that question is that one of the things I found very helpful for SDP Compression with Gzip for WebRTC. Was to truncate the original message that's a cutoff, shorter than the maximum window size. Making sure the start of the document is inside the window helps avoid resending some headers that only appear once and leaving a little bit of extra room makes sending the same SDP with only minor changes work much Have you considered being able to specify a limit on the amount of document used for the dictionary"
  },
  {
    "startTime": "00:24:04",
    "text": "pong So there's what is set as a dictionary when you've set a dictionary, the entire response is used as a dictionary. There's no sort of sub window. That said for, like, the HTML case, they're largely going to be external dictionaries that are custom built or even JSON and things like that. The case where a full response is used as a dictionary for a future request these things like Wazem or a JavaScript or a CSS where you're versioning from one to the next, and you really wanna use the whole thing anyway. And so I I guess the the case of for something like WRTC or whatever might be more thin to the the custom dictionary that's side loaded, and you can put whatever you want in there. It's not using an existing native resource or we're using one? And, yeah, I mean, as far as the size of the dictionaries go, Right now, at least within Chrome, they're allowed to be up to a 100 megabytes. The what you choose to use is sort of up to you. But there aren't hard limits. We do have On the broadly, there's some discussion on the broadly encoding, I think, separately about window sizes and things like that and how big should the default window size be, but I think that's sideoscope of the dictionary specific part of it. Thanks. And I'd say maybe after you're done with your presentation, he had a few follow ups. Now a little threaded. So if you wanted to read the chat after you're done, maybe 7. Mike, just commenting on the shah versus the,"
  },
  {
    "startTime": "00:26:00",
    "text": "Athen tag, I don't know that this is a blocker, but I just wanna point out that one of the benefits the is that if you don't know what that shot is, You don't know what it is, and it doesn't give you any methius of history. Is on the same origin probably doesn't matter, you are disclosing a little information, Versus, I've been through this specific path with an e tag that you no longer have oh, well. Yeah. I mean, I don't know that it exposes any more than the the shock exposes we've already basically assumed that the the shot can be used as a user tracking token. Because you could generate a unique dictionary, forever user and just tag them with it. And so we've already on the browser side of things, treated the the cleanup and partitioning as if was user identifiable. Good. Awesome. Hello, Austin Wright. Curious if you considered using URI templates for matching URI. I've I've done some research on the area of matching URI to URI templates and it's possible. And you can do it in constant time with respect to the size of the number of templates that you're searching through it's when you do it that way, it's complicated to insert into, but, suffice to say you can't do that. We haven't. I'll take a look. Although, there's definitely let's say, strong pressure on the at least on the the b 3 c side of things to move towards URL pattern for everything. Okay. Just just to be super clear, is that from the w three c or the what working group think a little bit of both, we've been getting it from, I"
  },
  {
    "startTime": "00:28:00",
    "text": "the the tag as well as the what working group Patrick, did you have anything else, or does anybody else have any other Things to discuss about this was it for me. Okay. Doubtless, we will discuss this again. But it sounds like things are moving one piece of So, Thank you. That Next up. We have cookies, and again, a remote presentation from Steven. Steven, are you here? Yes, I'm here. Hear Yes. Can you, do you wanna request, the slides, or shall we? Yeah. Do you mind hosting them? And I'll just tell you when to switch through. That's absolutely fine. One second. Go ahead. Alright. Great. Well, hello, everybody. This is a quick status update on RFC 6 265bis. This one shouldn't take very long. There haven't been many changes since the last presentation in Oklahoma. Next slide, please. In fact, there's been 1. We add an advisory section to help implementors have a better idea of which part of the specs they should be interested in implementing up until this point, the spec relied solely on user agent or servers, which wasn't always clear if you were writing a programming framework, for instance. So hopefully this will clear that up. Next slide please. These are all of the open issues. We've added a few at editorial issues but for the most part, it's safe, fairly constant. The big one that's keeping the spec from moving along is that top one up there, number 2104."
  },
  {
    "startTime": "00:30:00",
    "text": "Same site cookies and redirects. For anyone unfamiliar, the spec some time ago additive requirement, but if you had a same site requests that redirected to a cross site that then redirected back. So basically the start and end points are same site but you have a cross site redirect in the middle. That entire request should be considered cross site and should not send cookies. Both Chrome and Firefox found that enabling that behavior caused breakages. So we, put it on pause as I've been looking for a targeted fix to that. Unfortunately, that's easier said than done. Metrics haven't been particularly useful. So Chrome is currently running an experiment, which enables this behavior for a number of a small number of users. And encourages them to file a bug if they encounter any breakage. I'm hopeful that we'll get some good information that way. But but I'm going to consider this our final attempt at solving this issue for 626 like this. If we can't come up with a solution, I'm gonna recommend that we remove this requirement from the spec for now. So that the spec can move along to working group last call and and become a full spec. And then on the next version, we can take another look at this. See next slide, please. And then in addition to potentially the same set redirect that I mentioned. We already have some additional work lined up partition cookies or chips, is waiting for is waiting to be integrated as well as cookie spec layering, which is a project to detangle 6 265 this from the other specs that it kind of clumsily re implement at times. Next slide, please."
  },
  {
    "startTime": "00:32:01",
    "text": "And that's all I have. Are there any questions? Any questions about the cookie spec? Okay. Thank you, Steve. Alright. Thank you. Sure. I'm gonna try it. You've got it? Okay. You you take it away. Alright. Next up, we've got David Skinazi with the signature HTQ authentication scheme. Yep. It Yeah. Big box of my friends. This was wired. I can't go too far. Alright. And the camera's pointing at you, so it doesn't matter. Alright. Hello, everyone. I'm David Skinazi, and here to talk about the signature, off scheme. So used to call this unprompted authentication, but we've changed it a bunch. And thought about renaming the draft in the data tracker, but who cares? That's a bunch of work for no reason. So, and this has worked with my co authors, David Oliver, and Jonathan Huyland. Next slide. Alright. So quick summary for folks who haven't worn their entire prior sessions. The idea here is that the client authenticates to the server using a asymmetric cryptography, and the server wants to hide the fact that it serves these authenticated resources. We adopted it a while back. We wrote the whole darn thing because that's what we do. But now, like, it's starting to kind of settle down, next slide. So the rough shape of how it works, you use a TLS key exporter to generate nonce, you sign that nonce, And then you transmit And it has nice properties about what you need to"
  },
  {
    "startTime": "00:34:00",
    "text": "send over. It doesn't leak the fact that the server has, this, offers a solicitation because you don't need to request anything before the authentication, and it also can't be replayed. Next slide. Alright. So we had one big issue in there that we talked about, the last IETF. So it's San Francisco. That we then discussed on the issue about this kinda looks like exported authenticators. Which is a extension to TLS, should we just use that. So we thought about it. We looked into it. And kind of the conclusion was, like, from a mechanical cryptographic call cryptographic property perspective. It was possible. But it would require some tweaks to the spec over in the TLS working group, like nothing major, but enough, they would have to reopen that spec. And it would also make it a lot harder to implement. And for our use case, We have folks who wanna, adopt this from above the TRS Library with like, modifying the TLS Library. And while it is not impossible to implement supportive educators outside OTL's library, it is much harder than design we have here. So what we kinda landed on was to keep the current design and not switch to exported authenticators. Next slide, please. So just as a quick reminder, one of the things we talked about is should we add the X or y or z to the exporter context? The answer is just add all the things. So these are all the things And the idea being that that binds them into part of the cryptographic exchange so that they count. You can't do, you know, those kinds of attack. Where you swap them out and you have confusion between what the server thinks it's signing or not. So singing trial algorithm is what we're using. Key ID is just an identifier. The public key, so that's to pro that that's to prevent,"
  },
  {
    "startTime": "00:36:02",
    "text": "seems legit attacks. You just put the key in there. It kinda really double check that, the server thinks it's signing with the key that it actually is supposed to be a different one. Also put the origin in there and the realm if you're authentication is using well, which is optional that could be empty. Next slide, please. So, when you send the header, you have these parameters. So the key ID, again, just an identifier into the database, put the entire public key in there. In theory that's not necessary. That from discussing with implementers, you'll have cases where if you implement this on your front end, and the keys are in your back end. It wouldn't be a lot more work. So we send the key in there. It's a few more bites. It's a little bit wasteful, but Since this header will always be the same on every request, header compression will kind of fix that. And then you put in the signature as in, like, what you've signed, which algorithm you used to signed it with, And a verification is kind of another part of the exporter. Like, if you want all the details of the geography. That was kinda when we did the security analysis, It prevents a class of attack, and it really makes sure that the sender actually has access to the TLS Master's Secret. Next slide, please. So speaking of security analysis, Jonathan built the tamarind model. And that's kind of what found some of these issues, which is great. This stuff is useful. We kind of when the seems legit paper came out, sort of an added more, like, characters to the model and taking things. I really know nothing about all this, but I think it's great. Oh, Look, Jonathan's in the queue. Maybe you wants to say something about that. So there's now another paper on how you can extend the security model even more, and you can"
  },
  {
    "startTime": "00:38:00",
    "text": "consider even more attacks. So, I'm going to be doing that analysis, eminently. Yeah, as far as we know, it all seems to work beautifully. Now. Can the security people stop making their lives harder by finding more attacks? God, so much for it. Awesome. But Thanks. That's not how this works. We're not very motivating topic Alright. And so kind of One of the discussions we had, like, comparing this to for authenticator. So that uses, Sigma, which is kind of the sign in MAC approach. That's called a TLS. This has a somewhat different construction, but from the analysis, it has, like, the same security bound. And then as the last line says, if you know more about security than I do. Please look into this and you find it interesting. And if you find something, please let us because, more security be more good. Alright. Next slide. Implementation. So we have a full implementation of an earlier draft was kind of before we changed a bunch of things. So we're gonna have to spend a little bit of time updating it. And we're working on 2 more independent implementations of what's left. So hopefully, in the not too distant future. We'll have 3 implementations that can interoperate with each other. We're just getting hung up on dumb things, like, when implementation can only do HTTP 3. You know, the one can do it only HTTP 2, and then they don't interrupt it really well. Next slide. So where do we go from here? We wanna make sure that the spec is reasonable. So Like, we wanna actually implement it, before we ship it. But we're we've closed all the issues on this document. So What I would say is it assuming that the implementation work doesn't find anything major that we need to make major changes,"
  },
  {
    "startTime": "00:40:00",
    "text": "maybe we can get it. Do you want me to pass gold? Yeah. And next slide, I think that's it. You can add go go to the action. That was a Alessandra Gitini Cloudflare. Just a clarification about the the exporter authenticators it it That's I don't understand how that's more difficult than just doing xporter in terms of TLS library implementation, Like, if you can just clarify. Yeah. So the the main reason is that you also need to extract from the TLS library, which cache algorithm, was used by the, HKDF inside TLS. Because that's what you need for the, finished message, if my memory is correct, the the Mac of Sigma. And not all TL's libraries give you an easy way to do that. Like, in like, on one hand, everything uses shot to 56 most the time, but maybe not always. And so it's kinda feels like a foot gun when if we implement it with that, and then also I wanna change this wreck. Okay. Like, so, I mean, this is more of a general comment about the supporter authenticators. Like, if the spec is not useful for some use case where it could if useful, then maybe it's actually worth doing the work to modify it, but then I don't really ever, you know, stake in the Jonathan Holland. Cloudflare. There's another issue with explicit authenticators which is that the client cannot just send a certificate. I cannot just send an explosive authenticator. It has to be requested by the Saba. We we should fix all of the things with explicit authentications, but it is already our So I was like, yeah."
  },
  {
    "startTime": "00:42:00",
    "text": "And so, like, it it would be possible, but both in terms of standard work And in terms of implementation work, it'll be located, and I don't think anyone wants to do that. If there are other folks who wanna put do more work on expert authenticators separately. I think that's a fine thing, but I don't think it's needed here. Time, Tommy Paulie, export an authenticator enthusiast or implementer, at least. Personally, I I think the decision you have sounds fine. If Someone did fix those aspects exporter authenticators, or at least the client. Being able to generate a part Is there a way to start using that, with this, or is, like, What what's the extensibility Wow. That was fun. So in terms of like, extensibility. The idea is, like, this header has a construction, and we can build a diff or this or this authentication scheme as a construction, and we can build a different one. It doesn't make sense to add a other layer of direction in there. Yeah. And then one other question kind of regarding the implementation status. Glad to hear that there's implementation off experience already and plan to be more Can you talk about, like, if you can, like, is this just you know, like, do a little test between the things or, like, is there any try to, you know, deploy this or use this in some experimental setups deployment experience, to see like how it actually ends up working for the full thing in practice, or is the plan to you know, just more do happened cove. Basic and drop testing. More more of a basic entrop in this case. I think the it's part of a"
  },
  {
    "startTime": "00:44:02",
    "text": "wider plan to do other things, but the other things aren't ready. So like this be deployed kind of on its own. It's not a general purpose. Web thing. I don't see it in Mike? So I wanted to respond a little bit to Tommy on the export of authenticator's piece. If you think about Let's say, because I probably will soon, Someone worked through Rite Aid Draft about how to stick an exported authenticator into an authentication scheme. Because of the problems we know that there are in the existing export of authenticate respect, could also think of it as David is here addressing the case that we know exported authenticators currently can't do. And handling it separately. And then we can write a draft to handle the things that already can do. On my Alright. Thanks. Yeah. You got me really scared when you put 30 minutes on the agenda. You said you might use it. So so so At some point, we might wanna have a chat about the the very generic nature of the name that we'll sir Alright. I mean, if we wanna bike shed that, I'm happy. I'd rather do it sooner rather than later. Sure. Let's let's have a bike shed painting session maybe in the whole way or something is solved It's not good to paint, like, sheds at work. Okay. Next up. We have just a couple of brief, scheduled drafts that are active. First of all, the query method. This has been in our working group quite some time now. And I know Julian, has has not been able to make progress on it, I'm not sure if if he's here. Julian, if you wanna say anything, but but"
  },
  {
    "startTime": "00:46:02",
    "text": "the last time I talked to him, he he assured me he is going to have time to to work with us soon. We have a few issues left, to work through that are A little bit potentially difficult. Regarding how this interacts with the rest of HTTP. But, There aren't many of them. Is Julian, out there? I don't see him in the queue. Oh, okay. Do you wanna channel that? Thank you. Mike Bishop, Chain Line Julian. I have no news about query right now, but I did review the open issues, and I still think that a focused design team Telco could speed the, could speed things up. So sounds like we have a call for, design field participants. So I Personally, I've given feedback on the issues that I'm willing to participate in a design team. I've that's That's a good approach forward. Anyone else just showed hands, Mike? Like they ship for your information to Julian. And when I was interested, Okay. If if if that does some sound like something you're interested in, talk to Julian or or to myself or or Tommy, of course. And, can we can get you connected with the right people. But, let's see how that goes. And and the next one is, a retrofit structured fields. We've been focusing on, the structured fields, this, which is very much almost done. I think, we're gonna have another last call. Yeah. Just I I was gonna bring up in this section. Anyway, so previously, we'd run a last call on that document, and that's where we had brought up the fact that we want to include the, other string formats in there to handle non ASCII strings. We had a consensus call on that that work, was done and has been stabilized. So I think at this point, I will right after this meeting kick off another"
  },
  {
    "startTime": "00:48:00",
    "text": "a very short working group last call for just like a week to confirm, that and then progress the document forward. There any concerns about that? Please let me know, but, otherwise, I'll be kicking that off very shortly. Okay. Is that Julian? It was just random. It is. Yeah. Sorry. I couldn't find the queue button, we currently have, referent. You have currently have a dependency on the on Tim Bryce on the court. Characters Internet draft. And I'm not sure how that will be progressing So we'll need to make a decision whether we can rely on that. We've got to Yep. Yep. Yeah. I think it's an informational reference, though. Yeah. Yep. So it's it's worst case if it really looks like it's going downhill the time we get to the RC editor, I think we probably could take that in the last stages of process. And I'm seeing an area director nodding and thumbs up, which is always good to see. Yeah. I I noticed that too, Julian. And and regarding retrofit, I think I'd I'd characterize that that that we have an approach to the draft. Had a fair amount of discussion about it, and it it's relatively stable. We talked about it a bit last time. And I think we wanted to take a bit of a pause with that and and have a think about it. Make because it is quite an abstract draft, it it doesn't have, you know, any hard interoperability requirements, and and it has some interesting interactions with fallback behaviors, for example, wanted to have a bit more of a think about it and and maybe think about how it could be used in different cases. Even if they don't make their ways into the draft, to make sure that we were confident. In in taking that work forward."
  },
  {
    "startTime": "00:50:03",
    "text": "I think once SF, this is is, finalized we'll revisit it, do some of that work, and and see where we are. So we'll probably talk about it again in in Brisbane, I'd say. Oh, that that's my feeling about it, at least. And I see nothing from from Tommy, which is good. Any any thoughts, questions, comments on SFbis or on retrofit. Okay. We're doing really well on time, which is interesting. wondering if I could shave just one thing off of Friday's agenda just to give I'm little bit more time then, which is probably, again, a very brief discussion of, a new spec. We've we've just adopted is the cash groups spec. Objection moving that to right now? And I see a thumbs up, which is always good. So this is a new spec that we, just did a call for adoption 4. We discussed it last time. I'm editing and to refresh people's minds. This is, a new cash control mechanism to group together responses that you can do things like and validate them together. This is pretty widely implemented in content delivery networks, for example, in reverse proxies. And so this is kind of paving a cow path to be able to do that in a standard fashion. And my interest is in doing so in a way that is truly interoperable. So even the fine differences of how many know, what's what's the minimum number of of groups that you support, for example, is top recommended in the spec. It's very new. If if you like to take a look at and contribute, please do so. I don't think there's anything to discuss today. But if anybody has any thoughts, now's the time. No? Okay. That saves us 10 minutes on Friday."
  },
  {
    "startTime": "00:52:00",
    "text": "Which is exciting. And I think that takes us to our last item today, which is the Qpex static table version TLS extension. And Roy is remote. Roy, great. You're with us. I am. Do you wanna drive this slide, or would you like us to? If you could, that would be fantastic. Sure. One second. Oh, Time is on it. Go ahead, Rory, just as soon as yep. There they are. Okay. So, yeah, it's a it's a really boring name. First of all, I should note that Mike Bishop and Ferndell at least are in the audience. So this is not intended to be a desk on 2 hack, which they they came up with. So if you've rather thing, CUPAC is for Next slide. So what is this is briefly? What is the qpact static table and and why there are issues with it. So next slide. Answer this quick. So Quebecers waits 3 users for impression of heads and trailers is very simple. And rather like HVAC, it has a stack economic table So rather than send through you know, full headers themselves, even though they're compressed and binding format, you can simply sent through a a very simple bite for each of them. Each of them has an index in the static table. And for headers that are not common you can pass in the dynamic table So we have in QPA A static table. It is has nighttime entries. Very simple. And every h three client and server right now, supports QBAC. It actually has encoded in it what that table is. So we don't need any kind of versioning for this table right now."
  },
  {
    "startTime": "00:54:02",
    "text": "But, Quebec, the the data that was used to define this table, is already five years old. Since it was created, there are a bunch of new headers that are now pretty common things like all the sexy age emissions policy, things like the xpowered by there are a bunch of headers that are commonly passed back and forth now between client and server and because they are not part of the predefined standard table, they always get passed on the dynamic table, which means that it was get passed as strings. Compressed strings, but still strings. So this proposal is for two things. One is to say, and actually next slide, So we have this Hispanic table. It's old. It includes some invalid values, it doesn't mean they have upgrades. It's just the appendix to the original spec. That Mike and Al and, Buck put together. So My concern is Okay. It may already be out of date. That may already be headers that are being passed back and forth that are not that are very common that are not in the static cable left. I and ask more dynamically. Effectively air strings, taking up bytes on the wire. So this proposal says 2 things. One of them is to define the qpact static table in in a registry. And enable new headers to get added to that Cuemath static table. Such that plants and service, and then reference the latest version and the number of entries that are in that coupon static table, and therefore, as many as possible of the headers that passed back forth. Can be passed as simply references into this shared static table,"
  },
  {
    "startTime": "00:56:03",
    "text": "And secondly, that there will be a negotiation scheme which is the TLS extension that that happens before the HTTP requests. Where both the client and the server negotiate on entries that are in the they're in the static table. So in short, in the current initial table would be defined in a registry. As new commonly passed headers, Get discovered new, new headers that are being passed frequently we'll get added to that qpact static table and then clients and services will say, yes, I support a select table with a 120 entries, and the services I support it with 150 entries and they agree on 120 if this is really all about future config. It's about saying that we need to have a standard mechanism for doing this. Next slide So, the future proofing is is important. We need a standard way of being able to keep headers every client every server on the same in the same place in terms of headers. And the interoperability chaos is something that I'm concerned about. Where potentially different vendors may decide to say, okay. Well, you know, we have our own particular internet connected device, let us say, you know, an Amazon Alexa or a Google Home or whatever, and they start adding their own static headers. This could be problematic if then then becomes impossible for testing tools to be able to to be defined which"
  },
  {
    "startTime": "00:58:00",
    "text": "can use both which can which can rely on a standard set of headers, isn't it? So the spec basically is, yes, let us define and I in a registry. Or future potentially multiple anniversaries. To just store all these headers and define this interest in the static table, and then the TLs extension to to enable a client and server at one time to negotiate which version of that static table hammyentries they agree with. Originally, if the last slide is going to So, the things that brought up when I bought everyone in the working group should this even be a TLS extension? I mean, this is an HTTP internet draft So we're doing some boundary crossing with HTTP and TLS. That is a violent concern. I'm not sure how else it could be done. I was looking out some album and I see that them. Dave Benjamin thinks that this should be out. And It could be. I'm just not clear on how much either out or Alvin is actually being used now whether it is a valid standard which is being used. If it is, blips this should maybe be thrown in there. Alternatively, could this run actually in HTTP. Could there be, you know, the first request? A header which says, from client to server this is what I support and server responding. That seems a little key because we're sending headers discussing habits. And of course, as has been pointed out to me, why am I worrying so much about interoperability and stainless. This isn't a big deal. You know, I things will get sorted out. But but"
  },
  {
    "startTime": "01:00:02",
    "text": "I would like them to be sorted out sooner or later. That's it. That is my, That's my proposal. Thank you. Alright. So I see the queues filling up, David? Oh, yes. David, it's Kenazi. Thanks for bringing this work, Rory. So my first question is, Well, the meta question is, like, how much will this help? And I guess So have you measured some data on, like, looking at headers that go through your servers and if you pick, you know, one new dictionary. How how, like, what kind of percentage gain will we get for, like, real traffic compared to what we get with the today's dictionary. Do you know? Very good question. The quick answer is I don't know. I'm trying to do some testing now. What I do know from looking, and this is purely looking at the whether our live data is that the current Quebec static table to funnel the Quebec spec is there are a lot of headers now by a lot. I mean, I think do a 9 or 10, which are significantly more frequently found then the least frequently found entry into that table. How much does actually matters? I don't know. I mean, you know, it's a case of does it matter that much that we are passing things in a dynamic table as strings rather than just abstracted references into a shared table. Don't know the answer. I'm trying to test it now. Thanks. So I don't work on browsers anymore, but as someone who did, I would want to see some of those numbers before saying, okay. Then this is cool. We should like like like like pork with you and we should implement it. Absolutely."
  },
  {
    "startTime": "01:02:03",
    "text": "And then on the last bit, my personal take is ALTS was really designed for things exactly like this. I really personally think we should have designed HTTP 3 that way, but that ship has sailed. And luckily, Martin Thompson's 2 busy right now with non comms. So maybe we could ship ALPS today, and that way it'll be fine. Look, I would love nothing more than for ALPS today. Yes. Yep. Last thing last thing I checked and I forget. Oh, it was, it was Victor Vasilya Fluke. Who came up with ALPS. And his understanding was the I'm not sure if he's there is there was some implementation But It just kind of got lost. That draft has now expired. Not even sure of the current status of ARPS, to be honest. Yeah. Oh, well, I can answer that. The so it was a proposal from Victor to solve this and other problems. Some people, Martin, that's why I was making that joke, didn't like it. And that kind of put it on pause and then everyone being busy with other things. So it doesn't have any kinda, official standing. I think it's just an individual draft. But my thought would be that this is a great argument to revive that work. But that's a conversation for probably another time. So, Mike Bishop. I just wanna offer to jump the cukes. I have some done some recent profiling slash data that if I didn't if that's okay. Other folks. My kid. Is that okay? Okay. And, Allison. Hey, Alan from Dallas. So thank you for bringing this. I I think it's interesting to talk about. So just in terms of data, so I I went and did some optimization. It was really in in our, sort of, I worked for Meta. In around compression, earlier And so I spent a lot of time analyzing headers are sent"
  },
  {
    "startTime": "01:04:01",
    "text": "across our CDN insider data center, which involves a bunch of stuff that's not standard anywhere, and people make up headers all the time. And also tuning our dynamic cable strategy. So So that's I have that recent experience. I didn't come prepared necessarily with with data to present, but I I I will make the offer to go back and and look at it with the caveat that It's not general Internet data. You're right. It's it's very specific to what's mostly decent by our apps, and browsers are very rare. In our world, So that's one thing I have. I also know we've been experimented with rolling out a different, HTTP client stack across our earlier this year across Instagram, I think. And, that had different compression strategies and with respect to the dynamic table. End. Until we corrected its strategies to match the ones we already had in place, we saw big regressions. I just wanna we've been talking a lot about static table and the performance benefits that it offers. But I just wanna point out that that a dynamic table can be very powerful. And some of the things that you've addressed with static table, are were sort of meant to be tapered over by that dynamic table. As in you only send the spring once it gets added to the dynamic table. And if you're being smart about how you manage it in every table, then you can sure that never falls out by duplicating it and, etcetera. So that that's another possibility. I feel like there's something else like that, but I'll let the other folks go unless anybody has any questions about that bit. I I will offer this to to try to make And the other thing is that I did all this analysis in a bespoke way, and it took a bunch of time. And didn't take the time to automate it and, whatever we do, we decide to continuously update the table, we should automate it so that we don't have to do it all the Thank you. Peg cell. Mike. Oh, Mike Bishop,"
  },
  {
    "startTime": "01:06:01",
    "text": "As as I've said before, I'm interested in being able to do this. We had an issue open in H3 to be able to adjust the static table that was in use. We decided to table that at the time. Because if we needed it down the road, we could build an extension for it, and here's the extension. I do I'm less enthusiastic about the plan to just tag things onto the end of the static table. Because the longer your index gets, the less useful it is because the more bytes it takes to refer to that. I think the ability to choose a different static table. Which this would enable. And then have a collection that you can somehow choose from. Is probably more more appealing. That said also being able to trim it and say, you know, I know about the first ninety two entries. The first 150 entries doing the other way is also interesting. Because if you remember, we had some IoT discussions around H2 and H3, and there were about having statically compile the entire table and your binary, and you know, if if somebody wanted to come along and say, I don't support a static table, just send everything or I only support the first 16 because they're really useful. This this would allow that as well potentially. Yes. Certainly. I mean, I didn't really mention it there. The there would be a concept of being able to say For instance, if you were a particular client, which you know only ever talks to a particular server or an Alan's case some internal staff, they could each specify their own static table, which might only have 20 entries in it. Because they know those are the only headers that we only ever pass and then they'll the couple of specific ones all done the dynamic table."
  },
  {
    "startTime": "01:08:05",
    "text": "That were off IOT stuff where you have a tiny compiled binary and don't wanna be having a bunch of extra headers that are never gonna be passed in the Right. So I think for me, the takeaway here is the specific details here, there's a lot of wiggle room on exact how we spell this. Maybe reviving ALPS versus having a dedicated TLS extension is gonna be more palatable. I certainly think it's cleaner. But Yeah. Else has its own issues. There, how we spell the negotiation. All of that has wiggle room. But I support the overall point of the static table should not be a we wrote it one and now it's set in stone, and we must live with it for Because I wrote it and there was a lot of black magic of move this entry up here to get past this cut on. We can do better. I'm sure. Thank you. And I certainly, like I said, I didn't wanna disuse you or or or Alan or Bakham? The visual design. Roy, just so you know, we have a pretty long queue. So we need That was a Alessandra Gadini Kotler. Also agree. Like, this seems like useful work. It it always seemed like a bit weird that we would define, you know, a single stock table once, and then that would apply for years years years. I mean, it's not just new headers, but there's existing stuff, like expect CT that is probably not that useful anymore and and and and it should probably not be in the static table. So, I mean, as Mike said, there there's a lot that needs to be figured out, I don't particularly understand the whole negotiation process that is described in the in the in the draft. The way I would think it mentally is you know, someone comes, makes a draft,"
  },
  {
    "startTime": "01:10:00",
    "text": "defines a whole static table, and then, you know, that static table 2, and that goes into, a registry somewhere. And then you would simply have to negotiate that specific version rather than you know, I have to modify the existing registry or or there's a length parameter in the TLSX extension. So so that all seemed a bit too complicated. I don't know Do you know of any, like, specific use case that that wouldn't be required for. The use case there, I mean, in terms of length, the length issue was that if the if both the client and the server be using the same table, but but one of them, the client only supports night on our own interests and their service ports a 150 entries, we would need to make sure that they only both negotiate the same that they're only going to reference 99. Otherwise, you can have a problem with the server sending back Oh, static table entry, a 120, and the client doesn't know what that is. It has no idea. Right. But would the the length of the static table be part of, like, what the version of the static table is. Right. Well, and so this is where we're coming up with the concept of of a version which could potentially be a reordered copy the table. So you'd have version 1, which might have multiple lengths and entries added to it and then version 2 might say, well, now I header that had been added to a previous version as entry 100 is actually the 2nd most common header that we let's stick that at the beginning of a new version of the table because it will use fewer bytes. Oh, okay. So, like, we we can probably discuss"
  },
  {
    "startTime": "01:12:02",
    "text": "this letter, but my point is if you define a version of a start table, you define the table in its entirety rather than reference. Right. So version refers to ordering and length refers to number of entries. You know? Hello. Good is Pardo, cloudflare. We got loads of time left on the agenda. So, I could talk about in a previous life, I was working on, multicast HTTP. And so one of the the real difficulties we have there was that a lot of the HTTP stuff worked this was like, H. 3. Before it was called H3, but of the real difficulties with the dynamic key pack stuff is that you can have already join a session that had already been started. Because you, you didn't have the every instruction that was driving the QPAC dynamic table into the state that it needed to be to be able to join. And so one of the things I always wanted to be able to do was was have pluggable static table, so to speak, either can always just work around it and send string literals, but super attractive to that the idea that we could defined domain specific tables like this because it could really help some kinds of the obviously, this isn't an adopted work or or anything like that. But I can I could see creating a mechanism to allow pluggable, stack tables, whatever you wanna call it, could enable a load of interesting things, and that's what I'm more interested in than just and append only operation? Especially because of the concerns that Mike already expressed. So I'm going to them, but I wanted to pick up on is I think you know, there's a land grab it's it's better to be early than later can see the whole process of trying to keep up. Table up to date getting very political and and taking forever and chewing up cycles somewhere. I I don't know even know where you do that. One of the early suggestions was the IANA Designate of expert would have this job doing. Yeah. I think"
  },
  {
    "startTime": "01:14:03",
    "text": "That that is terrible for so many reasons. We can do it would probably need to be part of the working group and Or it just doesn't work in my mind. I think there's a lot Julie mentioned in the chat that know, why not H2? I think we should seriously consider that the mechanisms might be different, but that that no reason to make the things wide specific. Because It's HTTP. Right? It it needs to work for higgs before or whatever we come up with next. Yeah. That's all I wanted to say. Thanks. I wanna thank Rory for bringing this conversation to the list and kind of brings my ideas to the table that we could It calls in. Jizz. Thanks, Lucas Cassilho. Because of the whole guide, first egg white, Megan, look, I said. I think we are at a very good start now. And regarding how we convey the negotiation signal I'm not sure if you need to use HLS extension or ops. We can just use the settings frame because it's I mean, when TRS is doing 1 hour the settings can be 70 0.5 RTD. Them, when the client tries to send the first request, then you need to know what the server is capable of doing. And in case of ads, you know, we know how to negotiate. We've already done that in quick, by using, we made Brian's a information with the previous session so we can just fold that pattern do it. And, I'll push myself to the back of the queue to crypto gun. Sorry. Drag on me on to Microsoft. So I'm just probably going to repeat half of stuff that"
  },
  {
    "startTime": "01:16:00",
    "text": "that, I would like to see the performance data before we do anything. That is one. I would really like to us avoid TLS Essentials. Don't need to. And Kazuko actually said what they wanted to mentioned. So, yeah, Thank you. Thank you. And my Hi, Michael Tummim Invisible College. I just wanna kind of go along with what Lucas is saying, and I'm just noticing that if we're at the point where the static table has multiple versions, then maybe that is a dynamic table. Now. And so it might be time to rethink the model a little bit. Maybe this is more of an initial table. Or maybe we want to rethink what dynamic means or you initialize. Thank you. Draganna, you reentered the queue. Is that Oh, and, oh, sorry, I'm glad. I have a lot of. So, first of all, yeah, I think it's a good idea to have this extension given the data shows good air compression. But regarding the versions, I understand you send one version number and you pick the lower between the version on the server and the client, which is like FLS. However, once we get, like, to 50, tables, You have to have them all on the client, which kinda doesn't make sense. Like, for a service, not a problem. Probably a big server having all those stables, but maybe should be a list of supported Yeah. I mean, frankly, the if it were a TLS extension or ALPS or something in the settings frame, Yeah. I mean, you might I would ideally want to have the same thing to do with type of suites until extension. The client just sends through These are the ones that I support. And the server responds with"
  },
  {
    "startTime": "01:18:01",
    "text": "Whichever on it supports. And as long as they both add a minimum support current. Basic version, they can negotiate to that, but perhaps they can negotiate with separately. Yeah. I mean, it's, that's one of the reasons we're discussing this here because you're right. We can't really have a client with 50 different version of the table for all the ones that it it supports. Okay. David Benjamin. David Benjamin. So on half our cheesy data, we did consider that when we were designing apps with a lot of feedback. And, I wrote a draft. I I can I'll I'll send a link to it in the chat, but it's like comparing ALPS and how far gt data Half RT data does not quite work when you have a strong ordering between the server's information and the first request because you need the client to wait for the settings frame, but there's no guarantee that server will actually send the settings frame in half RTT. You need to like change the expectations slightly either by of some diversion, or finding the, like, ALPN version or by just introducing a new kind of animal and due to the state machine issues anyway, we were like, just to make a new pact at all. Subs of subs that like, just using RafRT data is not quite a it sounds Thanks, David. Eric's love. There was a good point raised domain specific header sets such as IoT devices that might have small, very specific set of headers instead of generic HTTPs. So maybe instead of numeric version notations it would make more sense to support alphanumeric. Strings where people could define their own domain specific tables rather than some arbitrary numbers. Mister Thank you."
  },
  {
    "startTime": "01:20:04",
    "text": "Okay. And I inserted myself at at the end, just speaking without any hats on, I'm not gonna bother getting up go to the mic. Because I'm old. I'm gonna sound a slightly different note here? I remember when we did the static table in H2, And then as part of H3, It is a by chatting process, there's a lot of opinions about what's on the table and what should not. For example, Rory, you mentioned Xpowered buy, and yes, that is seen a lot on the internet, but the question is we want to encourage it to use by putting it in the standard to make it more efficient? You have to have that discussion. And so I it's not quite as simple. I think you need to think about what's the governance on selecting these things. And how often do you want to do it? Is this something that that, you know, is done very dynamically, or is that something that we do every 5 years or something in between? Is that changes the nature of the decisions you make. At one end, yeah, you need to have it very dynamically negotiated at the other end. Maybe it's new AOPN token, and maybe that's okay. Which we've talked about before, you know, the different discussions there. If you do need AOPS, then that's, again, another hurdle to get over it because, so far, it hasn't had uh-uh, enough support, and it's had enough detractors where it hasn't done over the hurdle. So so it comes back to, I think, for me, the first comment, which was How much gain do we get from this? And my recollection of the first process was the static table is really just to get you through those first few flights. After that, you're in the dynamic table. And and so the benefits from it could be quite limited. Especially when you start doing trade offs like making Your reference is larger. As micro mentioned, So I think more than anything we need data here. Before we can before Does that make sense? That that's my check. Correct."
  },
  {
    "startTime": "01:22:00",
    "text": "Alexander Alasandro Gitini Cloudflirt. Just a comment on the static versus dynamic table. In particularly for Cuba, there's a lot of complexity that goes into actually implementing the dynamic table and implementing it in a way that is actually performance and doesn't run into, like, blocking and installing. So It is a fairly, I I I'm not saying common option, but, like, Some implementation do not actually implement dynamic table. So actually improving the static table, I think, is is if we can actually prove that, you know, there is benefits, then it seems like work. The the work as as almost a dynamic table replacement. It sounds like Yep. Lucas Pardier, Claudia. Mark's comment just then reminded me of, like, some discussion I watched from unarmed's length about how good it would be if we just embed it in JavaScript like with Enterprises. That's yeah. So so, Alex Russell wrote, a blog post about this, last day, I'll post a link in the chat. Just in case kind of viewing at how this sounds great, but the the ramifications of that in terms of entrenching behaviors and stuff that maybe we don't want And, like, we really need to think hard about that just Alan from Dow. I just wanted to quickly respond to the we don't implement the dynamic table, Yeah. I know it's complicated. Every time I tried to make it not complicated, somebody maybe make it complicated. So sorry, that it's like that. And I think if your use case is like, well, I I've I wish these 10 headers were in the static table. I think you can write a very simple dynamic table implementation just just pops those in in your first flight, and then you're off to the races. So you might be able to get what you're looking for for a lot of us"
  },
  {
    "startTime": "01:24:03",
    "text": "And and since you mentioned the work complicated, that was my other concern here was just, you know, how complicated is gonna but it sounds like we we there's definitely interest in this top. You know, it's pretty much air hat back on. It sounds like there's definitely interest in in exploring this space and seeing what else we can do here. Would you agree, Tommy? Yeah. Definitely agree on that. And I heard several people talk about data, and I see in the chat, you know, where's the data coming from, but it seems like some more discussion about actually collecting the data on this and what's working well and what's not should be the basis of informing our decisions going forward because that's what's gonna be compelling for all of us. And and and to that point, data from the viewpoint of one server side vendor is interesting, but also data from client vendors especially would be quite interesting because they're more diverse. Ellen. Just a suggestion is a follow-up. Maybe you can put out a call. I don't know if a call on the list is really gonna do anything more than just saying it here, but just saying, like, because, like, for example, like, I had a bunch of compression data sitting around a few months ago as I was going through process, but I did to, like, write it up and share it, but if you just said like, hey, we're gonna, I don't know, another HTTP workshop or an interim or something and say, like, if people wanna bring their compression data and just pair, talk strategies, commercial strategies, the don't know, four people in the world who think about this. We can get together. I don't know. Just an idea. Yeah. Yeah. Not to cross the streams, but if any, like, the workshop would be a nice place to talk about this. Okay. Thank you very much, Rory. It sounds like the discussion's continue Any anything else on that topic from anyone? Okay. We can I think oh, Mike, go ahead? If it turns out that we do wanted want to do this and we want to do it through Alps. Would that be a formal request of TLS, or would that just be us"
  },
  {
    "startTime": "01:26:00",
    "text": "going to TLS and shaking things, or why I I my recollection is is that there were some concerns about how in terms of of of not just feasibility, but you know, what effects it would have on the ecosystem. Somebody would those discussions, I would have to be had. I don't think we can guarantee anything. But I'd I'd personally, I'd I'd wanna say is discuss like, a lot more about this first before we get to that point because we need to know what properties we need from the negotiation system before we can say we need that one. Additionally, I think we have sufficient overlap between TLS and HTTP at least at the beginning to have that in the conversation do some initial evaluation, but more importantly figure out what do we want is the properties from any solution. I, I, I, I don't see a world in which you're just like, we need this from you working group. Like, we have a much more collaborative approach across these working groups. Okay. Well, thank you, everyone. I think we can give you now 3 minutes back. And we'll see you again tomorrow. That was interesting. And so they should give you when you leave the ID. So thank you for your questions. At one point, I think, yeah, when Joe Hildebrand left, they, who, you know, they gave me a little gift, you know, I found online get into your mic chair. Lot of"
  }
]
