[
  {
    "startTime": "00:00:04",
    "text": "I [Music] [Music] "
  },
  {
    "startTime": "00:06:45",
    "text": "the doctor the doctor may be nice there\u0027s a boat seat if you want I don\u0027t know sir I mean just a powerful person familiar yea ok Danny Rose sterilizing I make it into the time I probably ought to thank you because you get them play by ear Barbie quick through bubble Armas addressing how do I saw your son named my sanity zan 80-85 alright so we\u0027re starting a few minutes late but um lots of important people that we were waiting for welcome everyone to a net VC a few a few things before we get started we have a quite a bit of change in personnel so we\u0027d like to first of all bid farewell to our ad Alyssa we will now be stepping up as ITF chair so you go out to lists on that thank you very much for everything you\u0027ve done for net bc alyssa was a instrumental on getting us through the bath and getting everything started here and keeping us on track so she will be missed and as some people wearing dispatch I actually missed it but alyssa was presented with a turntable that plays opus so a little bit of something old and something new and so we followed with that theme and we have something rolled in something new Thanks really eat the mic for the last time um thanks and you\u0027re obviously in extremely capable hands as your former co-chairs now you\u0027re responsible lady so I will be watching from over in the "
  },
  {
    "startTime": "00:09:46",
    "text": "general area and so that\u0027s the other bit of important news that a replacing Alissa will be Adam are our friend will co-chair so should be a perfect continuity in that and not somebody to pester the write-ups and we want to welcome Natasha who\u0027s stepped up to co-chaired plus the bottom and I\u0027m going to stay on so today we have on the agenda some more administrative items look at our milestones and and this position of some of the work of documents that we have and then we\u0027re going to cover the requirements draft updates and then the testing and for update and dial update will i\u0027ll get to it and no we don\u0027t yet so if we want to go ahead and get some we\u0027re up volunteers four that switched its anybody that could take notes and do java scrub now describes an easy job you just look at the jabber and stand up at the mic if there\u0027s a question to be asked thank you um so sorry I don\u0027t know your name so Jonathan Jonathan Sarge APIs quite thank you very much anyone for note-taking you get a star you get a star I think it\u0027s like really crushes you can trade it in for nothing um but you can show how great you are this they would do around that maybe take a few notes thank you very much sorry to impose on you again I think and blue sheets are going around make sure you get signed them the note well is particularly important for this workgroup if you\u0027re not familiar with I TFI p r+ you please make sure you are aware of it this this work to remind you is a is part and parcel of having an IPR free standard at the output of this work make sure you review that any comments on the agenda before we get started didn\u0027t that make me feel better love have a new chairs alright so going on to the first item reviewing our work of documents in my son\u0027s so we have a first mass plan of a July last year which "
  },
  {
    "startTime": "00:12:47",
    "text": "we\u0027ve obviously exceeded and that was the requirements and testing evaluation criteria documents if we choose to publish them as information and we did decide to choose to publish them so that\u0027s not the question here but obviously this that\u0027s will update the milestone two may kind of aggressive what we think there\u0027s not much left to do we already did our work with class code requirements last time but they\u0027ve been some changes that Jose\u0027s going to review that that are probably a little bit more than editorial so we will restart over class call for two weeks after this meeting and I believe we\u0027re ready to start the work group last call and testing but we\u0027ll wait until after the VR testing presentation to to make that call but the goal is to get most both of those done by by the main milestone now so they\u0027re other many milestones the Codex specs and the reference implementations of them were due in may I don\u0027t think there\u0027s any reasonable way that can be accomplished so we\u0027re going to take those milestones to December and there\u0027s also a storage format spec which there has not been any activity on so that\u0027s also being updated to December but I\u0027d note that without even any individual drafts on that there\u0027s a probably unlikely that that December date will hold and then finally there\u0027s a test result not yet which again has not been started but it should be relatively straightforward after the testing evaluation criteria stabilizes this should just be a simple output of that document all right let\u0027s look for administrative part let\u0027s go to jose\u0027s going to present remotely would be just Tommy\u0027s day oh yeah so we have a different projector in this room because we requested a high-resolution projector and I don\u0027t think it gets me that good so the slide should be on vm again wet before you should get the slides are on the agenda so you should be able to follow it with that be that way absolute [Music] you still projecting again to the medical a chance somebody has a basic macbook to VGA dongle now new macbook "
  },
  {
    "startTime": "00:15:54",
    "text": "small macbook yeah okay so um yeah apologies to those uh remote will have to UM not to state the slide numbers and and people online will have to arm pull down the slides and uh and flip them annually sorry about that but those in the room are going to get a very high resolution version of these slides okay so Jose is he in seem coming hello can you hear me yes thank you very much so good afternoon everybody this is a quick presentation on the net VC and requirements this is the version number five of the document next page please so it it\u0027s going to be pretty quick there are changes to the applications some editorial changes some changes to the requirements and nothing to the evaluation methodology next page please slaughter it so in the applications we we did some changes to the introduction some editorial changes the important change here is to the video monitoring and surveillance application where we we change the rates that we had originally so for the 1080p we had originally only 25 frames per second and now we added both 25 and 34 5 megapixels we added low frame rate as well since for surveillance in many cases the quality of the pictures is what is important and not necessarily the frame rate so we added a 12 frame rate in 25 and 30 for adding higher temporal resolutions and for the 4k case as well we went from the low frame rate to adding 25 and 30 so this is just to cover a wider range of surveillance applications and that\u0027s that\u0027s that for the application section next page please smartform so there were "
  },
  {
    "startTime": "00:18:55",
    "text": "some changes to the general requirement and that was mostly for section 31 1 and 3 dot one dot 343 dot one dot one what we wanted to do is to mention compression performance and so that the compression performance would be good for both what we call easy material and difficult material for natural content so that is we would like to see improvements not just in the easy scenes but also in scenes that have a lot of detail a lot of motion and so that was the thinking in changing the the wording for for that section also to add explicitly call for screen content sharing for both moving which is static and also dynamic screen content sharing so that\u0027s a that that was the changes to that requirement for three dot one dot three we had mentioned syntax that would allow extensibility but we wanted to make clear that this is explicitly the bitstream syntax and that we recommend that there is backward compatibility and so in this case backward compatibility means that the changes to will not affect legacy decoders and by legacy we mean just simply decoders that are that are working at a specific profiling level will not be affected by future changes to the to the encoder so that\u0027s really they\u0027ll take the the essence of the changes for 313 so backward compatibility for a specific profile in level next please so just before we go in that so this is on this is what I thought there the changes would be really more than editorial and I think this is what we need to reset the worker class call so I\u0027d ask the worker to please review this I think this is more of a substantive change and we should realize what this means that explicitly calling out screen sharing performance being part of the target you know it is significant and you know requiring backward compatibility fer 4 first first generation encoders versus you know later decoders is quite a quite a requirement to so I said were quick to please review those during the next the last call and make sure you weigh in on your views on them now note that in other spec in other standards for example in hevc they\u0027re the first version did not have any target for screen sharing performance and it\u0027s not until version for that was just published a few months ago where screen "
  },
  {
    "startTime": "00:21:56",
    "text": "coding performance actually ended up being significantly better and if we\u0027re setting our bar relative to industry standards now this is even a more important thing to keep in mind twenty-five percent of better than the latest december state-of-the-art is a pretty significant undertaking any other comments um not go ahead hoser okay so next next slide please that\u0027s life I\u0027ve okay so for the basic requirement there so we just went to the general requirements now for basic requirements there was a change to support of efficient random access point encoding we had that before such as inter coding or resending of context variables as well as efficient switching between multiple quality representation so this is something that we we talked about before that would be a requirement in order to allow efficient random access encoding for three dot-to-dot three that has to do with complexity and here what we wanted to add is a specific sentence that would point towards reasonable complexity of hardware and software and color implementations compared to what we have today is as always we had in the document well still we we still have in the document requirements that for the high quality encoding the encoder should not be ten times as complex as what we have today but this particular paragraph compares with the current state of the art which is EP 9 or 265 and so that\u0027s that\u0027s the the added text or for this and by meaningful improvement we mean to say that there\u0027s improvements that are visible whether we in whatever way that we decide to to evaluate them whether subjectively or objectively and then there were no changes to the text for the optional requirements on any comments on this ok and that\u0027s uh that\u0027s mostly young Jim Carrey from missoula arm so just a question about the not better all right Tim character from missoula just a question about the first bullet point here arm do this doesn\u0027t say much about when you have to be able "
  },
  {
    "startTime": "00:24:59",
    "text": "to do this switching arm is your estimation that something like arm you know periodic aligned keyframes across multiple quality resolutions would be good enough or do you envision this as requiring something like s frames I Tim I I missed the last statement that you made um do you envision this as requiring something like s rains or with periodic arm aligned keyframes be sufficient to meet this requirement yeah I think that would be sufficient to meet that requirement correct okay then I think that\u0027s fine thank you good and then select space is 50 under peach just for jose\u0027s benefit their the quick exchange their Tim will be sending some pros text to the list on that thank you just one more question looking for Mike for Mike there was I think we\u0027re doing the dips for the for this change I think there was also an added definition of profiles and levels and I think that\u0027s probably important to call out have people review what we it\u0027s not defining what profiles and what levels the the spec should have but defining what is constituting a profile what is constituting a lovely could be something importantly we\u0027re reviewing coming on okay thank you alright so thank you so those are the changes from the previous version all right and like we said we\u0027re going to start a workup last call um starting on now for two weeks into a la so we get all the comments back and please we need some more reviewers on this document look we haven\u0027t enough I pausing feedback on it yet to a natural at the residence in a lot you give any of the hands of anyone that\u0027s willing to review all right for the notes Tim anyone else such a pretty short document in the updates or even shorter Dave all right thank you thank you thanks Jose so next up is um Thomas to talk about testing and he\u0027s also going to do it remotely so Thomas if you could come up to the mic q me dekha is he on okay "
  },
  {
    "startTime": "00:28:15",
    "text": "see and hear you okay cool and I can\u0027t or my slides up I can\u0027t see it all there we go now I can see um so I\u0027m going to present the next update of ITF net bc testing and i think is actually i think 05 i forgot to update the number on the first slide but there there\u0027s only one changes time um so the next step okay but there are basically two new test sets in the testing draft um I didn\u0027t remove yes that\u0027s it\u0027s honestly a little see me switching yeah I\u0027m able to see the slide I can read it on the camera so there there are two new test sets on their objective to slow and objective too fast so previously we had the version one ah and so these are basically just for these obsolete at old tests am i renamed instead of calling it objective 1.1 i renamed it to slow and fast just or less confusion which reflects what they are they\u0027re basis of just the same ways to previous test sets where a slow has the very high resolution 4k videos and twice as many videos total as fast as the next slide um the biggest difference with between these test sets and the previous ones is that these new ones have HDR material arm in the test sets the HDR materials at all resolutions all the way up from 360 to 4k um it\u0027s encoded in HDR 10 compatible format which is basically a su 2084 with the thousand at peak brightness and they\u0027re stored a Timbit sample depth um that means that these all these tests tests even the fest will now have 10 bit samples in them which means that you can only use these test sets if your codec supports tended oh that it does the probably the biggest change here so luckily the ones we\u0027re testing do so next slide um so dollar difference is that we\u0027ve added 240p content to both test sets arm so we basically didn\u0027t have with people were concerned we\u0027d have enough coverage of really low resolution for example very low bitrate cellphone streaming for YouTube in similar use cases um so we added a 6 240 p clips we also because of these these were small resolutions being much much faster than code than the fast big resolutions we decided to extend them to 100 previously limited 60 frames to now 120 frames in length which is also the iframe interval with the limitation on the hook length is mostly a a CPU optimization so we don\u0027t spend a whole lot of time to ion because the longest "
  },
  {
    "startTime": "00:31:18",
    "text": "video basically limits how long the test takes so for the small videos we\u0027re not limited by the time they take so we increase the length under 20 frames next slide um there\u0027s our small tamal provements shields to had a gray for a minute um so that that bug has been fixed on the new version of it isn\u0027t it Tessa um the other thing is a couple other videos have been switched around so that objective to slow as is a complete superset of objective too fast meaning that it only adds video is too effective too fast previously with objective one there were some differences between the videos like objective one fast had some videos in 420 format and objective 11.1 the slow one had videos in four before format so now the format\u0027s it had matched and you can basically if you can run a vector too fast and potentially run the slow version just by running the missing videos which is a convenient feature it\u0027s not implemented in our compressor tour any implementations yet but is something we can do in the future um I list the end of my presentation so it\u0027s just a purely two new test sets and the old tests also remain defined in the testing document for people who are already using them but these ones are intended to replace them okay any questions a silly question but I noticed that all your things even seem to either be 4 by 3 or 16 by 9 aspect ratio nonee need to test things that are weird aspect ratios um so actually all all of them are 69 the clips that weren\u0027t originally 69 have been crop is to create a 16-9 resolution arm basically the weird aspect ratios uh what they what they have is different order effects for example right because your video codec is limited to say 64 x 64 blocks with different aspects ratios you\u0027ll end up with blocks outside of the picture proportionally and you\u0027ll have to do weird edge of that I you know specialists often encoder um that\u0027s actually mostly covered by all the different resolutions especially some of the 240 clip sorta resolution where they are partial block sizes so that effect is harder comfortable just by having different resolutions I don\u0027t believe there are any other major aspect ratio dependent effects until unless you get into extreme long or wide aspect ratios alright "
  },
  {
    "startTime": "00:34:24",
    "text": "Steve Otto just this may be jumping ahead a little as we look forward to a working group last call i\u0027m wondering if it makes sense on this document to hold off publication until we\u0027re getting close to finalizing the credit specification itself since you might end up deciding you need to do more expensive tests and we now envision I yeah I do i do think that\u0027s a concern i like you know that this talking has been up you know iteratively updated um but I the dollar concerns I edit the test document does have a spot for a very expensive like moss score testing however that\u0027s not really been used so it\u0027s it\u0027s it\u0027s quite likely that there may need to be adjustments made in that part of the document when we actually run one so that I would be a concern for you know finalizing it right now I don\u0027t see any harm in leaving it in drafts that is a while longer so so that if there\u0027s any other opinions on if we progress the test document or if we just let our main work with back uniform for longer until the FedEx or what have any other opinions on that vary from Mozilla arm I basically the same opinion I think it\u0027s fine to leave it open don\u0027t see any real harm to it we also someone in the virtual queue hi Reynold just Mozilla I think it\u0027s fine to keep it open as agree with tim i also just one thing on the previous discussion of the the sizes I\u0027m just wondering whether it makes any sense to have at least a case where it\u0027s smaller than where the total width of our total height is smaller than one large male 64 x 64 macroblock the 240 case probably does not cover that and that\u0027s the question to the critic people I don\u0027t know what the answer is senator from Missoula so I think that\u0027s a reasonable thing to use in regression testing I\u0027m not sure it\u0027s that useful in quality performance testing that\u0027s a reasonable I agree before so I thought I\u0027d mention it thanks okay so it seems like that some support for leading the testing draft open and not not trying to progress it now is is there anyone that feels we should progress it now "
  },
  {
    "startTime": "00:37:29",
    "text": "I\u0027m also fine with leaving to this draft free right now until we finalize the subjective testing bits the only counter-argument I believe it get it if you get it done that means it\u0027s not picking up you can get this document this working group last all is in distracting attention how there were less balls and maybe you have more cycles in to finish them but I mean if you think that the process of finishing the Codex is going to discover and then the other counter-argument to be having a moving target for what the products of the art being tested as I evaluate them might be harder go to developers but I mean so I mean I think there\u0027s there\u0027s some benefit to getting it done and so that is a that\u0027s one more document that\u0027s not hanging fire and two it\u0027s a fixed point for the product developers to target target sku young though there is a middle ground potentially right which is to go through a working people estaba can not submitted for publication right away then you could be open issues as they come along later but you still know that you have something sexist on the test that you have already there if we intend to continually update it Thomas if that\u0027s your intent but you think there\u0027s going to be some subset of changes coming in over you know over the next several months then you\u0027re not all so violently try to push it for publication on the other hand you\u0027re you\u0027re pretty sure that you know it\u0027s it\u0027s ninety-nine percent done and that anything would just be minor updates you know editorial level updates are just adding a few more test sets any few more tests clips you know that would be in material too that\u0027s one in how we publish it now or later then out so we go ahead and do it now like it\u0027s really as editor what do you think is the likelihood of love dates here subscene the violence so I think I have done um I have so far for each of the last meetings I think there\u0027s been a fairly large update but mostly it\u0027s been bought awarding changes but I I would actually consider the addition of test clips a very large update because I get directly changes the results you get from the testing draft i mean i think i think that the larger most likely thing that happened would be there for a new ver new set of test clips to be added for some special case the and then also the subjective test the in section potentially changing so i mean if you you know if you if you don\u0027t consider adding not you know testing clips to be a large change then you know we could publish it but if you don\u0027t want to go into working group us called the potential for that then would have probably make sense to hold off I don\u0027t think want to publish stuff just "
  },
  {
    "startTime": "00:40:30",
    "text": "to publish stuff so it sounds like there\u0027s really no strong opinion on on progressing it now no strong opinion favoring progressing it now I heard a pretty weak opinion from Jonathan the self questioning whether or not you really believe that so I think we\u0027ll keep this document open and I don\u0027t think about you to do a last call on it is if we intended progressive later anyway it just replace the pork so probably will will progress the requirements first and will create a new milestone if we have to for the testing got there they both want the nervous a mouse tonight feel free to make your updates Thomas okay anything else on testing all right thank you so ok so the next item will have a Steiner give us an update on the floor codec I have two topics today I\u0027ll go through the changes in forces last meeting it\u0027s not a long list yeah it\u0027s a better and I will go through an update on the performance I have the new data using our request yet previously we have been using an internal cisco test so i think it\u0027s about time to make a switch to what we have agreed on to use in this work moving on to the first slide the new things in info i\u0027ve added support for monochrome video which was a trivial thing to add and also added support for 42 chroma sampling which i need to rebuild head it\u0027s actually encoded them as 444 internally which means that it\u0027s very simple to implement them code remains clean and simple we don\u0027t have to be concerned about from the aspect ratio or rectangular blocks the downside is that it likely gives us a problem of compression I don\u0027t know how much because I didn\u0027t do it the proper way [Music] but I think perhaps 422 is a corner case one use case is interlaced video which is an analog eight years old compression technique and we might belong to "
  },
  {
    "startTime": "00:43:31",
    "text": "something better now I perhaps so I think some sensors will give you four to two but again unless somebody can come up with I really use case for this I would be reluctant to add a lot of complexity in the encoder and decoder for a corner case so my suggestion is to just keep it as I did for now and I also made some changes to the C of F equals fellow past picture some improvements there which gave point four per cents PDR gain in the high complexity setting there\u0027s a question as well sir thomas is there any 42 content in the testing draft easy i think it is at least in the latest test set thomasville now let\u0027s talk Randall\u0027s question first and we\u0027ll get Thomas dancer sure mind on the same issue I\u0027ll note that currently we\u0027re weird C code both in chrome and firefox is very heavily 422 oriented in fact it\u0027s all four to two so just a note when you\u0027re in front 20 or 40 to 42 I believe now that I think that\u0027s probably a 420 420 may be here but when reporting stats for two hours probably yes for probably four to 0 in case it\u0027s not for 44 and so the question is how suboptimal is a compression um as I said I don\u0027t know because then I would have to implement the proper bait yeah on Centurions or not jumping I\u0027m sorry input yep Tim territorial one way to actually test that would be to take another codec which does implement it the quote-unquote proper way and see how much difference it makes there and it\u0027s probably seen the same ballpark enjoy yeah I haven\u0027t done that but it would give an indication i agree and a test set clumsy is a 4 4 4 and 4 20 there is no for 22 in the test set okay so it\u0027s not something that you think you should add um if we\u0027re going to support for two who yes but the the the main use cases for 42 are generally legacy broadcast applications which are not nearly as rate-sensitive in general so something we could add but i would "
  },
  {
    "startTime": "00:46:35",
    "text": "actually me one remember go ahead yeah i would actually be a pretty comfortable with that being you know heavy maybe that part of just regression testing or maybe one or two clips that are 42 just to make sure it\u0027s not totally broken if we want to support it but does anyone remember what their requirements s about partition yes I think tourism thank you to mention that good is yeah can you hear me yeah okay yes exactly so I was going to say that in the requirements we do have a mention of 422 requirement but no I agree completely with Thomas that the reason that it\u0027s there is for legacy broadcast applications so i think that it\u0027s something that we need to support but doesn\u0027t have to be optimally supported i think that most of the material will be 420 in for 44 in 42 as Thomas says we should have you know one or two streams just to make sure that nothing is broken but I\u0027m I think we\u0027re okay with having itself optimally supported ok then I\u0027ll live on and they are they are various fixes in for for instance there was a bug in the chromatin luma code in the high big that case we have the fixes for increased Portability and also we have a code that has been taken from for and put into a v1 codec and whenever that code has been updated in any one none and try to take that back in before so i won\u0027t i would like to keep common code and sync know so i\u0027ll give some details on the change in sea of the earth see if f has been percentage I because I\u0027m not going to repeat that but seals just reminding that C of F is no future it will modify the pixels by a delta which is calculated using the surrounding pixels it used to be six pixels that has been increased to eight pixels and also the filter has click function which is restricting the amount of change that the pixel can change and that has been modified as well it used to be a pure code function taking the difference on strength of the future and if the "
  },
  {
    "startTime": "00:49:35",
    "text": "difference most larger than the strength will return the strength an improvement of that is to change the function so that if the difference is very large then we don\u0027t want to modify that version we will want to leave the image and changed so that\u0027s what\u0027s been done like this on this side I try to illustrate the new function um it can have three different strengths and that\u0027s what the plot shows are the strengths can be either 12 or it\u0027s possible little bit hard to see on the image here but we have you have the hard resolution screen so perhaps you can see and so water has been added is a ramp down dates so in this case in this example if the difference is more than 32 we will not change the pixel and if the values are between the strength and and 32 it will ramp down gradually and the function takes now takes another argument which is the zero point that we have so but zero point will change depending on the quality so if the polity is high we want this deeper ramp down and also if we are encoding chroma with rant on this deeper so this adds some new complexity but it\u0027s still quite simple to implement itself Cindy friendly everything can be computed using eight bits lanes meaning that if you have a DX two instructions that you can do duty inter on 32 pixels in parallel next time so moving on to the next topic I have run some experiments using the RV compressed schedule I I wanted to include x265 as well ah but for some reason I didn\u0027t get that your orchids you can get it working at some later in the build so I only have four compared to 81 and it\u0027s I think it\u0027s useful to have an update on this since we have switched I have switched the test sequences the old sets used to be pretty video conferencing centric so there\u0027s now a much wider set of sequences another difference is that I used to have clips with 10 seconds of video now "
  },
  {
    "startTime": "00:52:36",
    "text": "it\u0027s one second it means that it is it shows much more than in track performance and luxury that\u0027s very useful but I guess magmatic reasons we decide to be short it\u0027s using the objective one set which Thomas said this is now updated I I try to use the new one but it can now add four doesn\u0027t support resolutions that are not multiple of 16 and I hadn\u0027t time to fix that so I had to use the old that\u0027s set and there has been quite a lot of activity in maybe one recently so it would be interesting to see how far compares now and what I found was that 81 now generally at least on average becomes better than poor it used to be somewhat worse that\u0027s compression but then again it was something that was very very close to be benign so anyone has progressed the Hammond memory improvement in everyone the new tools I think for still seems to be slightly better at video conferencing in low delay configurations so salty the meeting rooms and talking heads for performs pretty well Ramage Ariz one reason for that might be for having fo has 120 x 128 blocks weeks which helps in quite a quite a lot with these sequences on the other hand everyone is much better than four at screen content and the main reason for that is in usual in anyone under the palatal which helps a lot for some sequences and when I did this testing I discovered that everyone seems to have a three to four times B the lunches or before in the air compressed at service compared to what we have a I couldn\u0027t figure out why that was the reason whether that was because of compile options or different architectures and and so on so we should probably focus on the compression and I\u0027m not so much on the speed in the capacity that I did and you\u0027ll also see that resilience which is the only thing that\u0027s for support he has a significant cost the default mode I mean everyone is not to be errors in it meaning that if you lose some data then you can\u0027t really be called anything until you get an intro update Charlie everyone is a moving targets and as we speak new tools "
  },
  {
    "startTime": "00:55:36",
    "text": "are being added and in the queue next month\u0027s we\u0027ll probably see a ten percent improvement have seen more next slide so this shows poor compared to a the one and as before I have DD rate on the x-axis and the frame rate on the y-axis but you should probably focus on the x-axis and for is to the right here and either one is to the left under its let it states the the better side so we see with Aaron silence on a day one is on average about forty five percent better in compression as i said i wanted to have x265 here i would expect x265 to be so much in the right about these lines but [Music] unless at leasts unless x264 head improved a lot over the past year also and if we want the next time we will see what happens if we want at least you jump to what happens if we discard the recipient requirements in that case a one is almost ten percent better and if we move on to the hybrid a configuration then also everyone is almost ten percent better and finally we switch off the resilience next slide then everyone is something like eleven or twelve percent better on average but I have to add that there is a lot of difference between the sequences so on this slide we see for instance the Wikipedia sequence everyone is able to slash the bitrate by eighty percent complete before and I think that\u0027s mainly because some people are true but on the other hand sequences like kerline and also the video sequences which are the video conferencing back door is performing very good this is by the way low complexity and and a high high delay and for some reason for the hospital loans or some chroma and also on SC which is not the case in lonely if it is not because it\u0027s ten percent there SM is also about ten "
  },
  {
    "startTime": "00:58:39",
    "text": "percent so I need your ops why this is happening okay so my final slide um one quick point is since we\u0027re deciding to keep the testing graph to open it is a thing to consider you know other standards have broken out the screen content or in general different classes of content that they are expected to have wildly different results so maybe it\u0027s worth in the test expect to consider breaking out screen content if the results really do skew things to make them almost incomparable maybe that\u0027s worth considering for future versions of interesting document on the reports that we get from other contests that there is a categorical screen content at least 1080p screen content but I\u0027m not sure which sequences that included probably include sub the Wikipedia sequence I think that sequence alone makes a few percent of global yeah that\u0027s that\u0027s with the biasing metrics so this is hansel what next you don\u0027t have a fixed BAM harm for is still using the variable length and holding and I think the expectation or animal and codec is that it should have our if that decoding so one possible solution to that is to use the dollar and sugar colder and in that case perhaps is more correct talk of emerged of four and dollar since the entropy Qadri\u0027s exactly a very core of a codec I don\u0027t really know how much game that Woodson gave the I think we will see info is pretty good but again I I think should be taken seriously probably need something and another thing that could be Donell is to not see of death abdallah the ring and that has actually the dumb in everyone so much of that work is already done and again this will take the work in the script to work towards an inertial dollar I\u0027m doing and since the visuals have already been adopted in everyone so on his part public take us close to the sub settle everyone whore well actually it might be more correct to say that it\u0027s a bomb that has moved towards what we domain net diseases so much of the work that we are done here has been now been adopted in anyone all the troops 14 already in 81 rv7 bit interpolation "
  },
  {
    "startTime": "01:01:39",
    "text": "filters need sum of the coefficients from those filters a man dressed work based on what will happen for I quantization matrices Delta Q everything is now adopted in very warm so that\u0027s what I have it somebody has any opinions on how we should progress with the code at perkins speak up does it make sense to have emerged to me I think it\u0027s probably a good idea to see things convert in some way or another yeah sanitaryware from Missoula so I still have my my patches to integrate the da lench we go Dorinda thora dust off help you out with that I think it\u0027s changed quite a bit since then but I don\u0027t that that was one year ago wasn\u0027t it so i think we based in yes he\u0027s either remind the workgroup that the output of this is intended to be a single specification for the codec so we\u0027re not going to progress multiple codex we\u0027re not going to look for multiple candidates we we want a single interoperable codec at the end of this work so anything that can be done to help merge things i think would be a big benefit anything else oh by the way john mark is going to say a bit more about out Mitchell yeah I me valla de all right next up is your mark give a doll update and see that filter yep so there wasn\u0027t very much to do in terms of update on della itself so what I\u0027m going to present here is the constrained directional and has been filters EF that Steiner was talking about next slide please so first so Steiner explained what CL PF was like so brief reminder of what the direction the dolla directional joining filter was it\u0027s a filter that operates on a by eight blocks it works first by estimating the direction the main direction in each eight by eight block this is done only for luma then it uses a conditional replacement filter so the filter is kind of similar to the CLP f function except that there is "
  },
  {
    "startTime": "01:04:40",
    "text": "no Graham down it goes to zero abruptly and that filter is first apply along the direction that was found by the direction estimation and it is followed by a second filter that filters across the lines that are filtered by the first filter to remove air remaining ringing artifacts soand Allah we used a global frame level strand that was quality dependent and then each super block so each 16s or each 64 x 64 superblock would signal a strength of Dressman compared to the global frame level we were using for different values including one value that would be simply turn off the filter so that\u0027s how things work in dalla and originally in 81 when we have during the experiment it looks like so now we\u0027ve actually merged the dollar range filter with cl PF the result is this cdef proposal so it merges the two into a single filter basically by replacing the second during the second foot the second conditional replacement filter india ringing that gets replaced by CL PF so the resulting complexity is pretty similar to the original during proposal it\u0027s just slightly higher not very much the results on the other hand they exceed both during and Sylvia alone and they also they also exceed a cascading of during and CRPF done independently the signaling is still done on 64 x 64 blocks this time we can actually select the number of different strands we have we can pick ones trends for the entire frame or pick two four or eight and these are still signaled with super block level sly in terms of results these this is what we got with with our weak impressed yet on objective one fast we\u0027ve tested both real-time and non-real-time configurations what we can see in the result table below is the best results we got were in the low latency CPU equals CPU used equals four that\u0027s 481 that\u0027s essentially a lower complexity setting that\u0027s where we get the best results mostly because low latency is not using the frames which do some kind of averaging in noise reduction and it "
  },
  {
    "startTime": "01:07:41",
    "text": "appears that also lower complexity creates more artifacts oh there\u0027s more work to do for Brian enhancements poker but even that will highlight busy very high complexity we\u0027re still around two percent improvement in yes our next like in terms of complexity right now at the highest complexity settings cdef is adding less than 1% to the encoder complexity at lower at lower complexity setting that is still adding ten to thirty percent of anyone the exact settings but that is not very hard to reduce on the decoder side the complexity increase is on the order of twelve percent but we\u0027re still working on more optimizations to do there we\u0027re expecting to get more into the six to eight percent in terms of hardware line buffers which harder people care about it has been reduced now down to six lines which was what the original uranium filter proposal was using and for certain strategy right now we\u0027re using the first one which is the whole frame optimization but it\u0027s possible to simply select to pre-select some some strands to look at for a frame and just only search that then this is how it was implemented in dalla and that worked fairly well so it should also work with a CDF proposal next light and so what we have left to do mostly first we need a perceptual distortion metric right now c d e f has a bit of a tendency to blur to blur details in textured areas so we need to have the better encoder decisions to use lower strength in these areas we have yet to apply entropy coding to the strength so that should help us reduce the signaling over head slightly and last step is we probably to optimize interaction with other tools because if we\u0027re able to reduce ringing then you can configure other tools to get better quality by and allow more ringing which will then give you so there\u0027s still somewhere to do an integration there that\u0027s like and so here we have I think it should show up on the projector comparison of with the kind of during that can be applied here this is an example with a load like we see at low complexity so a case where we "
  },
  {
    "startTime": "01:10:43",
    "text": "see the most different you can clip maybe back and forth between the decides CDF disabled and this is enabled that\u0027s it your questions so I\u0027ll just say it\u0027s a great to see emerge of some of the ideas I think that was the whole spirit of of the work that we intended to have done here so I\u0027m good to see that the thorn dalla teams are working together and getting some of the common tools marched together and the results are are pretty good too and I don\u0027t know if people notice they\u0027re not go back to a particular slide here this is what actually surprised me that the the results are you know I thinking I think some are even had a lot to ten percent performance improvement when you use faster settings when you\u0027re trying to do real time I think that\u0027s a significant advantage for this filter that if they can if it can really help to improve the quality of the video visually and objectively when you\u0027re in time crunches it allow the coda to take corners in other areas and hopefully achieve real time it\u0027s one of the main differences I see between lot of the other work and other bodies and work we\u0027re doing here in the ITF a RT area who cares a lot about real-time encoding and you know some of the other video standards are much more focused on offline streaming so they only care about decoding speed but never real-time encoding I think this is a really great tool for for improving the cases where you\u0027re under real-time encoding constraints you can really take corners and still make up the difference with this filter all right thank you so the other questions or comments before we close then a little early today get 15 minutes back has anybody missing signing a blue sheets anyone else need blue sheets all right thank you very much "
  },
  {
    "startTime": "01:14:07",
    "text": "[Music] [Music] thanks for sticking for whole time when you were talking and yeah just for them anything nothing burned down knowing right now you when I step yeah I\u0027m sorry yeah sure mouse knows this yes I need the update so I\u0027m quickly what\u0027s speculatively changing the other one input and important and then miles don\u0027t have those do been trying to get input sooner you "
  }
]