[
  {
    "startTime": "00:00:05",
    "text": "so close I'd I'd rather not have to share this by myself I mean man can somebody where the hell did the option go to share the deck from the from Meet Echo that's still there chairs any chairs can help me out it's the one next to the hand raised near on the left hand side oh share preloaded side thank you there's a Ted who was that that was Ted thank you Ted there we go head in the sky all right so it might be the closest you come to being ceiling fan I'm just going to warn you that so much coffee this morning duck out for a minute during a talk maybe one of those days yes ah well it is it is 1001 so we could get started or we could wait a few minutes we'll get the the note well up there you guys know what this is about additionally note that this session is being recorded whether you are wearing a"
  },
  {
    "startTime": "00:02:01",
    "text": "red lanyard or not um I mean I can try speaking a little bit closer okay all right yeah so just note that this session is being recorded regardless of the color of your lanyard some useful tips on the slide are we starting then all right well we're starting then um yeah can you back up to the earlier slides please so uh thanks everybody who bravely made it to the room on Friday morning um appreciate the turnout and thanks to everybody online as well in your own home time zone um yeah next slide I did want to make note of the note well this is still an ietf meeting even if it is a Friday morning how do I really feel thanks um and yes we are still wearing masks um so please keep your mask on um and keep your mask on at the mic and as somebody else said in another session um unless you're standing on the pink X over here please keep your mask on um right I think we know the drill in next slide um yeah if you have all of the resources here's the agenda for today um I think we have a volunteer Note Taker in the shape of Chris lemons thank you um but don't let that stop anybody else from getting into the shared document and helping out yeah in particular during Chris's presentation um but also to help make sure that we capture names and details and whatnot right um any batches to the agenda"
  },
  {
    "startTime": "00:04:06",
    "text": "not hearing any bashes to the agenda everyone caught up on their email anything cool happening on Facebook anyone anyone okay then we will chug right along in the agenda to uh first up is the Ops cons document um was that Jake or Spencer who's doing the update oh okay um and just a word about this agenda item we uh working group glass called this document a while ago it's been through ietf last call and is now continuing to get um comments from the isg so this is an update on what has happened since you last saw it last week you know I'm Spencer Dawkins and um without a mask is okay yeah um and uh good morning um this is going to go either really fast or really slow um I don't know asking for a show of hands is the right thing to do on who has read the draft Dash 11 especially diffs compared to dash 10 ah excellent Jake is ready"
  },
  {
    "startTime": "00:06:01",
    "text": "so okay so uh that that uh does imply something about uh how you know uh things going forward uh next slide please one moment okay too many things at once cool um so just in case you've forgotten uh where we've been since uh dash 10 went to ITF last call uh so we had uh 21 GitHub issues created most were from area review team reviewers um and uh very soon after that we were on an isg ballot like the next telechat and we got two yes ballots which is and 10 no objection ballots which is not surprising and uh one discuss ballot which uh we can talk about in more detail um that created nine GitHub issues basically one per ad with comments or discuss uh positions and um so actually most of the comments that we've been getting have been from the review teams comments that uh we were still working on when we hit the isg uh total chat and a number of the ballots on the ISD tells that were please address the comments from my area team reviewer so no surprise there so we got Dash 11 uh submitted the last day well basically as of the uh internet draft cutoff so that's basically where we've gotten on GitHub comment resolution we have a few more a small number of issues that have been addressed in GitHub dash 12 is not submit been submitted yet because we"
  },
  {
    "startTime": "00:08:00",
    "text": "you know we submitted Dash 11 at the beginning of the week and we have two issues that remain open just from lack of time to work on them I I don't think either one of them are particularly big and the editor's plan is to address the two the last two issues and submit Dash 12. I could stop for objections oh yeah you didn't want me to Advance live well I mean anything is fine you know uh yeah go ahead and please yeah uh so this is a high level description of what changed between dash 10 and 11 and if you bring up the uh drafting the data tracker and look at the diff from H uh dashed into a dash 11. um you'll see you'll see this um the two things that I think are worth um mentioning are well the three things are highlighted here either in what started out as yellow or in uh purple text so we synchronize the abstract and introduction sections because our intention was to keep these uh keep these synchronized but we did have a couple of changes that were made in one place and not the other so that got significantly better we added a lot of definitions and scoping text and honestly uh a significant number of the the comments that we got uh familiar review teams and things like that were I don't understand if this is in scope for whatever the definition of this is and part of that is because um they were asking about specific use cases and so we were trying to make that clearer and you know one of the other things is"
  },
  {
    "startTime": "00:10:00",
    "text": "that we did have some text that seemed helpful to say about RTP but that took us a little bit out of the general purpose streaming uh video and media that we were talking about in most of the document um so that we added some notes about video bit rates and explaining what was going on there or maybe a little bit better in the section that talked about video bit rates um we had some questions we had some comments about uh the definition of Baseline for people who are monitoring because our advice was to say notice when things change from what you expect to see and try to make it clear that we're not thinking oh this is uh constantly you know uh constant bitrate video or anything like that you know so you know we're expecting fluctuations but if there's three times as much traffic there today as you thought there was yesterday uh that might be worth knowing noticing we cut a lot of the details about unpredictable usage profiles to be honest that this was something that God added early in the draft and grew as things went along um we were you know we started out talking I started out talking about uh issues with sudden growth of peer-to-peer networking in certain uh access networks and things like that um it grew to include observations about the pandemic and things like that and then it referenced the IAB Workshop that was talking about the impact of covet and things like that on networks"
  },
  {
    "startTime": "00:12:02",
    "text": "so we cut a lot at the early details out and I think it's I should say here and I should probably say several times during the discussion that uh the draft is better for these comments um so that we added some background about adaptive bitrate streaming um which um if you if you're not coming at this from the streaming streaming media Community you may not have that background and we were like I say we're just trying to describe at a high level what adaptive bitrite streaming is before we start talking about its effects we added uh competing goals text for personalized ad insertion and this is um this was in response to Romans uh discuss the only discussed belt that we had um and this the topic of personalized ad insertion came up during the sector review which was actually submitted after the isg telechat where this was valid and that's fine so like I say we were working on that and we'll um I think I well I'll wait to give an update on that until we get to the last slide I think I basically re so I basically rewrote section six uh which was talking about the effect of uh transport protocols and I added the idea of media transport protocols at the beginning at the beginning of section six um we can talk about that but uh it seemed like it seemed like a helpful thing to me because we had protocols that might be um right underneath the media or it"
  },
  {
    "startTime": "00:14:03",
    "text": "might be underneath another protocol that was right underneath media all the way down so trying to be clear about what the first protocol was that was right underneath media and a protocol stack and everything else is what that's trying to get at we provided a number of clarifications about media encryption about tunneling and about vpns and about several other things and I think that's section seven um and uh we made so so so so many additions in the acknowledgment session uh the next slide is uh would would show you what that looked like so yeah um we got comments and the you know if the point was to get comments we got comments and um these are the people who commented um next slide please so the editors take on the path forward is to ask the working group to object to any problematic changes soon please pay special attention to the changes that are in color on slide three uh they are the they are the ones that um probably have the most likelihood of surprising people in the working group and then to address the last two issues and submit-12 to ask Roman if we have addressed his discussed comments this is yeah Jake you want to say a word about this"
  },
  {
    "startTime": "00:16:05",
    "text": "sure Jay Colin uh yeah uh cornered Roman on his way out uh the plenary yesterday or day before I guess uh he said that uh uh he's you know very busy guy uh has had trouble uh wrapping this up he got a little hung up because he is trying to propose text um there's like uh some subtle he wasn't able to uh cover he had lost contacts with some of his other responsibilities at the moment but he's uh working on some texts that he wants to suggest for uh for finishing up his discuss comments so uh but he said uh he thinks it's addressable and and is uh trying to get there he said Eric's been poking him every few days and doing the right thing and he just hasn't quite got to it yet so I'm anticipating eagerly uh getting that wrap up could we give a Short Round of Applause for Eric uh cornering Robin and uh one of the advantages of coming to the ietf in person is that you can actually Corner area directors between uh the stage on West United and the restrooms and bars um then asking Eric to approve dash 12 ish and forward to the RFC editor asking for your thoughts um I would ask the chairs how you guys want to handle discussion on this because this could be really short or really long in the rooming or are yeah I mean I mean now yeah so I would say that if there are any comments or questions that in the room it'd be good to at least surface them now and we can see how long that will"
  },
  {
    "startTime": "00:18:01",
    "text": "actually take it doesn't look like the caffeine has hit the bloodstream yet um I did make a note to send to the mailing list to say to follow up your particular points about checking the document especially the highlighted items in this slide deck um so if there aren't any other comments in the room there will be another bite at the Apple on the mailing list to which I'm sure you're all subscribed because that would be the right thing to do um actually so Kyle is presenting uh just like I said the deaf between Dash 2 and dash 11. and if you want to just kind of fly through that at a relatively slow rate uh we give up people ideas about what changed and what didn't so um and like I said I because you can just kind of slide through but there's a there's a lot of text that did not change it's not what he's showing right now um yeah see there's a lot of stuff that didn't change and there's there's some say there's a lot of stuff that was deleted uh especially the stuff in section six and the stuff in um is that section three or four on uh unpredictable usage profiles uh a lot of deletions in both of those so like I said there's there's a significant number of words that changed um almost all of these were done in conjunction with reviewers that I think there is I think there's one isg member that I did not have a GitHub uh id4 and uh everybody else is tagged in the conversation so uh it's not like uh Jake and Ali and I went off in a corner"
  },
  {
    "startTime": "00:20:01",
    "text": "and just started typing but so this is actually had eyes on it just maybe not the working groups Eric yeah Eric wink as an Ade so thank you for all the change as you have seen on the diff yeah they are not small change I've read to them it's mostly editorial clarification so that's not really deserve another last call because you change nothing substantial techniques to extension but I would really encourage this working group to review the document while we still can change it to revert some change sure sure yeah and like I said we've still got two issues to resolve uh better that are in GitHub um Jake has started uh reminding me that um at this point with the document having left the working group we should be trying to respond to comments uh rather than trying to continue to evolve the document so um that is all he has also encouraged me to behave and uh I'm doing my best to do that as well great thank you and thank all of your co-authors as well kind of thing that we've gotten as far as we're going to this morning in this room on this topic looking around for disagreement and and if we if we are bike shedding word uh text in the document that may be a Fine Place to to stop yeah no I think as Eric said I think it's been all Improvement so far so now it's just to make sure that everybody's had their opportunity to nod and then we'll move on and declare victory all right yeah thank you and uh thank you everyone in the working group who commented and thank all the reviewers who have uh helped to improve this document great thanks Spencer all right next up we have a currently active working group document renan are you ready"
  },
  {
    "startTime": "00:22:02",
    "text": "hello can you hear me yes we can thanks Leslie um hi everyone uh my name is Arena and Krishna and I will be presenting an update to our draft uh this is a joint work with Akbar Rahman next slide please so the updates to the draft are in the abstract the introduction and section 5. we'll talk about these changes in the next few slides next slide please many thanks to Sanjay Mishra for the feedback in particular asking for clarifications in the abstract and introduction on the mailing list yesterday in the abstract we have added a couple of lines the first line specifies that we would want to discuss the expected behavior of XR applications in terms of the workload that a network operator can expect in a use case such as ours the next line specifies the service requirements that the Exxon application have in terms of the expected response times throughput resource utilization reliability and availability next slide please the updates in the abstract are further elaborated in the introduction sorry Leslie the previous slide for slide four yeah so the updates in the abstract are further elaborated in the introduction we point out that the XR traffics workload on The Operators network will have parameters that are heavy tailed making it hard to predict the resources that should be operationalized examples of such parameters include the amount of data carried in the connection connection duration burst length idle time Etc secondly we point out that service requirements of Exon applications will have qoe factors such as the need to"
  },
  {
    "startTime": "00:24:02",
    "text": "avoid motion sickness that will be unique to them next slide please so uh Section 5 is where we propose to elaborate on the abstract and introduction if the working group agrees section 5.1 will elaborate on the problem of what the network operator can expect in terms of arvr or XR traffic workload to be able to make informed decisions on resource deployment section 5.2 will elaborate on the problems of XR specific service requirements such that QA factors like motion sickness can be met by appropriate provisioning of operational resources next slide please so uh picking up the discussion from itf113 we are trying to identify issues in XR media delivery in an operational sense that would be within the scope of the mops working group and it would be great to get some pointers from the working group so for example the first issue is is offloading to the edge the only solution to deal with the problems of heat dissipation of the XR devices and The Limited battery power as they run computationally intensive tasks in our use case now our draft focuses on leveraging the edge devices but we welcome inputs from the working group that discuss other pertinent operational ways that could be Solutions secondly for the edge Computing solution for our use case what kinds of underlying technology do we envisage for example 5G or Wi-Fi how will the XR media delivery scale if we increase the number of users how to ensure that the edge servers are adequately provisioned for example how many servers what topology to connect them where to place them what capacity"
  },
  {
    "startTime": "00:26:00",
    "text": "to assign to the links Etc uh how to migrate users XR media State as they move how to operationally respond to changes in bandwidth creation and destruction of logical associations between software components Etc this of course is not an exhaustive list but we wish to prioritize the most important issues that the working group fields are appropriate for inclusion in the draft and it would be great to have everyone's feedback please so with the chairs permission we'd like to open the floor for a discussion yes please I think uh I'll I'll give people the opportunity to get in queue um and appreciative people will use the media Coq um we had some good discussion around this document uh at the last ietf um and then we sort of foundered in terms of follow-up on the list so I'd like to make sure that we that we take things in real time so go ahead please yeah you're good harina nice to meet you again hi York how are you um two two quick things um on the one on on the one hand I would have um I was I was reading through the dot and I would have loved to see some numbers um we all know on ranges or typical characteristics of of AR traffic we all know that there's many different flavors and resolutions and whatnot but I think it would be helpful to be more specific in these cases because that ultimately also governs what you can do the other comment I wanted to make is when is to the second to last bullet on this slide here migrating state so we probably want to have a careful differentiation between systems aspects um and the related protocol aspects I would expect that's just a thought just"
  },
  {
    "startTime": "00:28:03",
    "text": "yeah I agree with them they're really good points in particular we are looking for uh numbers for sure Colin so uh Colin Jennings uh I'm with Cisco and I don't normally talk about uh Cisco products but we talk about just briefly here in the context of providing you some numbers to try and answer that question so it's a product called WebEx hologram it records me as a or records a user with a set of light field cameras as a light field transmits it up to the cloud transmits it down to an AR headset and then uh you see the person sitting across the table from you as an AR hologram and it's a it's a very photorealistic system if you want to see videos of it you know Google WebEx hologram it's it's shipping to customers now so uh in the context of that uh there are you know I have specific numbers of what of what we're doing on that we can share some of those now I'll share some of those in a minute um but there are uh you know we've we've watched and followed what a lot of different uh vendors are doing in this space and I think this draft would benefit by talking about a little like I I think that now the industry's evolved enough that you can start talking about more details on how this works um so there are three major ways that we see this type of uh a XR based images and data coming across the network uh and different vendors have taken very different approaches to it I would say a bunch of vendors have gone down the texture mapped polygon approach so what they're sending is you know a bunch of polygons in the texture maps for them and the texture maps are updating with the video stream and the polygons are updating with some mesh data uh and that's a that's that's one representation we see widely used we see a representation widely used as Point clouds where you're basically sending a bunch of teeny points a huge cloud of them each point has a color you can think of it as a little teeny colored sphere when you render it and it results up that has a different data"
  },
  {
    "startTime": "00:30:01",
    "text": "characteristic so both of those have very different bandwidth and data cursors and then the third one that we use that's very popular magically Cisco some others uh is this light field approach where uh with the light field you can think of it as almost sort of You Know five-dimensional video or something like that but it is um we're trying to send the color of every ray of light going through every point in the room in every different direction and you might be like that's and so it's that's the field is this five-dimensional field and you compress it very much like you compress video everybody takes an existing video standard and extends it to do the multi-dimensional slicing approach uh so the um so I think the interesting thing on these numbers is so since we're talking using the light Fields I'm going to talk about numbers in that space you might think that that's a huge amount of data this five-dimensional space it actually has an incredible amount of redundancy in it so it compresses incredibly well we're seeing it use about 10x more than the standard video so as a very specific number of what our system is using today we're using about 30 megabits per second uh Upstream of recording the light field of a whole uh the whole image of the scene and setting it up that's a very specific metric um now on the downstream you don't need to send anywhere near as much data that you're sending to the headset because you can you the headset has a very localized point of view and you only need a small portion of the light field to make to cover everywhere that the person can move that you need to display in any reasonable amount of time of course you've got to be able to keep updating where the user's head is so you can change where that is but that reduced light field um it where we're seeing it at about 2x what the typical video of a relative thing is so there we're using about six megabits per second is is what we use on a download there now on the latencies of these things I think the draft gets really a lot of the latencies and power and you know those types of things uh very right uh however I think that it sort of occasionally confuses the issue"
  },
  {
    "startTime": "00:32:00",
    "text": "of what the update rate is like hey the screen's going to update every 15 milliseconds or um with we need that much time to update the screen you don't you just need to time your other updates with that so a lot of the latencies aren't actually as bad as they sound in the draft because you can overlap things in certain ways that make this easier um the system that we're doing has a you know end-to-end latencies that are comparable to video conferencing systems because it's very similar it goes you know up to a cloud running on AWS and then back down to an end user it will run today over uh you know we'll run it over LTE actually you don't actually really need 5G to make this work which is you know that's our experience anyway uh now some of the latencies uh the the latency is about the motion sickness and everything is very real you have to keep that well under you know the sort of 12 milliseconds that you you expressed in there but that's why people are doing all the compute on the head and the compute and battery power was a real issue to start with but as each evolution of headset and processors come out it's way less of a problem on any of the the latest generation of headsets uh so if you look at a magically two headset uh it is just it's a phenomenally better situation than it was now of course everybody wants to make the headset smaller and lighter and less battery so I'm not saying that that isn't a constant problem it always is but they won't be sort of uh changing up so I hope that helps with numbers a little bit I and I'm glad to discuss any more with those with anybody who's interested uh one bit of detail in the draft that seemed wrong to me and I sorry I didn't send an email on this but it mentions this zero point that that three that the five some of the three gpp specs are are it's reliability one and reliability two references say that they're going to do like five nines over 0.5 milliseconds I mean that's only 150 meters at the speed of light I find that very hard to believe and when I went and read those specs I couldn't find any reference to those so I suspect that those may have been there at one point in time but the"
  },
  {
    "startTime": "00:34:01",
    "text": "latest version of the specs may have moved them out so I think that we should I I think there's a lot of things in this draft that come from things 5G might have hoped could be true but not things that they were promising and the draft might confuse them a little bit we might just need to like really scan through all the numbers in the draft and make sure they actually check with the references I think some of them are maybe have become a little dated or a little bit off um yeah let me stop there thank you so and uh kicker points regarding the 3gpp reference I'll check the numbers again um and you've made fantastic points about the various devices that are available one question I had was uh have these devices been tested in outdoor environments where let's say there are clouds and and the the light is changing and those kinds of scenarios um they uh so they have not been so I was speaking only for the work I've done is and not been tested in in super outdoor environments but it has been done in classic video con like in in office rooms with like Windows All Along The Far Side where you have changing Cloud lighting and lots of stuff like that you can have very flexible you know very diverse lighting and it still works quite well but that's an advantage of the light field approach I think as you move to the um the polygon and the texture mapping approaches it's really all about your ability and look I've done a lot of work on both of those we've tried all three of these brooches before we went forward whether we did uh I I think that you end up with uh how good your depth map recovery is and obviously depth map recovery I've seen people obviously people are doing good depth map recovery on outdoor scenes but it's a lot harder than doing on a controlled lighting type environment uh so I think I I think it's one of those still you know your mileage varies widely and you get better depth and apps with more controlled lighting if you go down that approach the light field approach you're just capturing the color of the light in the room and it's like you know it's it's less dependent on uh clouds or fans spinning lights or those types of things in some other"
  },
  {
    "startTime": "00:36:00",
    "text": "systems okay great thanks Colin and and I guess um one observation is that probably um renan you're gonna have to go through the recording of this session if you didn't catch all that real time because I get the sense that there is an awful lot of depth of comment and what Colin had to say one specific question to Cullen are you suggesting that the document tees out the separate types of XR the I mean the polygons versus raster versus streaming yeah yeah I would and I'd be I'd be happy to help review as it goes along but I think that that is the reality of what's happening in the marketplace now and that people like maybe there's some other techniques out of those three but I would say that 95 of the companies work in this space and there are a credible number of companies working in this space particularly given the number of people in this room um are using one of those three I mean it's certainly you know the the vast majority um and I think that talking about that makes it easier to understand why you're seeing such different numbers from different people and it has to do with those techniques great thanks Spencer um so I'm getting up here to agree with uh everything Cohen said um but I I did want to to uh thank the authors for uh their continued sense of humor um hanging with this draft I think uh Leslie was exactly right that we had um you know the the what we're trying to describe is getting to closer to the maturity level that we actually could describe it and uh so I think that I think that this is a good time for us to push a bit further um I would say you know you'd notice that in the uh opscom draft the uh one of the uh one of the bigger changes that was there"
  },
  {
    "startTime": "00:38:03",
    "text": "rights and and things like you know and character characterizing those I think that that's a really good model to include in uh the in the uh in your draft as well and uh I'm sorry okay and uh the the last thing the last thing I would say uh the there is nothing that will help people contribute numbers as much as putting in one set of numbers and letting and letting Leslie and Kyle shop those numbers around and say is this what is this what you're seeing and if that you know if you've got that in the draft it really makes it easier for the chairs to make progress in my opinion thank you great points Spencer I agree with them great thanks so um yeah Kyle has taken himself out of queue and he's also locked the queue because we're targeting terminating this this section around quarter two but go ahead MO uh mosinati one one thing that um uh confused me when reading the draft was uh the the use case that was presented uh seemed like it was trying to be representative of of most um you know most popular use cases and then derived some requirements and and and and and conclusions from that and I don't think it really is very representative as what Colin just described very very different that what the way that the draft describes the rendering of of uh scenes and images is very very different than the system that Cohen described which I'm I'm familiar with and even even that system has morphed many times and will morph many more times that I don't think the draft could accurately capture all those permutations a better starting point"
  },
  {
    "startTime": "00:40:00",
    "text": "would be to look at how game developers the most popular game developers actually render things because that's more likely how most XR applications are going to be architecting their their entire solution from what's being done locally on device to what's being done Cloud processing and what's trying to offload somewhere in Edge in between and if you look at the things that really matter you should look at what matters to the local devices should look at what what the trends are on the local device and how that's dictating Network requirements and the the typical Trends are increased frame rates you're getting refresh rates of around 120 hertz on all new devices so that's eight millisecond refresh and it's unlikely that a lot of edge cases are going to allow eight millisecond round trip with processing involved in everything so you need to be cognizant of what the real Trends here are and that would be more useful to document than this um this I think kind of contrived use case that is deriving the other things that that the draft thinks are relevant are you basically arguing that um that there's sort of a minimum viable amount of computing required locally um to you know in order to make XR viable against motion sickness Etc I'm arguing that the draft should look at what the trends are in the industry and what matters to the XR experience and then look at the leading applications that are that are driving this and it's it's mostly gaming so sorry I guess I didn't mean if that was what you were arguing I mean is that kind of an example of the sort of thing that you're okay that that is driving those concerns yes yes okay thanks now Colin was in queue his left cue we still have a few minutes left if anybody else wants to uh add anything today I'm not seeing anybody rush to the queue"
  },
  {
    "startTime": "00:42:04",
    "text": "okay thank you very much Serena um and so I'd ask you also to note that Sanjay Mishra did send some comments on the mailing list recently so um I think that gives plenty to follow up thanks everyone thanks okay so then next up um we are switching over to related ietf work and we have a report from the hackathon which I believe Jake is going to do foreign so we were working on uh a uh so we have a a multicast quick draft uh we presented it that in about that in the quick working group um hopefully we'll get some discussion there uh we were working on an implementation at the hackathon uh that is still in progress I think we're uh we're making good progress we believe it to be possible and we've learned some some good things that have gone into updates uh to the draft that we've made so far uh we've been looking toward um thanks to Luke uh I think he's here about the uh warp server he's posted I think that would be a really good place for us to to go with that because it's the the quick multicaster after relies on server initiated data and warp uses the server-initiated data in such a way that we think we might be able to apply it and uh that will be way better than writing our own uh player also um so we're uh we're hoping to have you know some some useful demo running"
  },
  {
    "startTime": "00:44:00",
    "text": "at some point we've been working on it in the uh uh w3c multicast community group that meets uh well the working team for that's been waking meeting weekly if anybody wants to join in uh but we we also meet monthly uh just online so you can check the uh check that out anybody that wants to get in involved in that um and uh is there anything else like it's I I would say it's not done yet I wish it was further along of course uh but uh uh it's coming along we're hopeful that this is actually a plausible thing to do um we just don't have it actually run again uh any questions anybody wanted yeah I would ask if there were any questions and I would ask you if this is something that you anticipate working on for instance at the hackathon in November or or is it all gonna be done by then uh yeah it depends where it is I don't imagine everything will be done by then um like in my perfect world we'll be like debugging ABR issues at that point or something uh rather than trying to get the basic functionality running uh but yeah we so we got the draft up in maybe uh May or so I think and then uh and then we've been like uh hammering out you know bits and pieces of that kind of as time permits I think none of us are are uh this is our main project but um we would all like to see it work that I've been working on so uh we've been hacking on it when we can and uh it's not primarily a you know a media thing necessarily uh but I mean that's the use case that I have mostly so uh so that's what I'm I'm trying to hit a demo that will that will be able to do that right"
  },
  {
    "startTime": "00:46:03",
    "text": "any any questions thank you Jake all right uh other ietf work going on there is a media over quick buff this week which I'm sure many of you are also at um but Ted Hardy is here to give us a brief overview of how that went down Ted uh Howdy Folks uh thanks very much for uh the time today uh so the this was actually the second buff there was a previous off um that discussed the idea of forming this and the on the mailing list has been around for a while uh so as a second boss that was very much focused on the the chartering aspect of the discussion uh so almost all of the time was taken uh going through uh the charter and getting various improvements made into it I've just put a link to the uh the GitHub uh repo where the charter is with the current state of the charter um one of the changes uh suggested in the room and adopted in the room uh was to make sure that moq did a liaison with mops and so that and a couple of other um kind of key changes went in uh as a result of the interventions in the room if you go and look at the history for July 27th you'll see all the ones that kind of went in at that at that date are the ones that came as a result of the of the discussion uh we then went through uh the buff questions and there was uh generally speaking uh uh quite strong um agreement that forming a working group based on the the recently changed Charter uh was a good idea there are still a couple of uh issues that were unresolved in the discussion and that will need to be resolved as it goes through the iasg process um but uh I think we're anticipating that the iesg will will take it to the"
  },
  {
    "startTime": "00:48:01",
    "text": "broader Community for commentary relatively soon and I do see quite a few people in the room there that were also in that room if they want to uh to give their own Impressions or if they want to make Corrections well people are thinking about that I see that glendine is in the queue Glenn hey hey on here I'm clicking buttons and like hey so I'm going up here for live video for like at one moment for the entire ITF this week so hello everybody um Ted hey I'm I'm glad we got that connection established between Mock and uh mops and I think that's a really good thing sort of any thoughts on how we make that sort of move Beyond like into reality versus like hey let's put this in the in a charter any thoughts about how operationally we might make that really working well because a big part of mops as you know is to bring in Industry engagement um one of the things I see in the mock work that worries me a little bit is that there's some industry engagement but I like to see more industry engagements especially from professional media delivery and creation um and so how do we do it even better any thoughts um I think it's it's always a little bit easier one so uh group has been formed to convince people that it's worth their time um well something's still in the mailing list stage I think it's it's always a little bit harder to say hey you should be watching this as it as it comes into Focus um so I'm hopeful that we will get some increased engagement simply from having a charter uh approved and people knowing that we're working on uh the protocol mechanics and state machine and all of that I do agree with you that a lot of what we have right now are people who are very familiar uh with the networking side and maybe not as"
  },
  {
    "startTime": "00:50:01",
    "text": "familiar um with um the operation side or with uh the aspects of the media creation um for those those parts of the charter which are focused on on streaming so I do hope that some of the folks who do have those connections can help them bring a friend so to speak um and and go there I also anticipate that um now that we we've established that there needs to be a connection here uh that a regular Cadence of making sure that uh mops is invited to any moq interims or uh knows about uh kind of the Milestones uh that we're hitting that are maybe not the big level of Milestones of um you know sending something to the iesg but oh by the way there is an update to this document if you're not on the list uh you might want to take a um take a squint at it as it does change some things that may may be of interest so um that that's really um the usual mechanics that you get in the ITF when there's a fair amount of shared membership um and I'm I'm not really um thinking at this point that would make a big push out into um into the into the broader industry but if you think that's valuable and have ideas of how to do that please do at this point let the area directors know uh because it's still in their hands well I think you know part of and this is where the link is between Mock and mops really could work really well for everybody because part of the mission of mops is that industry linkage right trying to draw people in and so I mean the first place I sort of see a real opportunity here is when uh mock hits use case use cases are what really drives comments from the broader audience and so maybe you know us in here over here at mobs getting stuff from the mock"
  },
  {
    "startTime": "00:52:01",
    "text": "flowing in when that happens and then be able to amplify that message out and follow it back over would be something we can do together but I'm looking forward to working together great uh thanks very much I I I'm glad to hear that um and I guess one of the things we mentioned in the room just because we didn't get to any technical uh presentations or conversation uh is that we may in fact try and hold um uh some sort of interim um between now and itf-115 just to make sure that people who have who have been working on the technical aspects of moq for a while uh get a chance to share their thoughts and of course uh we'll make sure that when that gets discussed it uh that mops is is involved in um understands when it's going to happen or or the the logistics there too about just before I go is the thought Ted to make that interim hybrid or in person a lot of it depends on how fast the isg goes through the rest of the processing and what the comments are from the broader community so if if the isg and the broader Community say yeah this all looks good and we're we're ready to um to hold something that could be hybrid in let's say uh September uh then I think uh hybrid would be the right way to go because there's there's obviously a lot of energy you get when people can share um can share their ideas in real time in in a space the current reality is any any such meeting will obviously also have a remote uh uh component I mean just we're we're not at as at a situation uh either for travel for a variety of reasons or for um uh for covet to really rule that out um but I think um if it if it takes a little bit longer you know if August turns into kind of"
  },
  {
    "startTime": "00:54:02",
    "text": "um a time when very little goes on and it re the the ASG processing and Etc goes on mostly in September then we definitely be looking at uh at remote just to make sure that we would be able to um get the uh the advantage of the quicker Logistics um so that that turns into time zone math more than any other kind of logistics and that's a little it's never easy but it's a little bit easier than adding time zone math to you know finding a hotel and and making venue arrangements and doing all of that other stuff if I can put one idea out there um in order to help connect with industry um one of the things that might be good also is to be sensitive to Industry events we say September I'll point out that IBC happens in September it's a very big industry event and basically people disappear for about a week and a half during it so if they if there was overlap the ability to get industry engagement might be very difficult um during that window just FYI okay is is it something where people do things at the front and back of it though it might be useful sometimes I mean it starts just after Labor Day so like I think it's like September 10th or 11th because Labor Day is late this year and then runs over the weekend typically into into the next week so typically people do run things back on either side it depends upon the year uh and other events that are taking place and sometimes hallways so it gets very complicated sometimes a complicated month okay and and obviously it would be very quick work to try and get a uh something uh pulled together for an interim right right around Labor Day if if it was September it's more likely to be later but if you wouldn't mind sending the uh the details on CC Allen uh I will make sure that uh the the area directors get a get a hold of those um if we do ask them for an inter"
  },
  {
    "startTime": "00:56:02",
    "text": "meeting because we we can obviously also just hold a meeting without it being a full ITF meeting uh if if they haven't gone through the whole process but I'd much prefer to do everything under note well from the beginning and get all that settled um so uh that would be the intent if we can do it great thank you um I think it's time to move along on the Queue and uh Spencer yeah um so Spencer Dawkins and I just wanted to do a couple of things one was to say very clearly uh at a microphone that I thought the mock off went very well and uh appreciated very much Ted and Allen and the mock Community for that um a thing I would mention I was just following up for uh Glenn uh as he's thinking about how to talk through the uh through you know through the through the pathway to other uh operator forums and things like that is to say is to say that the Charter the last time I looked at it does have a requirements draft listed there and uh at any point the that might be very interesting for the uh operator Community to take a look at at the appropriate time thank you thank you Ted you might want to respond uh no it was actually gonna see if I could look at the Milestones quickly so I just flipped to the other window uh just to see if I could look at the set of deliverables to make sure uh that I could give the name to that um there's an architecture specification and a working group adoption of use cases and requirements uh for media delivery over quick and I think that's"
  },
  {
    "startTime": "00:58:00",
    "text": "the the one that would uh map to what uh yeah Spencer is agreeing with that Spencer Spencer was looking at so um that's definitely in in the um in the charter now I I would be a bit surprised to see the uh isg cut it in their um in their analysis of the charter but uh we'll have to see I've been surprised so many times over the past few years I just don't rule it out anymore great thanks Helen Collins I just wanted to respond to a little bit more uh data to Glenn uh I I mean it would it would definitely be great to see uh I I think there are some people I want to talk about them in a second that are operating large video networks um that are very involved with with the mock stuff I'll talk about that in a sec but it would be obviously great to have more and it would have great to have somebody like BBC or that class of development system involved though I'm not sure it's very relevant to that stuff which is why we haven't seen that group they already have good solutions to most of their problems so but still it'd be good to hear more from that sort of classic group but I mean uh you know there's three proposals right now in that draft in that or being proposed into that working group right now you know one from WebEx which is doing a billion minutes a day which is a drop in the bucket compared to what meta is doing meta looks I couldn't find recent numbers for them but several years ago they were doing six billion minutes a day so I'm sure they're doing a crop load more than that now and that's like a drop in the bucket compared to Twitch which is the third proposal in the group that's like you know you got like 2.6 million viewers live on it right now as we speak um so I think there's a fair amount of operational experience involved in that working group at some level and just wanted to pass that on thanks yeah so I don't want to put words in Glenn's mouth or anything but I think that part of the problem is that some of the people not necessarily represented uh in the industry there are not the ones operating the the big networks you mentioned but are the ones who are"
  },
  {
    "startTime": "01:00:01",
    "text": "shifting data around on IP networks for other reasons and the problem the ITF has is they don't have their own solution and we should be very afraid if they rule their own so it's as much that we should have them so kill the next level of that I'm not sure I really understood just be a little more rise so so the the point I'm trying to make is not everybody who uses IP protocols is actually involved in the ietf Shocker hasn't has been true for 20 years but um part of the point that we raised when we formed mops and everything leading up to it was the fact that there is a lot of video being shipped over IP whether or not it's in the traditionally internet oriented companies and so what we're saying now is some of those companies are still shipping video over IP um should should make use of more ietf protocols mock might be one of might be creating one of them um so it would be better if it was informed by their use cases rather than being yet another solution that works very well for those who are involved in the internet and we have more crap out there that uh sorry I have to remind myself to breathe we have more crap out there um that abuses the Internet Protocol stack as we know it so in some ways it's more our interests to make sure that we can Loop more more Industries into using the internet well than saying anything against what's going on in mock maybe that's clear yeah that's fair but can you say a little more like which class of industry or class of use cases are you thinking about I'm not asking for names of companies or anything but just sort of like what type of all the industries that are shipping around into shipping around IP for their own editing purposes and in their own workflows across across networks that are perhaps Geographic geographically diverse right right okay so that's why I mentioned like I'd love to see somebody like BBC's I mean they're an example of that right for sure they clearly do it but I work with them on a regular basis and I think that the thing is is they have a class"
  },
  {
    "startTime": "01:02:00",
    "text": "of solutions that are very applicable to their stuff and it's a very standardized area it's just not standardized at ITF and I'm not sure that what we're doing in mock it all aligns with their needs so I saw that that Glenn had his hand up again as our Tech advisor so I think I'm going to let him jump the closed Q for sure yeah for you pushing buttons um so you know you know Colin I think the the the vision I'm trying to put out here is that while there's um use cases today I think which you're right this doesn't satisfy some media use cases absolutely on the other hand media companies are really branched down to a lot of new areas and um even if they're not in that business today is one of their storefront items and I think that there may be useful connections that could be made here and ultimately what I'm really I'll I'll be very honest here I have two goals here I want to get them into the ITF because that means more participation and that means better standards and I also want them to get using ITF stuff more because that means less you know in-house Solutions and more standards which is good for everybody and I see this at the early stages since it is early stages I realize you've done a lot of work on it but it is still early stages from the itf's perspective it's a great opportunity to sort of wrangle them in make those connections and get them engaged and it won't all happen overnight and we won't get everybody in the room all at once but you know It's a Grind right and you know so anyways I hope we're I think we're I think we're totally agreeing let me know how I can help Okay well I think the biggest thing is bring a friend right so if they're people you you see that need to be in that room uh make sure that um you you encourage them make sure we know that we need to encourage them and we're definitely willing to do that thanks great I'm not seeing any other questions or comments in the room"
  },
  {
    "startTime": "01:04:00",
    "text": "so thank you very much Ted for coming along and sharing that update and engaging with us all right and next up yes next up we have Chris Lemons with an update from the CTA sbacta foreign stand up here all right all right can you hear me excellent all right I'm Chris lemons I am here on behalf at the moment of the CTA wave project and specifically the uh cmsd cat and smt working groups I just wanted to give you a general idea of some of the drafts that are coming out of that group and maybe get some cross-pollination next slide okay so first off all of these groups are all of these uh drafts are the work combined effort of the SVA and the CTA so the software video Alliance and the consumer technology Association specifically the web application video ecosystem group are working together to produce these standards talk about the common media server data common access token streaming media tracing and I'm just going to go very high level on these next slide so the common media server data is the other half of the common media client data which is published as CTA 5004 this draft is nearing completion and its job is to carry data from the origin down towards the clients whereas the cmcd specification carries data from the"
  },
  {
    "startTime": "01:06:00",
    "text": "clients upwards the goal here is to carry data that cdns can use operationally um to make decisions about how they are going to handle the data more intelligently split into two headers the cmsd static header which is data about the media object itself and the dynamic header which is data about the connection that is transferring the object next slide I am not going to go into all of the keys but I did put them up on the screen for you these are the attributes of the object and the origins response next slide same story these are the key attributes that are about the specific response and all of these are added together like proxy status and cache status into an agglutinative header next slide all right moving on to the common access token this is uh this is very similar to the URI signing token work out of the cdni working group this token is focusing on the streaming media uses very similar to what some of the work in the cvni group was doing the goal here though is to have one token that covers all of the existing industry use cases adoption is key uh we have a lot of energy in the room um a lot of different players and I am hoping I'm actually very optimistic for implementation of this uh fairly uh widely next slide okay um again not going to go through all of these but these are the claims that it has we start off with the core claims that you would expect in any cwt yes the uh token is based on cwt format and it goes usually in the URI um and then we have a bunch of General claims that are uh details about exactly"
  },
  {
    "startTime": "01:08:02",
    "text": "what uh uh what kinds of attributes of the request the token is valid for so that you can limit it to specific sorts of Uris specific methods say that this token can be used for a get but not a push and so on next slide composition claims this is somewhat new to cwts in general um was created for the uh cat and we have two kinds there the and or and nor Boolean logic claims do exactly what you expect what they say on the 10. um and they will have lists of claims inside them and so that you can do the logic on that uh we also have an encrypted claim because sometimes you don't want um certain kinds of information being stored easily readable in the URI and other information uh needs to be secret from the um uh from the holder of the URI so we have an encrypted claim as well the critical claim there is there to facilitate the encrypted claim since we have composite claims or composition claims we have to have uh implementation limits right now we've got that set about four levels of nesting and 50 list elements um but we have some more maximums that are well technically these are defined as uh implementation minimums you have to support at least this much but we know operationally that means maximum next slide action claims these are interesting in that these are claims that do not limit the utility of the token but they affect the response uh response of the verifier the renewal claim is very similar to the renewal that you'd see in the CD and I uh working group token um and it can be renewed as either a"
  },
  {
    "startTime": "01:10:01",
    "text": "cookie or a header and this allows you to specify uh the parameters on the cookie in case you want to have your cookie be something like same-site strict which is great um the if control response is still being worked on but the idea is that we want the issuer of the token to be able to set a location or a particular content code a status code to be returned when the token doesn't verify so it puts them in the driver's seat next slide moving right along we have the stream media tracing group this is a very new group of which I am one of the uh co-chairs we don't have any specification language set but we have finally settled on three major scopes for this work we have the uh Push Pull and Export model uh where the push is covering tracing all the way from uh for specifically streaming media all the way from the camera lens to the origin and keeping track of the entities that process it along the way and the latency is introduced and that sort of thing export is about taking it um off of the uh line from the uh from the camera to the viewer and sending the logs or traces to a third entity and we are looking heavily at the open Telemetry specification for that because it does that very well and so we want to use existing standards wherever possible uh for the poll um process that is in tracing in band for HTTP requests and responses and we're actually expecting that even though streaming media is our primary use case this may be something that is also fairly generalizable because HTTP is just http the goal here though is to collect and Report observational data even if it's not immediately actionable next slide"
  },
  {
    "startTime": "01:12:00",
    "text": "a number of these use agglutinative headers so these are headers like via cache status proxy status and the idea is that each entity that processes um one of these requests will add their the their name whatever they decide their name is along with the parameters that are appropriate to that particular header uh this is how these existing headers work um uh we are trying to encourage uh because we're getting a fairly reasonable number of ignitive headers one of the things we're looking at is we're trying to encourage entities to make sure they use the same name for themselves whatever they are uh when they put values in more than one of these headers at a time that'll help when the data gets exported or needs to be cross-compared for whatever reasons next slide I think I may have a few minutes left for questions indeed you do any questions you want to uh voice what you said at the mic possibly yeah sure for the common access tokens um hopefully you're not allowing those to be locked to IP addresses there's one thing that for those sorts of access tokens lots of them to IP addresses causes no end of operational pain you're right and there is a lot of text in there saying that IP addresses are uh almost useless for identifying uh people or systems and you should never use them and yet the goal is adoption and it is effectively an industry requirement so the compromise is effectively the"
  },
  {
    "startTime": "01:14:02",
    "text": "same compromise that the cdni working group took when they did the exact set when they had were faced with the exact same problem um any IP addresses that are um more specific than 24 24 56 as appropriate must be in the encrypted claims the encrypted claims are a lot more difficult to use and I'm frankly kind of hoping that no one ever needs to use them but they do exist there and uh there is a use case for them as little as I I like that it's not just a specificity issue it's also one of the biggest blockers to getting media content on IPv6 we've seen so it becomes a really big operational headache because you have a broken to get set on before and then try to be redeemed on V6 um similar things happen with things like um privacy proxies so the it may be worth looking at this might be even something for mops to look at is is there some way to be much more clear to to Industry saying no stop doing this this is this is this is a problem because I've also seen that case where some industry groups will try to say say well we'll say oh well our standard is you need to lock tokens to IP addresses and um I think having a some standards groups come out and say no don't do that you could also Point people at um might might be better than just putting them in blog post telling them not to do it yeah yeah and I agree the goal with this particular token is not to uh enforce anyone's particular business model even if that business model has very significant operational problems um we we've tried probably three or four times to remove the ability to lock tokens to IP addresses from the drafts and there are just too many people who"
  },
  {
    "startTime": "01:16:00",
    "text": "have said we won't implement this or we will Implement some variation of this uh uh regardless of what the specification says uh the uh CTA is very much like the ietf in that we don't have a police force so is I mean not not having looked at what the industry what what what the industry is doing in this area uh very closely uh has there been an attempt to uh to um sort of uh reveal and document the reasons why industry players want to use IP addresses in their claims and what better Alternatives there are uh for achieving the same goals yeah so there's a couple of really simple uh use cases that IP addresses just make really easy and a very standard and a very standard one that keeps coming up again and again is I just want to let anyone in who comes in on a 10 dot address right I trust those addresses I I don't care and so um I get it that's how their things are set up and while I don't think that that's necessarily the most robust way to do things um that is how they have it set up operationally and they have a need for that sort of capability and yes there are multiple paragraphs of text saying why this is a bad idea yeah I was more suggesting the okay this is a bad idea and here are some Alternatives I think it's the second part that may be uh that I I don't know what the status of of that is uh not not just in your draft but also in um sort of documentation of the industry has overall in this area I just don't know"
  },
  {
    "startTime": "01:18:00",
    "text": "if it's if it's something that's that people have spent a lot of time on given that hey we've got IP addresses we could just use those in our claims well I mean as operationally as was pointed out you mostly can't um uh dual stack devices devices changing their IP addresses devices that have IPv6 addresses um all of that is a significant operational concern uh entities that deploy this and expect IP address to work on the bare internet are going to disappoint their customers great not seeing any other questions or comments thank you very much Chris and if you want more information about the cdni or about the uh common access token there will be a slightly more in-depth presentation in the city of the United working group great thank you all right so next up we have Luis Contreras telling us about real world stuff so hello everyone I would like to share with all of you one initiative that we are running in in telefonica with the objective of trying to to to make the delivery of content a network aware so we are doing an exercise of integrating Alto uh is such a way that way with throughout or we can expose all these simple information that could fit the CDN logic and with that improve the the performance we I represent on behalf of my colleagues Patricia nice and Francisco as you can see this is a joint work between the transporter group and the video group and yeah I will provide the details so next slide please thank you so a little bit about about background of telefonica because it is"
  },
  {
    "startTime": "01:20:01",
    "text": "important thinking on the next steps we are telefonica is a group of different companies different operational business present in 15 countries mostly Latin America and Europe plus a tire one international carrier so we provide multiple Services as you can imagine residential mobile and so but also we have a contents that we distribute we we have contents produced by ourselves and with one several several brands like movie Star Plus and moisture play but also we deliver third party contents right we do we do this through an in-house CDN that has been developed by by the video group and this is called what I will refer to that as telephonic acidian or tcdn and this tcdn is worldwide deployed we have a you can see there the the list of countries where we have a different streamers everybody points we have in Spain Brazil Argentina Chile Colombia Peru Ecuador Mexico and the USA and we'll start we are starting to deploy as well in Germany so trying to cover all the footprint of telefonica in in order to deliver all these content uh the mechanisms for delivering is is based on HTTP adaptive streaming and this is uh used for serving either internal or external customers so so how we are delivering the content over the top so external customers to telefonica can receive as well the the this content so think you know talking a little bit about the the CDN the logic that the CDN is using for the deciding what is the streamer more convenient for a given a customer so essentially the the request protein logic that is is being used take into account the number of inputs uh the streamer health status the load level the availability of the content the cash hit radio maximization and so on so far but also and importantly and this is the topic of Interest let's say for for this presentation it's also the network"
  },
  {
    "startTime": "01:22:00",
    "text": "topology by now this network topology is fed into the CD analogy manually so somehow there is a group of people with taking into consideration what are the different prefixes of the different customers are located in the in existing points of presence of the telephonica networks and this is fed as I told you manually and and and so how this is the the the the kind of problem that we would like to to solve now this is the initial Revenue foreign for this activity in fact so how we could go in an automatic manner of maintaining these Maps uh yeah being being I mean provided in an automatic way the reason of going in in in this direction is because the different prefixes of the network can be can be changed because there are consideration of accesses of migrating for instance for DSL access to Fiverr and so so this implies that sometimes the the uh the addresses of the IP addresses are reused between different points of presence also there could be events in the network that could motivate the previous election based on this manual feeding could not be the optimal and so on so far so this is this was essentially the the driver and the motivation for this work so next slide please so the rationale of of making the tcdn transport Network aware is again to optimize the delivery so at the end what we will do is we want to do is is to have a more efficient way of uh of delivering the traffic to the customer where where this customer is so with this aesthetic view with this manual feeding of the topologies we we have these situations that cannot be controlled Network outages Network congestion the migration of the prefixes and so on so this requires a periodic and a a grade of the of these Network maps and well the what we push you essentially is to have this"
  },
  {
    "startTime": "01:24:01",
    "text": "um with a timely information in an automatic way and this is why we leverage in Alto for doing that next slide please so how can the world looks like that because it's important to understand what is let's say the playground uh for for all all all these uh work you know yeah the network on telefonica well you saw before we have so many networks in very in so many countries so there is not a common pattern but somehow this would reflect a converter that we are following at the time of Designing the telephonical networks so we divide in a number of hierarchical levels but you can see there is a kind of topology or a canonical topology that we could have in a mid-sized country so we have the hierarchical level one that represent the interconditional level for interconnecting to other Transit providers or either the tire one from telefonica but also uh other um uh Transit providers or ottps or whoever then we have the hierarchical ml2 that would be a mesh part of the network that takes essentially the traffic coming from the from the boundaries from the perineum from the transit and then distributed to the different regions and then we'll start in the topology that is covering the different regions that would be the the hierarchical level three which essentially is a kind of um a dual headings in in some regions or so depending on the size of the region for sure it could be more more than two and then we have the local level the hierarchical level four which are rep which represents basically the central offices and then hierarchical level 5 or even six that is essentially could represent the the more remote areas or the cell side routers and so connecting the the different customers so the customers are essentially as today connected in local level in the hierarchical level for hierarchical level five or could it be even connected in hierarchical level six as you can imagine not all the countries have the"
  },
  {
    "startTime": "01:26:01",
    "text": "same the same structure it's not the same as Spain as Brazil or Germany as Argentina or Chile are very different geographies and and this implies different different kind of architectures just for put in an example if you put Brazil on top of the map of Europe we will be covered in an area like from Lisbon to Moscow so it's it's different sizes that can modify somehow these canonical architecture let's move to the next slide yes just to present what could be I mean we saw before what would be a canonical architecture this is an excerpt representing uh Sonic's 16 deployment in in in in the operation in Spain and here we just represent some few notes for a hierarchical level one two one three um hierarchical level one will be represented by the Cycles Layer Two by the squares and larger three by the triangles so these represent the the upper part so from this part um below we have had the the central offices we have the the SSI routers and the remote areas and so on so far so the idea is we we have so many streamers deployed in the in the network so how do we can improve how we can maintain the the optimal delivery of the video as long as we suffer these changes in in the network again changes in the in the movement of the prefixes in the across the different Central offices changes in the in the network itself because there could be link outages or no outages or so so trying to find a mechanism to optimize this delivery in real time let's say so next slide please so how tcdn could leverage on the alto information in the information I suppose by Alto Accord in relation with the topology and so so essentially the the objective here would be to always to create a network map where we can somehow associate different prefixes to different identifiers that is are called"
  },
  {
    "startTime": "01:28:02",
    "text": "pids with us on how we can group the prefixes of the customers in the central offices the ranges the slash 24 20 or whatever um we've done I mean we create apids for for customers identifying the the prefixes of the customers and then also we generate pids Associated to the streamers in such a way that uh through this uh through these Maps we can have a a timely view of what will be the cost and the reachability between the different pids in the network so essentially how the streamers can be rich or how the streamers can reach the different customers and identifying the the cost Associated to that we will detail a little bit later but this course is easily now we are playing with a number of hops that could be some more richer information in some point on time so we are working also in attack election so what we do uh with with these Maps is to determine what will be in every time the more convenient streamer to deliver the content according to the request that is coming from the from the customer you can see there are a very simple example that we use in the lab in the in the premier steps in this work and and you can see reflected the the idea the basic idea so the pages of the streamers can correlate it with the pids of the of the customers and with that perform the the best selection let's move to the next slide please so we represent the network map and the cost map so in the network map as I told you before it's essentially the um the grouping of the different prefixes to the pids um and here this is related to the sample before so you can check later on offline and then we have the cost map that shows the reachability between the different pids so in a very straightforward manner we can select we can filter and we can select what could be the most convenient streamer for the A specific group of prefixes in the network"
  },
  {
    "startTime": "01:30:01",
    "text": "the network the network map is generated through establishing bdp session between Alto and and some root reflector in the network so with bgp we export we can advertise the preferences Associated to the to the end users in the central offices as they are being configured at the end the the preferences are associated to the BNG which is a element uh yeah and in the PPP session so the BEP is in this Central offices and the PDP is integrated with uh with the router that can the possibility of advertising these preferences so this is in one hand the the advertisement of the preferences Associated to the customers and to the streamers and then in the other hand we have that the topology itself for that we use bepls and with bgpls we can have the view of the nodes and the links connect the interconnecting the different nodes in the network inside so the final result is that we can build this cost map with essentially is the represents let's say the reachability between streamers and and users next slide please so the process for that we follow in in this integration was first to start a um the the feasibility phase in the lab so we played the with a very simplistic or a couple of very simplistic scenarios these are documented in the backup slides so you can take a look later on so uh we are starting essentially to understand the the visibility of the this mechanism for having an up-to-date view of the network so introducing outages into introducing new prefaces and so such a way that we verify that the visibility of of this exercise then we move to a pre-production lab I will provide more details later in the next slide but we move a production lab where we started to to play with real configurations in the network real situations that we could find in the network but in a more control environment so reduced number of"
  },
  {
    "startTime": "01:32:01",
    "text": "devices but the complexities of the configuration that we would face once we move to production and we are now in the point of moving into production we we are working on the deployment of Alto in in the real Network we will start with telephonic Spain a PDF moving later on to other companies in the in the group and here the point now that we are doing is trying to introduce Alto in the specific rules and processes and procedures and so that a production level implies in terms of secure securitization uh hardening all the stuff playing with the different IP addresses for connectivity within the different elements and so on so forth I will provide now more details on all these engineering steps so next slide please thank you so these are these as I provide a little bit of details about where the the engineering impact that we follow and what we what issues we faced in this process in the technology lab test as I said we started with a auto module that is present in open daylight uh this um this module was working in Italy with lldp so our first task that we do was to integrate with the bgp module of open daylight uh in this technology lab test we started playing with a monovender router scenario these routers were built for life so we were playing its own servers and so generating the issues as I mentioned before the outages of the nodes outages of the links creating new prefixes and so on so far we play with a very simplistic network with just one single igp on on top of that or SPF in that case a single autonomous system and simple metrics based on the the hop count so essentially the metric that we Associated to the AAP was just one so in such a way that we could determine the hop count and and that was what you also before in the course but they presented before and also in this setup the the"
  },
  {
    "startTime": "01:34:03",
    "text": "routers themselves some of the routers themselves were acting as Road reflectors so very simplistic setup in this case with Alto as well being beautiful eyes in that server that I mentioned before from this we move to the production Network test now the things started to change we migrated to xav as a open source bgp speaker for interacting with a real Rock reflectors in this preparation environment we in this exercise of migrating to xav we've found some issues for bdpls We rise a number of tickets you have data details you want to check these issues were basically related to bgpls at the time of parsing the information of bepls in order to build the to be able to build the the cost map okay the relationship between the pids that I mentioned before display production Network environment is a multi-mender multivender router scenario and the router vendors that are present in this in both pre-production and production Network are different to the ones from the lab test so essentially we we have tested at the end three different vendors on this setup um and this multivender scenarios is the real one because well the the production Network leverages or or is supported by the different vendors in reality these routers in the pre-production environment are physical routers we also deploy a dedicated Alto server there so no no longer vitalize on the same environment so it's just a dedicated server and then we have started with with this network that well generated a number of issues in the sense that this is a is a complex mpls Network so we don't have a Contin an IP continuity end-to-end in the different hierarchical levels that you saw at the beginning we have a hover an mpls continuity and this presents on issues at the time of integrating because well you need to to deal with different autonomous systems and of them in private for sure the public autonomous system as well and moving all"
  },
  {
    "startTime": "01:36:02",
    "text": "this information with the different vendor implementations created some let's say engineering problems that we had to resolve in order to be able to expose all the topology to I mean to the to digest let's say all the topology information by the alto server and then to expose to the uh to the telefonica CDN yeah also we started playing with more sophisticated metrics so it's dedicated in the sense that we're not just assigning a value of one for the AGP metric but playing with the real igp metrics as we could found in the in the production Network so having Richard let's say cost Maps richer values in the course map not only the Hops but playing actually with the IEP metrics there I'm finally also another point that was different to the technology lab test was the connection to different Power reflectors homegrown reflectors for vgp I mean a couple of robot inflators for vgp information uh another couple of Rob reflectors for the epls this was because it's somehow mimicking what we have in the a production Network and finally as I as I mentioned before we are in the in the pace of integrating all of this in the in the production Network so we have a in the very hard phase of the administrative issues for uh adapting to the production procedures the hardening environment as I told you before for the hardware for sure but also for the software because these are most all the pieces are coming from open source so we need to follow the internal rules of the engineering teams in the operational business units right also the one one situation that we have now in the in the real language is that we don't have a broad activation of bgpls on on that so we will start with some small region in the Network that has already activated the bgpls and from that we have started we will start growing this is not about I mean this is even a good thing for us in such a way that with that we we will be able to test also the scalability of all of this we have played in in I"
  },
  {
    "startTime": "01:38:01",
    "text": "didn't mention but in the production Network we could be start playing with 30 40 routers but in production Network we this will rise to several thousand routers so we need also to to have a view of how scalable will be the solution and this will be part of the in size that we will get once we move into the production Network that's the scalability at the end and yeah for sure this will coexist with so many services this will be also a learning process how to deal with that we don't expect any uh interference with that because at the end we are connecting to the raw reflector so we are doing nothing in in the network they are simply taking the information from the raw reflectors but okay there is always uncertainty what could be something could happen right um we expect to complete the deployment by by the end of this year and we hope to to comment in the next mobs maybe team maybe the updates on this next slide please so just for for finishing us next steps we will start with integration in telefonica as pay Network for later moving into the other countries of telephonica where we have the tcdn deployed the probably the next step will be Brazil this is something that we need to decide and again Brazil is a very uh [Music] very large challenge in the sense that there is a very big Network so and also the the topology is not so canonical as we saw before so it's it's a very good challenge that we start to face uh starting in Nigeria hopefully so apart from that we also need to complete the the full development of the tcdn logic so the idea is that the tcdn logic consumes the information that is provided by Alto so we also need to work on that on that line to let's say um how to say to refine the way in which we are interacting today with the with Alto so making more um iterating better in the in the CD and"
  },
  {
    "startTime": "01:40:01",
    "text": "logic at the end so but by now it's just a kind of proof of concept in the in this sense and yeah importantly we expect to characterize Alto performance on real environment in terms of scalability processing we will require many instances of Alpha and so this is also something that we will see once we start playing with Aldo in the in the Real Environment again because we will handle with thousands of routers so it's a a very huge Network at the end um one another line of work so by now we are working for for the topology in order to do this and enhance uh delivery and so on trying to guarantee the quality of experience but we already do foresee the next steps in the direction of integrating or enriching the the course map by introducing performance metrics for instance so understanding what are the congestion levels maybe understanding what is the latency that we do have between the different pids so enriching the decision at the end we will start by The Hop counts because it's a or igp metrics because it's the the basic stuff but we do foresee to do um yeah more advanced metrics Etc whether we couldn't reach even the the decision in the CDN also even we are considering to include Access Network information so to have some idea what could be the technology Associated to a specific prefix in in the customer side so that we could have some insight about if the customer is accessing by Fiverr or DSL or a mobile technology or whatever so next that's like this this is the the very final one so as conclusion the the objective of all of this is to make the CDN Network aware so to have the possibility of exposing Network information to applications that could leverage on that Network information to perform better and tcdn is a clear case on this respect um and yeah and we also apart from this uh integration work that we are doing we are foreseeing this next step that will"
  },
  {
    "startTime": "01:42:00",
    "text": "be to enrich the decisions incorporating these metrics that adds an additional complexity that we we we hope to report in on in some point in time and also here for for the media operational Community uh as well we would like also to ask for feedback from from mobs it will be very welcome to understand if this is useful if this is a good direction to to consider I don't know to get your your views on on this respect so you can approach directly us or even build them even more interestingly you could also use the auto working group list for for this so so how that we could discuss in a in in in in in the mailing list of Ronaldo that probably would enrich also an inference of the the guys working in in Alto as well and just let me finish with the acknowledgments to kaigao and Justin San that helped us a lot at the beginning with the technology with the lab test and the integration with odl and so and a big thank you for them for for their help and that's all from my side thank you thank you very much um so Rajiv you've been very patient would you like to ask your question hi so this is actually uh going back to the slide where you were talking about calculating the cost Maps ah yes so um I see what you've kind of done here is uh you know you basically have a couple of uh pcdn notes that the PID is ending in the five and a six and a number of customers right uh which are a lot of varies now I see that you [Music]"
  },
  {
    "startTime": "01:44:06",
    "text": "is there any specific reason why you are doing that the sound was very bad I could I couldn't get the request the video repeat the last part okay so um I see you you're calculating the cost not only of the routes from the customer endpoint to the pcdm mode you're also calculating the cost from customer to customers the customer umid03 for example yeah well this is essentially would be the the let's say the standard output of alpha so on top of this cost map so the idea would be to uh for us is not interesting at least with the integration with the CDN it's not interesting to to have the reachability between customers so this would be filtered so the The Next Step will be on top of this course map to filter and only uh retain the reachability between the um streamers and the different users so by now we will not use the user to user information so routing [Music] I couldn't get you again okay so I was just saying this cost map would go through another layer of filtering before you use it as input for your routing work yeah and my second question here is uh in the slide exactly previous to this can you move back one slide where you're allotting the CID um I'm assuming you are looking at pids not at the level of individual users but at the level of individual uh user segments so each slash 21st rather than each user"
  },
  {
    "startTime": "01:46:00",
    "text": "uh I I I'm just gonna let that assumption is today but I'm not sure if I understood the question you mean that we are looking at PID level not at the specific prefix of the customer is that yeah no I mean are you allotting the pids for each prefix for each customer sorry I couldn't understand your audio is really yeah is this is this better no not at all okay uh I will be back in a moment hopefully with better audio okay thank you I'm sorry so we can we can take uh Eric's question now so hey thanks Cisco without any yet except interested about what you are doing so thank you for the presentation the tradition as well that mobs is very different kind of point of view go to questions how often are those Maps recomputed or often can a change be done well by now this is a hello well I think Ronaldo's way of retrieving the map so deep I mean the CDM will ask no I mean we have not specified a frequency for these updates so budobe I mean this is not yet uh considered at all but we don't expect a continuous update of the of the of the statement so take into account how we are uh now with the manual procedure we also have a date in the maps every six months no no so what even if we go to a daily retrieval of the information would be a great advance so but we don't have that we have not thought yet how will be the the the frequency of a dating but you can do weekly or daily something like that okay because my next question will have been oh disruptivity because if you were doing it every minute could disrupt the capital of streams right yeah but if you do it daily I mean I guess you don't care so much something like that maybe weekly I mean they can"
  },
  {
    "startTime": "01:48:00",
    "text": "talk about I mean probably the the more uh frequent changes that or the changes that could be more representative for a real-time feedback could be Network outages or so this would be impact in some part of the network maybe not on that but even in that case you you could retrieve an update even in case of someone outage so but could be would be discrete events along the times or not every minute not every hours so okay thank you and the last one I guess it assumes that the network is the same MTU everywhere right oh yes okay thank you thanks uh Rajiv would you like to try again yes I hope this audio is better yes much thankfully okay so my second question was basically with regards to allotting the pids for um the end users so are you actually looking at pids for every end user or is it more like one PID per unique end user prefix oh okay now I got it no these pages will be a percentile office so essentially you will associate to the to the preferences that you have declared in the BNG that is in a central office so you you group a bunch of preferences in the same PIV OT yeah the first question is uh uh there are um you know similar efforts in place right now um you know though they are more tied to specific Cloud vendors and stuff like that to make this kind of internal Telco Network topology consumable as a service for people who are looking at uh doing some sort of Service delivery uh using uh you know beep Edge nodes in 5G and Mech environments so do you have plans"
  },
  {
    "startTime": "01:50:02",
    "text": "to um eventually make this uh or at least the subset of this information available outside of your integration with tcdn and uh you know make it consumable by other uh you know potential people who are hosting on the make yes as we do foresee Alto in general is to to play the role of as a network special function for whoever customer could be internal customer or external customer and with these Special capabilities so to suppose topology but also other other additional capabilities that we are proposing in the auto working group so the the general answer to uh the answer to your custom will be yes we are going in in that digression and yeah so the idea will be to to make all this information available in such a way that we can optimize the liberty or the usage of the network in general thank you thanks and I think Sanjay is next hi this is Sanjay Mishra um I think this is a very good presentation and very useful um one question I have is that so I get the the association of bid and the IP subnet now how important is the that relationship with the CDN streamers because I assume that content is replicated on all the CDN streamers right so that information pretty much remains static well the contents are not in all the the streamers I mean it could buy I mean you don't have the same information in all the streamers okay so not necessarily okay the content may not be necessarily yes so in that way you want to make sure that for a given request then you have to have extra logic to force that's IP subnet to always fetch content from that particular streamer then yes this astrologic for instance with the would perform this filtering that I commented before in the question from very deep and so would I come presented"
  },
  {
    "startTime": "01:52:00",
    "text": "to this is simply how we expose the information but yeah the logic in the CDN side will need to get a lot of more things so filtering and then taking into account where the the content is and so on so this is this that development is also in progress okay thank you thank you thank you great thank you and Kyle has again closed the queue I don't see anybody trying to rush that block uh thank you very much all right we are at the time of any other business are there any other points we should be covering today anyone anyone if not I think we are we will declare victory for today uh thank you all very much for coming out and um thank you again Chris for taking such wonderful notes um and we will see you all on the mailing list thank you you'll be right back foreign"
  }
]
