[
  {
    "startTime": "00:00:04",
    "text": "tomorrow please yeah okay but you're the ones who will be saying okay I'm fine again I don't want this to be all wants it is okay each other s I will sure"
  },
  {
    "startTime": "00:02:22",
    "text": "hold on click on that then you can enter a time and for sure yeah it's fine okay okay yeah all right good morning and welcome to the folks in the room good morning good afternoon good evening wherever you are to the folks on remote this is dnsop at ietf 115. and we should probably go ahead and get started okay hello welcome welcome group um well team is remote but he sent his regards of course and he will be presenting the document updates yeah they just sent a cute picture of his dog exactly we can't it's a good tradition here um the chairs myself Suzanne Tim our area director Warren he's here in the room the chat room we have of course the jabber room but also integrated in the meter Echo and zulip so there are the links in the reference the minutes uh Paul Maybe yeah and Tim will be back up or vice versa so Tim will also take notes together thanks"
  },
  {
    "startTime": "00:04:04",
    "text": "okay so we're an ITF working group so the node well applies here everything you contribute mentioned at the microphone will be recorded as part of the of is the node will applies to your work in your contributions so we we expect that you're aware of the node well part of the node well is the IDF conduct kind of sorry code of conduct um well there are six points here mentioned uh summary be respectful to each other if you think code of conduct is violated please reach out to the dean sub chairs the meeting tips we are in hybrid meeting so everybody in the room is asked also to register find the the meet Echo light client you can scan the quad code or just use the the full client um also we are asked or it's ITF policy here at ITF 115 to wear masks at any time except for the presenters here are allowed to take off their mask other things for especially for the people in the room the on-site if you want to go to the my queue use the mid Echo light app or the mid Echo app raise your hand and then you are asked to come over to the microphone so it's equal for the remote participants good we go now to the agenda we just have the blue sheets note well dream will give us an update of ongoing work the hackathon update traditionally part of the chair slide is now moved to current working group business so there"
  },
  {
    "startTime": "00:06:00",
    "text": "will be an update of the hackathon but not here now but in the regular agenda after the working group business the current working group business we have for consideration and type of time permitting presentations the agenda is also published on data tracker good Tim can I ask you to give the document updates yes oh yeah good morning all and thanks for thanks for being here so we'll we'll kind of go through this because I know we have some busy stuff as you know in the isgq um 5933 Biz which is scheduled for the teletracker I believe in uh January in December um and catalog zones which has warrants as the action but I think they need an update from the authors um so authors I know you're there you may have to step up a little bit and do that but everything else is moving along for those um avoid fragmentation has been approved and Ben and I are going to work on the write-up on that um and we'll we'll sort of Chase that down here very shortly so next slide um things are moving along on some of this um of course in the editor queue service B um I think it's going to go for a record and sort of sitting and the DNS type BCT which is in there too which it looks like it's been moving pretty fast so fast so thanks for all for sort of chewing on that chair on that so um next slide next slide we've got a bunches that are kind of so we have one more than we have last call the audio what's what's starting quite well but it becomes worse and worse oh I was afraid that I was afraid of that um um"
  },
  {
    "startTime": "00:08:01",
    "text": "well then um because for some reason the audio uh becomes worse and worse how I turned it off in background is that better oh oh much better thing oh interesting thanks for that you're sitting besides me almost so it's excellent um my big comment here on validator requirements is we need more comments from the working group to sort of move these documents along and so we're we get stuck and so the three of us have to go chase down um reviewers or or people to sort of you know thumbs up thumbs down um is there anybody in the room that's against moving this the working group last call please speak up um or we'll consider that the working request call approval um and we can move on from there I know we have one comment from Brian that needs to be addressed um so and we will get that address from Daniel um and part of the reason we're expecting moving documents as long as we're not we need more help from working here on that um yeah Tim yes Tim yeah so I'll I'll I just that was all really the comment I'd like to just get more folks on the working group last call um to sort of help us get those things moving along and I'll kick over to benno then and I apologize me Deco seems to be hating me this morning thank you thank you okay so oh sorry um Jeff Houston yeah responding to the previous slide please yes um I think it's pretty sad that we're moving a document into working group last call with only one comment and yeah the thing that's kind of"
  },
  {
    "startTime": "00:10:01",
    "text": "changed is of course there's now a DNS directorate and as chairs I believe you have the ability to actually request an early review by a member of the directorate and so one of the ways to actually resolve this is rather than go oh working group last call even though no one has read it evidently is to actually throw it at the directorate at this point and ask for an early review to see if it should proceed just a thought thank you Jeff yep yeah thank you Jeff that's actually really helpful um to have the reminder that the 80s have spun up the DNS directorate and that is another resource we have as far as managing our documents thank you I agree Jeff yep I agree and Jeff why don't you take we give you the action item of of asking for a review of this one how's that you're now in charge um this is Jeff I can assign a reviewer but I kind of signed a document for review I don't have that magic power in the data tracker I think chairs or someone can do that that bitter it's an it's an area director thing so and I'm sure there's an area director there who's qualified to push those buttons we will sort the buttons we'll sort the buttons offline thanks okay oh so oh so other current uh working group documents um we think an author think is close to working group last call so not just any specific order here we see blue note is not optional the RFC 84.99 base there's now discussion on two terminology yes at the the belly wig I think that discussion is uh Billy Victor historical is well had some replies but especially uh defining glue does see some discussion very good thank you so we need to take this discussion further to the"
  },
  {
    "startTime": "00:12:00",
    "text": "mailing list preferably finishing up in one or two three weeks but limited and then we can make forward progress with both documents all TLD will be presented in a minute or in five minutes [Music] um the Nissan version uh the authors think they Incorporated all the feedback from the mailing list they think it's ready for working group last call we will schedule it and please have a second look at the document and give feedback on the mailing list and Dinesh error reporting my good progress and will be presented later this this session so we're making good progress overall um we just just had a meeting with the author of dinosaur oh sorry dinasek bootstrapping I think the author also think it's ready for working group last call the Incorporated a number of uh the feedback from the working group there was some discussion so we also probably want to make progress here I will discuss it also with the author and as revalidation it will be some other authors helping with the document because some one of the authors has another job in other priorities uh rights more work unisec automation that one uh there will also be in another author or author should be added to the document it's in good shape maybe another revision and we'll also ask for a working group last call from the from the working group the domain verification techniques uh will be up will be presented and updated if time permitting let's put it on the agenda yesterday and caching resolution failures will be"
  },
  {
    "startTime": "00:14:01",
    "text": "presented so all in all uh yeah we make a good progress with the documents they're either close to working group law or making good progress so thank you and just adopt that SVC bit svcb Dane um no well I will skip these slides these are possible candidates for adoption new work in the working group I will reach out to some of the documents authors because it didn't have much attention on the mailing list yet but there's big continuous development in updates of the documents so it should get more attention of the working group or by the working group good our work is also on data tracker of course and on GitHub so check the the links if you want to get the latest updates or interact with us or with the authors this agenda I'll have somewhere okay well this is the current agenda for the working current working group yeah I will yeah I will go over the slides it's not so for consideration we have three presentations and if time permitting other work has priority but if time permitting we have these two presentations at the very end of the of the session we can start let's get started I will load the next slide here so you do the introductions oh sorry this is next one right yeah okay yeah so um we had a lot of discussion on the mailing list both on the process and the substance around the all TLD draft and the goal today you know where we gave it we're giving it a strictly limited time and a strictly limited scope"
  },
  {
    "startTime": "00:16:01",
    "text": "but Paul has uh very graciously agreed to come up and and speak to are there open issues that will benefit from further discussion um we've the chairs and editors have discussed what seemed to be contentious issues the the chairs posted some concerns on the list and that I believe you know have been addressed in the current draft um if it seems we do have open issues that could be closed by further discussion we'll schedule an interim or some other way of dealing with those but if it seems we've said everything and Views are not likely to change further we will move to working group last call um thanks everybody for your patience and we will we are getting this this draft towards uh resolution of one kind or another so Paul if you wouldn't uh just a very quick note Rob Wilton who's sitting over there is the responsible ad for this not me because Warren is a co-editor the the rules we all operate under mean that he can't be also the A.D that that oversees it's it's movement in the process so thanks for that reminder Warren so given that um I'm gonna do a mediumly brief presentation chairs are going to run a mic line if there are people who want to say things that haven't been said on the list or new and such and a new deck is being shared yeah indeed give me one minute because come find it now foreign"
  },
  {
    "startTime": "00:18:00",
    "text": "it's overwritten sorry excuses I already checked everything but Victor I see Victor and the queue Victor would you Victor are you going to proceed this I don't know it's in the data tracker but on Mid Echo did you click the refresh probably I need to refresh yeah oh I updated the slides this morning yeah but um my own you are on Victor yes okay uh right so if there's a quick spot uh the the similar somewhat dot home TLD has has a few hints for validators to try and reduce leakage of traffic I was wondering whether anything like that should be said for an adult like you know returning you know proof of non-existence of BS while not sending any other queries so I'll sort of cover that but since alt is not going to be in the root Zone that doesn't seem possible to do uh you can still return proof of non-existence off the whole domain which includes proof of the existence of its DS so it seems to work I'm not index domain sure how you would do that for a zone that doesn't exist maybe send that to the list the the insect records prove it's non-existent that's dnsic for you"
  },
  {
    "startTime": "00:20:03",
    "text": "all right you want me to share it yeah please please because hopefully it works right oh wow we're letting Warren take over well the pro yeah the problem is that it's listed in the um manifest but it does not appear to actually but in the meat Echo IDC uh twice the the chair slides explain it somebody has to actually brought me sharing oh you need to Grant Warren shareability yes you should have it now this is very weird chair sites yeah same for me yes Maybe are those the ones oh no that's Suzanne's oh it might have been that two things were named similarly but shouldn't be similarly but not this not right okay all right the other thing we could do is go on to the next agenda item you figure it out again Warren wants permission again I did you should have it we're looking at Orange slides down it's still saying shared so yeah okay I guess yeah okay thank you thank you that went more easily than I thought it would wow this is yeah this is new on me um with apologies"
  },
  {
    "startTime": "00:22:01",
    "text": "um so Roy was next shows yes actually if Roy Ahrens isn't here yes yes but I will oh you were doing okay yeah I uh okay yeah so actually uh DNS error reporting will be the next slide sets and also uh hackathon results because DNS error reporting was a major Topic at what we worked on during the hackathon uh there were five in-person persons working on it and one remote and uh yeah so uh Roy asked me better were also some other uh projects worked on so what I said why don't you present those other two and then I'll do the hackathon visuals for DNS air reporting um so uh next slide yes so uh indeed one of the projects was working on netina's resolver inbound so nothing is uh is a bill DNS Library works on primarily by dick Franks and Dick told me once if it's nice weather he goes out plays golf and if it's rainy then he works on nattiness and uh he lives in London so it rains quite often and but nothingness is actually a early adopter of many of the stormers that are drafted index up so uh worthwhile to to look at if you want to compare it with your own implementation or to see how it's uh how your draft draft is implemented"
  },
  {
    "startTime": "00:24:02",
    "text": "uh so we worked on a uh uh bindings for nutinas with lip inbound and that involved adding some new uh functions to lip and mount to synth packets directly so this is not quite finished but it's coming next slide please and the other interesting hack we did besides the initial reporting is implementation of handling of encrypted client hello in a proof of concept Library called connect by name so um the server name indications is one of the holes in the Leaky privacy boat that leaks the the name to which TLS session is set up and encrypted clients hello is the solution to make that private as well so we have this uh proof of concept library that sets up connections and under the hood does everything but it's good right happy eyeballs Dane you can specify policies to say I want all the DNS lookups to be opportunistically private or authenticated privates and uh yeah so Philip Holmberg worked on that uh for the library looking up svcb and https records and using the encrypted client hello configuration parameter to set up uh the encrypted clients hello with this with this one server we know that support is which is default.io and filipio also later in this session talk about the uh policy uh uh uh option that is also a"
  },
  {
    "startTime": "00:26:02",
    "text": "part or came out of the connectpoint name projects and next slide please yeah for you so uh yeah as we we have a really good time so I think it's also for other people working on drafts good to participate in the hackathon if not for the importion uh or the direct feedback on uh uh your drafts then uh for for the foot because it was amazing and we also learned that DNS error reporting rocks next slide so this is these are all the people that uh worked on it I see there's one name missing we also had a remote participant on Cape and next slide Roy is going to take over to talk about the initial reporting thank you sorry thanks William um I'm Roy Adams um I'm one of the two authors for DNS error reporting um where are we um just smart introduction DNS air reporting builds upon extended DNS errors um it reports to the operator of an authoritative domain instead of reporting back to the client that's what rc8914 um is useful to begin with um the resolver where a small change I will get to that in a minute the resolver now indicates support for reporting um the authoritative Sheriff had then sends an agent domain in an IDI in his zero option sorry I'll take this off eating a zero option alongside um a regular response and then the resolver sends errors to the report receiving agents format is actually DNS query"
  },
  {
    "startTime": "00:28:00",
    "text": "it's pretty straightforward we've seen it working during the hackathon also during the hackathon um folks were so enthusiastic that we immediately thought how can we improve this how can we make this more efficient next next slide please um one thing to make it more efficient so instead of using the report instead of usually queue type no to send a report and you want something back that you can cash initially we just had no error or any domain caching NX domain caching is a problem because you will cut off the entire um string for the the entire domain for that but if you have a tax record if you just query using a text record then you can tailor a response so you can basically send a specific text um record back with a TTL that is stay loot so it can dampen the query load accordingly and now we also have that the resolver must indicate support so what we used to have is that you just Spam with unsolicited Edina zero option in a response every time always um the reason we change that is not because um it's frowned upon to just include unsolicited DNS option edns options the reason for that is to avoid later on cascading error reports over error reports of error reports um so we change that another thing we um we we changed and this is a small optimization which is really really handy so in the formatters query you used to have um the extended DNS error as a as a label before the domain name that was broken it's easy to have it after domain name um so before the underscore error if you have read the draft and the reason for that you have now the error code in a consistent Place always it doesn't"
  },
  {
    "startTime": "00:30:01",
    "text": "change um depending on the domain name length depending on the remaining that's broken all right next slide please um we have a few implementations I'll list them quickly um Willem who was just up here in Unbound um you can actually test it now um by by going to these um open testing resolvers and next slide please um we have Stefan boxmeyer Stefan had an implementation um he's named a drink I hope it's an acronym otherwise it's a really funny one um it's an authority server um easily adjustable for experimentation etc etc um works as well and the report processing so this is basically the next step once you receive the reports you can now process them and do something about it um next slide please um Shane was there as well um Shane worked on an Implement a proprietary authoritative server called Trax this is ns1's proprietary server um he mentioned it was straightforward on the authoritative side um and you can configure unique report receiving agents per server next slide please um Mark Andrews submitted a ticket for buy nine um I'm just going to leave you to that I'll I'll leave it to Mark to um to come to the mic later on to explain what it means um I don't want to say they're going to implement it it's basically a ticket that says um have a look at this draft and maybe um implement it in the future Tom Carpe from home I apologize I didn't list him in the initial slide with all the people at the desk at the at the at the table and Tom Carpe worked on an ldns version a development Branch a version for for ldns and ldns test DNS test test NS sorry it can now easily be used to fake an error reporting support authoritative server next slide please"
  },
  {
    "startTime": "00:32:04",
    "text": "um oh yeah this is this is what I wanted to make clear so version 03 we thought it was stable enough um after some experimenting we made some optimizations not super major changes but some optimizations so after Dash o4 comes out I haven't submitted it yet after that comes out we'll give it a few days a few weeks to let um to let people read it and then we will ask the working group chairs to consider a working group last call all right um if you have any questions or suggestions um there's of course the mailing list yes up at itf.org it's not really useful to to to to to Mill me personally I'll do my best but um your what I've noticed is that your questions often are relevant to the entire working group which I've got a fair amount of feedback that's now in the draft and better wording etc etc but send your questions and suggestions to the mailing list that's it thank you thank you um we have one question from Victor fixer please go ahead uh should any language appear in the draft about validators behind forwarders um they don't they aren't directly talking to the auth so they can't see these extensions um thank you Victor DM um I think the question is related to the problem of cascading errors when when they um when a reporting resolver forwards the broken error query in order to get it reported to a forwarder the forwarder might then do ediness sorry it might might do error reporting as well and then you get cascading error reports now um one idea is to make sure that when a domain starts with underscore ER then don't send this option in the um in the in the query that you"
  },
  {
    "startTime": "00:34:02",
    "text": "send out so don't send the edns option in queries about error reports that's that's one way to do it the other way to do it if you if you're a forwarder um are you actually doing error detection right I mean that's that's a question with the forwarder if you do do error detection you basically need to implement the draft accordingly so um I will add some language into the documents um basically regarding forwarders or basically clients that may not do error reporting that may set the uh the the reporting option thank you Victor thank you Roy okay up next yeah it looks like we have the slide issue fixed if you're ready to try again Paul thanks for your patience foreign cool next slide okay so some people have been asking what is the status of the draft um the actual status I can do this um is held by working group um Warren and I co-authors ask for working group plus call shares ask for changes we did those the chairs seem to have accepted those changes um there's a new draft now and then once that newest draft came out a whole bunch of discussion happened I'm going to be covering the discussion here but basically the status is we're still in held by WG the chairs are still trying to decide about working you know moving it into working group last call so it's still just a draft next"
  },
  {
    "startTime": "00:36:03",
    "text": "um there are two top issues and I think probably two of the only issues that really matter here um this is the first one I've got two slides on this and I've got two slides on the second issue um so basically we have this text which says what resolvers should do when when it comes to dot alt and the current text basically says treat it like anything else it's not special some people on the list want to make it special that is they want to put text in this document and say resolvers should or must do something here um and the difference being that if the if the text says a resolver should or must be doing something then the hope is that resolver operators I'm sorry resolver vendors will read the draft go I'm supposed to do something with this and do it next slide um so the reason for putting in a muster should is to is to get resolver implementations to not send things to the root so the you know that's the only reason to do it is to is to have an effect the desired effect is fewer queries will go to the root because they'll just get swallowed by the resolver itself um and that has been shown to to be to work in the past dot onion the whatever the RFC that created dot onion says resolvers should not send these on and some revolvers don't some resolver implementations don't and some resolver implementations ignored that and they do pass it on and and their root server operators sitting in the room they can look at you know how many dot onion queries they get and such so it's definitely not zero but if you look in the code for some of the resolvers they"
  },
  {
    "startTime": "00:38:00",
    "text": "swallow dot onion okay Paul do you want to take questions now there's one in the queue or this is this is totally your call and let me at least finish this slide yeah okay but then if you would like me to take questions here that's fine um so the um but since we know not all resolver software I'm sorry Wes what are you saying keep going thank you yeah I think sorry maybe take yourself out of the queue or um so um the the the benefit is for adding this code would be to the root servers it does not help a resolver to have more code in it you know more code can always cause more errors it also doesn't hurt as we know because this is true for Don onion it's been true for years in a couple of the resolver software and no one's had any problems so really the question is what do we want to do here um about saying that a resolver software should or must do something um and then the last bullet here is the note which is this is an informational document which is fine but it's sort of weird for an informational document to tell all of the resolver operator all the resolver vendors out there what they should or must do um so would you do you want to stop and do this one first or go to the next one okay so okay now we're switching topic next slide this is the second major issue that came up on the list after we posted the last draft um which is some people said oh no we shouldn't be we shouldn't be using the current design which is just never allocate dot alt in the root we should allocate it and then have it Point as a d name to as112. um we have rfcs on that um this was brought up five years ago when the document was in working group last call the first time it wasn't"
  },
  {
    "startTime": "00:40:01",
    "text": "accepted then but now there's a discussion maybe we should really think of this now um the reason for doing this that was stated on the list and is backed up by data is that it seems like resolver implementations do better with a delegation at caching the fact that it's delegated then remembering that they have a negative um a negative uh answer in their cash so as you can see if you go to um that link Dwayne has a long presentation but basically when they dropped in a delegation the cash is kicked in much better so this would this redesign would again not help the end users but it would help reduce traffic going to the root servers next slide um so this is not an easy fix because in fact the whole point of this document has to date been this TLD will never appear in the root so when we say to somebody hey please use this TLD you're safe to use this TLD for all of your alternative stuff they knew that anything that leaked wouldn't would never pass the root servers that is they would come back with an NX domain what doing as112 says is um we already have a set of of um authoritative servers that will then include this for who always give back the right NX domain answer but this means that to somebody who's writing something that might use this they know that in fact it'll go to the root server and then go to some other server that's not controlled by them that they are relying on to send an NX domain so that's a very different promise to the people who would be using"
  },
  {
    "startTime": "00:42:01",
    "text": "the dot alt domain um it would require new agreements with Ayanna um but and some people said oh we can't do it because you know you can't put these in in the root Zone you can make changes to what Ayanna does it has to be you know asked officially and stuff like that but saying this will never happen is simply silly the ietf gets to say what happens in the root Zone on a technical level so that's not an argument against it but the basic argument against it is that this is a complete redesign this is saying instead of simply don't do this we're going to design it this way and then just as a side note Warren and I have talked about this if the working group wants to go for this it needs to start as a completely new draft because a lot of the text in the document it would be simply wrong that is the lot of the text in the document is assuming this is not going to be something in the root Zone um and neither of us are interested in this so if if this is what the working group wants you're going to have to find some new Authors to do it it's still doable I'm not in favor of it but I'm just one voice here and that's the last slide so then you guys run the mic line and you you say when not you know when to stop yeah um there has been quite a lot of discussion on the list several times over but the reason why we're doing this is so that everybody knows where the where the document stands now and if there's anything you feel has not been said or needs to be said and again um given where we're at and where we have been in the discussion you know we do have a few minutes but this is my this is mostly sort of a status setting Wes thank you Wes herediker uscisi um uh not with my icann board hat not"
  },
  {
    "startTime": "00:44:00",
    "text": "with my baby hat but with my root server operator hat because I think that's the one you wanted right yes exactly right um this is DNS op afterwards so when I think about you know what should be done so hey thank you for putting the the document together in the first place um the right thing is don't send packets to the DNS that shouldn't go to the DNS right so don't leak yeah right don't leak and and Dot alt is supposed to be the switch that says don't use it weirdly enough right but it will happen we know it will happen I do see queries for DOT onion I don't see a ton I don't worry about the massive dot alt you know queries because I don't see a massive amount that swamps us for DOT onion that being said don't do it so my suggestion for the document is yeah do put in a statement saying resolver shouldn't send this if possible so they should know about dot alt and not send it yeah and I recognize that the code issue um sure but we already have a code issue for pre-existing stuff and again only only I looked at all four of the the common resolvers only two of them did have that code in it but they already have the code and it looked like it was a way where they could extend the list of what they have and so one of the things I was going to add is we won't get hundred percent deployment but the reality is we shouldn't saturate the DNS system with anything so I don't really care about the root server system as much because there's a lot of them I care more about the constrained lengths that you know maybe actually these extra queries might actually you know affect people way down the line or something like that as far as it going into an informational document it's still guidance you know I mean the reality is it should must are not enforceable in standards documents either right so you know I don't have an issue with putting should and musk kind of information in there before you go off to the next one do you have a preference here for should or must foreign does it really make a difference they're"
  },
  {
    "startTime": "00:46:00",
    "text": "either going to no no preferences a perfectly good preference thanks I would say should because the system's going to operate without it right you're not going to cause interoperability problems if it's a should okay great so yep um as far as 112 you know yes it it might it probably needs to be a separate document it could be done later um again it can't be done later if this is already an RFC because this one says shall never appear in the root Zone we we could that the other one could update this one to fix that statement that's a broken promise then I I would I would be very hesitant to be author of this document knowing that we intended to break the promise later I in fact I can just say right now I would take my name off this in a moment if I thought that we were going to break the promise made in this RFC later that is fair but you so so why don't we take this offline Paul because okay the queue is already long but okay but we can fight about it okay yeah the other thing to comment on that as far as the document status is that it's actually currently tagged as standards track and I believe that's required by the registry policy informational I believe don't think so well what I was going to say and that's not required uh the requirement for 761 is either standards track or isg approval which this would have isg approval eventually that's yeah that's something for the for the chairs and the da data to sort thanks foreign I don't like the idea of as112 it just seems like a hammer for what shouldn't actually really get to DNS in normal working operations I do have a question though and this might be better for the root operators what do we perceive as the load increase of leakage of alt into the normal DNS space I mean how big of a"
  },
  {
    "startTime": "00:48:02",
    "text": "problem is it actually in just leaving this out in the sense that if we don't even say should or must um what is the actual load impact and how much of a problem would that be if we had that leakage I'm not answering that one I can switch hats long enough to answer that one as in my yes putting on the roots overhead that Wes and I actually passed back and forth the the actual impact would be negligible it's just a matter of in general what you get is is there there's an awful lot of stuff that goes to the roots that shouldn't then we don't need to do anything really it might be the roots are massively over provisioned is is sort of the right statement there that doesn't mean that we want the queries exactly exactly okay so next is Elliot hi there Elliot Lear here um okay so uh a couple things first thanks Paul for taking on the work thanks Warren and thanks chairs and working group for working through this um as the independent submissions editor this came to me as you saw um through the DNS uh work and in in the gns work depends on this work completing and so again I thank the working group for for working on this um there is we've we've had a discussion about a second level registry you pulled out the text there uh in the preview in the current version only you sort of half did that and there is still text in the draft that says um that uh name service name systems should add a unique uh field uh to the left of dot all and I'm going to channel Martin shenzenbach whose users said you know do or do not if we're not going to have a registry and let's not have that convention either it would be at this"
  },
  {
    "startTime": "00:50:00",
    "text": "point if we are going to have the registry then let's have the register sure absolutely send that to the list especially with word changes you're making it simpler thank you okay that that's that's his point of view and I'll just end with a third point which is thank you again okay well again Warren did all the work up till two drafts ago so is speaking as individual I just want to say that I don't think the as12 solution is very good because since it's not specified what could be on the left side of the of the alt part it could be a three three thousand character string and we only allow 63 on valid DNS so so you're going to get form errors before it would be following the D name up the chain anyway so I think that the as112 will not catch the proper things or it will catch things right actually has to return form error instead of NX domain or something so I think it's really bad solution for this it's like the wrong tool for this thanks okay Ben Schwartz hi um on on queries to the root uh please I I want to hear sorry go ahead on the topic of Aquarius to the root the uh I think that the right answer here is to say that the um from the Stubbs perspective a recursive resolver's Behavior should not be visibly altered by this informational document so while it's advantage while it's advantageous to uh to the root for recursive resolvers to synthesize some responses locally for DOT alt uh and and I think that's a good thing that synthesis should not result in a behavior change that's observable to the"
  },
  {
    "startTime": "00:52:00",
    "text": "stub resolver uh and so what that means in my view is that if we're going to talk about that kind of synthesis we need to have some very special language about how to handle DNS sec because uh because I if I ask the uh if I ask my resolver whether dot alt exists I'm asking whether or not all exists in the root and I want a DNS set validated I want I want the correct signed and SEC record to tell me there's no such thing and that can't be synthesized locally so uh I I don't object to local synthesis in general but I think that uh it's not it's not straightforward to implement uh at a minimum you know the simplest way to do it is to just disable local synthesis if the do bit is set for example essentially what we're saying is you're allowed to do local root and since dot all these will never be in the root you're also allowed to do the special subset of local root where you only do local route for not alt because we guarantee that that's never going to be in the root um but uh but you can't just blindly synthesize uh NX domain responses because you can't sign them locally unless you are also basically doing local Loop foreign I want to just make one last editorial comment that the draft constantly uses the has adopted the terminology um the DNS context as uh the namespace anchored at the Ayanna root um I find this terminology very confusing because DNS is a protocol it's a protocol that anybody can instantiate"
  },
  {
    "startTime": "00:54:00",
    "text": "an instance of not just Diana and there are a bunch of alt routes that uh prior to this document have always in my experience been described as implementations of DNS the protocol just not the the Ayana root so uh I I just have trouble reading the document because of that okay if you can send uh suggested text on that that would that would be helpful I think to everybody right thank you and sorry to sorry to step on you Ben um we had closed the queue after then but um Robert Rob did get in the queue as the responsible ID so I'm gonna you get a special pass yes sir Robertson um just to say thank thanks thanks for working group for working this I know it's a sort of contentious topic and tricky so I get it I think we're close to rough consensus here so I think we're making progress so I think that's great I love someone to say I don't know anything about DNS but I just want to make one comment as an individual in terms of the the must or way state must or should statements is saying um is it the the stub resolver shouldn't be sending this stuff on because obviously you should be filtering out at that stage and if so can we put the constraint on that and not the recursive resolvers is what is that one option does that make sense that's an option but I think that the folks who wanted it for the recursives know that asking the stubs not to do something is sort of silly you know it's like saying to your your dog you know don't do that and the dog goes great I heard the do that part whereas recursive resolvers we know in fact the resolver sought vendors actually do the right thing a lot so I think that that was more we can also add it in for the stubs but that that's almost wasted text okay and I'll absolutely defer to the experts on this and then the end of the other point I want to make in terms of the document status I I'm lesser keen on the isg approval thing that could be slightly trickier so is the reason why this can't go through a standards track now and if"
  },
  {
    "startTime": "00:56:01",
    "text": "the isg then says actually we wanted to be informational would downgrade it is that that's up to the working group I think the original reason for having it as informational is there's no protocol in this saying don't put something in in the root server is not really a protocol thing it could be standards track it can be informational should not be experimental so in my advice I think standards track gives it a bit more weight as to so I think that'd be my recommendation okay great thank you that's for the chairs not for Warren and I okay okay great thank you thank you very much who is next step thank you uh and and either the the people that were cute and well the the queue was locked please send also your comments or your questions to the mailing list and next next up is Dwayne right there we go all right hello everyone uh so I'm here to talk about the draft which is about caching um negative caching of DNS resolution failures this was last presented at ietf 113. next slide please so as a quick reminder there are some recursive name servers that seem to be really really bad at caching resolution failures or remembering that when they asked for uh for for resolution that they didn't get an answer the the graph there on the right is from the um the presentation to this working group at ihf113 uh and there's there's more supporting data there so you can go look at that if you want to but this graph in particular was from the Facebook outage of last year where we saw a huge increase in in query traffic uh to the comnet name servers during that outage so the goal of this draft is really to strengthen the requirements around"
  },
  {
    "startTime": "00:58:00",
    "text": "caching resolution failures and avoid these sorts of unnecessary repeated queries so there's a little definition in in the draft that says a DNS resolution failure occurs when none of the servers available uh to a resolver provide any useful response for a particular name type in class so just to be clear we're not talking about you know a timeout at one of the name servers available we're talking about timeouts say from all of the name servers available or NX domain are not sorry not NX domain refused from all of the name servers available something like that so next slide uh so since the last version this is probably the most significant change where some of the requirements have been rephrased previously there was there was language in in the draft that said a resident Evolution failure must be cached against a specific uh query Tuple of name type and class and server IP address and and now that requirement is is changed quite a bit where it just says that a resolver must have a cache for resolution failures and the purpose of the cache is to eliminate repeated queries uh that cannot be resolved so it doesn't really you know it doesn't say it has to be cached by Tuple that's now sort of an implementation dependent detail um folks can choose how to how to do that however they want um and then provide some examples of of reasons my why you might want to do it by Tuple or my white might want to do it by uh server IP address alone for example next there's also some new text about how resolvers should protect themselves from possible attacks so since since there's a requirement to Cache resolution failures there's that sort of introduces a new security risk where an attacker could try to exhaust this cache uh you know send lots of specific queries designed to fill up this this new type"
  },
  {
    "startTime": "01:00:02",
    "text": "of cache and of course resolvers need to protect themselves and and can can limit the resources they devote to such a resolution failure cache next um there's there's some text in the in the draft about um about timing and this is really unchanged since the last version there was a little bit of discussion about this but what what the draft currently says is that resolution failures must be cached for at least five seconds um and and the justification for this is that this is the amount of time that a user could reasonably be expected to wait to retry or something like that um there's a should level requirement that the resolver should use an exponential back off in the amount of time that it caches these sorts of things so you know five seconds to start increase increase and so on but no longer than five minutes um and then the five minutes is uh it matches language in RFC 2308 next and so lastly this is this is kind of a new uh a new thing that we would like discussion on um so some implementations some resolver implementations would have different caches based on edns client subnet values uh and uh sort of open for discussion whether or not resolution failure caching should be should ignore edns client subnet or if partitioning the cache by that client subnet value would be appropriate or a good thing to do so um I think our opinion is that you know should be independent of EDS client subnet but would like to hear what other people think about that and uh that's it thank you thank you Dwayne"
  },
  {
    "startTime": "01:02:01",
    "text": "um in the queue beta beta Thomas yes science Peter Thomason I think um like a few slides earlier you showed that um the partitioning of the cache should be up to the implementers whether it would be Q name or IP address or whatever and now this proposal seems to contradict that a little bit Yeah Yeah and and so the question is why wouldn't you just leave it up to the implementers if they think it's a good idea or not um yeah that's that's a fair question I I think the argument I would make is that um you know if if there's an implementation that normally has separate caches based on eating this client subnet that can really sort of blow up the the size of the cache and so there may be thousands of different subnet values which would mean that now uh the resolver is is emitting maybe thousands of more times queries than than it needs to right so if if you're allowed to emit one query per subnet value per some amount of time then then that's a lot of traffic still a certain perhaps that concern should go into this um protect the self section uh Duane thanks for for doing that work also to your um to your colleagues and there's one minor thing the security consideration section talks about resource exhaustion by deliberately asking for um domains or cue names resulting in in certain failures now given that most of these resolution failures aren't authenticated um there's probably also an attack Vector in forging so those responses is that something you would consider uh for adding to that discussion it might not be catastrophic but it's it's a window of opportunity as well sure yeah be"
  },
  {
    "startTime": "01:04:02",
    "text": "happy to add something like that thank you foreign I sort of would agree that it would be great if we could ignore edina's clients.net but um a lot of implementation sort of where this would be hard and we've seen in the wild that kind of uh depending on what you give the authority um sometimes the answer sometimes they don't so it would make the positive resolution worse I guess so okay so you would vote for not saying anything about this and just leaving it up to the implementation to to do how they want yeah I would leave it up to them okay all right okay that was the queue all right okay thank you Dwayne thank you yeah next is um I think Philip with uh rights there we are yeah okay my name is Philip Humber I did this work with Philip torup so if later you have questions find either of us um and this is basically about making a try to make complexity of a slippery solder a bit more manageable while still letting the stop resolver be in control next slide um so this is when life was simple stop resolve for censor query just out for Port 53 and then hopefully gets an answer back um but then uh of course when most of the traffic on the internet became"
  },
  {
    "startTime": "01:06:01",
    "text": "encrypted um everything has stopped resolver said queries say plain text uh it's not so great anymore so the ITF took its Apollo itself to create ways to solve that backslide um and then we got this because one option is fine but lots of options is always better so we got DNS over TLS that people about it DNS of HTTP but HTTP is actually at the moment sort of two protocols hp2 and hp3 and then there's a separate uh DNS over quick and then you can also create a nested implementation so you get oblivious Doh so complexity for a stop resolver is get a completely uh out of head next slide please foreign it's jumping ahead and I think you want to have this slide I don't know well this uh the next one after this yeah okay background um we were working on um a library called uh called connect by name and the ideas you put in a name and outcomes uh TLS collection and then does all the happy eyeballs and Dane and whatever um simplifying the life of the application and the on top of the gets library that we have and and just doing all of the DNS parts right sort of costs what we wanted to Chase and get here that's to completely explode because a lot of this stuff is recursive if you connect to Doh then you could also do data whatever"
  },
  {
    "startTime": "01:08:00",
    "text": "um so we were looking for ways to simplify it next slide um and we also notice like sort of in general with this model um there's quite a few stop resolvers out there are they going to implement all of these different transports what if they don't um um UDP to Port 53 has has basically no state if I run Bing and it has to set up a DLH collection to look up uh lrp at a name and then tear it down immediately that costs a lot of extra resources resources are also show up on a recursive resolver and in general you can expect latency and stuff like that so next slide please um there's of course an obvious way to solve that and that is just introduce a local proxy and then the proxy can maintain those connections for a longer period of time so so it becomes more efficient and there's plenty of those proxies already around so there's a lot of people who have a local inbounds uh they're stubby more designed as a proxy there's TNS mask has been allowed for a long time and there's a systemd Softee that tries to do several things um next slide please but the problem there is that the application now is talking to a complete Black Box it's like well what if the application would really insist on having some sort of a private collection privacy preserving collection to recursively software if you talk to a local proxy you just don't know um maybe an application has very specific desires like it it's really about to have a Doh collections to a specific public resolver or something like that um what kind of feedback do you get from the proxy if it fails I mean you just get the software usually I guess if if"
  },
  {
    "startTime": "01:10:01",
    "text": "the collection to the Upstream recursive resolver fails and also for diagnostic tools if if your deck or drill or whatever goes directly out on the internet any applications go through a proxy then it creates a mismatch if your diagnostic tools go always through the proxy that you like visibility um next slide please um so we came up with this as as a solution and that is uh the step resolver includes this option in a request when it sends it uh to the local proxy and basically this option can describe uh What uh the stock price author would like to get from the Upstream collection to uh the recursive resolver and it consists of a number of sections that's first a set of bits which basically specify what kind of uh encryption and authentication you want whether there's a specific desire to have or exclude certain Upstream transports if an application wants to be more specific it could list IP addresses for Upstream resolvers if you want to have any kind of authenticated collection that you need to have a name um if for example you want to do do you want to have a dough path so that can be put in the SVC parameters as well as support or LPS and finally all devices were outgoing interface really matters like for example on a phone if an application is aware of interfaces then it could also put in an interface name but the basic idea is that an application is not required to put anything ill I mean if you just said this option with all bits clear that you basically tell the proxy will do whatever you want if you just said well I need authenticated connection that the"
  },
  {
    "startTime": "01:12:00",
    "text": "proxy should figure out a way to give you an authenticated collection or report a failure if it cannot do that next slide so a key design thing of this is It's stateless um every so it sort of mimics uh the original uh DNS to Port 53 uh set up uh so we said the same proxy option in every requests and then assume that um the the proxy will do something clever um um to avoid having some sort of State between the local proxy and the step um we've had to maximize control given to the application I'm not saying that all applications have to use it but if they want to use it they should be there um of course for for step resources the benefit of moving to this model would be that there's a very bigger potential for caching certainly for short-lived applications um it also introduces opportunity to implement local uh policies in the blockchain instead of well try to figure out whatever stop resolve your application has it and try to do something for that um the next bullet item is formulated a bit sloppy here the idea is that the proxy just forwards staff from an upstream recursive resolver and it's not required to do any additional dnsic validation basically to say well either you do it in the application itself or you leave it to a recursive resolver but if the the proxy would use for example Dane or something like that then of course part of data is that you should do uh that you need to do the DLS acceleration but it only does that for internal stuff not as a server uh to the user um and we implemented uh this not"
  },
  {
    "startTime": "01:14:01",
    "text": "completely but but most of it uh in a branch of of Cathy and S uh people about to play with it um next slide please uh thinking about this um if you have um sort of a current proxy then it's quite possible that the current proxies blindly forwards uh edns zero options um and then if if you would end up with the situation that's some because of his authority the network would implement this uh proxy control option which is not ruled out then you could have the situation that stop resolver thinks it's topic to a local proxy that affects traffic is just forwarded unencrypted um so there's a separate option that specifically a way to communicate between the resolved proxy and then the the proxy basically tells the surplus of what sort of oh what sort of uh Network Source adders that I get this request from and I really if if a slippery sulfur is very private see sensitive that it should say well if this is not host local then just drop it because something is wrong but if you're more lenient then you could say well if it's still linked local and I trust my local link then I'll go to allow it so it's it's well piece of puzzle that you need for for the the slippery sulfur to to verify that the whole thing is really contained and then the next thing um the left slide please um this is basically a coffee this thing that might need uh to a separate document or something like that is that if an application or a stop wants to do"
  },
  {
    "startTime": "01:16:00",
    "text": "a DNS check validation and you want to sort of be guaranteed that as a fallback uh trust anchor that it would be nice if your local proxy can just cash the other side trust or Data Trust anchors and return that so there's an extra option that basically said well please give me this stuff if you already have a local uh trust anchor that you don't need it but but applications needs a fallback and it would be better if step resolvers they'll have to set up https collections to Eli and stuff like that um so that's the three different options next slide please uh so the question is uh do people find this useful would they like this working group to work on it or any other kind of feedback or questions thank you Philip um just this last ITF the author sended the document to the add group that was discussed there but was out of Charter so the different DNS working group chess discussed this uh were to present it or where should it learn we send an email to the mailing list to the DDS open list with this question actually and that's also why we scheduled this presentation here we would like to share the feedback from the from the working group uh Ralph please go ahead yeah so you confused me a bit because when I read the document I thought I wasn't clear that it was local only then you said in the in the talk it was local only but then you could extend it so what is the scope now because there are probably different kind of considerations when you have it so the scope of the draft is the communication between a stop resolver and a local proxy but for example at the moment lots of"
  },
  {
    "startTime": "01:18:01",
    "text": "people use Unbound as some sort of local resolver which could be extended to to support this option it is communication on a machine between two programs yeah yeah and you need to change pretty much both programs for stuff to work yeah definitely so wouldn't it be easier to do a direct an API like get DNS for for doing that stuff just um so we're looking at doing inter-process communication uh within the host in a way that fits within the DLS model so there's a fake that's the actual problem is name resolution and uh so yeah but the thing is the alternative of doing it is for example a talk Alpha debus and do something like that and then it sort of becomes completely outside uh the DNS Community to to design anything on how that works so so this is an attempt like can we structure uh this part of communication that just definitely happening uh in the real world in a way that that sort of we can have a say on it instead of leaving it to the random implementer of house operating system okay I mean I've just found on a machine it better to do something with an API and for going off the machine we have that's probably why it comes out of 80d DNR and DDR to make secure connections from application to resolvers right uh so those are protocols between in this model that would be running between the local proxy and the recursive resolver whereas this would be specific for a sub resolver at a local to to reduce the complexity of the step resolver because otherwise the step"
  },
  {
    "startTime": "01:20:01",
    "text": "resolver would have to implement all of the add protocols uh creating more complexity yeah I mean if you could use apis that's the thank you uh Victor let's go ahead sorry Victor you're on uh hi can you hear me um so um the the Dane mode that's described in the draft is either no mention of Dane or Dana's mandatory or pkx you know mention or mandatory um and it seems to me that that putting the knowledge in the application of which of these will or will not work uh is fragile uh an application doesn't necessarily know uh which authentication mechanisms will or won't be available to a particular destination uh one of the great ways in which daneworks is something called opportunistic name which is use it when there are tlsa records and don't use it when there aren't uh so use Dane when possible that's not covered in the in the draft uh yes because if you set both bits to zero that it should do exactly that uh so the model should be that's sort of everything can be clear uh and then it's up to the the proxy to basically do the right thing but if an application has specific knowledge or desired an application can override that and say well this is now mandatory because I want it uh um is the proxy expected to detain when TLC records are published there was no language about that at all it expected to do uh Dane yes so um it's expected to exactly do a Dane lookup uh see whether"
  },
  {
    "startTime": "01:22:02",
    "text": "that would work or not and then use the information yeah of course if if the language is not clear then then that can be added as a more strict requirement uh but yeah it's definitely expected to do that okay thank you Benjamin hi uh I want I want to focus on something I I just heard you say at the end I feel like uh was was kind of crucial right that uh this isn't formulated as an API because the ietf doesn't standardize apis and so the only way we can insert ourselves into this process and and provide our our proposal for how the system works is to structure our solution in the form of a protocol and uh I don't know if that's exactly true that the ITF has started to dabble in API definitions but uh whether or not uh it's true it doesn't it doesn't strike me as a good reason to uh to structure it this way I think that what we're describing here is something that that's really most naturally characterized as an API and if the iatf hasn't traditionally been very involved in API definitions I think that's for a good reason which is that those definitions have to evolve pretty fast and and the requirements uh aren't always so clear up front in this particular case uh you know I I don't think that the specific behavior that's laid out here would precisely work on for example any of the major consumer operating systems or for use by any of the major consumer browsers those all have very detailed and evolving"
  },
  {
    "startTime": "01:24:02",
    "text": "requirements for how they do their DNS lookups for what security requirements they expect Etc so uh I think that if you actually look at the the market for this I think it's sort of not there uh and instead we we do need to figure out a a richer API for name resolution for essentially the uh the longer tale of applications who aren't willing to deeply customize their DNS Behavior but also aren't willing to be stuck on get Adder info forever uh but I don't think the answer is to take all of the metadata about how you want the request to be processed and bundle it into the request itself in particular I think that there's a layering violation here where the the client in this case doesn't have any clear signal as to whether it's talking to a DNS proxy that is aware of this until after the query has already been issued it only finds out it from the response whether it's requests were uh were met that's a kind of an upside down design to me I would I would much rather say okay we're going to define a new interaction model ideally an API and a platform relevant format but even if it were an IPC I would still say this is an or an RPC I would say this is a new protocol being spoken between a new interesting pair of parties one of which is a in not quite a stub resolver but it's more like an a smart forwarder but maybe it's a steerable smart forwarder the client can actually tell it where it wants queries to go so I think there's a lot of uh question marks about what really what we really"
  },
  {
    "startTime": "01:26:02",
    "text": "ought to do here so many Bucks one is it seems that at the moment there is almost nothing uh for to allow sort of an application to talk to a local proxy through an API or at least I'm not aware of anything that that works uh on more than one platform the second part is that the draft specifically has a probing query to make sure that um the the application doesn't leak any privacy sensitive DNS query name but can still probe whether this local proxy that supports uh this draft is available so in that sense the mechanism to to interrogate the option the capabilities of the local proxy is taken care of sure um we're running a little bit behind time so the further discussion can go to the list are you sure Warren okay thank you and I guess Peter is next okay so um I'm going to give a quick update on the draft that I wrote on mandating consistency checks when processing CDs or csync records we've talked about this in Philadelphia in July and got some feedback which is not Incorporated um yeah so this is a quick talk and the next one will also be mine which I perhaps will borrow a minute or two from this one thanks um yeah so this is mainly for documentation for people who will look it up later when they download the slides so everybody probably knows CDs"
  },
  {
    "startTime": "01:28:02",
    "text": "records are used by the child to tell the parent which are the future DS records it desires it's good for Royal office and so on and so forth and the type publishes it and the parent can digest it and similarly similarly for csync the child can indicate what other stuff should be updated like um an S record so glue um the finding is that the rfcs about these record types don't specify how the parents should be doing the polling and the simple implementation would be to just ask a trusted validating resolver what the CDs record at a child for example is and if you do that you end up asking only one authoritative server which may be giving you one response and if you ask another time or I don't know in another microsecond you may be asking another authoritative server which might be giving a different answer and there is no um no way to decide what's the right one and the specifications so far don't consider this problem so let's look into what can possibly go wrong with this next so there's mainly two um scenarios one is the multi-homing scenario which gets more interesting if you add DNA SEC then it's called multi-signer um so consider um you have two providers um which both um host a Zone and they sign it independently each other announcing their keys um each other's and their own Keys now one of them does a key role and accordingly updates the CDs records for their with the updated keys in that case when they do that and they forget to include the other providers Keys which may easily happen when you update the CDs records with your own new stuff and the parent ends up querying this um it may happen that the other provider gets thrown out of the DS record set which makes the general trust and breaks the solution and similarly um with NS updates via csync you can get the same kind of problem and remove the other providers and S records accidentally so that also breaks a multi-signer setup and the"
  },
  {
    "startTime": "01:30:01",
    "text": "multi-homing setup it doesn't necessarily mean the validation breaks but that resolution breaks but it does break the multi um redundancy promise that you have in a multi-homic setup usually next and similarly when you do a provider change without turning dnsic off you have to do a multi-signup period so you onboard a new provider and then off-board the first one and that also involves multiple steps with Ds record and NS record updates um so particularly you have to prepare the DS records for the new provider first and only then add the new provider to the NS record set and at that point the new providers CDs records become visible and they haven't been tested before so if the new provider isn't aware that this is even a multi-signer setup they may not have included the old providers stuff into their CDs record set and then the parent might end up adjusting that stuff and throwing the old providers DS records out of the delegation although it is still in the NS record set and that breaks the the things too so this is um kind of a special case of the multi-seller thing so to fix this let's look at the next and I think final slide um so um these problems can be um mitigated if the parent is a bit more careful and if you have a policy that whenever you use a CDs or cdns key or csync records um as a parent for doing this kind of scanning you um should check whether things are consistent across all name servers in the delegation you may disregard unresponsive name servers but otherwise if you discover an inconsistency you must abort and not change the delegation and you can do it again tomorrow or you can retry after five minutes or whatever your back off um policy is but that would solve that problem and if um multi-signer deployments at some point get more prominent I would expect um these things to happen unless care is taken so I think we should clarify to"
  },
  {
    "startTime": "01:32:01",
    "text": "people who have these scanning implementations how it would be done correctly and if someone discovers an implementation that only does one query to one name server you could easily say look at this document and you're not doing it right um so this is what I think about it and I I was going to ask the working group if you think this is reasonable if it should be moved forward and so on and so forth thank you wish thank you West herdicker uscisi no hats actually hat of the csync author document I support this because I actually think I wanted to do something like this back when I published it but there's some pushback so if you read the feasting document in a particular section 4.2 it says you have to take the the most recent SOA so there is some notion of how to make sure that you know even if things are inconsistent you still get the most recent up to date record and things like that the problem is is that in some deployments uh my recollection from the discussion is you there may be some complexity and you actually want to point at a at a hidden server which is actually what this document also talks about in section 4.2 it says you know the scanners maybe you know or registrars might be configurable to say hey go look somewhere else and things like that so uh do I'd read that section just to see you know what it follows it but otherwise I like the idea of mandating checking everything okay so you said csync RFC section 4.2 okay I'll read that so you also support this and there were a couple of things that I mean maybe in regards to what Wes said if you kind of ask all servers you still might not have asked all server because there's any cast and all the other stuff behind that maybe it might be good to have some text around that in the document and then what is the reasoning behind kind of if servers are not"
  },
  {
    "startTime": "01:34:00",
    "text": "responding to discount them rather than doing some sort of retry okay um so two things regarding your first um point about various anycast nodes I think the important policy is to ask all providers involved and you can achieve that by asking one node of each name server host name so I think that's why that's okay and then the second way to disregard unresponsive name servers um so sometimes there's maintenance but more importantly from some corners of the topology um some stuff may just be unreachable because of routing issues and you would otherwise never have the ability to um to do an actual update if you take that as a blocking failure I don't feel very strongly and it wasn't in the draft originally but at the last ATF was proposed to add it in I think it was Victor um so perhaps Victor can start the battle okay I mean if I just find it weird because I mean yeah that's obviously has an attack Vector yeah I don't I don't feel strongly about it um so whatever the the working group feels like Paul Walker speaking as one of the authors of the Celia record um I just skimmed my uh our sales like did we really not say anything about this and uh we didn't so uh yes please do this work this is our buck I'm sorry it's not a fault back then there was no multi-seller Vector neuron allowing name servers to be unreachable my concern was about uh Hidden Monsters and also about being able to remove name servers that have died and aren't going to come back right when your name server is permanently decommissioned you want to be able to still make updates and it's presently listed so you know what are you gonna do should I add these these reasonings to the draft I mean I said unreachable corners of the internet and you said phasing out name"
  },
  {
    "startTime": "01:36:01",
    "text": "service and all of that do you think that's important or do we just I mean it's important but do you think it's important for the draft or should we just specify the protocol without um justification I don't know how it's handled usually I don't have strong opinions about how to say it okay thank you Peter um wrapping up um there's also been good discussion on the mailing list in July August there's a good feedback from the room will schedule a working group adoption call later with and we coordinate with you okay next presentation also by Peter this one all right um so it's Peter Thomason um yeah so in the past few years um multi-signing scenarios have been discussed in various places um and I was sometimes part of the discussion and I noticed that um the the way that the key exchange that's necessary between the participating providers um hasn't been um discussed on a protocol level so far or well like there's no no automatable recipe for it essentially it's not really protocol change and I just wanted to um talk about that and um put it out there to the group how that could be addressed again I don't feel very strongly it's just an idea I don't know if anyone needs a solution even maybe people like doing things manually um but so let's let's um just take a look at it and then we can discuss or do whatever so next slide um so this is a bit of a messy slide um but I'll walk you through it um so to look at um what's needed for the key exchange it's"
  },
  {
    "startTime": "01:38:00",
    "text": "interesting to investigate how the DNS resolution works if you have a multi-center setup and let's say you you're asking for some record of Interest let's say an a record and actually you will need two separate queries one is for the a record which gets you the response and also the signature and the other is for the DNS key that you need for validation and a reserver might end up sending these two queries to two different name server host names and then a multi-center setup that might be operated by two different providers and so the DNS key record set is not necessarily delivered by the party who also gave you the signature um so to make that work and to to um keep it that way that reservers don't need to be aware of any of this multi-cellular stuff you need to make sure that the DNS key responses include all the keys that a validator may need to do the validation regardless of whether the record of interest is delivered by the same provider or not so um the interesting question here is what exactly needs to be included in the dnsq record set and it turns out of course it works if you just include all of the DNS keys of all providers so you just take the global Union or something like that but turns out you don't need that it actually depends on the Queue type because if you are looking for the DNS key only if that's the record of Interest then the signature will always be um in the same response as the DNS key so it will always be done with a key that is part of the dnsc records that you get as a response so it's actually just a one provider problem in the DNS record set so to validate DNS key record responses you only need the ks case of that provider not of the other providers um and um yes for everything else let's say for example for an a record um it may be that the signature is delivered by a provider that's different from the DNS key delivery provider as I said earlier because then you really have two different um queries and then you need the other"
  },
  {
    "startTime": "01:40:00",
    "text": "provider's zsks right because you you don't know ahead of time which name server hostname belongs to who so um forget all about that um the summary of that is so the bottom line is the DNS record said that everybody has to deliver is at least the local DNS keys of that provider who's responding plus the other providers is use case so anyone who's sending a response needs to have imported the other providers Zs case but not necessarily the case case um and then very similarly for CDs and CDN SQ records if you want to use that and you also have to to serve the union of all the providers ksk um type DNS keys because otherwise things wouldn't work out with the previous draft where you require consistency um so next so let's look at what the um additional requirements would be Beyond um what are the keys you need so um we just learned that providers need to discover each other's Case Case and include them in the CDs kind of records and to learn each other's Zeus case and announce them in the dnsq record sets and all of that in principle has been described in order automation draft I think together with Schumann and actually um the link is outdated it's been adopted um already but um the draft doesn't specify how to do it um in a technical way um and there are a few questions to to answer for example one is which channel do you use and another is how do you decide whether a key that you observe at another provider's DNS key record set that you want to import if that is actually a ksk or also used for signing of other records in which case it's a zsk or CSK and that's hard to tell um because you don't know if a ksk like signs that other one record That You Don't See from the outside and then also if you have three providers for example um just for illustration let's say provider a b and c everybody has imported each other's stuff and then provide a b um obsoletes the key that they phase out"
  },
  {
    "startTime": "01:42:02",
    "text": "it'll have been imported by A and B right so how should a for example know that they should remove this key because B has faced it out although it's still visible in C so it could be C is key a doesn't know and that kind of inference doesn't work if you just look at the DNS key record set in the child to um yeah so so you get these orphaned keys if you only try to infer from what you see at the Apex so you need something else and that's something else what properties would you like um so so one property would be it would be in band I mean it doesn't need to um we can use rest apis or whatever but perhaps you can make it work in band would be nice if it's if it is authenticated and because of the how to distinguish different kinds of keys a problem that I just mentioned it would be nice if somehow it would be explicit about these things next so there's two proposals one is for how to do the key exchange and the other is for when to do it how to trigger it um the bootstrapping draft has a signaling mechanism um how the um DNS provider the names of operators can make authenticated announcements of um stuff about their domains that they host it's used in the bootstrapping draft to make an initial statement about what the DS record set should be before there is a chain of trust and there is a label in the beginning of the signaling owner names in this draft that is the signaling type and we can introduce a new one like for example underscore multi and we can use that signaling mechanism to have an authenticated signaling path between the different DNS operators who participate in a dnsic multi-signer scenario and the idea is that under these signaling um records each provider would announce their own keys for which they control the private part so no Union and then all the other ones could look at that and collect whatever they find and import it into their local stuff that requires the host names of the name server no incorrect the zones in which the names of our host names live to be"
  },
  {
    "startTime": "01:44:01",
    "text": "the dnsic validation of whatever is published there so it's the same requirement as in the bootstrap draft um the idea is to do it as shown at the bottom of this slide so let's say you're provider.net and you want to make an announcement to your multi-signer peers about the domain example.co.uk then you would assemble the name as it's shown here underscore multi.example.co.uk underscore signal dot whatever the name server host name is and on this name which is a not an apex name so it's a subdomain necessarily you can't have a delegation there um you publish CDs and CDN SQ records and put your own C your own case case there and you publish a DNS key record set which has your Zs case of course you would have to update the language of the other rfcs who Define those record types to only live at the Apex and then if you have that you have an authenticated signaling mechanism and the other providers can query that stuff and import things that's the basic idea it kind of sounds complicated but actually boils down to just having providers publish a copy of their own records under these names um next slide the question is then how do you trigger this how does a provider know that the other ones even exist and when does an import have to happen um so if you consider for example the beginning of a multi-signer setup initially the new provider is not yet in the name server record set and before you can add the provider you have to um to set up the DNS configuration so you can't do it based on the NS record sets because it's not yet there you can't find the new provider yet um the proposal for Discovery is that we introduce a new record type I have called it tentatively CNS and it could hold the prospective name server host names in the final state after the transition has happened that's analogous to how CDs records hold the prospective DS records and the idea is that when um The Zone owner has provisioned the zone"
  },
  {
    "startTime": "01:46:00",
    "text": "at the old provider and also the new provider and synchronized all the contents like a records or whatever then when everything is in order they add a CNS record set which is the union of name server host names so it would have the old and the new name server host names and um when a DNS operator discovers that that has been created they can look at it and see oh okay so these are my host names and then the other three are from the other provider and then they can go ahead and determine what the signaling names would be from the previous slide and import stuff um this also works for triggering um a rollover synchronization so for example when you have done the multi-signer setup you would of course remove this CNS stuff again because you don't need it anymore and then when one provider does a rollover The Zone owner can trigger a synchronization or re-synchronization of keys between multisand appears by recreating this CNS record set and then they go and do the queries and and collect yeah so that's the idea um for the trigger um I don't care about what the name of the record type would be I called it CNS because it lives on the child side just like CDs and csync and it conveys configuration although not to the parent but to the peers and that's what I thought the CNS would be intuitive but I know that some people at least feel differently some people have told me um so whatever um I just wanted to include the concern here we can change it but I think it's neat um there's two more slides um the next slide has an example workflow so let's say you have example.co.uk and you are provider a I mean you are not provider a but that's the current setup and this one dot provider a.net and you want to onboard a second provider into the multi-signer scenario the first thing to do is that the domain owner creates a zone at the second provider B and um you know Provisions are the a"
  },
  {
    "startTime": "01:48:00",
    "text": "records and whatever the Zone contents are and then when that's in order the domain owner creates the CNS record set which is a joint set of name server host names at both providers they both observe this and then provide a B for example would do whatever like underscore multi The Zone name.signal Dot and then the other provider's host names which are taken from the CNS record set query DNS key and CDs records to DNS ACC validation on that because that's assigned with the provider A's keys because the subdomain of their hostname and then you can do the import everybody can observe what's happening because provider B can look at what provider a is publishing at the child's Apex And when everybody has observed convergence then you can go ahead and update the NS record set to to finish the onboarding of the new provider it's possible to just do that by renaming the CNS record set to the NS record set and overriding that and then do csync or you can use Epp or whatever you want it's it's an orthogonal problem to this one um yeah so final slide um the summary of The Proposal is um that it solves The multi-signer Exchange problem in a way that has a few properties that I think are interesting it's automated it's authenticated it's in band it's explicit about the ksk versus zsk questions so there's no guessing involved by the importing party it's comprehensive in that it covers onboarding and off-boarding and key roles and it's minimal in the sense that it has a signaling mechanism which is necessary and it has a trigger mechanism which is necessary but it doesn't add any protocol change resolvers don't need to learn anything um and all of that stuff um I'm not implying it's the solution maybe there's a better one maybe nobody needs a solution um it's just what I came up with and I would be interested in what people think thank you sorry thank you Peter in the queue Victor but we have two minutes for questions for Q a so please be brief um you haven't talked about uh ongoing"
  },
  {
    "startTime": "01:50:01",
    "text": "is it a scale rollovers from the individual providers the uh the customers then not involved in publishing uh CNS records they might have removed them but the operators will still periodically roll their own set of SKS how's the timing of that manage um so it appears to me but I'm not sure if I thought it through fully that if one of the provider does is zsk roll over then it would be unsafe um to allow the provider to do that unilaterally and you always need to have the Zone owner approved kind of by creating the CNS record and say okay that's fine go ahead and change it I'm not sure if that's true um but no it seems to me like that now if you're saying perhaps there is a way of doing it unilaterally yeah probably there is right because as far as a an operator is in control of their part of the CNS records but doing this signaling stuff why not let them do it um yeah so I I know of no method of of triggering that um synchronization um I think that's worth discussing because providers will want to roll zeta's case if they're the operator for the customer's own in terms of just making the signing go yeah that's a good point do you have a suggestion otherwise uh no we should discuss it later okay thank you yeah since it's um a new draft you know you know we should go ahead and uh bring the discussion to the mailing list looking forward to that yeah thank you thank you thank you okay uh our final presentation for today's tiru um there we are"
  },
  {
    "startTime": "01:52:01",
    "text": "all right sure okay good morning everyone I'm thiru I'll be I'm one of the co-authors of the draft uh structured data for filter DNS was presented at the last IDF uh next slide please uh a quick recap it's it's the primary purpose of the draft is to assist DNS filter troubleshooting uh next slide uh at the last idea of we got feedback with regard to this craft was uh how would it interrupt with the RPC servers in case they don't upgrade themselves to support this specification so we added a section to address that specific comment next slide so RPC servers are the ones which uh in case if they do DNS filtering they would put an NXT domain response with uh clearing the array bit uh in those cases in case if the client is upgraded to support this specification uh but the server is not it would continue to accept the next domain response uh but let's imagine a case where a server is also upgraded to support this specification in that case uh the client would learn the server's capability using the resin foreign type that's being discussed in the ad working group and I will be presenting that in the ad working group in the next uh meeting and then the client includes the Ade uh option in this pseudo record type to tell that it's capable of understanding the Ade response so with that the server knows whether the client is indeed capable of understanding the Ed option or not so it decides whether to put an NX domain response or send an ede option where it can now pass the fields that are being sent in the extra text field to help troubleshooting next slide yeah I think we've been presenting this graph for quite some time and uh we've"
  },
  {
    "startTime": "01:54:00",
    "text": "been addressing all the comments that have been received so far and uh we request for working group adoption yeah thank you so the documents did have uh received some feedback from the mailing list I understand there was also interest from the industry yes so are there any comments here in the working group we also put it on a working or a chair slide that this document might be up for a working group adoption we will move that to the mailing list and schedule it we will coordinate it with the authors yeah we have server implementation of this I spoke to Apple and Microsoft and they were interested in this so thank you okay thank you that's it thank you um okay and that's what we have time for today thanks everybody in the room and out in radio land and um some of these things will will take to further discussion on the mailing list and um looking forward to seeing folks yeah thank you so apologies to Shivan we we don't have enough time to give you the floor but please working group reach the updated document he has a pull request ready um this is sorry the domain verification draft um you want to add something and thank you Tim for the dog pictures so thank you all thank you for your participation contribution to the working group see you uh next in Yokohama or online bye foreign"
  }
]
