[
  {
    "startTime": "00:00:14",
    "text": "my okay welcome to tls at uh iatf uh 113 here in vienna and virtually online just a reminder for everybody people who are online blue sheets will be attendance will be automatically collected for those in the room please scan the barcodes or the qr codes throughout the room to join the meeteco [Music] mobile app so you can have your attendance counted and participate in polls and other important meeting things uh you should all be familiar with the no well at this point uh but uh here it is uh also i want to remind everybody of the ietf code of conduct to treat your colleagues with respect try to be understandable and reasoned using good judgment that can be tough um and uh we're trying to find good solutions for the whole internet all right we have minute takers um please also i think usually people are on uh jabber at this point but if there's things that need to be relayed to the mic and we're not getting to them please let us know all right um we have some administrivia to deal with that i think we're done with"
  },
  {
    "startTime": "00:02:01",
    "text": "that um there are some working group drafts that we have in progress um so we'll discuss those at the meeting today i think we have a a request from ben to discuss a kitten issue that we will add after the working group drafts um and then we'll have some discussion of new work um are there any other agenda bashing topics that people would like to discuss uh sean did you want to give any document update yeah hi joe thanks i just want to say thanks to the working group and all those participated we got two rfcs published since the last time um we met the dtls cid draft and the deprecate md5 and shaw one draft yay um we have three uh documents with the rfc editor today it's possible that uh dtls 1.3 will pop out and ticket requests as well um we have the external psk guidance document is out the door and i guess there were um there's another document that went back on the isd telechat because it's been sitting around um for a while and lost enough um ads to go forward and it's only got a couple of minor editorial things that need to get fixed so hopefully that'll pop through um so we're hoping that a lot of the log jam of the drafts that are in the working group will pop through and as you can see that some of the notes and the asterisks in pink and yellow there on the on the left on the bottom of the left hand side column they've been kind of sitting around for a while so we're happy to to move those on and get them out the door and that's it you i think back to you unless anyone has any specific questions about a draft i i got logged out of uh"
  },
  {
    "startTime": "00:04:03",
    "text": "the uh uh meet echo i think it should be back now okay yeah we see now can you go back to the slide real quick just to make sure to jog my memory here uh yeah and the other thing is that uh delegator credentials is in iatf last call and and i guess we should note too that we paused two drafts the crosses and our assumption and the flags extensions until we actually get some implementation experience and that's it back to you joe okay um i think now we will start into our regularly scheduled uh program with uh i think ctls was first is ecker do you wanna run slides or do you want me to is ecker on the call there you go slide i'll probably i can run slides probably for largely say you know next slide about eight times um where's the button again on the it's it's the uh thing that looks like a piece of paper on the upper yes under your name uh to the right to the left i think of the oh yes right right what could be more clear okay i pressed the button but it didn't tell me okay there that was not fast okay yeah this well this is this is like really warm up for for for a 46 bits so we can we can do this first um tljr i think you know we're getting pretty close to think being done with this um our intention was to take it to experimental i think and get some experience rather than try to take it to"
  },
  {
    "startTime": "00:06:00",
    "text": "ps i think i mentioned this last time um and um so uh recent changes these are mostly due to because by ben schwartz so thank you ben um so i can just summarize these um uh the first is allowing optional elements in the profile so you can have if you have elements which are which are distinguishable by the receiver um whether they're not um then you can have the optional um moving the profile do the client hello to make it the uh the structure clear um uh instead of having a a conditional sequence number um which um which is the conditional profile making it show why you're doing stream or datagram um this seems to make more sense because uh you know it does you really need the sequence number if you're in the datagram and you don't need a future stream um some clarifications around the alerts and around um or in the encryption computation um these actually don't change anything they're just like well the encryption computation really doesn't change anything and the alerts um i always intended to be the same and somehow i just never wrote that down so i don't know if you want to call it a clarification or not that's about the other to you um so um uh there's still numerous small number issues um uh the next two are actually related so i'm going to do them both and then we can um talk about them um that we remove the length field in the same space and um the underlying idea um uh was either that um the the messages actually every message actually was self-describing so you could parse the messages and then just stop um uh and also that perhaps this would be carried over transport that wasn't wasn't really like tcp was more message oriented in which case um um in which case you would need um to do that because you could just like parse the end of the message um so um but if you're kind of tcp this is actually kind of a pain because you have to actually pursue the message before you get to the end rather than just being as an ordinary tls so you could"
  },
  {
    "startTime": "00:08:00",
    "text": "just like look at the message header and find out how long it is and then of course you're facing the possibility that the um that like the message is not as long or short as it is but at least um you could you could have a two-layer parser so ben suggested a flag in the record for this but it's of course won't work for udp um and there's a separate issue um issue 41. um he's been here by the way and he just look uh good awesome about fragmentation for udp so um we originally assumed the tc the ctls was going to run over tcp and so we wouldn't need to reconstruct and so the headers don't get any information at all about how to read the reconstruction um so that's pretty clearly in a mission um and um and then we just like said well this will work fine for dtls we like you know we put a d in front of everything um and so that's not also fantastic um uh this is what happens when you have an implementation that when you wear them tell us um so um my first solution to this which um i'm thinking people will be surprised here um is to uh profile even further which is simply have um the traditional framing for both um the la uh um you have you know a a version that has no framing a version that has um a length framing and a person that has the full framing um and those would simply be as they are in the current in the current system um although we might might make the image a little smaller um so um i don't love this but i think it's probably the clean solution and um um and if which is that doesn't work then uh then it's to say the profile because it lets us um save ourselves so um uh um i guess i'll take comments but this is my put on this ben i figure you're going to say something maybe not yeah go ahead ben hey uh cool so what's the difference between length and full length means tls and formulas dtls effectively okay uh so so full is is the one that that"
  },
  {
    "startTime": "00:10:02",
    "text": "supports include and this is optional because it's um because there are some use cases where you know that your handshake messages are so small that they fit into a single message uh i was more thinking uh a single record no i was more thinking use cases where you have a transport that's carrying them that um the time to limit them okay so so you it sounds like you imagine that in the ctls dtls we need a better tls udp uh case that we would always use fall i think should have to yes okay and then the question is just on the um on the ctls tcp side uh this would be an option for well i think i think that yes the purpose of that and the purpose of that option would be to save three bytes affirmative um okay yeah i think i i i just i want to just like sharpen that a tiny bit um which is to say that there's a um uh um you know one of the purposes of this exercise though i think it may be it might be as clear as it was before we started is also to like draw a clear line between tls and uses like a handshake protocol but then with like with an exterior as an ache as an exterior for other protocols like it's used in quick and in that case you might imagine having a having a protocol which had like full message framing in which case you wouldn't have to worry about the problem of of any framing at all okay uh well yeah i i don't have an objection to this i okay i'm not entirely sure i get the motivation but it works for me okay i i i think i'm happy to like have this is like obviously not like the most amazing thing ever so like i'm really"
  },
  {
    "startTime": "00:12:00",
    "text": "happy to like hear this is a bad idea in the future uh um you know i i i don't think them knows anything now they're not committing themselves forever martin oh um when you say full i'm looking at the low spec here and it has a length which is the length of the handshake message there's a fragment offset and fragment length do we need all three or can we get by with just two um you can get by uh um you can get by you you can you can shave off one with that you can sorry uh you need all three with the cur sorry if they're the same as they currently have you need all three um but um you can imagine different semantics which only had two um in particular um uh in particular if you had an end of message bit like like t like like ip does you could shave off you could take one you could run you you could say you could rob one bit from one of those and and then and then um and then you know uh uh and then say there's only two so that suggests there's maybe something we could do that's a little more efficient than yeah than just i think the gtls one is pretty arguable you can improve it i think i think actually arguably for ctl are you for tls you could just make it two bytes too i think like um almost certainly yep okay um so i think i'm gonna like i'm gonna put something like vaguely like this in here and then and then and then people can like say the pr a little bit thanks i was hoping to get a sense of how people thought we should proceed because i hadn't like actually engaged with this as carefully as i was hoping um so um uh there are um uh the other there are there are two other optimizations of the ache on which people suggested one is emitting the random values in favor of requiring um diffie-hellman to be random and the other is even in the finish value"
  },
  {
    "startTime": "00:14:00",
    "text": "so the implication of meaning the randoms like if that's why there's randomness um which is obviously a problem if you do like pure pure pure psk equation detailment which is like inadvisable in general um um but also like a lot of analysis people do often will assume the random values are there um the um uh the the finished um basically uh as you will recall from the discussion of phil's 1.3 when we first did it if you take the finished out um you still do get integrity of the handshape but you're relying entirely on the aed on the subsequent messages um so it's not impossible but like it really substantiates the analysis and the guarantees and the separation between those two proofs um uh my um i given i i guess i think you know when we first started this there was like an attempt to like radically summon everything we possibly could um because there was a feeling like that was the only chance we had i think that my sense now is now that we have the profile mechanism these are things we could like to add later and of the jr now and i'm sort of like i think i'd rather try to get some um and if you like the people i've talked to um that actually are talking about doing this like i think um you know let's see if we actually get any interest anyway um uh or rather let's see if we haven't developed justified me uh just any cases that really have that narrow requirement as well as extra pieces um yeah i was just gonna second that on the can we do it later the profiling mechanism made this possible to do very very cleanly in the implementation work i did so i think this as long as we believe the profiling thing can be extended i think this is fine to do later okay um i i plan to do that as i say um okay um the sec the second piece that i heard suggested these are these by the way these suggestions are are you know been floating around but most recently they're due to karthik bargavan so i want to make sure i'm getting proper credit there um the um uh was to remove the transfer"
  },
  {
    "startTime": "00:16:01",
    "text": "reconstruction piece so so richard had this very clever idea of like treating this like a compression layer um in the uh in the system um and then but the implication of the compression layer is that then when you um that then you actually operate the t at the tls layer um um as if it were uh uh um as if it were rare class and then you extract everything down and brought it back up again so you had actually a compatible transcript except for um except for like some handshake value distinguishing that you actually were doing ctls um so uh this seems to add some like conceptual complexity and tetra complexity i'm not that's not i think there's something better how much so i don't know if you want to think what real thoughts on that um or not uh so uh i'm defense myself harness is at the mic line honest just i couldn't see honest you can check in at the using the app too but you don't have to worry about that harness i was looking i was looking on the actual queue so i couldn't see with the mic you're very tiny no no problem yeah i'm far away uh so exactly um so those those three proposals were made by kartik as you said and um i think they actually they are very good optimizations but there's a kind of a chicken and egg problem before we we didn't incorporate them into the document so neither karthik nor others like really sort of what looked like uh considered them as a a serious um area of investigation and so like delaying them to a later stage uh i think could be could be tricky in practice um because you don't want to do these sort of like bigger changes later on specifically the the transcript sort of reconstruction because that could um be quite a time saver implementation wise because now what i have to do is i have to basically construct the message um and then re-run the whole uh process to create the kind of real message to just"
  },
  {
    "startTime": "00:18:01",
    "text": "have the the transcript version which is um in an embedded implementation not a piece of cake in richard's go implementation it's not a problem but um if you care about saving ram and and uh also the computational efforts it's it is something so i don't know so much better yeah who um who to look for to actually do that analysis because this is a pretty serious uh security analysis that needs to be done here but it's not just uh oh it looks good i'm sort of like on the envelope assessment so i guess i think this way i think i think this one we should i think this one we should resolve one with the other before we do this because like i think that the um i think you're right this is like this is like the other things you can imagine adding later but this one i think either works do it it should happen or not um i i guess uh well i guess i'd like to hear for other people i'm sort of like i thought this was a clever idea i think when richard suggested it but i've called on it some so um um for the reasons you indicate honest um uh so i guess obviously there's some other points of view um maybe from richard or maybe not for sure there you go um i don't have a whole lot of stake in this fight um i think the transcript reconstruction stuff was mainly about um kind of establishing logical equivalence between the ct the compressed transcript in the real thing um i i you know in kind of an information theoretic point of view um right i i don't think i ever envisioned that the mechanical expansion of compression and extraction was was necessary um so i think it would be useful to have you know validation on this but i expect that the results of that you know analysis would be that it's okay not to"
  },
  {
    "startTime": "00:20:02",
    "text": "okay thanks i think i know what to do now i don't think that's all those are all slides i have so um i'm um i'm not aware of any other police like changes here um um i do go through the issues um okay sorry i thought it was kind of mike i did go through the issues so um i think you know um now the dtls is basically done i'm trying to clear out my queue of these other documents um as you can see so um my hope was to uh make these changes such as they are and then ask for your price call expert okay sounds good i think i'm ready for 84.46 well i think they call it 8846 which is just a show uh you know all right i have to do it don't do it do i play unshare and then share again i think so i think you do okay and i might have to check there we go here we go uh i didn't okay i did call i did call it the right thing look at that oh i'm glad to see that my confusion about the number of the rfc is only it only occurs at two in the morning it does not generally occur um okay so this also is hopefully close to done um there are still a few substantive issues some of which i propose to do something about and some of which i propose to do little about um as people recall the purpose of this exercise was like um you know largely to remove some problematic language for the document and in the process to clean up some uh"
  },
  {
    "startTime": "00:22:00",
    "text": "points that have been confusing in the in in the rfc um it was not to make any substantive changes that like would cause real problems um or in our problems because we're not planning to rev the protocol number so um uh so i think you know any any change we make actually measured against that question of are we improving the world are we just like thinking ourselves a whole and we do have sort of the overhang of obvious confusion about different pieces um as well as said the problematic language so i do want to get this out and if they're things that are like grievously wrong but require like a lot of engineering time i want to kind of pump them or even less curiously wrong hopefully um i i guess if they're grievously wrong we have to fix them but if they're just complicated and someone and somewhat confusing but but edge cases maybe less important since we already have 84 46 um so um uh first issue was by john matson who i don't think is actually i was actually here because i was presenting in some other um uh some other meetings i don't see them here um was um to have recommendations around ecdhe um so um currently um key update offers pfs because you hash the keys forward rotate these forwards as long as you delete the old keys you're fine um which i mean always is a condition for pfs um but uh it doesn't offer pcs and for that of course you need ecdha exchange so um johnny proposed um we had some text explaining this point but in that pr john proposed also recommending the new exchange at some precipice intervals specific intervals namely an hour or 100 gigabytes um there seemed be a lot of talk to me um and um it seemed like uh you know we probably did not need that um so my appraisal actually is the closest to no change which is what i'm worked on the bug um obviously um you know if people um i i said since john is not here if john wants to jump into the pr or later if that's okay um or in the bug um but i wanted to see what other people thought if anybody else believed we should make this change and if so we could discuss it"
  },
  {
    "startTime": "00:24:06",
    "text": "hearing no objection uh the second is also john metsen um tls is a relatively rich set of errors for certificate problems um so there's like certificate revokes difficult spirits if you've got a known um it doesn't really have anything for psk's um psks after all kind of an afterthought in original tls um and 1.3 we didn't bother to extend the alert set um so pr is just repurposing um these uh these alerts to mean the same you know effectively mean the same thing with the tickets um that seemed confusing to me since after all you could present with it you could have a psk and a ticket simultaneously uh sorry a psk and a certificate although i guess it would go in the opposite direction um uh depending on the time of the handshake um um my sense is that these granular messages in in ordinary tls for certificates were not actually as helpful as you might have seemed um and in particular because of the way um you know in particular because the way the path construction happens um you couldn't you could um you know especially for intermediates you might encounter any of these um so um for the same certificate um so my sense is probably that's not a great idea um and i think we should just if we're gonna do anything we should add just a ticket invalid alert um that says like something's wrong with your ticket um it's also the case that um depending on exactly your service constructed you might um encounter this for a given ticket um because tickets are because it's possible to have like um you know to fall back to ordinary uh certificate-based authentication depending how things are configured um so i think um again uh john's that here um um i have usefully hear from like david and martin um and other people who are implementers whether like they find the certificate like uh uh richness that helpful um or whether this just seems appropriate"
  },
  {
    "startTime": "00:26:05",
    "text": "you have my input in chat this is i'm finally on certificates uh it's really hard to get the right alert under the different conditions so i'd be very happy to say um just a single thing not the people have that richness to go either so that's fine i guess they can acquire they can't really be revoked in the same way it's this is all internals so yeah i think this was larger than external ps case but again it just seems like this is like i can't make a connection right um yeah okay i will take this on board thank you um okay um uh this brings us to issue 1227 um uh raised by david benjamin um so um um we we were it turns out that like um there are multiple hashes in play when you're doing psks one is the one associated with the psk and the other is the one that is associated with the transcript and these indepen and at least one case is potentially different um which is supposing you have two ps case um obviously um you have to use the hash associated with psk for the binder um in the client l1 because you had no other information um um but um you know they might have different different hashes associated with them um so um if you're gonna use the when it's just the blind the psk hash for the binder associated with the psk and ch1 you obviously should use it for ch2 because that was like part of the whole point of attributing of having um the hashes associated with the psks so it's clearly you have to do that um but then we have message and but on the other hand for the transcript you at the very end of the day you clearly have to use the negotiated hash and what hash is used for the message hash rejection becomes the question um and when david and i talked about this a little bit um it became clear that david thought that"
  },
  {
    "startTime": "00:28:01",
    "text": "um that this text said that the um that you should use the psk hash for re-injection and i thought you should use the negotiated hash um and david and i i believe agree that it should be the negotiated hash but it's not clear what the test currently says um so um uh it will work it pretty much doesn't work properly if you use the psk hash um and um so the proposal is to um and so i think um you know david's model where that where the um where it said he's the psk hash he had a hack to make sure that hap made sure that they matched um and so um i think the proposal here is just to modify a document to make it clear at every point in the first of all to make clear that that is the negotiated hash um yes it does include negotiators ever suite um and um so the proposal is to modify a document to make sure that's the case and in fact every case every place we use hash to indicate which hash it is properly um in some way or another so the transcript is clear so i think everywhere else it actually is relatively clear but that's because when i produce the pr people can object to that if i if if i concretize it in some way that thing is wrong that'll be helpful okay that's what i intend to do okay um uh david benjamin also read a couple points um 12 23 and 12 24 about the hr um uh um and so um his point is the general model is kind of confusing um so we don't really say um i think martin and i had largely assumed that almost every important decision was made in ch2 and sometimes they hadn't made some preliminary decisions in ch1 but that they were just effectively confirmed by ch2 and i think david sort of assumed that you must have made a decision in ch1 and um and then uh and then like you just pictured pick things out of ch2 um and memorize the material systems h2 and um neither is possible purely because as you make decisions in ch one which"
  },
  {
    "startTime": "00:30:02",
    "text": "the example david gave in in this comment was imagine what happens if um someone offers you like psk only resumption with no dhe um and so depending on whether you accept that or not and they also offer you a set of helmet groups where you need to do an hr and so depending with your accept presumption or not you might need to do an hr or not um so this is like a bit of a rat hole i fear um and so i think the um and as i understand it from talking to david yesterday for a while um most ambiguity comes into play when we're doing ech so he's less worried about it now and so i guess my question would be what's the minimum thing we can do here to like reduce the ambiguity of this um and um what do we not have to do and so i think we do the minimum thing um i don't have a proposal of that um i was actually hoping david could make suggestions um uh or or antiques i think they're a little closer to this point um but uh i think like as i was sort of saying at the beginning um what i don't want to do is spend the next six months or a year um you know trying to clarify this um in unhelpful ways um because where it's an improvement to get this out um and then if someone wants to make a bigger pass at it um we could position it out there um unless there's like things that are actively causing people confusion right now oh it's unfortunate i see dave ben's not actually here um um um so um uh well i think uh stephen i don't think ditching hr is in scope for this effort um so feel free to process overdraft but this is like was intended to be like a a set of compatible clarification changes um so um i guess david ben being here um does anybody else want to speak up for like substantial changes here and if not um i think i'm going to ask david to produce a pr what he thinks the minimum pr is and um and then move on okay thank you um uh finally i want to make a last call on some issues um i've commented in these"
  },
  {
    "startTime": "00:32:00",
    "text": "issues i don't think any changes are needed i'm just going to go through them very quickly if anyone wants to object to them now um please do and if not i'm just going to close them again basically after this meeting um so in 1206 um ben kadek um i think going from a um uh some comments that have been on the list suggested that we give more guidance about what should actually be in the cookies um my proposal's not to do anything here i think it's like at least clear enough and i think any more guidance probably risks getting confusing um i'm not going to stop for these and someone like think of the microphone or or whatever of course uh you know i'll stop but otherwise um the um second is um there's a i had a pr uh sorry uh uh issue to expand the discussion of recommended not recommended and have like another term but as i understand it this is being carried 847 this this is no longer appropriate for 8446 um and so we can just close this though we're not we're not closing the topic we're really deciding we're not going to handle that 84 46 because i'm belong there um and finally there was some discussion on um more guidance on how to handle multiple identities in post-handshake auth so if the server for instance offers multiple identities if a client does how do you um how do you think about that in your authentication without authorization decisions um and um this i think we agree with an application issue so i prefer to close that as well okay so i'm going to close all these out um essentially after i stop speaking so um i believe um there were a couple issues that i didn't get to here um because i think they're um easy to handle um but i posed to handle them and put some aprs for them and try to get a new draft out um and hopefully let's just start with last call um as soon as we get those things done and potentially david benjamin's appear so this please consider this your your your chance to uh to make it to raise any other issues which i've forgotten um it'll probably take me a couple weeks to a month to like actually do a little"
  },
  {
    "startTime": "00:34:01",
    "text": "stuff but if you um but this is this is this is your call to uh to raise other issues um and otherwise we'll have to go to e446 business sean um no new issues i think what i heard is the next time you spend a new version which will come in about a month maybe the end of april beginning of may we will issue a working group last call to get this thing out the door that's my hope um i i think you know you say given that we already have this protocol shipping and this is really about clarifying improving people's lives i think that like that is best served by actually having the document published and um and then if if you know and if we if we find then subsequently there's a bunch of energy issues i have no objection to spinning another other small other small bits or twists that's her i guess roger thank you very much bye-bye all right next i think we have uh martin thompson with snip do you want to run the slides martin yeah you do i think we're we're not hearing you martin there we go sorry about that uh one slide uh nothing has happened really here technically um but a lot has happened in terms of the editorial content of the document i went through and did a rip and tear and reordered things rewrote things i think is a whole lot more comprehensible than previously um there were some good discussions after that revision that i haven't yet published but i think it's just removing an appendix was was the upshot of most of that discussion um so at this stage we don't have anyone"
  },
  {
    "startTime": "00:36:01",
    "text": "implementing this uh this is probably another one of those documents that it's worth putting in that parked state i don't know what other people think about that but i i think that's probably the right way to do this let's sit it in the park state and see if we can uh get some implementations going it's relatively straightforward to do uh from a client side so i'd be willing to set up some sort of interoperability event if someone's willing to do the server-side work which i understand is a little more complicated that's all i have questions look someone's getting up to run away so hey on so i think unless like i'm we're not hearing seeing anything else here i think it pops up on the list uh thank you martin for doing your editorial changes to make it more readable and we'll leave it parked till we start to hear people beating down the door to uh implement this yep thank you i'll give you back your time thanks uh next we have a hybrid key exchange see is douglas on the call i will will note that when we first did this we weren't sure if he was going to be able to show up uh at this particular time so maybe we can just slide this back okay he shows up"
  },
  {
    "startTime": "00:38:09",
    "text": "um if i may uh yeah can we uh can we consider renaming this document um and now that we have hybrid public key exchange which is actually you know i believe rfc having hybrid key exchange at least at least at 2 30 eight in the morning was extraordinarily confusing to me i think you're thinking of hybrid public key encryption that makes it totally different all right we should move on to the next item which is uh ech update all right was who is uh presenting was that vincent presenting or somebody else seems we're having some trouble let me see if i can share the slides because it seems like they're not"
  },
  {
    "startTime": "00:40:03",
    "text": "i don't have access to the slides um joe are you saying they're not uh available to share what by the preload option vincent was trying to share and it didn't seem to to uh work um he's failed and it says a new deck is being shared but i don't see the deck that might have been me trying to press the button all right under that of the deck it just blew i can i can drive um vincent uh you you have to share audio as well um uh the icon that has the microphone button uh will allow you to unmute yourself which you could let us know in chat if that is or is not working um oh you have a commission problem i see um could that be handled with a browser restart yeah permissions you'll have to restart your browser i think perhaps then in the interest of time um uh while vincent sorts that out maybe we can move on to the next presentation um okay um i think the next uh topic uh sean do you want to go through the uh kittens sure so back in october i guess there was a message about um a draft"
  },
  {
    "startTime": "00:42:01",
    "text": "uh it's a draft in the kitten working group um where they're including an updates header in top of the oh is that vincent there i think yes let's heal the floor and get you get you onto your draft i guess um can someone share the okay perfect okay yeah sorry about that just let me know when you would like me to advance and i will advance for you okay uh thank you uh so yeah so i'm gonna talk about the ech updates and in particular or privacy so it's uh somewhere having a little trouble uh hearing you might need to get closer to the mic yeah is it better now that's better okay so it's a joint work with chris and kartik next slide please uh so the the basic diplomacy now that you consider is uh typically a client that wants to connect to the to a website that is hosted on a client facing server so here the backend server is the the websites and the next slide please and so for tls uh stls contains uh can you switch to the next slide chris okay so as gls contains uh if i'm supposed to secure communication between the client to the server it acts first as a as negotiation and dpml key exchange uh so we consider also the server authentication with the certificates and then that we're gonna we also model the encryption of the data through the application traffic and created with application traffic key that where the keys derived from the from the full transcript so all this kind of a recall"
  },
  {
    "startTime": "00:44:01",
    "text": "but i'm guessing all of you knows about all this information uh so in term of a next slide please in term of a feature that we looked at uh can you see the slides uh chris yeah so we consider uh most of the most of the feature that is in the nfc of tls in particular we wanted to model the hello we try requests that come from the negotiation the certificate based authentication the as well as the pre-shed key and the ticket assumption uh that are generated at the end of the session at the end of the handshake plus any other extension in particular we looked at the sni that can save the identity of the identity of the the server so in term of verification uh what's important is that because all this feature can can be used or not used depending on the on the scenario that you consider we need to verify tls with as many scenario as possible depending on the feature that you use next slide please so in term of security tls supposed to achieve quite a lot of security guarantees so we have kind of the classical one which are the authentication and the confidence security goal so in particular uh the one that have already been studied in the literature are all of those so typically key secrecy the secrecy of the the data that i send at the rtt and one entity so for one entity even the forward secrecy and in term of authentication you have the client and server authentication as well as the downgrade resilience to ensure that the attacker is not able to force the the client server to use the whole version of tls next slide please so uh in term of verification because you have to consider all those properties and as well as many scenarios"
  },
  {
    "startTime": "00:46:02",
    "text": "it's important to be able to verify the security goal not by hand but using automated verification there have been already many work on this in the past so here just mentioned tools that have been used to crypto derived star temere and project but as you can see the picture is not really homogeneous yet uh because some work have been focusing on some properties and some others so we don't have a full homogeneous picture next slides please but more problematic is that the model do not cover all the features of i mean the union of the model usually covers most of the feature but the intersection they're not intersection of the model is not complete so the goals of our work was try to have a model that's uh feature model that covers all the features as well all the security properties next slides uh so in terms of a privacy goal that have been much less studied in the past so we looked at identity of the participants in particular the client and the server we also looked at the unlinkability of the client through several handshakes and also the privacy of the extension both on the client and the server side uh next slide so here the problem is that even though tls current gls is supposed to guarantee at least the identity the privacy of the client and capability and the sub extension there have not have been any automated proof rights there have been some proof by hand pen and paper and of course for the client extension and the server identity it's not guaranteed by tls almost by design because everything is sent in the clear uh in the clientele so the ecs extension is supposed to guarantee next slide please uh"
  },
  {
    "startTime": "00:48:01",
    "text": "the ecs extension is supposed to guarantee all these privacy goals next so the basic idea of ech was to somehow encrypt the sensitive that information supposed to go to to the back end with the public key of the client-facing server with the id that only the client testing server would be able to decrypt and forward it to the backend okay but uh if you just do this it's it's not easy still to obtain a privacy guarantee of the identity of the backend server next because if you so if you just do this simple intuition of encrypted the sni and even bind it with the client random you have a very uh simple attack where the attacker just take the client hello message from the from the clients remove the key share of the clients and put his own key share and then just let the handshake run and when you receive the certificates of the server is able to get the identity of it next so the the idea of the ech that through the many uh draft have been to in fact encrypt the whole client cell that is destined for the backend server which we call the which is called the inner client hello and bind it with the parameter of the client cello that is this thing for the client-facing server so the overall is if you look at the rfc it's called the outer clamp but if you even if you do this you have some issues with uh some features in particular the hello retry request next please uh because if even though you have the this binding between the inner and the other clientele"
  },
  {
    "startTime": "00:50:00",
    "text": "the attacker can forward the the first clientele and upon receiving uh hello retry request from the server it can re-inject his own inner client hello to the third message on the slide and for the identity of the server he puts his guess whether it typically put s prime which is a guess on the identity of s so if s is equal to s prime meaning that if it guessed correctly then the n shake will continue normally and otherwise if s is different from price so if it gets wrong then [Music] the server will raise an error meaning that the attacker will be able to understand whether or not this guess is correct next please so the [Music] key idea here to solve this problem was to ensure that the encryption of the second inner clientele should be linked with the first one which leads us to the current version of ech next where we use uh hpk uh encryption for encrypting the the clientele so this the setup of the hpk create a context that is updated every time uh there is an encryption and same thing that is updated every time you try to decrypt and so the the important part here is on the left that we reuse the contact that have been updated and the same contact that have been updated to encrypt the first and the second inner clientele which guarantees you that you have this link between the inner and the other so in red is the the part that have been modified for ech and in black is like the vanilla the vanilla part of tls okay next so in terms of verification we consider"
  },
  {
    "startTime": "00:52:00",
    "text": "the symbolic models uh so typically otherwise know that dollavio model so where the attacker can you know have a control over the network he can read write and intercept messages but it's a bit idealized in the sense that he cannot break cryptographic the cryptography nor use side channel the good thing about using the avio model is that you have very powerful state-of-the-art tool and in particular we are using probe next so we only focus in our model on tls 1.3 so no version negotiation to previous version of tls but we as i mentioned before we modeled all the features that i've presented as well as all the security property authentication configuration privacy goals all of them and ideally we would have liked to be able to prove all the property with all the feature but uh it's too taxing in terms of poverty we put the time out of 48 hours as well as a limit of memory of 100 gigabytes and for some security properties and some scenarios we were blowing up the memory very quickly so what we did next please what we did is that we parameterized our model with a configuration file so we have one model but uh this configuration file allows you to easily activate or deactivate features the as well as which key are going to be compromised and the behavior of the client in the server and just using this uh this configuration file it allows us to run about 600 round of progress corresponding to about 20 to 30 uh 30 scenario per security properties so our results next so we first look at the classical signature property in particular we rechecked all the property on tls alone valina tls with all the feature activated"
  },
  {
    "startTime": "00:54:00",
    "text": "so that was as almost as insanity checked but still now we have a homogeneous picture and we try to reprove of course all of them also with ech to ensure that echo doesn't break any of those guarantees but in that case because of the blow up in memory most of the time we had to deactivate some of the features so we tried here to present just the interesting scenarios next so in symbolic models the way we model the privacy uh of the server identity so it's gonna be similar for unlinkability client privacy and so on but just here i'm only focusing on the privacy of the server it's typically it's an equivalence between two situations where on one side you're going to have a handshake with back-end server one and on the other side back in server two and those identities are known to the attacker and you put that in parallel with other handshake with other client or the front server so you have unbound number of session and everything and so if the attacker is not able to distribute the situation we consider that the identity of the backend server that is used in these two different scenarios are remaining private so we did have to consider some fairly standard assumption simple assumption otherwise would break directly the privacy like the fact that the privacy of the hpk private key of the client-facing server should remain uncompromised otherwise the attacker can just decrete the inner to obtain the identity of the back-end server and same thing similar assumption for the whether or not the back-end server have a pre-shared key shared with the client or if they have a long-term certificates so all of those are very it's not very restricting assumption next please so uh in terms of results uh for the privacy goal so equivalence in progress is even more taxing in terms of memory and more"
  },
  {
    "startTime": "00:56:01",
    "text": "specifically in in memory sorry it's you know more taxing in time but much more so in terms of memory so we have by default to deactivate the one entity and zero tt for the proofs and so we still we managed to prove most of the security properties that we were looking at for vanilla tls for the one that are possible to achieve uh with almost the feature activated uh and for ech we had to unfortunately deactivate some many of the features to try to have interesting scenario and obtain the proof and so currently we are mostly working on improving progress to remove this problem of how to reduce this memory consumption because with the hope that if we manage to solve this problem we can you know remove all the cross and put checks everywhere thanks see can i ask a clarifying question i've been saying oh perfect i didn't realize you're getting any questions um uh so first let me say this is like amazing work so thank you so much for do for doing and presenting it um um can you um it's really great to have this done um can you clarify what you mean when you say that one rtt and zero to two are both disabled i understand what it means to have zero t disabled if you're one or two disabled that means we don't have tls so can you tell me a little more about what that means yeah so it's in the term of the proof so typically uh the it means that in the middle when you do the when you do the proof the use normally in the model uh you're gonna send the messages that are sent at the end uh encrypted with the application uh data but then in for the proof there the uh we we assume that they are we assume we hope that those [Music] adding those entities at the end of those one entity at the end would not impact the proof because we managed to have some of them with when almost re remove all the conflict the all the all the feature and just put one entity"
  },
  {
    "startTime": "00:58:01",
    "text": "it didn't change anything uh but in term of verification really really really made product blow up like right i use the server of 500 gigabytes and in some in one scenario i was going over that here the prime that we really reached the limit of the material so it's it's really problematic so this means you only go as far as cfin but you don't go as far as saying the application data is that with that that one exactly okay that is correct that that seems like totally reasonable thank you right hello yeah arnold today from broadcom so it's two years i could not come to atf so i'm rediscovering a little bit what's going on here i have a question in one of your earlier slides you are saying that you have tested the number of scenario i appreciate the amount of work and i appreciate the the the approach you are taking but at imagine we consider an enterprise scenario right we have ech in an enterprise scenario now you have a customer that has to deal with network inspection so if you were to have to do this exercise with a more complex environment with where you have people who have to do data loss prevention because they are concerned by compliancy they are concerned by gdpr they are concerned by mass exfiltration they are concerned by attacks they are concerned by all sorts of other things is this something you could extend to a more complex case um i'm not sure uh so so you want to add in the model uh [Music] yeah i'm not sure exactly in terms of it my question is if you were to put your your construction"
  },
  {
    "startTime": "01:00:02",
    "text": "into a real case enterprise scenario where you have proxies firewalls load balancing all sorts of other things uh so your question is whether or not we would be able to model such a thing [Music] but i mean i am yeah to be completely honest i i cannot give you a definitive answer because it will depend what you what your aim about well not what the game but uh what exactly which feature would you need to to see appear in the model but theoretically yes we could model it and extend the model to have those those features added i don't know how it would impact in terms of in term of verification but theoretically yes you could add this in the model okay you are based in france right correct okay it contacts you offline thank you thank you yeah go ahead honest i'm okay uh hi this is hannes um um thanks for doing the work uh i was wondering whether you have um published a paper and released the the scripts that you had shown um would be interesting to verify uh some of that work is that available somewhere already or yes so there's a github public github that is available online if it's public and it's the work is going to be it's uh ongoing [Music] submission to cc to ccs of this year okay so if i send chris or you an email i might get access to it yes yes currently awesome thank you hi stephen farrell just noting that i"
  },
  {
    "startTime": "01:02:00",
    "text": "think i just formed the first actual mic line until we had this there was actually a line here no no but there was a physical line of two people hi so again thanks this work can you go back two slides to the assumptions there yeah so again i i asked this in the chat but i just wanted to kind of raise it so i think there's also an assumption here that the same ech configuration is in use for both ps1 and bs2 uh yes yes of course you have to to use uh wait sorry for between p uh so they're the same the same hch probably hpk public key is used yeah so no not necessarily i mean typically if the client facing server has several configuration possible uh so of course his public key uh wait no no yeah i'm sorry my bad he has to have the same public keys right so given that those are read from the dns entries of the backend servers they could differ um because of caching in dns or something and and even you might even have different groups or something so it would be nice to try and write down the the assumptions there so that people have some guidance as to you know what not to do in terms of publishing ech configs in dns yeah indeed i agree thanks yeah i'm not completely uh in terms of uh in some of the implementation detail i'm not completely uh aware of the you know the the how the the link with the the the the public key of the fonted server with respect to backend server so this i think chris would be able to uh answer those questions more in detail yeah and so so i think in terms of the analysis that hopefully it shouldn't make much difference as long as you use the same group but it would be nice just to have that"
  },
  {
    "startTime": "01:04:00",
    "text": "written down somewhere that has guidance for people publishing dns records jonathan hoyland cloudflare i just want to say this is super awesome work i think it's so exciting um what's the how does pro verif handle using 500 gig of ram is it does it just choke or is it does it work well it does it does work i mean uh the uh the thing is that the the the previous typically has to store it translate your your your process into one class you have to store like a huge amount of classes so the storage in the end you know it's just a normal doesn't really make any problem with product if it doesn't have time to go through the memory uh but it's mostly you know the your limitation of your server so from the poverty point of view it doesn't have any problem handling 500 gigabytes if you have 500 gigabytes available of course it doesn't get bogged down in syscalls or bus width or i mean from from my experience i mean when it's the first time that i had to handle that much memory for for uh for a model so i'm i'm not gonna say definitely that's uh it's not a problem but apparently the only error we got was every time we would reach the the limit of the memory and then just then the call would just be erased by the system and that's it very cool thank you so much okay thanks vincent i think we're getting ready for the next uh presentation all right douglas okay good morning can you hear me yeah great uh so i'm here to give a quick"
  },
  {
    "startTime": "01:06:01",
    "text": "update on uh hybrid key exchange and i guess i saw in the chat there is a discussion of the word hybrid hybrid in this setting is meant to uh refer to the use of multiple algorithms together so the motivation of this draft and i've presented this before is to commit uh the simultaneous use of traditional and post quantum key exchange in tls 1.3 and that thereby enable early adopters to get post quantum security without discarding the existing security that might be offered by current algorithms and that would reduce the risk of the break from one algorithm and help maintain standards compliance uh during the transition to post-quantum cryptography so in this document the goals are to define the uh mechanisms for uh negotiat for negotiating and establishing a shared secret using hybrid key exchange um but there are several non-goals uh so it is not a goal to select which post-quantum algorithms are actually used in tls that's the ongoing work of nist as well as cfrg and it's not a goal to do hybrid or composite certificates or to do digital signatures um some of that is being done by the lamps working group and others will have to be done later by this working group so the uh mechanism in uh this document is to just define a new key exchange mechanism a new key exchange group for each desired combination of traditional and post-quantum algorithm parameter sets and that will act as a new opaque key exchange group and then from that main idea negotiation is straightforward using new named groups for each combination which will have to be standardized subsequently key shares are conveyed by concatenating the key shares for each algorithm and submitting them just in the current key share fields and then shared secret calculation is done by concatenating shared secrets uh just as byte strings and then"
  },
  {
    "startTime": "01:08:01",
    "text": "inputting that into the key schedule and i note here that concatenation isn't a combiner for key material that's been approved by nist as maintaining fips compliance if one of the key material inputs is fips compliance so that's the main mechanism which i've presented before and has not changed since previous discussions the main thing since i last presented was a discussion on the mailing list started in august 2021 by uh nimrod avaram and his colleagues about whether concatenation is in fact safe to use and they started from the premise that if the hash function used in the combiner is not collision resistance then it may be possible to learn some keying material and the conditions of their scenario were actually that the hash function needed to not be collision resistant and that collisions could be found within the lifetime of the tls session that the first uh spite string in the keying material is uh variable length and that the ephemeral keys used in the second component are reused for a long period of time and this is based on uh similar to the crime attack it kind of works in a bite-by-byte scenario so this is very interesting and obviously has some significant assumptions here and asking for security in a world where the hash function is not collision resistant um is uh is a challenge and there are certainly impacts on other parts of the tls protocol as well for this specific attack it ends up not applying while the first and third conditions could plausibly hold the second condition that the first keying material component is variable length is not satisfied so in all standardized tls 1.3 diffie-hellman groups the shared secret component is fixed length and so it is not possible for this attack to apply to the draft as stated"
  },
  {
    "startTime": "01:10:01",
    "text": "so at this point we decided that meant we did not need to make any changes to the draft now this is still a worthwhile exercise given long-lived hard to upgrade implementations how should we design our protocols to be robust against algorithm failure and it may be worthwhile to for the tls working group to further consider uh the role of collision resistance in the protocol design of tls 1.3 overall but at this point we don't see a need to continue uh the adjustments to the hybrid key exchange draft as a result of this document so where we stand now is that we don't have any known pending tasks for this draft there are several interoperable implementations at this point here some from the open quantum safe projects openssl and boring self-works as well as wolf ssl and amazon signal to noise library um the specific pq algorithms to be uh used in this context as i mentioned are going to be identified outside of this document um when the nist round three uh process concludes um leading to cfrg and then finally uh to tls so i'm not an iutf procedure expert but i think it may be the case that this could move to working group last call so i'd like some guidance on how to proceed here and of course happy to answer any questions that come up okay martin [Music] yeah thanks for this douglas when you uh on the previous slide i think it was when you said that we're not making any changes in the document uh have we stated our assumptions very clearly okay i there are statements in the document that uh sorry i guess when i say no change is made to this draft uh there are no technical changes to make this"
  },
  {
    "startTime": "01:12:00",
    "text": "draft we did uh mention this uh scenario and there is a clear statement that uh this document is only meant to be used with uh algorithms that have fixed length shared secrets to to be clear that we require assumption b to uh to not be satisfied perfect thanks stephen hi steven uh just on the question of working group last call um i mean generally i think a lot of this work is being done too soon all this post quantum stuff um i might be in the minority there that's fine uh it would seem very weird to have a working group last call on a protocol document where the algorithms that are used are unknown so uh if we have if we're starting a practice of parking documents until people implement them maybe we should also park documents until the actual cryptographic algorithm details are understood um so i i i take your point um and uh i guess my goal had been to make sure this mechanism was ready when people wanted to use it um and really i'll all defer to how the working group wants to proceed in terms of process because i'm not an expert on that and uh i think we could have a working group last call and not move the document forward after that depending on you know to to kind of get feedback on the current state so so again yeah there's probably this is more question to the chairs i guess for sure yeah yeah i mean so i just don't understand how you could consider something being a last call when the underlying cryptographic algorithms to be used are unknown we don't know which ones they still pick or not for sure all right hey this is sean just to use chair prerogative to jump in here the only thing that i would add to the last bullet there is you know could we move to a working group last call it doesn't have to be the le"
  },
  {
    "startTime": "01:14:00",
    "text": "working group last call the problem is that i think that a lot of times that people don't really review drafts unless we start to say working group last call and i think doug's only point is hey we want people to like look at this so that when it when the when the uh our algorithms are actually announced that they can move quicker to implementation i don't want to mischaracterize you doug is that basically what you're thinking yes thank you okay so so then i guess i'd ask the chairs if you could kind of be specific about that we you know we don't want an rfc popping out before we know what the actual result of the nist competition is i think right oh yeah absolutely so that was when we first started this whole draft that was the you know we're not going to finish this until we actually the algorithms get picked so i that's supposed to happen any moment now possibly you know today who knows maybe it maybe it's sag tomorrow who knows but uh so the the algorithm is supposed to be coming fairly quickly and so i think it's just trying to get this draft in the right place to launch ports so sorry for using chair prerogative there to jump in the cube no and thanks sean i mean it really was a question for the chairs and not so much for doug hacker yeah working across college is appropriate to me here i have no problem with parking it um algorithms are announced as far as i can tell no significant part of like like no significant part of one's review this document actually depends what the algorithms are because this is intentionally algorithm agnostic so if we assume the algorithms are sound then um you know then it should not matter to me whether which algorithm it actually is um which is fortunate as i don't understand the algorithms um the um could you go back um to your um uh to decide about the active attack please right um so uh i think your professor illusion is fine but i want to push but so let me just add in advance before i push so um suppose we were to introduce a you"
  },
  {
    "startTime": "01:16:00",
    "text": "know uh a tails 4.4 or an extension which had a different a different well more collision resistant um more sorry more length and length ambiguous resistance structure right um uh um uh would that um uh and and the client and the server are both upgraded to that um to that mode um and so they would negotiate if left alone right um uh does um uh but of course the attacker can do whatever they want and then the clients are also have to jointly do um the uh um do you have to do the older mode so like so have in the while we have like that the structure we have now and then some future collision resistance structure and we have a way of negotiating that and both clients ever have to do to chip between them is this attack going to slowly possible or will the fact that the client server will naively uh negotiate the stronger version frederick's attack so you're imagining a scenario where there's this version which is only used with fixed length elements and then there is a version that can be used with variable length shared secrets but has some protection mechanism padding or a different combiner that is meant to protect uh when using variable length secrets uh that's a good good question um i actually i was imagining that we relaxed that we stupid really relaxed the restriction on it being fixed length secrets um uh um um and you use it and you use this version so i was imagining so i think what you i hear let me see if i can recap what i hear you saying which is this is entirely safe because we're requiring fixed length secrets um and um um uh so i think what i had in mind was imagine we like actually foolishly um you know uh a lot of variable like secrets but um i think the question that you're but i think the question that that you're phrasing still is a reasonable question because we still could have we still have the possibility of um the of those of the two of the two versions you described the existing"
  },
  {
    "startTime": "01:18:01",
    "text": "right okay so if if uh if there are two modes of operation both of which um are secure so where you know in the variable length setting there's appropriate protection and in the other setting it is insured to use fixed length my intuition tells me that that would be safe that there wouldn't be a downgrade route if one of them is weak for example uh one did allow the one on the screen here to be used with variable in secrets um i believe it would be possible for an attacker to attempt to downgrade to that including rewriting the transcript history to make it appear that uh one party for example did not support this more secure option and therefore this one had to be negotiated and does the signature of the transcript help or is the attack already in place before the signature is validated uh [Music] sorry this is like a pretty detailed question for this early in the morning yeah i'm not i'm i'm not sure off the top of my head how the signature validation uh ties into that uh i think well if the hash function is not collision resistant the signature is over a hash of the transcript so you could have right handed to rewrite the hash before it was signed yeah maybe right that would be a potentially a pre-image i get okay sorry this is like this is like now like a not very interesting question so i think the the relevant point as i take home is that if we ever were to specify a um is it if we were if we were in the future to attempt to specify a version of this that had um uh sorry if if we were if we were to"
  },
  {
    "startTime": "01:20:00",
    "text": "specify um a variant of this that as you say through potentially through padding or whatever was was like with length uh we dealt with variable length correctly as opposed to making the algorithms if we had so we have variable length algorithms and we have two ways of doing that one is the algorithm is fixed length under the under the hood and the other is to make is to have a version of this that is that deals with a variable algorithms and if we were to do the latter then we have to have a filter in the negotiation system that said if that that you can't do you can't do a hybrid key exchange with variable algorithm blah unless you also have the new combiners in place um so that suggests that we're really committing so that's just that as a practical matter we're probably really committing to having fixed length algorithms later because that filter's annoying but i mean we had to we could if we had to but like that kind of pushes us down this this this i think it's probably the right answer but i just try to think about it correct i think so eric okay great i think this is great sorry i i didn't mean to like take us too far in the rabbit hole this is great and i think we should like go over the work that last call thanks um yeah i i will mention that uh avaram and his colleagues did propose a combiner that does work with variable lengths uh using some more extensive uh hashing construction um so it is possible to do that at this moment um and if the working group prefers to do that we can but we did we chose to to not uh do this and focus on fixed length instead thank you ah should i go ahead yep go ahead uh yeah so hi i'm nimrod i'm one of the people that are pro and that send this email um i think uh one perspective we can use is uh is there an action but actionable attack under uh reasonable assumptions and some of the assumptions are pretty hard to meet"
  },
  {
    "startTime": "01:22:02",
    "text": "uh can we prove the security of this and uh my understanding of the literature around uh key combiners is uh it will be very hard to prove the security of this whole protocol uh absent uh assumptions like uh the the how horror hash function is like a random occur so uh [Music] uh i get that people are not worried about this attack and this is fine by me i would know that we are kind of backing in uh something that will be how to prove later uh so i think we should we might consider uh like uh how do we expect uh to upgrade the key combiner function if we ever choose to alternatively if we if we're saying we don't plan to ever come up like ever use a different three combiner throughout tls 1.3 uh then we should probably be explicit about it okay uh yeah thanks nimrod um i i mean we've talked about this before so i don't know that i have anything to add but um yeah is there any other questions and i think um we'll move to the next nicholas uh yeah hi uh nitchkowski nsa um yeah i just wanted to make a comment just to follow up on the um working group last call um so like the document is a little it's not very specific on um uh reuse of um uh keys ephemeral keys and you know that that is an issue and it does note that is an issue with some of the lattice-based mechanisms and you know because of um"
  },
  {
    "startTime": "01:24:02",
    "text": "um well you know it's it's common with the the last space protocols and um and i guess part of the reason why it's kind of a little loose on the um the guidance i suspect is because we don't actually have the specification written and how you know certain things will be done with you know like key encapsulation and and and you know it just you know we this you know they the competition's about done you know they have their their candidates they have in mind and stuff but you don't they the details aren't aren't you know set and you know they're not going to be set until nest writes the standard that'll take a little time and so you know i just you know so i just want to stress it's a little early because you know you can't even pin down you know how how to um you know uh handle um reuse of keys without you know having that other component finalized so i just you know just wanted to put that out there okay yeah so the document uh does not say that fml key reuse is prohibited because tls 1.3 in fact if my instruction is correct does not prohibit ephemeral key reuse it does permit ephemeral key reuse which is viable under the cca security definition for chems the document does clearly state that the use reuse of randomness in chem ciphertext generation is prohibited which is also kind of compatible with the cca2 security definition in the nist competition okay namara did you have a final comment or are you next in the queue you're next in the queue okay all right thank you douglas thank you"
  },
  {
    "startTime": "01:26:01",
    "text": "your slide should be up shortly okay we can see the slides here all right and everyone can hear me right yes all right so hi everyone uh my name is nimboda viram ah my co-author cake battle is also here virtually and we would like to deprecate obsolete key exchange methods in tls what this document does is it deprecates rsa key exchange and static finite field diffie-hellman limits finite sphere defiantly in its ephemeral form to only reasonable groups with sufficient security and it discourages a static elliptical difference for those keeping score at home this version came out of merging two separate documents that were presented at previous meetings as we've argued in those previous meetings this would be fully practical for the web it's consistent with mozilla's service id last guide and would be compatible with almost every web client release since around 2015. um for email the picture is more complicated however we would know that email encryption is largely opportunistic anyway and previous discussions in this working group seem to conclude that we should move forward with this as the alternative would be to allow problems with other ecosystems to affect the web um the approach of letting other market segments be because no it does not isolate the web from potential security arms for example consider drown a black-and-white attack from 2016. um [Music] 17 of web servers were uh affected because they were directly vulnerable"
  },
  {
    "startTime": "01:28:02",
    "text": "and an additional 16 percent of web servers were affected because they shared an rsa key with a different vulnerable service on another host of ports and these were mostly email posts uh these types of attacks like blackenbach type attacks allow rsa signature 4g and the forged signature can then be used for a man in the middle attack against web clients and hosts even if they don't support rsa at all so even fully deprecating rsa key exchange from the entire web in and of itself would not isolate the web from problems with rsa this is obviously in addition to the usual problems with rsa namely there's no forward secrecy and the risk of a direct form of blackenbacher's attack which practically happens every few years uh even without kyries for uh finite field diffie-hellman the document merely requires the minimum properties that guarantee security that is for ephemerality appropriate group size and appropriate group structure uh as for static elliptical diffie-hellman uh these siphon suits don't provide forward secrecy so they are already listed as not recommended and also uh because they reuse secrets this opens the door uh for a class of attacks that uh exploit the secret reuse to gradually learn uh cryptographic secrets and we've had quite a few of those over the years uh however uh we we have in the document static ecdh merely as it should not"
  },
  {
    "startTime": "01:30:00",
    "text": "um this version tries to incorporate uh everyone's useful feedback from previous discussions uh several people have argued that we should uh deprecate rsa key exchange in parallel to uh deprecating uh static ffdh and we've done so by merging the documents some people have argued for full deprecation of ffdhg even when fully ephemeral and it did not appeal to me those consensus for this and i would argue this is probably unnecessary uh because the requirements in the document should be enough to provide security uh ffdhe is not mandatory to implement and implementations are free to draw support as most web implementations have already done um and we can make it explicit in the documents that uh in the document that the implementations are free to not support uh ffdhg at all but if someone needs ffdhe and can operate it securely which is kind of equivalent to equivalent to the requirements in the document then i would argue we should probably allow it and as for the last bullet point um we still have a few open questions around ffdhe namely how would the client verify that the group is safe and what it would do if it can't verify that the group is safe um i think we can sort those out on the mailing list but uh if any if anyone feels otherwise that it should be discussed during this meeting then please pick up that's it for me and i'm happy to take questions thanks you off yeah god"
  },
  {
    "startTime": "01:32:06",
    "text": "i'm sorry i don't think we can hear you um okay um so there was a conversation on the jabra room uh this looks like an update of uh rfc 7525 it's recommendations for how to use tls which is really more about configuration because um i assume this is all about tls 1.2 and lower because 1.3 already deprecated all these things so utah wrote this rfc 7525 about uh how you should configure uh your tls 1.2 and lower and uh if you want to revise that one that's also a great idea i don't think you should just um deprecate the protocols one by one or the algorithms one by one rather than put it in this big how to configure tls 1.2 document um you do you imagine a scenario well someone would uh use our uh rsa kxg or say static finite 3d film uh do you imagine a scenario someone uses just saying that this sounds like part of what utah has been doing rather than something that uh this working group is should work on um i think that's a valid point so uh like if we think that an algorithm is broken uh do do we treat that as the configuration knob that someone would configure or do we say this is broken well i think i'm not going to fix open a"
  },
  {
    "startTime": "01:34:00",
    "text": "cell 0 9 8 to get tls 1.2 safer and people either upgrade to the latest openssl and get 1.3 or they configure their 098 to not have um do not have bad stuff so that it looks to me like the what you're specifying is how to configure rather than um changing the protocol all right thank you um david benjamin why don't you go ahead hi uh so i think like oh i mean maybe we should all like i don't know utah is also a place to do this but we have had other drafts in this working group to deprecate things that are broken uh we recently published 9155 which is like sha-1 and md5 i think we also deprecated deprecated tls-1011 and we had rc4 before that so i think this is at least consistent with what we've done historically um i don't if we want to do something different from historical things that's fine but otherwise i think this draft is perfectly reasonable thanks oh by the way also uh i spoke with um uh someone on the youtube group whose name escapes me and they said they would want like our working group to um to first deprecate uh some algorithms before uh saying uh before uh disrecommending them yeah they're selling that uh was there anyone else on the queue are you wrong yeah yeah yeah it's a call on 75 25 25"
  },
  {
    "startTime": "01:36:01",
    "text": "what you just said misrepresents the concerns of the authors and i believe of the working group 7525 has deprecated stuff that wasn't necessarily like certain stone by the pls working group and i totally agree with you that yes in the past we've had a duplication of work between the tls working group and the utah working group and and it's time to stop it thank you i'm sorry could you repeat that last sentence in the past we've had duplication of work between the tls working group and and the utah working group and so in some cases it was warranted i think it was in fact up to the dls working group to deprecate earlier versions of tls but for the smaller stuff i think it would have been better for everybody including the customers of these documents if we had done the work once and right now um the right forum for that is in my opinion and the right venue for that is utah and specifically 75 to and 25 base all right thank you uh i guess we're done with the queue uh do i need to uh stop showing uh give his oh okay panos is next okay yeah i think um uh chairs we'll have to we can discuss with you to chairs and see uh how to"
  },
  {
    "startTime": "01:38:01",
    "text": "proceed all right thank you folks hopefully you can hear me let me know if you can oh you're very faint let me try to change my source how about now still faint yeah i think how do can people in the room here still kind of faint let me let me restart the browser one second i'm back hopefully you can you folks can hear me now much better all right it was the headset all right uh hello everyone my name is panus campanakis with aws and i'm here to talk about a new draft we submitted about a month back with my co-authors martin"
  },
  {
    "startTime": "01:40:02",
    "text": "bass and cameron so this draft is practically an attempt to revive martin's old tls suppression draft from three years back i think and you know it's a draft that tries to address a well-known well-understood problem basically we all know that tls is heavy on authentication data we know that it includes a bunch of signatures and public keys that are that come down as part of the certificate and the identity certificate and the certificate chain to authenticate the identity we know that it includes certificate verification signature if it's if it's for the web we know it includes two or more scts and in some cases it includes an all csp staple signature so we know that there are a bunch of signatures and public keys included in these handshakes and that could introduce issues for some use cases so basically for in for the post-quantum use case um all post-quantum signatures that are being considered for standard standardization by nist have relatively big public keys and signatures so you know that could lead to 10 or more kilobytes of data increases in tls for authentication which could lead to tls slowdowns there has been research there have been research papers published on this and and past published a very good blog post where he he tested um big big certificates and certificate chains and and he proved that if we go over 10k then we start seeing double digit slowdowns so there could be some slowdowns introduced by post quantum signatures"
  },
  {
    "startTime": "01:42:01",
    "text": "and also um quake would would would see and at least one extra round trip because of its amplification protection uh when we're talking about invalid you know ip addresses that have not been validated yet so quake would see extra round trips there because of these public keys and signatures there are also some other use cases that are discussed in the emu work group that deal with epls and big signatures and the issues they could bring in these use cases so um john matson has these drafts and he has talked about this before and finally i've seen some use cases in in mesh networks where they're constrained mediums and you know we have certificate chains could cause slowdowns there where the medium is constrained and everyone is fighting over just a little bit of bandwidth someone could argue that ctls tries to address that that issue there as well so that that's the premise that that's the idea behind the draft and um the solution that we're proposing uh it's it's using um the tls flags draft in order to signal ica suppression to the peer so basically we require um to to pre-acquire a fresh ica list that's the list of icas that someone would use to verify the peers chain and we cri required for it to be fresh in order to avoid failures you know in case that we have entries that are expired and that shouldn't be used that they're old um so we first get use a an ica chain an ica list which"
  },
  {
    "startTime": "01:44:01",
    "text": "pre-load let's say on the client and then you know the client could signal to the peer using a tls flag to say you know don't send me your intermediate cas and and that way alleviate the protocol while we're proposing this it's for the post quantum use case we know the post quantum use case would suffer so you know using a mechanism like that would keep the authentication data within a limit that's relatively acceptable based on testing so it would save one and a half or three kilobytes if we're talking about one ica and if we're talking for nist's leanest two signature finalists you know if we're talking about other signatures it it's even more or it would save three three kilobytes or six kilobytes if we're talking about two intermediate days for nist's round three leanest post quantum signatures so you know it it helps a little bit the the post quantum use case it also helps the emu use cases that i mentioned earlier we also have to say that we consider this low hanging fruit it's a relatively easy mechanism that can be and it doesn't require great redesigns of protocols and stuff so we wanted to give a little bit of data on the icas or the ica list so if we're talking about web pki the total number of intermediate cas would be around a thousand or let's say 1500 intermediate cas in the list that we would need to to keep and that could amount to one or two megabytes of compressed data that would have to live on the client"
  },
  {
    "startTime": "01:46:02",
    "text": "so these are not i mean these are manageable numbers they're not too big numbers for for most use cases and and also at this point i had to say i i have to mention that if we're talking about the non-web pki use case and the the ica list does not even have to be statically pre-loaded and defined there are some use cases where we could build the intermediate ca list dynamically and these are use cases that are not for the web right the use cases where we have a very limited set of peers and a very limited set of icas um in the draft we defined that you can uh you you can send you you can allow the server to send its intermediate cas if it knows that if they're likely to not exist on on the client so that could be a constrained um ica list so you know in that case the server may choose and say you know i'll send it no matter what because i want to pretend uh to prevent failures or another use case could be if we if there was a third party that was hosting this intermediate cas then the server could could confirm if it's icas exist there or not and in order to prevent a failure it could you could decide to send them if they don't exist in that ica list so you know the draft allows for these use cases where even though the client may be asking for it the server can make the decision to send them to prevent a failure in this way i also wanted to bring up that we have some similar precedents that would make the deployment of such a draft relatively easy so we know that mozilla firefox already has an ica preload list that list is not used for the same reason it's used to prevent outages but"
  },
  {
    "startTime": "01:48:00",
    "text": "it's a list that that's loaded on the on the browser already we also know that the browsers deploy some sort of list for revocation whitelist for revocation lists so there is a mechanism to deploy um such listing lists to a browser and we also know that the ctls draft that eric was presenting earlier also defines compression certificate dictionaries so you know it's also mentioned in another draft a mechanism like that i mean so we had we have a couple of open questions that have have not been addressed in the draft and we want to work on them um um if i may um yeah we're basically at the end of time um and trying to make room for the next presentation i'm um did we mention the asks and we should be cool yeah i i i i imagine there's going to be good questions so i wanted to make sure there's time for questions um but also for the following presentation i'm sorry to just sort of jump in like this um yeah i don't know where there's no words so i'll jump jump the open questions there are a couple of open questions that we haven't answered and we're planning to to think about them the last slide i want to bring up is that you know there could be some challenges for web pki and ryan has brought them up on the list before we think that we can address them but i would also suggest the group to to not forget that tls is used in a bunch of other use cases that could benefit from this and i would like to ask for um a discussion in the list or or on the github github repo and we will not we will not ask for workgroup adoption uh i think maybe in the next ietf we first want to think about some of these open questions before we ask for workgroup adoption and we also want nist to pick algorithms so"
  },
  {
    "startTime": "01:50:01",
    "text": "that's what i had let me know if there are questions so i think you you partially mentioned this in the last slide but i don't think this draft as is will work for the web pki for the the reasons you mentioned like the the the while we do have precedent for pushing lists and stuff um this draft assumes that the list in all the browsers gets pushed it gets like updated basically instantaneously whereas there's going to be this long tail of like clients that still are on an old list and so you're basically going to be stuck with the servers always assuming they have to send the intermediates or like some interviews just won't work um i could imagine a more complicated scheme where we like name the lists or something um but that would be slightly higher hanging fruit than this hanging fruit um maybe for non-web use cases to be useful but it sounded like you were pretty interested in the webkinz okay i think we're gonna cut the cue here and ask the rest of the discussion to go the list so that we have time for our last presentation thank you sorry folks but okay let's try to figure out how this works um it should come here and then i can i think authcam updates very exciting stuff i can do it for my phone um so we don't have a lot of time uh thanks everyone for being here of course and also those that are in unfortunate time zones uh i'm just gonna give a brief update about the oddcam draft so what did we do last time we introduced it uh the idea is basically instead of doing authentication via a signature we do it via a key exchange because that is better post quantum uh possibly smaller"
  },
  {
    "startTime": "01:52:00",
    "text": "more efficient but we realized that we hadn't had a lot of space in the rfc to do also why this is a good idea because it's many folks on all the implementation stuff and we had a bunch of questions so in this presentation uh we have basically what do we need from you to make this thing better a bunch of the small changes that we made and some bigger changes and we have this offcam abridged sort of behind the scenes document so let's start with what do we need from you basically we need feedback it is not a small change and [Music] we would like to know does this fit for you does this not fit for you um stuff like that we also need some i'm not uh i'm a first-time rfc writer i'm used to writing scientific papers which is quite different so yeah that is quite visible still and it's been mentioned a few times the nist finalists are going to be announced very soon probably end of the month and when that time comes it will probably be very nice if you investigate if they fit in the way that you use tls and especially if the signature schemes are problematic if possibly afghan could solve problems for you oh there yeah the changelog so we restructured the whole thing we split the protocol diagrams from a lot of implementation details and we hope that that makes the thing a lot more readable this is really the most important thing that we changed since revision00 um so you'll find that it now first introduces the arrows on the paper before it starts to go into how do you put those arrows into bytes and then"
  },
  {
    "startTime": "01:54:01",
    "text": "transmit them over the wire some other things that we did was we used now hpke more fully and we added some certificate request context to the keying caps messages to possibly be able to keep track of those a little bit better so off camera bridged this is intended to be more of a sort of living document where we just try to sort of do q a and provide intuition we don't want to sweep anything under the rug here so we also very much try to clarify all of the open questions and the more tricky security intuition bits um and we really really would like also help there so please ask your questions uh either directly or in the mailing list and we will also try to keep this uh document up to date so some of the things that we have there for example why do we use camps for authentication uh stuff like how much time do we have five minutes so again end of the month uh we should see announcements from nist's uh from nist's pq thing the signature schemes are it's looking like it's going to be either quite big or quite annoying if you have like a small microcontroller that can't do floating point paths um and it's quite probably be gonna be just one of those two options so that is why we think of chemists work well um why do we not do draft semi-static is another question that we saw last time i really like the idea behind the semi-static difficult key exchange unfortunately it doesn't work post quantum why do we want to do it now is also something that came up um"
  },
  {
    "startTime": "01:56:01",
    "text": "and our answer there is that really this work is very hard um and post quantum this this move is a really good good opportunity to re-examine the things that we have right now and to see if that still works instead of just scribbling in pq in front of all of the things the last meeting already identified a rough edge so we really see that this interaction is helping and we want to file down all of those rough edges and that is going to take a lot of effort and is this finished enough was also something that came up we have a lot of academic work going on we are working on a tamarind proof actually we've mainly finished that work we've extended the tls 1.3 model and douglas has also done a model of the time of the chem tls protocol and research has a hard time finding out the practical stuff though and we think that also this interaction helps in that area let's see next there we go um other things to read uh are like why we added another handshake secrets and why we put chems into signature algorithms because clearly chems aren't signature algorithms and just small stuff like that so again we would like to hear from you if you want to help or have feedback i want to comment on any of the open issues of want to point out something that we missed unanswered questions really there are no dumb questions and also if you have something that we should investigate if you want to work with us on some experiment or really do whatever if you want to say that we're being idiots and forgetting something really stupid that would also be helpful so yeah that is i think my ask to the room today"
  },
  {
    "startTime": "01:58:01",
    "text": "and i think that was my last slide okay the queue is open for don't be shy well i guess i was very clear [Music] if you come up with something later our email uh boxes are always open so um i don't think i'm particularly hard to reach uh and also for those here in person you can also always come up to me with questions and if that went very fast for you i think the slides are on the data tracker so you can also go at them at your own pace but yeah i was asked to hurry up okay um i think that draws uh tls at iatf 113 to a close um looking forward to seeing uh everybody online or in person at the next ietf in philadelphia and on the list in [Music] the meantime thanks everybody bye-bye hello how are you"
  },
  {
    "startTime": "02:00:52",
    "text": "is oh"
  }
]
