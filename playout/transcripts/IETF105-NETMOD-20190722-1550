[
  {
    "startTime": "00:00:15",
    "text": "yep so we\u0027re gonna work through the administrative detail here this is a continuation of the immediately previous meeting which had occurred in the adjacent roof so our agenda still holds as planned I would observe that the note well still applies to this meeting just as it did to the previous half of the meeting so keep that in mind this is very much an IETF activity blue sheets are going around it is not actually Liggett or II that you signed them both times since we\u0027re having the same meeting but if you didn\u0027t sign them previously by all means do so so that we have an accounting of the fact that you are in the network of vertices these are different blue sheets yes [Music] okay administrative details we do have a media echo session for this I was scribing in there for who was speaking we have the same etherpad as previously so we can just pretty much pick up where we left off all right so agenda wise we are going to start in with the design team and so this is actually about half of our agenda for this session and first up is Joe Clark a versioning design team update all right so it will actually be three of us presenting actually be three of us presenting today I will be your first host oh okay next please using that so there are agenda today will be five minutes hopefully less for me followed by I\u0027m gonna guess the bulk of the time with Rob and then Bala will round us out and Rob will take us to next steps next please so the first thing we want to talk about is the versioning requirement changes and the reason this is only five minutes is because this is going to be fairly short essentially last time we agreed that we would adopt this document it was "
  },
  {
    "startTime": "00:03:17",
    "text": "still unclear as to what the fate of this document will be if it will be taken RFC or if it will just be something that the working group agrees to that these are the requirements that we\u0027re trying to solve and instead we will then adopt solutions work through those solutions as a working group and take those two RFC but we did adopt it there has been one change since just transitioning it over to an IETF net mod document and that is changed to text for requirement 1.4 based on feedback we got directly at the last meeting next please that change was the original 1.4 said essentially that non backwards compatible changes must be allowed there was some consternation over why must they be allowed instead what they were what we really wanted to focus on was win non backwards compatible changes occur those changes need to be signaled or documented so that one can see that between two revisions of a particular yang module that backwards-compatible changes have occurred so what you can see down there under the new heading is the new text we arrived at this was posted to the mailing list a little bit of while a little while ago we haven\u0027t heard any additional comments on this so at this point the design team feels that the requirements draft the ITF version at revision 0-1 is final these are the requirements that we have been working towards in terms of a solution at this point questions all right as to what the final resting place of this document is we of course leave that to the chairs and the working group the design team feels that what I said earlier this document will not progress to an RFC it will just be there to serve as the guidelines for the requirements that will inform the solution or solutions that come forward actually on the next document but it maybe is pertinent to this question wait and it\u0027s really why not combine the two and you have like a solution overview document that repeats a whole bunch of requirements in it if you really believe that we need requirements somewhere let\u0027s keep it at one place rather than have because the requirements even though you don\u0027t think it needs to be documented it\u0027s not meant twice so it\u0027d be great just to have one document and maybe maybe what we end up as from a working group is a requirements in solution overview or requirements and framework document and that\u0027s how we end up publishing that so we fold in what\u0027s now an individual document into the working group document and let that go forward and you know maybe all the historic stuff goes in an appendix just for context okay so so I do feel that the documenting the requirements are important not "
  },
  {
    "startTime": "00:06:19",
    "text": "necessarily document is a ratified document but I get your point and maybe that\u0027s what then will become of the the framework of the next document that will be presented any other questions comments ones requirements are facing stone even if they are in document we don\u0027t spend our time reviewing them all the time because they\u0027re wise you\u0027re back to square one right well we definitely shouldn\u0027t change this one once we\u0027re done with you know the process of agreeing that we\u0027ve arrived at that point very good and actually that\u0027s a hundred percent my objection with repeating requirements in another document now I have to go review those make sure they\u0027re right now we have to go discuss them is it the right way to summarize let\u0027s not do that please so we\u0027re saying yeah our intent is that these requirements now become fixed these are the requirements for which we\u0027re trying to solve the the requirements in the overview draft are only there to make it easy to read so if it\u0027s easy to have them now just refer to this one that sorts of it\u0027s more easier to say the requirements are documented here go read it just give a second second set which isn\u0027t written quite exactly the same way that you have to figure out what\u0027s different what\u0027s not different yes that\u0027s right well oddly Rob why don\u0027t you get up here I\u0027m gonna get out before something changes okay so so I need a quick update for next slide please so I just want to we continue to have semi regular meeting since ITF 104 there\u0027s quite a few people who\u0027ve I\u0027m dialed in either a weekly or semi weekly basis and we\u0027ve continued to progress various documents I like to thank everyone down there on that list I don\u0027t repeat them and our main output really is that tweak the requirements document the judges talked about an updated sort of solution solutions overview draft that sort of tries to pin everything together and show you wear the different bits of the solution hanging together and then our main focus has been working on this sort of new / updated yang moderate module revision handling draft that evolved from the somatic version draft that we presented in 104 my opinion is that this draft accommodates all sort of core feedback we received during the working group meetings and also the versioning discussions we had at 1:04 and so we think it was sort of reflects that consensus from that next slide please so I\u0027m now going to spend the next 20 minutes discussing the solution overview "
  },
  {
    "startTime": "00:09:19",
    "text": "I\u0027m just trying to set the scene of where these drafts ought to hang together then there\u0027s me subsequent talks on some of those there are different parts so next slide please so my intention here was that the solution David Dreier you draft is meant to be a sort of transient temporary document the the idea here really is just to help the readers who are reviewing those drafts understand how they fit together what bits haven\u0027t yet been written but in what will be written a mind teacher wasn\u0027t intended to take this to RFC I mean it could be done but that the attention of this was to help people during the review process in terms of updates there will be a separate presentation by bal√°zs on updated mod revision handling I will talk about young packages after this and Rashied will talk about version selection so those three ones will be covered in more detail next slide please so the overall solution as we see it now is made up of five different parts the first one is in updated yang module revision handling so this is doesn\u0027t talk about semantic versioning at all but talks about yang module revisions and how they can allow non backwards compatible changes and Express those and more branching and fixing other things related to that area there\u0027s a really just a semantic version number scheme that it sure could be described fairly abstractly that hasn\u0027t been written yet but we derived from the text from the previous one draft 30 over DT net mod yang Simba\u0027s eros eros or take the semantic versioning a definition from that draft you just extract that text and I\u0027m putting in isolation so we\u0027ll do that in the next phase there\u0027s a version yank packages draft and this one was published this update was much before ITF 104 I need some changes to take into account the changes in the updated yang mode revision handling so I will present that one this time it wasn\u0027t presented in 104 and but there needs to be some updates to that there\u0027s also a draft for protocol operations for package version selection so that\u0027s draft Wilson Ahmad yang vs. election 0/0 again that one was published before 104 Rashad will be talking about that so again that is sort of quite early draft we expect there to be more substantial changes to that and then the final part of this whole puzzle we think he\u0027s tolling related to doing schema comparisons between either a module by module basis all you group a set of modules together into one is yang packages to actually version and be able to compare two schemas and report at the schema level what\u0027s different or maybe on a per leaf node base of data node basis what\u0027s changed between those two schemas so that work is on is our least lowest priority at the moment we\u0027re to try and get the other work out the way "
  },
  {
    "startTime": "00:12:19",
    "text": "first so next slide please okay can you talk about if there\u0027s any significance that the naming of the document I notice go through some transformations from version design team only well I think probably not at this stage the ones that came out of the Verde T the design team obviously have the Verde T prefix the young version yanked packages and the packaged version selection were not work there was output from the design team there in need to individual drafts that I wrote but I that\u0027s not because the design team doesn\u0027t align necessarily with that direction I don\u0027t think it was just more that that\u0027s when they produced the proposal later on here is for the design team to hopefully pick up those documents and work on them as design team documents that\u0027s the plan if that\u0027s okay the name doesn\u0027t it\u0027s a file name so it doesn\u0027t really matter but whether we have a complete solution from the design team or a partial solution I think does matter and we really are looking the chairs are really hoping to get a complete solution from the design team yeah and if for some reason a design team didn\u0027t feel that that was a a noble goal we should you talk about that so it\u0027s great to hear your plan so yeah it\u0027s one card they\u0027re like one comment on that not everyone the design team believes that the version selection is required I would say so that\u0027s the one we\u0027re not going to redo des Kate are our requirements and that it\u0027s in their requirements yeah I\u0027m sorry that\u0027s one so you know good so of the first of those five drafts the updated yang module revision handling this is the one there\u0027s a more detailed talk on this by launch we\u0027ll cover all of the different parts of this in a lot more detail so this is just a one slide summary of what we\u0027ve done and what the draft covers and you have the core enhancements to Yang or to allow but not necessarily encourage nonlinear module development eg for bug fixes so we allow we allow some sort of branching to occur in yang module history and to document when not on backwards compatible changes have occurred in the revision history so we\u0027re not saying that we\u0027re not encouraging that people should do this but even when they do occur at least be able to describe that so that when clients when people read these documents and or client tools are processing them they can know where and Nan box classical changes have occurred the next part of that is that we we still identified module revisions uniquely using the revision date so nothing\u0027s change from what we have today but we allow a new freeform text label to be "
  },
  {
    "startTime": "00:15:21",
    "text": "associated with a revision and this text label can be used effectively to overlay like a semantic versioning scheme for example or some other scheme that somebody else comes up to it\u0027s not we\u0027re not defining within this document what the form of those text labels can be but we do allow these revision labels to be used when in the file name for example in replace for a revision date and the import by derived revision again can also use this label as well we define a new version of import so today yang has an import that will choose any revision or has an import that chooses a very specific revision and one of those is two general ones to specific so we are introducing one that\u0027s import by revision data or derived and that effectively you will find you a revision that is either that or that\u0027s within its history and so that\u0027s the attention there is if a module that you\u0027re importing has a new container added into it or new and you know that you\u0027re referencing then you can put dependency on that revision or later so you put in that source code dependency we define backwards-compatible versus non backwards-compatible changes and these are actually the non backwards-compatible change so bogus collateral changes are very close to what is defined in our c 7950 with some tweaks and the non box-cutter ones fairly obvious from that we clarify and prove yang status handling so in particular we clarified the deprecated means you still have to implement the node or otherwise and use deviations to indicate you\u0027re not implementing it and obsolete means you don\u0027t implement the node and then finally we\u0027ve added some updates and guidelines for how you update yang word rules based on these updated rules next slide please so the second draft and this one\u0027s not been written yet and this is the semantic version number scheme so I\u0027m just saying what the plan is do it and we tend to to do this over the next window next four months is to define a semantic versioning scheme that allows a bug fixes to release software released software assets so effectively it\u0027s what\u0027s already documented the algorithm in the draft DT net mod yang symbol 0 0 and it\u0027s a version of semver 2 0 0 but with the ability to add these bug fixes in to the released assets when necessary the main changes to is that doesn\u0027t actually now need to define what constitutes a backwards compatible or non box-cutter will change that would be assumed to be defined outside this and this is this is what will be used we expect this is some people as a revision label so effectively the revision labels you have will use this semantic versioning scheme so you end up with having semantic version for your young "
  },
  {
    "startTime": "00:18:23",
    "text": "modules and then again it\u0027s worth pointing out that in terms of this this versioning scheme is not going to be tied to yang so although it will be defined or have some references to the and models it could be used anywhere where you want to do this sort of semantic versioning of assets but you want to have a bit more flexibility to be putting be to put bug fixes in two older released code or released api\u0027s looks like so yang package again an overview I\u0027m I\u0027ve got with more detail on this later on so what is a yang package is identifying a set of yang modules and their dependency so it\u0027s a bit like taking Watson Yang library and putting it into a file or this one example but it\u0027s a bit more flexible than that so whereas Yang library will tell you what the schema is for a particular data store an entire device this allows you to do subsets of yang modules so bits of bits of stuff together and group them and the key thing here is that those packages can then be versioned in the same way that modules are being versions so rather than having each vendor implementing choosing exactly which module version module they want so every single language will they\u0027re implementing I think the use of packages could encourage people to have more commonality in what they implement so if you took the ITF young model for example you could have a package that defines the base models and types and things you could have separate package for routine you could have a separate package for VPN services for example and those would be versioned over time and so rather than somebody saying well I want this version this or this version of that you could choose something off that the history of those version packages yes yes yep it copes with that has dependencies between packages and you may have dependencies between packages that conflict and so the the solution here requires that you resolve those conflicts at the time you combine those two packages together into a into a combined package you have any conflicting module dependencies you have to resolve them explicitly say how they\u0027re resolved so yes in terms of packages that could be available offline using the yang instance data document "
  },
  {
    "startTime": "00:21:24",
    "text": "they also the plan is to augment yang library so that rather than necessarily downloading the full module list off a device if you knew and expected what package version it\u0027s going to implement you can just check that it\u0027s implementing what you expect so make it an easier check for comments conformance wise and as I said there\u0027s a separate present presentation on this following later so that\u0027s what I cover now next slide so the fourth one is protocol operations for package version selection so one of the key aims of yang packages is to allow devices to potentially implement different versions of modules as cohesive sets and then to allow clients to select which ones to use so this could be done where they\u0027re choosing between some different sets of vendor modules or it might be they want to choose to use the ITF yang models or a particular version of the open config yeah models as examples and so the packages are identifying those sets of modules and then using our pcs to select which ones to use and this could be the case that the server only allows you to support implementing one particular packaged version for the entire management interface or it may be that some devices allow you to have support multiple different packaged versions and to select those depending on maybe the session that\u0027s being used so again there\u0027s another presentation covering this but as I say here is failure the early draft there will be more changes in here but really it\u0027s just the ideas are being presented and next slide please and then the last one so there\u0027s no draft written yet they slightly lower priority I do think it\u0027s a key part of this set and that\u0027s to define an algorithm to compare to schema trees the detects backwards-compatible versus non backwards-compatible changes so it looks through those two schemas and says that these are where the changes are so P yang already does some of this the result could then be given at the schema level or it could be given on a data node level and it could be also taken to account features or deviations or the subset of the schema actually being used by by the operator so if they are only using no 1/3 of a particular protocol module they\u0027re not using these options then when you\u0027re comparing to see what\u0027s changed between two versions of that module you may not care if stuff has changed in the stuff you\u0027re not using so again be able to compare the schemas and subset it in to the stuff you care about I think gives you almost like the perfect answer there is some some cases where this is difficult to do you can\u0027t well known it\u0027s very hard to have tolling that would check the description statements and find out whether there\u0027s some change in the semantics behavior of a data node until our machine learning gets a bit better XPath expressions and "
  },
  {
    "startTime": "00:24:25",
    "text": "regular expressions in other cases where it\u0027s very hard to see what has changed it\u0027s very hard to tell if it\u0027s a backwards compatible change that\u0027s been made in those cases so I think there\u0027s consideration there as to whether we use some form of annotation potentially to mark those cases where it might look like it\u0027s about as compared to a change but it\u0027s not or vice versa it looks like a non box collateral change but actually it\u0027s backwards compatible any questions on this one okay come on automatic sliders is so so this is just a chart I\u0027m not sure how accurate this is it it\u0027s effective trying to show you the dependencies between the the modules between the the drafts with the darker blue arrows showing sort of proper dependencies and then the lighter colored arrows sort of showing user level dependency so where you may choose to use semantic versioning scheme for example but there\u0027s not actually a dependency between the drafts and you can see that this module the module revision handling sit to the top and pari has a key dependencies then everything that might want to use semantic versioning scheme \u0027obviously has dependency on that but other schemes could be used it\u0027s just one choice the packages draft depends on the module versioning and the package version selection of C depends on that one and then the schema comparison touring depends on packages if that\u0027s what you\u0027re comparing or modules if that\u0027s what you\u0027re comparing now next slide and that\u0027s it for me so any questions on that overview section at all in terms of the sort of overall picture of how the solution fits together you have any examples examples of the first the first one versioning the Motorama version right and we\u0027re using revisions so if you have an example the new revision format looks like yes in the in the next so the module revision handling draft will be covered in detail next so that covers all that and a lot more detail of those examples in there I will talk about the packages version schema draft after that Rashaad will talk about the package version selection the two that we\u0027re not covering any more detail today is the semantic versioning scheme that\u0027s based on what was there before we have written in yet and the schema comparison told him that we haven\u0027t really looked at in great detail with you the design team really want the working room today I think what I would like to know is "
  },
  {
    "startTime": "00:27:26",
    "text": "where the people in this room think that as a sort of solution space of solving the entire problem is does this look like the right set of things that we are solving and does it look like it covers all the pieces you would expect it to cover does it look like it\u0027s morally the right approach so obviously they\u0027ve become some individual drafts and things but does this look like overall the right thing then work is needed exactly all of this with you show there I am I\u0027m not hundred percent sure that maybe the scope is too much over there trying to put it but what they see as a problem when doing yank are the dependencies and figuring out what are my dependencies what they have flawed in order to enable the service and we are planning to be able to create abstractions at different layers that going to change where they\u0027re happening and be able to take into the content and maybe even prepackaged those things up and saying oh here\u0027s my whole package and and it\u0027s it\u0027s getting deployed you can unit tested etc it is very helpful exactly how to do that that\u0027s a question not because there many of the issues that you\u0027re just beginning to the stuff in the other comments so I think I\u0027m bashing them up they start at the end but I think the plan will be to try and continue down this track effectively and try and get these bits the doctors as we go along earlier we\u0027re looking for the design team to come up with a full and set of it documents that answers all the requirements and then bring them to the working group for further option call so it\u0027s important to make sure that the working group is aware of what\u0027s going on in the design team and is generally aligned with the answers once once they become working group documents we\u0027re going to follow a normal working group process which is everyone in the working group has it will have an opportunity to provide equipment influence so it\u0027s not that at adoption we\u0027re done it\u0027s that we have a focus team that\u0027s trying to give us a starting point don\u0027t you blurt about the pre-comp so when you\u0027re the semantic version sounds great I was always wondering why it didn\u0027t start out that way so it that\u0027s not great when you\u0027re talking about visualizing the difference between schemas would it be the resolve schema once you\u0027ve resolved all the groups because usually that\u0027s what consumers baby eyes are mentally visualize or is it visualizing I think I think both is answer so I think you\u0027re comparing a "
  },
  {
    "startTime": "00:30:26",
    "text": "module itself then you might do it on the module text but even even then actually I think you have to resolve the sub modules and allow groupings and things to move around so I think it\u0027s sort of the the resolved schema to some level but I might not be fully resolving all dependencies it might be this module with dependency still hanging in open or it might be the entire scheme like a yang package you take the whole package resolve everything internally and it\u0027s a complete package you then then look at the actual abstract syntax tree for the yang effectively constructed and could be comparing those on a node by node basis okay I think it\u0027s time for blush so this draft is there let\u0027s say the main out main output at this point we derived it from the complete solution we try to separate parts of it and we believe that we had discussions on the last IDF on the on the meeting but also outside afterwards with many people we believe that all the all the main comments were included one point is that this applies to yang modules so sub modules they are very closely connected to module 2 the modules themselves so they should just follow the modules themselves next please this updates a number of current RFC\u0027s one is the yang one that one because the update rules are sometimes not not specific enough but sometimes they are too strict those updates yang library because the versioning provides additional information that we want to include there and also the authoring guidelines for example hydrogen information should always be present and and life cycles of the different schema notes should be also included so what do we have here we have an extension that will go into the revision statement and include indicates that this revision of the yang module is not known backwards compatible and BC to a previous version if if it\u0027s not there then it\u0027s assumed or it must be backwards compatible we also explicitly state that we allow nonlinear yang module development so branching and updating previous "
  },
  {
    "startTime": "00:33:29",
    "text": "previous revisions which was not forbidden in 7950 but many people assume that they are there we will have linear development only we introduced to revision labels because many people many companies have nice versioning scheme Sykes same wear or some other ones and they would like that information that gives a short compatibility information short history information in some form to be included provision or derived was also mentioned earlier so that states that you can import something that is newer than whatever mode module date you chose but it can\u0027t be just a date because of the nonlinear development anymore we had to update what backward compatible and the unknown backward compatible changes mean because we want to accept some NBC changes and especially the status related changes were not clear in 79 15 we have some additions for status handling and yang library are updates as we mentioned next slide please so maybe the most important part is here the red thing we have and BC changes that indicates inside the revision information that this revision made are incompatible and on backwards-compatible change to compare to the previous revision and it\u0027s always in this full list of revision statements the previous revision that means that you should not remove revision statements maybe you can remove the description part or shorten the description parts but you should not remove their revision statement itself because at that point you lose this information also you should add a revision statement all the time I think it\u0027s not mandatory in 790 50 every time if when at the Green Point where we just added functionality we don\u0027t have this revision extension this will allow normal in their development so here the February first revolution date was also developed because whatever customer didn\u0027t want to upgrade to the new version and then we have two branches and there\u0027s actually no limit of branching so you can branch the branch and then again and again do an infinite tree although that\u0027s not a very good practice but if business needs force you you can do that because if you look at it every yank file in itself is linear "
  },
  {
    "startTime": "00:36:29",
    "text": "but the yang module might have multiple files that go on different branches in on this tree we don\u0027t this boss this is a possibility that can be misused we don\u0027t recommend arbitrary branching especially not for as the earth and each yang module the text by itself will represent one route from the leaf of this tree up to maybe the root or at least to some level next please so we have revision labels because the NBC only tells you that yes we have and change but to actually understand that you have to parse the module already and look up all the revision statements which is quite a bit of work so as an alternative you can have revision label that contains similar information this draft does not say what is in the revision label these are examples and we can will have multiple drafts or at least one drafts about at the same where can be in the revision label the format is rather free only concern is that it should not be not be mistaken or as a date and it can be used later for other in the import statements as well yeah next one please okay here is an example of what the revision labels for assembler would be if you see that the main number changes every time when we have this read NBC changes extension there so from when we just add something then we only go from 3 to 0 to 3 1 next please okay import by revision or derived that\u0027s a very important part of this work so we said the simple import without any revision date is too liberal if you have the revision date there is too strict what the usual case is that I want something that includes the functionality I\u0027m depending on already and anything later on I very much hope that it will not remove what the functionality I depend on it\u0027s not a strict promise that everything afterwards is good for me but usually it is enough very revision or derived can be based both on the revision label and it can also be based on revision date or derived would it stop at a module revision and has NBC changes no no "
  },
  {
    "startTime": "00:39:31",
    "text": "should it no because most of the time the NBC changes don\u0027t impact the import there is a risk there and that we had in earlier versions very complex sets where we said that from this version to that version and it gets more and more complex and usually you want to leave it open-ended because you don\u0027t know what changes the new revisions will bring and many many times that even if the changes are NBC they won\u0027t impact your import won\u0027t impact your importers so this is not as if you really want to be strict and really be sure then you must check every every date but we don\u0027t want to be there actually in the previous versions of the same draft we had more strict and more complicated solutions and this was the most user-friendly and feel helpful the revision will derive dependency it\u0027s almost like a source time dependency when you actually come to use these modules you knew something like downline really on package that will constrain exactly which version you\u0027re going to use anyway and in the case that something comes along and breaks your source dependency they made some nautical change at that point you\u0027ve expected probably to releasing a new version you revision off your jewel to do the import then fixes to a later provisional derived or changes up to them to fix the important pence again so we think that this is the right balance being not too strict because otherwise if you limit it it\u0027s more likely than actually but I said you\u0027re not gonna be impacted you start update your module anyway so we think it\u0027s better to be better to ask forgiveness them to be too strict performed okay I think my only analogy here would be like suffered you know when you\u0027re building and you have dependencies on libraries and you\u0027ll say I depend on library you know three dot one dot two so if three dot X I\u0027ll support but if it ever goes to for TEDx I don\u0027t want to support that so sometimes there\u0027s the ability to put brackets or limits into how much future you want to support automatically but I accept you know it\u0027s been discussed by the design team just want to make sure that was something that you guys have to cover and also previous might as well I think it was yes so this the the two future statements that you\u0027re creating here is this what I understand to be possible extensions to yang quarreling gang language yes okay max next okay so in order to define what is when we put in those statements we have to define what is backward compatible and NBC 7950 gives us a very "
  },
  {
    "startTime": "00:42:34",
    "text": "good basis for that but not the full statement because deprecating and obsoleting nodes can actually be NBC or BC depending on how it\u0027s implemented what we assume is that if you deprecated the node it\u0027s still there so that\u0027s a backwards compatible change but if you obsolete a node then it will be removed so that we define as a non backward compatible change also reordering data definition statements in most of the cases that should not hurt anyone so that we allow that and anything else is known backward compatible but stating that opps obsoleting is NBC that\u0027s a definite change from 7950 next okay we have the so that we have the status statement in yang we want to change what deprecated and adopts elite means we still is this is not a mandatory statement so it\u0027s not a must or a shell but we say that deprecated should be still there working fully functional while obsolete should be removed if if you don\u0027t remove obsolete that can or that can also result in surprising and errors so even for obsolete I think we is important to define this but for backwards compatibility we put into the Yang library to the extra leaves that states that do you follow what we recommend here or not if you don\u0027t put these extra Leafs then you are backward compatible meaning you can do anything you like and your clients will be surprised maybe also when you deprecated or obsolete something often you have a reason for that often you have a time line when you will actually remove it maybe you have a replacement so a status description statement was added for that so I like the idea of having an ability to specify whether or not the server actually complies or not that being the case why aren\u0027t these musts i mean and backwards compatibility i three months the server has data more data than it should but for the first bullet point where it says it should be implemented its must I mean how else can we have interoperability if it\u0027s not sure the clients aren\u0027t sure that it\u0027s actually there because you can check in the yang library that is it ro the deprecated nodes we implemented and functional if you sorry okay so the third by you saying gang library you\u0027re "
  },
  {
    "startTime": "00:45:34",
    "text": "talking about the third bullet point yes that indicates if you follow the first two or not but are you saying that with third bullet point that is possible for the server to say that the first bullet point is actually those two will contract you must not judge yes if you yes if we next then I agree that we would try and get these to be fine since you\u0027re doing extensions you can change the rules for implementations that implement that extension so you can say if you implement this extension you must do these things okay and it\u0027s probably worth reducing the number of options so in the case where you have an extension think about making things more bus than shirts Martin be account held previous meetings a very strong opinion that we need to indicate in the yang library whether whether these first two rules are followed or not we should not make them must probably could get about masks now that\u0027s what we want isn\u0027t it yes I agree with two you know but we had some pushback that\u0027s why we have this in young library to indicate whether these are followed or not please so what we have in the yang library is two nodes deprecated nodes implemented obsolete node up steps and these are the first two bullet points we have discussed lately and if they are not there and then there anything can happen with these that\u0027s one of the problems that in yang one that one that they the definition is too open the other problem was that currently yang library doesn\u0027t specify which version which revision of a yang module is imported if multiple revisions are present and that might mean in some cases that mandatory data nodes are present when we thought it\u0027s not or mandated three nodes are absent when we thought they would be there so it\u0027s kind of a bug let\u0027s say or a missing point piece in 7950 so it\u0027s not the rules data model of some of angle eyebrow is not modified but the rules what they mean are modified to make it very specific "
  },
  {
    "startTime": "00:48:35",
    "text": "which more module is imported in this case excellent or in a question whether the second point here exists really bug fixes is is something that a raft failed to cover or not my precious is a change of behavior offensive it couldn\u0027t be covered in an errata but he was opening that if we could get in after that would be better he\u0027s clarifying I hate Lee that\u0027s ambiguous today we\u0027re still trying to digest what exactly what seconds no it\u0027s both 1 \u0026 2 of the second so I need to see the errata before making a call as to the level of change that\u0027s being done yeah okay to judge whether it\u0027s right or something is suitable for errata or abyss or update okay yeah I think the specific proposed text we have to look at not the problem but the solution ultimately if you believe it\u0027s a clarification you should probably just submit it and then we can debate it except that it will be in a row then it will be at a unverified errata and we can add it to the list or discuss it so you\u0027re right on track but you\u0027re on track for like another 10 minutes okay yes data it was required requirements to do say what it what happens with versioning instance data itself is not version because what backwards compatibility means there that\u0027s not defined on the other hand it back versioning is very useful for instance data understanding if the schema defining modules can be somewhat different next please and then we have some guidelines telling others how to do changes that not to do NBC changes and try to make the changes for the clients that\u0027s painful use deprecation use this more flexible import use status information and such things and sometimes duplicate data to "
  },
  {
    "startTime": "00:51:35",
    "text": "be able to use both new and old versions or potentially sell right version selection next please if clients is kind of a requirement of recommendation for clients that yes changes are coming and they should tolerate a number of changes and also they should monitor what kuat happens with modules so they should check if the module is backwards compatible and my first answer is I don\u0027t know don\u0027t care this only says that we have a revision label where you can put in some numbers now there will be a separate draft about Sandler based the revision labels yes ember has difficulty with unlimited branching there whatever you put into the revision label will have its limitations or maybe you have a versioning number version numbering scheme that\u0027s all powerful them no limitations but that\u0027s not part of this draft again we here in this draft we just defined that there is a place where you can put that in the further drafts will propose the same where based a visioning system and there they will have meaning but not in this draft we here just we have a placeholder so Robin just have one comment to that so you so somebody might a vendor might choose to choose their module labels as foo and bar and what said like choose whatever they want so he\u0027s whoever\u0027s doing that scheme is define the semantics of the scheme so very quickly to cover the next steps there\u0027s just one slide here actually we sort of discussed it earlier so at the beginning we were going to seek adoption for this first draft I think the feedback from the chairs was that actually they want to adopt this as a "
  },
  {
    "startTime": "00:54:35",
    "text": "set so I think of fatally we\u0027re going to continue on the same track any comments we received on the module version draft will update but the other ones will effectively work on the other ones the static version scheme yank packages in version selection drafts and also the tooling one but I\u0027m not sure we\u0027ll get those all done before the next IDF there\u0027s still a lot of work there and then on seryung packages please that\u0027s it so I already covered a little bit of this this is just a little bit more details and so next slide please on this and yank packages and so yes effectively the idea here as beforethe said \u0027is to diversion sets of young modules together with their dependencies and in terms of how the yank packages draft is written at the moment it\u0027s using the yang cember solution as a way of identifying or the the version number scheme for these modules that\u0027s the one thing I think we need to update or at least discuss relative to how we\u0027ve changed the modular versioning and made the semantic versioning number a label and option thing rather than things tied in the packages could be hierarchical so a package can import other packages and that gonna curse down the packages themselves can be I their complete or incomplete so you don\u0027t necessarily have to tie off all your dependencies depending on what you\u0027re doing and that might help if you were you had dependencies and like type modules and things that like you may not want to depend those the package themselves can be available from yang library or they can be available on a lot of line and yeah instance data and in the yang in stated discussion there was talk about how you identify the schema using yang library I think yang packages might be another example which were a good way of defining that schema a better way because it\u0027s it\u0027s more what you\u0027re actually trying to do rather than yang robe it\u0027s returning slightly different information and as I mentioned the draft is slightly out of date because it hasn\u0027t been updated with the changes that we\u0027ve done to the module level versioning you say it works but I think it does say yes it\u0027s just okay so why do young packages of what we\u0027re trying to solve several problems here we want to actually get consistent version sets of modules just versioning modules individually when you have hundreds of them or tens and different organizations becomes too hard it\u0027s too complex and it\u0027s too likely that different vendors will implement different versions of the same modules and get too many incompatibility so for one vendor that might implement B GB version 2 and Ice PFE one and on different OS or different vendor while does BGP v1 and OSPF v2 yang models and then when it comes to an "
  },
  {
    "startTime": "00:57:36",
    "text": "operator and that to use these well neither those sets are ideal because they can\u0027t get a consistent set across both of them if you\u0027ve got young packages and your and your versioning for like the ITF routing protocols and every time the module gets a new routing module gets updated you add that into the yank package then and a new version that yang packed you\u0027ve now got a more linear update in terms of how these packages are evolving but you\u0027re not fixed to that you can still deviate those the packages that you still use your override and say actually I\u0027m going to support this baseline package with these changed in these differences to it another one another use case for them is to avoid downloading this this full set of modules off the device and having to check your exactly what you want because that\u0027s a hard thing to do it\u0027d be much nicer to say actually I support this package or these packages these API is the things I support with these modifications and rather have to do an individual check on every single module either I\u0027ve got a higher level conversation about the API that you\u0027re supporting and as to say and again you can do this with yang library making the schemer available offline so you can check it in advance and you can design your tooling to expect to talk to a device and expect which which API which package version it\u0027s using and correlate those is easier than how to deal with full sets of of packages when the full sets of modules when they differ next please so this is just an example I\u0027ve I\u0027ve got a simple ITF network device version 1.1.2 there\u0027s some metadata description and other information where you can wake and a URL of where to download that package from and that lists a set of modules that implements here and it lists a set of modules our import only and again this could be fully resolved it might not be resolved and the definition includes metadata like URLs where to find it it lists features that mandatory so which features that if you implement this package you are obliged to implement and support it has a list of the imported packages not there\u0027s none shown here but list the pictures you importing list the modules that are implemented by that package and the import only module it\u0027s a very similar to yang library from that point of view except it recursos and has a list of imported packages and then finally and again it\u0027s not shown here is import conflict conflict resolution so if you combine two packages and they each those packages import different versions of modules and you have conflicts so when you do that when your package pulls in two separate packages with conflicts you surface and you specify exactly which version of which module you resolve to next slide please one more slide so this is another example package example ITF basic "
  },
  {
    "startTime": "01:00:38",
    "text": "routing package and this one is importing from Network instant network device is one that 1.2 and then so it lists the extra modules that are implemented as part of that extra imports on top of that and as I said before any version conflicts or change must be explicitly resolved that\u0027s that\u0027s one thing that\u0027s critical here the forgiven package definition the list of modules that it\u0027s using is is exactly tightly defined that\u0027s the specific versions and the package version indicates the nature of changes in the modules or package imports so the version number that we\u0027re using here is again using like a somatic versioning scheme so if you update your package to include a module that\u0027s changing a number non box compatible way which in semver would mean going from no 2.00 to 3.0 to 0 then your package would also have a major version change in its version number as well if you had minor version changes in your packages or you own or you\u0027re importing more modules in your package definition then you have a minor version change so it\u0027s using the same send their ideas and rules and things for doing versioning applied a package level rather than a module level yeah two slides back you said that if you say that you support the package you\u0027re obliged to implement all the package versions as they are I just wanna clarify is that include features and or and or deviations so you you what you\u0027d be allowed to do is you\u0027ve allowed to run the saying you you implement this package you would implement your own package on top of that or they\u0027re in they includes this one and then has it extra modules with deviations listed in terms of features you would list the features you support but you\u0027re obliged to support the features that are listed here the mandatory features or otherwise deviate those nodes so you can steal these deviations and changes but you have to expect them explicit and then the key issues the key question in terms of updating this draft so the current package draft of actually draft uses yang Simba\u0027s the versioning scheme because that was based on the work that we did for ITF 104 where it looked like that was the version seen we were going to use but the latest module level version now has been decoupled so in terms of the module revision handling and it\u0027s and its concept of backwards compatible versus non backward but non box collateral changes and you separated from the really the versioning scheme that you\u0027re using so yang semver is one of the examples of the version scheme you could use so I think probably it\u0027s better for yang packages also to have that same be coupling so for it not to have be hard-coded to a particular semantic versioning scheme but just to say actually it can use any scheme that\u0027s partially ordered sets of "
  },
  {
    "startTime": "01:03:41",
    "text": "identifiers to have that more flexibility in to what\u0027s in terms of what it\u0027s done or in terms of what it uses and allow yang cember as one example of what could be used in that case then the question is is to be is how flex lie you in that how do you do that do you have an identifier or an enumeration to identify the different schemes I\u0027m not sure we want to have a huge proliferation of them because every single different scheme will have impact on clients that need to be able to compare these things so but same time toyotas yang Semba might be a mistake does anyone have any thoughts or pins on us Charles that call for table more like the version of the package as it said it would be ordered so is it implied as the version of the package increases the version of I think entirely decoupled so I think you\u0027d be allowed to there\u0027s no correspondence between the package version number and the version numbers inside other than other than the semantic change the package so if you\u0027ve made a change to the what\u0027s included in that package this numbers compatible because you\u0027ve changed your numbers compared to a module or you\u0027ve down read the module that would be like a non box non backwards would change to that package definition so it would go from 1 0 0 to 2 0 0 if you were doing a down Rev I think does that answer your question yes any other on this issue at all opinions are you coming up because we\u0027re speaking next complete resolution you mentioned I think in one slide between two different packages in a different slide you type one package how do you explicitly yes so you see effectively say on the config resolution say I want to have this particular version and I think I try to remember having read the draft recently I think in terms of import only again you might need to identify which specific import you are overriding and the and the overriding version but it be "
  },
  {
    "startTime": "01:06:41",
    "text": "only other day you\u0027re explicitly saying this is the version I\u0027m gonna use in the circumstance I think you are now up so can you elaborate either on your view of the design team view of why you want to allow multiple ways so in terms of the modular version the reason for doing that is because that\u0027s what some people wanted they thought that they don\u0027t like the yang symbol scheme because they find it too restrictive some people other people think it\u0027s not well why don\u0027t we just use the standard Semba and I think it\u0027s not flexible enough so there\u0027s difference opinions as to what version of scheme is required and if you are a vendor and you end up having arbitrary branching of your modules for whatever reason then the semver scheme we defining can\u0027t accommodate that deliberately so it\u0027s limited deliberately some partial branch but not too much so I think that\u0027s the reason we had that separation in the module level stuff and then in terms of packages the question is whether if you\u0027ve got modules that have that flexibility and you package them together you probably need a versioning scheme for the package has the same number flexibility we progress from the design team to the working group because to the eventual something we submit to the is G we\u0027ll really want to think hard about whether we want that flexibility because anytime you have flexibility but that really leads is to interoperability problems and of course the reason we have standards is you know for interoperability so if there\u0027s good reason to allow that different off those different options sure but if there\u0027s not you know we should think really hard about the cost of that flexibility greatly if you want a question about the different water networks continue question on that conflict so I need werden conflict must be how can we resolve that so if for example this was importing two modules to the two different packages and one of them he was using IETF types version 1 0 0 and up was using ITF types 1 0 1 then this package as well as doing the import would say I\u0027m going to use ITF 1 0 1 as my version for this package then but each pack each tire package each time you\u0027re combining modules with two different packages two or more packages you\u0027re explicitly resolving that you\u0027re specifying exactly which module you\u0027re using anything interface Bank on do "
  },
  {
    "startTime": "01:09:45",
    "text": "another module they are not a package need to user interface 2.0 they are not compatible and I hope to use two packages together how do I do that without I think is something you can\u0027t do I mean in the day if you\u0027re trying to combine different $6 another set foxy application your doctor C library Lipstein southern euros we all pay we have both live in there so you define two packages in that case interface modules - that one though they were a madman but if you\u0027ve got that sort of splitting your yang ecosystem where you got the modules that that different and there and there\u0027s no way you can combine them you got some dependencies on the older than you well you\u0027re combining them into one package so if you got dependency says half of my package depending on ITF interfaces one and half as depending on ITF interfaces - and there\u0027s significant changes between the two then you\u0027ve either got to split that and just do them for one and a separate set of packages for the ones that depending on version - you can\u0027t you can\u0027t magically put those things together this won\u0027t fix and the same system together then yang does not allow that yang says you can only implement a single version of a module you can import multiple versions but in terms of implementation you can only forgiving scheme oh you can only implement one version of a yang module actually it\u0027s possible if you have two different Netcom for restaurant servers each server can has to have a specific implementation show up in the device but in that case you\u0027re in two separate packages working packages sometimes may not be practical too much education about that but it but the same issue exists with using yang libraries is no different in that scenario so you\u0027re trying to you can\u0027t do it yang packages you means you can\u0027t do it young library either there\u0027s no fun little difference there it\u0027s just how they\u0027re being pieced together can you use the mic please only one person can represent can be yes so I\u0027ll "
  },
  {
    "startTime": "01:12:55",
    "text": "be presenting the version selection graph on behalf of Robin myself so this slide talks about why are we doing this well this comes from the requirements 3.1 and 3.2 from the requirements draft you spoke about and the what this is basically saying is because yang modules are change in non backwards compatible ways we need to help clients migrate so servers can support multiple versions and help clients select which version they actually want to run with next please so the summary so it allows servers to do non backwards compatible changes without forcing clients to make immediately migrate it does make use of the yang packages draft Rob was presenting earlier and it provides mechanism for servers to advertise what versions of the package is the support and it allows clients to choose among the ones advertised which one they want to run with on the pitch Lee recession next please so before people start throwing bricks servers are not required to concurrently support clients using different schema versions those things are optional servers are not required to support every published version and they are not required to support all parts of all version schema the important thing is when we say support non backwards comes come all changes if you remove functionality in the later yahng yahng yahng version obviously you cannot support the newer one and the older one but in some cases if you\u0027ve we organized your yang module you\u0027ve moved your nodes around in a non backwards compatible way the server should be able to support all the older version and the newer version next please okay so the overview which you\u0027ll see in the yang tree NEX is you know a version schema it\u0027s a yang schema which Rob was talking about with an Associated yang revision that could be the semantic version number in the draft which will be done soon and yes as I said this could be yang package the schema set is a set of related yang schema one per datastore the server support configuration for the default schema and they also support configuration for what we call the secondary and maybe more net confess count instances to use different schema this is done by a port number for both net count and restaurant and for restaurant we also support the the different route path which we source to see like which schema to use this is it for this slide next please and this is basically the schema tree for what I was just describing you can "
  },
  {
    "startTime": "01:15:55",
    "text": "see you know you can you can configure your the schema sets and all that or read/write but in terms of the information per datastore that\u0027s all what the system the server decides to support I don\u0027t believe we got any comments on the we probably need to do in Ex Rev based on the latest discussions from 104 work and all that and hopefully we\u0027ll get this cut will get comments on this draft and the yang packages draft and as Rob was explaining earlier in the next steps for the design team we actually want the this draft which is currently private draft to be part of the design team orc questions don\u0027t feel obligated to rename it if you want to rename it that\u0027s fine the government okay not to okay and as a contributor seeing the protocol names there alerts me just a little bit macabre scoffs you know what about other like co-op do we have to call out those protocols by name here well if we just support port we don\u0027t have to I believe my recollection is they\u0027re separated because Raskin has the route path okay support but I mean the route path support has not been discussed maybe we\u0027ll take take that out so since they\u0027re optional you can still have both of them and then wholly set that when they promote a football yep easy too soon okay that\u0027s can do you have a suggestion here of how many think we should attack to know the keystore draft some things you\u0027ve got more separation so is that what you\u0027re suggesting might be a good approach to use it I was leading up to it I was looking at the port and I was wondering what the intention for that port was and why wouldn\u0027t we be using the the appropriate client server drafts from my comp oh yeah what\u0027s referencing notes directly okay I need that works yeah well I mean so this isn\u0027t even adopted work yet but nice and the that working neck off will be done before this and so hopefully it\u0027ll be it\u0027ll just make sense where I\u0027m set then I actually related to that I think eventually this draft who then would probably end up in good michael wings up with a yang model for [Music] is a microphone hello today I want to introduce a data file unit module for in "
  },
  {
    "startTime": "01:18:57",
    "text": "the measurement okay sis chapter 2 funding model fold is a base the network policy management and it can provide some billete to fold an imagine function to control that information a monitor state changes on the network element and if the sister if the trigger condition be meted and you can perform some simple and instant action and this document has we discussed toys in the working group and the since many people are interested in two interesting related works so we update sir document and in this version made a new leaf a group ID it can be used to group a set of events that can be the group a set of key witnesses can be excute together to perform some specific tasks for example to provides a service assurance and the way also optimized must even leave it moving from action lists to trigger condition lists and allow the one even\u0027s trigger to reference nazareth even stuff nation and the way a change stratford condition in choose a variation condition to further clarification difference between poland trigger and the variation trigger and we also simplifies action container in this size will provide our example how to use this module to perform some and here with the fund even a and it\u0027s being used to monitor if the trigger a to be we be set up so it can trigger even the B and the even P use a call even if the even exist and there\u0027s a polling condition net sending the triggers corresponding action to active standby a fair work okay and we use a group ID to groups is to event to perform the proverb provides a sort of surance a test okay okay it says document have discussed at least it system is already discussed three times and is same some many people are "
  },
  {
    "startTime": "01:21:57",
    "text": "interested in this works so I think maybe we can think about document yes is there somebody comment at the mic processing units just is provide for routing policy and here we use this doc use this module to perform such high service assurance if you here is example if for example food loss package across the street then it can perform the relate action for example logins you lost packet cross their food and then perform some action to Octavian birth of fare over taxes yeah yeah yeah we want to define the more generic model and they can perform provide ability to do service assurance to our munchers yeah I understand your question but here our document ma do not want to coverage routing policies the walks and here is just to provide okay if some condition met and we can do some management walks like starting okay policy documents one of the co-authors I like I just like to "
  },
  {
    "startTime": "01:24:57",
    "text": "state that this is more a data plane document whereas the routing is strictly a control plane policies for a control plane for you know the the selection and complete and redistribution and Newport export complete protocols so there isn\u0027t other than in the word policy yes so yes so I understand this record I think I understand this correctly there is no correlation between either work neurotic working group in the policy there using the event condition action as well as well as some constant question and in this work here is that accurate now this work here I would have mixed on standings incorrect is this work just data plank or is admit the general was is it meant for control playing or other usages a single the intention for these the motive actually means that provider of closed loop was of its managing that close to a life cycles of its maximum punishment and so they can Kalu imagine model and probit model so is that using this kind of policy in order so they can trigger the automation so is a management automation is it so is it destined for applications of control planning data plan or up I think not sure we should right next to the control plan but I think that may be happy to the state of a name and imaginary cheapening thank you um who\u0027s read Benoit clays so goodnight let\u0027s just explain to him some bio information so we created the working group called super in the past by use of policy scratcher structured reaction shamrock was there became an interest raft he has submitted their of the main reference which is then in that super working group the goal must be something generic so they had policy that the routing policies we\u0027re going to be using that and security policies to be reusing that yep so now it\u0027s in the next right it\u0027s based on the policy document which is convert raft but reg do something generic while the world has been moving out so this is like discrepancy well "
  },
  {
    "startTime": "01:27:59",
    "text": "yeah and everyone still needs one of these two for each of their applications um so who\u0027s read this it\u0027s actually been here twice I believe so far the zero zero and the zero one have been presented here so who has read it either in its present Oh to form or in one of the previous forms okay so some people have read it of those people who have read it actually let\u0027s just generalize that let\u0027s say yeah who here is interested in the topic and thinks we should do work on it okay no hands went down there so that\u0027s a reason that\u0027s a reasonable number like that is at least as much attention as many of our drafts get who thinks we should be doing this somewhere else or not at all okay nobody so it sounds like you\u0027re probably here for better or worse yeah so we\u0027re at a starting point I don\u0027t think we will yeah yeah no no we want to pull for working group adoption after this I think you\u0027ll be interesting to see how many think this is a starting point we ask that the last meeting and there was a pretty small number you know interesting to see if that changed or there are people who are not on the list of authors presently who are interested in this work with an eye towards participating in any hands for that okay well one partial hand from somebody I greatly respect so I guess that\u0027s probably of some value yeah I think we\u0027ll probably pull for adoption on the list after the meeting so what it sounds like okay thank you next hi anime based notification and jin-woo is presenting yeah my colleague er is not here I represent his topic my name is him actually the topic is powder empty base notification for antenna "
  },
  {
    "startTime": "01:31:00",
    "text": "based another configuration update actually this job has been around for a while actually moved from net cough actually has already presented twice in tent mode actually my colleague actually revised this chapter base his experience on the network network a conversation very question so we sinker we most negatives job to turn an empty ative actually for actually but you know they can work together with the problem is a negative right now can compare the difference between the datastore by the limitation is the latter type ability to verify whereas an elevation from Indian or other sauce take effect so we we sink so that the the solution we propose is that affine notification actually to reporter this cannon a verification event to check these miscalculation issues but the week not you know check out all these miss conversion issue because for for summer cases may rely on you need to export data from different device so so we gave some cases like you wanna maintain the considered a consistency in network configuration may cover a two different device you want to maintain the consistency as it is something we cannot just use this event and here we gave one use cases and we think we can use a native to compare the antenna with the operational data store and we have two different cases so for some object that may be present in but another present in operational for example you may have an interface but another physical exist so it can exist in antennae but not existing in operational another cases they may present in operational but not a present in intent so typical case actually is interface MTU and so here the maximum weight way proposed actually we need to you know make sure the server can detect the hardware changing so this may rely on the system interaction with the hardware so based on this assumption actually we can detect whether there are some miss compression issues and probably actually here okay we\u0027ll get some phrase we can compare the difference between in 10 and operational and we can make sure all this actually caused by some mystery sauce and here is "
  },
  {
    "startTime": "01:34:03",
    "text": "the motor structure we make some change actually we introduce a application tag actually to provide additional to provide a new parameter to identify each update and also we clarified that difference with native and we think this can work together with a nominative and this is the position of the CMD notification on education and we already present this in an outside eye TM meeting and we show how hot the position of this message so this job has been around for a while and we think actually the seems concern synergize with any media first so we want to hear what are you thing about this again yeah so I think the challenge with discussing this since I don\u0027t see anyone running to the mic at the moment is that at 104 and 103 there were pretty few people who had read this I guess that is their queen our show of hands of anybody who\u0027s read this in either its present form or the I guess o 1 and O 2 versions that are have been present previously prevented presented okay well there\u0027s a few does do any of those people have the willingness to express an opinion as to whether or not this more work is worth progressing Rob I\u0027m gonna put you on the spot so I\u0027m not sure it turns off of how I imagine your sisters working I would imagine more that the devices were just monitor operational and monitor the system that way around so rather than getting errors back from the ply failures whether used monitor operational and detect the changes between what you as an operator wanted the device to do and what it\u0027s actually doing so that\u0027s one observation the other one is I think that it\u0027s possibly really hard for some systems to implement this to be able to report back when some of these operations have failed because to be committed to the running datastore the configurations there the actual apply phase with system might go through many different demons and my how other intermediate failures "
  },
  {
    "startTime": "01:37:03",
    "text": "and things like that so I think generally my experience is really hard to track these errors back we\u0027ve always struggled with this sort of thing so I\u0027m not sure that helps I\u0027m not sure yeah one clarification amusing actually medical computation and verification is very popular that\u0027s a lot of you know research on this and you know this seems actually morning--i to this systems data that are put into the operational data store actually we can leverage this network variation Maxim to to do data is possible so that\u0027s why I bring up this kind of idea again it\u0027s a certain thing for the verification side and check into the verification the configuration is valid what your state\u0027s all about completely agree with and that makes sense but in terms of the next set of applying it which is sort of a sickness or semi asynchronous and systems are aware of that\u0027s the big thing that\u0027s harder than trackback so I think that if you have a simple device you may be able to do that and may have value for that but I think there\u0027s many devices that this would be to trigger to do and instead you would you expect the operator to be monitoring the operational safety device and the applied configuration to whether this is happened or not and another observation here is that some things this configuration takes a long time to be applied so so what do you do in that scenario Jim Carrey Nokia so when I read the draft there was a couple things that were it was running through our mind I\u0027ve just couldn\u0027t I just couldn\u0027t form an opinion on because what I\u0027ve seen here is is what we\u0027ve done in the past is grated up the examples that you use this is well if I have something tonight of the sign oh so did you did and now I\u0027m going to put it and there\u0027s a difference between that and call me differences between data source now it\u0027s gonna put the easy assignment problem right and in the past we said okay those are just status I\u0027m on the side or not I put my own tl-one things right so that\u0027s usually solved in a status type of thing all right so so I was struggling in what we wanted to produce notifications for right typically to produce notifications when there\u0027s some sort of mystery but I on a Sunday to be this but someone plug in that right and then I need to get any of that from this particular draft those things where I think it\u0027s also saw that those particular notifications are generalized notifications there\u0027s notifications in the context of the problem that you\u0027re trying to resolve on "
  },
  {
    "startTime": "01:40:03",
    "text": "I\u0027m going to do a quick meet I\u0027m going to do that type of stuff and so I that\u0027s what I was like going on I don\u0027t know if this will do you realistically if this will be you and you really use because I think it\u0027s the problem the maintenance of the use in the and the person or the enemy that\u0027s interpreting that is not the server the thing being actuated for the thing that\u0027s doing acts like the client and that\u0027s that\u0027s what I was going through my head as I go through this I go I don\u0027t know there\u0027s other ways of doing it thank you I think what we\u0027re hearing here like is some people who have given this a little thought but they\u0027re not they\u0027re not necessarily interested in being consumers of it and that would actually I think be the sort of thing that would drive interest or its implementation and refinement and would also get us better feedback so I think um I I think borrowing some kind of expression of interest of that variety on the list this is probably not something that we need to revisit if if you know if we can find that or muster the energy in the community for people who are interested in it then I think it\u0027s pretty easy to come back here and go well we\u0027ve reviewed this enough that we can call for adoption but I don\u0027t think we have I don\u0027t think we have the level of energy or enthusiasm with respect to being consumers of this that would cause us to to really ask that question at this point okay um thank you for your diligent efforts however yeah thank you to refine this into something and to seek feedback thank you it\u0027s in the other room that\u0027s not it\u0027s noisy so watch their semen on to this one we focus on a transition "
  },
  {
    "startTime": "01:43:12",
    "text": "I\u0027m gay protocol translation you see it yeah I see that okay this is a tumor again and I want to talk about an MD protocol transition issue discussion there\u0027s a many discussion here we already have lot of discussion on these kind of issues actually recap a little bit because right now actually Nana colress coming and he has ought to be published and actually right now mostly idea for young anymore should be the NMDA compliant and also there\u0027s more young a motor that developers should be done be combined but we still see actually there\u0027s some temporary and no MDA actually exist to bridge the capper of the time period and kill them they can be available so we see there\u0027s transition stages so our you know confusion is how how so how long is this transition period will will take actually when this can get started when and so so so we have some misconception with sinker the current are empty young town lying actually only provide a guideline for the young trans transition but the tenant provide the transition kind line for the protocols actually so especially another case actually so protocol actually if we forego support empty but you you still can use some Nnamdi modules so so this is something we think maybe there\u0027s some gap actually maybe this is a misconception we already discussed this on the man is also offline discussion with several people and so here we give several option you know we have a client actually they can be the MBK liner convenient lambda cannot client for the device who support a net AMD could be the AMD server on and no long an MDA server but in a between we single may be the other cases you know for the server they only implement MDA Maxim but it doesn\u0027t implement the button tenant support MDA combined young data model so actually talked with some some people we "
  },
  {
    "startTime": "01:46:12",
    "text": "think the lacing the semi an empty is a very confusion maybe we were Chester you know we can remove these semi MDA so so based on these are some she actually we we sink you know the colonel problem is when the non empty a client they talk to the server who support the Amity and an MBA actually using the traditional get operation you cannot get as a system-generated complication so we try to address these issues we propose a three different solutions so the first one actually you know we can add as a state a copy node in in the inner MTA young big mantra I think this is another good approach it because we already moved to order an MD we add back actually seems you know actually not a reasonable actually but this is the one solution we can using the get operation challenging get operation to care as a system generator the second option is we can you know define the state module state model well using the same structure as an MDA module and this is something already be discussed in mm dae-jung timeline and but the problem is this state of module actually for some cases that you may when we actually move toward an MD for some MD model doesn\u0027t define of these stay the module so that will cause you know we when we implement this we need to implement some non-standard state a module so whether we should you know ask all the NMB multi-with you provide us data module so this is a something we single could be the solution but the with this data mode you stay the model we can actually address the problem we can care system generate the confirmation from these data modules the third option actually we can actually you know enhance the get operation to allow uses the traditional ket operation you get a system generated a pattern this actually the impactor is you know only modular post so we think that\u0027s possible to actually get but that we simply is very you know the influence we haven\u0027t evaluated we Singham maybe it\u0027s very hard to see this so we so we we propose these three different solution so so the first question we want to ask is actually church as you know as we assumed actually we may have "
  },
  {
    "startTime": "01:49:14",
    "text": "for for the server name a support semi an MDA so we you know so the question is a supporter you know when when we migrated to the MDA just athos away supporter and MDA protocol like an alcohol rescue empty air support and then we can support a M de young beta model are we when we implement all the other choices that we implement the young Vinney model and MDA protocol at the same time so so so we for the option we we proposed actually we may have three option me we may actually be single we can skip these transition stage if we can go directly to the nmda solution actually this already be done by ITF is a completed standard solution but the we the problem we are facing is we sink we assume many at nanoka line that doesn\u0027t support an mp4 right now at this stage here how to migrate it and so we propose the another to option one is option one actually option will actually you may take a one of solution we prefer actually the the solution to actually you may define a state a module but this is not a standard state a module in some cases so another one which has to you know Chester you know agrees there\u0027s a transition stage it but there we may be we may have different no standard solution we we can pick oh what do we and take so that\u0027s a option we single we can address these kind of issues any comments on this so I mean I I think pragmatically probably something to so I think one Colin here is the potential for a given server or vendor they could have a bespoke in a conflict switch to choose whether it\u0027s going in and nmda mode I think for a lot of deployments that\u0027s probably sufficient and fine and that the operators would would either upgrade all their clients and won\u0027t go or not so to do this in terms of the option to we do there is a specification in the young off guidelines of how to generate that state module that\u0027s quite prescriptive and fairly easy steps so one option here could be to say the ITF young modules that we run through that process and we dump those date trees and the names well-defined into github for example and then they\u0027re just there so I think that that may be a pragmatic way for it and then the other session I had was I think on vesties in terms of the new young library and get operations used to have a case of where existing "
  },
  {
    "startTime": "01:52:15",
    "text": "gets returns there are the extra spec trees exact estate modules but the new ones also work as before so I think there are ways through this whether we needed another standard or document to define the I don\u0027t know yeah the puzzle we\u0027re facing is the way which taker the operation to actually we need to you know have a completed standard solution you for every an MD model you should define and stay the module so for some Oh an empty a model they may didn\u0027t define the state model such as a motive attack or some maybe some other cases or so that will delay implementation so how do you how do you address these so I think it\u0027s just you need to publish a scientific you publishing I took routine - state I think that\u0027s okay with the same version number and you follow that also how to generate it and then you\u0027ve got that state route so even if they are not included with the appendix that module how to construct that equivalent state module is defined so it logically this doesn\u0027t just because this is a file somewhere I think two different vendors could apparently generate that same module yeah Tim do you want to go okay so Kent as a contributor so you say agree that there\u0027s an NDA a transition period I mean that is in fact what we have right now we are in a in MD a transition period so I don\u0027t think there\u0027s anything to agree on the you also early on your other slide I think is solution number two you mention the possibility that the bad state module is missing but I think that\u0027s a hypothetical like do you actually have an example of dismissing ya Modi tag actually is a typical example that one that particular draft was discussed on this just recently it\u0027s okay for that draft not have a - state equivalent because it contains no config false notes and also the has no meaningful operational impact have tracked the operational value of the conviction notes so it\u0027s actually allowed to not have a state variant for that draft yeah but I see the nd respond actually he sees is wrong but I don\u0027t know but it may be this is another cool example actually we have some other you dumb prods Chester you know operated for some of mmm be compliant model doesn\u0027t define state emotive so so these state a mode we should be follows a young and a young kind line and but this is not a standard state Amodeo so it\u0027s just that defined in the appendix issue we are free to may be different people given a developer implement in different ways that will cause the you know you know a "
  },
  {
    "startTime": "01:55:17",
    "text": "lot of interoperability issues models that are progressing right now through the ITF that don\u0027t have - state that are an FDA compliant yeah I haven\u0027t check of these so if that exists we should go back to the working group that\u0027s progressing that tell them they they should add - okay unless there\u0027s a reason not to and if the ist is processing if the is GE is processing such in in other areas they the ISP should should say you need to get formed with the PCP and it is true that like in tags one of the ways you conform is we\u0027ve looked at it and don\u0027t think it\u0027s opiate for this particular module so that\u0027s a that\u0027s an okay - way to conform with the BCP okay but if it\u0027s going on and really this is a comment i Torrini to bring back to the is-3 is please make sure that the PCE is being followed yeah that\u0027s a cool situation definitely knew these he says that the I think it\u0027s the introduction or the abstract to say that module conforms to NMDA or not it just says to imitate well it should also have in it the thing like we have especially looked at and have concluded that it\u0027s not necessary to conform to NMDA so it\u0027s explicit supposedly said yeah there\u0027s some saying maybe there\u0027s something guideline should be modified to just yeah yeah yeah okay but regardless I think what Rob said earlier is that if there isn\u0027t missing that state on a published draft we can always retroactively to go back and publish the - state for okay okay okay let me utilize others SPO those were our two great models on my own right so they said oh okay yeah we need your stuff it\u0027s all problem who use it well the problem is is that we moved to NDA right there are organizations that said I\u0027m not going to produce a module that has produced eight modules friends of d8 - so their organization - yes yes sir that\u0027s the standard operating procedure there are organizations that says that will do them right so there\u0027s a problem in the industry that were not consistent on our point of the Rothstein transition to them yet and I would say that as the the authors and the owners that probably "
  },
  {
    "startTime": "01:58:21",
    "text": "has incumbent upon this group us to provide guidance where it\u0027s necessary above and beyond now we\u0027ve done that need some of the some of the guidance I will say the guys in some of the groups that are marketed and looked at that since 1918 and has has made some decisions of it right s - I can\u0027t go into too much because of both member organization tree had have made decisions on some sort of some of the decisions that have been made here says everything has to be a state model but they\u0027re getting caught up on some of the permutations that human even was missed in earlier drafts which says I got that non on a client\u0027s client you know for permutations trying to find the circuitry audience aw server is not defined like in what and they\u0027re getting cut up around like some of the operations that we\u0027re introduced it so I like my my concern is is that if we don\u0027t talk about this I don\u0027t know if we\u0027ve got I don\u0027t know if we\u0027ve got all all the pieces in place that we get from industry the necessary guidance that they need to get through this we\u0027re just I think crates tink modules and has to end and look at the existing DCP some say some of the resolutions in this one room was simply okay so we are out of time just quickly so three things one I\u0027m and we\u0027ll have to take all this the lists but one I\u0027m wondering if we should consider a flag day something on the order of currently the guideline to say you know as soon as possible but maybe we should as important group say how many years one year two year three years like is there a deadline should there be a deadline if so could we do that secondly Andy had written something - Jabar but we don\u0027t have time to go model text and lastly I knew one of the ask if there\u0027s some interest in Leia\u0027s on to address your issue Tim again we\u0027re out of time so we\u0027ll take all that to list thank you and there is like a yang next meeting tomorrow morning yeah for that amazing actually there\u0027s a young next step meeting on Tuesday morning remember you can check out the wiki page for the side meeting and we will organize this meeting to discuss the summer issue may be related to the I am the transition but not know "
  },
  {
    "startTime": "02:01:25",
    "text": "that is who I actually just so it is a side meeting that and if you\u0027re interested in it you should go but it is not one of our things okay thank you if you haven\u0027t signed the blue sheet please come up and do so this is your last opportunity "
  }
]