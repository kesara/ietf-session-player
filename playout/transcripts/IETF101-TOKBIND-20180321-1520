[
  {
    "startTime": "00:00:05",
    "text": "exactly you only hope that the Venn diagram of people understand token bindings and the Venn diagram of people who understand the people who how to get here is sort of like non zero intersection all right can you can get a volunteer to take notes or do we have to like on volunteer people type that\u0027s always a possibility well thank you um and can somebody sit on Jabbar are you gonna do that anyway Jeff all right so if somebody turns up you can channel them I don\u0027t know that or people absent oh well we\u0027ll see I guess alright so the room is being relocated oh yeah it\u0027s the batteries excellent it\u0027s always useful all right so it\u0027s good point you can fight about it later right all right welcome should we should we stop should we start let\u0027s let\u0027s start where is it oh you did you know all right you do that once all right all right while we get the blue sheets going while our beard fashion model in residence gets the blue sheet going take a look at the note well I have no idea whether this is the latest version but you all know what it says supposed to anyway alright you wanted all right yeah we got pens all right so we got some stuff to do today the I think the first thing is to look at our agenda a little bit we do we\u0027re gonna just briefly look at the screenshot of a data tracker to to note the status of our core documents and then it\u0027s our usual suspects of things plus one newcomer so it\u0027s its proxies it\u0027s the various forms of 1 \u0026 0 RT t Nick isn\u0027t gonna do slides that I just gonna do a quick update and then we\u0027re gonna have a little bit of feedback session from the informal what working group meeting on I think was Monday the bob off and hopefully that can turn into "
  },
  {
    "startTime": "00:03:07",
    "text": "a discussion of how we get Fitch moving a little bit and then finally we have Monday I\u0027m here to talk to us a little bit of talk remaining attestation and independent draft that I think he wants us to adopt at some point and then if we had time we had time so let\u0027s look at the screenshot so I think I took this grab this last night so I think it\u0027s up it\u0027s I think it\u0027s up to date so this is we it\u0027s on the next is detailer chat all the core documents so we are I guess we\u0027re over one of the major hurdles and that\u0027s good and there\u0027s no outstanding discusses or anything that we\u0027re anticipating is going to be controversial but our authors are very confident which doesn\u0027t make me quite so much well well just cross our fingers and hope for the best I guess and that leaves us but the draft TLS 1.3 thing and the the proxy which Brian I think I\u0027ll ask you to talk about right now all right all right so yeah skipped ahead but that\u0027s all right we can look at that for the title HTTP token binding with TLS terminating reverse proxies shortened to TT RP thank you Jeff for saving some time on that so just do a little bit of review inside contacts I apologize for you that I\u0027ve seen some of us before but the the basic problem statement is that HTTP application deployments are very often set up where they have TLS terminated by some sort of reverse proxy sitting in front of the actual application the network topology and these terminators are sometimes products like you know your f5 or open source solutions engine X Apache will do this sometimes or increasingly now we\u0027re seeing services that do it on Amazon\u0027s application layer load balancer CloudFlare those kind of things all do this job on behalf of the application in front of the application and for applications that are deployed in in this kind of situation some something needs to happen some sort of information needs to be communicated from that TLS front-end layer back to the application in order to actually take advantage of token behind at least "
  },
  {
    "startTime": "00:06:09",
    "text": "in the general case we\u0027ve seen a few sort of custom solutions that\u0027ll automatically bind cookies for you by rewriting them but for the application to do things like deal with the referred to combining and bind in ways that that the proxy can\u0027t necessarily anticipate which is a lot of a lot of needs something needs to be communicated from that front end of the backend in the absence of some standardized way of doing this different implementations will do it differently or maybe not at all so I\u0027m trying to get ahead of that and provide some some standardized guidance about how to how to make this work so that products services open-source system can interoperate easily next please so sort of the overview of what we have in the draft now on version 3 we try to define a couple of HTTP headers a few HTTP headers that enable this T TRP and the backend server to function sort of together as a single logical server-side deployment of HTTP token bindings so from the clients perspective it looks like a single server doing all the right stuff but in the backend there\u0027s community information being communicated such that they can do different respective jobs to sort of form the whole of the processing what happens is this the reverse proxy validates the token binding message that was sent from the client and the sector combining header and it removes it from the dispatched request that it forwards on to the back-end application assuming it\u0027s valid it adds the sec provided token binding ID header that itself contains the base64 URL encoded provided token binding ID and that\u0027s added to the the dispatch request if in fact there\u0027s a refer to combining it does the same thing and codes it and sends it as the sec refer to combining ID header added in this most recent draft then is this other token binding ID header which can have additional token binding types and their IDs added to it and communicated to the backend something that has been asked for a couple times of the last few meetings that I\u0027ve booked out a little bit but have finally added it into the draft at least for the sake of discussion in this case there\u0027s some kind of trust is required between the TT RP and the back-end server they need to know who they are they\u0027re deployed together they\u0027re functioning as a single unit not that needs to needs to happen they need to trust each other and the TT RP is required to sanitize some of these headers so that that includes stripping the above-mentioned headers if token binding hasn\u0027t been negotiated if they\u0027re not appropriate so that the client itself can\u0027t inject these things through the through the proxy and onto the backend application and spoof it next slide please so just to give a visual view of this I don\u0027t know help me a little bit you have your client here that\u0027s doing what I\u0027m calling old fashioned token bonding over teach HTTP old fashioned it\u0027s almost in the RFC editors queue so it\u0027s old home it does the normal negotiation when proxy and sons they took a sector combining header the reverse proxy does the negotiation it also accepts this request validates the token binding message and sanitizes headers assuming "
  },
  {
    "startTime": "00:09:09",
    "text": "everything\u0027s okay it dispatches the request and although it looks kind of similar you can see it\u0027s a little bit smaller and it has the SEC provided token binding ID header and behind that it has just the encoded token binding ID so it\u0027s it\u0027s validated the signature and stripped out sort of from the application standpoint the extraneous stuff that it doesn\u0027t need but it\u0027s passed along the token binding ID itself which is the content that the origin server or the backend application itself will use to bind its cookies or tokens to either to doubt directly or who may be a hash of that and then that the origin server is able then to do the actual binding of the tokens based on this this information about the validated tow combining that\u0027s being passed from the front end an X line so a few changes since Singapore published two new drafts with mostly pretty minor stuff updated the boilerplate to use 8174 which is what everyone\u0027s doing nowadays so I did the same thing out of the few things that acknowledges acknowledgments updated references I think they\u0027re still up to date but hopefully soon I\u0027ll be able to update those two actual RFC\u0027s a few minor editorial things rewarded a few things to try to make it a little bit easier to read reformatted the document a little bit to try to make the header names the newly defined header names more prominent as I was looking at it they kind of got lost in there so hopefully they stick out more and define encodings first so that you read the encoding and then when you read about the headers the actual header definitions you can refer back to the encoding x\u0027 and probably the most well definitely the most sort of functional change as I added a new header which allows for additional token binding types those other than the provided and the referred to be conveyed from the front end to the back end and this is a newly named header it\u0027s a comma separated list so there can be more than one it could happen I guess and each of those individual values is a concatenation of the base 16 or hex encoded token binding type which is actually just a single byte so that\u0027s why hex seemed like the most reasonable encoding there a period character to to distinguish the two pieces and then the base64 you all encode it took Ambani an idea which is the same that piece is the same format as the other took the mining idea coded and so if there are additional types even though they\u0027re not to find this this trap now specifies a mechanism to convey them so they\u0027re there though next slide please so next steps looking on here it\u0027s been relatively quiet and it\u0027s kind of a small room now but I\u0027m looking to get some level of consensus on this new header and the functionality it provides to be honest I I sort of balked at adding it for a while because I given that there are no other types defined was concerned about the real-world applicability of it as well as bloating the draft and making it more complicated than it need to be after adding it it it doesn\u0027t make it that much worse it is extra text it is extra functionality but it\u0027s not that "
  },
  {
    "startTime": "00:12:10",
    "text": "much more so I may be less opposed to it than I was having written it down but I I guess I\u0027m looking for consensus one way or the other whether this is what we really want to have in there and then pending some decision on that or lack thereof I feel like we\u0027re getting close to taking this to working group last call I hate to revisit this because I\u0027m pretty sure we did talk about it earlier but in one of your earlier slides you said that this architecture implies trust between the T TR P and the back end servers should we reconsider having some way of proving that the T TR P actually didn\u0027t really build headers at all no because if you don\u0027t then different system will do it in different ways and that\u0027s kind of something that we\u0027re trying to get away from well I mean different systems may do it in different ways but right now there are other systems where a reverse proxy sits in front of some other application and communicates information relevant information about whatever\u0027s going on in the front to the back end through a header or various headers and the the standard or de facto standard way of protecting against a client injecting those headers is for the reverse proxy to sanitize the Associated headers so this is this is just going along with existing convention although it\u0027s clearly documented and and prescribed what needs to happen what and what the actual header names are so it makes it more difficult to to miss configure or deploy but it\u0027s relying on its rely on an existing standard practice I guess and so the back install or pretty much has to know that it is receiving the headers from the TRP it\u0027s right I\u0027m how the way they do it right now somehow the way they do it which might oftentimes I think will be based on you know the network topology that the backend server is only accessible from from the reverse proxy or possibly via some you know some sort of authentication some other form of authentication where the the request from the proxy to the backend are authenticated and thus can be trusted from from a broader sense that I have a real hesitation to try to define any sort of one-off mechanism around trying to protect or secure those headers that that would be specific to this draft where it\u0027s a broader issue of proxies in HTTP in general and if there was you know if there was some existing functionality that I could point to I\u0027d be happy to do that but but there isn\u0027t and there there there\u0027s been some talk about it but there doesn\u0027t seem to be a real appetite for development anything like that Chris Newman a question I have about this is how it would inner yes so you mentioned SSL load balancers that do SSL and then then you don\u0027t do I sell to the backend my understanding is one of the protocols that\u0027s commonly used with them between the front and the back end is the proxy to proto proxy version 2 "
  },
  {
    "startTime": "00:15:13",
    "text": "protocol which forwards information about the client certificate and other stuff about the SSL connection from the front to the back end you know in one of these deployments what is your opinion on the interaction you know where on the interactions where the proxy has to both you know sit send data this lower layer and then have God in the HCP lair - something for we\u0027re not familiar with that protocol I know you\u0027re not it\u0027s the one I believe it\u0027s used in a lot of cloud service - services deployments it\u0027s called proxy protocol and there\u0027s version 1 which is just forwarding the IP addresses of the proxy and then version 2 is forwarding more information about the SSL negotiation and it\u0027s and the thing that\u0027s nice about it is it actually works with protocols other than HTTP which will also have the problem of token binding of getting token binding information out of TLS they would oh they\u0027re not currently defined so I honestly don\u0027t know I think there would be a likely similar what that\u0027s not an RFC it\u0027s a de facto yeah because for example a place where we have you know an early version of toking binding on the standard track is the scrams ass\u0027ll mechanism in SAS olysio authentication used by a bunch of protocols like mail protocols LDAP etcetera and so making sure the token binding information from one of these front end SSL things gets to non a cheapy protocols is interesting and so I wonder I wonder if doing it at the HTTP level is the right level to pass this information so I\u0027m very much trying to solve for the HTTP use case as as even indicated in the in the title itself but that that\u0027s the scope of this work and the target of this work I don\u0027t I don\u0027t know to what extent there might be overlap or applicability beyond it Kyle nekritz with the proxy protocol you just get basically some information at the front of the connection so you can use that to say send the like the ekm but you don\u0027t like with HTTP you\u0027re not gonna have the token fighting so you\u0027re not gonna actually be able to send validated ideas like that it\u0027s good point although presumably the message would be sent at some level the the proxy might not be in a position about I don\u0027t know I don\u0027t know how it would work I guess so my my entertaining I axial not only familiar with version one of this but it just sends like a prefix "
  },
  {
    "startTime": "00:18:14",
    "text": "on the connection and on the on the establishment of the connection yes the initial part okay so that would be completely I guess it would be different it would be a different bit of functionality they wouldn\u0027t it would need to be defined or like a v3 yes and rape of Microsoft I have a question specifically about sex other token binding ID so my understanding is that this header is gonna contain a list of token binding IDs that are not provided and not referred right yes why did you choose to not combine than everything into one like why why not Carrie provided and referred as well in that thing name is something somewhat differently but primarily a goal of simplicity to the back-end application mice my sense is that the the vast majority of applications will be using the provided to combining ID and will enable them to just pull it out of the header and use it directly and some will use referred as well and and so having individual specific names for those headers that you can look at specifically for that was the goal to make it simple on the backend application where this was a in in some views maybe even unnecessary maybe will never be used extension so I tried to make the common cases simple right right I was just thinking you know if I were to design it I would probably you know if I\u0027m willing to combine multiple token binding ideas into one extension then I would probably come by no limit to that because obviously it carries the the type identifier of the token binding idea right like you but by necessity by necessity so so then I would probably combine all three but it\u0027s just design aesthetics I guess I mean I guess to be honest that\u0027s how you design the message itself was to convey them all together and in in my view and HTTP applications they\u0027re much more usable as individually sort of identified messages so it\u0027s a lot easier at the application layer to deal with them like this that\u0027s the reason connector it\u0027s one other thing I think might be is full of pride some guidance in this draft is on caching of different validated ideas is if you\u0027re doing say HTTP 2 and getting a ton of different requests to the same origin was the same token binding they\u0027re going to be the same for every request on the connection and you probably do not want to spend the cpu to do the verification every single one but you may also want some more more than just like a single cast value if you might get multiple token bindings on the same connection so that\u0027s probably a consideration that a lot of people run into influencing this it might be worth giving a little bit guidance on so to be honest I\u0027m not "
  },
  {
    "startTime": "00:21:15",
    "text": "exactly sure what guidance I would give there and I think it\u0027s also generally applicable to Joe combining over HTTP in general so I\u0027m not sure this is the right place to try to provide that guidance so um who has read the latest version of the o 3 or some of the draft few probably shamea huh somebody in the back probably should have a few more review so um I would like to get a couple of sort of sub couple of people who would stand up and volunteer to do like a like that\u0027s called it a pre working app last quarter review and you say add it this feels I\u0027ve reviewed it this looks okay so get some volunteers to do that on the list Dennis thanks perfect William and Nick perfect q yeah I think that\u0027s fine I mean get a couple of reviews on the list I mean you know preferably sooner than later and if there are issues right now you know then bring him up otherwise I think we I think if the working group is okay we can go take this to to working you a blouse call in in a few weeks anybody have a problem with that kind of plan right or you know we\u0027d like to suggest another plan yes Tony um just wanna know how many people have implemented this there are a couple of implement I know that there\u0027s an Apache right there\u0027s a couple there been any any interoperability problems between them I\u0027m not aware of any actual problems or non problems yeah okay it could be either it it\u0027s pretty straightforward so it shouldn\u0027t be but yeah there\u0027s there\u0027s some implementation some experience but there\u0027s not a ton right now I mean we we did just before you Stephanie we had this sort of discussion early on and it\u0027s work and we sort of we all agree that yes this probably it doesn\u0027t this doesn\u0027t have to describe what you do when you\u0027re an Akamai or Google or you know it doesn\u0027t matter right you know you know you don\u0027t have interoperability issues with anyone this is for when for for app for when f5 or H a proxy or Apache wants advice on what to do right yeah if you if you run in your stack top to bottom you can do whatever you want to make it work this is the goal of this is to facilitate interoperability and mix and match between components in a stack so Kyle nekritz Facebook\u0027s implemented this in our reverse proxies we did it before I think this graph is really round but we basically came up with the same thing so "
  },
  {
    "startTime": "00:24:16",
    "text": "I think it\u0027s a good approach just enricher I haven\u0027t implemented this but I wanted to provide the perspective that this is the kind of thing that if we don\u0027t standardize it then they\u0027ll will end up being a de facto standardization like you know X SSL cert stuff like that whatever Apache does everybody else is gonna copy and everyone\u0027s gonna get it slightly wrong and I\u0027ve seen enough injection attacks against proxies that shadow stuff like this in the real world that would be nice to have a document address this kind of thing up front before the rest of the world decides to just do it wrong anyway so yeah let\u0027s roll this out all right so the plan is you go to Stuckey\u0027s for for a you know final review cycle and then we do work you blast call and I know within a month let\u0027s let\u0027s say within a month all right sorry the light wound is just angry Justin\u0027s concerns there I think we need it I actually see a world where most application developers are actually using this with with the reverse proxy rather than doing totem bind themselves especially since it\u0027s just so hard to get all the bits you kind of just want to do once at the reverse proxy level so makes a lot of sense and makes sense for cloud providers as well I do think that they\u0027re having something like this if if it\u0027s deployed will help adoption and deployment overall because it maybe move some of the hard parts on due to the piece of functionality that\u0027s more likely to be able to do it rather than and require non individual applications it may be just a code Justin\u0027s point I\u0027ve recently done some work with the certificates and some of the the weird little almost the same but same concepts but in consistencies different ways people different shows to do is part of the motivation for trying to standardize something here so we don\u0027t we don\u0027t end up in that situation Google just want to say that even for operators of that single stack into end if you\u0027re operating cloud-based services and you want your cloud applications to be able to use binding you still need this kind of thing so it\u0027s important okay thanks you\u0027re just you\u0027re not required to do this if you own everything it\u0027s certainly a pattern that you can follow and you can do but I feel like there was some misconception earlier on that this would be a mandate that everyone had to build their infrastructure this way this is really just if you want to if you want to follow the pattern that exists or you want to facilitate interoperability between components even cloud providers that are working with you know applications that can be deployed in their infrastructure might take advantage of it but if you own everything top to bottom it\u0027s it\u0027s not as important certainly you\u0027re not constrained by this or wouldn\u0027t be in trouble for lack of compliance not that you would be anyway but yeah Nick didn\u0027t "
  },
  {
    "startTime": "00:27:58",
    "text": "didn\u0027t want to do slides he was lazy so you know yeah that\u0027s what it was I was lazy and didn\u0027t do slides for this so for Jeff took buying TLS one three I\u0027m gonna give an update on one RTT first I\u0027ve implemented it in chrome and on Google servers and those in dropped with each other Facebook has also implemented it and that interrupts with Chrome I so that\u0027s where we are for implementation I think at this point it\u0027s ready for a working group last call right so we\u0027re basically at the same place where we were just not with TD RP so you know can we maybe great to have a couple of Stuckey\u0027s to do a finals of round round of you reviews before we launch into working a basketball so are we gonna you know have the same people or maybe we can get some new people to review stuff let\u0027s start here who has read the last version of a couple years Tony have you read it no yes I heard him volunteer yeah have there been any have you tested with anybody else it\u0027s just been those three implementations that I know of so Facebook Google client Google server it\u0027s not nothing I\u0027m just just a little worried yeah we have some other issues besides um getting to the you know with TLS so I\u0027m not sure it\u0027s been through enough yet to see if we\u0027re gonna have any problem it looks simple but not sure if there\u0027s gonna be any you know interoperability problems yet or so yeah my experience with implementing it is that like if you have a TLS stack that does token binding and does TLS 1.3 you know there\u0027s easily to come down that you have to get right so yeah so if you have those two separately then your stack probably does the combination of them as specified in the draft call nekritz I think it was really straightforward to implement it\u0027s very straightforward draft I think it\u0027s ready I\u0027m happy to review it okay that\u0027s great we could we can always ask for for an ordinary secretary of you I mean that\u0027s a possibility especially since this is typically gonna get the signed to them I mean this will gets assigned to them anyway "
  },
  {
    "startTime": "00:30:58",
    "text": "and there are you know people who understand TLS in the sector group we could ask that but you know a different area from from the work group is great are you volunteering I\u0027m sorry I lost context at one point we\u0027re talking about just the basic tow combining for negotiation for 1/3 right not the zero RTT correct we are not talking about zero right so I I have read the draft I don\u0027t I don\u0027t think I have the expertise to really have a lot of meaningful feedback from him from what I do know it seemed fine so um alright but we got one volunteer from the Facebook guy and will will ask for an early secretary of you I think before we do working guys cold I think that\u0027s sort of alright that\u0027s good and then my update on zero RTT token binding that internet draft has expired I haven\u0027t really had time to work on implementing it so I think the best thing to do right now is sort of wait for until there\u0027s more implementation interest and experience and then pick that up again once there\u0027s more that and people implementing it and trying to do token binding over I right now I believe there are zero implementations of that draft and we\u0027ve had lots of good discussions in this group about like the security concerns and how we want to approach that but I just haven\u0027t had any work moving forward on that right and we decided that keep the document separate Mike Jones\u0027s secretary I thought you said at the beginning that 0 RTT was implemented in chrome no I was saying that token binding for TLS 1.3 is implemented in Chrome I said this slide has zero RTT listed before one RTT and i confusingly am it was talking about them on the other order okay yeah it should Els 1.30 to D and R 1 or DD so everything Nick is working on quick update right that was the it was supposed to say that so is there a danger of people mistakenly using token binding with 0 RT T in the near term without guidance that is they\u0027re gonna wind up having zero security or some sayin that tokin binding works with TLS 1.3 without giving people guidance about avoiding 0rt T or how to deal with it I believe in the one RT t TLS 1.3 draft there is a must not for doing token "
  },
  {
    "startTime": "00:33:59",
    "text": "binding and 0 RT T so the 0 RT t draft specifies a different TLS extension to use for doing that the one RT t draft says do not do this with 0 RT T so I think if anyone tries to do it over 0 TT they will run into interoperate problems all right because the the keys Android people because also the keys are not the same right like that you get export so yeah so I don\u0027t think there is a risk of that nature yeah good so we\u0027ll to summarize will do a 40 that\u0027s 1.3 will also corner Li a secretary of you and and we\u0027ve got one Stuckey and then we\u0027ll do work your PLAs call if those things look like if it looks like it\u0027s okay sorry alright so who did we hey get to talk about fetch Vinod yeah um so it looks like I missed the Monday meeting could you tell me a little bit about what happened on the money meeting and that I can bring us up to speed on the fake stuff there was discussion about character set mapping how to parse you our eyes and almost no discussion about token binding okay so um you know the pull request for token binding in fetch has been alive for a while it sort of has been going through stages where it goes into stasis and then gets revived and moves but anyway uh where we are right now we\u0027ve sorted out pretty much all the structural aspects of the PR I think at this point it\u0027s mostly editorial changes that need to be made and another sticking point so so hopefully that should happen pretty quickly another aspect of it was since the PRS was started a new policy that went in to fetch was that we do web platform tests for the new features in fetch along with the PR and the issue is that token mining isn\u0027t implemented in Python yet which is what the infrastructure for web platform tests so where is and so um the conversation with reviewer essentially was that we will create an alternate implementation for testing the token mining feature till token binding actually shows up in Python and so the idea is once we have all of those things in place we should be able to get everything moving okay how does that impact your intent to ship well so our plan is to get the editorial changes in and see whether that is "
  },
  {
    "startTime": "00:37:01",
    "text": "sufficient most likely that should be sufficient and then we do the test in parallel with everything else in the worst case we do the editorial changes and the tests and then unblock the intent to ship but I\u0027m fairly sanguine that the former should be possible and I asked the I know one thing that confused me was fetch is kind of this weird creature of its own so there\u0027s the fetch JavaScript API which is only a small part of fetch I discovered so so yes so fetch um at a high level describes how a client should use HTTP to fetch resources in a browser and so even though the fetch API is not used that much the actual fetching of resources by a browser is all governed by the fetch spec at this point so the very small change in the JavaScript API most of the changes that we are specifying are how the browser should actually use - it should use our token binding in the flows that it would normally use to get resources okay any other questions would it be possible to give a little bit a little bit broader explanation of what what you\u0027re really trying to do with such a I don\u0027t understand it very well or is it - it\u0027s not so is it defining like just browser behavior or is it defining ap is that would be used to that a developer application developer might use - to work we\u0027re talking about in functionality or both well um so the fit spec is primarily browser behavior it\u0027s the implementation of well so what happens is you know an elemental level you know you just make a connection and you send an HTTP request and you get a response but what fetch does is it unifies everything you know how cookies should work how credentials should work how cores should work into one unified framework so that every part of the browser is using the same framework we fetch resources and honoring all the different rules that are being set up by the different aspects that don\u0027t get done on enough and talk money has one place in in that big infrastructure so it\u0027s but it is very specifically I guess technically any client that implements an endpoint for HTTP and follows all the rules which typically would be browsers at this point so it\u0027s I would say it\u0027s kind of an impedance mix-up it\u0027s a layer that matches up the IETF specs with what we want to see inside the browser that\u0027s "
  },
  {
    "startTime": "00:40:04",
    "text": "basically what I would say I try it as Jeff Mike hi Jeff Hodges um so maybe this is helpful maybe not so the FET respect basically defines the algorithms that they go off and implement inside the browser it\u0027s it it specifies browser gets you can almost compile the spec into a browser now one more thing the Fed spec does have a JavaScript API so from JavaScript inside the browser you can say fetch a URL and that invokes the same underlying fetch mechanism and so there\u0027s one brief change that we are adding into that API that could allow the possibility of the requesting context to trigger refer to combining type flows and that\u0027s pretty much the only change in the JavaScript API everything else is a change inside the underlying browser implementation itself okay thank you alright so again this is not strictly speaking in the ITF remit but you know it\u0027s good to keep everybody informed and there are I mean the the standard the deployability understand that if I understand it correct is really impacted by our ability to actually get this this these changes through and otherwise this is not you know it will it will severely impact our ability to actually get stuff running right with that I think we\u0027re at your turn me into got your um so thank you to the chair for allowing me to present my name is Gary money ml my my affiliation is Qualcomm but I know we\u0027re in the IETF now so I and so I\u0027m gonna talk as an individual and this presentation is on a tested TLS token binding I\u0027ll admit I haven\u0027t been as deeply involved in this group as probably most everybody in this room so "
  },
  {
    "startTime": "00:43:04",
    "text": "if I make some generalizations or that may be misleading or inaccurate you know please feel free to correct me because this is mainly based on my understanding of specification through my participation in the w3c the w3c n didn\u0027t fight out fights in fast I didn\u0027t any online spotty wines so and this first two slides will be old hat for anybody who\u0027s been involved in the specification as to the motivation for token binding that basically as basically it was addressing a problem that arises in Federation systems where bearer tokens are issued to clients and the in the Mara tokens themselves are vulnerable either to physical attack due to extraction and based on extraction at the device side or possibly even even when encrypted connections such as TLS are still subject to man-in-the-middle attacks and when the attacker attacks it extracts token is no game is over that enables a lot of other attacks too and that was at least one of the primary motivations my understanding for kicking off the tale combining work a couple years ago well you go to the next slide so token binding one of the key strengths of it is that they are must prove I must provide the proof of possession of the private key when I say on every TLS connection that server I just realize that I\u0027m reading that that\u0027s that\u0027s actually inaccurate you\u0027re not going to want to do a signing operation on every single TLS session but I mean it does it enough so as to validate the TLS connection to the server the current specification actually does this by sending the token binding message based on signing the ekm along with the token binding type and taught mine key parameters now this is where I guess you know I\u0027m coming from a semiconductor perspective but as far as we can tell those private keys you know make us yo and how and where those private keys are stored make a scratch our heads a little bit the user agents for instance the browser\u0027s are maintaining their own their own store private keys that\u0027s generally in user space and there are vulnerabilities on that once again an attacker could extract the private key and they can impersonate the client now you might say well that\u0027s a physical attack that\u0027s not easy to carry off but you know good you\u0027re in the past couple of months while we\u0027ve been well the semiconductor industry been trying to answer the it gave her certain attacks that you may have heard of such as specter and meltdown we\u0027ve been handed yeah we\u0027ve actually seen attacks verify verified we\u0027re even for sandbox applications are able to get it to a given to other applications memory space "
  },
  {
    "startTime": "00:46:08",
    "text": "it\u0027s not just a browser issue native applications that he did that implement their own TLS tax may still be vulnerable you know many of them use open source libraries such as open SSL and there\u0027s not necessarily binding to any kind of secure environment of the private key store so not saying these attacks are super easy to carry off but they can\u0027t but but they are feasible here we go to the next slide please so I\u0027ll give a little bit of definitions before I go into the motivation for this basically I\u0027m defining a signing process isn\u0027t as any application or platform functionality that executes script operations such as signing so when I say hardware bound or Hardware secured signing process that means the process will run in the context of a root of trust I\u0027m hoping that we all have common definitions of what a root of trust is but these are basic basically I would have I would define it going from memory here is something that\u0027s purpose specific purpose specific and generally isolated so many Hardware abound signing process protect private keys and trusted environments so you may be familiar with trusted execution environments secure elements TPMS many particularly prominent in the PC world you know examples also include Hardware secured authenticators several which we rolled out and certified in the phyto alliance you know such as Authenticator is running a trusted execution environment we\u0027ve actually in the Android version we\u0027ve actually an Android key store is now try something that and when trust zone is the prominent trusted execution environment in the our Matco system so we\u0027re seeing this uh this kind of this protection of private keys becoming more and more efficient more and more important particularly in the mobile space so relying parties can you know can make if they know how the key is protected they can make decisions whether to continue it to us TLS session with the client in question or not how do they know what they with the protection of the private keys are know what\u0027s gone can we move to the next one that\u0027s none by the process of remote attestation where a where which is a process by which software executing on a device provides an assertion that the relying party can use to verify integrity of the platform in this case the attestation would be applicable to the header to the storage of the private key at a stations can also include a lot of other measurements too you know sometimes you know like healthy health assessments of the platform what do I mean by that I mentioned that the browser is probably letting in user space we actually have commercialized we have we actually have commercialized attestation solutions that are trusts own bound from Qualcomm and kind of the "
  },
  {
    "startTime": "00:49:12",
    "text": "they call it the haven attestation solution where we actually do measure the integrity of the operating system kernel you usually win it\u0027s and we can actually provide that as part of it and part of an asset attestation we also can vary record it\u0027s also possible to court suspicious events such as protect memory access which I mentioned is part of the recent attacks on the arm-based devices in the attestation data is formed by combining these into a compact data structure that can be sent to your allowing party it\u0027s usually pretty important that it be created at the attestation data decrypted graphically verifiable signed and/or encrypted thinking the TLS context the encryption becomes a less critical if you\u0027re thinking of it for hey we\u0027re looking at a primary one for privacy purposes this is probably a lot of old hat for several people in this room so I\u0027ll get to the proposal now okay thank you so what does this mean as far as the standard is concerned to include include to enable remote attestation for the private key well it\u0027s already been hinted at the latest version of the talk-line protocol in fact it\u0027s been in the spec for several versions now there is a feature called the talk line message extension and one of the uses of the extensions was that\u0027s been proposed in that document is is foreign attestation I think I first permitted this document two years ago to the working group I don\u0027t know that actually came about a result of that or this carrier or maybe this is already in respect to the version history I mean you did submit it but I\u0027m not I can\u0027t remember whether they get I got a little review at the time yeah that\u0027s that\u0027s on me so this is what this inner this is what this idea is about just it\u0027s basically proposing what could be the first official extension for the talk lines that is an attestation data for his extension simple pair of an identifier and a B string to actually to actually encompass the attestation data even though I the current version the spec actually seeds it with with the TPM references CPM attestation is particularly you know I don\u0027t believe in the spec of reference to version 1.2 I have to go back and check on that but you know that would be for TPM we\u0027ve also defined many attestation types in wet and the web authentication API at the time I submitted this spec only one I felt it stabilized with a pact attestation but now we have from so now I think we progressed quite a bit where all the format\u0027s are stabilized um I know several people in this room also "
  },
  {
    "startTime": "00:52:12",
    "text": "participate in those w3c standards effort for web authentication I\u0027ll mention that with the caveat yes we may have to give a little guidance on the use of that in the context of the talk behind attestation because a lot of that is relevant to an authenticator attestation but the format\u0027s are still fairly general purpose okay last night so my recommendations is that the talk mine working group can adopt this dress it could even be information which is currently listed a standard strap but I don\u0027t know how we\u0027d be treating extensions I\u0027m also looking for co-editors yeah I think yeah I think I think it would be perfectly welcome and also determine what would be the initial attestation formats for choke mine I know this is a huge interoperability burden to support everything under the Sun that\u0027s why I stayed a little conservative the initial draft well I think that\u0027s the I think that\u0027s I suspect we won\u0027t this is not gonna be able to be an informational draft I think it has interoperability considerations and and you know what that means it standards track or experimental but I don\u0027t think it\u0027s informational yes undriveable Microsoft so I think at the station is very important and we\u0027re planning to support some form of token binding key attestation and Windows going forward I was speaking of specifically about this draft I think also the approach is plausible the I didn\u0027t read the very latest version of the draft but I read the previous versions and they lacked information about how specifically what goes into the attestation Bob how it generated how do you validate that attestation and to me that\u0027s the key information right not where you carry this in the protocol that\u0027s important right but but that\u0027s the simple part the tricky part is how do you generate the attestation statement how you know if it generated if it\u0027s like one software vendors application generated that attestation how does another software vendor validated how do we deal with privacy all of that stuff and and that\u0027s not in the draft therefore I think the draft is not a good like we in its current shape it doesn\u0027t have enough information basically I agree I think we may we\u0027ve gone through this actually with the web audience packing room you know I know specifically when I was trying to compare the TPM attestation definition there in the verification procedures versus what what my company does for firmware TPM you know Irene I had a lot of things a lot of questions on it I think I would probably take a similar approach there where I said yes we can refer to an underlying standard but we would actually tell a verifier this is this is the fields that you need to check these are the fields that you need to that you and based on exclusion these are the rest of the fields you could probably ignore but I agree with that and certainly I think what I wanted to "
  },
  {
    "startTime": "00:55:15",
    "text": "what I wanted to know is what should be as I mentioned before since this is an interoperability point what should be the minimum number of formats to be supporting this spec and then I would actually work out the verification procedures because right now I\u0027m just looking at and they say okay they in the web often spec I believe we have seven defined there and I don\u0027t know how we\u0027re gonna get I deal with in or out there so I certainly don\u0027t want to export such problems to this group honorable I just think if we had one defiant method at least you know to start I think that would go a long way towards you know understanding how like whether this is a good starting point basically that the working group can adopt right just my point of view so it might be useful to understand what attestation format Microsoft was considering whether it was Android attestation format or pact attestation one would tend to guess that it would be one that might align with web authentication hopefully Tony nedelin at least the the TPM attestation since that\u0027s our main usage now with our surface devices and stuff I considering we augment the spec for TPA we do have software we do have software authenticators that will require pack tack test stations also so okay good those are the two that I seeded this neck oneself so what I hear here is a sort of caution intra cautious interest from the working group in the topic but sort of it you there doesn\u0027t seem to be clarity as to whether this particular approach is solid enough right now I think that\u0027s something that could evolve over time right they\u0027ve you know but but it also needs a little bit of you know it actually needs people willing to go and work on it right so that I think John\u0027s question here to princess the Microsoft who\u0027s sort of Antley about the releases right are you or you know at some point would you guys be willing to to work on this right or this version or publish your own draft I mean that there are many ways we can take this forward write a separate informational drive from Microsoft saying here\u0027s what we do or I could be a discussion starting point to so Tony nedelin we do have some things in common so I\u0027m not sure we\u0027d want to put together a separate draft but we would work with Gary to to you know to fill in the gaps that are existing in his draft today I don\u0027t want to start another that\u0027s fine I mean I think that\u0027d be even better if you guys could you know huddle and come up with something a common approach and you know preferably stick a few III anti registries in there to to make everybody happy all right you know that I think that would be Tony "
  },
  {
    "startTime": "00:58:22",
    "text": "I guess I can work with you offline and maybe if you want to identify a co-editor so okay it would also be nice if Google could at least comment on what attestation format they might be interested in because it\u0027s probably not TPM um I look into it and figure out what we can do I agree it\u0027s an important area we probably should be working on it all right in that case I think the the right approach on the working group here is to see what you guys come back with a an update to the individual draft with sort of a few more editors on it that sort of seems to have broad support in the work group I I can definitely see that being in scope for are shorter and be adopted but it really requires that because otherwise we don\u0027t actually see that people are interested in the result even though people are interested in the topic that\u0027s not necessarily enough right but I think you there\u0027s a plan you go off come back in Montreal with weird like a version Oh for with like more names on it and more support I think we\u0027re definitely are able that we could definitely talk about their working group adoption at that time right thank you very much appreciate it all right yeah that\u0027s it I mean we have open mic so if somebody wants a mic to open have we forgotten anything in the working group as you can see there\u0027s there\u0027s there\u0027s a little bit\u0027s work to be done but you could sort of see the the end of the tunnel no that\u0027s good um if nobody has anything to do race then we give you give you the time back unless somebody wants to sing a song or do a dance or nobody I mean alright in that case you get a half an hour back thank you very much and probably see you in Montreal all right you "
  }
]