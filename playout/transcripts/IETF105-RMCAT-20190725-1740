[
  {
    "startTime": "00:02:35",
    "text": "[Music] [Music] [Applause] [Music] so this is the orange cat session are you all here for our MCAT if not you\u0027re in the wrong room so we\u0027re having some "
  },
  {
    "startTime": "00:05:44",
    "text": "technical problems but we hope we will get the slides online here in minute [Music] so we need Yammer scribe and the minute taker please Thank You Alton do we have someone who can take the minutes as well it should not be too difficult thank you box them okay good so then welcome everyone to the armed cat session now we also have slides to you so this is good so let\u0027s let\u0027s get started this is the note well I think by now you are all familiar with it it guides the procedures for the meeting so if you are not familiar with it then please read it we have now you have a scribe and minute taker so thank you for this this is the under for today we will start by going over the status for the working group the different documents then we have a presentation on nada some updates on the draft and some evaluation results and "
  },
  {
    "startTime": "00:08:44",
    "text": "the charging will give this presentation remotely and then Collin is going to give an update on the rtcp feedback work and if there are any other items that anyone wants to bring up so let\u0027s start with the overview of the status so we are finishing up most of our documents so for the algorithms congestion control algorithms two of them were already RFC\u0027s before the meeting and we have nada that was submitted to the iesg and it gets some review from Mira and the 80 review and the authors are updated to draft after that so we have this on the agenda for today and then it will go back of course and continue the process and then we have the coupled congestion control draft which was in the RFC additives queue when there was some we detected the optimisation for the using the bandwidth fully so we took this draft back to the working group the authors are updated it and it was with the shares for review in the last meeting that has been completed and we use now need the final document from the waters before it goes back to media so shabby cool who is the the first author on the draft has been on parental leave so he\u0027s coming back in August and then we will have the updated version and then Miriah will have a look and decide what needs to be done with it for it to go back into the queue and of course the GCC congestion control was a draft that we don\u0027t expect that wit will continue then we have the various documents we have the requirements draft that is in the RFC editor too and there is now hopes that this whole bundle will be resolved quite soon so probably this draft will finally move on to RFC we have the different evaluation graph drafts and one of them now became an RFC the RFC 85 93 the video traffic model and the valve test draft is in the RFC editor queue also waiting for the requirements draft to finish up because yes so it hopefully will come out on the same bundle results and then we have the eval criteria and the wireless test that went through the the working group last call and the author\u0027s just submitted up the final updates on both of those two drafts so they are now with the shares for the write up and sending it off and then we have the feedback part so column will give us an update on the draft in a Vedic core and then we have the draft in Orion cap that will be updated once the AVD core draft gets finished and we have "
  },
  {
    "startTime": "00:11:46",
    "text": "some of the old other drafts that we don\u0027t expect to go on at this point our milestones so the evaluation criteria and those drafts or being submitted so we still need to finish up the final ones then we had some milestones related to the evaluation results and how to proceed beyond the experimental part so we have some presentations today on the evaluations and and at some point we need to figure out how to proceed the area field continue moving draft onto the the proposed standard track or if they will end up as the experimental draft depending on the the interest and needs okay so that completes the overview hi should I get started yes let\u0027s see if then I think yes now we should be able to have the drafts up yes please go ahead judging your yeah thanks a lot sir I\u0027m hoping the audio goes through okay just to double-check first fine thank you great so yeah so this will be and I\u0027m giving an update another post on the draft as well as on some updated implementation and evaluation results in integrating it in a the open source Mozilla browser steering the development branch next slide please so first the update on the draft is that recently we got that the 80 review from amnesia thanks for that and on the draft she raised a collection of questions as well as some editorial suggestions and I pushed the updated version and 11 version 11 now to the basically uploaded the draft this morning and then I wanted to summarize the changes here these changes were also summarized in sort of my email response to Mira before the the addition the edit so first off the question was around the the impact of how the rate adjustment on the great shaping buffer size influences of targets video encoding rate as well as descending grades so Mira raised some good points some concerns about what if the video encoder for instance is then it\u0027s an iris irresponsive one then what if the great shaping buffer buttes builds up to you know an outrageous size would that "
  },
  {
    "startTime": "00:14:46",
    "text": "basically become counterproductive with respect to the actual rate per one percent over to the network so based on those concerns I\u0027ve both and carried out some simulation based results that I will show later as well as some additional sort of you know sort of caveats noting and text in the current draft so we added discussion to show that the typical rate changes introduced by a read shaping buffer in a you know in a normal scenario is on the order of tens of kilobits per second we added one example of calculation in the draft and assuming a 2,000 bytes of a great shaping buffer I\u0027ve run some simulations and see that most of the time the ratio ping buffer is empty because you know the interest being fairly responsive and one thing about if there\u0027s the generation of an iframe so there is an instantaneous you know sort of a big frame interested in great shaping buffer and the size is between you know sort of 2,000 to 4,000 bytes typically depend to an iframe so that\u0027s where the numbers come from and the assimilation results that I\u0027ll show later will kind of show the impact of the ratio ping buffer when we use the recommended parameters and the corresponding and code changes have also been pushed to our open source report for this one and github now secondly to maybe to address the concern and in the presence of an you know not so cooperative video encoder we added some bonding conditions some bonding logic just to bounce the influence the the rate change in reduced by this mechanism noting that this is a mechanism that\u0027s kind of optional because it depends on whether the great shaping buffer information is available or not in the sender that implementation so it\u0027s outside of the core congestion control modular so it added some bonding conditions both on the size of the absolute yessir as a percentage of the reference rate as well as bounding the final rate decisions within its original and range the minimum and the max so all these text changes are now in the version 11 of the draft and in addition as I mentioned this is a option of the feature not really not the core congestion control modeler the second point raised by the ad review was to add text on the security considerations so we did that and I\u0027ll be fleshing out the security consideration text in the next page and finally there were some editorial suggestions we incorporated all of them in the draft and I see mirror a console there\u0027s a question go ahead I didn\u0027t notice that do you that this is optional can you explain why it\u0027s optional optional in the sense that so the implementation is not on the congestion "
  },
  {
    "startTime": "00:17:48",
    "text": "control modular but rather in the sender module so in the draft we have a diagram showing that it it basically revises the rate calculation from the congestion control modular but modulates descending the reason why it\u0027s respect this rate shaping buffer and information may or may not be exposed to the let\u0027s it to the developer so for instance in our an s3 simulation we added the implementation of the race shipping buffer but then in our implementation of the mozilla code right and there is no way in the congestion control modeler to find this information so that\u0027s why it\u0027s an external mechanism to to handle instantaneous sort of additional bursts of traffic kind of the discrepancy between what the video encoder produces and what we want to send over the network but was that clear yeah okay so yeah cool so then the next page I\u0027ll just show up the text on the security consideration next slide yes so this one maybe I\u0027ll briefly mention it and of course you know people are welcome to read it it\u0027s the same text now in the track as well as I coded the same text in the email so there are sort of two maybe aspects of security consideration the first one is to say that because everything is feedback based so we do want the feedback message to be an integrity checked you know there is kind of the potential vulnerability to attacks based on feedback messages now secondly is kind of inspired by mirrors comment to say that you know this mechanism of the great shaping buffer potentially is can you know can can hold up you know large chunks of data if the encoder is not a responsive one and our current medication in the draft is to limit its impact on the sort of on the outgoing traffic so in the worst case the video itself will suffer but the traffic over the network will still be congestion control so if people have suggestions of notes on the text in the in this section feel free to either mention it here or you know discuss further on the mailing list and so if that is fine maybe we can move on so these are some of the results just showing kind of the before and after in introducing the influence of the great shaping buffer these are simulation results from the and s3 simulation the ones on the should be should be identical to what we\u0027ve shown an earlier and then the one ones on the right are using this in basically adding the year the influence of the read shaping buffer bite by tuning up the scaling parameter from zero to point one and I can I picked four I think I "
  },
  {
    "startTime": "00:20:51",
    "text": "picked three out of the test cases to show in this section and then there are a few more in the very and just because qualitatively we see very similar behavior except that and the one on the right because of the the you know the slight change multiplications of the grades added by the great shaping effort there\u0027s a little bit of a jitter so this is the first test case with a single flow and next page please this one is shows the competition of two floats over and time glaring ventless and it is also interesting to see that for instance in the second case there\u0027s there\u0027s always some random hissing you know in how the traffic is being modulated over to the network so in the second case for instance the the one on the right kind of works even a bit better than the delay introduced in that this region is slightly lower next page and the other test case I\u0027m showing is for the multiple competing flows with different round-trip time over sort of over different paths sharing a bottleneck and and I think I\u0027m also showing the next page reads so the five point six this one is the competition against TCP so I thought these side-by-side simulations can help to characterize that the impact of the rating buffer for the parameter value that will pick the end of this slide deck also includes the remaining four test cases and for this suit just for just for reference but I think maybe in the interest of time I won\u0027t go into them they show very similar qualitative comparisons and next page please so now for the second half of the presentation I wanted to give an update on the implementation both on the implementation state status and some evaluation results and this is of the NADA implementation we have rebates or modifications to the mozilla-central nightly branch to a much newer recent so sorry to a much more recent version compared to our last presentation so is this one we this one the main difference is that this this May version of the Mozilla Apple now incorporates are also a much more recent version of the web RTC Mozilla we did realize that the earlier modifications we did there were a lot of coach angels in web RTC so we now replace it to the newer version and if people interested in checking out the code we do have we do have we have pushed it up you know under Sergio\u0027s account and also under my accounts are as a development branch so this link for instance if you\u0027re looking to there you\u0027ll be able to see our code if you want right now it\u0027s slightly "
  },
  {
    "startTime": "00:23:51",
    "text": "pending some further clean cleaning up but you know the main logic is there and in terms of the main part of the code changes that in this version of the implementation what we did is that we replaced with switch the use of playing web RTC there was a delay based sorry I think it should be delay based spend with CERN and with estimation model not one other delay based PMP w/e modular with our own nada one-way delay based on congestion control and this is in the congestion control modular a within web RTC and here compared to our previous presentation in this version will following the draft more strictly in the sense that we now use a relative one-way delay as the congestion signal so the calculation of the congestion control signal now follows more closely to the draft I should mention that at this stage we haven\u0027t yet added the influence of packet losses yet that is pending further investigation but in terms of using a reacting to delay and using a relative one-way delay as the basic congestion control no we\u0027re not were not in sync with the draft and the reason we are able to do it is that with this version if we interoperate with an unmodified Chrome or Firefox they both support the track see back we provides which actually reports a perfected information including sequence number as well as send and receive timestamp which turned out to be a super convenient for us to gather all the per packet information at the sender and the your error I product here is sort of embedded in the code itself and that is how the transport CC feedback message is sort of incremented based on so with that we can operate with sort of against our modified Chrome or Firefox browser so long as both sides support transport system and finally just for convenience our implementation we also use export statistics using similar mechanism the sort of the standard web RTC login framework and that\u0027s kind of the main changes in the in the code in terms of implementation we basically implemented our modular and you know modify some of the switching logic in WebRTC to use the nagas based bandwidth estimation as opposed to the delay the original delay based Ventus estimation and if that is good I can maybe explain a bit more kind of the test setup we we have carried out will follow more or less the same formula in the sense that we set up by directional audio-visual cars between a "
  },
  {
    "startTime": "00:26:52",
    "text": "modified Firefox nightly with our Ranade in one way relative one way delay based bandwidth estimation against an unmodified Chrome browser so basically the blue stream right from hi and a to B will be sort of congestion controlled using the proposed nada scheme whereas the reversed and green extreme from client B to a will be sort of congestion control using Chrome so whatever is the import algorithm there and the reason why we want to do bi-directional and also check out the performance of the reverse direction is mostly just to consider that as a reference but of course I do want to call out that the comparison between the blue and the green are not really side-by-side comparisons yeah this is more just for our reference and most of the but the other thing we did for our is that we just fixed the screen but address it so basically in the browser you can configure the default resolution so we set it to 720p and then also inside the code we set our our mags to three men but then I looked into some of the code in the Mozilla browser there is a spatial resolutions of baseline rates which ended with limits the sending rate to 0.55 by the representin if the X the resolution of 720p and that is indeed what we observed and finally as I mentioned we do lock the statistics of the outgoing floor based on both the our calculation itself as well as the as well as the the per packet sort of information from the feedback message so from that we do have kind of per packets and information of how our how the blue stream went and then also to double check on those results in chrome the conveniently provides you know graphs of ongoing statistics in both directions so we also have a few screenshots just to corroborate with whatever we measure locally and so let\u0027s go through a few of the evaluation scenarios and what we measure next paper please so the first scenario is really more a sanity check so this is more I have two Macs in my home I have you know sort of Google Fiber and then you know Wi-Fi so basically it\u0027s a local connection between two clients and connected through a home Wi-Fi I am used a sorry I forgot to mention I am using the APR is but I believe that it\u0027s more for and setting up the car where\u0027s the car is it set up it doesn\u0027t really go through that it does not really go through the UM the the server so it\u0027s a peer-to-peer car so for instance in this first car it is a local car what I\u0027m showing here are three graphs "
  },
  {
    "startTime": "00:29:53",
    "text": "and they were state of the the semantics would stay the same for the rest of the presentation the first one shows both the calculated grade by the conditional continued modular in blue as well as the reported kind of the impact rates by the receiver based on the per packet information and in red so for instance once in a while those people to introduce sort of spiked up arrivals at the receivers we do see them at you know the s reported back in red and as as I mentioned before even though our reads congestion control algorithm in this case it\u0027s kind of uncongested specifies the sending grades to be the reference rate to be 3 megabits per second the actual sending rate is limited by one to two point five meter per second in the middle graph shows the delay in pollution we report on both the congestion control signal which is the relative one-way delay in blue as well as as a reference the round-trip time measurement on the per packet basis in Inglot and the bottom graph shows the instantaneous packet loss ratio measured over a window of five hundred minutes ago I believe but then with the sliding windows our report for for one data point for every 100 minute second so even though you do see sort of vocational route are some very high in setting up a Colossus coinciding with those big delays the overall loss ratio as reported up only one point six percent throughout this session so most of the time there are no losses but when there is it\u0027s very thirsty so and also in this case because it\u0027s a local connection the baseline RTP is only five millisecond but then believe it or not you know even in a local session one thing about the RTT measurement is one point the highest part it is one point two setting it lucky you have a question yeah just a clarification question sure so you say like your kind implementation doesn\u0027t react to packet loss yes right now we\u0027re not using that information yet yes oh yes so the high losses will not create impact condition control at all okay just I just wanted because I want to beaut I got to build the implementation of one layer at a time yeah and go ahead Anna yeah yeah so from the floor so I\u0027m also the clarifying question because you have the path characteristics and they\u0027re the max or tt is 1.2 seconds and in your delay measurements you don\u0027t have that high value so is this during a longer time period or how does have character that\u0027s a great respond to the I limited the graph to 400 mini-set and top just so that we can see because otherwise if we "
  },
  {
    "startTime": "00:32:53",
    "text": "saw everything for scale and the blue and the red would be locked together that\u0027s also why I\u0027m reporting on the one going to sew a are high up there part yeah this is more visualization challenge yourself but I think for that question yeah that\u0027s also why I\u0027m always reporting on the maximum RTP see usually they\u0027re not even a single data point there are a few and then I wanted to show the shape of the delay measurements a bit more clearly that\u0027s why I was limiting the kind of the the plotting bound yeah so if if folks are good sort of with this graph we can then we can move forward and of course feel free to answer a question sorry ask questions because I\u0027m always happy to chat about how I measure and you know all kinds of observations the second so the from the same experiment shows none of the view report by the chrome so keep in mind that chrome is the client B so when it says it\u0027s a receive stream it really refers to the blue a to be stream which is controlled by nada whereas when it says when it\u0027s reporting on any of the sense doing statistics it\u0027s the one from p2a or just adding those labels for reference so we can see here the other thing is that the reported grades are in some reason are in bytes per second so whatever number you see here if you multiply by eight it should more or less corroborate disturb a red curve before for the direction of A to B whereas the reverse direction within the nada modular we really don\u0027t have any visibility into that so it was good or so cool just to check how the reversal was doing I want to mention that here because of the scale so the blue stream was operating more or less at 300 kilobytes per second so that\u0027s approximately 2.4 2.5 megabits per second whereas the the reverse direction it\u0027s a little bit lower it\u0027s more at 200 kilobytes per second so that\u0027s more like 1.6 so for some reason the reverse flow was operating at a lower rate and that\u0027s also reflected are they\u0027re operating at a little bit lower at a lower spatial resolution even though with the same frame rate at 30 frames per second so this is a local flow by the way yeah so we are looking at more or less a typical but you know sort of probably kind of the best-case scenario more or less but but everything is a world Wi-Fi so they\u0027re still you know spikes of delay and next page please so this next one "
  },
  {
    "startTime": "00:35:55",
    "text": "sort of and confirmed more to a more typical remote cause so this is between me and a colleague in San Jose so both of us are in fiscal office but those are thing over enterprise Wi-Fi so enterprise Wi-Fi and then you know as well and kind of enterprise of enterprise grade wired connections right behind that so here again maybe what I want to point out is that overall the past is uncongested and there is you know sort of target rate at three and the actual sending rates most of time at two point five we do see that in this case the baseline are kiki is reported at 16 milliseconds so that\u0027s why in this scale of the graph would you see that you know there\u0027s there\u0027s kind of a floor of the are cheeky measurements whereas with relative one wait delay as the congestion signal most of Tanglers do measuring sort of close to zero so that\u0027s why the you know the sending rate is able to sustain at the maximum possible and occasional petty losses but occasional bonuses of packets maybe I should put it that way and I\u0027m reporting on post there the highest our Tiki measured is actually two point five seconds and the overall loss ratio remains fairly low to point to over this duration of four hundred four hundred and fifteen seconds so next page so in this scenario I\u0027m again kind of the reported rate on post directions from the chrome and sort of chrome reported statistics the corresponding framed resolution as well as the frames per second so in this case number wise both on the streams reach around three hundred kilobytes per second at the maximum rate but maybe one thing I do want to point out here is that apparently the NADA control stream is able to ramp up much faster compared to the the chrome default behavior and also in the middle there was Chrome\u0027s or maybe there was a a glitch and it took it like somewhat longer to recover whereas in another stream the recovery typically its varied asked so one that I didn\u0027t really talk about but I want to mention is that and another we have designed this the great adaptation to automate entry modes one is gradual great update the other one is accelerated ramp up initially we wanted the accelerated ramp up mode to to help the initial start great but turns out it\u0027s being invoked very often also in all those recovery mode so that turned out "
  },
  {
    "startTime": "00:38:55",
    "text": "to be the main kind of one feature that really helped and if folks are good with this one I can move on to a second case between Austin and San Jose and so this one the main difference is that again this is between the two locations but in this case client B is behind a home Wi-Fi network so we see much easier delay measurements and in this case also even though physically the similar location much higher baseline our Kiki just maybe for reference the previous set up between the two offices it was 60 minute set here even though the sender is at the same location just because receiver was behind a home Wi-Fi behind cable modem if the baseline our Tiki is now a hundred and ten milliseconds and the the high belay and sort of the corresponding burst of patchy losses are much more frequently within similar duration but other than that yeah so the sending rate right the calculate not ascending great to dip very frequently too but it also bounced back to the maximum rate whenever it can next page and this is the corresponding rate resolution and framing great statistics reported by van chrome so the top three graphs correspond to what we sort of measured for the blue stream for the NADA control stream and the bottom three graphs shows a reference on the reverse direction in this case the reverse direction does suffer a hike a bit so we see sort of fairly low grades and lower resolution and the frame the frame rate drops quite a bit I want to mention that visually obviously I also have some screenshots but since it\u0027s all people spaces I wasn\u0027t so sure whether to show them here the of course you know at this resolution and frame rates and also encoding grades yet the visual effect were not very good on the other direction so and then moving forward next page this is again between Austin and San Jose and this is a case where were a bit curious about what happens if you have a background address you know suburb ongoing data downloading flow so in this case the client be behind the home Wi-Fi also has an ongoing bit current as our BitTorrent sort of "
  },
  {
    "startTime": "00:41:57",
    "text": "traffic and he verified that this disposal uplink and downlink both directions so in this case we did see that the fellow from A to B now operates at a much lower grades around 650 8 kilobits per second and and the other thing I want to mention but I don\u0027t really have an explanation here is that in this case we also see that the actual grades is the target rate where is you know in critical way drawn so for this one I just want to mention this conservation but it it\u0027s pending further investigation to to find out why now delay wise they did my article 125 mini second and similar maximum RT key and loss ratio as before so this mainly shows that in the presence of a persistent background traffic the video flow itself in term you know only operates at a much lower sort of this is how it operates right now in the face of a competing flow next page and if you look at both directions the top graph shows the NADA behavior the bottom graphs shows in the chrome behavior I do want to mention that here the rate reported by the direction controlled by chrome operates at even lower rate the the Nano graph is a 80 kilobytes per second whereas for Chrome it\u0027s below 20 kilobytes so so so looks like chrome the chrome flow and suffers even more in the presence of the background traffic yeah and that shows up on post frame frame rate and the resolution choices too so I have two more two more experiments to go over and now in this case I was working with another colleague and this this is the call over even longer distances across the Atlantic because we really wanted to stretch the past RT and Lisa these type of remote colors can crystal sustain so this one is between Austin Texas and Florida in Switzerland and we listed two cases in this first case the client B is wired lately connected so the only waters hub is between I laptop you know in the local enterprise Wi-Fi network that may be compared to previous graphs now the past is much cleaner there are "
  },
  {
    "startTime": "00:45:00",
    "text": "still occasional archie keys and even a big one but overall with even lower losses and more stable calculate posts the calculate the gradient and the actual rate i should mention that in this case the based on RTG is 180 mini second that\u0027s very high so I was on I was happy that this in didn\u0027t break it sort of still worked well next page and this one shows the the corresponding screenshot me you both for for both directions I guess by now you guys are very familiar what to look for in these graphs supposed sending worried as well as the frame sort of the temporal rate yeah off of the frames I forgot to point out that in this case for instance the reverse direction this is quite typical of Chrome it typically takes them a bit longer time to ramp up on the next wait even if the past is good and one final set of experiments this is again between Austin and the Switzerland office and this Switzerland office the Wi-Fi connection happens to be very choppy so even when we were let\u0027s say occasional cause over WebEx etc sometimes even the audio itself that\u0027s largely delayed so instead of using the wired connection for client B in this case we switch back to enterprise Wi-Fi and we see a similar behavior kind of similar as previous case with a home connection so those big Jones of spite of delay introduced brief jobs in the calculated rates but our calculations also our target rate bounce back thirdly the clean and the crisp on the sort of her delay and bursts of loss sorry I forgot to puts the loss ratio number in this one I should look up the number and feed adding that was a glitch but it but I should mention or sin it should be similar to the the previous work is around one or two percent probably next one and this one we didn\u0027t capture the corresponding resolution and great information what the I should mention is that throughout our case my guest speakers we have specified the import resolution in the in the nada controlled stream in Firefox the resolution is always at 720p so great changes show up in frame rate changes whereas in Chrome to adapt both the frame rate has as well as the spatial resolution so here there\u0027s a "
  },
  {
    "startTime": "00:48:01",
    "text": "difference in scale but if you peel that off we\u0027re really looking at sort of 300k as kind of the main operating point for both of the flows the thing is the diverse flow at one point that may be the spiking delay introduced a dip in the rate and it took that stream sort of a longer time to recover I think this should be the last slide in terms of experimental so next slide is more a summary our observations so so far in I think we kind of tried you we try three different combinations the local session is a very easy one the other two are rolling what we think as typical remote car and situations in these cases typically we do have sufficient bandwidth but then because of the presence of the wireless link we do see that there are occasional delay spikes so our observation of the NADA control and flow is that it tends to ramp up fairly fast a maximum allowed rate that\u0027s within a few seconds and also the sending rate will react to occasional big delay spikes but it recovers very quickly thanks to the the other mode of operation the accelerated grab mode operation and we have examined how sort of how frequently the modes switch so we do see that the switching between the axillary ramp up and the gradual updated ramp up a gradual update of modes are fairly frequent and he certificate is used by those of frequent delay spikes and also just because we have a stringent some of criteria for the flow to operate in accelerated relic mode yeah and finally maybe kind of the the reassuring part is that we have tested these cars with past baseline our teepees up to a hundred millisecond and you see that the flows seem to operate in very you know speaking a very stable work mechanism even though 180 milliseconds is just the baseline the occasional our teachers can be on the order of several seconds so that was fairly reassuring to to know and finally maybe for further investigations were more interested in looking maybe looking into performance where there is abandoned bandwidth limited connections we\u0027re scratching our head a little bit in terms of what type of typical use usage scenario that would relate to so if the audience have any suggestions we\u0027d like to hear those as well and then finally sort of the study of coexistence with TCP light background traffic are also of interest from the audience go ahead I\u0027ll show from tensing so I think "
  },
  {
    "startTime": "00:51:03",
    "text": "it\u0027s better to show a third graph all the scenario to show that a prompt chrome because all the data at the reverse that I could be because of the rest method to giving a different path and then the delay is gonna be different so it\u0027s better to show like ROM to chrome from differencing arrows then you will see if Ranade from nada to chrome might be better can you explain about extreme scenario is from the from nada to chrome right there\u0027s no data there\u0027s no testing from crumb crumb to be 24 locations truly yeah but the reverse direction and is I\u0027ll modify if I may say so but I understand about from the two different continent rows and the reverse path would be different most of the time yes this I agree yes yeah so that\u0027s always saying they in my if you show three different grasses from nada to chrome and Chrome to Chrome that might be I\u0027ll show you more instead of just okay so I\u0027m saying instance for the scenario and we do a wine round with nada to Chrome and then another one and switch the same Google Chrome John thanks in terms of figuring out what do you is for your typical prefer your bandwidth limited case I\u0027m not I\u0027m sort of spitballing here but it might be if you can find somebody who\u0027s you know got cheap home connection like DSL or something that might be a useful case I think that\u0027s probably the you know where somebody has a I mean I\u0027m gonna have to find a colleague who\u0027s lived somewhere remote you know lips of more rural or doesn\u0027t feel like spending a lot for home bandwidth it can be hard for you know engineering colleagues I understand yeah I think that feels like that might be a you know you know somebody with you know just to you know live out in the woods and all we can get his DSL or something like that okay another thing to try but I guess this probably has a lot of other complexity might be mobile data but that might have a whole lot of other complexity here so I\u0027m a transfer from the phone so in terms of comparing the two maybe you can also run them in parallel so that you would have gotten call with with nada and one call with the chrome in the same direction at the same time if you do with her after each other the path I mean the conditions will also not be exactly the same at the two points in time they may remove similar done going in different directions but but still then Wi-Fi over time and then the path over time may "
  },
  {
    "startTime": "00:54:04",
    "text": "change sure thank you yep new to me I actually learned at the hackathon last weekend that there\u0027s a nice command-line tool for limiting your bandwidth it\u0027s all Comcast all right Comcast you know like the like like you\u0027re not so great in that provider in the US or I don\u0027t know I\u0027m I\u0027m guessing that\u0027s what the naming is coming from but it allows you to basically set on the command line bandwidth limitations for given ports and protocols and so on so maybe that\u0027s like something to explore it works on OSX and Linux okay thank you I think we can definitely try was artificially limiting the bandwidth and see what we want but maybe the other side and actually early on in some of the tests that evaluations we we did some of those too but maybe we\u0027ll try those as well I think we\u0027re really trying to hunt for typical scenarios where the bandwidth is limited just more like a real word type of test so this so yeah I think you know what pursue pros sort of both methods and the suggestion earlier there was one on mobile connections that\u0027s exactly something were curious inga seeing how things work yeah but we haven\u0027t really tried the mobile version of the browsers to to carry out cause yeah thank you I think this is my last slide so I\u0027m happy to answer more questions or you know so thank you do we have any more questions before we come no seems not okay thank you okay thank you so we move on and call in you are next [Music] all right uh hi I\u0027m Colin Perkins I can now actually see my slides help so I want to run the RTP congestion control "
  },
  {
    "startTime": "00:57:05",
    "text": "feedback draft I feel I should be looking at the rest of the room but then I can\u0027t see this at all this will do so the conditioning trophy back draft was obviously something we\u0027ve been discussing for a while we got a bunch of feedback based on hackathons at the last few meetings most recently in the product meeting and we submitted the the zero for draft to reflect the implementation experience and the hackathon lots of changes in the draft a few changes in draft no changes the packet format everything is clarifications and we discussed these in a boutique or earlier in the week most of the clarifications are around Sigma link which I\u0027m proposin but this or about that the precise details of what you report on when and how you split our TCP packets up and that sort of thing there\u0027s two changes I wanted to highlight for this working group one is about the feedback hardened effect in retransmission packets and one is the response to lost feedback so in the first subject the the thing we\u0027ve added to the draft this time is a statement that if you are sending separate RTP streams that contain if forward error correction or retransmission packets with their own SSRC then when you\u0027re sending congestion feedback you also send the congestion feedback reports on those streams see using congestion feedback on on the on the fact trafficker on the retransmission traffic on the basis that this is taking a bandwidth from potentially causing congestion so you should report on it the second change was to add a section talking about congestion response when congestion control feedback packets are lost and this is two things firstly it points out that like all all our TCP packets it\u0027s possible the congestion control feedback packets are lost and any TP congestion control algorithm must specify what it does in response to the fact that feedback is being lost it can\u0027t just assume the feedback could be delivered reliably it then suggests that if you just get an isolated feedback packets loss then probably the right thing to do is assume that the congestion remains at about same level it was before but if a significant number of feedback packets are being lost you should fairly rapidly reduce something rate down towards zero on the assumption that if all the feedback is being lost then it\u0027s likely that something significant has failed on the pass and it points out that the circuit breaker RFC provides some further "
  },
  {
    "startTime": "01:00:06",
    "text": "guidance here and just when you should stop sending entirely and does they have a microphone yes it does okay and those are the main changes that there are two very hopefully minor open issues with a drift the first is that we have yet to add a comparison with the whole mer draft to explain that the design rationale costs and benefits and so on and also to add it has previously been suggested that we add some discussion of power of how you convert between the per SSRC sequence numbers as proposed in this draft and that the unified sequence numbers face in the other draft and talk about what are the trade-offs between the two approaches you know that these are fairly straightforward in that the per SSRC sequence numbers let you do per SSRC congestion control if you want to do something different for the audio and video for example much more easily than having a unified sequence number space but at the expense of having a a slight increase in complexity also a slight reduction in bandwidth because you don\u0027t have that the header extensions with the unified sequence number space so the trade-offs pretty quick pretty clear that\u0027s all I have hopefully we will address these the plan is to address these over the summer and then hopefully this should be ready to go for working your bus call before the Singapore meeting him and hopefully significantly before that\u0027s why I have for any comments or questions the comparison with the home of draft yes as far as I remember leaving the design team there are some comparisons done and I have compared the results like well what are the compression or what kind of benefit or cost we get our overrated get but I\u0027m still like I have a hard time digesting like why we need this compression in this it was a previous meeting we were asked to provide such a comparison I have no particular desire to do it but it was what are the what are the things we were asked to do it a previous meeting of course at every Depot of ABC car yeah and what benefit it brings to the draft unknown whatsoever as far as I could tell it just positions it makes it clear what why you would implement certain I mean what it\u0027s like yeah I mean we in the design we did calculation and we saw like yeah that could be a better I mean there could be another way of doing the signalling and we agree to this working group will do that and we this is what our output right and then if somebody "
  },
  {
    "startTime": "01:03:07",
    "text": "thinks like okay they have a better and a feedback and they don\u0027t want to really compile generation because now then we have other bike Nara has their own consumer feedback scream has their own condition config crap shall we be comparing all of them if you are not comparing all of them then why we are picking up this one and I actually really have to understand why we need to do that at all as I say that the reason it\u0027s on the to-do list is because one of the outcomes of a previous apt meeting was that we would other comparisons I don\u0027t remember done I don\u0027t remember exactly what the group said but I mean my argument for it would be because the homer graph is actually widely deployed and to convey need to convince people to switch from that to something standard you have to show them no this isn\u0027t gonna hurt you and in fact hopefully will help you yes and I think this is a pretty straightforward thing to do and it will be a very short amount of time yeah yeah basically you know be know the you know the extremely aggressive you know very Zara you know virally encoding as well in home or don\u0027t actually help you that much in the normal case where you\u0027re just reporting on a few packets so this isn\u0027t gonna be you know some huge explosion and your feedback because for the despite the much simpler packet format for instance yes yeah and I\u0027m not sure I would even go so far as to have a comparison of the bandwidth costs in this I think that the main the main advantage of this is that it provides per sssee feedback which gives you flexibility to do differential congestion control for the different sources and this one here but worth the whole my draft give kiss it gives you a single secret i spaced honestly i do don\u0027t have a nice guy honest ii don\u0027t think so because the conversion you\u0027re describing here between caresses are see and you know if i think whatever it\u0027s been run either direction it doesn\u0027t actually it\u0027s difficult to do if you don\u0027t know which always the sender but no i think the big advantage is not having the header extension especially as i think i\u0027m pretty sure that gradually in most cases you\u0027ll actually get all header extensions out of your average varsity video packet which is actually losing the generic header extension overhead is actually a fairly large win as opposed to just yeah I think that\u0027s that\u0027s the bigger win is losing the per per packet header extension overhead yes yeah I mean I yeah I can propose some text separately to the list and we can discuss whether it makes sense to put it in the first text on the comparison of the home a draft and then we can have a discussion about whether it makes sense to go in "
  },
  {
    "startTime": "01:06:08",
    "text": "okay Thank You Colin and the plan is to do the working group last call on him both Sunday Tom boasts lists I guess yeah yeah so that for the recording that was Jonathan saying yes it would be done in both groups [Music] Jonathan exam what Colin said in a boutique or is that he hopes to get all this done before his students come back for the fall semester because as many doesn\u0027t have time anymore so that\u0027s is the hook yes is the help so basically so where our hope was before the end of the summer we will get the new draft with all this requested text they\u0027ll be able to do organ group last call which indeed we will make sure to send to both maybe d√©cor and Armco yeah thank you that smells good and then I guess Colin once this draft goes through down you will update the Orem cat dress yeah this is pretty straightforward to updates is just plugging in the the appropriate package sizes I\u0027m rerunning the analysis and that then we can have a discussion as to whether that is describing what what we wanted to describe but it\u0027s very easy to bring in substitutes okay very good thank you okay this was the last item on the agenda unless anyone has anything they want to bring up for discussion so thank you all very much for attending despite being light late on Thursday afternoon and very good temperature as well so it\u0027s a good spot okay thank you let\u0027s complete AB did everyone sign the blue sheet where is it okay perfect Thanks "
  }
]