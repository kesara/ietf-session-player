[
  {
    "startTime": "00:00:16",
    "text": "Yes. Yeah."
  },
  {
    "startTime": "00:06:48",
    "text": "Hello. Good afternoon to those in Brisbane, and good day to those somewhere else, we're still gonna get black. Just to confirm, people can't hear me. See. Yep. We can hear you. Great. Thank you, Steven. Welcome everybody to the meeting of all the RASP Research Group. We have one interesting agenda. I hope everybody is forward to it. So let's move on with it. Can you move to an access like this? Well, as usual, The nod well, recommender or for the IETF considerations to be taken into account with regards to this meeting. And it's a streaming It's a slide. Just a very brief mention. Remember Raspa is about understanding the summarization process We are evidence based, predictable work. The intended outputs are a joint reports, papers, tools that an open source software, it is not in terms of, this research group to produce hierarchical comp comparisons between It's not development organizations or directly influence IETF operations."
  },
  {
    "startTime": "00:08:04",
    "text": "The chairs are Nelson, myself, a new will be stepping down and, Stephen is, the delegate today as, Both chairs are on remote. And of course, more information is usually is available in the charter Next slide. Hi, everybody. This is welcome to join the LEAF and data requests, ideas, and papers, and please do so by using the link above. House rules, simple places, and the QR code, using the mid echo, for the question and answer. And, speakers, really appreciate it if you can leave time for question and answers. Though I think that the agenda is not too tight. So that should be fine. And please get ready during the previous question and answers, for your presentation. Can I also ask for a volunteer for note taking? Nick volunteers, There's no volunteers. Oh, there is or someone in the chat that's gonna take notes. Thank you. Thank you very much. Right. So moving on to the agenda, pano. Hi. And apologies for the background noise. That's my dog. And and So We have finished the welcome and Please note that we have, had a last minute request for change in the agenda. Nicky, it's gonna be talking first about the large language models and RFC GPT, which he was gonna do at the 1550."
  },
  {
    "startTime": "00:10:02",
    "text": "But it overlaps with a side meeting on, LLMs, and network. So please be aware of that. So Nick, if, You can get ready with your presentation. Room is yours. Okay. Thank you. Thanks to the chairs for inviting me. So today. I'm gonna talk about a small project that I I did over a couple a few months ago, in an effort to be more efficient in understanding our humongous archive of of of documents in the RFC series, and making sense of them. Next slide, please. So this is an overview of the talk. This is going to be at a relatively high level. I'm I'm not going to be going too deep into technical details. The point of this talk is to give the audience an overview of how to get to something functional from, just an idea or at least the path that that I took for RFC GPT. So from top to bottom here, we'll a bit of a background on LLMs how they're trained, how typical models are used or have been used in the the last year or so, in a lot of products, it sort of loaded, in popularity, this model of being able to use machine learning to, do do human text. And so, from there, I'll I'll talk about one particular platform that was built to make it easy to, build your own tool that can help, answer questions, and interact with with customers in a in a text a way. I'll talk about RFCGPT. What went well, what was difficult about it, as well as future directions. And, and next steps. Next slide, please."
  },
  {
    "startTime": "00:12:03",
    "text": "So, if folks don't really don't don't know yet, this Been in the news. Almost every day for last year and a half since, some high profile announcements what is a large language model? Well, basically, it's an algorithm that, takes text in and spits text out. It's says artificial intelligence. It's sort of a it it's become a very broad term but this is an algorithm that's designed to understand and generate text. And interact with humans in a human natural way. And there are a lot of different, machine learning models, including very popularly generated generative pretend pretrained models GPT. Which, is based on some some work, offer transformers. Which was published within the last decade or so, and has has really grown. Next slide, please. Okay. So LMs in action, how are these being used, how are people using them? Well, smart assistance. A lot of folks are are have deployed LOMs as chatbots you've probably interacted with them, customer service agents, things like this. Sort of replacing the route conversations that you would have. With someone website to support. That's one example. LLMs are are great at tech classification, taking, text document and describing in in in words what's what's in it? What what sort of aspects can be extracted from this text. It's also good at text generation. This is the heart of what has been really exciting for folks lately as these, tools have become more and more sophisticated, more advanced, And, the last one here is expert systems, and that's kind of a a lead in to, what RCGPT is intended to be."
  },
  {
    "startTime": "00:14:00",
    "text": "It's, a a system that is meant to act as an expert to give advice to folks who are less than expert on a particular tool. On the underlying tech, involves training data, which is just a very, very large set of text, and this text is processed. Tokenized, which is effectively splitting up the words and and sub words into, smaller chunks. Vectorization, which is converting text into into numbers, putting it into a large matrix, There's a number of algorithms I won't really get into. This is, you know, there are 10,000 experts the world on this, and, and I am not one of them. But, effectively, there's a lot of large, natural end language processing tools that take this training data. And, turn it into a predictive tool. So, there's different techniques like taking your series of tokens, and say removing 1 and and and teaching the neural network to predict what that token will be. An LLM is effectively an auto complete. With a a ton of, of, ability to go beyond just one word. And a a lot of context that goes into And so one of the interesting things about transformers, which has led to these things becoming shockingly much more effective in the last few years is the fact that in the transformer model to make your make your model or with transformers to make your model better or more efficient. You just have to throw in more data and it's been remarkable for just getting better with more data put into it. So with training data, you you get what's called a model. It's basically a large file. Vectors. And, a lot of folks have been doing this there are models that have been trained out there on public data private data, other things. There are private models. There are open source models."
  },
  {
    "startTime": "00:16:03",
    "text": "Available online. There's tons of tools to, compare these and and look at efficiency. And then there's platforms that are built on top of these, such as the Claude or, chatgpt or there there's a ton of other ones barred, for example, that essentially provide a user interface, which is, oftentimes a chat interface, although it can be an API, and, there can be additional filtering layers before and answers returned to you, bias filters, and things like this. But, there's there's models and there's platforms. So you can run these models with appropriate back end servers or you can you can use a use a platform. And, these models themselves can be updated in various ways, or they don't have to be used as is. They're not set in stone. There's tools like rags retrieval, augmented generation, which is effectively a way to take a model and put more data into it from something that I'll I'll get into this a little bit later. We'll we'll do the next slide and and I'll kind of describe this. So with a retrieval augmented generation, this is one way to to modify a model, there's also something called fine tuning, which I won't go into. But, the API for a large language model is what's called a context window. It's bunch of tokens that get sent in. And so if you're interacting with a chat model and you type of words in. It can go to the model. That's sort of a small amount of data to extrapolate what the response would be, with with rags, you can take, another set of data, tokenize it, vectorize it, put in a database like Pine cone or something like this. And use it to basically augment what the query is to, the LLM model. So you you might say tell me a story in the style"
  },
  {
    "startTime": "00:18:03",
    "text": "of of whoever. And, and then it can go to this other database get additional context and send that into the model. And this is meant to, help inform the responses and make them more custom to whatever information you're adding to. What is a pretrained model? Next slide, please. So what's this talk about? What what is RCGBT, why didn't I do this? Well, There are a couple non goals. Non goals include building a collaborative platform for, writing RFCs building a tool for for for writing texts for RFCs. This is definitely not the objective. The objective was to be able to interact with the RFC series in a different mode. And this mode is a conversational and question based. I find, you know, reading a 50 page RFC document can be pretty dry and oftentimes there are just particular questions that you wanna ask it. And so the the hope was that this expert service would be able to interact with you in human relatable way. And, answer questions. So this is the goal. The interaction model, as I mentioned, hopefully it's an intuitive interface chat is one that's been popular used, but they're they're definitely many other ways to interact with OLMs. But, yeah, you can get explanations and summaries of ROC content. That's the point. So, with this there were some requirements, some some things that that it has to do and it has to be able to have at least enough. Information in the model to be able to interact with with its users in a way that sounds like a person. It doesn't sound like a machine. Doesn't have to pass the Turing test, but it needs to be able write sentences and and be able to glean context from different places and make relations and have sort of the base level of what we"
  },
  {
    "startTime": "00:20:00",
    "text": "currently now expect from text based AIs. It's so this is the sort of the important part for the interaction, but it also needs to have the domain specific data. In particular, the RFC series, it needs to know it. And, if there's like a really large base model, as I mentioned, there's ways to incorporate new data, or you could train your own entirety model, but The important part here is that the entire RFC series is, internalized and known. Next slide, please. So, there's a I could have built this from scratch might have taken longer and it might have been, better long term and it may be something we can do, but, OpenAI, in November launch a feature called mygpt, which, allows creation of custom versions of chatty PT with specific use cases in mind. The underlying engine is gpt4 which is the current open AI model. Next slide, please. One of many that they support, but most popular for, folks who are using chatgbdplus. So, there are 3 available features. There are a couple other features to this MyGPG tool. There's the instructions section. There's the knowledge section and there's the code interpreter tool. On top of this, there are other tools like web search you can enable as well. But from the instructions is effectively text window. That lets you prime the context. If someone were interacting with chat dbt, this would be similar to them type typing in whatever this instructions are as a prompt as the first step for interacting. So this can be things like how do you know who the author is which what do you do if something, some failure happens internally, and you have to search the web to, to download the RFC and and all these sort of things. It's a lot of additional, clues to"
  },
  {
    "startTime": "00:22:00",
    "text": "Chad GPT to do the right thing. For for the knowledge section, this is, a rag or it it's a rag like like feature, it allows you to upload a lot of files, and it will tokenize and vectorize them. And, incorporate them as a first step for a rag. So There's some limitations to this. It's only you do have 8 text. You can only use 20 files and 2, 2,000,000 tokens per file 50 megabytes. But, this is a drag and drop solution to creating one of these rather than actually going through end, creating a a database. The last section, the last PCS code interpreter, which is a pretty nice feature, especially for code but, you can upload a zip file or dotcfiles or Python files or whatever, and it will use it will be able to execute Python code to analyze this data. So that this is also really interesting for things like math problems and data analysis, things that are less relevant to this project. Next slide, please. So, making the data fit. This was this was you know, it's a beta product. Well, it was, It's a GM product, but it's a new product. There were some issues in the instructions, oh, there's a missing s there. There is a bias in the underlying model. It's very, very hard to override. With instructions. Chat GPT is going to chat GPT. No matter how many initial tokens you send it. There are things you could do to put additional instructions in but It will make things up, unfortunately, which is not ideal for for an expert, although it does sort of reflect what real experts do. In times. Okay. In the knowledge section, this was even more tricky. While the RC archive just downloading"
  },
  {
    "startTime": "00:24:01",
    "text": "downloading the r RFC archive in a big zip file. A lot of the early RFCs are are not about conforming fully to UTF 8. There's a lot of special characters in there. Chatty PT will fail on these without telling you. And so you have to do some text transformations and all these sort of things will actually change your tokens. So I can e with an accent. Will either split up the word or become something that's not necessarily relevant too. To match, like, other tip cans. That don't have an accent or are are similar words. Or are presented in different ways. So this was tricky. Had to do a lot of manual missing on the RFCs to get them in here. And also the 50 megabyte files that didn't really work. The upload failed. Tried splitting it into group of 100, which is approximately 5 megabytes without limitation, you don't get the entire RC series, which is approaching. 10 k. Right. And, the overall file, you can kinda approximate this from here. We're talking 5 gigabytes or so. For the for the entire thing. So this this was also tricky. It it did originally work at first. And so the workaround that I did was to, basically zip archive the entire RFC series. And rely on the code interpreter to to load individual files into context. This is a hack. It's definitely a hack and it's a hack for which chatgbt late, later disabled this feature after deployment. So, it did break this. Next slide, please. So we did a soft launch, just launch this on Twitter or whatnot. You can go to cryptography consulting RCGPT or If you're a chat GPT plus customer, search the RC store for RC GPT, And, there's been some pretty good feedback about 400 conversations."
  },
  {
    "startTime": "00:26:00",
    "text": "Lots of issues in particular with the code curves of files, as well as uploading these 20 files and and saving it. I'm it is currently in a state in which chatty PT will not accept my current set of uploaded files. It's an address state. And, well, they use a GPT as their support, and it There's no help. But in any case, we launched it. And, it had a had a bunch of uses. Next slide, please. Yeah, so the early results it was actually, it was useful for me on a lot of different things, but you know, if you're building a tool for yourself, that's That's fine. It's it's better if it's useful for other folks. Had some feedback from folks who were working on Mod Security, which is a WAF tool, trying to analyze some RFCs and, and they actually, you know, found bugs in their code by, interrogating some of these RFCs and corrected the behavior. So this is this is a positive result chat GPT is also able to to to understand different languages pretty pretty easily. So this is some somebody on Twitter tried to do a query about SRTP and I didn't I didn't translate that, but, effectively, this is what the output looks like. It'll be, A set of answers, and these answers are meant to be to be helpful. And, if you Closely go through these. There may be 1 or 2. Issues with accuracy, but generally, it's a good way to point folks in the right direction or and if you get an you don't like or something's not specific, you can dig in more and it'll typically become, more accurate if you ask the right rate questions. Next slide, please. Okay. So success not yet. You know, the limitations of chat, OpenAI's platform where basically out"
  },
  {
    "startTime": "00:28:01",
    "text": "not catastrophic, but, they did limit the ability for this tool to be effective and useful. So next slide Please. So future directions, there's a lot of ways you can go here. Maintaining the using the open open a plot platform, you can build an external rag. You can plug up APIs inside of chat GPT and have it call out to external services. To do this. So there are a lot of platforms that allow you to take all this extra data. Eventually, it could be interesting to expand this training data to include the mailing list archive. Which, is where a lot of conversations happen and a lot of important context happens for these RFCs definitely way too much information for the current platform. The third part here is is important, which is open source models, As of now, the tools fully closed source related relying on a closed source model, and you actually have to be a paid customer chat GPT use to use it. This is no good. But it was fine for a first draft to, to test this out. And the the last part here is quality measurement. There's no tools to measure and and, really give a quality score for how well on the RC series. So there there's a lot a lot of work there to do. And so, it it I would say a mixed bag, but it was useful at least for me to, use a new model of interacting with the RC series. And find some interesting things out about how these platforms work and how simple and and, low effort it is to build tools on top of existing platforms to be able to build something like an expert service. So, the point here isn't that everyone should use this to understand IETF RFCs. But that this is an additional tool that"
  },
  {
    "startTime": "00:30:00",
    "text": "can help you reason about the text that's in it, ask questions, interrogate and, oftentimes you don't know where your answer is and something like this can, can help point you to the right RCCs. And, next slide, please. That's basically it. So At this point, I'm looking forward to any feedback about RCGPT if you if you've seeing it about the directions and open to questions right now. Hi. Thank you very much, Nick. I think we have quite a few questions. So if people can make the questions, relatively, succinctly, that would be great as we might run out of time otherwise. Thank you. Hi. I'm Alex from Simmons. I have a suggestion to include in the future direction is the use of this thing for generating test cases. So I implement a tool that quantifies for measures compliance with a certain RFC. And I use the plain chat deputy to have an initial draft of writing use cases based on must must not should and so on. I think it's a logical, Next step, and I would be happy if it were included in your own map. Okay. Thank you. I I think if if I were to conceptualize this, I'd probably separate the generative versus the analysis side. But, under under the hood. I think it's definitely, good direction to look into generating test cases are always great. Hi. Thanks. Hi. Jay Daley, IETF Executive Director. We were talking about this earlier today, the, the rest of the talk team and me, our, thoughts were to actually create a database so that we would take the RFCs and create the vector database make that as an open resource for people to use based on the RFCs underneath it. Potentially also then to have, you know, a series of custom on top of it that enables people to query that in some sort of way. If we did create that, open vector database, would that be of use to you at all?"
  },
  {
    "startTime": "00:32:01",
    "text": "Yeah. That would be that would be great because you could just plug this in as the rag. For this rather than the, Yankee Openai. User interface. So any way to take the RFC series and, present it in, in a database form that could be useful for these, these styles of tools and with APIs that these styles of tools expect, would be great and it would be super useful for this. And generally for the IETF. Okay. Thanks. And on your last slide, you mentioned fine tuning. Do you have a series of Do you have data of, you know, questions and replies questions, replies that you can use for fine tuning the talk. Not yet. No. And I think, with regard to fine tuning, it's not necessarily about questions and answers as much as just training new data into the model. And updating it with with new data without having to retrain the entire model, which can be extremely expensive. Okay. Thanks. Yep. Is it my turn yet? Sorry. Really interesting. I guess in terms of, like, the audience for this, I wonder if you have thoughts about kind of kind of, who this is kinda best for or or equally who shouldn't be kind of using this thinking, I guess, about communities, both within the IUTF for, like, external communities kind of outside of the IETF and, and, some of the issues around, like, hallucination or, or kind of other things. And then second, kind of shorter question, just around extending this, you mentioned mailing list did you have thoughts about, like, the drafts that are currently in progress, as opposed to just kind of published RFCs, Oh, yeah. For the second question, basically any artifact generated by the I IETF could be incorporated. There is a lot of data. So thinking about how to do that right is is the cult. What was the first question it was about? Just about kind of audiences for this tool and people who may be shouldn't or should be using it yet."
  },
  {
    "startTime": "00:34:00",
    "text": "Yeah. This is a this is a dangerous tool on the wrong hands. As of as of today. And, if you are not at all aware of how the the IETF works. So I think the audience for this is folks who have based on understanding, of the IETF and RFCs, but want to be more efficient at finding answers to questions that they may have. The RC series. I'm Jean Francois. Thank you for for the presentation and support the ZZ ID. Just a question because you say, so you you use a rag, And at some point in models, they have already been train with, too big that task force issues have ericsis And I was wondering in your next A step to mention that you want to measure quality. Even if it's not defined, oh, if you We try to look at what will be the difference with the rag approach, without the white approach, but maybe in for example, GPT models, to be contextualized with the already sources of information included Yeah. And and GPT 4 has also incorporated a good chunk of the RC series, but playing with it plain, you you really have to use the web tool to or the web enablement for it to actually download things, especially with older RFC. So, yeah, I think there's there's there's lots you can do. Sorry. I was next, but I think my question got asked by Marek. I was also wondering whether you could extend to internet drafts. And I was thinking of you know, people that are preparing for IETF and to do sort of engagement in the space. Do you think that would be sort of useful for, you know, people"
  },
  {
    "startTime": "00:36:00",
    "text": "doing prep work, I guess. Yeah. I mean, one use case that immediately comes to mind is is as as a chair of of, IETF group is is to get get a sense of know, what is the timeline of the drafts and what changes have happened and why through the conversations in the mailing list. And, it could be useful for accountability for chairs as well. Great. Thank you very much. I'm afraid I have close the queue because we are already, running over time. I think it's super interesting. I could be super curious to have a debate about, what will be the role of these tools in, let's say, 5 years when they are not in if those are not in their infancy, medicines are not such a big problem, and the whole process emerged online. Yeah. Thank you very much, Nick, and we can move on to the next stop. So thank you again, Yep. So the next talk is by from the DNS Research so he's gonna be talking about the Internet defender's truckers, Carolina bedroom is yours. Thank you, Ignacio, and good afternoon, everyone. So, yeah, my name is Carolina. I'm, with DNS Research Federation. We're a UK based, known for profit organization, and, our mission is to, make makes sense of the internet, through data and research. And, yeah, next slide, please. And Alright. So this presentation is actually a follow-up from a presentation I did at IETF118. Where I introduced, the internet standards Observatory, which is an if we're running at the DNSRF, and the tool that we have launched a part of the, the standards of service, where you call the standard tracker. Which, until the last, IETF meeting"
  },
  {
    "startTime": "00:38:01",
    "text": "we were using solely for tracking, ITU standards. Today, I will be, doing a brief recap for new people in the room celebratory, you know, what it is about. I will also to be, speaking about, our standards tracker and how we have a Expanded, coverage to, IETF. And then I'll be also addressing how we, took in some of the feedback that we received at the private event. So next please. Alright. So the Internet extender's Observatory, what is it? So this is an initiative funded by, the Internet Society Foundation and the right community fund. And essentially the goal of the Internet standards secretary is to help, identify and track standards, proposals that could potentially challenge interoperability in the internet. And specifically, our, you know, our centers of surgery home scene on standards proposals that could potentially, transform how we do addressing naming, networking, and routing the internet in ways that, you know, could fragment the internet essentially. Next slide, please. So why, tracking Internet standards so the first thing we always, you know, like to say when we present this project is that we find that SEO, especially IETF, are obviously an opportunity to make it the Internet better and to ensure that interoperability. That we are concerned about, and, release it the the the purpose or, you know, what we're hoping to accomplish, I guess, by doing, the Sender's tracking is to ensure that we are discussing internet, standards in the right forum. And whenever internet standards not being discussed in the right 4 that the community is aware of that. And we're also hoping to encourage, sort of participation with, standards proposals, that could potentially"
  },
  {
    "startTime": "00:40:00",
    "text": "shape the internet of the future, and really sort of encourage thorough conversations, about how, we want the internet to evolve And lastly, we were hoping that our, internet, standards tracking can help lower barriers, to engagement, in standards. Essentially by, sort of facilitating, analysis on, standards proposals and and helping standards participants, sort of figure out which, proposals they may want to sort of prioritize in terms of tracking or, engagement. Next slide, please. Alright. So the sender strucker. Next slide. So what is the sender's, tracker? So the the sender chacker release, the, the, the heart, the, the, the bread and butter, of the Internet standards of Observatory. And it's be a tool to automate the identification of sender proposals, by topics of interest. And as I mentioned before, our areas of focus are, again, proposals related to, naming addressing, routing and networking on the Internet. So what we do, is we input standards proposals into the DAP, the data analytics platform, of the DNS research federation. We, essentially, stand for specific sets of words in those, sender's proposals that are related to our topics of interest And then what we do is, we generate, a score essentially based on how many, how frequently those those words and phrases appearing in the documents. And this, this or enables, prioritization of standards proposals So essentially, we, sort of organize the, the standards proposals we analyze into 3 buckets. By order of sort of priority from sort of the ones require requiring, sort of more immediate, or, yeah, more direct engagement, if you will, to, proposals that"
  },
  {
    "startTime": "00:42:03",
    "text": "we think the community should monitor and proposals that we, we, think the community should track. In terms of our focuses is also an important, sort of caveat to sort of highlight to the group. Our focus is on standards proposals that are currently under development. So we don't track approved standards and, sort of their their deployment or adoption, and, the SEOs, focus are 3. We started off with the ITU, team. We've expanded, the tracker to IITF, and we're going to, be launching shortly, the tracker for Etsy, which is European auto communication standard institute. Next slide, please. So this is what the tracker look on the website of the internet sender's observatories. So I'm going to get started with the ITU, tracker just to show you the updates since the last presentation. Next slide, please. So this is what the tracker, looks like. So in the bottles at the top, you can see the 3 study groups that we are tracking, for ITU. These are study group 13 on future networks. Study group 16 on multimedia and study group 17 on, security. And, essentially, what the tracker does is it shows you, a list of the, senators proposals that are being discussed in the given group sort of, ranked, if you will, by how closely the they they match our topics of interest. Next slide, please. If you click on one of the, you know, the on this proposal so you're presented with, sort of more detailed information about the, the under in questions. So you essentially get to access things like the title of the proposal, the proponent, what the proposal is about, what's being proposed for a standard station, and ask associated use cases, that are sort of presented or discussed in the standard proposal. So here in this case, we're, you know, looking at, standard proposal on"
  },
  {
    "startTime": "00:44:01",
    "text": "computing a network convergence, that was presented at study group 13. Next slide, please. The tracker also enables you to do, filtering. So say if you participated in the study group 13 meeting, that took place right before IETF, you could select, the March meeting and be, basically presented with the standards that we're discussed in that specific meeting. And then there's also other elements by which you can do filtering, for instance, if you're aware interested only on, you know, looking at new work items you could, you know, select that and and view that subset of, standards proposals. Next slide, please. And here we have another example of, how you can do filtering. So say you were interested specific use case. In this case, I selected augmented reality Again, you can be presented with the standards proposals that focus on that specific use case. Next slide, please. Alright. So onto the IETF tracker, which is the we're recently launched tracker. Sorry. Thank you, Steven. So this is, what the IETF tracker, looks like, in the case of the IETF, our of organizing principles. So the bubbles at the top are the IETF meetings. And here we did something interesting, essentially, the way we were able sort of compile this information was by, scraping the meeting materials. And whenever we, identify, a phrase that starts draft dash. We know it's, basically an internet draft, that's been, sort of, included in the meeting materials. In that way, we're able to populate least that you see, here on the screen. And very much like the, ITU tracker, what we do here is we present a list of, Internet drafts are being discussed at a given meeting, again, sort of ranked or or or sort of prioritizing order, based on our, areas of interest. Next slide, please."
  },
  {
    "startTime": "00:46:03",
    "text": "And, again, like the IT tracker, you can click on a specific, standard proposal, and then you're presented with you know, information for that specific proposal. Given that the data tracker gave us a lot of, you know, grade, organization or, you know, systematized information, if you will, about the different standards. We've organized it, in three blocks. So, basically, you can see where the standard is being discussed in the agenda what the standard is about and, the standard, status. So here, basically, we are looking at an independent, draft that was presented at the routing, area, working group. And it was a proposal on BGP blockchain. Next piece. this is Next week. Quick question. Is this live? Because tried using it, and it just shows blank for the IETF, at least. Oh, that's strange. You know, it is live. Are you on our site? should be fine. It might well be me. I'm just on okay. I'll I'll try harder. Yeah. Yes. Okay. It Are you having the same issue? Oh, dear. Okay. Alright. That's, something that we'll look into. It was working fine for me all week. So, but we'll have a look. So I'll I'll continue on with the the presentation so, yeah, here, I guess I, you know, wanted to show that just like, in the IT tracker, you can also filter by, you know, during, by use cases, say you wanted to look at proposals related to the metaverse you can select that and see which proposals we're flagging there. Next slide, please. We also recognize that people that use the tracker may be interested in, actually, searching the tracker for topics of their own, their own interests. So, here, you know, say you were interested in, you know, RPKI, what you would do is you would select all the drafts, you would type your search term in the search box. And it would, you know, provide you, with the, the drafts that are being discussed at"
  },
  {
    "startTime": "00:48:04",
    "text": "in this case, IETF 119, on RPKI. In this case, we're getting, I guess, unsurprising results. It's sending you to the site or ops group, obviously, but, if know, there were, internet drafts on RPI been discussing other spaces perhaps that you wouldn't expect this will help you you know, make sure you're not missing out on on any relevant presentations that you're interested in tracking. Next slide, please. So I wanted to show you very briefly the back end of the a standard tracker just to sort of, you know, emphasize how the methodology works, next slide, please. So this is, our data analytics platform, and essentially what we do is we upload, the, the internet drafts or, you know, the contributions in the case of ITU that we're interested in analyzing Next slide, please. We have also curated a a set of dictionaries that we use to, do our, scoring. Essentially, we have 3 dictionaries, at the moment, one for, what the standard is about, one for what's being proposed for standardization, and one for use cases. Next slide, please. And here we show you how we do the scoring configuration is really straightforward. We essentially assign different dictionaries, different weights, And also, there's, sort of slightly different weights for how frequently works appear, on the documents And that's basically how we arrive to our scoring and how we do the sort of the ranking, if you will, on on the tracker. Next slide, please. Alright. So feedback from Prague. So we received a lot of questions, Greg, question is actually on our methodology, Basically, we have questions on the meaning of track monitor and engage, and also on the color coding that we were using, up until the earlier version of the tracker. We've now, gotten rid of that. We had questions about how to access our dictionaries and search terms,"
  },
  {
    "startTime": "00:50:01",
    "text": "we have suggestions to, sort of include features that would allow to broaden the, the search terms And we also had a a comment, you know, asking us to sort of, you know, understand or, you know, pay attention the status of the standard, and, you know, whether, you know, standard was, you know, in, in a very sort of advanced, you know, stage whether it makes sense. To, to have, engagement with, with that standard proposal. So what we did in response to the feedback we received is, we created a new section spending our methodology, which is, on the Internet asunder Observatory website. Our dictionaries are now open, and they're all visible through the filtering, especially, those sort of boxes that you can take on the left the tracker actually our dictionaries. And we also enable the search box for people to be able to do their, search for their own terms And we have added also the status of the proposal. Next slide, please. So next steps, so on the side, we, we still have quite a bit of work to do on, improving the search box We're currently looking at titles of proposals and words within the, the proposal that match words in our dictionaries. So we are intending, to improve the search box so that it can actually search the entire text of the Internet draft. We also are running other, projects where we are doing AI powered semantic analysis, and, we are basically going to test the the the AI semantic analysis for the tracker. So we're not bound to be looking for specific terms or phrases but we can, you know, rely on the AI. So this is something that we're going to test and possibly deploy. And we are also hoping to participate in, future idea of hackathon. So our team can basically socialize, with the IT, ATF community some of the work that we've done. On the content side, very quickly, we're"
  },
  {
    "startTime": "00:52:04",
    "text": "beginning to plan for, expanding our topic coverage essentially to focus on emerging technologies. So we want to more firmly expand analysis to metaverse, quantum network trust, and other areas. We're going to be expanding the study groups that we, are studying, with an ITU and, the Etsy, tracker, which is for coming. And I had a couple of, extra slides that I think I've run out of time. I will let Ignacio tell me. If not, I'll run through this very quickly. Last day, I guess, I wanted to Sorry? If you can do it quickly, that would be great. Okay. Yeah. I'll take a minute. So, the last couple of slides are to highlight that, as part of the centers of Observatory, we're also putting, out there a series of resources for, the community to really sort of make sense of, sort of you know, trends and, and developments, across different STOs. So we've recently launched, our block series here, you can see our latest, blog article on the, buff that took place on yesterday. Next slide, please. And, with the support from the Internet IT Foundation. We're also funding, 7 wonderful research projects related to, standard station processes across the COs. That next slide, please Steven. And here I put on the screen a couple of the, research projects that we are supporting, especially the ones, where we are collaborating with researchers from the RASborgy community. So we're working with Ignacio with Steven also Yag who's, I think, in the audience summer, I think I see you back there. Yes. And a couple of other folks. So these are resources we're also going to be putting out there So, yeah, you should be on the lookout for that. So That'd be all for me, and I'm happy to take comments and questions. Thank you. Great. Thank you very I think Jen is in the queue. We have time for a few quick questions,"
  },
  {
    "startTime": "00:54:03",
    "text": "Hi. Thanks for the presentation. That that was great. A lot of stuff that I was already looking at looking into, and I I'm I'm happy to see that this implementation would Would the information that you have, be only available through the website of tracker, or are you also planning to have an API Good question. We haven't planned for an API, but we could could could could could could could Do that easily. Yes. I will say in terms of state of our work being open, that's, our code is open, and available now GitHub repository, and I can actually maybe share that on the list, as our, as our our dictionaries well. So, yeah, so that other people can sit if you don't interact with yeah, the data and and and, the software development that we've engaged in. If I may do a very quick follow-up, are you thinking about publishing an RFC with that dictionary? We weren't thinking of it. No. But, we can maybe discuss that, and, Yeah. That that can maybe, be a conversation for for us to follow-up on. Thank you. Any other questions? Great. Well, thank you very much. Well, I see that there is one last question. Yeah. I think, yeah, Jonathan, I see him. Coming up to the mic Sorry. I was having issues getting with thing, I think. Jonathan No worries. Hurlan Ploughler. How much of this work per time is manual because just, like, identifying the number of times someone has, like, misspelled the draft or, like, the notes aren't quite perfect or like people have done stupid things. Seems like"
  },
  {
    "startTime": "00:56:04",
    "text": "it would be very hard to keep this accurate without loads of manual work. Mhmm. Yeah. So, I guess you're referring to the scraping that we do of the meats and materials. Yeah. This is actually a good question. We don't do any manual work. We scrape them and what we what the system sort of picks up, it shows on the tracker and what it didn't or what it missed, it just doesn't. And one of the the suggestions we received, in the ProgyBend was maybe working with, the folks developing the data tracker. And, you know, working with them in, sort of figuring out waste in which we can know whether a given draft is being discussed at a meeting and sort of having a more stable, way essentially often fairing that information straight off the data tracker. Right now, because that information doesn't exist, we sort of you know, how to, you know, we did this work around, I guess. But it is indeed imperfect. Yeah. And is there a way for people to, like, Issue correct, like, if I wanted to fix it, could I just go and, like, oh, yeah. This is blinking to this draft. Yeah. I mean, right now, we don't have a way for the communities have sort of, you know, you know, go into the system and, you know, do corrections. So I think, you know, contacting us via email would be the best. But this is a great point, and that's you know, certainly an area for improvements. So thank you for highlighting that. Thank Thanks. you. Alright. Okay. Thank you very much, Carolina. Thank you, Steven. Thank you for the great talk. And Bujanka, Yes. I can see you. I can see your deck coming up. So, Nobu Janki is gonna be talking about computationally understanding give consensus process. The room is yours. Hello. Hello, I'm Priyanka, and"
  },
  {
    "startTime": "00:58:05",
    "text": "I'll continue the conversation that we have been having from my previous presentations at the Yokohama IITF where I presented PhD work at the RASBAR G. And the position paper in 2021 at the IAB, AID workshop Where we wanted to study consensus processes at the IETF, We learned about tools like IETF data, which colleagues data from data tracker. And also about Big Bang, which, interfaces with IETF data and WTHC. So continuing from that conversation, slight From that conversation, I wanted to talk about understanding the consensus process computationally. Using tools like IETF data, And then bird topic, which extracts topics statistically from text. And empaths pretrained model, which provides insight into psycho linguistic. Processes from text. Now I've conducted my experiments on 6 ops and 6 man working group mailing lists Next slide. So we know that the consensus process is slow. But different groups and topics have different ways in which the consensus builds. Now by topics here, I mean statistical topics. Like issues surrounding ICMP V Six, for example, and not a particular thread on the mailing list or a particular ID have draft. We could analyze topics for a given draft or a particular idea of thread. Just just just just that I haven't done it for them in this experiments. My hypothesis here is that by creating a fingerprint, that is a temporal fingerprint of the way the group as a whole is represented by the mailing list. One could characterize that mailing list and understand the various ways in which consensus is is ongoing in these groups and topics."
  },
  {
    "startTime": "01:00:00",
    "text": "And then by understanding the temporal psycholinguistic aspects, we have a fingerprint on how the group behaves. And how it is different from other groups. This should in future help us study war makes consensus slow or fast in the idea. Next slide. So after applying bird topics, dynamic top model on the email messages in the v Sixops working group mailing list. We see that there are some topics that have been discussed for a long time. And some which are only of interest for the relatively short time. On the y axis is the amount of the topic being discussed the x axis is time that is from the year 2008 to 2024. And each line graph represents a topic in the group And the legend on the right is the set of top most frequent words in that topic globally over time. Whether we use threads or messages to generate the topics, the results are similar. The top graph is generated using the thread's first message and the lower graph is with all of the messages. And each topic here over time over the years may have different specific top words, but essentially, the thought has continued over time. For example, around 2018, there activity around a transition of ipv4 and around 2014 it was around ip6tables, ICMP V6 Filters. So it's you can see visually that there is some severe event that has happened around 2011 that had an impact on the working group. Next slide, please. Doing the same for the related 6 man working group, we see that the topics until 2011 were sparse. There have been discussion around ICMP V4, V6, VPN, As you can see, even for the related working group, that is V Six and man which are related, the temporal tech topic activity here is different from the V Six ops working group. Even for related topics."
  },
  {
    "startTime": "01:02:02",
    "text": "And there's some similarity of peak activity and some major events. Next slide. grass, To reduce the noisiness of the I have selected a few representative topics to showcase which of these topics had activity over time to understand whether consensus was achieved slowly or fast in the same working group. We see that ebpf point to point ipv6 table is an ongoing topic still. Whereas IP to IP dual stack light and loop back is no longer being discussed. Afrin was discussed for a very short time. And hop by hop is still being discussed. These results should be obvious to participants of the working groups. But this kind of computational analysis provides this insight to anyone else in a data driven manner. Next item. Now by applying the impact model psycho linguistic model on the messages in the V Six ops mailing list. We have some interesting findings as well. Now the original model a pretrained model has 200 categories and which can also be fine tuned for specific datasets. However, I've used a small dataset of categories that may be of interest to the IITF consensus of In V Six ops, even though in the early days around 2011, people may have felt a lot of negative emotion. There's some fighting and some hate. In general, the amount of anger, feelings of torment, ridicule, exasperation, irritability, timidity and politeness have been low. And so have joined CFO, less been low. No. But participants feel some need for negotiation confusion. There's some confusion. There's some disappointment. There's some celebration. There's some crust. Relates to a possibly healthy working group Next slide, please. In the 6 man working group,"
  },
  {
    "startTime": "01:04:00",
    "text": "we see similar behavior with some differences such as there are some frequent disputes frequent celebrations, frequent fights, So these temporal psycholinguistic time cities contribute to fingerprints of the working group. And its evolution of its consensus process as these group behavior contribute to the scene, These working groups with the similar time series would be expected to computationally have similar com consensus process. Next night. Now I did try to capture the central linguistic processes for specific selected topics in the working group, but the existing models has very low coverage for them. So this may require some extending of the model, the algorithms itself. And the set of time series from this early experiment along with the code to generate them are available at the GitHub link And over time, I hope to improve these techniques and provide more meaningful results. Next. And with that, I would like to thank APNIC for, the funding and, my employer at IIESOC and INTC for their support. AI and And now I'm open for questions. Thanks. Great. Thank you very much. We have questions from Jonathan and Susan Jonna come first, please. Hi, gentlemen, Hoyden, Karlflare. Do you consider author of the comment as one of the key factors because I think at least my experiences in certain working groups, can get one person saying no. And suddenly, everyone's like, okay. Let's not do or one person, I guess. these Yes. Definitely, you can experiments redo where you are doing it for a particular person who's the author versus somebody who's commenting, etcetera. But in this in this particular study, this early study. I'm just considering everybody be to be part of the group. So it's like So I'm not distinguishing between who's the author and who's who's the commenter. But, yes, that is definitely doable. Because because you think could"
  },
  {
    "startTime": "01:06:00",
    "text": "group dynamic would be a big factor in how you get consensus. Yeah. And and if you were there with the Sebastian lesson, I mean, he's also interested in, seeing that there is something that's happening around V Six ops in IETF, which is endogenous in this mailing list, but there could be exogenous factors like outside factors, which are happening in some other mailing list. Let's say, you know, 3gpp or somewhere else, and that might be impacting us. So, this is just a very early study. This is really cool. Thank you. Thank you. And the next person in the queue is Susan. Thank you for a very excellent presentation. 2, Two questions. Did you consider the area of the working group, ops is a very good area to get a broad thing It would be fascinating to see you pick a working group in every area of the IETF. I think that would provide some very good feedback. 2nd, could you send me what the definition of consensus that you are using You don't have to tell me now. I I don't wanna take everyone's time, but you know, consensus you know, how did you define it? How did you look at it? That sort of thing actually impacts. Your your studies are your statistics are are well laid out, but the definition of I I in had totally adhesives Yes. This is, I'll I'll I'll reach out to Thank you for the comments. Fantastic. Thank you very much. Puyjanka. And the last Talk of this session is from, Jeff Houston."
  },
  {
    "startTime": "01:08:01",
    "text": "On the wonders of making RFC nowadays. So, Joe, room is your the room is yours. Hi. Jeff Houston. I'm I'm really not sure why I'm here, but I did write that's truly did write a blog article at one point because, I was try to try it. Get get get a draft through the process of producing an RFC and got Amazingly frustrated. I might it just strikes me as insane in some ways that there are all these review teams doing all this review and yet there's a massive amount of IRata coming out anyway. You kind of wonder exactly where and how does quality come from? And it certainly doesn't appear to come from the massive amount of review process that happens in the final stages of an internet draft. It just seems like a whole lot of work with almost no benefit next slide. So I started sort of musing about this and looked through the data tracker document, and I had a few questions, you know, Exactly how long does it take to produce an RFC? And and are we kind of bogging down in this process? Or have we got more streamlined than an efficient is it a case that the more we do this, the more every single RFC seems to be a surprise to process. Oh my god. Let's do this all from scratch again. And the other thing too, the What's the success rate for drafts? How many drafts actually get published as an RFC some point. So those are a few questions. And I just looked through the data tracker and kind of collated some stats. So next slide, Right now, Currently, in the current draft's repository,"
  },
  {
    "startTime": "01:10:00",
    "text": "There are 21,000 185 Internet drafts which have basically unique stem names. The average version count is now 6. And surprisingly, The amount of time We take to cook a draft is now 2 years 4 months on average. Which, to my mind, strikes me as astonishingly long. Do you wanna jump up now, Susan? Cause I don't really care. You're gonna leap up and make a comment, make one. Otherwise, I'll plow on. I'll plow on. Pops Oh, god. This is not a deep talk. Okay? It's just a talk frustration. Next slide, So then I started to look again at at@thefulldata And, you know, months. There is an outlier out there at 2 160 months. Truly, truly, truly. The average draft age, as I said, is what did I say? It was 2 years and something. But if you look at that distribution, there's awfully, awfully long tail. You know, and and that count, as I recall rightly, you know, is, is in months. And there's a huge amount of drafts just sitting there as if aging them makes them better. It doesn't. It makes them less and less relevant as time goes on is my view. And I don't understand why there's just so much stuff to sitting there gently rotting next slide. And, of course, the classics. I really think. I have a quick question. Do you filter out the drafts that are with the ISG. snow. In the Right. So so the It's in the current repository. I don't care if the IS is leading the mate or something else is leading the mate. leading the So Someone's mate. It's it's The the long tail has a reason. When they're so so if you wanna do this analysis and look at the IOTF process,"
  },
  {
    "startTime": "01:12:00",
    "text": "I would encourage you to limit it to the time before ISG because after ISG, there's individuals, that have disagreements that go on for 2 60 months. And, several ISGs have told them that, you know, it's gonna go forward until this gets fixed and they disagree with that. I'm not looking for reasons, Lars. I'm like, You you might. I'm not. I'm just saying they're sitting there rotting. And these are the worst. And I really don't understand about Mister Edwards and Tillmet and these Axonics off state. I I can't find it anywhere else. And I I honestly think that's a mistake, but, you know, On the other hand, draft Kunzey ARC, which gets faithfully date date updated every whatever it is 3 months or whatever. And he's been doing it now 37 times. Persistent. Oh, no. No. No. Again, if that's a Sorry? Oh god. No. These are the old ones in the current draft's repository. They're the ones that are sitting there aging. These are the oldest things there. I'm not attributing blame to anyone. I'm observing what's in that directory. So, you know, nothing personal here. It's just what I see. Next slide. Now this is kind of interesting because We do the dates, and there's an incoming, ID draft rate. I had a data drop somewhere around, you know, 2017. But you kind of see IETF Meetings Cause the draft per week to to rise up to around 400. And so there's this background activity of submitting drafts throughout a year and then there's kind of a cutoff and then there's bangs. Stuff comes through IETF Meetings. And it sort of goes about four times the running average. Next, and there's that blow up. I forgot when we year 2023. And just look at every week in 2023, and it's immediately obvious the IETF, you know, meetings and cutoff weeks. That is this?"
  },
  {
    "startTime": "01:14:02",
    "text": "Sort of flurry of activity in the 2 weeks before an ATF meeting or before the cutoff point drop, drop, drop, drop. Post meeting, Not so much. So we think the meetings are a case for working groups to meet and sort of work through the draft rate and sort of produce a new version of the draft. Not as much as the stuff before. Afterwards, it very quickly lapses within 2 weeks down to Ho, business as usual. Next, This is a longer one, Drafts per month from the year 2000. And I'm trying to see the long term rate here. At a monthly level. I'm trying to get rid of the IETF meeting factors, which are the peaks and looking at the longer term of has the activity in the IETF grown, We've got lower. So since about 22,009, steady at about 300 and you draft per month. Sort of. Next. But the o o submission. Right? Is much lower. Around about 50 to 80. 0 0 drafts per month. Outside of the meeting months, and that's been since 2003. Since 2003, the amount of incoming work items coming to the IETF as done by OO Draft has actually been steady for now 20 odd years, COVID period, small decline, But, you know, what you actually notice from 2003 to 2009 is the amount of cutting and polishing 01020304. That's increased. And then that decreased again later on. The basic incoming work pattern has been incredibly steady. Next. So let's move on to RFCs. And the success rate. So Since 1989 in the repository, you have a comment I was gonna come along the last line."
  },
  {
    "startTime": "01:16:04",
    "text": "Richard Barnes. Oh, okay. Sorry, Richard. It's the mask, mate. worries. Yeah. No Previous slide things. You know, backwards. So so I I know that this this decline in 2010 or so correlates roughly when GitHub started to be, a thing that we started to use around the TF. So I wonder if some of the the change, you know, the lack of revision you're detecting just be revisions happening elsewhere. I I like that. Theory. Personally, I I'd load GitHub with an intensity that is probably unrivaled. But nevertheless, I I can I can see that other folks seem to love you know, love it or hate it, but nothing in between? So you're you're right. It could well be GitHub. Reduces the intensity of the revisions. Because previously you kind of sneezed another revision, another revision. Could be right, Susan. Four points. I just got to 4 and I left all the things. Yeah. Right. Well, let's get rid of the pool. the patience to guys for I just I don't have Number 1, I did a 10% look at Drafts in detail. Blow by boy. Sequence by sequence, which tells you I went deep dive instead of the sort of round, statistics that you did. Meaning, I tracked them and I tracked when they went through the ISG. You need to listen to wars, ISG time, Matters. Number 2, Our the publication time varies. Which you probably are getting, maybe getting to, but The publication time varies, and it varies for variety of reasons. There is a lot of post processing number. You want me to keep going? You want me to I was gonna notice that Christian Wheaton she did an RFC. On that exact same deep dive, which is at the back end of this side pack. So, yes, there are a lot of raisins There are reasons. I'm I'm not giving you reasons. I'm giving you numbers. No. And then I I have some of the same numbers."
  },
  {
    "startTime": "01:18:00",
    "text": "The ISG process has some ebb and flow as well. You know, the lacking process has no member flow. So I'm trying to say while this is interesting. Some of the you're getting some false positives and some false negatives. I look forward to talking to you in detail. I think that yellow thing at the bottom is kind of important. The yellow but it's a thing to be that goes beyond it, that you might wanna consider is whether And this goes back to some research done, around, 2007. By Simcoe. I think it matters whether the content that the previous speaker does, apparently, it's really easy to do little REMS CSR routing. But it may not be as the big humps are different. Jeff. Right. But the incoming work rate was really where I was pointing. Yeah. But the incoming work rate is Incoming work rate is varied based on whether it's a new big work or it's a whole bunch of little graphs that are iterated Just a thought. Well, we're having fun. Yeah. Yeah. Well, might as well get in Alice Stewartman. And, so I can't quite, as a description of what's happening, I think it's really useful. I I still get the in impression that you can play there's a there's a negative observation to this that this is not good. Is that No. No. correct? This all started because I was just pushing through one draft. Seemed to be taking forever. And I had a negative impression of treatment of my draft as does everyone when it takes forever purely personally. And then I started to look at the big numbers, and I'm kinda going, well, these are the big numbers."
  },
  {
    "startTime": "01:20:00",
    "text": "I really don't have a criticism or not. It's just Oh, you think it'd be fairly mistreat as opposed to unfairly mistreated. Isn't everybody? Day? Okay. Oh, okay. Fine. We agree. Okay. Right. Good. Okay. So because I think that this is like it's supposed to be. I don't know. I don't understand what supposed is. But will see. I have some more data on RSC. So I'll I'll we just make the observation that it should be progressively harder, to make modifications today. The low hanging fruit is all gone. So it should be more and more complicated because you've got to deal with the integrated some of all that stuff these guys need recording and looking after. Right? So it It's got to be another. Hold that. Okay. Thought. Mixed because it's a good thought to hold. 39,719 drafts RFCs in the same period, not so much. And the success rate as far as I can see in looking at the conversion rates is 21%. We managed to get rid of a bit at the bottom, 1130. We updated a few. Verify to Rata, I actually didn't take into account grammar. This is technically verified IRata quite deliberately. So, you know, come as the anything else, you know, that everyone slips up on? Nah. That's that's not here, but the ones where there is a true this is a problem. And it needs to be recorded is a lot lower. 21% conversion rate. Next Sorry. On on the conversion rate, you're you're taking into account, individual drafts that get adopted as working group drafts as some parts of the conversion are not just drafts that disappear. Right? It starts. It gets adopted by a working group. Goes to the ISG name changes a few times. And I'll put it up. and You're tracking you're tracking the name change. And Yes. Because someone did that, and that could have even been there's a data track a record. There is a record out there that says"
  },
  {
    "startTime": "01:22:02",
    "text": "This became that, became this, became an RFC. It's very incomplete in the data tracker. It's a wonderful thing. 21%. Next So this is the publication rate from the RFC editor. From the date. So you can mate. Are some ones out there from the air dot things started to go you know, with 1990, with the NSF net and off we go, Alastair You can start to see that tail off. Because because next. Now I have missing data, which is a pinning the bot. But This is from the 1st Draft of the first kite flight So you go back through all those chains of a became b, became c, became b. And and from the point to the that point when it was a published RFC. I have decent data around 2003, 2004, when the number of years to do that process seemed to be pretty ground 3 to 4 years. These days, they do come out in bursts if if this is done by month but it is somewhere between 8 to 12 years, one way or another to actually go from the initial draft through to an RFC these days. Next, And I've sort of compressed it up there. Done it by, RFC number, which is actually a nicer way of doing things. Because the RSC number is kind of monotonic, but it doesn't have the work bursts. In time. It just says, RFC numbers. So for about RFC 65100 onward, that time has been stretching out The early drafts, and this is directed to your point too, Around 3000 to to 3a half 1000. Came out within around 2 to 3 years. Relatively straightforward. These days, that is a rarity Some do. But most of the time, that entire period"
  },
  {
    "startTime": "01:24:02",
    "text": "is somewhere between 4 and currently between 6 8 years actually go through the mill Yeah. So this is, great to show the average. It would be nice to the phase, the the statistical spread. Of a croissant distribution over this time period to see the ones So anyway, just data processing. Data processing stats. Call in the actuaries. Yeah. I mean, coming back to the, sorry, common Perkins coming back to the comments you're you're making earlier. I mean, What's instructive is to also look at, the number of citations to previous sees a number of the amounts of mailing lists discussion of each draft the number of, so I received 2 119, comments and the drafts and so on. And there is a clear trend of increasing complex to an increasing discussion and increasing difficulty in keeping with the backwards compatibility with all the previous So, yes, the the the delays are increasing, but I think it's very clear why they're increasing. You see, I have no value judgment on the fact of why. I'm just flying over the landscape at 30,000 foot going. This is the landscape. I I understand there are reasons, but I'm not trying to actually produce any here in this this pack. It just these are the numbers. So I appreciate the point. I think it is a lot lot harder to get an RFC out that actually makes sense. In today's world where you're charting charting through previous work. You're trying to understand if it reinforces contradicts it, what you're trying to say in the context of all the work we've done before. That's a lot. Time and a lot of work. It's it's a lot of work, and I think it's some unsurprising increase as as the technology matures, as the network matures, us money for backwards compatibility, it it's harder to It's harder to produce an ROCE than when you're starting from scratch a a greenfield."
  },
  {
    "startTime": "01:26:01",
    "text": "Harder equals longer. Before we go there, Susan, let me see if there is a next slide gotten what I said here. I gave you an answers. So currently around 6 to 8 years. That's about four times longer than it was 20 years ago. And and as I said before, the success rate of actually getting this process is around 1 in 5. Is that it? Is there another slide? I promised. Christian Hwedma in 2021, actually did a deep deep deep deep dive into a small number of RFCs and picked apart every piece and every step of the process. It's interesting reading because that then does get to the reasons why. Which I have not done here. Just have not. Oddly enough the data is there, but, you know, life is finite. There are many things to do and spending my entire time coming through data tracker statistics and seeing state changes is not exactly top on my list. Others might find it entertaining. And I think that's it. Yes. It is. So, yes, k. Some of us did find this entertaining. Great. No. More power to you. And and I'll take a step back and you should be up here next time. We we we wrote an AMC paper in 2021 that talks about this in great detail. And and I think, you know, This kind of stuff is relevant. While Susan comes to the microphone, I do remember from the very early days, 89, 1991, where we prided ourselves. That we were vastly inefficient and pragmatic, and the ITU was not, and this was wonderful. But I'm like, once you're in the mainstream of this business, you are the business. Then complexity kind of creeps up. And with city comes indeed, all of these issues about trying to get the message right as distant from getting any old message out the door. I think that's just maturity of what we're doing, but you might have a different view, Susan. I don't know the question was, do I find that complex"
  },
  {
    "startTime": "01:28:01",
    "text": "is causing some of this Yes. Because when you have to wedge in something based on all the stuff we've been doing before, it takes a little idea to see if we're gonna break something and cause some meltdowns. Now, not that a working group I'm familiar with would do that. What a concept. So the the point is, just to let you know that the strife I did has And what I mean by a stripe is 10% of the RFCs. And yes, Jeff. I had nothing better to do with my life. And look at that. you very much for that. Thank I'm glad to do it. Comment. I I had a wonderful time. But One of the reasons your strike between 2000 June 2006. It's a little funky. Is there's also some weakness in the data at that area because the data track was in a transition period. And so you'll find that things are missing if you do a deep dive. I thought it was mine lost right around. No. It wasn't there last right. I went ahead and tracked it down. And then when I tried to track down the ISG processes in there, that the the even the notes are a little squirrely. Not gonna You're saying it's not me. No. It's not you, dear. So the point is I think The deep dives are useful. I think it's also Again, to AC Lars. You gotta look at where the delays are. I think the next step is, you know, Are we doing the right thing by this? Is the process, etcetera, etcetera? And that level of introspection not here. This is just a straight up. This is just a pass through the data to see how long it's all taking. I think we've all made we have run out of time, Whatever. I've run out of slides. You've run out of questions, Andrew."
  },
  {
    "startTime": "01:30:01",
    "text": "So just sorry, Andrew Campling, for the people remote. Observations. 1, I guess, 6 or 8 years if that's what it is now, we might wanna question whether the stuff's still relevant when comes out the other end of the sausage machine. And complexity notwithstanding It's not much point producing stuff if it's already obsolete. And maybe picking up on comment, I think, from Colin, if most of the 6 straight years is vested with the ISG. Maybe we should give some KPIs to the ISG just to inject a bit of speed into the process. Oh, those are microphone forming qqforming words here. Oh, John Pollan Klapler. I've only been coming to ATF for 5 years, and I want to thank you for giving me hope that my draft might one day come out. I Thank you. Appreciate it. Thank you. Like I said, I wrote this original blog article out cute frustration. You know, I was just feeling myself, oh my god. Why why is this happening? To my favorite draft. But anyway, So, colin Perkins to to correct the record This is not the AESG's fault. This is not the ASU which is the delay here. It does not take 8 years to publish an RFC the the data we have looking at it. It takes 3 or 4, perhaps. And, yes, the time is increasing, but it is not the ISG processing which takes I'm not saying where the process is. I'm saying from the initial 0 through to an RSC. I understand that. And and we agree that it is around 6 to 8 years because that's what I see in the data Drecker. The data that we see is never free to fall. I think there's something wrong with your analysis. Oh, I'm wrong. I think the ISG is always right. Sorry. Yes. You're right. quite That that that it I think you need to be"
  },
  {
    "startTime": "01:32:01",
    "text": "think you need to listen to what people are saying here. The delays are not the ASG processing type. The delays of the working groups and the discussion in the working groups and there is considerably more working group discussion and considerably more revisions in the working groups. And considerably more cross references to previous drafts more normative statements, and that is what's taking the time. We have done this analysis. So please look at the prior work Thank you. We're done. That was Colin. That was it. Oh, Susan. I will disagree with my esteemed colleague. Colin, that I think there's a little bit of flux in both both from the working groups since I've seen plenty of that. And all. So in things that happen inside the And if we ever had a metric of time to product, it would be different again. I don't think this is an industry that works a speedy fashion. Thank you Thank you, Joe, and, thank you everybody for the and discussion. And for joining the session. Bye, everybody."
  }
]
