[
  {
    "startTime": "00:00:05",
    "text": "there is a fair amount of echo that we get from the room i'm not sure there's anything that you guys can fix so he did i'm not sure what to do i don't know what knights are on so all right good morning how is our echo sounding right now it sounds pretty good here okay there's a little bit of it but i think it's manageable"
  },
  {
    "startTime": "00:02:01",
    "text": "it's still there but i think we can deal with it all right i think we'll just go ahead then um if there are people on site with meat echo who can help keep tuning things that would be wonderful but otherwise we'll forge ahead alright let me turn on my video a bit hello from 2am in california all right um let's get started so welcome officially to ietf 113 in vienna and virtually um it's our first really hybrid meeting and so we'll all be learning how to do this so let's have a lot of patience and grace with each other in this you are in ippm ip performance measurement i am tommy paulie one of your chairs marcus also here probably more awake than me and we have a pretty packed agenda today let's get started first if this is um one of your first itf meetings or if it's your 30th 30th we do ask you to note well all of the different policies for participation and contribution in the itf if you haven't seen this before please do take a moment to read through it for the meeting management um for people both on site and remote we are using meat echo and it's the same way it's been working virtually"
  },
  {
    "startTime": "00:04:01",
    "text": "for the people who are remote and in person i believe there is a heat echo mobile app that you can use for queuing please do use that we can see the camera into the room but it will be useful um to manage everything from me tech over there if you are presenting you are able to share your own slides in the meat echo tool up at the top there is the document view with a slash through it and you click on that you should be able to ask to share slides there should be an equivalent button in the mobile experience if you need help sharing slides the chairs can also do it for you and then we do have notes going on thank you stuart for taking the notes for this meeting um for jabber scribing uh i i think the chairs right now can take care of forever and we can also ask these people in the room to release things all right looking at our agenda we are spending the first chunk on the primary working group documents that we have that are active we have a bunch of documents that are in later stages they're with the isg or they are in the rfc editor queue where we've been very productive so thank you to everyone in the working group for that but today we'll go through um some of the protocols starting with some of the more newly adopted protocol work and then getting some updates on iom as well as explicit flow measurements and srpf then after that we have some shorter talks about some new proposed work that has received either a lot of uh work on side meetings or uh discussion on the test and that's all we have for today any"
  },
  {
    "startTime": "00:06:01",
    "text": "agenda bashing or should we launch right in okay i think first up then we have our capacity metric protocol with al and al do you want to share slides hi tommy if if if you guys can share the slides uh that would help i think okay i can do it again it is available in the pre-loaded slides here but yeah that's great all right and i'll i'll share my video briefly there i am in front of my quilt made of ietf t-shirts good morning everybody so um we've got the capacity uh measurement protocol uh to talk about this morning we've got a working group draft and one which we've updated uh lynn chaviton my long time colleague and i are working on this together we're looking for more help and review from the working group so next slide please so here's a little reminder about the protocol we've got a basically a simple setup exchange between the client and the server test activation exchange that follows that talks about the optional testing parameters in the in this first phase we've we've added a server admission control a um kind of a programmed bandwidth check and we think that'll help with managing the server capacity"
  },
  {
    "startTime": "00:08:02",
    "text": "and um the rest of the after the test exchange setup exchange and test activation exchange takes place we have the test stream and that still has a feedback path with the uh either the measurements or the commanded test rates to use for the next 50 milliseconds or so so we've got a continued round-trip relationship going on throughout the operation of the protocol and we actually set bits in the load pdus to stop the test stop one and stop two from the server and client respectively and so that's how we basically turn things down at the end of the test duration next slide please so uh thanks for working group adoption some new folks joined the working group based on the um the work in the open source project and uh it was good to have their input and review uh all along the way in fact they good suggestions like uh the suggestion to include a randomized payload option and also um how that might be implemented so we've tested the performance of that and the code suggests uh performance of the code um it suggests very little uh compressibility of packet payloads so uh so that's good in fact we got surprisingly low rates and in some of the tests where you know much higher rates were uh claimed and as i mentioned the server can set a"
  },
  {
    "startTime": "00:10:00",
    "text": "bandwidth limit for admission control um that's great when you have uh you know some clients trying to test five gigabit per second services and some clients trying to test 25 megabit per second services you don't have to allocate uh five gigabits to everybody uh big big savings there um we have an optional stop for start i'm sorry start rate in the load adjustment algorithm now the fixed rate option remains so that basically means that if you're trying to achieve gigabit rates you might start at 500 megabits and test your search your way up from there also we've got backward compatibility uh the new version nine of the protocol which is in the draft is is backward compatible with version eight which was present up to up till the last version working group zero zero um and we got some good feedback from uh folks during working group adoption uh one of the points was consistent terms for test activation and question response that that came from your guy also the clarifications about test stop and um there are even more error codes now so we're keeping the field uh uh bite-sized and uh a bitmap would be much bigger i think if we tried to implement that um and in section four i took out all the parameters that were basically referred to or were redundant with uh rfc 1997 the the metric and method and um trim down we've basically trimmed down our proposal to four security modes the two that we've got implemented unauthenticated and password and um"
  },
  {
    "startTime": "00:12:01",
    "text": "we've got a secure setup exchange so that would just be the first part of the setup and then you know the classic secure all the things that's the last purpose so we'll talk about more about that in a moment next slide okay so the next steps authors uh the welcome proposals and revisions to the security modes uh with working group adoption we can now adopt uh or ask for a um an early sector review uh may help us solve that one go and uh that would be really cool um you know that as we've learned in past meetings there's no silver bullet but uh you know maybe if we make this simple we can get a good simple answer and we don't so um obviously one of the things i talked about last time back in november was that this protocol can do more than measure capacity we've got the ability to to have real-time feedbacks of measurements and you can actually do a lot with that change the sending rates as we do now but that could be as a result of other paradigms or heuristics that people want to use in order to model traffic uh i mentioned the four modes if you want more modes say so and um protocol 9 allows for a new load adjustment algorithm with more robustness to all sorts of problems because the feedback we got is is people said look you guys say you're measuring maximum capacity so please always do that you know even even if you have to put more uh load in the channel uh do it so uh so that's what we heard and that's what we're working on so i got three minutes to let people ask"
  },
  {
    "startTime": "00:14:01",
    "text": "questions thanks all right um frank were you in the queue are you i'm trying to go and understand how to cue ah yeah you you are able to unmute yourself you can also click the hand but it's fine go ahead please okay i have a very simple question to uh al so al uh you mentioned that there is an open source implementation uh could you drop us a pointer to that one yeah yeah of course frank and maybe add a reference um so i'd be well i might have somebody that wants to go and use it yeah cool i i think it's i think it's in the draft and i didn't find it on the draft which is why i'm asking so but but maybe i just didn't read it carefully enough oh oh okay okay um all right i you know i'll i'll drop it in the meeting minutes and um so it'll be there but it's a it's an open broadband project on github uh so it's open broadband uh okay then it's the udp st reference okay got it thank you yeah yeah yeah good i'll i'll and i'll go back and put it in the notes all right uh will were you trying to get in queue or no okay cool thank you all right any other questions next presentation thanks okay i'm not seeing anyone else getting cute thank you al for this um"
  },
  {
    "startTime": "00:16:01",
    "text": "so it sounds like there are a couple actions that the chairs have so if we could add that to the notes that we should be asking for the early sector review and we can kick that off soon and then also for the repository for the code we actually have a new tag and data tracker for related implementations so that you can find it more easily and we can make sure that can get added as well so that when people look at the document in data tracker they can just click on a link and see your implementation so thank you cool all right i think next up we have responsiveness and christoph did you want to be able to drive the slides for yourself there uh yes i can do that great thank you yeah let's show my screen i'm sorry about that okay hello everyone uh i hope you can see my slides being presented yes okay so um welcome um this is responsiveness under working conditions i am going to present uh the changes that have been happening in the draft and the main discussions points that were happening during the working group adoption but before i go into the draft i have two parts of the presentation uh one that is on the implementation experience the first one"
  },
  {
    "startTime": "00:18:00",
    "text": "is on the server side we have open source implementations of the server side and the second one is we have a new open source client-side implementation that implements the methodology so first i'll hand over speaking to randall about from apple about the server side hello hi uh hopefully it can be heard it looks like it okay um hi at the network quality uh quality server repository we have a sample configurations for opacity traffic server apache httpd and nginx in this same repo there are two complete server implementations written in swift and go that can be used standalone from other web servers in front of them the apache traffic server configuration in that repo is the same implementation that apple cdn uses to serve traffic for the network quality tool from apple um next i'd like to introduce will hawkins of the university of cincinnati particularly will thanks that was uh that was quick and succinct i like that um well my name is will hawkins i'm from the university of cincinnati and i've been working with um both kristoff and randall quite some time now on implementing the protocol in go as a second um clean room implementation and um i just wanted to report a little bit on that today uh all of this code is out there right now on uh github at the following url"
  },
  {
    "startTime": "00:20:00",
    "text": "url uh the license is under gpl version three 3 we're having a little trouble in the in the room here with the the slides aren't showing for some reason on the screen and uh we're trying to diagnose that um kristoff yeah let's switch to the preload yeah take off your screen will you share it or should i go ahead you should be granted um you should be able to see a way to select which dick you want yeah there you go okay we're seeing it now on our screen here awesome okay great sorry about that yeah i'm sorry i hope i didn't uh nobody didn't screw anything up there um uh but uh the implementation is in go and it is has been tested as far back as government 1.16 uh presumably to work with earlier versions uh i just haven't tested with it so not that it won't work but this is sort of our backwards version so far i wanted to report on interoperability successes we have had uh successful interoperability with apple's um implementation as randall just talked about the one that they didn't go so we've had successful implementation interoperation with that one and also successful interoperation with apple's public measurement endpoints um that are out there and there are the same ones that are used by the mac os and ios clients the to do on the interoperability right now is to do calibration of the rpm measurement between the network quality client that's in mac os and ios and uh our version so we're currently working"
  },
  {
    "startTime": "00:22:01",
    "text": "on that just a few lessons learned uh before i turn it back over to kristoff and one of the really important lessons that we learned was to ensure that go's http api opens http connections uh when we attempt to use some advanced configuration options on the http api it tends to default back to uh http 1.1 connections and we really want to make sure that that's uh 2.0 one of the other lessons that one of the other big lessons that we learned that took a long time to overcome is that uh those http api aggressively pools tcp connections so that prevents us from saturating the bandwidth in the way that we really want to to be able to do saturation finally one of the big lessons that we learned is to build in debugging support from the beginning one of the things that the implementation has now is the ability to log per session ssl keys which give you the option or the opportunity to use wireshark to do debugging of connections and um and at the saturation as it goes finally uh as usual with this with any implementation and interoperation test and work is to take advantage of this experience to clarify ambiguities in the protocol and to get those rounded out and that's one of the things that i think kristoff will talk about as he goes into talking about the protocol itself and the changes that we've made so i don't want to steal his thunder but um feel free as we go forward at the end of the talk if there's any questions i would love to have those and please feel free to reach out on github and send patches or submit issues if you if you try it out thank you very much thank you will that was great"
  },
  {
    "startTime": "00:24:00",
    "text": "so over to the major changes in the itf draft um thank you very much for the working group group adoption um so during this presentation i want to address mostly the two biggest discussion points which were around what is working conditions and how can we interpret responsiveness results additionally they were in terms of the changes to the draft there were a lot of minor tweaks in the wording and clarifications thanks to many contributors particularly will also from his implementation experience on uh to make things more clear on how the protocol actually works so the first big discussion point was what does it actually mean working conditions so in that sense i clarified the definition of working conditions in the uh section in the working conditions section and so i want to revisit this here and open it up for any kind of discussions that may come up so the goal of the working conditions the way we define it is to create a realistic traffic pattern that is exploring the worst case scenario and that is an important definition in the sense that realistic means that we don't want to flood the network with i don't know udp traffic for example because we are not trying to measure the maximum capacity um like in the previous draft we are trying to explore how the network behaves when it is under traffic patterns that end users actually generate and so we use http 2 or http 3 in the future with standard congestion controls that way we create the realistic part of the network responsiveness working condition and how can we push it to the worst case scenario is by creating multiple bulk"
  },
  {
    "startTime": "00:26:02",
    "text": "http requests like now what we want to do is in the responsiveness test is we want to expose any kind of buffer bloat right and a single tcp connection already would create the kind of buffer load that we need to measure it however a single connection with tcps sawtooth would create only very temporary buffer bloat however we want to create what we call a stable buffer load situation so that we can actually measure it over a certain duration of time and so we create this kind of um stable buffer load situation by creating multiple http requests and so we really push the network into a worst case scenario but even by creating those multiple bulk http requests we remain as a realistic traffic pattern because um it's very similar to basically when you receive a message or send an email with multiple large attachments same scenario so there any questions or comments on the working conditions okay thanks then i move on to the next part another part of the discussions we had was about how to interpret responsiveness results and what are we actually measuring so i mentioned earlier that we are trying to expose buffer bloat and typically people look at buffer load as what is ever is happening inside the routers and switches now that is true definitely and each network point between your client and"
  },
  {
    "startTime": "00:28:01",
    "text": "the server has the potential to expose buffer bloat and to to have buffer bloat however buffer blows can also happen in the end host sets the entire networking stack from ip all the way up to http can be subject to buffer load and so each of these points in the in the networking stack layer has the potential to create buffer bloat and so because our methodology is using http we um we may expose these kind of buffer blocks as well it can be argued whether that is um uh intentional or not and in our case it actually is intentional right we because we want to measure responsiveness the way the end users are experiencing we are intentionally using http so that we are able to expose these kind of buffer loads on the end endpoint networking stacks so one of the questions during the adoption call was well if i'm having let's say i'm measuring um [Music] responsiveness and i create this load generating connection between the client and the server here in red right and it's filling the pipe and it exposing it is exposing buffer bloat on the right side those blue boxes that i draw here let's say the buffer load is happening in this in these sections the http the tls and the tcp connection now as as a measurement uh user how would i be able to rootcast it and to identify that the buffer load is happening there well one way it is possible to do this is because we create not only responsiveness probes on the load generating connection we also create separate connections to"
  },
  {
    "startTime": "00:30:00",
    "text": "propel responsiveness and by using these separate connections we are able to identify whether the buffer bloat is happening deep inside the network or it is happening on an end and or endpoint networking stack on the http or tls or tcp layout so that with this explanation in the new section interpreting responsiveness results i hope that i addressed all the comments around how we can root cause and understand the responsiveness results so are there does anybody has any questions or suggestions around uh these uh say replies to the comments during the adoption call um yeah so please get in the meat echo q if you have any questions uh ignacio i do see that you have uh some comments or questions on the chat be happy to hear those as well and stuart who's in the cube so i assume i'm doing this right i click the button on my laptop and i'm coming to the microphone yes okay that's you're good okay i just wanted to thank william for getting involved with this and doing the clients in go i think that's awesome so thank you for that contribution and see thanks stuart i also see there's a comment on the chat how do we intend to create real traffic um"
  },
  {
    "startTime": "00:32:03",
    "text": "so the real traffic is by we create http bulk data transfers so we do an http get for a very large file and depending on the server implementation we actually recommend this large file to be basically an infinite uh response and so that is our way to create unreal traffic because http gets for large file is what happens when you are downloading a large attachment from an email and so this is as far as we see the closest we can get to a realistic traffic pattern all right and then listen also do you want to unmute yourself thank you thank you hi everybody okay um oh i am my question is related to because normally the the real traffic inside of of a network depends not just in one client dependent several clients multiple clients and this is the part which is really difficult to imitate imagine that you are behind a network and and then okay it's now so clear in the literature but normally it depends on on the on the loop of a tcp for instance when some packet is dropped something like that this is this is the the idea about the question how do you plan to imitate this large amount of clients doing traffic at the same time thank you"
  },
  {
    "startTime": "00:34:01",
    "text": "thank you for this question um so i agree it's that's uh imitating multiple different clients and if i say clients i mean different um different devices is unfortunately not possible with this kind of a test we would need to have some inter-device synchronization and communication to start the test and then have them all create these kind of http bulk data transfers at the same time um and doing that is not possible without without a protocol to talk between the devices and it's from our perspective currently out of scope for this draft to do this for now we are targeting only [Music] load that is generated by the device itself um you had a second question around uh tcp uh and how it reacts to um how to react to the packet loss and so on that is the reason why we create multiple tcp connections so that we can when one tcp experiences a packet loss the other one is still going and sending it at full speed all right and we have al in the queue go ahead okay thanks uh thanks for your updated draft uh christopher and to everyone uh for your work and implementation um a a couple of questions to your uh your your summary trying to close the discussion on working load and responsiveness here the um i noted i read the draft again yesterday quickly and and i noted"
  },
  {
    "startTime": "00:36:01",
    "text": "sort of the use of capacity uh alongside um you know the capacity of the link alongside words like saturation and and then you know the real test is based on uh tcp maximum or good put so i mean there's there's still um you know obviously some different terms and some different um uh ways to interpret what uh the working load conditions all could be um for example you know where in the in the metric and method that uh the protocol i just talked about supports uh that's a maximum iplayer capacity so there's still i think a little little ambiguity in the terminology that you might be able to root out um also i didn't notice in the draft any uh discussion of the effects of congestion control algorithms uh you know sort of the older ones are more likely to fill the buffers and some of the newer ones have the goal of of not doing that so um you know you're going to get different levels of working conditions from those and um and and as ignacio says uh with multiple clients you're going to get kind of a mixture of those congestion control algorithms potentially so there's you know there's some some things to talk about here and and um you know unfortunately i don't think we can shut the door on on all these discussions quite yet but thanks for uh putting your work together appreciate it thanks a lot for your feedback al um yeah we'll definitely try to clean up some parts of the capacity wording and uh i'll take your feedback and go"
  },
  {
    "startTime": "00:38:02",
    "text": "another pass on capacity and the wording we're making sure that we use the right terminologies there and uh i like actually the suggestion aren't having a discussion about congestion controls um i'll add a subject section for that as well all right thank you and i think we are up on time christoph were you at the end of your slides yes okay well thank you very much um and i believe next we have and are you able to drive the slides yourself or do you want us to do that uh would you help to share the slide i can thank you i can do it let's let me find it there you go okay hello everyone uh it's xiaomi speaking this presentation is on echo request reply for enabled institute om capabilities the latest version is 0 3 the last itf the 0 1 version has been presented next slide please after ietf112 three discussion points were raised and fully discussed on the main list first one is this document still needed in a limited domain the quick answer is yes correspondingly updates have been made in the introduction section to clarify clarify its usage"
  },
  {
    "startTime": "00:40:02",
    "text": "second discussion point is may this document be obsoleted by a young model the quick answer is no correspondingly a suggestion on using icmp to carry a model is not accepted the third discussion point is are more requirements than recommendations needed for security the quick answer is yes and the requirements are specific to icmp v6 etc clarifications have been made in the security considerations section of this job next slide please uh this slide provides more details on discussion on point one uh in a limited domain as defined in rc 8799 this document is not needed if both preconditions exist and the first one a control entity that has control over every iom device is deployed second one a strict explicit path for the iom package is provisioned by the control entity and the takeaway from the discussion is that if neither of the above preconditions can be confirmed then this document is still needed in a limited domain next slide is this slide provides more details on discussion point two"
  },
  {
    "startTime": "00:42:00",
    "text": "during the first working group adoption part of this draft there was an order suggestion to use netconf between irm encapsulating node and iom transit encapsulating nodes one paragraph was added into the introduction section to explain why it's not a preferred approach after that there was a later suggestion to use icmp to carry the informational elements derived from the yam model however i echo requested reply is not a management protocol like netconf or rest com icmp doesn't seem suitable for carrying informational elements derived derived from the yam model so this latest suggestion is not accepted next slide please uh this slide provides more details on discussion point three a number of specific security requirements for icmp v6 are defined in the icmp v6 extension jobs the enforcement of these security methods might be discussed and recorded in that jobs so here we list other security methods uh first one we can use ipos and authentication header"
  },
  {
    "startTime": "00:44:01",
    "text": "or i'm encapsulating security parallel header to provide integrated protection for the im capabilities information we can also use ip encapsulating security payload header to provide privacy protection and network operators can establish policies that restrict access to the smp v6 iom echo functionality they can enable disable icmpv6 iom echo functionality they can define enable the namespace ids they can do for each uh enable database namespace id define the prefix from which is mpv6 iom echo request messages are acceptable and last one right limit incoming icmpv6 iomatica request messages is also a method for the security education next one slide please a few other updates have been made since i tf-112 first change is to design tracing capabilities objects including a pre-allocated tracing and incremental tracing egress mtu and egress interface id are substituted by ingress mtu and the ingress interface id"
  },
  {
    "startTime": "00:46:02",
    "text": "because icmpv6 echo request is testing the for the responding node itself the last two changes are on pot proof of transit capabilities object and h capabilities object respectively they are aimed to align with the latest iom data draft next slide please the authors believe this chapter is ready for our working group last call so we kind of requested working group chairs to issue working of last call on its jobs that's all thank you all right thank you do we have any um comments questions does anyone in the room have any concerns with going to working group let's call on this relatively soon all right i'm not seeing anyone come into the queue so we can uh the chairs will discuss and then get back to you on that okay thank you thank you tommy thank you all right then next up i believe we have frank"
  },
  {
    "startTime": "00:48:01",
    "text": "covering a couple documents on iom as well or justin oh sorry my bad can you hear me yep all right [Music] it's a little bit quiet for the remote my mic is working actually is this one working that one is better yeah so let's use that one yeah so i'll go first and then frank will provide the update on the deployment draft so about the data integrity um we have clarified the scope of the document so basically now the integrity protection is on iom data fields and not including headers for obvious reasons we have uh shared on the mailing list and as a consequence the algorithms were returned to be more generic and so they work for currently defined iom option types and so for future defining and also as a direct consequence the direct export option type is not included anymore because it doesn't fit because if you see the define the defining of such option type it doesn't contain any ion data field per c okay so if you really want to go that way and have um protection i think um we could have a per hub verification but not sure if you want to go that way so we can just discuss that later on the mailing list and so the update also includes some editorial changes we have used the irm data fields notation that is defined in the iom data"
  },
  {
    "startTime": "00:50:02",
    "text": "draft to keep it consistent and some structure or some section and subsections were restricted also so if you can review it and provide some feedback it would be greatly appreciated and tommy i don't know if you want to take questions now for this draft or if we do it for post after frank sure if there are any questions on this document we can take them now i don't know has any i guess just for myself um forgetting further reviews do we want to ask for any particular external reviews sector reviews etc who are we asking are we asking people inside the working group are we asking people outside yeah i think the main objective was that given that this document is really a document that was inspired by the working group originally right where people said well yeah well even though we're in a limited domain we do want to have a dedicated way to go and ensure integrity above and beyond what you can go and do with the underlying transport if you're riding on on top of say v6 and would be able to use authentication headers and the likes and um so we would really appreciate hearing back from people that well originally driving the the questions uh whether the document in its current shape actually meets what they had in mind i think that's more like what we were asking this this review to be so that we"
  },
  {
    "startTime": "00:52:02",
    "text": "at some point can call the document done and then progress okay i think it's not so much of a of a security review because i think the methods that we are using are well well known and state of the art uh there's nothing really new or inventive here it's more like application appliance well donor to the problem but let's see whether people consider that is well usable useful um in the context of the the original problem that people had in mind got it all right sounds good and yeah just let us know if you want help soliciting feedback all right don't see anyone else in queue so let's move forward yeah the next one is even faster the next one is my bad right um so the document's been pretty stable we've not really heard anything back um and sorry gentlemen i i forgot to add the beer reference or not i didn't forget that the beer reference i forgot to publish the draft um the the o1 version before the cut off so which is why i added the github reference uh i'll i'll push that out today or well if we to get more feedback uh during the week maybe towards the end of the week early next week um if there is more things that people want or have experiences with from an iom deployment perspective that they want to go and see represented in the draft um i want to go and keep it well rolling for a while we could go for last call but i do think that well if we mature it over the course of another two or three itf meetings it might help everybody given that"
  },
  {
    "startTime": "00:54:02",
    "text": "it should go and uh aggregate all deployment experiences that we have at iom and um thanks to justin for coming up with an even more mature implementation uh in the kernel and we also have an update on uh on vpp um so well maybe we we get more experience with even the open source implementations and um we can go and fault that in but for now i've not really heard anything back so keep feedback coming to the list or well the implementers thank you all right thank you any questions on nine minutes back that's fantastic we will take it any day all right thanks so much thank you all right and next we have iom yang i believe all right china do you want to share your slides or do you want help with that could you please help to share okay thanks great and this presentation we will report the major changes since the last meeting next we address the comments from some patch and the requirements of the list firstly we add some detailed parameters like timestamps type and available interface to ion info iom info is a container for all the readable read-only assistant information"
  },
  {
    "startTime": "00:56:00",
    "text": "so so that's monitoring system can interpret the iom data and secondly we aligned with the latest ion data chart on port configuration user needs to augment this module for the configuration of a specific port type and then some uh young module issues we reduced all the prefix yum identifiers add more descriptions and make the draft more readable and updated the security considerations and cleaned some knits and next um the iron with the plain drafts are stable and this young module is already aligned stable and mature so we would like to ask for young doctor review and also working group call any questions comments all right i'm not seeing anyone queue up if we could get in the notes of the request to do to kick off the yang doctor review the chairs can request that yes thanks okay all right if there are no comments or questions on this i think we have a little bit of time back again um thank you and yeah it's good to see this update and get this moving along thank you"
  },
  {
    "startTime": "00:58:00",
    "text": "all right and then next up should have the explicit flow measurements document all right and will that be my representing great okay can you help me yes we can okay i can't see your slides yet okay you have to pick which which deck you like which which deck you need there you go thank you to all start okay okay okay can you resume briefly the topic of this draft the species flow measurement our measurement made using real traffic not artificial traffic we can mark one or two bits or three in some cases or different measurements the measurements that are in the draft are the rounded time a new version of the routing time measurement is the delay beat with the hidden beat option that is an option that permits to"
  },
  {
    "startTime": "01:00:00",
    "text": "save the privacy of the users the round three packet loss one bit that permit to have a new measurement that is a strange because we have a round three packet loss not a unidirectional clause this case we have the measurement of all the packets from one side and a percentage of the package from the side with more packets and the one-way particulars that are made in the best options in our opinion using it to be the square beat is common to the option that we can have before this measurement and two different bits for the second part of the measurement the loss event need the reflection square okay uh the number of uh groups and the companies that works about this top is is incremented from last time because uh the university of technion joined us in this kind of work and in technology if your caller from huawei manage the contact with his institutional research so we are a free university three different research groups that explore this kind of methodology for measurement in the network so this is little bit that is the last addition to the draft as a methodology last update so it is a meeting we don't present the draft updates because we are waiting the very extensive revision that the ike coons from akin university terminate only last thursday"
  },
  {
    "startTime": "01:02:01",
    "text": "and so we are waiting is a revision i thanks ike for his work and the work of his research group in the university because he implemented all the algorithm described in this draft so we have a new implementation totally separate from the others so he tested also the clarity of the description of the algorithm and he suggested some updated uh the main tool is about the tv description the routing packet loss because uh he asked to clarify better the token mechanism that maintains the throughput of the measurement equal in the two directions uh the discussion about the trade-off of the duration of the measurement because if the measurement the period of the measurement is uh longer we have less measurement and is is short we measure less packets for the packet loss so there is a trade-off there is a little bit discussion that is better to describe in the draft there are other minor changes that he requested one about a corner case in the reflection and some editorial changes we introduced this change in next days and we published the draft when reopened the publication this is the summary for the delay beat the bit that are used to measure the delay in the route trip it is the summary of the measurement about the packet loss"
  },
  {
    "startTime": "01:04:01",
    "text": "there are many options it depends from the protocol for example some protocol have only two bits so only one bit can be used for packet loss this is a little bit the problem because with them one bit the measurement are more less precise for the delay one bit is a sufficient because both spin bit and delay beat also in the hidden version needs only one beat with a three bit it's possible to have one bit for loss one bit for delay and two bit for loss this is all the options that we think that are quite interesting so the conclusion is there are quite a big work about this topic there are some sibling draft in the ppm working group one in particular that is about putting the probe not in the network as we thought at the beginning of the work but also in the end user device in order to have an end-to-end measurement in a very simple way also for methodology like a kubit that is not an end-to-end methodology so it's very convenient and it's possible to measure end to end and combining this measurement with probe in the network is possible to split the measurement and to locate the problem if there is other sibling draft are presented in other working group in the co-op working group in particular the last one in the past was present in quick working group and there are one draft also in tcpa proposal so we think that we are quite ready i don't know if you are agree for the"
  },
  {
    "startTime": "01:06:01",
    "text": "working group last call in the end of the presentation there is a summary of uh that is not a summary of all the authors of the working group excuse me of the draft but only our company fabio bulgarella massimo neil and i suggested some possibility in case of the more common protocol for core aap with two beats to use the sb the spin beat for rtt er artifact loss for could beat they could beat a foreign [Music] the preferred option was in our opinion delay beat also in the [Music] hidden beat version but naturally also the spin beat is quite good the delay beat have some advantage as we speak about in the draft for the tcp uh there is in our opinion a little bit difference about the packet loss because for quick we prefer cubit and albeit for tcp cubit and rbit because the albeit is a simple as a simple implementation and there is a less measurement delay their bit detector's losses also for all accurate tcp packets it is a protocol independent so it not depends from the implementation of the protocol so there are strengths and the weakness in the bot but in uh our opinion for quick is better albeit as second was beat 40 cp is better arbit but this is only a personal opinion of a subset of the working group about not working group draft group"
  },
  {
    "startTime": "01:08:00",
    "text": "about this draft thank you there are some questions so we are all right do we have any questions thoughts on this please join the queue not seeing anything immediately um one question i did have on the uh drafts in other working groups and the discussion for how to apply this um i think the one on quick was a while ago and in co-op that just happened is this something that looks like it will get adopted in any of these working groups are we going to see this progress um for great views no no because we decided to start from a ppm also with some materials that are agree with this approach and after we put this idea inside the specific protocol working group for copper the the draft is active we presented in the last interim meeting where people represented is a quite good interest from the working group for quick in particular in past was presented some technologies in particular for packet loss but the the draft don't go didn't go ahead so we start again from the beginning in the methodology group that we think that ppm is the right one to refine the methodologies yeah i'm asking though as we are maturing this and you know i think we could look at doing a last call on it"
  },
  {
    "startTime": "01:10:00",
    "text": "um do do we do we want to essentially publish this without any adopters necessarily um or or if we had some adopter lined up um that was that we thought would come in relatively soon then we could um see if there's any feedback from that protocol or group before we kind of finalize and publish this document but that's not necessary okay we have to present something in other groups so but now we are presenting only in the co-op working group because quick working group i don't know if they are so much interested in the topic till now but we can retry it well maybe what we can do is you know do a last call get the feedback here but then once that has wrapped up at least send a note too quick to say hey if you remember this from before we have some updates um did we have someone in queue for a moment okay all right that sounds good thank you thank you to all right i believe we have one last working group document presentation on srpm rawkish do you want to share your slides or do you want help doing that let me see if i can do it um there we go"
  },
  {
    "startTime": "01:12:18",
    "text": "you see slides i'm setting we can see them okay perfect uh hi everyone uh my name is rakesh gandhi and i'm presenting the stem extensions for sr networks recent updates to this drop on behalf of the authors listed here so the agenda just updates that we made in the reason 003 recently the stamp based work that we're doing in other working groups we just flash it and the next steps so uh in the recent revision um we have updated the usage of deflect around destination flag uh the wrong the decision with a reply required or not required so there is either zero or one uh we added a sub dlv for srv6 uh it's a structure sub tlv and some small minor editorial changes and we have no open issues currently so the structure srv6 uh um segments tlv basically identifies the structure of the 128-bit srv6 seat so 128 bits some bits can be for the node uh some for the function length and some uh for the uh so it just identifies that this is in line with uh other uh drops and repsis for a srv6"
  },
  {
    "startTime": "01:14:02",
    "text": "so uh there is some work going on as well another working group uh the ippm has done a great job with coming up with stamp and there are some extensions uh there's some work in spring uh there is also some enhanced srpm draft as well in spring as well as for the work for pseudowire extension in mpls working group so we'll uh appreciate your uh review comments so uh there is some inter interest to do the interrupt testing for the extension in this trap so uh we are interested in uh early in the components um so we'd like to make a request for that um welcome your comments and suggestion on the drought and that's all i have any comments questions uh jermaine go ahead can you go to uh wi-fi can we hear you hi do you hear me yep yes yes please go to slide 5. i think the second document is not ietf document it's a individual document right ah yes yeah there is a typo sorry all right um"
  },
  {
    "startTime": "01:16:01",
    "text": "rockish for the ayanna assignment can you send a a note to the chairs an email to the chairs about that or on the list yeah i'll do that great okay seems like we don't have any more comments or questions on this right now thank you okay and at that point i believe we are ready to move on to some of our proposed work we're a little bit ahead of time so that's good and first up i believe we should have nalini it's a it's a it's pretty quiet oh grab the other mic okay thank you uh yeah just speak up um do you want me to share the slides okay okay so thank you okay so i'm talking about pdm v2 so um we are on the o2 draft next slide please so we first presented it in itf 111 had a side meeting we explained the concept over there then we presented it at 112 in the ippm working group and had a side meeting where we explained"
  },
  {
    "startTime": "01:18:00",
    "text": "our linux implementation and how it's working recently we have been working on the lightweight registration protocol which um it is a sample protocol along with pdmv2 where we try to authenticate authorize and generate a shared context for well with the the primary secret basically so uh that's what we have been working on today morning we had another side meeting where we showed the recent progress in registration protocol and yesterday we had we got a chance to present it at the hackathon as well next slide please so this is the summary of the registration protocol we have a primary client primary server secondary client secondary server architecture and yeah the draft mentions a rational for it this is a summary mentioned in our appendix we give one possible way of registration protocol and we keep the option open to enterprises to either use this or have their own registration protocol so well um there is a flow between primary client and the primary server where well this is this is the starting step where which we call it a setup step where we try to negotiate the cipher suite a common cipher suite and in return the primary server will respond with the cipher suite and also share its public key"
  },
  {
    "startTime": "01:20:02",
    "text": "then uh this is the hpk chem key encapsulation mechanism where we do the chem and share the encapsulation and the primary server will basically do a decap and generate the same secret on its side after this step we have a common shared context on both the sites and the secret can be used to encrypt the medium extension header well this secret is later shared with um with the secondary server and the secondary clients we had received some comments in the side meetings with sharing the secret with the secondary clients and we had taken care of it by generating client specific keys so what primary client does is it generates generates the client specifically plea please please keep the mic up your mouse so um what the primary client does is it generates the client specific keys by doing a kdf with the info parameter as the client ip and generates a specific client uh generate the specific secondary client keys and for sharing all these keys we are using tls uh as a means so yeah this is a registration protocol which we have added in the draft as of now and um yesterday in the hackathon we were discussing on how to add authentication and authorization and we had a brief implementation of that as well uh today we'll be presenting it at the hack demo"
  },
  {
    "startTime": "01:22:01",
    "text": "so yeah next slide yeah so we would like to ask for working rook adoption on this any questions all right thank you for the presentation um just thank you for the question on my end actually um just you know since we're not there in person i'm other person right now for the side meetings in the hackathon how many people are you having at the side meetings and the hackathon projects how many people are engaged on this right now let me let me help you guys maybe we have um our team here maybe you can you guys can all raise your hands we have we have um tomaso who's a cryptographer from university of florence and then we have mike ackerman who is an enterprise who's been involved with us all along um and so uh i think at the at the hackathon um there were what maybe i think there were 50 60 people uh at the at the hackathon itself that we presented to and i think at this side meeting it was a little early in the morning so we we had a little less attendance than we would have wanted but the other side meetings i think in the first one we had at least oh i will say 30 40 people second one maybe i think 20 including some uh"
  },
  {
    "startTime": "01:24:02",
    "text": "very good cryptographers because that's what we were concerned with um is uh the the you know this is sensitive information uh and mike i don't know if you want to come up and talk about the enterprise um uh use of this oh you're in the queue already using you all right come on up mike uh i'm mike ackerman i'm with a large enterprise and we're excited about the information that i that pdm can provide for enterprises and anybody else that are going to be managing their ipv6 networks in the future um we also recognize that there'll be situations where this information needs to be encrypted in the ehs that it's residing in so that's where pdmv2 comes into play so we're excited about both these developments and i'm going to add one more thing this is a personal thought i think that when we enterprises finally do get ipv6 networks which we're dragging our heels on terribly on right now that we will have other pieces of information in other extension headers and i would not like to see a different solution for each one of those that we're going to deploy in the future so those are my three points and we're excited about this development i hope it can continue yeah thank you so much mike and one thing i know that i'm going to just put a boost out mike and i have been working with a lot of the federal government in the united states to help them do their ipv6 address planning because ipv6 planning at enterprises has lagged a great deal and uh and we're hoping actually to get some of these federal agencies to talk next time but we're"
  },
  {
    "startTime": "01:26:00",
    "text": "working with at least uh three different agencies uh these are like you know i mean if i if i gave you the three letter acronyms you would recognize all of them some of them worldwide and i know they will need this so yeah great al is in queue you wanna join thank you tom uh thanks uh uh nelly and mike and your team for this um it it seems to me that you guys are extremely lucky to get the original pdm uh through the ietf and approval without encryption uh just good timing i guess and and uh you know in today's environment it makes a lot more sense to have an encrypted version of it so uh just uh offering my um support for this direction draft a long time ago um you know i i i appreciate that they've got a lot of work to do here and it should be interesting to see it complete thanks thank you so much al all right and martin martin duke google no hats on um yeah like encryption's good so thank you um uh if we do adopt this i think it'd be good to get really early sec area review of this um i don't know i mean you've mentioned some cryptographers a bunch i don't know who those people are but we should probably run this through suck area sooner rather than later absolutely absolutely yeah great um that sounds good i was thinking the same thing that it would be something good to adopt and then get a very early sector review uh the the use of hpke i think it's you know the the right thing to do here um but having more eyes on it it's always a"
  },
  {
    "startTime": "01:28:01",
    "text": "good idea all right thank you so much for this presentation thank you so much okay and next up we have greg with a couple documents greg do you want to oh if you hear yourself oh much appreciated okay let me pull those up all right so we have a 15-minute slot but we're going to go through two documents here yes thank you so uh let's first start with the hybrid two-step uh collection and transport method and uh next slide please so uh what is their goal of this protocol it's a method to collect and transport on path telemetry information it can equally be used in a point-to-point or point-to-multi-point cases and the point of multi-point cases is a tricky one because as you understand the replication of packets if packet includes telemetry information inherently leads to replication of upstream collected telemetry uh in some environments that uh is not a big concern but some networks are especially for the services that a premium service and use um guarantees uh for like out reliable low latency services that that becomes challenging by separating uh the moment of uh originating on generating telemetry"
  },
  {
    "startTime": "01:30:01",
    "text": "information from the collection in transport we can achieve more accurate measurements it's a known fact that getting the timestamp is recommended at the moment of the physical start of the transmitting packet to minimize the variable delay but especially in ap and ipv6 environment the packet checksum needs to be recalculated once we change the content once we write the time step time value so the separation is a good technique to improve the accuracy of the measurement also uh with the hybrid two step uh we can uh we are removing the limits of a mountain information that can be collected for the monitored flow so we know that even if um the network uses a jumper frames that still has put some limits um on the amount of information that can be carried uh embedded into this uh trigger packet and uh also because this is a separate mechanism and the packets are not the data packets the integrity protection can be applied uh to this information and without affecting the accuracy of the measurement because again if we take a measurement and then we apply integrity protection then it reduces variable delay next slide please so we use specif especially constructed messages that follow their trigger packet in a data flow"
  },
  {
    "startTime": "01:32:01",
    "text": "another advantage of what can be seen as advantage of this method is that the collection can be done out of band so which means that it follows their topological path but uses a different uh class of service so not to use the same bandwidth allocated for the data flow that is monitored and again in many uh environments in many cases that would be advantageous because uh it would not use their premium bandwidth next slide please so this is their outline of their uh follow-up packet we had discussions and we added some fields for ease of parsing and uh it's expected that it's processed at their same notes that are generating information and each node when it receives the trigger packet originates information and holds it for uh according to the local policy for the follow-up package uh one of their options that uh it gives us is that we can export raw measurements for each trigger packet or measurements can be statistically processed locally and then collected using their uh follow-up packet next slide please uh as mentioned so uh we can authenticate uh their information collected on each node individually next slide"
  },
  {
    "startTime": "01:34:02",
    "text": "hybrid two step can be used as i uh with iem as another um trace option and so we are proposing to allocate our appropriate uh flight uh flag so that uh intelligent data profile field next slide please so this is a graphical representation of the protocol we identify the trigger packet their transit ingress node originates the follow-up packet and then each transit node adds more information if the mtu is about to be exceeded then it uses their encapsulation of preceding follow-up packet and starts uh additional generates additional packet so and then they arrive at the egress node next slide so that was uh the case of for point to point and this diagram reflects the theory of operation for point to multipoint and so because uh we identify the flow we don't have to copy the packets and uh they're replication node only generates a new follow-up packet that collects uh telemetry information on downstream of their uh multicast tree slide please and this is very interesting uh mode"
  },
  {
    "startTime": "01:36:02",
    "text": "that was suggested by pascal so that it works upstream and their follow-up packet is uh generated by egress node of their um for the flow and then as uh sent um in return path tracing the same path of the monitored flow to the ingress so which might be useful for cases when the ingress node needs to be aware of the performance and uh can influence uh the network by selecting certain uh scenarios one of the possible scenario was the wireless um so it's a discussion in a real reliable wireless communication um i think the next slide so uh we welcome comments and uh will appreciate the consideration of the working group adoption all right thank you any questions comments support for doing this and people can please also send feedback to the list okay so let's go next presentation we find those okay so precision availability metrics for um slo govern end-to-end services or services that have multiple slos next slide please"
  },
  {
    "startTime": "01:38:01",
    "text": "this is not really a new document as you see so this is a merge of two documents that uh we've discussed in the course of several um meetings next slide please and so what is the uh precision availability metrics uh it expresses availability of the service uh relative to uh the requirements that are expressed in slo and as low as being the measurable performance that characterizes the service and usually it might have um as an optimum performance that is requested and a critical level that um needs to be maintained so the um pam or precision availability metrics can be used to determine the degree of compliance which is the service is delivered um versus their uh contract between their operator and the client it also can provide the service according to slo whether it's uh for accounting and of course it's a billing or continuously monitor the quality with which the service is delivered so what we include what we propose to include in this metrics next slide please so uh their key element is their time unit or pam interval um and then we differentiate the error interval the interval uh when their uh metrics um exceeds the optimal thresholds predefined and error-free interval uh when their"
  },
  {
    "startTime": "01:40:02",
    "text": "performance is below optimal uh or better not below but below the threshold so not exceeding their optimal uh thresholds and there is no uh defect being detected uh the time interval could be one second or one millisecond uh with uh error um error interval uh we can um identify the severely errored interval so and define it would be proposed to define it as an interval uh where their uh performance uh net metric exceeded um critical level previously predefined or uh defect was detected you can notice that a severely arrowed interval is a subset of error interval um so um then uh based on these definitions uh we can introduce uh basic metrics such as uh error interval count error free interval count and severely error count so the violated packet can be counted by intervals over more meaningful and that leads us to the definition of availability so if we can go to the next slide please based on counts we can go to the timing so the time since the last errored interval and uh mean time between and the number of packet since and mean number of packets and analogous for the severe errant interval"
  },
  {
    "startTime": "01:42:00",
    "text": "next slide please so uh lengthy disruption can give us the state if we have consecutive uh severe error interval we can define this uh state as unavailability and then an availability state uh begins with the start of the first of uh 10 consecutive states uh similarly if we have 10 consecutive states of non-ce so which is an error-free or error interval and that qualify then we can say that we have a service availability state also we can calculate the ratio ratio of error availability intervals and severe error intervals next slide please uh so we identified uh the items for further discussion and future work that will be outside of the scope of this draft and we welcome our inputs and contributions and collaboration next slide please so welcome comments discussion and uh we think that as a merge of the work that's been discussed uh we would like ask the chairs to consider working group adoption all right thank you um and thank you for your work on merging this i think that's become more clear certainly as part of that do we have any quick questions from this group don't say anyone in the queue"
  },
  {
    "startTime": "01:44:08",
    "text": "all right thank you greg for both of those presentations and thank you again if you have comments or thoughts please uh bring those to the mailing list thank you all right then next up we have the uh ot ramp on lag documents and i will present this okay thank you okay i will start this topic we talk about performance standard extensions and next [Music] lag provides to pull physical links into a single logical link uh you should sorry general your your microphone was cutting out a little bit if you could start again usually i'm not i'm not hearing your audio coming through now let's let's try that again all right china do you want to uh try to send audio again or if you're not able to if you could drop a note in the chat oh here we go"
  },
  {
    "startTime": "01:46:12",
    "text": "i'm not able to hear you currently i don't know if anyone else is you cannot hear it it's not only you right so we can't hear genre okay great great okay [Music] all right um maybe let's switch over to oh yes now i can hear you can i try again okay it sounds like we're having issues um let frank let's switch over to your documents if that's okay let me approve that there you go yeah so let me see when i can find the deck all right so this is not my document this is about trying to understand whether we want to go and progress that work or not it's been it had a it had its hype and then it went a little stale because people were waiting for the data graph to mature uh we have the data draft and the rfc editor queue right now and we have two documents that people felt are important prior and i want to go and understand whether we want to go and progress them or just kind of sunset them the first one is on using either type a protocol and identification to carry iom data and that is largely for protocols like gre or we can use that for geneva as"
  },
  {
    "startTime": "01:48:02",
    "text": "well the second document is for raw export of iom data take the the ium data blob and export it using a fix very simple method to go and at least have one standard means to go and get the data out um so the two drafts are old mature both of them started in in 2018 and they've been tagging along um they expired at some point and i kind of refreshed them just recently um first one is raw export um it as i said it just takes the the iom blob encapsulates that into ipfix and then ships it off um there's a few nuances that are being added a few new data fields um we would not even need to go and uh do an rfc for that in order to go and get the additional code points but i think it's better if we do it that way because that means people are um aware of it and it's it's well documented how they want to go and be done the second thing is a draft that brian weiss wrote originally a couple of protocols use an either type to identify a particular header geneva's one gre is another example and that can be used to carry iom data fields and people felt like this is a simple way at least to go and get um v4 support for for iom using a gre header um if we want to go and get um the work progressed um on both ends i think yeah well we can need to go and decide on whether we want to have a simple means to go and export iom data um using ipfix um mickey spiegelstraf would be a green"
  },
  {
    "startTime": "01:50:00",
    "text": "option for that i've not really seen anything else i know that there is a load of proprietary versions coming up right now so having one standard version i would see as beneficial but that would require other people to be interested in it and the same goes for brian's draft i've seen people wanted to use iom with v4 and gre i think is the the only way to go and do it in a standard conformant way if we want jre we need an either type and if we want an either type we at least need the document to be working group adopted and matured so that based on that the isg could formally apply with ieee for an either time so i think the question is really here adopt or sunset for both of them and i would appreciate your feedback all right we have our area directory in the queue martin duke google um can you explain the difference in the use case between rock sport and direct export so raw export just tells or is a way to go and get the iom data shipped using ipfix so it's it's the ipfix kind of wrapping or the additional data fields that you need in ipfix the code points to go and ship the data direct export is iom information or flags that tell a node to go and extract the data and then eventually ship it how it's been shipped direct export doesn't tell you right so direct export is about flags and iuem on the wire that tell a node what to do um raw export is what rapper you want to go well some means in ipfix to go and get us a quote"
  },
  {
    "startTime": "01:52:00",
    "text": "standardized effort to go and get data off the note okay so they're complimentary thank you all right so i can go and send the question one more time to list and um we can go decide accordingly like as i said i'm not the the author of those two drafts but i do see value but i'm the only one that doesn't make sense right um i guess as a follow-on to that frank do you know if those authors are willing to carry on their work are they still willing to drive that yeah i think um at least from from brian i know that he retired at some point i'm not sure and uh well with mickey i picked him but uh he probably moved on to other topics of given that he switched companies and the likes right yeah okay so yeah let's raise this on the list but it does seem like we would need both interest in someone to yeah and i heard feedback off off list uh from from a launch last large service provider in the in in europe that had its interest in the in at least the raw export work so maybe we can have other people speak up there i'll i'll raise it on the list thank you all right thank you frank all right uh chandran are we able to hear your audio now you want to try talking again can you hear me thank you that's great um that's too quick this topic we talk about performance management on a lab including two drops for stamp at the tm extensions lag provides multiples to combine multiple physical links into a single logical link"
  },
  {
    "startTime": "01:54:00",
    "text": "usually when forwarding traffic over lag the hash based motion is used to load balance the traffic across the member links link delay of each member links varies because of different transport paths to provide low latency service for time sensitive traffic we need to leastly steer the traffic across the lag member links based on the link delay loss and so on that requires a solution to measure the performance metrics of every member link of lag existing active pm methods around a single test session over the aggregation without the knowledge of each member link this will make it impossible to measure the performance of a given physical member link the measured traffic management metrics can only reflect the performance of one member link or an average of all the member lengths of the lag to solve this we followed the similar idea of rfc 71 and 30 the bfd on that next please and to measure the performance matrix of every member link of a lag not multiple sections need to be established between the two endpoints that are connected by the lab these sessions are called micro sessions the micro sessions need to associate with the corresponding member links for example when the reflector receives a test packet it needs to know from which member link the packet is"
  },
  {
    "startTime": "01:56:00",
    "text": "received and correlated with a micro session so we extend a new new command type to indicate the set of micro sections of a lag and use identifiers to correlate the test packet to a particular micro session and carry the member link information for a validity check next this shows the omp and the tvamp extensions including control message and the test packet we add two new uh control messages the request the om micro sessions and the requested tv micro sessions and in the test packet we add sender micro session id and the reflector micro section id both ids are locally assigned [Music] next and this shows the location of sender micro session id and reflectors micro session id in the authenticated mode and next stamp do not have a control plan so only need to extend the test packet stamp trv mechanism extender stamp tester packets with one or more optional tlvs so we proposed a micro session idtlv like this and next there are many suggestions in the mailing list we all adjusted them in the latest version and next"
  },
  {
    "startTime": "01:58:04",
    "text": "so more comments are welcome and we believe both drafts are mature to be adopted by the working group thanks okay thank you um any questions comments support please get in the queue if you have thoughts on this okay sounds like we can probably take it back to the list but uh thank you for this update thank you all right and with that we are at the end of our agenda so thank you all i think we got through a lot of good good progress on this um thanks to all the authors um marcus anything from your end comments no thanks everyone great oh and thank you to stewart for taking the notes much appreciated all right great well have a great itf week everyone whether you are in vienna or virtual take care"
  },
  {
    "startTime": "02:00:08",
    "text": "um"
  }
]
