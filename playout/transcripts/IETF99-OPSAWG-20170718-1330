[
  {
    "startTime": "00:00:23",
    "text": "for the so hello everyone we\u0027ll be starting in about a minute because people are still walking in so walk faster ok so hello everyone welcome to the joint ops area an ops AWG meeting hopefully you\u0027re intending to be at the ops area not zwg meeting if not leave now or forever hold your peace so welcome to ops area I\u0027m Warren this is Benoit we have a note well which I\u0027ll be displaying soon that\u0027s the note well please make sure that you note it well this has important legal stuff on it I\u0027m not gonna try and interpret that for you "
  },
  {
    "startTime": "00:03:23",
    "text": "you should go talk to your company attorney or lawyer or rabbi or whatever can we go back to the agenda a thing so this is the ops area agenda part of the meeting if there\u0027s any agenda bashing please let\u0027s bash it now also there are blue sheets we will be circulating those they are circulating please make sure you put your name on them otherwise you will get a smaller room next time what are we forgetting Java scrapes and we have the Canasta next to you how thing with plantation thank you we have job scribes we have a JavaScript Thank You Joel and who is going to do minutes and who is going to do minutes and thank you for volunteering Wes thank you and will you do them for both parts of it or just both the ops area and ops Avery teapot thank you very much I\u0027ll give you some candy at the end of the meeting and I think that that\u0027s all of the boring administrivia out of the way and with that we will hop into our first presentation which will be Jo this one please stand in the pink box test test but hi my name is Joe Clark I\u0027m with Cisco and today I\u0027m gonna talk about the yang catalog which I\u0027m sure many of you have heard if you\u0027ve been in other meetings such as Netcom Frenette mod or heard Benoit talk in the past month or a year ultimately what is this about there we\u0027re approaching this point where we\u0027ve got a fairly good problem to be had yang is proliferating we have a number of yang modules being created not just in net mod not just in net comic not just in hops but across the IETF and across standards development organizations and across vendors we have a number of people working on yang models and implementing these yang models that is vendors putting them in their products and customers starting to consume them customers of those vendors starting to consume them but that does beg a question is it sufficient enough just to have a yang model written just to have something model in Yang and then and then once you have that module to that model written is it sufficient enough to implement it I say okay we\u0027re done we we\u0027ve got it on "
  },
  {
    "startTime": "00:06:24",
    "text": "our devices there have at it what we\u0027ve been seeing is in general this is even though it\u0027s been going on for a while consumers need help in order to better adopt this new way of thinking about network management of thinking about configuration of thinking about operational state we need to develop a set of tools a set of visibility into these yang modules that can help the consumers that can help new and experienced model developers and can help organizations working with yang models understand how what is available how to learn from best practices that others have done and then where there where models can be used and found in the products or devices or service controller architecture to buy a controller architecture elements that these consumers are using to that end we have stood up this thing we call the yang catalog at HTTP yang catalog org we\u0027ve started to accumulate these open tools in order to help those parties the module the modular to the module developers the stos the consumers and the vendors we want them to understand the models out there we want them to understand how to learn how to dissect these models understand what people have already done leading up to today so that their people aren\u0027t reinventing the wheel and understand where they can use a yang model in what vendors products more specifically the tools we\u0027ve created our around first a keyword search so for example you want to be able to find a yang model that matches a specific keyword or a mod a node within a yang model that matches a specific keyword for example a type def for ether type or mac address already got a question with Wes yeah so one real quick clarification you say we have stood up who is we ah question is we who is we um we right now initially this was Benoit and myself stood this up I mean physically stood up the the virtual machine that is the server we\u0027ve now and I\u0027m going to get to that point in a little bit reached out to a number of vendors a number of different stos and other interested parties to contribute to this so while initially the tools were put up by some of the validation work that Benoit was doing some of the the search the search functionality that I built we now have other tools developed by a number of people from Cisco we now have contributions from the BBF broadband forum we have vendors contributing metadata around their models from Huawei we expect to see juniper there soon as well as the M EF is also just recently "
  },
  {
    "startTime": "00:09:26",
    "text": "contributed some models so the point being we want this to be open we want multiple vendors we want multiple SDOs to be able to come here and contribute and because everything we\u0027re putting up here is open-source we\u0027re saying anyone who wants to help code this anyone helped wants to help contribute by all means come and do this in addition to the search we have the ability to look at a module impact analysis we\u0027ll look at all of these in a little bit we can do a yang model validation across a number of a number of validators within the industry like yang yang lint this can help module developers understand exactly how well their models do or fair with varying degrees of conformance most recently and part of the hackathon we have a validator for yang Yang compatible regular expressions and we\u0027re looking to do more with yang model exploration and by that I mean take a hierarchical or tree view of a yang model be able to adjust some of the values there and be able to generate things like our pcs or the the yang development kit our open source package be able to develop direct Python code to go in manipulate yang model data on devices and finally we want to do what we call a yang implementation discovery which is across all vendors be able to find out what yang models are supported at what levels in what vendors products and with what software releases in order to facilitate much of this we need a bunch of metadata metadata about modules metadata about the implementations of these modules we then raw myself and some other developers have stood up a rest like API in order to push that information and as I mentioned we already have the BBF M EF a Huawei has contributed or pushed their metadata up and arrests alike API to be able to pull this metadata back down digging a little bit deeper into the yang search just to give you a quick overview as I mentioned if you\u0027re looking for something like a specific type death you want to see if someone is implemented a type death like this before and what they\u0027ve done maybe how mature that implementation is you can use the yang search to do that and there\u0027s a number of different options you can see here that allows you to be able to get a fine-grain result of what you\u0027re looking for we met with the I Triple E this week and one of the things that they commented on was they found some old revisions in the search results old module revisions thus translating into older node revisions and they said we don\u0027t like that the yang catalog is trying to catalog "
  },
  {
    "startTime": "00:12:26",
    "text": "everything and and move forward over time as modules develop we will collect new metadata so we added just recently as part of the hackathon the ability to only show the latest revision of the latest revision per module from a search results standpoint this can be very useful both for people looking for a node looking for something that they might want to manipulate on their device as well as those yang model authors in this case you can say I\u0027m looking for something called you are I I want to know where it\u0027s been defined where it\u0027s probably most trusted meaning is it a standard is its maturity level a standard how many other modules are using this and by using the search they can do that in fact I saw an email today on the net mod list where our BBF colleague had made use of this to be able to identify as an ether type or ether - type that\u0027s more prominently used so there are a number of different use cases one can use for the search and in addition to just showing you the the search results you can drill in to get a a quick overview of the node details and launch out to the impact analysis for a given module our ops ad benoit has been quite successful at using the impact analysis to help drive module of progression through the IETF and through some other standards bodies the impact analysis shows you for a given module or given target module or target modules how many other modules are affected by this and how many other modules affected this module and by doing so we can identify bottlenecks that is we can identify if there is a draft that needs to progress in order to get the target module further progressed as well meaning towards a ratification or standardization so this can be a very nice visual way of being able to do that we also have the ability because we\u0027re running these modules through validation to spot modules that do not compile and make authors aware of that so that they can work on fixing those with respect to their standards development organization so that they do compile and they do validate the other major piece of this as I mentioned is this API in order to get a lot of what you saw here like maturity like the document from which a module is extracted especially in order to get where a model might be implemented in what vendors device and in what software release we need to be able to collect metadata there are many things that we can extract directly from and we do but there are other things that cannot be extracted and that\u0027s why this metadata is important so we\u0027ve stood up a page that explains how one being an sto or a vendor could contribute to this so if you are a model author being a vendor model author or an "
  },
  {
    "startTime": "00:15:26",
    "text": "sto model author you can push metadata about your individual modules and will catalog that and if you\u0027re a vendor who has implementation detail same thing you can push that via a REST API and we will add into our into our API tree where your models are implemented and at what conformance level with what deviations from a model metadata structure we\u0027ve actually modeled the API and yang that mantra using the word model a lot but that model is up there as well and this is the tree view of it again highlighting those fields that are mostly non extractable same thing for vendor implementation vendor implementation metadata of models and one thing I want to point out here is that we are evolving this constantly based on feedback we got some great feedback at hackathon 99 and we\u0027re going to continue to iterate this add new Leafs new nodes so that we can get the right amount of data out of yang modules and make the catalog as useful as possible in order to retrieve metadata again we have a REST API for that we can for example find out just metadata about a specific model say I want to know where a revision of the IETF interfaces tell me a little bit about it from a metadata perspective and then show me where it was implemented and this is an example of that we were able to see this particular model implemented in a few vendors devices we can also walk this from the other angle meaning if I know a vendor I know a platform I know a software release show me all the models implemented by that vendor platform and software release so there\u0027s the two use cases we\u0027ve identified thus far allow us to take approach this tree in two different ways in order to get the information we want and we fully realized that our probably going to be other use cases that come up out of this and we are going to want to adapt and that\u0027s why we say this this approach this a way of collecting this metadata and the metadata that we collect were likely evolved over time I mentioned that one of the things that came out of this hackathon was a regex validator so we had a very interested participant who actually worked from remote that was able to stand up a ganger yang re and the w3c gret a web-based front-end of that now standing off yang catalog so that model developers can test to make sure their regular expressions conform to the xst syntax within yang models so that they they absolutely are sure that their regular expression is going to validate and also is going to match the intended pattern they want and again we\u0027ve already gotten some feedback on this and we expect more features and especially some more help text to be added to this "
  },
  {
    "startTime": "00:18:27",
    "text": "tool as it progresses in terms of results overall results and next steps Wes raised the question of who is we this again touches on the people or the groups who have already contributed to some of this part of this work has spawned a draft that will be presented tomorrow I believe in net mod that is draft clock law for Clarke plays on the overall catalog the model we are using to hold all of the metadata that describes the modules and their vendor implementations as I mentioned when I open this if you probably heard been while talk in the last year you\u0027ve probably heard a little bit about this it\u0027s that evangelization it\u0027s talking to customers talking to stos talking to vendors to get them to contribute to this so that we can proliferate and make make it easier to consume yang models even though we we have a draft submitted the claw claw draft we realize that that too will probably not ever move directly towards standardization it\u0027s something that\u0027s going to be constantly changing as we learn new things and we want to be very transparent with the work we\u0027re doing so that we\u0027ve we\u0027ve submitted it to show that hey this is what we\u0027re doing and we expect that model to grow as we learn new things as we hear new feedback I did mention the italicized things on that belief slide slide 4 we want to do more with respect to yang Discovery to help people generate our pcs or restaurant operations or even generate code directly from yang catalog tools and we want to be able to implement a GUI a web-based front-end around that implementation discovery so those are some of the the next items that we\u0027re we have planned for the yang catalog and so far we\u0027ve it\u0027s been somewhat successful and when I see people use it when I see Benoit advertise this out in terms of helping to get models in the ITF further towards standardization it shows that there\u0027s certainly some need for this and the fact that we\u0027ve opened it up as much as we can hopefully will entice the community to be able to contribute to it offer feedback and help make this a a better set of tools that ultimately helps everyone do better with yang models what questions do you have Kent Watson Juniper Networks not so much a question as a comment I like where this is going I especially look forward to the ability for some of the modules service level modules and then Native models and that there\u0027d be maybe translators converters between the two and who is providing these translators what language they\u0027re in I\u0027m not sure but I think a big interesting "
  },
  {
    "startTime": "00:21:27",
    "text": "development to have the ability for you know the the various stakeholders you discussed being able to identify you know okay yes I want this service level model but I have it get down to the device my own you know it might be a commercial tool and GPL open-source that\u0027s a good thing thanks for that Andy Berman I was still not seeing the level of organization what I called yang packages a while back because yang modules the granularity is is difficult to work with and it\u0027s only gonna get worse okay so you probably familiar with diem TF redfish they they have just released their schema package 1.0 and and what that means is here\u0027s a whole bunch of modules that we have verified and claimed work together and they that and they are meant to be used as as a group on one obvious being package could be routing routing as being split up into many many modules and and I\u0027m just can you know concerned that from the high-level view from consumers they\u0027re not wanting to look at a thousand and 24 separate modules maybe they\u0027re there they\u0027re wanting to look what do you have routing what do you have for accounting what do you have for this another project that\u0027s out there that\u0027s been doing great work you can probably know about yocto bitbake in the openembedded project openembedded is taking on a problem that\u0027s three orders of magnitude harder than this and doing a pretty good job of organizing it into layers and recipes and things that are manageable to make to make things work together so I would like to see that next step of bundling things into packages we know this the set of modules works for routing this is what we\u0027re claiming you should do for routing that sort of thing very specifically on that we had discussed the idea or or adding the yang bundles or that type of thing routing is probably a great example of that that is down the road we have to tackle some things first but in fact at the hackathon it was brought up you should be able to say I want to generate a debian package for this or an RPM package for this I don\u0027t know that we want to be the clearinghouse for for downloading models but I do like the idea of being able to show the bundle these like this logical bundle of models is expected to work together for this higher-level type operation or a task packaging literally like rpm or Debbie and I just maybe the support choice of terms actually I was on mid beliefs its Cisco for ten years and one of the biggest issues was getting "
  },
  {
    "startTime": "00:24:27",
    "text": "developers to know what they can reuse yep and so the so the you\u0027re doing the right thing the first step of really trying to tackle that and and you\u0027d be surprised that how many people don\u0027t know that even in their own company that modules like this III remember you admit police and and I yes for nineteen years I\u0027ve been with SNMP at Cisco\u0027s hi I get that and no I I knew you weren\u0027t talking necessarily about rpms but we don\u0027t want to be that Clearinghouse we do want to offer that kind of logical bundle notion and I want to add something to that this has been more speaking so yes we start to understand at having modules only it\u0027s just not gonna need to have the metadata the tooling and next step is that the packages as you mentioned that at least the bundle we started from the open config catalog draft and realize it was not doing what you wanted it\u0027s one of the field which is in the open config draft the what Joe mentioned there is what we\u0027ve been implementing so far right so and that will progress so the burden yes another way of looking the bundle is the three type right we\u0027ve been discussing nmda and open configured see it it will be there pretty soon so I don\u0027t know another way to look at that a bundle and the last thing I want to say is that at the hackathon we\u0027ve been there since day one with all these tools right maybe ten hackathon so far so you are very welcome to come but you are also working on this in-between hackathon with a spark room was maybe ten or fifteen people now helping on a regular basis so a lot of great to request but feel free to help any other questions and this will be which will be during the bits and bytes we will be there to show you if you want to see some details thank you very much so the next one is for me is on semantic versioning the structure of ITF spect and how I believe the ITF should be evolving and that\u0027s that will build on what we learned from the first session which is very good part of it will be done by Richard over there I just want to say hi because I thought you were kind of sleeping so it\u0027s in your time so the background during the ihe retreat I spoke me before one hour on the latest trends on you know data modelling driven management and what\u0027s happening with yang and mat comp and rest company industry right industry but also in the ITF so I kind of did that along the different ITF "
  },
  {
    "startTime": "00:27:28",
    "text": "meetings here so there is nothing like really new but out of this came like I want to extract a couple of slides from that session and then I want to draw the conclusions and the conclusions from the retreat so yeah going to be quick right we\u0027ve got the growing number of yang models in the ITF fine we know that you\u0027ve seen that type of slides for many times now well actually at some point in time we were turning the revered tsunami of yang models right and people were kind of laughing yeah but now what\u0027s happening we have that in the ITF open config at sea cable up site EU broadband forum open rod mc3 podium TF I\u0027m missing some right so yes yang is over the place it makes sense because me to automate networks these days right now we could segment this between network elements and services it\u0027s almost the same picture but I want to say it\u0027s not only to manage devices right we go up to the layers with that with services again being quick here because you probably you know all of this now I\u0027ve been collecting as you know all the animals I know and validate this that\u0027s how we started with the first hackathon now if you don\u0027t read that if you don\u0027t look at a slide try to guess how many I have and directly I see people looking the slides that\u0027s funny try to guess on money I have in my virtual machine right now if I did you placate them almost mm right mm yang models in the industry so we start to have like a good problem but it\u0027s a problem which is like way bigger than the ITF this was one of the message that Joe was trying to relay was the catalog right it\u0027s not as simple simply a service for the ITF but for the industry and there\u0027s a lot of kind of duplicate yang models there now we could say good brim to have it\u0027s a success and I\u0027m thinking maybe slightly differently we could say yes we move from MIPS to data modeling River management success good we can automate networking now great ITF we did the protocols we\u0027ve got the spec for not count and restaurant success we\u0027ve got multiple encodings with JSON XML success right but on the data model part of it this is where we need coronation i\u0027ve been dreaming for some time that my chart that shows the number of the RFC based yang model would see the hockey stick curve in the ITF we still don\u0027t see that maybe now this is the syndrome of trying to do the best model day one right which I believe is a dream but okay so the point is that we "
  },
  {
    "startTime": "00:30:31",
    "text": "don\u0027t produce those model fast enough now I\u0027ve been mentioning just to reply to you to Andy that automation is as good as your data models you\u0027re too changed and all the metadata next being the bundle which is going to meet just one of the metadata now in the hackathon we developed all this and just spoke about it right now what are we asking out of the different SDO and the vendor we asked them can you please put all your models into github right we will pick them from github we\u0027re going to extract the metadata I can extract we\u0027re going to generate some of them like the computation result and then you have to give up the extra set that we can\u0027t get by ourself like whenever BBF tells us the maturity level of specific documents and then we\u0027re thinking right so we\u0027re asking all these SDOs and again with the I Triple E due this weekend and they\u0027re doing it right they\u0027re putting their models in in github so what do we do in the ITF right and this is where I\u0027ve got like a small concern how do we deal with young models in the ITF you know to produce all the reports on our and you\u0027ve seen if you\u0027ve been dealing with young model unless it\u0027s a perfect one and you\u0027ve got no relation issues I guess that you\u0027ve seen or my email is turning look at this report out of four editors there are some warnings and mistakes now the way I do it is that I do a crunch up every day that gets all the ITF draft I extract the models I come I validate them I look at the different day before I say you post a new version there can you change this because there\u0027s a mistake in your yang module and you drop an email hoping that the people will act on this right and then if you don\u0027t forget you repeat it after some time now I mean is this like what inappropriate not efficient or fashion or even stupid do we work that way while we have mechanisms like github right I would rather have like a pull request telling change this in your yang module and that will validate and I know it\u0027s documented it will be there it assumes that people will work from github right but then I do the work a single time it would be way more efficient someone with video would say yeah sure that makes sense merge done end of story so should the ITF adapt I\u0027ve been here for more than five years some people say too long as IAD I can agree with that I\u0027ve been there for that long and I believe that the ITF should adapt or must adapt to be to use RFC 21 19 we\u0027re way too slow we\u0027re not efficient to produce those modules what do we need a mechanism which is based like on something like github we need to "
  },
  {
    "startTime": "00:33:31",
    "text": "have like the semantic versioning in there and rich art we\u0027ll be speaking about that negative slides making sure you\u0027re working up but it means that we still have to produce RFC\u0027s at key points in time right now the point is that what we want to do is run a console to score on the yang module and then whenever the working will be fine with the young modules we produce the RFC at explain how to use it the point to say I have a yang module then I created txt file because that\u0027s the way it works in the ITF then I have to extract it point hopefully to the right line because depending on how extracted it might be the right the right one so it\u0027s more like running like open config which by the way makes sense and I\u0027ll get your question you know I was fine now I spoke to one day cooperator about that he was telling me you know it\u0027s a game and one big one who\u0027s typically sponsoring this ITF he was telling me and I\u0027m trying to quote this it\u0027s a game changer the ITF and each day you don\u0027t do it you\u0027re close to the grave right and I believe that right net mutton that counts are kind of working like that with github but somehow it\u0027s not too clear if whenever people send like a pull request and engage it needs to be discussed on the mailing list or not or whether the message from from github should be sent to the mailing list and I want you to have a last thought here with AD 3sm right we had an RFC fine working closed success right we produce RFC we have it one of the implementers wanted to implement it and found some issues right in the yang part okay obviously again I said maybe not obviously but I mean we\u0027re engineers right we can assume that we\u0027ll make mistakes at it we need to improve it so in this case I would like to run the process directing gets her on the yang module to say okay we improve it we all agree on this angle you good push we\u0027ve created our FC ID if we want so then the organic and you just mentioned the main problem usually people don\u0027t implement actually in most cases people don\u0027t implement until there is an RFC and with yang we\u0027re writing software and until implemented you really don\u0027t know if there is a bug will it work or will it not work so we have this issue that we are putting the card in front of the horse and unless we can change somehow how we will adopt the models and people say implementing them earlier that will continue being a problem and there there was a saying in the idea from early early days that we believe in working code and consensus and the working code is being forgotten and only consensus has stayed but the "
  },
  {
    "startTime": "00:36:35",
    "text": "working code is missing it\u0027s also part of this solution where I would like the yang models to be easily accessible and you\u0027ll see how we could tag them and hopefully we will run the automation directly from github for a specific working room for a specific document and people just extract it and work from there I don\u0027t think it\u0027s an issue of what tools we use it\u0027s an issue that people don\u0027t implement them until they\u0027re you know because the managers are saying no until it\u0027s an RFC we don\u0027t want to do it and this is something that for system interfaces made sense to a certain extent although I disagree with that but for especially if or models we have to change we have to get we this has to change otherwise this modeling effort will not be successful because for many drafts for example routing draft which was one of the key drafts for all the other models was six years in the draft status and after six years in the draft centers it became an RFC and I would ask a question how many vendors implemented that draft actually that RFC now so let me make a link with something different because obviously you\u0027ve seen what you\u0027ve seen from the catalogue but maybe I want to express some more things one of the midterm ID which is cataract is to give the kind of score scorecard to young models and a couple of metadata that you\u0027ve seen like did compiled maturity level included imported by some eight times then the next one you see is employed like ten times right and going with this court card whatever we say in any SDO is that this is the the thing that you have to do it doesn\u0027t matter because the scorecard there will be what count in the end whenever you see that this young model is sampled like six times regardless was coming from this is a de facto standard one point that is missing there is the vendors that implemented it I will go back into the actual implementation out there in the world because many of those are cross-reference between drafts no no you missed a point there was like a specific slide from Jo were you so a couple of models implemented by vendors okay the first one is my own company the legend wasn\u0027t clear sorry so different colors I just couldn\u0027t read what was the different one it\u0027s not the one with all the arrow which is impact on users which is import right there was a different one telling if you click on that yang module I mean we\u0027ve got the data not the GUI yet if you click on that yang module "
  },
  {
    "startTime": "00:39:36",
    "text": "you will season it on sr9 k61 all flavor love software and this is part of the scorecard I\u0027m mentioning Phil Schafer you know Juniper Networks so one of the one of the nice things we\u0027ve done in Genesis to make it so that modules and the translation scripts to to convert from module data to native data all that in Juno\u0027s is programmable so we can take some of these modules that that that no one has any you know very early where you\u0027ll you\u0027re not going to get any real vendor interest in in doing an implementation you can take those take a Gino\u0027s VM load the Aang directly make a translation script to the native you know get some experience playing with it see that it actually not only can represent data accurately but also can be translated into something and that translation mechanism isn\u0027t isn\u0027t a standard but it\u0027s a it\u0027s a Python script so just as a tool any Behrman so a couple comments been while one is that our review process really discourages people from implementing early because once it gets to the area director and then goes to the iesg they could change anything they want and and your early work is thrown in the dumpster you have to start over so that\u0027s that\u0027s a significant problem the other one another significant problem is we don\u0027t really understand how to use augment yet we keep piling and piling on in large modules and instead of shipping what we have is a core group of functionality we keep piling on until it\u0027s what we call a kitchen sink nib okay and and that\u0027s that\u0027s a problem as well so it makes longer and longer before that module actually gets shit because Oh somebody thought of one more thing that we can do well you\u0027re allowed to do that in a separate module that augments it\u0027s okay and in fact it would help get the early work out the door will really make a difference and that\u0027s ghost of the way I was talking about with the the bundles is if you have a whole bunch of models you really need the metadata to pull it all back together I agree on the augment under review what is your solution for that I have it as well so you know and I will go back to my as a former alcohol "
  },
  {
    "startTime": "00:42:36",
    "text": "draft author so ACOs turning into the kitchen sink and everything has to be thrown in and the original idea was to use augmentation start implementing early and then adding for augmentation process and essentially what has to be done because we are somewhat you know restricted by the RFC create a high level model that you know provides you know the logical functionality that we are looking for and through the augmentation process you know do it you know make it closer to the low level you know a technical model because most of them from a logical perspective it can create the high level model that can be implemented widely and then technical dependencies and them you know later for the rotation process but majority of the working group members are disagreeing and saying oh we have to put you know all the technical details up front and then they are start using you know de feature and from a day one I was very much against you know the e featured functionalities because this is exactly where you will be putting more and more into it and that there is one thing that I believe who could make it faster is saying okay here\u0027s the first RFC you know it\u0027s a high level model because are implementing it at least create some of the common api\u0027s and then add more low level technical details through the augmentation process so one quick one because I would like Richard to present their dissolution they\u0027re not I want to defend kitchen sinks but sometimes I think they\u0027re concerned with augmentations is this the structure has to be augmenta ball I mean and so people want to ensure that they\u0027ve considered enough of the use cases that at least the structure won\u0027t be changed later on when so when you need two developments you at least the structures therefore you document that you know that you have the right structure so so Richard up to you to explain the plan was github so hi my name is Richard I don\u0027t know anything about ops but I have written some specs that get used for things and we\u0027ve used github to develop them so I\u0027ve been kind of acting as scribe and interpreter for some of the ideas and problems that up and wah has had trying to come up with some ideas for how we might try and try and make things a little better so like raise your hand if internet draft format is your preferred format for editing documents or yang models like like seeing things zero hands here so so maybe let\u0027s not do that so it kind of started with the idea of I was just chatting about this with them Wow like do could we just edit things edit directly the things we care about so like if you\u0027ve got a structure for a game I\u0027ll just edit the yang model maybe have some explainin sprite exits the next to it and then call working group consensus on that as much as you can it "
  },
  {
    "startTime": "00:45:36",
    "text": "turns out you can\u0027t quite do that and get all the way to RFC there\u0027s some process documents that require you to produce internet drafts at certain critical points of the process but you can basically run the entire working group process just looking at structured documents or whatever format you want to use so we wrote up a document let\u0027s see I knew the next slide here yeah we wrote up a draft kind of describing how to look at kind of two problems one is how do you develop how you develop it IETF documents without using this internet draft format you know so if you want to work in HTML the or markdown or directly on a gang model or an XML schema or JSON schema or sieve or schema whatever your preferred languages for working in as a working group how can you do that while still meshing well with the IETF consensus process and kind of upholding all those standards of consensus and wide review and all that so that was kind of one problem how do you how do we deal in alternative formats the other question is how do you do some semantic versioning to provide a little more continuity and enable some more agility so I think a couple of the points on in the previous mic line we\u0027re about how do we iterate a little faster how do we have a little bit more agility in how we release specs so the basic idea is you know instead of having you know the internet drafts as this ad-hoc versioning system that terminated in RFC and the RFC number is being completely disconnected from any semantic meaning of versions of the thing we\u0027re developing let\u0027s have a repo for each document that is the the tracks the evolution of extra documents the wrong word a repo for each model or each technology we\u0027re dealing with so you might have a repo for TLS say or for acne for a protocol and you develop the protocol in that in that space and then the repo provides the history of that document and it\u0027s more of a coherent history so you think in terms of you know right now we think of in terms of internet dress and those provide sort of a timeline a very coarse timeline of how the document involves the idea here is to you know a version control system has a constant stream of commits as you\u0027re working on a document and the idea here is to kind of use tags in the repo to highlight essential vo critical points in that life cycle of the document so for versions you know when we want to do into implementation mode you enter off we want to kind of as a working group decide this is a version of the document we declare an official version and for that we want to kind of with the proposal in this document is to kind of adopts the major minor scheme that is pretty common in the software industry now so you know if you develop a new version of the protocol that is backward and compatible you know you develop a completely new yang model that has no no relation to the previous "
  },
  {
    "startTime": "00:48:37",
    "text": "hanging model for this thing that\u0027s a major upgrade so we\u0027re going to update that major number if you are say adding a feature or adding some details or something like that where you might still maintain backward compatibility be able to reuse data in the old model but also have some new features in the new model that can be a minor update and of course if you really something you get implementation experiences and you discover eating bug bug fixes then you can you know increment the patch soul and the this is you know kind of completely non surprising if you\u0027ve ever looked at semantic versioning before the that\u0027s what the document does is kind of describe how these relates the ietf process and the idea is that we need kind of increasing levels of consensus as the changes get more and more major I think if I recall correctly yeah okay we\u0027ve got some these here so patch level you know the idea is you should be able to make those level changes with the consensus of the working group you don\u0027t need to go through the whole IETF consensus process to fix a bug you might want to roll that into a Nara you know full up rx you later if you make a more major update but we can fix bugs more quickly without it was a lighter process minor minor changes like adding adding features the default kind of the default option is yes you will go through the whole consensus process but there\u0027s some ways you can opt out if the changes are sufficiently Myer and maybe just do that with working group consensus with the consent of the 80s and then major changes are like RFC\u0027s like you always have to get IETF consensus full review full discussion around a major change let\u0027s see and then so so that\u0027s kind of how you deal with big you know big official releases and then these four you kind of replace internet drafts with like feature branches so when we start an RFC you start working on new something new you you branch you get pick a label for that just like you pick a name for an internet draft and you tag up you know tag versions tag working versions as you go when you need to have one for an IETF meeting or for a hackathon or someplace where you need a stable reference that everyone\u0027s going to refer to for some period of time so instead of having you know a an internet draft be a document that is you know in its own you know it\u0027s kind of own its own version space it\u0027s good the idea here is to have these as tags that fit into an overall history of the document so you can see things like diffs between individual commits and understand why things are changing what has changed between versions of the drafts so yeah Mike like I think any Behrman so you\u0027re aware that the gang update rules don\u0027t apply to a work-in-progress we\u0027re allowed to keep changing a work-in-progress all we want we make we make it in illegal changes to gang "
  },
  {
    "startTime": "00:51:38",
    "text": "modules all the time in Internet drafts and so and this problem goes back at least 10 or 15 years in the ITF is how do we know that this work in progress has some special meaning being you know we call them snapshots or something at one point but even that snapshot can be can be tossed out and all kinds of changes made so so really this this kind of semantic versioning only really applies to the the published modules but we\u0027re not patient enough to wait for the published module so so going back to my previous point get the module started get it out you\u0027ve heard of the agile development process well we need to do that because we\u0027re not doing it now yes it\u0027s a part of part of the what the draft says about these these multiple levels of version change is that some of these levels of official versions can come with lower process requirements so you can make a published version with without going through a whole bunch of heavyweight process and so hopefully you can have those tighter cycles and be a little bit more agile but also you need to have some work in trogir stuff that is outside the fish version process so that you can do things like throw it away and and figure out how you\u0027re gonna change the official version yeah actually one interesting comment was made yesterday during the working group when they said oh we might have to release a new draft by November and working group chair said oh if you really planned it by then I would make a last call a big existing model and just to get it out because you know we cannot wait much longer yeah Richard this is pretty cool stuff Ellie layer two questions first what is the difference between a minor and a what is the intended difference between a minor change and a patch change in terms of what do you think the process difference is so I think if we go back I think we kind of envisions some loose equivalences to existing processes so a patch or a bug fix is kind of similar to an ER Atum on a current RFC and so that\u0027s those like 80 80 approval rod I get marked for the 88 approval so you could envision some some similar process here and so likewise the minor updates kind of get mapped to update our FCS and so you know most of the time you\u0027d expect those to go through RFC it maybe if we want to get some more agility in the process we don\u0027t require all of those to go through the whole process if they\u0027re minor enough okay second question is where do you expect the repository to be is it github or have for these for these documents so the the document the document we\u0027re discussing here not subject dockings it doesn\u0027t actually even specify anything about get "
  },
  {
    "startTime": "00:54:38",
    "text": "it just assumes you have a version control that system that kind of roughly tracks his commits and has some tagging capability I think where exactly what exactly the repos are that we used for this is going to be a good problem for working groups and ADEs and folks chat about I believe there\u0027s been some work already on obviously there\u0027s several working groups making a lot of work use of github right now I think there\u0027s also some other hosts that are being used for that but I think the interesting github has already gotten some people thinking about how do we maintain control of destiny here and be able to recover in case github explodes and things like that so I mean there\u0027s obviously those sorts of considerations with any kind of hosting repo hosting provider and so I think that there\u0027s some work already started on that due to some user github already going on so the other comment I\u0027ll just make is this is well this is very useful I think at least I think it will be the other problem which i think is also interesting is how we turn on the models well while we\u0027re doing development such that you don\u0027t have to continuously turn on internet drafts and having a you know some sort of include mechanism for the RFC editor to move forward I realized that\u0027s not your particular bailiwick but it\u0027s something that it would be nice if we can sort that I think I had heard rumblings that somebody was working on that but I\u0027m not sure if that\u0027s the case yeah I think one thing that\u0027s not in the slides that it believe is in the document is that it\u0027s at certain points I think when you submitted documents the iesg it has to be an internet draft format so there\u0027s a little bit of a presumption that at some point even if the working group is working primarily on directly on the model and maybe with some supporting text next to it there\u0027s going to need to be some tooling that takes all that and wraps it up and bundles it into an internet draft that can go to the IES tree for approval and go to the RSC editor because then the process we got until we have to take this process RFC\u0027s we got to work with them yes please Phil Schafer Juniper Networks three comments one is you\u0027ll need more than tags because you also need branching you\u0027ll want to be able to patch publish versions and non-public surgeons well multiple versions of of existing documents the second is if you look at so so so when I did the initial Netcom draft way back when we used it but the chairs were telling me we had two minutes left to the thousand in 2000 when we started this I used a tool that we\u0027ve used for I want to say 80% of the tools inside inside the Netcom area that confident mod but that\u0027s probably an exaggeration but but more than between 50 and 80 percent all right we use a "
  },
  {
    "startTime": "00:57:40",
    "text": "tool that that takes text turns it into fancy stuff allows you to include modules and you know behave ins insane manners so so that that part isn\u0027t that that part we have but we need to do more in terms of announcing it and documenting it so that other people follow that follow that and use the tools I mean you you you you you know use a standard make file make file as you say make generates your stuff make check it does like ID knits and runs P hang on the yang modules you know just all kinds of cool crap and the third point is returning to Andy\u0027s point about base modules and augmentation that really is key you know I think the poster child for for oh we really suck is the syslog month the syslog model which is now at 15 or 16 and is you know is drawing on two years for the for the the simplest model that everybody agreed to and it\u0027s just taken forever and and the last ashame them it is it is a public shame it\u0027s it\u0027s a it\u0027s a humiliation saying that even even as we move forward we are still well we\u0027re still Neanderthals so and a large portion of that I want to say the last four or five revisions were all about TLS and security and all of that could have been augmentation we could have been done with this you know even even ten even ten revisions was horrible but but you know having been you know we could have written done I think I think seven was a year ago so we could have we could have published and been done alright good so where are tough times so quick - quick - quick last - to be added for example for the young catalog the average age of model that is not published yet Lee Howard thanks I love this I really want to see this go forward I support this even if we there you talked about there may be some process stuff that we need to update we need to and this may be I don\u0027t know if it\u0027s working group chairs ADEs we I don\u0027t see where the policy walks in the room need to keep track of what might need updating if this is incredibly successful especially if we start to consider doing things like this beyond just yang modules which i think is contemplated or sort of I infer it from from which talking about here I don\u0027t think that the let\u0027s use let\u0027s have let\u0027s do it eration on text whether it\u0027s you know model text whatever is the hard part is that is the interesting part here I think using git as a discussion platform for how we\u0027re doing our work is really the interesting juicy part versioning yeah like okay Elliot disagrees he\u0027s yawning um so so I want "
  },
  {
    "startTime": "01:00:40",
    "text": "to keep track of that and but you\u0027re absolutely really good could do this oh yeah of course I always have to say you know github doesn\u0027t support ipv6 we\u0027re alright good so I actually cannot I\u0027m sorry but you have to cut the line were late already I would appreciate if you could send your feedback to the mailing list okay thank you thank you so these were actually two sessions but we including a lot of the Q\u0026A in there which is a good thing so thank you and we\u0027ll have the absolute value G meeting now [Music] okay hello everyone welcome to the absurd GG and this is chaired by echinus Jana and Joe and let\u0027s welcome our new working guru chair and Joe would you like to introduce yourself well it\u0027s a little anti-climatic now I just presented Joe Clarke I\u0027ve been at Cisco now 19 years you know I mean look at and as Andy got out of me I\u0027ve been doing a network management operational type support as well as now more programmatic with yang in net comp so I look forward to bringing that experience to ops AWG into the ops area in general thank you and note well please understand not well and those important legal issues basically all your contributions to your to ITF including your presentation right app video audio need to follow the rules and note will has changed since last meeting RFC to 179 on intellectual property rules was published please make yourself aware with that there are five active working group documents firstly the cap web alternated hanno we adjusted the editors since some of them has lost the connections and the new revision adjuster all the previous comments and "
  },
  {
    "startTime": "01:03:42",
    "text": "we send it to the security Directorate for early review before the working group last call the IP fix BGP community document is in progress and the also updates the document based on the working group discussion made about extended community large community and wide community and the discussion also generates a new requirement on IP fix extension and later the also well reporter to draft and the mud walk is progressing well the also well concludes the discussion and status of the draft we newly adopted the service model explained the document it\u0027s an very interesting work with the experience of chairing a or ESM and they altruism the authors explained the concepts on service models the tucker\u0027s protocol is also in progress as the Shepherd Ignace can report the status of the draft so developments with the tax document it comes in waves sometimes as a peak of activity then there\u0027s a quite a long silence the version has not been updated for five months now the office chose not to discuss this in Prague for the reason that they did not have enough time to finish their current editing before the document cut off and the chairs are not concerned that much about the progress of this document but getting a little bit worried for two reasons one the process seems to be rather slow the second the process is not very public office are working on comments mostly by providing private feedback but not on the mailing list so those are the two aspects that office are being encouraged to address they promised to do that and therefore there will be something like a check point one month before the cutoff date for the Singapore whether there is sufficient and visible progress and that work addresses the comments which have been made on the mailing list if if there is no evidence of such progress then like leeches we\u0027ll need to think about assigning an editor or making suggestions to do - mm change the office of the document or assign somebody who will simply do that editing work so far that is not happening until before the Singapore all the other documents are "
  },
  {
    "startTime": "01:06:42",
    "text": "very readable and we encourage you to reveal in the comments and that\u0027s all for the what can Google status and let\u0027s continue with the presentation the first one Maude hi everybody Eliot here so this is an update since our meeting in Chicago and what\u0027s happened with a draft next slide please I\u0027ll try and keep it brief because I realize you got a long agenda unfortunately we\u0027ve had a lot of work done so for those of you who\u0027ve been keeping score basically there have been a handful of changes but some of them are fake as you know the the mud model is essentially an augmentation of the Akal model and as the Akal model has gone through major revisions and you were treated in the in this very working group to a lovely display of shall we say cisco on cisco arguing with one another in the last draft hopefully waiting on the model model be done a lot of work has progressed there however we\u0027re still pretty much normally blocked on on the continue to work on that model that having been said what we\u0027ve done thus far is a line the mud model to the interim model and the aqua model so that these things stay relatively in sync the so there\u0027s a small amount of work done here but one of the things that\u0027s been done in the Apple model is that everything is now optional and that works just fine using the feature statement if you happen to be using net comp which is not what Mudd does so one of the things we have before us is what do we put in the document in terms of stating what is assumed to be present when you do we need to find a mud model now the way that mud works right if you if you recall is we\u0027re using abstractions like same you know allow access to the same manufacturer allow access to my controller or allow local access or allow access to domain none of these things are IP addresses that\u0027s really good none of these things are MAC addresses that also happens to be pretty good because what we want people to do is abstract out the local deployment information well if you\u0027ve done that all right most of the changes that are going on in the Apple Model A don\u0027t affect us and B we probably want to make a statement maybe even a very strong statement that you shouldn\u0027t do things like have IP addresses in in a in a mud file so this is something that we need feedback on the other change that we that we perform is that we we\u0027ve begun to modularize the model just slightly based on some feedback that I "
  },
  {
    "startTime": "01:09:44",
    "text": "got from inna who some of you know who said well this is great if you\u0027re only ever going to do apples well if you\u0027re gonna do something else and so I said I don\u0027t know you know you tell me so he came up with a recommendation and that was to essentially have have inbound and outbound communication paths to the devices amongst which Ackles could be one of those things and so if you look at the the new version of the draft this is what it does and that leads to a couple of other items one of which is even at this IETF I have an approach not fewer than three times about means to extend the model means to extend mud now recall that again we\u0027re not using net comp as a communication pass so capabilities exchange is not part of the current functions so we have a different extensibility model inside the draft which is integral to the co2 to the to the model it\u0027s important to get the extensibility model done correctly and so I\u0027m asking people to take a good look at that in the next couple of days and weeks and I\u0027ll prompt people on the list so just to make sure that we have our extensibility model done correctly the way it\u0027s done right now is essentially there\u0027s a list of extension names that you can have I think it\u0027s a leafless memory starts correctly that you can have and based on that then you can instantiate essentially the you you\u0027re telling the implementation here\u0027s what you can expect to see and everything else you should ignore if you don\u0027t understand it and that\u0027s the basis of the extensibility please comment and if you comment and don\u0027t like what you see come up with an alternative or propose an alternative because we\u0027d like to get this right finally the the last change we made was that we were in process of tweaking direction initiated it became clear to us that in in some people\u0027s implementations they find it hard to do that for other than TCP and so the idea is we\u0027re gonna limit that to TCP for the moment and if people want to expand it out to UDP they should do so as an extension so those are the big changes since the last call there\u0027s one big change that didn\u0027t happen that has to happen which is that the examples have to be updated also for those keeping score I have this thing called the mud file maker that has to be updated for the last based on what\u0027s in the last draft and I will do so in the next couple of weeks next slide please so as I mentioned the examples need to be updated a little bit more we need to decide what we\u0027re gonna do about features whether any features are expected whether we should simply say only the mud features should be used and the reason this is again the reason this important was we\u0027re really using the "
  },
  {
    "startTime": "01:12:44",
    "text": "Akal model for is for its structure not necessarily for the features and and but maybe there\u0027s a feature or two we want a list like I don\u0027t know that TCP capabilities so I\u0027m asking people to review the extension mechanism well I\u0027ll try to do an update in the next couple of weeks to the to the draft I\u0027m not going to ask the chairs for another last call until the Apple model is done and I\u0027m breathing down the neck of the person who\u0027s taken over that to say please get it done as I did here last time and so the other thing is that hopefully we\u0027ll have some open source out there in the next couple of weeks would you say that people should review now or wait for your next rather than two weeks I\u0027d like the extensibility components reviewed in particular now and then the examples and the an actual model reviewed after I get the next version out and so what I\u0027m aiming to do is ask you for a last call by September 1st and I\u0027m when I mean last call I mean last last working and your document included a young model and you may need to check the MTA guidelines yeah I\u0027m I\u0027m pretty sure that I\u0027ll be that Ben while we\u0027ll be breathing down my neck about that if nobody else yeah see questions comments how many people have read the draft cool okay anybody else implementing I see I don\u0027t know a couple of people are again here and it could use a couple more implementations I think I know that some people didn\u0027t raise their hand that I know that they are so alright with that thank you and next one so is models explained everyone my name is Ching I will present a service model expand also pick up and this job to actually identify a list of service model not a defining the idea who so a clarify the relationship of these service models clear some misconception for this service model definition so history of the status and this chapter has been around several key meetings and we were revised seven types to address a list of comments based on discussion on a list and some offline discussion so just this job had a dog "
  },
  {
    "startTime": "01:15:44",
    "text": "before the prat meeting and we made a one more revision revision because we receive one comments actually fixed some type of toaster clarify the relationship with Yamamoto classification Chavez that I define in the meta mode and young model net classification chapter has already be stable has already in the publishing publication status and so we cannot change it actually for young more those classification job to define the madman and motor classified Yamato into two types one is Nana was service model the second is animal model so this caused a few debate about our G after since the way this car we discuss the service model we sink model definition you be refine so what I would Jeff does actually we actually provide foundation provider complex the distribution for model that are used by the provider to describe the Nano service in communication with customers so the customer use these service model to describe the service characteristics or survey requirements to the provider so how to use these model actually you can implement as a software this software can be part of the management system and so they can provide actually dynamic exchange for this service model parameter also you can implement as that some kind of portal page or some kind of form so the customer can feel the parameter in this form and submit it is form to the operator provider so provider can take action on that so the example of a service model we have obviously a t-49 that already be published in a USM working group and we also have air to SM worker that in progressing over to SM working group so this surface model unlike actually animal models cannot code implement in the network device so that\u0027s a difference so how we address the overlapping with yamato-class we change after and actually pays some discussion with yamaraja also we rich equipment at USM and elsewhere SM surface model both nano service model but we sync nano surface model high reporter meaning so we need to extend it so that\u0027s why I\u0027m motivated for for us to write this draft and and so how to address this overlapping for Yamamoto classification "
  },
  {
    "startTime": "01:18:46",
    "text": "shaft actually we actually ensure that definition can be a broader to cover the area same area over to a sense of his model and will also actually update ask also to update the reference and some discussion about air CSM so yamato-class killing java can move on and is so for our child we try to get in now with geometry change after so most of change actually actually ensure the reference to the Yamato class in Java is correct and we as ways said actually we single nano service model Hasbro meaning so we further broke down the narrow service model into the customer service model and a service delivery model so so how to position these different a service model in this kind of appetizer we actually broke down the actuator into two layer we have service of true that we have nano operator so we can position the customer service model um lost boundary in the face of the service operator and we we position the service delivery model actually between the so it\u0027s up straighter and never out Raider so for the figure we updated actually for Yamazaki last week in Java the original have sounds a figure so we add some additional in inquiry and we think these something useful and so for the next step actually we think you people single still have some concern on the range with llamo modem has gained chapter please tell us and we actually need to first understand the the relationship and and take action to Portugal chapter to access that additional actually for vaping is not a part of the yamato-class region chapter thicker so we think actually we are also wasting disease EBP is a useful additional but if you have some concern please let us know beside this we think of this chapter is a ready for the last call we like story say the the review from the community that\u0027s all thank you any questions Allah Allah had clarification Joe Clark is an individual contributor on the evpn initially when I read the draft I was confused as to the "
  },
  {
    "startTime": "01:21:46",
    "text": "intent as to inform changes in the classification draft Hadrian and I went back and forth and I\u0027m fine personally as a contributor if you leave that in there sort of an augmentation so to speak of that of that figure how much more back as chair had on how much more text do you think is is needed there\u0027s been already discussion on the list about last column what do you have tangible plans to add more text or to update the draft or you waiting just to hear more feedback yeah I talked with my car\u0027s always secretly this chapter actually already in Bishop we just want to better understand if there some confusion about these about this relation with Yamato class of in each other if it was as known we think this Chavez table okay as you have there are some work still to do so I think we can wait for your relation and we moved last caught use caution in the mailing list is that okay okay thank you thank you and the next one the IP fix related walk hello everyone my name is Chan Chan Lee from tan mobile the title of my presentation is exposed PGP community information here a prefix so the main content traffic application in BGP community granularity is useful for several applications such as backbone network traffic engineering so this traffic introduces several new information elements you know a prefix to its thoughts which P community information about specific traffic flow there are several kinds of bgp communities a defend including the standard community it extended community and the larger community the committee container is the idea working group draft so in this version the information element to export which P standard community extended community and logically are included we defend three "
  },
  {
    "startTime": "01:24:48",
    "text": "information elements for each candle PP community the first one is about community itself which carries exact one community radio and the other two are the basically the first one they are cross banking with law the source IP address and the destination IP address are specific flow respectively because the community values responding with the source IP address or destination IP address or specific flow may be 0 or more so we have basic list the PTP community container we do not include a gin in Skyrim and I don\u0027t think we should include this kind of community in this document because the big big community container has totally different encoding format the previous three kinds of BGP communities have the encoding format in fixed size and the Pacific community container has the barber size it uses the tap dance and weather including format and different can do types of PGP community containers may have different encoding formats for the various in current versions our BTB community contained the document the type one community container is defend at least called the white pacific lineage as format is thrown in the right favor we can see that that is also available because it consists the tiara is being used in the optional part the second reason is the perverse the beach picnic dinner has totally different applicant perverse pacific many contenders many used to to delivery the locally different policy parameters to the BB speaker and what we want to know is to get the the traffic information in "
  },
  {
    "startTime": "01:27:52",
    "text": "BGP the granularity and besides the pcommunity container is still a working group document mine halves will be defend and your way includes this kind of community in my document we have to update our document accordion the other users that we talked about in the previous fiscal health media and me list is about epithets message lands do we do one a prefix as well a prefix message have enough space to fit all the PP community related to a specific flow as the answer depends down on the on the BG features that the ipv6 Potter suppose if the a prefix is Potter doesn\u0027t support the BGP taunted message the answer is yes because the maximum lands o1 b TP message is 4 kilobytes as per our RFC 4281 and 64 kilobytes for one IP fixed message you know the effective Porter suppose as a BGP transit community the beatific handed message the answer is no because the maximum of the massive size of BGP intended message is 40 is 64 kilobytes so the effective Potter has to to handle the effects message are probably for example trumpeting the effect as a BGP community information even idiot to solve this problem completely we tend the message lands from September through 32-bit the proposal will be presented after this document so you you will all agree that the PGP community container is not suitable to be included in this document I think this this version is stable for the way to group to to do the last car so that\u0027s all thank you can I please see show of hands who has read this and also accompanying ide fixe extension "
  },
  {
    "startTime": "01:30:52",
    "text": "documents and how many of those who read are operators who intend to use or see a need for this or or intentions for deploying this all right one hand to do three maxim right pretty much the same first question was who has read and probably couple more hands more five or so and of those operators and who i have interest in this work speaking as a working group member individual member it\u0027s good that you have covered extended messages those eventually going to happen but i would think that you need to be realistic about the number of communities that you see in actual deployments if you look at the current global public global routing table the average of standard communities count is around six seven and ninety five percent of them are less than ten in private deployment certainly you can see the use where there are much larger numbers of communities so the question where you need to extend IP fix probably needs to be raised and ITF is not like the right Organization for that it\u0027s much closer to the operational community events whether there is an actual need to have support for that many of the communities so just a comment video for Deutsche Telekom I think I\u0027m seeing questions that\u0027s kind of follow Ignace the type of issues that you were going after I think the question of under what circumstance are implementations actually realistic some of Ignace your concerns are kind of scalability things I would say and I wonder I wonder whether we actually have collected some comments from with addressing the actual feasibility of this from the implementer side and actually for the implementer and the operator side I would assume that some "
  },
  {
    "startTime": "01:33:53",
    "text": "ideas about what configuration to limit the info may focus and filter the information that actually goes into this probably would be really important like if I were thinking about using that kind of information I\u0027m pretty sure I\u0027m pretty sure I would really I would really go after and say yes I have a certain filter of a communities that are relevant for getting statistics like like the net flow here and I plenty of other communities that I certainly do not want to excavate the scalability problems so am i right summarizing that what you are saying that this document would certainly benefit from operational consideration sections so yes I think you can configure the filters on the Potter to limit the communities to choose the ones that you want you to be exported to the collector right and you don\u0027t need all the BTB communities covered in this document you can you can state what you want in the template you know activates so as its Potter is easy where you\u0027ve got the deformations that you want according to the template I\u0027m John Easley from NTT I\u0027m curious about how many operators would apply or see the application for for this draft in business intelligence so pulling stuff to determine where a rob arrived in from the network that sort of thing versus and there were very few hands that seemed to have interest in it which i think is odd so who sees it as a as an application for business intelligence just just one interesting right so when as a recommendation it really would be good that you socialize this with operators with operations community not only 90 f and add in the operational consideration section to your document thank you no to socialize all of this idea and they require the need for having that many of communities to be exported of all the types all of them I used the ball of the mind deployment in the field "
  },
  {
    "startTime": "01:37:02",
    "text": "just a quick note could you be quickly this because you are really are out of time of your slot so this is the companion document the proposal about the attorney learns message spot for IP fix the main content to updates artifact specification by if 20 of the IP fix message lands from 16-bit 32-bit to allow to accommodate longer information the volume to use anonymous will be covered in this document the first one is one at the fixed message consists of many as more information animations where if admin she is it is assistant law and the the as scenario yet the ActiveX message consists at least one information element which is longer than a 64 kilobytes so how to how to achieve it we attend the Lancefield in a fixed passage header the settler and verbal and information element the specifications about other fields in those handle headers and information elements are unchanged so for backward compatibility or waiting it a new version or a prefix to sports xx message rounds so I now it stress it a certain new world I think you know I mean it\u0027s perfect and for the next step please read this document at comment in the nerdiest and since the requirement is clear and the content of this document is pretty simple so I think it\u0027s ready to be adopted by the working group thank you thank you for that and probably I met a question on not for you but for the working group I met a question on the need of extending IP fix to accommodate information elements that potentially can be larger than the currently be carried or may be raising the question of a fragmentation is needed an IP fix simply a mechanism that can carry information elements which are larger than the current container not that I would be expecting the question right now could you please speak up on the mailing list and if you have use cases for that please tell so and requirements "
  },
  {
    "startTime": "01:40:04",
    "text": "potential requirements for extending ipv6 thank you thank you so interactive queries could you please try doing that in 9 minutes because we are quite short of time so what\u0027s the next big thing in network this must be something I\u0027m going to talk about right but no I\u0027m just kidding I think the next big thing is about using big data analytics artificial intelligence and the machine learning algorithm itting network operations and keep people keep him being out of the control loop that\u0027s why some vendors and the operators actually initially some proposals about the future autonomous not network or a self-driving network but before we realize this long-term vision we have to realize that the foundation of this vision is actually the deep insight to the network to gain the full visibility of the network also this needs some technology called the telemetry so recently there\u0027s some nutrient for the network telemetry technologies such as allow user to subscribe streaming data from network devices also use a model driven telemetry technologies and also allow user to even customize the data they want to collect from the network data plane and also many several technologies related to machine learning and artificial intelligence has been applied for data analytics here I just you know put some know two key takeaways upfront so to realize are the network visibility I\u0027ll be first to you know understand two things the first is that the data network data is a really a big data for to fulfill many applications requirement we need to gain the full visibility to the network but the network january to too much data not only all the data packets are user traffic goes through a pass through the network also each in natural device will simultaneously january 2 tons of data due to the limited resource is very difficult to gain to you know to be able to collect all the data for analysis but the "
  },
  {
    "startTime": "01:43:08",
    "text": "another trend is the networks also increasingly programmable right the user can define the behavior now so it\u0027s possible to actually provide the an amount of visibility to order to meet all the applications requirements so that\u0027s why we are proposed this key concept called dynamic network probe or the EMP so the VM key is basically a piece of functions to do the customized data collection and pre-processing it can be realized through the runtime programming yes you can insert a new piece of code through your system at runtime also you can do that through configuration if you have you know pre-allocated resource or pre implemented module in your system you can just configure it to enable it and also from the user perspective the user read doesn\u0027t care how this TMP is implemented it can be directly embedded into the first pass or it can be implemented in the slow pass control processor and even they can be separated you know two parts so one part does handle something and jointly they can provide the full required function so I just talked about you know this a custom and data processing and the event event monitoring is basically what\u0027s the DMP is supported and there are two key deployment approaches either from programming or configuration if it\u0027s a programming that means we need to support some runtime and loadable function modules to the system it is through configuration basically just enable some existing program model in the data data path so self has some key used cases of for the NP the first one to support in in-band network telemetry or the you see 200 m there are two scenarios we can apply the dynamic dynamic probes the first one is you know to support some custom customize the data generation functions so user can define what\u0027s data new data they want to collect and then us asks a packet to carry this theta and so they can collect on somewhere else also there are many possible configurations from the management plane so they can use a dynamic interface to modify the configuration dynamically to "
  },
  {
    "startTime": "01:46:09",
    "text": "customize how they want to get set streaming data back there are some other use cases due to the time limits I won\u0027t talk about them you can look at the draft so there are different type of DMP team piece.we summarizes into three groups as it can be note based data type they mainly concerns the state and the status of each individual nodes in the network all it can be the path based data types as they make many concerns you know state and status of a designated path in the network are the last group is a flow based class they just concerned the state and status of any specific fellow in the network so this different data types doesn\u0027t necessary to be exclusive with each other so some data type can be derived from some other types cause that\u0027s totally possible so who minutes two minutes okay I\u0027m almost done so the architecture to support the you know dynamic network probe is to use that for supporting the interactive query write the applications can have a requirement for any type of data so they just basically use some query interface to ask for data so the data can be compiled into a set of ten and dynamic probes the probes are inserted to the system data plane and the runtime and then start to collect data and feed the data back to the your application the application will continually continuously refine their further queries to the system so you can see this is a highly dynamic process it can only happen in the run time so there are many different requirements so we need a application interface from the application to the you know to the system also we need standards sauce font deployment and the data collection interface some examples like G RPC and net Kampf and also we need to be very careful that the EMP shouldn\u0027t you know modify the form D behavior or even affect the folding performance in the system and we need to support multiple DMPs in parallel because many applications each may have their own data requirement from the data plane also there are many different challenges we are facing like the first of all is the security and the safety issues because now we allow the some kind of dynamic change to the data plane at runtime so we need to be to be very careful about that to know for any intentional and intentionally chained to "
  },
  {
    "startTime": "01:49:09",
    "text": "the for any behavior and also we need to support network wide deployment multiple nodes each peak work collab to collaborate together to cooperate so they need to work in concert we need to avoid any performance impact to that tree forwarding and also we may need to consider some innovations in device and chip architecture to mix the implementation more efficient we\u0027re out of time quickly who has read the draft and we have time for one question all right it\u0027s around ten hands thank you next is young model phone at least nine minutes or less how you going to put on this draft on behalf of my co-author so this is am just a quick background on the draft this is the draft which is here from since some twenty years see reiteration of the draft has been in so far received various comments including from Natick experts especially for instance from danwon and also for one implementers and the since the behave working of which is normally supposed to work on the not specific aspects has been closed we we are looking for our working group to to endure this work so basically the this model is covering various our systems including the dismal net there is a net that you can have in your CP and the net which you can have in the network as a large-scale net but also the all the ipv6 flavors including not 64 and in PT v6 the ipv6 prefix translation and not the address translation and we cover both the individual on the Porsche translation and we recover all the the BCP that are for this video TF for the ICMP UDP TCP and so far and the recent updates that are produced by the TSV working off we support both configuration and the state management in the model there is no need to replicate but we have already the draft in term of destruction of the end of the model that you can refer to the draft who do that what is out of scope we we are not dealing with what you call the dynamic explicit mapping that mean that if your isn\u0027t a dedicated protocol to instruct you not to quit for forwarding we are not dealing with that for instance the PCPD document for that there is also the dynamic what is called a dynamic net assignment this is something which is outer scope so far from Dickman because there is no standard in the IETF there\u0027s only informational but is it on individuals so there is no "
  },
  {
    "startTime": "01:52:09",
    "text": "need for us to take into account this kind of algorithms in the indie model and of course the last one we did this EP marking we are not covering because we don\u0027t want to deport overloading by playing with the DCP value to multiply the number of nut map need you can have with one single IP address so this is out of scope the main point I am here today is that there is a dependency of this model at Yui because we have two other models that are developed in this software working group we mainly do this light one and also the the the map II and map map T modules that depends on the young the national model because we have this dependency what we have done so far there because if you want to progress in the publication process we have just cloned what we have in the net model there in the day slide which is not actually a cleaner design so that\u0027s why we are coming here to ask the adoption of this for this working group so that we can report back to to the software working group so that you can update this boat draft that we have there so that this light model will be built as where we are augmenting the GNAT module and also will point to to this one by the map and map T model so this is the end of my presentation and the questions are welcome and they I would like to address for adoption in this in this program this is something we discussed on the manage and also in private with there one of the co-chairs thank you for that questions quickly Lee Howard since it supports both net 4-6 nat64 does that mean it implicitly also supports 4 6 for X let I think the answer is yes and it\u0027s like a note saying that the be useful sorry because it supports nat64 I think it also implicitly supports 4 6 for X let and I think that would be or at least the excellent side of 4 6 for having a note saying that would be useful as a use K as a usability statement yeah and so yeah it\u0027s it\u0027s not big slot it is the see that function that you are referring to I guess yes are you and there\u0027s a typo I think says this document it does make any assumption how internal hosts are attached to give in that instance sorry there\u0027s a sentence this document does make any assumption how internal hosts are I think it probably should say does not make it\u0027s just a typo thanks for watching that that all thanks one clarification question and to consider the Silva net water destination that it is used for the solar load balancing and will change the destination address this is not a discussion so far but we are open to include it if this is what a feature that is it is a question yeah so far it\u0027s not supported but this is something we can add okay all right thank you for that we will then bring this question to the list and soliciting for feedback and and all for adoption okay thank you Nicola on young-young for some events "
  },
  {
    "startTime": "01:55:10",
    "text": "and other soprano things hi good afternoon so this draft proposes young models for events and finished state machine in order to increase the programmability of of network devices network devices which are modeled with with younger one of the use cases that we have considered we for this draft is the case of the flexible transponders so transponders support support supporting multiple modulation formats and encoding so this transmission parameters can be set depending on the optical physical layer for example copious key is most more robust than 16 QAM modulation format and in case this physical layer conditions change these transmission parameters can be readapted so the draft the objective of the draft is to instruct network device of how to reconfigure itself so the control scenario is the one of AB no these these three modules functional modules are the one that we are considering so the SDN controller configures and reconfigured the data plane and the on-demand layer receives and process the the alarms so at the state-of-the-art if without considering the model that we we have submitted in this draft if something happens at the physical layer so a degradation an alarm is central to the on-demand layer then new transmission parameters are computed and the SDN controller configures reconfigures the data plane devices so then the the service record so this workflow is time consuming what we can do with the draft we submitted is to pray instruct the network devices on what to do if something happens so if this degradation happens the network devices can promptly reconfigure their self because they know about this finished state machine and the pre configuration is faster so the the young model is based on on these three we have a leaf called event for example a bit error rate increase we have the sub leaf filters to "
  },
  {
    "startTime": "01:58:15",
    "text": "fighter express the event so to put a threshold for example on this bit error rate and then we have the reaction for example the change of modulation format and the the field execute recalls an rfp an RPC that actually encapsulate the task of of the operation for reaction the feed state machine module extend extend this one the previous one of events by including staying state information and transition so considering the previous use case assumed to have this service working normally we are at the steady state if the bit error rate increases of over threshold we can we can adapt the Malaysian format or decoding and thus we we transit to the new state that we call the FAQ adapt and if the bit error rate returns below to the threshold we can reuse the less redundant redundant back and we return back to the state steady state condition so this is one of the use cases is the use case that we thought for for this draft and that\u0027s it thanks it seems like you\u0027ve created something or you\u0027re defining something that could be very generally useful but you\u0027ve done so in a very very very specific use case is your intent to be that\u0027s specific or are you looking to build something that could be more general purpose yeah event condition yeah we started from this use case because I actually work on optical networks so we started from that but finally yeah I agree with you it\u0027s something that is more generic so yeah this is just one use case we can think about some other use cases because finally the model is is generic and so if someone has some idea for other use cases for as is welcome daniela to currently see camper culture I find this work really into I have a comment along the line at the lines of yours in the sense that this work sentence has an optical work but it\u0027s just one of the many use cases one of the applicability whatever I would really like to see is this worker to be "
  },
  {
    "startTime": "02:01:16",
    "text": "done in a general manner in I believe the observer is the right place maybe not mode but any working rope in in the ops area and then I see technology specific extensions possibly in sea camp or Ori and other working groups of the rocking atom this is my suggestion thank you thank you very much so this is Michael Shaw have some thoughts on the specific use case but we don\u0027t have to discuss this here some I\u0027m wondering have you looked at the superb working group we submitted we we made the same across working group submission so we included also a young module and I\u0027m wondering better or what you do here just can be done with the supermodel well I I disc one of my colleagues discussed with Daniel King from from supe and as far as I know the models that they are working in that working group do not include Finnish state machine that might be true but for the other part I think 100% what you could wear it could be done by super okay okay for the way it stated I\u0027ve seen I think general okay in general considered that well I\u0027m not in IETF it\u0027s my first time so what we want to we would like to highlight is the possibility and the importance of using a finite state machine to increase the level of programmability then if there is a more suitable syntax within younger or it\u0027s it\u0027s okay for us we can and your comment is welcome to we can discuss with people from ask super yeah thank you it\u0027s just a quick comment and what yo proposed very interesting it seems to me is exactly one way to implement a DMP because the the each dinette probe is essentially just a finite state machine that\u0027s used to user to define how you can pre-process the data and collect data so I thinks it\u0027s a very irrelevant if you can extend this work to you know more than the optical network and to the general no data plane processing be very relevant thank you very much for the minutes could you identify yourself how you soon from Poway thank you thank you we are we are out of time thank you for bringing this work in please bring this to the mailing list and from what I know somebody somebody from your extended group will also try to present this at they\u0027re out in working group on Friday "
  },
  {
    "startTime": "02:04:16",
    "text": "or not maybe I\u0027m mistaken so please bring this to the mailing list and initiate a discussion and I 2rs super and then technology specific group certainly need I I already sent the draft to the mailing list of PS AWG the draft yes but please initiate the discussion okay okay thank you for okay thank you thanks everyone for coming with this meeting is over and there are cookies and other good things outside with these let\u0027s go and bring those basically you need to bring them to registration and there is Stephanie collect all of them so we can go together and see and there\u0027s a box of there\u0027s a box of them and they collect this you "
  }
]