[
  {
    "startTime": "00:02:14",
    "text": "thank you okay now we are two minutes past the half hour last time to get started welcome everyone this is the thing good thing research group our summer meeting my name is one of the chairs of the group of course the Mormon is the co-chair he's just coming from another session on IAP session joining this in a minute um quick reminder to everyone since this is an irkf session the node will applies so we are recording a session be nice to each everyone and also the iPad guidelines of the IEP applied the longer version of the node well is covered by the following two slides if you have any question on this please do read the recommend rfcs or do reach out to the chairs for more details both on the code of conduct and the intellectual property also quick reminder about the goals of the irtf so here at irtf we focus on long-term research issues related to the internet whereas our parallel organization ietf focus on the shorter term issues of engineering and standards making so here at the IU therap with the conduct results and not not doing standard development as the ietf does but however we do publish information on experimental documents in the RFC series primarily as a proper way to promote development of research collaboration and teamwork on the topics that are relevant for us a few notes on the administrative so we have an online note-taking uh using the noteside.org and the chairs will be taking notes but we do welcome everyone to join on the note taking so always more fun and better on collaborative"
  },
  {
    "startTime": "00:04:00",
    "text": "fashion we do have a mailing list where we recommend you to join if you haven't already the thinking RT at irpf.org there's a link how you can subscribe there and as usual with our sessions we do have a GitHub repository uh for this session where we have the agenda materials related links Etc stored a quick reminder on the tinselin Archie scope and goals so here where we focus is on open research issues internally through internet of things in the reality in particular on internet we're also the low resource nodes can communicate among themselves and with the wider internet and we focus here on the topic of iot and issues with opportunities variety of standardization so usually starting at the IP adaptation layer and going all the way up the application layer including architectures apis data management security Etc there are a few groups that we work including particular closely at the ietf site so for example core where there's a lot of work on protocols and data models and also more recently with ASDF which is engineering format variety model convergence and then for example groups like L we can iot oops where is more recommendations for an operational issues when it comes to iot but usually how it happens that we look at RG the more longer term issues on these topics and when there's need to write standards on the topic that work is done on the ietf side so right now we are having a summary meeting so these are meetings that we have roughly once per ietf more recently before or after the itfs where we give a overview of the activities that are happening in the thinking artist scope but we do have also other meetings that we have in between in particular we have had quite some time wishing meetings um varying Cadence sometimes once once a quarter sometimes more more often we're planning to continue those and we also"
  },
  {
    "startTime": "00:06:00",
    "text": "now we're starting a new series on topic of security on the secure which European will be talk more rather soon also we are planning to have summer meetings like this also before or after the next two ietfs and also we have had in the past very many successful meetings with other sdos Alliance operators communities on the relevant topics so we'll be very much open having more of those that we don't have anything scheduled at the moment and also we will be having work meetings where we go in more details on specific topics for example we had one on digital twins uh not that long ago where we take a specific topic and work more specifically on that we are also planning to have finally the physical meetings someday soon of course not this year but next year we are technically discussing to have one uh before the Prague ietf uh have a for example half a layer or full day workshop on the topics relevant for evening or cheap so please stay tuned more on that coming soon and we have had a quite some time planned to have a online call okay in academic conferences we haven't been very successful on that but if you are aware of perhaps an organizing and a conference that is of relevance to this group we'd be very very happy to talk with you so please do let us chairs know foreign s about the research group document status the document on H and iot is currently has passed the research group last call and if share review and it's going to irst review now the other research could talk when we have on the restful design for iot is we're currently waiting a couple of more PR's to come and then we should be soon going to research group last call also on that topic and then we have the document on Terminal chain processes for initial security of setup of iot devices formerly known as security bootstrapping that we get a quick update on on the following slide we have also a set of documents that are"
  },
  {
    "startTime": "00:08:00",
    "text": "not currently subscription script documents which most of them are essentially looking for more feedback and in particular the semantic landscape document or nutrition labels for iot is something would be very much appreciate more input and feedback on in addition to all the documents that we have today on agenda so next a quick update on the second bootstrapping Craft um do we have done and yes this is then one of the co-authors of the the draft so just very quickly let you know in this version we have completely uh assumed the new terminology used in this sense we are using uh the terms entities or or players involved in the different uh processes and terminologies regarding the the initial processes like bootstrapping provisioning onboarding Etc so we analyze different players involved in in different proposals or standards we also go over the different initial assumptions about the the devices involved and the different processes that need to be completed to to have the device completely operational and also we go over the different knowledge imported to the device before the different processes for it to become operational and the knowledge imported after the the processes have been completed and we go over as well in a comparison of the different processes involved for for the different standards and protocols reviewed so any feedback and review is is welcome as we work towards the the next version in"
  },
  {
    "startTime": "00:10:00",
    "text": "which I think we need to update some of the uh protocols for a new version that arised not sonar also again any review and feedback is welcome excellent thank you Dan and see we have Michael on thecube go ahead Michael hi um thanks um so it would be interesting to get this document back uh uh in in its uh progressing um I think one of the most important things that we need to do is kind of step forward since the document was started and um uh we need to to uh make sure that we're not using the word bootstrapping and because the industry's kind of moved on to the word onboarding um which you know brewski didn't get right either um and so I think that actually is probably the most important thing is because nobody knows what bootstrapping is anymore um so that's that's what I would say is is is we need to have a top to bottom assuming it's 20 22 and not you know those document's been sitting around a long time and I think it's okay for us to say that we had these old terms and that uh we have some new terminology that um is there so I'll be happy to send you some pull requests and stuff like that but I think we need a working group wide consensus to change the title of the document so uh thank you Michael uh just a quick note the the the title was was already changed so now the title is terminology and processes for initial security setup of iot devices bootstrapping is actually removed from from the the new title and uh what I would just say is that we"
  },
  {
    "startTime": "00:12:02",
    "text": "try not to uh Focus or favor any of the specific terminologies but we just try to to review the different terms that different protocols and standards used sometimes interchangeably like bootstrap in provisioning so if if we do not mention boost shopping maybe the process cannot be understood when we read some of the protocols right so in some in some protocols or or senders bootstrapping is used and others provisioning onboarding enrollment Etc so what I'm trying to say is that that that actually people have come to some consensus about what the different terms mean and that provisioning is not onboarding and that provisioning has a very specific thing and so I think we need to walk through the document and we need to rewrite it like even in section two it talks about DPP has bootstrapping information and it doesn't it is provisioned with onboarding information right and I think that's just really important for us to get to get on top of that and I think that's actually the major contribution of this document is to nail down those terms for everybody okay thank you yeah I I would uh just add that uh we we can recognize industry terms and of course should be using them we're we're useful and we also have to keep in mind that industry terms are not always very sharply defined and where we find that an industry term actually is ambiguous that we may want to Define uh some of our outer of our own terms our qualify the industry term with another adjective or something like that to make sure we have really well defined Towers but I agree with Michael that getting the"
  },
  {
    "startTime": "00:14:00",
    "text": "terminology right really yes it's a major part of this document okay thank you very much so as as Michael commented if you can please uh maybe through the mailing list or apple request and so we can we can uh Focus the the work uh from this point on thank you great thank you Dan and thank you everyone for the comments so I think we have a good Way Forward here then moving on on the agenda so now we are finishing the intro and RT status segment next we have a segment coming on security topic so your answer will start with update on secure work and your Matson will continue on on the update on the application attacks using Co-op and then finally Michael Richardson we can update on the tax annoy operational security considerations for manufacturing install keys and Trust anchors work after the security segment we have a semantic interoperability segment where microcluster will start with the One dmit schemework update followed by Carson with an update on SDF and then Jan Roman will talk you a brief update on the w3cb of things and talk about his work on SDF of things conversions and then finally Ali and bean will give a talk about their work on knowledge graphs for iot platform digital twins based on SDF and then around 1725 UTC we should be wrapping up and concluding the meeting any questions or comments on the agenda for today okay in that case let me share the slides for yearn and urine you can go ahead in a second hello can you hear me"
  },
  {
    "startTime": "00:16:04",
    "text": "can you hear me yes we can thank you okay so this is uh this will be short um because I don't have so much update just informing you about the new uh topic the new activity called Secor security for constrained restful environments or or if it had been Italian uh it could mean dryness or secure or something like that so that's um so I only have one slide please go to the next one actually you should have a control now it says hurricane slides here but I think I have control yes thank you so uh as I mentioned this is a new activity we have got some good feedback but we are still looking for drivers or uh what we might call pen holders for the topics it was basically taking some sort of administrative responsibility for for the progress of the work and and we have had in the previous meeting we went through a number of different topics and and there are some topics which has raised some some more interest than others there is already the ongoing work about amplification attacks which John will talk about next but there are also two candidate topics which seem to which is has more ideas attached to it and we'd like to get back to in a later meeting and one of those deals with software update using Co-op group communication so it's the idea around how to make software update more efficient using multicast or other group communication mechanisms"
  },
  {
    "startTime": "00:18:02",
    "text": "and the second topic relates to delegation of Rights in in particular in the case oauth setting so that's also an interest uh interesting topic and which we didn't cover in in the Ace work and which might benefits from first a research activity so those are are two topics where there is some ideas already and we're just waiting for people to have time to be engaged in this and and bring it uh forward to to the working group and if there are other people who are interested in some uh some other topics either those uh in the list we discussed last meeting or some other topics related to the topic of this working group and also fitting into the charter of t2tg RG that's of course welcome so um yeah please uh please join the work any questions or comments okay then I'm done thank you thank you joran maybe one quick question like um would you expect there to be a follow-up meetings um sometime in the near future and what's the right place for people to hear about them is it notifications come to the list or what's the best way I think the idea of having um meetings somehow relate in the same Pace as um as the ITF meetings either before or after or during I think that's a reasonable attempt for given the commitment of other people who also are interested in this area but don't have the time to to contribute so that's that's my expectation uh so in terms of but if other people are"
  },
  {
    "startTime": "00:20:00",
    "text": "interested in in driving some some things we can of course have more frequent meetings great thank you thank you any more comments or questions here okay then let's move on next is yon to talk about the about the application attacks and um let me pass the slide control and you can actually request to share the preloaded slides yes see there do you hear me how we can see them we can hear and we can see your slides thank you yeah great I had some audio problems but for some Network problem I switched to mobile networks but I will not use any cameras so hopefully the audio will work fine so this is follow-up presentation on the amplification attack game draft so we have submitted a 0-2 version uh no no one a month ago or so with basically fixing all the comments and issues known at the time a lot of some editorial work updated some references updated some text in the in the or in the draft that was better written in the slide for the last thing to think RG presentation and then addressed some comments from uh"
  },
  {
    "startTime": "00:22:00",
    "text": "from Achim to how calculation of the amplification factor that yeah depending on where in the stack you calculated you you might end up with with different things he has some clarification that you need to you might get different things but depending on where you calculate them sometimes it may one option makes more sense than another uh then there was some some error in the in the draft received from attacker is is now stated instead of sent from the attacker then we have after zero two I'll do it there uh received quite a lot of new comments on GitHub uh there's best requests from a researcher that wants he he wanted implementations of the amplification attacks until several emails that this is smoothly a theoretical work that's quite it has to implement it himself but that is quite easy giving him links to to different Co-op implementations and explain how to high level to implement it then there are quite a lot of good comments I think most of them hopefully quite small from aquim that will be handled for the zero three draft there's some some explanation and some corrections that needs to be done in in the draft uh maybe the biggest thing is adding proposals for mitigation as a there are some text on mitigations right now but"
  },
  {
    "startTime": "00:24:04",
    "text": "probably not enough [Music] uh high level what's the future of this document I what we have seen quite gotten a lot of quite a lot of good comments and issues about like small technical details having important question for the for the research group is what is the long-term goal and scope of this document my my own view is that should raise awareness of iot amplification attacks in general and as pointed out why it should probably also talked about about mitigations as much as we know a question that could be discussed is whether it should discuss known amplification denial of service attacks I'm I don't know probably not but if there are material then why not but this is is typically involved hacking devices and so on so it's quite a lot quite a different attacks than amplification attacks amplification attacks is also something ITF can mitigate with the protocols um hardening devices is different um thing and then the fourth thing that is should the document include concrete information about actual attacks um there's previous well definitely discuss this it was important part of the discussion why this is important uh there was a request for newer and more concrete information about the actual attacks we have tried to make the information a little a little bit better but the reality is that there are little new and concrete"
  },
  {
    "startTime": "00:26:03",
    "text": "information out that information give them by various security companies monitoring these kind of things are very limited and some of the media reporting things are maybe more confusing than helping it's very easy to see that some of the uh one suggestion would be my CSA to maybe completely remove this part from the draft it's maybe more confusing than helping um some other comments from also relate to actual attacks from is to not painted to paint it black maybe especially regarding Co-op um I think removing these things about actual attack is First Step could also maybe make the high level document less core focused the current title is amplification attacks using Co-op I think the main goal of the document is maybe to raise awareness of iot amplification attacks in general um so I think maybe high level the document could be less core focused I think the examples are probably on most of the examples are probably best to keep in Co-op that's the most relevant uh ietf iot protocol and then I think the document is in a quite good shape so maybe a research group adoption and that was my short presentation"
  },
  {
    "startTime": "00:28:00",
    "text": "great thank you John any questions or comments on the on the craft so far um well think about your question comments what we're thinking of is doing a show of hands in the medical Tool uh for those who think we should be adopting this documents now you should actually see it in mythical um okay so this is a for a question who has read a version of this document and you can either click raise hand or do not raise hand okay seems so we actually have quite many people I see six raised hands uh in in mythical okay thank you everyone for answering on that poll so should we do another one um on this is quite a few have actually read it what's your take on adopting okay so now you have another pollen going um please raise your hand if you would be in favor of adopting the document and as usual of course this is just the first version of a document that will be then continuing working together in with the whole research group yeah so there are actually several ways in which we can adopt um a documents so we we can actually achieve uh research group consensus so we we all agree on on what's in the document or we can simply agree that this is useful information uh to have published even if we don't necessarily agree with all the details"
  },
  {
    "startTime": "00:30:01",
    "text": "um I think we can decide what we want to do uh when the document is already adopted um but my take of the discussion so far would be we should be able to to get a research group consensus on this which will icon which I will I continue to believe until we actually get this agreement so I'm ending the poll in three seconds okay so we have eight people in favor of adoption uh one uh hand that was explicitly not raised and for this I actually would be interested if you want uh can you tell us why you you don't think this should be adopted by the research group so that this is an anonymous call so you are very much free not to answer my question but it would be interesting uh to hear the answer and as as you as well feel feel free to comment on the list or if you wish directly to the chairs if you have any thing you need to comment on and of course we'll confirm the call on the list as usual it seems that we have a quite good support for on working on this topic okay thank you John thank you everyone uh any more comments and questions here before we move forward"
  },
  {
    "startTime": "00:32:01",
    "text": "okay then next we have Michael Richardson Michael would you like to request sharing or do you want me to initiate so uh you have the slides and you can give me control yes I can do that cool and now you should have control okay um thank you um so I'm gonna make this quicker I thought I had uh was expected to provide more time so I made so many slides thank you for the extra time uh so I've had this document um and uh taxonomy of operational security considerations for manufacturer installs keys and Trust anchors it's quite a mouthful and I would be happy to shorten it if people had a good way of shortening it without losing detail um anyway um so history of the draft so it started in uh 2020 um it actually is first of all was in this document this animate document called Master considerations where I felt needed to give some advice to uh Enterprises or manufacturers about how to build their um idav ID their 8021 AR Keys um and people have been asking for it and the other thing that I experienced in 2020 was that there was a fair bit of um pushback on things like brewski and now actually matter has the same issue and DPP as well about whether or not manufacturers would ever actually put birth certificates in their devices and if they did could we ever trust them to have gotten it right um and specifically uh there was basically a lot of cynicism that these Keys would actually ever be kind of secure in any way and I was surprised by that considering that we've had you know workshops security workshops and iot that I think the Paris one I think is 2012 is that"
  },
  {
    "startTime": "00:34:01",
    "text": "really 10 years ago when we heard from various entities that they were putting idav ID keys in there um VoIP phones for you know more than five years already so at this point now we're talking like it's 15 years ago that people started doing this um and the other interesting thing was that I came to realize that a bunch of people that were pushing back on this didn't know their companies already did it so you know oh we couldn't possibly do this and it's like well actually you're doing it and the reason why it turns out that people don't know about this is because this process is all shrouded in in secrecy of of ndas and this kind of thing uh so this document evolved um and uh we went to six SEC dispatch at ITF 108 in the summer and SEC dispatch says please go take it out to Industry talk to people find If people really relevant to this really get this um and then uh the suggestion was to bring it to the t2g RG um in 2021 and we did some presentations in 2021 um and there's now been about I've probably done about 10 presentations uh to various places some of them quite big groups um and uh some quite privately uh with a fair bit of nodding um and in fact um one or two manufacturers uh that say you know I have dozens of ndas with customers and I can not even discuss with customer a how they could simplify things by doing a customer B did because of course both of them are under NDA and they can't talk about them and they were kind of saying well if only I could refer to some external source that was public uh that would allow me to say well could we simplify this and what terminology could we use and and then everyone might actually be able to have a you know fewer code paths and so there was a fair bit of of interest there and there's also some work happening at nist right now um to kind of write some of the processes that some of these people are doing down in actual more detail uh"
  },
  {
    "startTime": "00:36:01",
    "text": "rather than what this document does which really is just um to provide some taxonomy um so there's some images from the talks um there's some links here if you really want to go see the talks again they're linkable there and uh that last set of talks the same talk but in some cases there's three different videos of it that'll be up um so you may remember this um you know remember that time we did that I'm not going to go through the content but non-goals of the document okay so this is not an ISO 27 000-ish or 14 000-ish evaluation process I'm not going to tell you in this how to do your auditing okay um and uh not the goal of this document is also not to say what is more secure what we're actually trying to do is simply say what is and and that's the the really the the first part right so we want to say you know what um this is what you need to go this is a certificate we have on appliances in Canada uh tells you how energy efficient or not they are and you can see in this example it's far to the left it's really not very energy efficient and you know what that's actually sometimes okay you know what you're okay with buying a cheap refrigerator uh or um microwave that you don't use very often and so the fact that it's energy inefficient doesn't actually matter because you hardly ever use it so what we're kind of looking at is this is just the numbers here and you know this this Cheetos holding the uh uh closet shut you know what that actually might be an appropriate level of security for uh some class of devices and the only important thing is that you recognize when that's what you're buying and when you're buying something super more secure you recognize that and you see that there's a difference in the price and that's okay because they can tell you what the difference in the security is in a reasonable way uh one of the things that comes of this document is a way to count a number of"
  },
  {
    "startTime": "00:38:01",
    "text": "pki levels I'm not going to talk a lot about that now how is the key generated still unhappy about some of the naming I'd like better names no one's come up with a thing everyone seems to hate the third name but I don't have a better name at this point um and then how do you deal with um descriptions of business continuity about uh secret sharing what do you publish and what do not publish um and what I believe that the answer is is that we're gonna you're gonna say publish n minus K as the as a something that you can share without actually telling anyone n or k so if you have seven pieces and you need four of them to reconstruct a key then the answer is you you have this uh you have a redundancy of three which means that you know it it also is a little bit like people might say bus count which is how many people you can lose from your team before your project is unviable for that um and there's an example right of what people were talking about you split off these keys they have different pieces that go different places and you need to know how many there and one of the conclusions is that um you might never even publish the list uh of who has the keys externally obviously but you might not even tell the board of directors okay that that actually also might be something that that you might not do but it's not really our problem but you think about about the different situations but how that's going to work so next stop and get documented document adopted there's some wordsmithing and maybe some bike shining over some terminology that I would like to have happen um I think we need to talk about the resulting terminology widely um and we need to listen to while we're talking we need to listen carefully to the Expressions on people's faces and see you know where there's still some awkwardness uh or some disagreement or something like this and figure out what that is in there and I'd love to publish it in late 2023 that would be my schedule and goal"
  },
  {
    "startTime": "00:40:02",
    "text": "good enough great so as we said we really are in need of stable terminology so this is really an important contribution this document can make and I think by actually phrasing it as a terminology document uh and and less of an evaluation and recommendation document it will be easier for us to actually achieve a research group consensus on on actually publishing uh this so I'm I'm going to ask the same questions again so who who has read a version of this document a lot of people have not then have so far um so Michael would the current version be a good version to read or do you want to make sure so there is an update that was done just before the ITF I think it was um and um that version is pretty stable and very happy with it um and um there's you know there's still some gaps in it um but um I I think it's 90 92 percent of the way there okay so we can recommend uh reading that and actually we could underscore uh the the need to read this now by actually going for a call for a research group adoption so of of the people who"
  },
  {
    "startTime": "00:42:00",
    "text": "actually have read uh the the thing who is in favor of research group adoption obviously we will have to complement this with voices uh from the mailing list so everybody who has read it plus one more are in favor of research group adoption oh wow okay that gets better and better six okay so this looks like we have strong support for doing this and uh we we should actually issue the the call for adoption on the the mailing list with this as uh input and get people to read and review it thank you thanks great thank you Michael so very good progress also here any final questions or comments on that topic before we move forward we're actually nicely on time even okay so next we have moving to the semantic interoperability segment and of course we have Michael Coster and the 1D and IIT schema update so Michael do you want to request this sharing or should I share I only have two slides so if you could just do that that would be fine yes and I can pass you the control we have an update on the one data model lies on organization and also iot schema basically the organizations that are attempting to capture industry data models and publish them in a consistent format so go ahead and show my next slide please"
  },
  {
    "startTime": "00:44:00",
    "text": "yeah I passed you the control so you can oh you did um okay so all I have to do is find it yeah in the bottom of the slides you should have the control yeah you can just press there it is there it is never mind okay so one data model we've been going for a while now and I think I without giving people a lot of unnecessary background the focus of the organization we've really shifted in the last years of the news is that we rather than driving toward model convergence and coming up with a single model for how everyone should model A light switch or however we should model you know a pressure transducer or whatever we've basically recognized that the industry isn't really ready to go do that at this point anyway and that's that's a lot of work and a big lift and and we're going to move that into the background what we really need is to get more contributions and you get people to sort of you know build out that first step where we have now almost a standard language we have SDF which is which is almost there and we'll hear more about that later but basically to get everyone to bring what they have in this format and uh and then work on the convergence from there and that will in in really two ways um so we're basically giving uh opening up so that people can create their own uh repository in the one data model space and use the CI tools and basically enforce a set of common practices and common patterns on top of that so that's kind of what we're working for right now and and the technical work is focusing on the semantic proxy and mappings and binding so I guess you'd say we're we're sort of looking taking a more long-term view of the model harmonization approach to get everyone to use the same model and that will probably happen over time but that will be make it easier to happen if we"
  },
  {
    "startTime": "00:46:01",
    "text": "support translation and semantic proxy and mappings and bindings and so that's that's really what the uh where the focus is um that's really the big news now we've um we've got this set up already so anyone can come and open up a repo and start downloading their their models and we've done this already with Oma and OC after those those two organizations are pretty pretty far along we're just starting on Bluetooth and initially we're we're going to uh look at modeling the characteristics and the mesh device properties which are both uh I guess they're non and IPR encumbered they only have copyright rules so we don't have to worry about the next level of agreements and publish them and um they're they're basically data models so that they but but with Bluetooth mesh them embody a lot of the semantics of what's happening in the data types so it's a it's a I think it's that's a good direction and we're also reaching out to CSA to matter now that they have launched now that they have uh they're calling their data model dot dot so originally dot dot was going to be this zigbee cluster Library over IP networks but now they've sort of branded their the data model is dot dot it's still plan to be open but so we're reaching out to them to see how we can work together to um you know whether whether we're going to publish that or exactly how that's going to to work now that we have all these tools we can offer a low bar for them to participate in the using SDF to model and currently they have XML and it's based on a lot of earlier tool sets from zigbee so I think it might be a good thing for them to to look at but we're still in the reaching out phase there um and the third thing that's happening I think with one data model of note is"
  },
  {
    "startTime": "00:48:00",
    "text": "that we're looking at broadening things out now that we have anyone can just come and add models we're looking honestly I think digital twin models and the the use case uh we're focusing on really looking at whether we have everything we need to do that modeling and I think the big gap appears to be sort of how do we model relations and links and things that that are coming from ontologies and graphs and so we were really building out our use cases for SDF to support both abstract references in the modeling and links in a in a body graph that uses the model we have some dtdl Azure dtdl uh I guess interworking that we're working on to to test some of this out but we're looking for some other use cases you know we'd like to do uh OPC UA and some find some other people who are using and and I've privately done some similar modeling myself that I can't quite share yet but there'll be some public stuff coming out at some point um I think that's that's pretty much the three main points uh for one data model but I'd like to open it up and see if uh Audi or Karsten or some of the other folks Jan have been participating in one data model have anything to add to that or if there are any other questions or comments okay well if something occurs to anyone please just speak up um you see Milan is unmuted okay I'm along please yeah I I can contributive models but with what intent is it for 1dn to then map them to"
  },
  {
    "startTime": "00:50:01",
    "text": "a common model representation or simply to have a view of what's going on out there and just uh easy to increase awareness or is it to map them to some common format yeah yeah thank you the expected outcome of this is to um to first get people to participate in a common modeling activity in a way that doesn't require that they change any of their models so it's there's there's a a sort of a lowering of the bar um but also I think that the the technical outcomes since we're focusing on the semantic proxy and the mappings and the bindings it would have what we're expecting and what we'd like to drive is that we have a way for any model to use SDF and the common patterns that are already in the repositories that people have contributed and the the layer of translation and mapping tools to to to practically to do a practical implementation of interoperability and interworking using mapping and binding instead of trying to go straight to a converged model so this will give the ability for say someone who is using um let's just say a Oma to try out some of the ocf models to try out the Bluetooth model so it's basically opening this up for people to adopt each other's models before we try to adopt a common set of models okay thanks that explains it and in the meantime people will have the ability to publish their models in a Common Language and it'll reduce the the burden of some of the tool sets you know the question do we use XML or rdf or whatever well they're you know there still are those choices but um if SDF provides a reasonable alternative we think that will be uh easier for people to adopt also"
  },
  {
    "startTime": "00:52:01",
    "text": "okay any other comments questions please all right well let's let's move on um I'll give you a quick update on iot schema .org we started iot schema.org with basically the same idea to capture the the i o the information models that uh vendors and other other participants in iot were using to represent their device affordances that how do you read temperature from a device Etc how do you turn the light on how do you change the color of the brightness of the light um so we we created an rdf framework that basically follows the property action event pattern that we use in one dm and also we're using w3c thing description and a lot of common models as as we have in our sort of landscape we see that events actions and properties or some abstractions of those are very very common in all these models so what we have in iot schema.org is a small useful set of of example models for sound levels and motion sensing and lighting control that have been used with w3c in in different plug fests and they they do map back and forth to and from sdfs based on um a path model so which when in SDF we have consistent paths and that basically or in one dm with SDF we have consistent paths and that basically will give you the identifiers you need for mapping to RDS but um I think that the the real interesting thing is if there is an rdf framework we don't have to create as many different models to adapt to different rdf systems the expectation and and rdf is more that you'll import a model as it is and then reason about it to do whatever kind of you know integration into your other model so um that's um that's an interesting point that we"
  },
  {
    "startTime": "00:54:00",
    "text": "we need to look at and see how how we could deliver rdf models across the space and maybe it's through translating SDF or something like that but iot schema.org we're leaving it up because people are using it and and using it as an examples for semantic annotation and thing descriptions but we're there really isn't any governance it's ad hoc and the development meetings are paused we add models as people need to to do their demos and and think TD interrupt uh blood tests for w3c but um you know there might be some some future there in making it a w3c community group we started that activity at one point but um right now it's just sort of a I guess uh an experiment that that was moderately successful but doesn't really have a lot of legs because you know there are probably other ways to do this that people are more interested in doing with with one data model and things like that so I don't really have a future forward plan for that but just where it is we're going to keep it running and it's only a little bit of uh a server that runs and and a domain registered and stuff like that but basically we're not going to try to integrate it with fema.org because fema.org is more about higher level business Concepts and not about device affordances and I think there's a pretty clear dividing line there if if we do end up producing a higher level iot conceptual model that might be appropriate for schema.org that's a that's a different thing okay that's that's all I have we need to move on any questions comments yeah I would I'm wondering whether we can get those uh models translated into SDF and include them in the 1dm playground that would be an interesting thing to do to do the other direction translation I would look into that thank you"
  },
  {
    "startTime": "00:56:04",
    "text": "other questions comments then I will I will yield okay thank you Michael just no more questions or comments on that um this next time up is Carson and SDF update and status go ahead Carson thank you so I want to give a really short uh uh look at SDF I think many people who are in this meeting know what's going on there but maybe it's interesting to see my view of what's going on there so um just to remind people SDF is the semantic definition formed it started out as a simple definition format and of course you know that that nothing stays simple over time even though I still think it's pretty simple for what it does and the the idea is to look at the thing an iot thing and look at its digital side not not the the um a real world site not the physical side but the digital side and describe the interactions that that the device can do in terms of affordances and as as Michael has mentioned we have this property action event uh uh now I need to reuse the word model that we have way too few words in this space um the scheme of of partitioning these affordances into the three different kinds uh which seems to work reasonably well and we are following uh that as well and we are providing some way to assemble the affordances into things or actually classes of things because all"
  },
  {
    "startTime": "00:58:02",
    "text": "of this is at the level of classes so this was originally started by wandian and uh 1dm submitted the protocol or the the specification on how to write these uh models to to This research group and we worked on uh getting an iitf working group uh working that that now is working on that we have a pretty stable Dash 12. uh there are still a list of issues that we need to work on and I don't think going through these issues will take long um but of course we also have a few uh items that that are really defining something that we have been calling SDF next so we have to think about ways of of not having to wait for the entire world to to come to a stance before we can ship the RFC um so this is what we are doing right now and of course this is not just specification work but it's also work on tools uh and we will here talk about one of the tools uh later today uh there is a tool for converting between Yang uh and SDF for the ITF Yang specification is used for uh talking to network elements but there's nothing fundamental that limits it to that um so uh it's useful to be able to translate back and forth and the the main point of having a common uh semantic division format is that we can have converters that convert from into a lot of other ecosystems like and we have them for Uma or CF dtdl uh What uh"
  },
  {
    "startTime": "01:00:02",
    "text": "whatever things um and um we have used these converters to populate 1dm's playground and that's certainly an activity that will continue in uh parallel but of course it's not the working group that does the implementation so we are just working with people who usually have an implementation cooking somewhere um so talking about uh how we will uh actually get SDF next uh going um there are several documents out there right now that describe various um extensions or alternate views at the um this space one is just a different Syntax for SDF that that is actually meant to be used by humans so it's not based on Json but um uh yaml but also does some other uh ways of reducing the noise in the specification um so this this has no functional uh component to it but it just makes it easier to write a spec on the Whiteboard or keep it on on one side when you talk about this um the second one is the SDF mapping document that describes a way uh how an SDF model that exists can be augmented by adding to this model usually by adding additional qualities qualities is the weird name we are using for properties of the model um because the word property already means two things in this space and and using it for a third thing doesn't help so we call them qualities"
  },
  {
    "startTime": "01:02:02",
    "text": "um so this this is uh uh relatively simple approach right now uh and what we really need to do here to complete this is make sure we are happy uh with uh the Simplicity of this uh document whether it actually can solve our problems uh nicely and then we have two uh documents that talk about talk about links uh one is talking about Links at the model level and one is talking about links as an actual data type tool to be used in interactions that are provided by the affordances so one would say uh here is something about the description of of uh the uh interactions that you can find more information on in a different place um and the other one is about uh hello temperature sensor please tell that thermostat over there uh your your current temperature in a periodic way so looking at these two link oriented documents the distinction that I just made appears to be a very nice and sharp distinction but of course that that's not entirely sure so for uh semantic links we have an example we actually have a unit quality in SDF that allows you to tell what uh unit a specific number you might find in a property um has and uh that's great uh for many models on the model level but then of"
  },
  {
    "startTime": "01:04:02",
    "text": "course there are um ecosystems that actually provide units in their interactions so an Oma device might tell you its unit and it might even provide a way to switch between Fahrenheit and and Celsius or something like that so it yeah it's not as clear-cut as as um it seems but anyway we do have these model of links already for reuse and composition that's called SDF ref and uh we probably want to do more things than than just gluing um SDF models together uh so that's why we need more uh relation types than than just uh the the one that is implied by an SDF ref uh quality on the the insurance level uh of course we need a data type because the information model has to model uh the the data Exchange in the interactions and that data model is based on RFC 82 ADH web linking so it's pretty straightforward and what we now have to find out whether the the the statements we can make at the model level about what the values of these links will be you can actually expressed in in this generic data model in a way that that makes sense so what what we really need for for the continuation of this work is appropriate examples and and trying out the mechanisms whether they they do the right thing and that's uh where I hope uh we will get some some input from uh This research group more generally we we are talking about"
  },
  {
    "startTime": "01:06:00",
    "text": "extension points so we can wrap up SDF base an stf's based specification and as I said this all results revolves around qualities um and uh it's extending SDF can be as simple as adding uh qualities and then you of course need to to manage some namespaces uh there may be General stf extensions there may be ecosystem specific one so we have to Define how uh this uh should be done this is currently just an issue on the SDF uh spec but it seems relatively straightforward to Define this so this will be one of the things to be done next and yeah then again we want to do verify validate whether we are doing the right thing here so that's simple not so simple is actually extending the architecture um so for instance web of things has something called protocol bindings um we we currently put these into mapping files but that doesn't really answer the question whether the protocol bindings are can be described in a cross-ecosystem way and of course there are also other kinds of ecosystem info for affordances so we can put these into mapping files that that's the easy part uh the not so easy part is how do you actually go one one meta level above and say by the way a mapping file for Bluetooth typically looks like this or the mapping file for Oma typically has an Oma object ID somewhere in it so of course we can write this in English but maybe we want to have some some form of uh automatic processing"
  },
  {
    "startTime": "01:08:02",
    "text": "there as well and we don't have an easy way to to uh generalize class level information for entire things or our parameters for affordances uh so how do you get from a product line uh description to a specific product description and so on um yeah some some interesting questions there uh which again where I hope the the research group will help and uh finally there are all kinds of other information that go beyond uh just providing a description of the affordances such as purpose in life um information uh part of which which a device needs to know but part of which actually is outward uh facing and there's also uh deployment information such as location a device doesn't need to know its own location um so that that may be somewhere else but then we need to properly link this together in a way that actually is not brittle um and links to other things uh where SDF type link already does something but is that that all we need and more generally uh we we seem to need uh locating uh things at the class level uh modeling the instances but we also need to have a way of actually describing what what's going into a specific instance okay I think you you will see some of this in the the next two uh talks so I actually want to stop at this point but if there are any immediate questions we should feed them now"
  },
  {
    "startTime": "01:10:03",
    "text": "foreign and I guess for all of those interested in more details um you're very welcome to join the 1dm and ASDF sessions okay one VM we have bi-weekly calls and an ASDF will have an interim coming quite soon yeah I think we have a doodle up for that interim in January so just look into the SDF mailings okay very good then we are slightly over time now so maybe we then move forward so next we have Jan and with the a lot of things update and about work about the SDF web of things conversion so young should I share your slides from here and pass you the control um that would be great yeah thank you just a moment and now you should have the control uh yeah yeah it should just work great yeah thank you and uh hello everyone um yeah my name is Jan I'm a computer science student at the University of Bremen and in the following I want to present my results um yeah I've obtained from my bachelor's thesis which dealt with the conversion between SDF and watch data models namely thing descriptions and the newly specified thing models but first I want to yeah start with the update on the specification process in the watch working group and yeah because Michael May correct me if I got anything wrong here but yes you might know um currently there's the second Charter period of the watch a working group which will last until the end of January however there's probably going to be an"
  },
  {
    "startTime": "01:12:02",
    "text": "extension by three months and due to some delay in the publication process um there are three documents which are going to be published um in the first half of the next year namely um 1.1 versions of the thing description and architecture specifications as well as a new discovery specification which specifies methods for obtaining thing descriptions and yeah discovering things based on their TDS and um yeah um from what I've seen um there's going to be the transition to candidate recommendations for these three documents um later this week and then in March there will be the transition to proposed recommendations um and eventually yeah there there will be published as recommendations and web standards by the w3c if everything goes right um then there will be a new Charter beginning in May um where first of all uh postponed document from this Charter period will be published uh profile specification which yeah specifies a profiling mechanism for GDs it's also a basic HTT HTTP profile and yeah um in this Charter period there will be a new delivery boards such as a 2.0 version of the HD specification but also on new deliverables and new topics such as a stronger focus on protocol bindings however the actual topics are still being discussed and yeah this discussion is going to be finalized into the mid of January and yeah you can find the current"
  },
  {
    "startTime": "01:14:02",
    "text": "publication schedule as well as the discussion on the new Charter topics in the what in the in the main word repository on GitHub but also for example on the watch in the word Wiki the w3c yeah coming to the actual topic of this uh the main topic of this talk and the mapping between SDF and what and the conversion I first want to the brief motivation for this uh conversion so as you probably know um both what and SDF are dealing with improving the interoperability and the internet of things from different angles so SDF primarily focuses on improving the probability between ecosystems and the data models by providing uh Universal universal language which can be used in conversion processes and what you de primarily focuses on improving the interoperable interoperability between individual device instances and yes they both cover different parts of the interoperability problem in the interim of things they both complement each other quite well and yeah this makes OCD an interesting conversion Target for SDF however there's currently not a canonical mapping between the two data formats or specifications yet and my thesis uh yeah water to propose a first first proposal in this regard and also provides and convert implementation which can automate this process and yeah so um in contrast to other formats such"
  },
  {
    "startTime": "01:16:02",
    "text": "as Yang the conversion between SDF and what GD or what data models is relatively straightforward due to a number of similarities for example both use Json as their civilization formats or from the document formats and they both use similar Concepts namely for example interaction performances for modeling the capabilities of things so properties actions and events as Michael is already mentioned and they also use similar terminology terminology inspired by Json schema org for data schemas and data qualities and these similarities can be Illustrated um yeah with this simple example um so on the left hand we see an SDF model containing one SDF object describing a smart lamp with one status property containing Json SEMA inspired schema information indicating that the data type used for this property is a string and we also have some human readable metadata namely a label the object level and a description at the fonts level and as we can see on the right when trying to map this to this information to the thing description we can um yeah we have a similar structure so the label from the SDF object can be mapped to a title at the GD level or the top level of the TD and the property from the SDF model or the SF object can be mapped to property at the thing in the thing description containing a"
  },
  {
    "startTime": "01:18:02",
    "text": "similar information however we can also observe two major differences so on the one hand we have Json ad context at the top of the theme description so every thing description is also a Json IDE document and also we have instant specific information in the description namely a security member at the GD level and forms member at the property level containing protocol bindings which cannot be expressed in the ssdf model itself and yeah this raised two questions um the first of uh which being um yeah how first of all how we can map the uh what specific vocabulary which is the F and for this I mentioned I used a concept already mentioned by Carson um the so-called mapping files which uh allow for the augmentation of the SDF model so on the left we can see the same model as before and on the right hand side we have a map object within this mapping file or Json Json object that contains Json pointers which indicate where the state of model on the left uh is being augmented with the what specific vocabulary and yeah from this these two documents um yeah was possible for example to create augmented SDF model which could then be converted to what what data model in the other direction there was the question of how to map SDF models um and themselves to what um that abstract and contain no instance specific information since the forms and"
  },
  {
    "startTime": "01:20:03",
    "text": "the security information is actually mandatory in thing descriptions and it has to be provided and to solve this question or this problem it was possible to use a New Concept called thing models which are near superset of theme descriptions with fewer constraints that allowed to omits the instant specific information while only requiring um the addition of uh and Json ID Edge type annotation indicating that this is a thing model and yeah this allows the mapping of abstract SDF models to get to the word ecosystem um on a high level the conversion process I've used um looked like like this so as we can see here the thing models are actually acting as intermediaries between thing descriptions on the left side and SDF models and mapping files on the right hand side so um due to the fact that thing models are almost supersets of thin descriptions and it was possible to only specify the conversion between SDF and thing models and on the other hand the conversion between descriptions and thing models and then gets the conversion between TDS and SCF models as a cover Library as a result and yeah this um enabled me to cover all three types of documents um with only yeah two real implementations so to speak uh yeah another aspect mentioned or displayed here in the uh in the figure"
  },
  {
    "startTime": "01:22:01",
    "text": "is that thing models can also be augmented with additional information um yeah but this is uh that's uh yeah a lot relevant for the rest of uh there's a talk um yeah besides the um problems I've already mentioned there have been a number of additional challenges during the con for the mapping and conversion so um for example um SDF and what use different approaches for nested models or composition so and what documents we actually have a linking approach for creating hierarchies while in SDF as you might know we can express hierarchies in a single SDF model using the SDF think class and eventually it was possible to map these two approaches to each other after making slight adjustments to the state of think class and the SDF specifications um however one challenge was that um it's it's currently not intended to um have a self-contained documents containing multiple nesteds TMS or TDS and therefore I used an experimental approach called TM otd collections uh where the linking relations are expressed using Json pointers um yeah so this is actually one thing where the what specification might uh be improved in the future and another challenge was of course round tripping um so um this yeah converting from what to SDF this was relatively easy using mapping files put in the other direction it was"
  },
  {
    "startTime": "01:24:00",
    "text": "necessary to use certain additional keywords prefixed with SDF and um yeah this is uh definitely something that has been has to be Revisited when making a more formal specification of the conversion process or mapping process and um yeah another challenge for round tripping of course was um when external references have been used these have had to be resolved before converting documents to the other format yeah um as I mentioned I implemented this mapping or conversion as a software using using the Python programming language um I published my converter as a library to the python package repository Pi Pi um so you can simply install it using the package manager and obtain both the library and an in the CLI tool contained within within this Library so you can either use it from the command line or in your own python project I also created a web application where you can experiment with the conversion between SDF and what models currently this is hosted on page on a website called python anywhere but I might move this somewhere else eventually and the convert is also featured in the conversion tool collection compiled by Petri so you can experiment with the conversion between different formats including what TD and compare the results and yeah I'm always grateful"
  },
  {
    "startTime": "01:26:02",
    "text": "for feedback or any issues that have been raised to improve the incubator um yeah and to draw a short conclusion um So eventually it was possible to map what a data models in SDF to each other quite well um I used some additional Concepts such as mapping files for this and as it turned out what thing models could be is very well as intermediaries in this process as an artifact I obtained or I created a flexible converter implementation in Python which can be used as a library CI tool and also a web interface or throughout the web interface however there's still most energization work in research needed so there should be some kind of canonical mapping specification in the end and it has been already mentioned and the question of how to map the linking approaches used in what is also still an open question so this hasn't been taken into account yet by me and um yeah so last Point um yeah there was also the there's also still the question of how to deal with nested TMS and TDS and how to include them in a single document yeah and uh this was it for now I'm looking forward to any questions or discussions but I suppose you probably need to move on at this point excellent thank you John we are slightly over over time but only only a minute or two so I guess we can have a one or two quick questions if anyone has here"
  },
  {
    "startTime": "01:28:03",
    "text": "my quick question would be like um when when and where can we read the thesis to get more in the details of your work um it is uh almost ready to be published so um yeah I need to make some minor revisions and yeah maybe then I can send a link around so then you can have a look at the document that would be great thanks okay and we can take the there are no immediate questions but like follow-ups um I guess in the 1dm ASDF work oh I see Milan in the queue go ahead and run thank you you can go ahead and unmute I think you can get operational terms what is the objective of this work is it to prove the feasibility of doing the conversion or is it to service the basis for some automated tools that will do the conversion I presume at the design time this is a bit heavy to do at runtime at the node level but in any case is this a feasibility demonstration objective or is it to create a tool for a conversion tool uh so creating a conversion tool was uh certainly one of the objectives but um yeah another all of me was to provide a proposal Nation one for yeah or mapping between SDF and what that can or that could be used for this then standardization process so yeah um I think I also demonstrated the feasibility but it was also met as an"
  },
  {
    "startTime": "01:30:01",
    "text": "input for the sanitization process [Applause] okay thank you young okay it's no more for the questions for immediately as I said we can of course continue on on the list and in the 1D on ASDF sessions on the topic but then we have our final topic uh Ali and Bin on the knowledge crafts for iot platform digital twins based on SDF so let me enable the slide sharing and now I'll use it have the control of the slides okay can can everyone hear me yes we can okay yes so then I will proceed to present the project I have carried that Ericsson research we've been shower as my supervisor and this project is a title knowledge graphs for iot platform digital twins based on SDF as re as mentioned so at the end of this presentation is the following first I'm going to give a brief uh description of the background on the research question followed by uh Russell's overview and also a talk about the key enablers of this project and then I will dive more deeply into the projects itself starting by describing the test environment we have used the Prototype and the in the algorithm we have used to measure"
  },
  {
    "startTime": "01:32:00",
    "text": "the similarity between devices and integrate new devices within the graph and we will talk about more in detail and of course we will finish with the future work and a discussion of the questions that may arise so first uh brief description of the background and the focus the project that builds the digital twin using like knowledge graphs which represent manage and reason with grab structured knowledge for this we are using the fields of knowledge representation and reasoning being a knowledge representation based on the representation of knowledge as a set of facts and rules and then we have knowledge reasoning which allows using the rules to stay to discover non-speedly non-licitly stated fast then I guess mostly will be familiar with this concept but we we will we will develop this digital twin uh based on an iot platform and it's a platform where connected devices that Implement sensor and actuators exchange data and then I will one I want to describe the concept of digital twin which is a digital model that accurately reflects the physical assets and it can it's important to differentiate this one to emulations uh because this uh this digital twin usually is built automatically built on automatically relying reliant on automatically built automatically rely on real-time data sorry and has a directional information flow with the with the physical object it models so in our project the physical address assets will be the Real World objects of interest that are connected to the deltoin system and the digital stream will be in this case a Knowledge Graph present in these devices these iot devices and how they relate to each"
  },
  {
    "startTime": "01:34:00",
    "text": "other so there is situation we stated was how to design a knowledge Handler for a digital twin iot device platform so that it enables a story knowledge in a in a knowledge phase query in that knowledge through query language and conduct a reasoning in that knowledge or knowledge base to get non-splicitly stated facts and this first three requirements I usually implemented the building in like the available knowledge graphs uh but then we want to focus on the fourth requirement which is the integration of uh uh new unfortunate iot devices in the in this stream we are going to model of the iot platform uh which is which as I said it will be the main contribution and here we have an example of what could be this scenario so imagine we have a iot platform representing our production line in a in a manufacturing plant so this will be divided in two tasks The Underpants configuration which will be developed by a pickup robot and a piece detector these are iot devices and also the body configuration task which will be the developed by the pickup robot drilling robot and so on so the question here is if in this stream of data in maybe Co-op Co-op or mqtt uh protocol uh if a new message from a device that we still don't have in our graph appears such as this new pickup robot how to how can we interpret this message and integrate this device into the graph of existing devices we have um now I want to briefly describe the results of this project"
  },
  {
    "startTime": "01:36:01",
    "text": "this is divided into three main goals we pursued and the first one was the exploration of the available methods to develop two storage store knowledge in a digital twing and we chose to store this knowledge using the type DB open source Knowledge Graph and then for this graph we Define a domain adapted ontology or schema um using that schema we initial design and initialization of the data we this is the initial devices and their connections based on the physical asset we want to model and this physical asset the uh since we don't have data from a real physical object or asset available we decided to emulate it so the second goal main goal was to set up this iot based test bet for the knowledge ingestion um this is the first you will see divided into the following sub goals which is the Define the iot devices like it was based in iot devices in a simplified automobile production line that can be seen here in the picture on the upper right um then for each of the devices involved in this production line we described them semantically using SDF and these devices are divided in modules which you will be SDF objects which are divided in proper in attributes which will be in this case the SDF uh properties while the modules will be the object objects yes and then we emulated the data generation for each of each of these devices based that depends highly on the tasks they are developing the final goal was the device in integration of the device data into the knowledge graph um for this we Define we have the"
  },
  {
    "startTime": "01:38:04",
    "text": "made the algorithm able to Define each new class of iot device it detest detects which is described by the SD by its SDF file in the schema of the knowledge graph and update this the device they are the attributes of these devices in real time as well as being able to integrate new 14 devices when they appear so for in order to achieve these goals we have so certain key numbers enablers as the first one is the type DB Knowledge Graph which is divided into the schema and the data first the schema is describing the automatological description uh which would be the backbone of this graph and it represents domain specific terminal terminology that defines the objects in this graph and how they relate to each other so in this graph we will have a three main types which are entities which are the objects involved in this in this graph for example in this uh simple schema for a phone calls a knowledge graph we have that the entities are persons and companies and then we have another type which is the relationship which is which are in NRA connections based on roles so for this simplify the schema for another phone calls this will be the contract and these are based on roles which state the the activity of these relations so a contract will have a provider which can be cut which can be played by a company and a customer which can be played by a person and so on this will be similar for the of the relationship of the call that has a caller which is a person and a colleague that's also a person and then they all the last type we have"
  },
  {
    "startTime": "01:40:01",
    "text": "in this schema definition is the attributes which are the actual values that are owned by entities that could be for the person could be a name a phone number a city and an H and as a most databases this type type DB has its own query language which is called query typeql so for today in order to define a schema like this one we will execute the say the this the defining query we have here so for example for the contract we will Define it as a type of relation so sub relation and then it will relate a provider with a customer which I was with over here for example if we then dive deeply into the object The Entity company it would be a sub entity and we play the role of the role provider in the relationship contract and you will own a name then as in another in the knowledge graph we also have the data which are the actual entities uh the under instances and relationships in relationships so for them the basic example of the phone calls Knowledge Graph we talked about before we could Define a company such as Ericson and two persons such as me and John Legend John Legend and then we can also they insert some calls between this person with a certain duration and give certain give specific names to the persons as we can see on the graph on the right then the second key enabler is SDF which you are of course familiar with the semantic definition format and we have used this format to define a semantic Json description of each iot device class which is divided in modules"
  },
  {
    "startTime": "01:42:00",
    "text": "attributes and value type so it like specifies the modules the attributes and value types that each iot device has so this is done with with the goal of understanding each device each iot device as an instance of a class of iot devices which is defined by its SDF description so in the case of an air quality iot device which we which we have here we will have this one will be divided in several modules which are of SDF objects which are temperature sensor they made the sensor the pressure and the air quality sensor and each of these modules which are will have at the same time some Properties or as I call them attributes as as they are calling the knowledge graph attributes which will be the temperature in this case which are certain type and unit and it is also important that since they are defining uh since SDF format is used to define classes of devices they will also Implement uh uu ID attribute which which is uh which whose goal is to identify each instance of a certain device class um so this uh the goal of this SDS institution description then is that each time they we detect a device in the in the Stream of data we are listening to but it's not whose class it's not just defined in the schema so the classes are known we would like query this SDF description and use in the description we will automatically generate a query or defining query with a typeql like that will look like the one we have been blue in the bottom and through this gray we will Define the schema for this specific iot device class inside the"
  },
  {
    "startTime": "01:44:01",
    "text": "Knowledge Graph automatically which will look like we have in the lower right of the slide so now that we have defined the describe the background on the on the key enablers we were going to dive more deeply into the the job done so we will start with by describing the test environment which as I said it's a based on iot devices in a in a car manufacturing plant and then we're going to talk about the Prototype which is divided in the key component's key component description and the data flow flow and then we will end with the algorithm that we have used to measure similarity between devices which is divided into the class similarity and the instant similarity or behavioral similar similarity so first talking about the environment it is based on a car manufacturing plant divided in task and as I said before a Knowledge Graph requires us to define a schema based on the domain so for this manufacturing plan we designer simple schema to model how the devices relate between each other and what role does it take in the in the environment uh this is based on this has this schema has a department that is related by an execution relation to a task uh and then this task will have a processor a successor which is it's the same type of task so each type will be like there will be a sequence of tasks and it's uh in this this class will play the role processor sensor depending on the link between them and then the task will need a an iot device which is called device in this schema in the schema which will at the same time include include a set of modules that will be defined by the Earth by the SDF"
  },
  {
    "startTime": "01:46:00",
    "text": "description of the specific iot class and then we have apart from the schema we have the data so for the data we use where a specific design and initialization for the iot platform that defines an initial set of tasks which is the this is a an object of the schema and their devices adapted to the system so we have two departments and it's a environment the production department and the safety Environmental and within the production Department we have the initialization task divide that includes the attack scanner device and a production control device and also the underpant configuration task that pickup robot device as a piece detector and so on and the thing will apply for the safety environmental department and the task of interim indoors monetization Outdoors control monetize monetization and safety alarms so now we're going to talk about the key components of this prototype uh I want to start with from the right of the slide so uh first we will have a set of scripts in specific specifically the Escape that the uh defines the physical object or the or the emulates the physical object or the iot platform and this will be will Define a set of iot device classes uh that will be implemented implemented through threads and mqtt clients where we have decided to use mqdb just because it was It was a it was not the focus of our project how the devices communicate but to make it seem simple but we could uh we also implemented it with Co-op uh so these devices will published messages to a broker on specific topics and in the header of this message it will be the uuid specifying which instance"
  },
  {
    "startTime": "01:48:00",
    "text": "that the device is the device name that will relate to the class of the iot device and the time at times I'm saying when the data was generated and then also the body with the task dependent actual device data so this is the messages will be published on topics to the broker and then there will be sent from the broker uh back to the uh but then we will be sent by the broker to the mqtt client that will um receive and process these messages and then uh send them to the consistency Hardware that will actually process the information of these messages and Define new devices in the schema if necessary update their attributes and integrate new 14 devices and then since it needs to update the information in the knowledge graph it will be this uh this updates that are necessary to be done on the graph will be handled by the type of client that will generate the query automatically and send it to the actual uh database with the knowledge graph to update the information necessary so here we go we have the flowchart of how this algorithm that we have just talked about of the consistently consistency Handler works um it starts from an idle point where we are waiting to receive a message from an iot device so in case you receive a message this message is decoded and this message is divided in in the header as we talked before we specifying the name or the class of the iot device and the uuid of this device and then we are also the body which specifies the actual values that this"
  },
  {
    "startTime": "01:50:00",
    "text": "device has so what we will ask ourselves is ourselves first is is the class of this device known and in case it is not known we will Define the device slash in the knowledge graph schema using the SDF description so as we said before we will turn the SDS decryption of the device into this automate uh into this query automatically to Define it into the schema of the graph and then once this is done we will ask the following question do we know the actual device instance so this is like if uh do we have the uuid already in our known devices and in case the device is not known so we will insert a floating device in the knowledge graph through the which where floating means it is inside the graph already but it doesn't have any relation so it's like floating on the graph and go to the next step which is to update the device uh that the actual attributes or values of the device and as we said in case this device is not known it will repeat this until we have enough samples to analyze the time series behavior of the device of this device and then go to the next step which is the flight find closest device within those integrated in another 12. the algorithm we use to file to measure similarly I will explain uh in continuation but if this algorithm finds these are really similar device what we will do is we will replicate the relationship of the relations of the closest device on the new device and check if it was active lately to in case it was considered a new device complementary and keep the closest device and in case it wasn't replaced the the older device consider the replacement took place so we removed the older device from the graph and put the newer one in its place and then we will go back to the Iowa State"
  },
  {
    "startTime": "01:52:03",
    "text": "so I want to end up by explaining how we measure the similarity within devices so this the similarity measure is divided into device similarity and device in an instance similarity and foreign classes of devices we're comparing their SDF descriptions and to do that we turn them into table which is the analysis but adds a bit of redundancy and the problems we encounter to measure this distance was that how can we compute that distance based on the string values which uh uh for what we use the natural language processing tools and then the other problem was how to compare device classes with different number of properties for what we use a rows wise voltage voting system that we are going to explain briefly in continuation so to compare devices with different number of properties or we did this uh take a row of this sdl description defining a branch of the description so it would be a certain attribute and we will compare this class SDF row to all of the possible rows or attributes in the other already integrated classes in the graph um uh we will determine somehow which one is the closest one semantically and for this losses we will look closest row we will look at what class it belongs to and give this class about so if we repeat this process for all the attributes this air quality simplified new device that appears in the Stream has we can get we will get at the end that the closest device is the air quality device which is not simplified it's a"
  },
  {
    "startTime": "01:54:02",
    "text": "bit more complex device but they're doing the same job so since it was the closest last it will or the one with the most votes what we will do is integrate this inference using the SD Evolution uh into this DF description so now we will say in the description of the air quality simplified and we will add the density of relation saying that it's the same as or similar to an air quality device Plus and we also need to compare them to be able to uh see which device is behaving closer to the device we want to integrate within the graph so for this we also look at the attributes but now we look at the series of series of values uh the time series of values they have around time and we search for which other device has this most similar behavior in the last uh period of time through the comparison of a sliding window which we can see which we can see for the pickup robot new device in green here so what we will do is like take the sliding Windows of the last values of this attributes of this unknown device and slide it through the all of the other possible attributes of the closest classes device entities and see which ones are the closer ones so we will vote the closer class for each of these attributes and I said before get the closest device as the one with the most books and I was gonna do a quick demo but I I think I'm I'm a bit uh I don't have enough time so I'm gonna skip it for now and in case someone is interested in seeing it like maybe I can run it afterwards"
  },
  {
    "startTime": "01:56:00",
    "text": "so I'm gonna talk about the future work uh of this project which is probably looking on the generation of automatic generation of SDF description from the device specification we also need to look on the optimization of the closest device the computation of the most similar devices this is the class and behavioral distance because it's a it's a bit a bit too slow at the moment and uh it could be made more fast and then we are also in we don't tackle the integration of devices new devices from scratch this is that if in case we don't find any similar any really similar devices within the graph to the new device we don't have a process yet to integrate the device but the new device but it will require uh you uh creating a new Branch within this graph and then we also need to test this implementation this project with the real data coming from an actual iot platform uh when with this I I end the presentation I mean open for questions excellent thank you and we have Michael Koster and Q go ahead Michael foreign thank you this is awesome work and this is very closely parallel some work that um that I was just doing also which is basically how do you make models for things that you don't yet know about but my question is how much um standardization are you assuming that already exists in the terms of an SDF Sable capulary if you encounter the term temperature do you expect that um you know how much fuzzy reasoning are you doing to to sort of try to harmonize different models or are you expecting vocabularies to already be harmonized harmonized here"
  },
  {
    "startTime": "01:58:01",
    "text": "foreign maybe I can answer this question uh for that uh that's first a very good question and just to say we are not following up with the capillary ones and meanwhile we are very much open for different type of uh identified vocabularies for and for the isdf notation look that's because the way we are doing is actually calculating distance then the only question is that it doesn't matter what are in the dictionary or not once we annotated use SDF then you can always try to find and search in the current existing Knowledge Graph if there be anything close to that using a distance calculation we have and if they're being do let's say close on the distance then things can be integrated with the new data to the existing Knowledge Graph I hope I answered the question this way that that's very that's great thank you very sensible approach also okay thank you I guess we have a for a very quick comment um our well not really works we're practically out of time here that that's actually true um but I what what we could definitely do uh is to have the demo in one of the one dm or as the obsessors we could take a closer since we didn't have one first time for it today but thanks a lot for presenting a lot of things was very interesting and relevant work here so what we could do now is is to wrap up here um we have we already identified a couple of um ways forward especially with the documents so thank you everyone for showing your support on adoption and looking forward to all the reviews on"
  },
  {
    "startTime": "02:00:01",
    "text": "the documents um when it comes to the presented protocol on stf yes let's continue the discussions in the one VM calls uh in the ASDF calls that are coming and also on the all the security topics uh you will be hearing more on the Secor on the mailing list and anything else any final other final comments before we close for today okay in that case thank you everyone for joining today and I'm looking forward to see you in the follow-up work meetings and also in the following summer meetings of the things research group let's stay in touch thank you but thank you bye good eigenvalues for text"
  }
]
