[
  {
    "startTime": "00:00:16",
    "text": "[Music] [Music] yeah yeah I\u0027m not sure what I use that the providing Lamia don\u0027t you know how to use yeah No oh that\u0027s for the mouse the remote thank you it\u0027s forward for this right sure right yeah I think it\u0027s just before my cookies [Music] [Music] "
  },
  {
    "startTime": "00:03:28",
    "text": "yeah yeah all these three minutes it\u0027s a meeting get that minute taker yeah I need to get Jake 400 but yeah I can take commitments which should take minutes along okay I\u0027m sorry yeah Derek okay we\u0027re gonna go ahead get started thank you for coming people may filter in we\u0027re competing with spring unfortunately we\u0027ll try not to make that conflict next time but proceed being here we do need a thank you for getting that door we do need a note-taker our usual people that take notes are not here does anybody have interest in taking notes and it\u0027s no so we just do it this time we\u0027re just gonna do it we\u0027re just gonna have to take turns and do it ourselves plus we got the video so we can go back and watch the video if we have to fill in the gaps all right so no well this is our agenda should take us most of the time today if any that looks incorrect if we missed you please say something hooman we I know you have a draft name but we just didn\u0027t update this with your draft name that yeah it\u0027s it\u0027s there all right so stayed you\u0027re gonna take all this alright so we\u0027ll try to go through all the working group documents and what her status is so we have a pin yang model that has been approved and it\u0027s been in the RFC editors queue for half a year maybe it\u0027s basically waiting on references there\u0027s a lot of other young documents that that it\u0027s waiting on so sorry big group or young documents that will go in together I\u0027ll be published together a startup cease we also have a MP and Emily yang models that are with the isg and there was an ITF last call and there\u0027s some comments and some work on addressing those we\u0027ll have a presentation on that today I believe so "
  },
  {
    "startTime": "00:06:31",
    "text": "as an MSc p yang model did pass last call and we yeah we should probably request publication for that now there was some question whether there should be adjacent example in there or not not entirely sure that we may have to ask a llevarlo or some young expert but you might just request publication and see whether we will be told to add that or not we got the multiple upstream document so it\u0027s a little complicated but basically our ad and the is G doesn\u0027t think it\u0027s worth publishing it the way it is now as we understand it it\u0027s just requirements and they fought a requirements where it may be not that well not worth publishing so the offers are asking to publish it as an independent submission basically anyone can unrelated to working groups can go ahead and publish a document as an RFC there\u0027s like a separate approval process for those doesn\u0027t really mean much for us I think as the working group will get published the document at how the requirements that we agreed on that we wanted to get published it\u0027s just that it\u0027s not officially a working group product of the working group see you next slide I was trying to change all right we got the dr load-balancing draft we requested publication for that since society f we got Emily slipping yang model get an update on that today it might be ready for last call perhaps we\u0027ll talk about that the before prefix or ipv6 next hop the offers have been very lazy that means I have had been very lazy I\u0027ll try to work on that for next ITF dr improvement draft it past working group last call the rest mandatory all comments and almost all of them are addressed I had two very minor comments I think they\u0027re waiting for a bond last relation to to satisfy those so yes and the thing in those revisions seven I commented on and you said that you would address my comments but I don\u0027t think they have attribution eight yet yes I said I\u0027m out for you to make sure than you the new explanation address you\u0027re okay yeah but I haven\u0027t submitted a new version okay wait okay I will I\u0027ll check my email too but yeah it\u0027s just that editorial might very minor thing so once that is done though will request publication and then we have an explicit tracking job that is dead and probably remained that unless the author\u0027s or "
  },
  {
    "startTime": "00:09:31",
    "text": "someone else decides that they want to work on it okay okay we also have our draft on reserve bits that will be discussed this meeting and all registered packing as well and there\u0027s also a draft on by using point-to-multipoint BFD that got adopted since the last meeting but we\u0027re not discussing that today so I think that\u0027s all we working group documents that we have right now any questions comments yeah all right [Music] good afternoon I\u0027m chief Miller from water networks here to give a quick update Toto documents this is the first one the smoking model so we we are trying to get some updates to this document and the since last revision we are tracing few comments because we have another similar young documents which is a AGM pmid young or though so we got a lot of comments for that document so when we review the comments so we think a lot of our comments can be applied to this document also so which is the address the most comments in this document also and some changes particular to the model so here there are some tax young tax already been published in some other documents other models so the comments is that ask us to reuse those types so that we can share the same type between models so here are some examples here instead of what we use the IP addresses so we are dative and the multicast Corp address and multicast are sausages so we just echo had to use them so making a more consistent and more precise and those "
  },
  {
    "startTime": "00:12:34",
    "text": "are the changes and we have down for this document and so we still trying to see if any further comments if we have any or dress them otherwise probably we can go further for the next call all right thanks so see we\u0027re not too many people here but have you read this document raise your hand if you have read this document okay one person so I wanted to ask people photos ready for last call but it\u0027s a little hard with with only one person having read the draft so unless you have any objections we we plan to do a record blast caller on the mailing list in a few weeks no objections right okay so you do plan to do some additional revision firsts are they pretty much ready to do the last call right now if you want to write then we think of pretty much merida so the comments we solve another document already been prior to this one alright next document that\u0027s a different model so this is for the proxy so this is a revision 0 1 so 0 0 was a present 8 in Bangkok I think so there are some really received some comments to this model and thanks for those comments we addressed other comments so far so when is that the place where we should argument this one\u0027s at the model from young models we have a base model and augmentation model so we\u0027re trying to fit the big structure of the routing protocols all the polar calls together and so the place we think it\u0027s better for this model to fade no it\u0027s nicer routing protocols and particular protocol for this one and also there\u0027s another comments about the restriction between different models so let\u0027s look "
  },
  {
    "startTime": "00:15:35",
    "text": "at the changes so you should be since we\u0027re trying to enable us to say both the proxy and particularly interfaces without probably put on the interfaces and but the interface here is it\u0027s not a good place because that could be different kind of interface and may or may not be the protocol interfaces and the current conversion is that we have all the protocols kupah together in the place like the control protocols and protocol and list of protocols so we do the same here and move the structure here we have a list of interface here so that we know which interface we are trying to do the confirmation and that\u0027s one change another change is the restriction between the models but now we have the proxy in about an interface which should be we need to check the pin should not be enabled on the same interface so we added check but there are some issues and so because we just assert the proxy model and so to toe the check we have to access the pin model so we have that these issues so if we try to implement the proxy on the system we may not have the pin implemented at all so we had this issue and yesterday talked with the young doctors in the net count session mode so the consensus from them is that so the way we are doing should be okay so here even though we don\u0027t have the pin model implemented we can still import the pin model and mark them as Justin cost not imprinted and in that case we can still to the checking and they are trying to improve the yen language in the next revision so make it better usable we can check see if the particular model is in imprinted are not implanted and that\u0027s a client in still being discussed see if they can be put into the next revision of the yen language so we\u0027ll see if we have that feature then well use that data but for now we just to whatever we do here unless we have objections from the working group other that so we like to receive more comments and so we can impor the model further "
  },
  {
    "startTime": "00:18:36",
    "text": "that\u0027s it thank you all right thanks so I guess that question is whether we should have adopted this as a working group item can ask how many people have read this draft the IGMP MLD snipping draft can you please raise your hand if you read the the IGMP Emily snipping draft any people read it a couple of people two people so so now there\u0027s been this young model design team working on this but it looks like there is less vendors work that were involved with this one than the other documents we are trying to cut seems like yeah we came back more participant also we got people from Cisco VMware and not the Huawei and others so I think of a resume we create discussion meeting from participants to the session okay thanks so do you do you have a feeling where this is something we should work on is it useful to have a young model for our gym PML is sleeping okay one person - yeah yes this has been around for Inc like maybe three ITX now more so and at least there\u0027s a handful of people that have been working on it so from a few different vendors so at least they are interested so I think maybe wish we could do another option call on the list do you have any thoughts on that well we had two people that raised their hands do you of those two or anybody else think that we should have got this work Ian Duncan Sienna I\u0027m neither a yang expert or an ml d or IGMP expert really haven\u0027t I understand them that I\u0027ve worked on implementations of some of them so I don\u0027t feel qualified to say whether the document as it\u0027s written is correct but I think it\u0027s work that we should be doing okay fair enough well we appreciate you raising your hand anyway so okay well well we\u0027ll make this request on the list thank you and they\u0027re working on getting us another "
  },
  {
    "startTime": "00:21:37",
    "text": "microphone [Music] all right so this draft is about penal register packing the offers couldn\u0027t be here so I\u0027m presenting on their behalf this was adopted as a working rep item since the last ITF I think very recently at least so the most you remember this I guess the idea is simple some deployments you have to send hundreds even maybe thousand lot registers every second or something like that because it\u0027s a single message per Eskimo G and this causes problems if some of those small registers get dropped for because of control plane passing or other reasons and you know if you miss some of those you will end up doing data registers and the load gets even higher on the RP and so on so based on several issues we\u0027ve seen but also like Cisco customers we decided that it would be useful to have a way of sending multiple Eskimo gene all registers in a single message so that is what this draft is about and in addition to the they\u0027re packing itself there\u0027s also this compatibility check which basically says that initially you would send the the regular registers we have today but if an RP supports this it will send a bit set of bits in a register stop messages so that\u0027s where the first uproar can learn learn that your pin supports this and can change to using this new new type of knowledge sirs and the other is some some good reasons for doing this the changes is last time is mainly the the P message type there is this draft I\u0027m presenting after this that talks about how to extend the PIM message type face and this has been changed to make you so that there\u0027s also so many cast RP considerations basically if you do any cost RP you should make sure that you either enable this new support for this new thing on all your piece or none of them else you might have a first browser that initially registers to one RP and thinks it supports it then because it\u0027s any cause it might suddenly send a registered to one on the other our piece which maybe wouldn\u0027t support it so so that\u0027s just some text explaining that that\u0027s that\u0027s all that happens since "
  },
  {
    "startTime": "00:24:38",
    "text": "last version let\u0027s see that\u0027s all we have so I guess the offers would like input on on a changes or we like people to help review the document this is do you know I I haven\u0027t read the draft just want to know I hope the format is exactly like a giant prune message since it\u0027s not so so no new code has to be written you can use existing code right so basically you\u0027re saying that for instance you would like to have a group range and the number of sources or something like that then yeah yeah right right yeah there\u0027s another job presented later today that also does this type of packing and that some may be something to consider for that as well right thanks to skill inputs yeah yeah any other comments this is Deena um so protocols for what\u0027s called protocols for internet multicast IP multicast so why isn\u0027t the EM also stand for hambone what why isn\u0027t hasn\u0027t it been combined and I thought that was something I was supposed to happen [Music] yeah we\u0027re not thank you for the comment I don\u0027t know if we\u0027re gonna get into that again but we have discussed that a lot yeah we decided not to you that there\u0027s plenty of working both organ groups but they\u0027re trying to meet together as much as we can lock in their JS and slots this time we had a lunch break between those all right okay I think that\u0027s it for this document that\u0027s the research it\u0027s that phone okay so this is about him reserved bits it does a couple of things the main thing at least what we fought initially "
  },
  {
    "startTime": "00:27:38",
    "text": "was the document how different we throwed bits have been used by different RFC\u0027s there\u0027s no there\u0027s no place today where you can go and see which bits are used by which IRC and some of the sources should have updated 4601 but they never did anyway this just so this document started out explaining that but maybe the most important part with this document is extending the PIM type space so as you see on the bottom here we have type 13 14 and 15 and you\u0027re proposing taking four restore bits for each of those types and make make subtypes similar to what was done for embody before so what happens is the pin header type will change from what you see at the top there to the bottom one so after the type you have a sub type field that this forbids so we talked about this before too but just repeating this so basically what happens is that new new if you do this the new RFC\u0027s would not get a single like type like type 30 no type 14 they would be assigned say type 30 not 0 30 not 113 not 2 and so on so this gives us 48 new types instead of T that we have today yeah so this document was adopted I think well kind of recently and I kind of want to move ahead with this and maybe go for last call so it\u0027s been stable for a long time I don\u0027t know anything that needs to be added to it but please let me know if you have any concerns and the thing is we have some new new drafts that might need new types soon and we would like to you know use this new sub type space for it for those drafts this do you know do you think you have enough bits where you can assign one type to vendors specific and then vendors keep two things I would be kind of hesitant at least my feeling is that would become hesitant to give them say one of those types like 13 14 or 15 because that will reduce it to like 32 types that we have used this subtype but we could we could but we do have if you do this you have 48 types so it could maybe assign a couple or a few of those for the eight types for vendor specific yeah yeah yeah sure yeah so I think we talked about earlier that this draft could just stay around until we be neatly needed the type space there\u0027s no urgency publishing this but given that you\u0027re on your "
  },
  {
    "startTime": "00:30:38",
    "text": "drafts that that you might want to publish in an ITF or two or something I think it would be good to just get this done and so other drivers don\u0027t have to wait on this that\u0027s my my feel at least so any comments on the draft do you think it could be ready for last call should ask the chairs if they would consider last call on this or if you want to ask the room there\u0027s only one left by default so who\u0027s read the draft so I see three hands four hands okay so of those who think that this draft is ready for a working group last call so two of the four Fila that\u0027s three of the four okay all right so that\u0027s good indicator we\u0027ll take it to the list and see how we\u0027ll get responses but I you\u0027re probably right all right thanks yep then I got one more presentation all right so we published fairly recently an RFC on this BIM flooding pellicle the main purpose for now is source announcements but it could be used for other stuff and the way it\u0027s defined this the first up router with every 60 seconds or some configurable time send a periodic update with all the active Eskimo G\u0027s that it has yeah and the thing is potentially there could be a big amount of state and it\u0027s kind of unfortunately having to send this updates every that yeah that often also you kind of want to send them often just in case you missed some triggered updates but if yes reliable way of doing this we could send updates much less frequently you could pretty much only sense you get updates only rarely do like a full update so at least the idea in this draft here is we want to try to make pfm pre or reliable and we\u0027re thinking we can maybe use import for this so import we have reliable transport between peer neighbors and this message is doesn\u0027t hop by hop between neighbors so that seems fairly easy so what you\u0027re proposing is some new port message types so that we can send not just join principal also send these messages so you are suggesting "
  },
  {
    "startTime": "00:33:41",
    "text": "that port connections can be established between neighbors according to the existing pin port RFC and then we have two new message types one is for sending and pfm update so a more less than the update as it is defined in the pfm RFC but we add a major and a minor sequence number to identify the updates we also have a new message to request an update from a neighbor so when a TCP connection comes up you can send this message and say the latest I have from these two originators are these versions and the neighbor can send all the latest it has that is more recent than what was requested and also if you receive a message from a neighbor that is has something newer than what you already had you will update what you stored and it will send what you just got to your neighbors and this is major and minor sequence numbers the idea is that each full update would have like a major number - 0.0 1.0 2.0 and so on the minor updates would be say 2.1 2.2 which are updates versus say version to 0 that was the full update and if you get the full update you can forget the course all the previous state you had from that originator if you don\u0027t get the full update you need to remember the previous full update still plus all incremental updates since since to us full of it I should say though that we didn\u0027t have time to make this perfect we can see some issues with how we describe this and we will do some more work it\u0027s a little bit like maybe how an OSP fo ice is how you ensure that everyone has the latest information except that this is using TCP for reliability and one of the main issues we have in the current solution perhaps is sequence numbers we rely on these numbers being always be increasing but if a router restarts all you ensure that it can use numbers that are higher than the previous used versions so you can maybe rely on the clock or something like that but it\u0027s vicious with that you can maybe need some way of finding out the last version number that is out there in in the domain or the network and then finally ok I need to use something larger than that this is something that has been solved for the our GPS as well I think so there\u0027s more work to do here guess my main question for you is thought about adoption or anything but what do you think it\u0027s useful to to work in this space and happy for any feedback of course this is Dina I don\u0027t know if it\u0027s real "
  },
  {
    "startTime": "00:36:41",
    "text": "late it\u0027s not related to this draft but I was just wondering and it\u0027s kind of off topic and if you want to tell me to sit down please do but is there any requirements to send him control messages encrypted and would you consider adding quick to port yeah so the there there are people that want to do authentication no pin messages I\u0027m not sure about encryption and yeah maybe okay this is just me talking as I know as an individual you develop import which has been defined but I\u0027m not sure if anyone has implemented it so this it wouldn\u0027t be a top priority to had a quick unless that is actually something that you know would make it more useful to people we had that telepsychic we had that discussion a decade back in snooping and when we\u0027re doing PIM security the discussion before the RFC and I think one of the compromise that we seem to like was to I only have authentication but zero encryption so that you could still see what payload is there but they would be authenticated I\u0027ve never seen that being done and to the best of my knowledge now both TLS 1.3 and quake are kind of of the matter that zero encryption nobody needs that so it\u0027s not in the profiles it\u0027s one of the things I bitched about in TLS one three so I\u0027m not sure how difficult it would be to use you know TLS or quick where zero encryption only authentication that\u0027s what I would love to see another thing I think we need to consider where transport like TCP or our quick is if you actually want to have like a snipping device that can do say like PIM snooping to actually have connections explicitly terminated at the snipping device or something instead of having to inspect these I know packets on the wire maybe maybe I should ask the more general question is do you think the performance properties of quick merit adding it to port not just for encryption yeah yeah I mean I think it could be fun to look into it I\u0027m happy to maybe have some discussions all right I think that\u0027s okay one more comment I mean I obviously like port so you know if we adopt anything new it would be lovely not to have the new staff be a reason of not being able to to use port right so from that perspective I\u0027d support this year down to two basically you know when people want to start using "
  },
  {
    "startTime": "00:39:42",
    "text": "it unfortunately I feel that there\u0027s so little support for port right now that this may be a little bit still not sufficient to have people import yeah and it\u0027s also a draft presented a little while ago on em registers using TCP or port for transport so I guess we need to see overall how much interest is there in like reliable signaling for for PIM and its port the right solution other things we can do to improve port and so on somehow I think we managed to avoid in the last pin revisions the discussion about you know if you do this you know across the internet or so how about your congestion control right so we never got into that and I\u0027m not sure how we would fare today if that would come up but the obvious answer to those congestion problems you know when you do reconvergence and if you\u0027re really big bursts of things to do and we know how badly pin works in general and how interval problems are with the buffers port is the right answer but I think we have a hard time now elevating it up to really be the recommended solution as opposed to the you know all data grandpa right yeah right only I we can maybe see if there\u0027s some improvements or are things we can do to make this work better for PIM alright okay thanks good afternoon when come now my server from Cisco Systems so we had presented this draft in I think - I - ATF back it was about about back up dr election so basically there are a couple of deployments where we are looking for having live live traffic and to select the primary path and secondary paths you could use either or a vector to make sure they are divergent paths are there are flex L go there are so many other procedures to do that so the question comes how do you elect backup dr so this this drop doesn\u0027t propose any new protocol mechanism per se and so i think i just wanted to go by a problem statement again that if you have failure in the dr this guy has to detect new dr election you build the tree and then get the traffic so maybe for some deployment this might be a problems problem they "
  },
  {
    "startTime": "00:42:43",
    "text": "don\u0027t want any delay in the traffic flow in case of any failures and for those cases for faster convergence this was the draft we proposed okay so the solution was having backup dr and now question is how do you elect the backup dear so in this draft i had said that rather than doing any protocol signaling for backup dr election you just do the second best dr as a backup dr and send pim join and keep dropping the traffic at the backup dr and finally when you detect the failure you have to basically move to the new dr there were a couple of cases and feedback which i had got in last IETF was to make it informational rather than standard because it doesn\u0027t define any new procedure there are a couple of cases which need to be thought through which like when new router is coming up our priority changes so how we are going to handle that so I have added text in those area but we are it would be good to get feedback at all secretary I hope I\u0027m not contradicting anything I not remember having said last time but just because there are no new messages the behavior on the wire does change right you are sending out the joints or which would to me mean it\u0027s actually a protocol extension and it should be just normal standards track I mean I would rather like to call it hot standby because there\u0027s I think the typical term that you basically use when you base it you have this backup that you know is immediately ready to do things makeup is a little bit unto an specific but other than that you know why not simply standard strike I\u0027m you know what was the argument for it there is change on the way you two are sending the joint with your otherwise don\u0027t okay I don\u0027t remember what all the argument but yes I presented in 102 and that\u0027s when I think there was a feedback from the room that it has to be informational I don\u0027t remember who had made that comment you know some comments sticker yeah so it does also propose things like you know like using your priorities here of initially for instance when you come up and stuff so it does change the protocol behavior so I feel like this draft has other important things than just back up the are for instance for that just said about whole time of 0 sorry the our priorities here of initially so I wonder if the title should be slightly different sure just think about it I feel like we need some more text explain how this differs from the the dr improvement "
  },
  {
    "startTime": "00:45:45",
    "text": "draft okay why would you use this versus that or so the idea improvement draft which your improvement what it does is it uses some new hello options and it allows you to have kind of like a sticky dr and sticky PDR when there\u0027s changes which is something that this lesson do so it\u0027s Quebec good to maybe explain that with a few words Jeffery from juniper did we talk about the merging those two tracts no no we discuss it I remember we mentioned this in the previous working group but then you decided that they\u0027re you know worthwhile to keep on attendant okay should mention each other just so that the yeah yes actually I was thinking you know this should mention that they are improvement draft but we we should think about maybe it\u0027s worth adding just a little bit of text and we are improvement to to just sort of say how it is different from this sure we can propose some text in the list and discuss that yeah also yeah I\u0027m reading this draft I felt like it could need some more text still to explain the behavior of the BDR like what what are the benefits so electing a PDR and how exactly can the PDR take advantage show talk about that is that improvement draft also support this type of use cases meant to do that or yeah so much about the whole time of 0 but at least the whole idea with that too is do you like the PDR and the PDR can do things like do like hot standby as you said like it\u0027s in joints upstream and so on so we do have then two competing solutions and yeah okay so I need to reach two drafts as no two RFC\u0027s later on as a user and figure out without having any explicit comparison which one fits me better by understanding all the protocol details yeah I\u0027m named I yeah I understand as a draft reader I should do it in the IDF but is that also what we want the end user absorbing are sees later on to do yes well is one option would have been to merge them the other option we are saying now is you know maybe that two drafts can reference each other and have some brief text explaining you know how is this different so I think maybe in the list we can get the feedback and then decide so in fact during last presentation the same question was reused whether we want "
  },
  {
    "startTime": "00:48:46",
    "text": "to have single draft or we want to have both of them whether it makes sense to have two different kind of solution I mean I completely understand how it\u0027s easier to get a lot of small drafts through the ITF but I mean ask any poor operator how he kind of tries to get through that maze right I think that\u0027s always the issue yeah I think that would be the ideal an avro I think that you would agree that that would be the ideal but it\u0027s working groups do produce competing RFC\u0027s right I mean that\u0027s something that happens yeah yes I was referred as documents because I have to read them all but yes I think the important thing is is if there are two solutions to this a problem it needs to be clear why if it\u0027s just that we have two solutions a problem and there\u0027s no real functional difference or nothing against this raft but the other draft does other things and addresses this use case yeah maybe that\u0027s something that working group should consider as well but in the in the I guess it\u0027s case where we go with two competing solutions we need to sort of justify why yeah we\u0027re talking about you know there\u0027s implementations and there\u0027s appointments of both or something you know maybe those are factors that would weigh into policy both as well so it\u0027s not as easy as just saying one thought to members to think there\u0027s other things that need to be considered as well no requests right well then I think there\u0027s some more disgusting music [Music] [Music] you\u0027ll take it yeah okay so while we\u0027re packing things why not pack a certs as well it\u0027d be interesting to get your opinions on this whether this is a something that would be a good idea or if it\u0027s crap but we\u0027d like to just get your opinions on this and the goal is to be kind of forward-thinking you know it would be potentially helpful to reduce the sending and receiving of a certain messages the pressure of that in maybe some you know that it\u0027s probably not really an issue today but you know maybe in some future deployments whether it\u0027s TSN kind of networks there may be a benefit of doing this we\u0027ll see so let "
  },
  {
    "startTime": "00:51:48",
    "text": "me just explain it and then get your opinions so we didn\u0027t cleat include some use cases that describe where this could be helpful and again we admittedly need to develop these use cases more especially ones that are maybe a future related but if we want him to scale well into the future then we should be able to work on these kind of things if we you just want to push people towards beer and other things then we won\u0027t alright so the problem that most of us are likely aware of is just the certain mechanism if you do have a lot of sources and groups there could be times where there could be in short bursts a lot of assert messaging that\u0027s happening and there could be a large processing load on the routers so we aren\u0027t proposing any changes to the PIM state machine where we are proposing a new pin hello option extension for assert packing and being able to know she can negotiate that packing capability and then we\u0027re considering two types of solutions one is a simple packing solution one a little bit more involved aggregating packing solution if this is something that we pursue so the proposed PIM hello option extension format is a new option type and then a packing type whether it\u0027s simple or aggregated so again the new defined hello option is used to negotiate the assert packing capability and we will have a packing type of one for the simple packing type and a packing type of two for aggregating Steiger ever question so if you support aggregating the type to aggregating them do them implicitly also support check one more I don\u0027t know because if you if you support both you announce one or two and what if you know someone else one and some announced you take a question yeah we were assuming that they were discreet but we need to make that clear in the draft that\u0027s a good that\u0027s a very good point Stig okay yeah think about that one some more so in the simple packing solution you\u0027re simply taking the existing assert packet and inserting that into a new assert packet that\u0027s grouping all these inserts together the original assert message bodies is used as the record making carry multiple assert records and then identify the number of Records so the advantages is that it\u0027s a simple extension that disadvantage is that when you oftentimes have a small number of sources and "
  },
  {
    "startTime": "00:54:48",
    "text": "groups there could be a large number of records with the same metric preferences and stuff so it kind of wastes the the payload or the transmit has transmitted message but it is a simple way to go about doing it and this is what the simple packet format would look like just putting in those each asset record into the new packet you could separately have a little bit more or a lot more involved aggregating packet solution where you could combine the records rated to the same source or RP address in in the assert message so in the case of like a cert record one you could have the source address and all the groups that use that same address packed into that particular record you have another record which has based upon the RP address grouping the groups according to the RP address and then subsequently each group record having the sources that use that particular group more involved not sure what hit that would have on the processing but again it\u0027s less messages that on the wire that the routers have to process it adds more complexity but the advantages you\u0027re also optimizing the payload of the transmitted message by merging the same filled content so I believe this is the last slide this again just kind of takes a look at the pen assert packing format on the left upper left and then each star comma G assert record format with the you know with the rpe address and then all the different group records the bottom left you have a s comma G assert record and all the groups that use those same address same source address and then each group format would be as as follows [Music] so yeah comments yeah Toula Tosa is a co-author so it didn\u0027t have you know really a lot of cycles spent on trying to see all the details or so my main interest was really the problems that we had heard over the years and so in business critical environments like you know in the finance sector or what we had to do to deal with assert problems or is ready to tell them you can\u0027t have a transit land with multiple downstream in multiple app streams you need to create you know point-to-point lands and you know when your whole business depends on it you can basically go through the trouble of changing your network but since then you know and ten years passed and now we have a lot more interesting layer two technologies that actually you know you can buy Metro Ethernet lands right if you buy a single Metro Ethernet line that\u0027s a different price point than buying a lot more point-to-point matauri that land putting another Q\u0026Q on top of it is another problem space death net you may get qsr "
  },
  {
    "startTime": "00:57:49",
    "text": "in these lands right so having the expectation that you don\u0027t have any transit layer two lands just because of multicast I think is is a risky proposition for us right it\u0027s like in the Wi-Fi case maybe kicking us as multicast more and more out of the picture right now obviously the proof of the pudding would be to figure out if you know and I think that applies to the other packing drafts as well could there be any performance numbers right so I\u0027m prototyping or so that would really be I think very helpful to persuade right but obviously it should be better how much better we don\u0027t know and it\u0027s it\u0027s an important problem especially because also in port we we have no replacement for for the multicast deserts so this thing is going here the assert problem is going here to stay whenever you have multiple down streams and at least you know two redundant up streams and so we should continue to be right because in big deployments we have big issues thank you so if a sir it\u0027s becoming a scanning concern I wonder if there are other ways to solve that problem without using p2p beings for example you already learned you already know who else is sending what kind of joins if you if you remember that information you maybe when you choose your own upstream router you can consider who who else yes asking for that something I mean that that came up over and over again I was always suggesting what I called strong RPF check which is your RPF against the sending MAC address and people were never kind of you know daring to to break that layer the separation right I think the guy back there is already starting to laugh out loud so yes I think there are a better solution no I don\u0027t think we could get them through the idea so that was truly speaking and it\u0027s Jeffrey speaking again for the people on video another common is that now if you are start packing how long do you wait before yours you send out and since these this is for a certain your your having duplicate packets going young how how fast how quickly do you want to send out your SMS you so that you can quickly stop the duplication yeah great questions we don\u0027t we are we are proposing any changes to the search state machine so that would all be the same as it would be today mission change a meeting at the timings because when you are you know compacting that means you know you\u0027re waiting for certain point certain times before you send out your pack pack packets right that\u0027s yeah yeah okay typically the way you do it is that you basically you know as long as you don\u0027t have to wait so you can read non-blocking further assert notification your control plane that\u0027s when you basically take them and as soon as you basically your packet is folder you send them out that\u0027s no additional delay "
  },
  {
    "startTime": "01:00:50",
    "text": "right that\u0027s there\u0027s no waiting for additional notification mancom no Cisco I think actually Jeffrey asked my question I just wanted to know that how are we going to implement it how long you are going to wait when when to send the update whether we will create lists only for the subsequent asserts and we will send the new one right away how it is going to happen okay those are things we have not included in the draft thank you well we should do that misty know yeah those last two points are critically important in terms of implementation because why do you send an assert because a packet came on an outgoing interface that means at that point in time there\u0027s only one s comma G you know and if you want to aggregate that means you need to collect all subsequent ask emojis that are going to come on this output it interface and if you wait then Jeffrey\u0027s point is true that you\u0027re gonna be sending its while you\u0027re waiting on the previous ones so it\u0027s really hard to implement right now but so the other question I had is this why do certs happen so much in sparse mode you send joins one way versus the other you know so oh are you worried about the RPF caves and a join to a new path and then the prune gets lost and then you have the double forwarding on a multi excess so if you want to solve it for den smoke because the search happened more often there that\u0027s fine but was that a motivation that wasn\u0027t we were just thinking of sparse mode just just sparse or sparse mode yeah in the transient case of joins because you know a downstream router sends to join one way in a multi access network to one that neighbor the only time I could think you get certs is when there\u0027s an RPF changed you join this way and you didn\u0027t prove that way which you should the spec says you should but if the previous then that you have two routers that are forwarding on the multi-axis LAN and that\u0027s when the cert would happen but that doesn\u0027t happen very often no it doesn\u0027t happen that often and we do we do talk about that in the draft that bit it\u0027s just that there could be those small bursts of times where there could be a lot in a short burst of time it could be a lot of asserts happening if there\u0027s a lot of yes okay so you\u0027re what you\u0027re saying is in that transient case there\u0027s a burst of asserts for a bunch of different Eskimo Gees that may have been affected by the prefix for the RPS yeah and and then how long do you think you should wait because Jonas may have some comments on the comments if you if you wait for the timeout period it\u0027s just going to clear itself out because the routers just gonna prune but that\u0027s gonna be three minutes and that\u0027s like infinity right if you wait one second then you yeah it just this doesn\u0027t seem to I think it\u0027s going to be hard to do the implementation based on what these two guys said and it doesn\u0027t seem like it\u0027s worth it for the very rare case it\u0027s a lot of effort in machinery put in "
  },
  {
    "startTime": "01:03:50",
    "text": "for a rare case you believe it\u0027s a rare case or or you think it\u0027s going to happen yeah we\u0027re thinking it may happen more I don\u0027t know I\u0027m gonna jump into the queue at some point in there along the same lines why we\u0027re asserts put in there it was because of this idea that we would have trained it lands for multicast exchanges where one provider would pick this neighbor and another provider would pick a different neighbor I don\u0027t know that we\u0027re gonna have multicast exchanges anytime soon and I think that use case may have evaporated so so maybe I think Dino\u0027s along the same like on the right lines of the thing that we thought a cert would do is probably irrelevant these days and moot what is it yeah for sparsh mode and certainly for dense mode if there\u0027s anything more mooted it would be dense mode so I think it\u0027s worth looking at all right what does a cert do now because the search do happen and is it just those transient are you know transient reconvergence or is it something\u0027s broken or does it not happen that much because usually what is you know what\u0027s your typical transit land it\u0027s going to be a you know a whatever a pimsy with multiple pease who have connectivity to the source but you know again are these are cert I\u0027ve seen a search happen recently but why are they happening is it because something\u0027s misconfigured is it because there\u0027s transient reconvergence issues certainly I have a tough time believing that it\u0027s happening for the reasons we thought the cert was going to be used originally so I think that be looking at something\u0027s broken here somebody misconfigured something yeah or you know somebody somebody poorly designed something it shouldn\u0027t happen that was Lenny from juniper speaking by the way and turn this is crawling out of his skin to say something so first of all in this thing in burundi working group we finished last year a BCP about inter-domain so there is basically section about exactly that absurd problem in exchanges and you can\u0027t build these exchanges with a layer tool and because it would get persistence cert so this is not the use case right this is the broken stuff this is what we would need strong RPF check this is really in my opinion for layer two transit lands in normal enterprise networks which may use Metro which may use that net which may use layer two subnets because a transit instead of point-to-point for all the reasons that you know layer two Ethernet has improved over the 10 years and is very attractive except for the assert stuff right and we have seen in the past as I said exactly in these networks in finance they were using layer 2 transit network they had humongous refreshes right there is one improvement in the latest version of PIM which is basically proactive asserts oh just because you\u0027re basically having not exactly the same type of conversion speed of your 10 downstream routers to your to upstream routers when you have RPF change all right so when these two "
  },
  {
    "startTime": "01:06:51",
    "text": "are conflicting with each other both of them are sending and you get the earth pretty much for all the state leave certs is a standard mechanism yeah the prunes and joints are overlapping and basically the latest version of PMS try to improve that and obviously one of the important things is to figure out how to implement it for the two cases one is the data trigger the third one the other one is a lot easier which is the preventive asserts and for the data triggered it asserts I don\u0027t really see the issue right you have a queue of event notification no no I mean you you basically get your assert which are data triggered events there is a queue of that and basically you\u0027re simply whenever there is the first message in that queue you look through the queue if the queue has more than one element you\u0027re just everything that\u0027s in the queue that fits into one assert packet you\u0027re collecting and sending out I don\u0027t see the problem sorry so I do want a support tool is here on this first you see I always say Isis so I would think you know we want to make modifications to a search it\u0027s better to get rid of them completely they said of move on to make it better so up there SEC based on MAC address or some other things I think maybe that\u0027s where we should spend our time yeah this stay gonna make some comments too so I think one common case forget asserts is last hop very you know one router is the DR but also another router is receiving a pin joints if you wish and both a transit land and the last topically if they\u0027re receivers then you will get the certs and often a source can be kind of transient situations but once you get an assert you end up listening and starts forever as long as your Eskimo G state and for those pre Ola concerts I think this graph is useful so base that this Deena based on what tourists said about just make more than layer two topologies point to point does that mean there\u0027s multiple there\u0027s multiple replications on that land because that\u0027s a that\u0027s a disadvantage you want you want to take advantage of multi access lands because you want the replication to be done by the media not by the router well so I mean read the BCP about you know the case of an exchange point where every downstream has different opinions who his upstream is and he wouldn\u0027t like to get his multicast from a different upstream right so that\u0027s that case hopefully exactly so that\u0027s cases out of bounds right that\u0027s what I was trying to say to Lenny and I think we should basically talk have a sentence about that that\u0027s clear so yes within a network where a single network operator wants to do the policies obviously we should do the replication but the whole point of strong RPF check is instead of very quickly for the transient case to try to resolve the duplicates and get rid of them rather have a little bit more duplicates in the transient state and not do all the signaling ice is saying "
  },
  {
    "startTime": "01:09:55",
    "text": "is you turn off a search on that land altogether and everybody who is switching over to joins I know they do them in a different time so some are still joining here until they get the RPF inside but eventually they\u0027re all going to switch over and there\u0027s gonna be a shitload of prunes that are you going this way so even if it\u0027s a it\u0027s a congested network one of those prunes are going to get through and that\u0027s gonna cause that guy to remove the ayat oh I am so so I think just get rid of these I think you\u0027re not how about having a neighbor option to say we don\u0027t do a search but that\u0027s I think what what what we say it right so the better option is strong RPF check the way that the term we phrase in the back well that basically means both both up streams are for you know half a seconds are sending but when I\u0027m sending my join I\u0027m putting in my RPF to say not only from this interface but from the following sending MAC address and that way I will not forward that\u0027s the whole point you want to avoid that during the switch over you\u0027re forwarding duplicates and the asserts are all meant to avoid duplicates as quickly as possible yeah that\u0027s exactly why you know this is the better best solution in my opinion but we are not doing it no we haven\u0027t we haven\u0027t done it I think huh yes yes that\u0027s why examine the products that\u0027s why I\u0027ve given up on it you know we\u0027ve done it in MPLS obviously right but you don\u0027t want to hear about MPLS right you know ml DP yes so the answer of course is a MPLS right but if you don\u0027t want it sorry that you know there\u0027s a cost for it either you try to optimize the assert or you come up with another complex state machinery that everybody agrees and you know you make a downstream elector for everything like in OSPF or this is ice but ice now yeah so I wasn\u0027t suggesting to stop using a search well yeah sometimes it\u0027s but but I do want I think you need to strung up your check has to let\u0027s say that stronger artistic means that downstream does not just art be up against the interface but something more now I think we can be mac address you can use ambulance labels or maybe even feeling there\u0027s something something to tune make your land into a virtual point multiple [Music] but it\u0027s it\u0027s this is being recorded you guys get to go to the mic YouTube just remove the assert allow duplicates for a very short period of time and everybody\u0027s roughly good if you\u0027re running OSPF or any I GP everybody\u0027s roughly gonna converge at the same time enjoying the same way so I think the amount of time that there\u0027s duplicates being sent is going to be minimized that\u0027s the trade-off from sending a hell of a lot of asserts or waiting waiting "
  },
  {
    "startTime": "01:12:55",
    "text": "to aggregate them was just still gonna send duplicates so well the tone ii again that the the problem with duplicates is that we have a lot of networks and in video applications or so where duplicates because they\u0027re causing link congestion are a lot worse than you know missing packets right so and we\u0027re not getting missing packets because the switch over actually is fairly flawless in the way that we have it it just creates duplicates so no no I mean with with with the way we\u0027re working I\u0027m saying if we had the strong RPF check we would have you know pretty flawless failover right so that\u0027s right but I mean then then that\u0027s fine which is basically why I\u0027ve kind of you know said it\u0027s super consulate vendors the next after this from RPF check so that\u0027s the question how cheap can it be made these days right and otherwise here is a software only implementation that optimizes the asserts you\u0027re saying get rid of the asserts and accept duplicates I don\u0027t think so there are corner cases reimagine of the duplicates permanently though like one example is as I was saying if you have transatlantic that\u0027s also a last hop if the dr is forwarding and another router is sending a pin joint across that land to receive the traffic no you might tell think it\u0027s that easy plugin so I think there\u0027s letting do please go to is quite dangerous because she can have ten thousand states right converging so it takes a while for pin to converge right so the first boom you got in okay people cough kills but number 10,000 there\u0027s a lot of duplicates going down don\u0027t forget when there\u0027s a unicast RPF change it\u0027s affecting a lot of s comma G\u0027s and the joins are gonna happen and they\u0027re gonna be aggregated and grouped the prunes are going to get rid of a lot at one time because we already have an aggregated solution to call during prune messages right it\u0027s just not one eskimo G like the assert has just one s comma G yeah Lenna Giuliana juniper so it seems like the choices are fix or replace asserts which Dino\u0027s suggesting is really expensive nobody\u0027s ever going to do it the alternative is don\u0027t bother doing asserts because and just live with duplicates because it shouldn\u0027t be a persistent duplicate case it\u0027s duplicates should be quite rare and assert just shortens the amount of duplicates that you\u0027re getting it doesn\u0027t eliminate it and then the what you\u0027re suggesting is let\u0027s optimize asserts the idea of let\u0027s eliminate "
  },
  {
    "startTime": "01:15:59",
    "text": "asserts only makes sense if you\u0027re not going to build asserts in the first place but once you\u0027ve already implemented asserts and asserts are there you might as well keep them it\u0027s not like somebody\u0027s gonna go back in and say let me turn off my asserts now perhaps there\u0027s a processing cost or maybe there isn\u0027t and maybe the point of this was just to enhance the process but the process is a rare and unlikely and not worth enhance about process I guess that\u0027s what it comes down to is so yes it makes it it would make sense if you are gonna build an implementation to start like if you\u0027re going to implement PIM for the first time let\u0027s not bother building this assert thing because I think it\u0027s obsolete we don\u0027t really need it anymore we\u0027ll just live with these duplicates and you know it\u0027s a canary in the coal mine anyway and you know you\u0027re broken anyhow if it\u0027s happening if or you say this is a problem just for transit transient cases in which case we\u0027re reducing it from a short amount of time to a shorter amount of time or you know that\u0027s oh I think I don\u0027t know what I think but that\u0027s what you think I just what I would say is I\u0027m not sure it\u0027s worth optimizing I\u0027m not sure it\u0027s worth fixing I\u0027m not sure it\u0027s it\u0027s worth eliminating I guess I\u0027m saying maybe if we just stick with what we got put our hands up in the air and say yeah yeah I think you have to stop pretty soon that\u0027s like kids good summary I mean we had nationwide TPT right which is basically these wonderful sub 50 millisecond layer two rings which were basically carrying all TV programs of the bloody country and you know when you had a switchover between the two app streams and you had 50 down streams right you do get bloody asserts and you have duplicate traffic you know to all the receivers right that is not a good service thinking we\u0027re gonna be done there appreciate those comments those are very helpful us authors will powwow and if anybody\u0027s interested in joining us in this please do and we\u0027ll decide whether we want to pursue it or not thank you yeah and if anyone wants to write some new drafts of proposals on how to do a source different your improve them or avoid them whatever I mean you\u0027re you\u0027re welcome it\u0027s a good discussion and you\u0027re bringing up a starts to be excite people and cause some discussion thank you so my meatball you know Kia so first I\u0027d like to thank the chairs for allowing us to present this here I think this is a new multicast concept and it is being the PIM group it would be nice for everybody to hear about it it\u0027s a "
  },
  {
    "startTime": "01:19:00",
    "text": "concept that we are working with Bell Canada and our Cisco colleagues and basically what it is it\u0027s a segmented routing policy for point-to-multipoint so the basic idea behind this concept is that as probably you guys know going forward there has been some changes on the unicast on some simplification this segmented routing the removal of an LD they remove up removal of MPLS protocols like LD P rsvp-te everything is being advertised with underlay IGP overlay BGP and then you have the PCE which really calculates the traffic engineering and any updates to the to the path of a LSP throughout the domain so those simplification of course starts trickling into the multicast domain as well and this is the main idea behind this new console so basically what it is it\u0027s it\u0027s a segment routing policy its instantiate it on a PCE from a route to a set of leaves and it gets downloaded from the PCE we had different type of technologies which I\u0027ll go through it later on but it\u0027s Pisa whether it\u0027s BGP srte etc etc the PCE will download the tree to the nodes or the PC sees and then the traffic will flow throughout that point-to-multipoint tunnel what are the point-to-multipoint tunneled is the Kimsey or whatever it\u0027s sitting in the IGP and certain SG like IGMP team joins will join will actually go through that tunnel beside the point it\u0027s going to be like a MPLS tunnel on the data path that is instantiated via the PC so I think I kind of explained this but again the SRA application is a point-to-multipoint segment and if you guys are familiar with segment routing a segment is presented via a label hence the MPLS part of this in the future we might extend it as our v6 but as of now it\u0027s MPLS so you will configure the data path on the nodes we are MPLS there is going to be push actions there is going to be swapping actions on the data path and there are two type of replication seconds there is a spray basically what that spray is is ingress replication meaning that you try to create your tree via point-to-point segment routing tunnels and then there is a tree see a tree seed is more like a tree obviously by the name and what it means is there\u0027s going to be a route there\u0027s gonna be a replication points and there\u0027s going to be a leaf the entire biggest point here is the tree itself is a single segment "
  },
  {
    "startTime": "01:22:02",
    "text": "so it\u0027s gonna be presented we are a single MPLS path and a single label astac how that label a stack gonna be if it\u0027s gonna have extra pushes on it comes on the PC which I\u0027m going to explain later on or you could have and label a stack with multiple labels on it when you try to do fast reroute when your route is resolved via point-to-point segment routing tunnel then you can start stacking labels but as of now that receipt is a single segment so the entire idea will take the spring segment routing policy to the next step so we are actually using that policy to to create the point in multi-point segments and it\u0027s really identified via our route and we are a set of transit nodes and the leaf nodes you can do traffic engineering there could be constraints colors etc and all those are done on the PC so basically from the PCC point of view or north point of view we will send the update to the PC saying that this is the route here are set of the Leafs on the next slide you will see that and this point multi point three is identified throughout the network we are the root node IP address loopback whatever it is and a tree ID which is unique on that root node so here\u0027s an example of it basically these three was in Senshi ated we are a single root and two Leafs and then the PCE was able to calculate the path throughout the network so in this case you can see that the PCE programs so maybe I should take a step back how it was in Senshi ated on the root in this case could have been via two mechanism you could have gone on the controller and you could have said that here is my root statically configure it and here are my leaves and then the PCE will actually figure out the path from the root to the leaf figuring out what are replication notes or another way to do that is you could have used the next generation and VPN procedures with BGP where you can discover your Leafs via an VPN procedures on the route you will discover all the Leafs via those procedure and the routes update the controller with all that information and that\u0027s how the controller will know where the route is and where the Leafs is either way it doesn\u0027t matter the fact remains that the controller needs to understand a single route and multiple leaves to build that tree so in this case when the controller was really trying to build the tree it realizes as an example from n1 to entry there is a ijp shirkuh the example here so what it does it actually built a label stack with that IGP shortcut on "
  },
  {
    "startTime": "01:25:04",
    "text": "top of the tree see and we were gonna have multiple label stacks or with the same token it between n 3 and n 5 in this example there were two links entry could have created a fast reroute protecting the previous link and that fast reroute were it will be programs from the PC to the node will have another label is that so you could actually do label a stack in video it was mechanisms from the node to the PCE you could create a tree you could delete a tree and you can update a tree based on these procedures PCE will recalculate the tree if there is some optimization the PC can do make before break so from redundancy resiliency point of view you\u0027re gonna have redundancy and resiliency on the node itself which is fast reroute and you can recover the tree within minimum amount of time but after that like any other MPLS protocol out there rsvp-te point-to-multipoint RS 50 you could optimize the tree and redownload the tree to the to the PCCs or the nodes and do a make before break whether that\u0027s local optimization whether its global 3 optimization and you\u0027ll make before break to switch to a new optimized tree so with the same token there will be a couple of more drafts coming up as I mentioned we try to keep this concept very simple the PC is the brain of the concept the PC is the one that calculates the entire tree as of now IGP is not involved in calculating the tree except the fact that the linker states are sucked up to the PCE there is gonna be a PCE draft which the SR policies are going to be defined they are gonna be based on like extra objects based on the current SR policy there\u0027s going to be an VPN draft and the SR v6 3 C or fully bill comes in but this is Dina a question on the PC ok compute reverse paths as well there\u0027s no reason why I couldn\u0027t remember because the the PC he really has the entire state of the network right so assign if it\u0027s RPF or okay and a suggestion spray it might be good to have another term a different term because people rather than introducing new terms people are going to say is it like this or is like that maybe you should call it head end replication because that\u0027s what it is I mean it\u0027s henan replication of using regular segment routes and for Teresa that is probably as good as any other thing I mean replicating said or whatever but um but it just spray and also spray gets scary because it looks like it\u0027s broadcast right actually that\u0027s a good point thank you very much appreciate there are indeed looks some discussions and on the terms I also agreed that could be renamed for "
  },
  {
    "startTime": "01:28:06",
    "text": "something else but ahead Andrea and replication versus ingress replication the ingress replication is a is established name yes this in some context yeah the other reason I wanted to rename and I forgot to bring up the point is your what you\u0027re really doing is you\u0027re replicating on the route some people call that ingress replication other people\u0027s call it egress that\u0027s another source of confusion [Music] any other comments questions so I\u0027m not gonna go through that last slide I think this is going to be part of this spring from adaptation point of view but thank you for your time who already saw this in M Bundy okay not too bad okay so this is an an update report of the work that started out something around ITF 102 about how can we update the status of our AGM P and M LV RFC\u0027s with a particular fun data point that if you\u0027re looking for the best standardized full internet standard receiver signal protocol use IGMP version one nets and full internet standard so obviously that\u0027s not what you want to do but everything newer has just you know draft or proposed standard and so we wanted to change that and so then we started to understand that we need to steal the process we did with him which is basically trying to vet the industry operationally and implementation wise what\u0027s out there for the newer ones and once we have that understanding hopefully then Alvaro tells us the next steps on how we can basically update the status of the documents and maybe we need to fix the documents but so right now we\u0027re at this questionnaire estate and so around ITF 103 we formed a mailing list any group of people that started to work out that questionnaire so there were a couple of really good meetings where we had all these people here which are also now on the draft come together and work out the questionnaire it\u0027s just a comment I\u0027m not sure if it\u0027s in there but the mailing list is archived and everything is public so you can go and see it there oh yeah and this was a wiki and some stuff right yeah wiki really um yeah if you go to the pimiki there\u0027s a link to pin wiki oh yeah I looked on the inbound e wiki a okay I\u0027m confused right so so "
  },
  {
    "startTime": "01:31:12",
    "text": "the plan would be to finalize this with basically the feedback we got some feedback in EMBO Andy hopefully we\u0027re getting feedback here as well and please if you can bring it up on the list ideally so that we\u0027re not losing it through the minutes and once that\u0027s done the plan is described in the draft is to have the working people working chairs but maybe hopefully also anybody else who has an idea try to start circulating with a request for feedback that questionnaire to you know vendors and operators so I mean the obvious one is in a two mailing list right there\u0027s internet whom multicast hopefully will remember all similar mailing lists in other parts of the world or you know specifically address and send it to operators that we know in the ITF right just sending it to pay more in bond you will not have as much an effect as sending it out to the individual operators we all know here and then the process would be to designate a trusted party that collects the feedback and anonymizes it and so the proposal here was Tim Joan I guess that\u0027s something to finalize by the working of chairs and put in the final question yeah yeah so Tim Chum did this for him sparse mode and I have briefly talked to him and I think it\u0027s okay doing it that would be necessary one thing though I see you know like we discussed and then BOOM do you draft them here we have on this slide is still sorry I was totally back Gloria on the next slide is corrected so yeah so there is there is a draft that we you know need to consider later maybe we should adopt it or not but I guess it doesn\u0027t really matter that much right if we want to just in on data tracker you know finalize it for eternity we can as well adopt it once we\u0027re done with everything so that it gets posted but I mean having in RFC isn\u0027t you know much different from being able to send around the draft yeah so we can discuss that later here do we need to Mindless hopefully we\u0027re getting that done before 105 right so that we get through the process and then the story continues from there on so can you click there I can\u0027t click click let\u0027s see in the past this has shown to work can you maybe get out of full screen because it may have right yeah it did work um yeah so we skip the ITF yada yada then there the introduction is kind of for the target audience the yada yada why we\u0027re doing this I think we explained this and then basically we\u0027re starting "
  },
  {
    "startTime": "01:34:12",
    "text": "here with the intended audience and we\u0027ve basically cut the questions were replicated then and it slightly made them different between operators and vendors so let\u0027s go down obviously you know here the first one is for implementers a lot of the questions are duplicated but we wanted to make sure that people don\u0027t get confused and so we duplicated between operators members so here\u0027s the implementation status questions right IGMP v1 v2 v3 also very important IGMP v3 lights so one of the interesting outcomes obviously in the end would be can we identify from the feedback enough justification whether to make IGMP v3 light or full IGMP v3 the final best recommended standard same thing for ml DB 1 ml DB 2 so and then it goes go further down so these are a little bit open-ended question because we felt a little bit that overwhelming customers with details would be too much in EM Bondi we got the feedback that we may want to give an example list of features just as hints and I think that\u0027s one of the things we\u0027re going to do then very similar go down to a3 implementation perspective questionnaire that\u0027s your right so this is also yeah it would be lovely to to get feedback on on this implementation perspective that\u0027s also a little bit open-ended because we\u0027re trying to really compress the thing and not come up with a lot of detailed questions but obviously that is always difficult to do then going down 3-2 deployment stages so this is you can go down faster here all right so you saw this was copy and paste and for the operators deployment specifics are very similar just you know are they deployed and yeah also the type of open-ended questions so yeah we would love to get any further insight and also within the team are going to go back and revisit the latest state here the the the one other feedback which I found to be helpful from Mikkel Abramson was the bitching about the problem that in IPTV deployments he wanted to have SSM and then ultimately he got the answer yeah we\u0027re doing IGMP v3 which just meant the setup box operating system supported IGMP v3 but the application was just sending an IG MP group membership report so the application effectively didn\u0027t use as the same so and my proposal was that we do add a section their application and asking basically if applications that should use you know SSM are not using SSM or something like that it\u0027s clearly somewhat outside of the original scope which was just for PIM to understand the status of of the "
  },
  {
    "startTime": "01:37:15",
    "text": "RFC\u0027s that we should get because this would be an application question but I think for us in Ambon Dee and also trying to figure out how to deal with this problem that you know IGMP v3 support by the OS is not good enough the application also needs to do SSM how we can basically in the future try to you know highlight that that as an issue better so that was that there was a suggestion to add a section on that with you know one or two very simple questions and yeah go to the end I think that was pretty much it yep please read and who has read it here good who has already posted comments please post some comments to it on the mailing list right so so that that we you know get really that insight and yeah any questions here one question that was raised is how do we reach out to the people that need to respond to this so there\u0027s like vendors that go to the ITF but it might be like hosts tech vendors that are not here at the ITF of course this feels like nano go right pointer to your you know communities I mean there are a lot of people that you know have connections to do to these folks I mean we can try to figure out when we are at that point or we can split it up so that the poor folks that say from Microsoft or from Google or a Linux folks don\u0027t get overloaded but I think we can we can come up with some good listened have multiple of us divide that up yeah toom winners from the UNH I well you know we have a lot of people who do testing for MLD and IGMP at our lab in particular we do have a lot of MLD because of the US government test profile we\u0027d obviously send this to all of those posts and random vendors to try to get them to respond excellent [Music] [Music] "
  },
  {
    "startTime": "01:40:17",
    "text": "No [Music] [Music] yeah have to look into the smell of yeah yeah yeah no one cares she\u0027s British to be honest you program vacations you know yeah I haven\u0027t seen [Music] [Music] yeah explaining a few items first first level versus charity the second was pretty strict as well [Music] "
  }
]