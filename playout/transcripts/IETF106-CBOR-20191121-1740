[
  {
    "startTime": "00:00:04",
    "text": "okay okay that\u0027s why for you so let\u0027s start hi everyone here in the room for seaboard working group please note the note well we have minutes being taken by Michael thank you so much this meeting is recorded your presence is logged there are blue sheets going around and think your Jabra scribe as well and we have our chair gym in remote so for the agenda today we have a short introduction about the working group status these working group document status then Carsten is gonna walk us through some sibour specification issues left we talked about CDL the ways forward and we have some sex time and I times are definitely not final so we can we can move some time around if we need to finally we will wrap up any agenda bashing nope okay so status update we got six interim since ITF 105 I thought these were really useful we progress the documents you can find all the information about them the recordings are on on YouTube minutes slides everything we have on this link the chartering has been finalized since ITF 105 the sea beret tags and seaboard sequence sequences document or in RSC editor queue so great job with those and finally we have C Barbie\u0027s version 9 which has started it\u0027s working group last call in last week or yeah Thursday last week and that will go on until December 12 it\u0027s a long working group last call because we have ITF week and also some holiday going on after that so please do send comments about this before we move on to the Super Bass I wanted to discuss in terms so now that basically Super Bass is almost done we might want to stop the interims every two weeks but we me and Jim were suggesting to have these three interims up to end of January so this are all on Wednesday December 18 January 15 and January 29 or Wednesdays in the same "
  },
  {
    "startTime": "00:03:06",
    "text": "time slot and then we can have in dreams when we need them if we need them do you have any opinions about that thumbs-up from carsten 4 to 5 UTC is the time slot so let\u0027s make sure that they don\u0027t collide with the core in terms if those continue which I think they will they will but they will probably also go to a slightly slower pace so you\u0027re saying they will collide no they will go to a slower pace so we will also not have one every two weeks yes yeah okay great yeah then we can start talking about Super Bass yeah so I have one slide about cos it\u0027s done no it\u0027s not quite like that oops so just just as a reminder what this was about we were planning to take SIBO to internet Senate so this is not the time for great innovations this is the time for fixing things looking at it\u0027s Robert Horry making in particular making improvements in specification quality because that is probably the biggest source of potential into our ability problems and we had some some 29 issues that Poland is closed since IETF 105 so there was some work document does look a bit different now it still still has the same substance but it has a different structure and as Francesca said we we are now in the working of last call so I think the the biggest thing that we managed to do is understand the various kinds of errors in a better way and also I understood where these errors could potentially be handled so we clearly separated well non well-formed from non village in village situations and the document just surf the data item it\u0027s not well formed there\u0027s not really that much you can do and we now have "
  },
  {
    "startTime": "00:06:09",
    "text": "corrected pseudocode for there there even was a small bug in the pseudocode and the appendix for well-formed and then the the other question is is the semantics okay and semantic errors are of course also errors but it may still be possible to present a data item with semantic errors to the application if there is a way to indicate those errors so the first two of the three levels levels that that happen at the level of C bar in the generic decoder for instance and then there is the third level of course the most applications will need some form of validation on top of the validation the generic decoder can do and this is out of the scope of this document and that\u0027s where either handwritten application code comes in and or some form of data definition language like CDL or JSON schema org or UD DF or JD DFO however it\u0027s called right now or JCR or there are lots of these that are out there and can potentially be used for SIBO data items so I think that\u0027s a good thing that has happened and I think we have pretty much completed this change other significant changes we now have not only have in appendix with working examples we also have an appendix with examples that have where from this errors we have discarded the concept of strict mode because it meant too many different things and we also do not paint the idea of a SIBO firewall that was probably a bit misguided we had a bit of tightening on the JSON to see what conversion issues so since C Bo has a richer data model then then Jason there sometimes the question how exactly do we interpret some jason in adjacent sasebo conversion we are not standardizing this but we are defining enough that an application a protocol can essentially just reference this section and and maybe provide a little bit more information how it wants its conversion being done instead we fixed a bug in the appendix with the pseudocode for detecting well-formed s and we worked on validity and there we now have the the "
  },
  {
    "startTime": "00:09:14",
    "text": "validity in the basic generic data model which is exactly two things correct utf-8 syntax and non duplication of map keys and then we have tag validity and of course since we have dozens of tags we have dozens of different things that can go wrong there and given that the number of tags is supposed to grow the idea that a generic decoder is a completely validity checking decoders is rather unlikely all generic decoders will have limitations there and the important thing here is that these limitations are documented are communicated to the application so the application knows which parts of the validity checking has to do itself because it hasn\u0027t been done by the generic decoder so that is pretty much what what has changed of course there are 29 issues also that there were many things that on the editorial level even more complex editorial things and there is one open issue actually there are two open issues but one is just the tasks that we have to do it doesn\u0027t have anything to do with the document and the other open issue is what exactly what owners do we exactly put on an application protocol definition how to handle duplicate map so besides it\u0027s interesting that we are not even discussing this for utf-8 for the utf-8 validity but for the map keys it\u0027s a little bit more a key because well different implementations handle it in a different way and that\u0027s not something that we have invented or Mis designed or something but it\u0027s something we inherited from JSON and interestingly nobody in the JSON world is as concerned about this issue and well yeah so how do we handle it and my proposal is to essentially punch and say well we live in a world where we\u0027re not all decoders will be validating in this space so it will be the unusual case that an application protocol says must error out on on a duplicate map key and the problem really is that many decoders by construction just silently discard duplicates so I spent a couple days between the IDF\u0027s trying to fix my main Zeebo implementation to detect duplicate "
  },
  {
    "startTime": "00:12:18",
    "text": "map keys and it just turns out it\u0027s much more difficult in the platform I\u0027m coding true then I thought it would be and I think other decoder writers will have a similar problem so the generic decoder may be discarding duplicates and may be discarding the the early ones or the late ones or something in between we don\u0027t know the application has little control because it only sees a very nice well-formed map and so that\u0027s the normal situation there may be some applications that actually have to require village validity checking so that\u0027s not outlawed but this is the unusual case so what there is actually a must in the text and the the must here is the application protocol designer needs to make up their mind so is it one that will work with most decoders or is it one that actually needs a decoder that does the validity checking so my proposal would be to put her bound tricks on the on the number three and Geoffrey you put this issue in luckily is here so maybe you can have an opinion on that I think he\u0027s reviewing the issue let\u0027s give it a couple of minutes yeah we can can Oh No okay Sean Leonard I actually just have an observation or a question given the extensive use of JSON and protocols and so forth are there a class of known security vulnerabilities that have been reported that exploit duplicate map key issues and the different ways that decoders handle it because I\u0027m not personally aware of cases where it\u0027s actually been shown to be an exploitable problem and I think that if there are if it is then it\u0027s much more important but if it\u0027s not then maybe that just shows actually it\u0027s not that big of a deal Jef Raskin I\u0027m gonna ask our security team about that question whether whether they can give some examples of JSON vulnerabilities caused by two keys I do feel like even if we don\u0027t want to require applications to to like require say picking the first key or something that the text still needs to change because right now it says like make an intentional decision and it\u0027s not clear what what they could decide if "
  },
  {
    "startTime": "00:15:18",
    "text": "if these are the two choices that either kind of pick an arbitrary one or error like if those are the choices that are available we should just list them I think Paul Hoffman so it\u0027s not an arbitrary choice at least in the Jason we\u0027ve seen ones where once you hit a duplicate it swaps in the duplicated it forgets the first one and we\u0027ve seen them where once it sees one it it it ignores it so I\u0027m going back to your question Shawn if there is a security vulnerability found it\u0027s likely to be in just one of those not both of them so if we say pick one then we\u0027re picking you know we\u0027re hoping that all the security vulnerabilities were in the other one which doesn\u0027t seem likely to me and certainly if we revisit this question five years from now it also doesn\u0027t seem likely the other situation here where why I agree with Carsten on no change is unlike Jason we have indefinite length maps so if we say you got to be careful you got to do it there are are you know given that we have indefinite length maps there are a whole class of applications that are very appropriate for seaboard that are completely inappropriate for Jason where we\u0027re now saying you have to remember every key you\u0027ve seen whereas for some of these it would make great sense to say I\u0027m only going to look at you know like like let\u0027s say the key is numeric I\u0027m only going to look at ones that are divisible by 10 or wait you know like there\u0027s things like that and you don\u0027t care because there\u0027s all these down now if we\u0027re saying oh no you\u0027ve got to save all the keys that\u0027s really bad okay so before Laurence Jim was in the queue so so so one of the types of cases where you actually could have a security vulnerability is in cozy if you use the the critical header parameter and you put two of them in to the protected header parameters different applications may pick up either the first one or the second one as being the one that they care about and that could produce a different security answer yeah I think that\u0027s exactly the the situation where the security problem comes in where you have one data item that is interpreted by multiple different implementations so for instance player a generates some some data structures player B signs it and player C interprets it and that\u0027s where these these problems come in so lauren slim blade so i actually wrote "
  },
  {
    "startTime": "00:18:18",
    "text": "the code the gym was just talking about since the last IETF so and had to think about what was going to happen with duplicates because josé\u0027s specifically says no duplicate header parameters so that did that detection I wound up implementing it in the cozy layers not in the C bore layers so it was not a characteristic of the decoder it\u0027s a characteristic of the thing above the decoder above the generic decoder but you know you\u0027re not going to see the duplicates if the decoders from your discuss them depends on how the decoder works yes most decoders actually work by discarding one of the duplicate keys but some don\u0027t some don\u0027t yes and some don\u0027t and the ones that don\u0027t then the how you handle the duplicates is a characteristic of the thing on top so it seems I mean it\u0027s just I don\u0027t know seems it seems there\u0027s a lot of variability here I guess my question and so my brains not very working with unbounded map it\u0027s not the right word indefinite I knew that was the wrong word so so with a pull parser and an indefinite map you would not until you got to the end you wouldn\u0027t know if there was another key so you would in a pull parser return the first one and you\u0027re done you found it right and so any any ability to say you should validate means that you always have to go to the end of the stream right so not even a question of you\u0027d have to remember it you have to process all gigabyte of data even though the thing you want was specially arranged to be in the first you know kilobyte so it would be the very end very bad to say something like this that\u0027s a fundamental issue with Matz yeah and and so I I would say that I think we should make some recommendation as to whether you should keep the first or the last okay but I also think that we should say very strongly that you know there probably that it\u0027s it\u0027s probably indefinite we should make a recommendation not a a must if you understand what I\u0027m saying yeah except there\u0027s there is no good recommendation I think picking not none is is worse that\u0027s all okay Sean Leonard I think picking on might be okay so I respectfully disagree with that i think "
  },
  {
    "startTime": "00:21:18",
    "text": "that no change is is okay I have another observation of about this duplicate map keys problem I think that it\u0027s much more serious when the attacker controls the production of the map keys so that when so if you ask for user supplied or attacker supply data and the attacker provides the map data as opposed to the map keys it\u0027s not really a big deal because the keys are chosen by the secured by the secured code base more or less it\u0027s it\u0027s when you ask a potential attacker to supply the keys themselves right or an open ended production of keys where it could intentionally construct pairs that have repeated keys that\u0027s a more that\u0027s a source of potential additional security vulnerabilities and that\u0027s really common to maps in general not a seaboard specific thing hey hi this is Hank so I think that\u0027s almost nothing left to say from here except that I\u0027m Pro no change which is one strange when you say it out loud and I always assumed that the last key was the valid key with indefinite maps I think you should be very careful in case to allow them in any case because they can be a real big issue but still I would not recommend first hit but last hit in that case but just a personal opinion I don\u0027t think that is for me to decide but I am in favor of the proposal thank you and so actually if you look at the JSON objects they are a bit like indefinite maps in Siebel because you don\u0027t have information from the beginning how long they\u0027re going to be so I think we are quite close to what happens in Jason here and I haven\u0027t done a serious search about the check versus use problems that we are talking about so I\u0027m not aware of any such problem that that exists in the JSON word but that doesn\u0027t mean it won\u0027t existed at some point there\u0027s Jim pointed out we even know places in our data structures where where it could become a problem my name is Joe Cheshire from Apple listen if this discussion I achieved lurkers you made me think to check RC 67-63 for dns service discovery to see what language we had there and then we said if there are duplicates you take the first and ignore the rest and there\u0027s so there is some precedent for doing that and I think with the discussion of indefinite maps if the defined behaviors take the last you always have to read to the end whereas if you take the first when you find it you know you have it I think that "
  },
  {
    "startTime": "00:24:19",
    "text": "language should specify which is the right thing to do otherwise different people do different things yeah I would I would be most happy with language saying kind of you can either pick the first or error I\u0027d be fine with you closing with this with no change and I\u0027ll come back if the security team comes up with examples and we can reopen it but but that that change is what I prefer if you can do take the first you can fully validate so there\u0027s never a reason to do to the first if you read to the end yes I okay so I\u0027m having a bit of a hard time reading the consensus here because I hear a lot of different opinions and people are nodding or shaking their heads yeah Alex a personal opinion again either take first or error but I hope no change doesn\u0027t mean not saying anything about the issue I would Rodgers so the document already said explain that this is a problem okay and it says the application and protocol is an must say how to handle this problem but it doesn\u0027t do what what Jeffery just said list the options but I would not be happy with requiring generate decoders to always take the first because that is expensive in certain situations yeah it\u0027s those situations where the generic order generates a platform dictionary from the data then you just take the key value pairs and stash the values under the keys into the dictionary and when you\u0027re done with this the last one has one Alexa is thinking there\u0027s Jim in the queue if you do that then you already can store the whole thing in memory so you can probably do the right thing well I\u0027m not entirely sure I understand the argument for the for the decoder it may be twice the work to first look up the thing and and then only if the lookup fails - the thing Pete you want to go to the mic "
  },
  {
    "startTime": "00:27:27",
    "text": "yeah so Jim Europe I mean I I don\u0027t know that I agree that it\u0027d be twice the work since you kind of have to do the look up as part of inserting it into the dictionary I mean I think that that the answers are one take the first to error or three return all of them and let the the application deal with it because there are cases like you know when you\u0027re doing streaming that you are going to want to be able to return all of them exactly I was I was also going to say that if you\u0027re if you\u0027re filling a native map you can always check for presents before you insert and there are a lot of map api\u0027s where that does require two lookups but there are some where it doesn\u0027t michael so if you are processing a big map and you are interested in a subset of the keys which is a sort of a variation of the pull parser then for the subset of the keys you don\u0027t have to store them all you just care about the subset that you know so a gigabyte of map data and you\u0027re interested in twelve keys okay so you may have to read to the end of the data stream anyway to find it if all those keys are there if there are some that just don\u0027t appear right you\u0027re still looking and still looking and still looking and so that may not be so terrible most dictionaries lookups under the hood everyone said they have to find out where to put the item and so probably the check if it\u0027s already there while you\u0027re inserting it in other words insert if not already there is is probably does not require to trivet treat reversals if you have a good implementation unfortunately not patron so not all platforms are that smart but but but that\u0027s but under the hood they all do that right they all they\u0027re all looking up if they have a tree of some kind for a dictionary they\u0027re all they\u0027re all have to find out where to put the item and see if it\u0027s there or not and it\u0027s not it\u0027s not twice as much work it\u0027s order a number of entries in the map right it\u0027s may be much larger it\u0027s may be much larger if you have demanding myths this way you shouldn\u0027t be implementing stuff like this so most people implement maps using hash tables whether it\u0027s a hash table or a tree you have to find the location of the to put it yes okay there\u0027s different costs for doing that okay I agree but in both cases when you have the new item you have to find a place to put it and you would discover what they\u0027re already yes okay in that process "
  },
  {
    "startTime": "00:30:27",
    "text": "that phone code will even discard the old video and some of them will out will replace yes someone will do their plays you\u0027re asking I agree may not have a good way to actually get at their code Laurence limb but it seems there\u0027s there\u0027s cases were you\u0027re not gonna store the whole thing ever you just don\u0027t want to do that because the way your protocol works or something like that I don\u0027t know maybe time you get a an entry you flash a light and that\u0027s all you\u0027re gonna do then you have no way to I mean you can\u0027t dude you can\u0027t do any detection or the first or the last because you just don\u0027t know so if you\u0027re not storing it you can\u0027t you can\u0027t do anything right what so could you could you huh could you clarify what that will be then you\u0027re a preferred option for this yes to the microphone please Sean Leonard if if you\u0027re just care about if one of the keys is there once you get a hit you stop processing the rest of the stream so you know you don\u0027t actually want to keep on going you you got it that\u0027s it Reznik I have hopefully a question that might drive us toward something if we find a security problem an actual like we\u0027ve seen this before it really causes a security problem what are we going to do well we already have found it so we are standing here because we have found the problem okay little a security problem so an actual exploit that can be used because of this MU literature is full of check residuals products and the defect we happen not to know one for Jason just means that people have been reasonably prudent using Jason maybe so so we\u0027re saying that we are assuming that one such exploit one if not many exists and we\u0027re still some of us are still feeling like we should just leave it the way it is yes the reason is trying the reason is is we might find to one that relies on decoders that do this and one that relies on decoders to I guess we have three choices I have a hard time believing anyway there could be there could be two and so us finding one going Oh we\u0027ll do the other one isn\u0027t as a point of reference though we argued about this for I Jason and I Jason always said was "
  },
  {
    "startTime": "00:33:27",
    "text": "must not produce whatever I think we hunted once it\u0027s okay to punt again I mean because just because I Jason really is one of those successful things that we did with Jason I don\u0027t know all the sudden we can do better because of the Seaboard brother we want to be better than Jason so that\u0027s one reason I think as long as we\u0027re no worse Alex yeah I\u0027m not sure it would help but if we were designing new protocol we were we would have picked one right Geoffrey asking things you don\u0027t go away sorry it seems like the two options right now are say protocols have to decide between pick the first and error or we leave the text as it is as did I capture the two options correctly now pick the first is not a good option because it invalidates invalidates about half of the generic de corazon said that\u0027s not what we done from 75 implementations to so we I think alright I thought that the working group kind of has two options either we leave the text alone or we change the to say protocols must decide between pick the first and error yes I guess I guess yeah we could we could say protocols have to decide or they could leave that choice up to the application but there\u0027s kind of there would be to two valid choices which I think disagrees with Karstens statement that maybe you want to pick the last sometimes but it\u0027s not it\u0027s not picking it it\u0027s an accident of the way it can be efficiently implemented there was no conscious decision because all implementers of course know that you never get a duplicate lucky so they didn\u0027t kill I mean even even an accidental choice is a choice and I was suggesting maybe we hum between those options okay I think I think protocols you know in whatever we do protocols have to have the option to say they don\u0027t care you can\u0027t force a protocol into error or pick the first because then you to make a choice between those two you have to be tracking the key so to answer that if I understood Jeffrey correctly what he said is that if we do the change which is the second option that these working we put harm on if you do a hum the the change in the text will be either you don\u0027t care or if you care take the first or return or error so "
  },
  {
    "startTime": "00:36:29",
    "text": "it\u0027s like it\u0027s like two choices and then two more choices on one side is that right Jeffrey that\u0027s that\u0027s what I understood so this is Paul I propose we don\u0027t hum here there\u0027s more people on the mailing list who count and hum with a small number of people is actually more dangerous than with a large number of people Alexi do you wanna put your ad half-done can I make you make a choice I don\u0027t know I might do it in one core if this issue is talking something before okay so there is a third option to those that Jeffrey said which is don\u0027t change don\u0027t change the processing and make sure that there is sufficient language around describing why all of the options are bad that\u0027s I would say that\u0027s option number three okay now you can go ahead yeah the comment about you know you some some implementation will be class so yes they might but I\u0027m just thinking we have a protocol which is covered an issue of this okay well maybe I mean you but now most of us aware of it we could make implementations which we consider to be broken to be fixed by adding new requirements that\u0027s an option still available to us so this would be what I just said do not change the text and add text describing I suppose I\u0027m saying more of adding text so ruling out certain choices if it helps Michael here I I\u0027m I think that I think that if I understand the potential security threats that it only occurs if you haven\u0027t implementations that implement both ways that one is confused in one way in the other is confused the other way and there so so you said you know if we pick this baguette the first one that some group of people would have a exploit and we\u0027ll pick another well the other way another group of people have an exploit and I would say well I would say it differently if you pick one correct way then the people that did it "
  },
  {
    "startTime": "00:39:31",
    "text": "the other way are exploited and if you pick the other correct way it\u0027s the other group of people that are potentially exploited okay but the exploit actually depends upon the fact that you have to two interpretations if you if we can rule one of the interpretations as being that invalid and I think that that\u0027s part of the point of going to internet standard is to remove any big you ities like there then we actually we closed the exploit okay regardless of which one we pick we closed the export because we make everyone interpret it the same way so now we\u0027re just simply arguing as to which is computationally more efficient or more convenient and how many implementations we would obsolete okay okay so that\u0027s why I\u0027m don\u0027t feel comfortable leaving it as is because I think that the exploit is there because of the ambiguity not because of a specific choice a or b we require the ambiguity to be exposed in order to fort to make an exploit jeffrey askin we were looking for a JSON example of the exploit and the security team got back to me with a zip example yes in in android the signature checker checked the version of a file identified by the index and the parser that actually loaded content looked at the first one and when those were different it it allowed arbitrary content that was not signed Jim was in money go ahead what Michael said is true for cozy the only place that is an issue is with the protected attributes if you haven\u0027t happened in the unprotected attributes well you\u0027re not supposed to trust them anyway so if your code is screwing up because it picked up the wrong one it doesn\u0027t really matter all right so I think whether or not there was a security vulnerability is dependent on the protocol some protocols don\u0027t like just just as Jim said in the protected headers in in cozy it matters in the unprotected headers it does not in in the Jose says you can\u0027t have a duplicate header parameters so the text maybe should be if you are designing a protocol that has a security issue with duplicate headers pick one pick first or pick error one or whatever you do if you have a protocol that\u0027s the that has a has a would have encouraged our ability you need to pick one if you don\u0027t if there\u0027s no vulnerability if you\u0027re just flashing light or something "
  },
  {
    "startTime": "00:42:31",
    "text": "like that then you don\u0027t have to pick one Sean Leonard I think that it sounds from Jeffrey\u0027s description the security problem comes from when you have whether you a second piece of software or a second process looks at in parses the data item from the original source material versus taking the results of the decoded item in the first pass when it was doing validation or authentication if the first process takes the map and it sees the first or the last or picks one arbitrarily and then passes that decoded Siebe or data item to the subsequent processes there should be no exploit either way because it\u0027s only gonna see one and and the result of that security check like authentication where I will be yes or no but but if they but if the check just says yes use this and they take the original blob of seaboard data and then reparse it using a different decoder then that different can can make a different choice than the original one that did the authentication or the validation it sounds like yeah you essentially cannot do that for signed data for that data you always have write work from from the original right well you have to work or you have to work from the original but then you take the results of the original for further processing of to get at the application layer semantics of what the data represents Paul Hoffman so I think we\u0027ve gone down a rat hole here because this whole discussion is about valid a decoders that validate decoders that don\u0027t validate are perfectly valid the carbs are here perfectly good decoders so we can\u0027t make assumptions about receivers of the data because it might not be a validating decoder so who will look if we have to do this one we can make it safer we can\u0027t make it safer we can only make it safer for decoders that are validating and we don\u0027t know if decoders are validating so I\u0027m still ok with no change from the current text geoffrey askin a validating decoder will error here a non validating one might pick one or more of the of the values and replying to Shawn it\u0027s it\u0027s absolutely true that you need kind of two mistakes in order to get a vulnerability here one of the mistakes is parsing the same data twice with two different parsers but the other one is a mistake in the in the specification of the format that that there are two legal parses or even in "
  },
  {
    "startTime": "00:45:31",
    "text": "zip like one of the parses is not legal but it\u0027s still possible because the data is duplicated and and so we can we can avoid that second mistake by changing the definition of the format to require or the definition of the protocol to require that it that it pick one of the map keys well got to the mic so I I\u0027m not saying Paul Paul said I was claiming that all parsers need to be validating I don\u0027t believe I\u0027m claiming that I\u0027m saying a validating parson will error an on validating parser must must return one of the values a particular one of the values and we need to pick which value an on validating parser returns so this is a proposal for a change like the proposal for change of text so that the duplicate detection can be done either in the generic decoder or in the software above it that is using the generic decoder if the decoder doesn\u0027t this card yeah that\u0027s right if it doesn\u0027t describe yes that\u0027s that\u0027s the problematic Dakota and unfortunately it\u0027s the common decoder so to go back what I was saying before then if your protocol can\u0027t tolerate duplicate map keys you should only use decoders that can facilitate the detection that you need or so either they either they do the detection that you need or they allow you to do the detection that you need Geoffrey askin I think I would be happy with I think three three results one is saying like see Bor uh all generic non validating decoders pick the first or say the protocol has to say which which to pick or the protocol has to either say which value to pick or declare that it\u0027s not a security critical value and an explicitly saying that if the protocol decides it\u0027s not important for security that that it doesn\u0027t have to say I think would be enough warning for me to be happy with it yeah so I think the net effect apart from improving the security of the world is that we declare a significant percentage of the existing decoders non-conforming which may be exactly what you want to do but we should do this okay so I think we need to stop the discussion I thought I thought she bore base would go really quickly today apparently not but okay "
  },
  {
    "startTime": "00:48:32",
    "text": "we\u0027ll continue in the main list but what I\u0027m hearing is mostly against no change and we need to work on what text we want to add yeah Alexei can I suggest that Jeffrey you send a message to the mailing list I don\u0027t know I maybe I\u0027m just being talked to mistake but I almost felt like we\u0027re getting somewhere yes I thought and I know we need to stop because we\u0027re out of time yeah okay so great so there are also two new issues for super base that Lawrence has added into the github tracker I don\u0027t think we need to discuss them today Lawrence is shaking his head custom agrees yeah I would hope that everyone in this room submits two or three little editorial problems remaining so Lawrence started the trend change please do review the document yeah please go ahead and and submit reviews and you have until the 12th of December so now we can talk about CDL ways forward and we have ten minutes so we\u0027ll try to be quick we probably won\u0027t have time to go into the details that I was hoping we would so the what we started doing me and Jim we started identifying interesting features for CDL users to go forward so CDL features that are not in the city deal RC these are additional features like going to a CDL 2.0 and today I\u0027m gonna give a report of the first investigations they started at the hackathon and the discussion today would probably not happen but if it did it shouldn\u0027t be focused on the technical solution rather on the scope of the features and possibly identify pitfalls so this is the list of new features that were identified those were taken from the mailing list and from C were the Karstens document CDL freezer so we have prepared the questionnaire a survey that we will end up send out and please fill it in even if you have been so kind to answer to all my questions and put in any feedback you have or any questions any questions you have about this so probably not gonna read them all but "
  },
  {
    "startTime": "00:51:32",
    "text": "this is the result from the 11 responses so in green you have the yes response yes I want this or I\u0027m interested the yellow is a maybe in the future possibly and the red is either no don\u0027t do this or it\u0027s mostly this worries me so it might not be a no don\u0027t do this but it might be a if we do this we need to be careful that this is done right so I I ordered them based on mostly on the yes and the top four features are the module superstructure import/export computed literals variants so both seaboard and Jason variants in one speck and do coke current constraints most of these are don\u0027t need too much explanation but I tried to summarize as well what what they mean so for module superstructure is about modules for Citadel definitions that can be referenced from under modules and we identify some of additional features that would be needed to be included in CDL like name spacing import/export module naming and versioning just checking time to see if we should have a discussion or maybe let\u0027s have a one or two minutes if you want to go to the my again so Carson said hard this is hard this is also the top feature that everybody wanted this is just Alexi you wanna say so yeah so another plus one for this feature which is hard but yeah so these are points that the working group would have to decide on if we get this and I think if I don\u0027t get this wrong yeah so we also have some this worries me about this feature so we need to get this right if you want to put it in next feature let\u0027s see if nothing from the jabber okay so cast is a piece of cake about this feature so these are all computed literals right now citadel is not defined to be able to compute and we are considering to add the functionality to define integers as components of a computer operation or string literals and operation being concatenation or so station or representative or tags a string literals tailored to their semantics rather than she realized Sieber so these are three options was that it thumbs up what "
  },
  {
    "startTime": "00:54:33",
    "text": "thumbs up to three in in the room one and two easy to implement otherwise I have to repeat everything you say so Sean Leonard so what I was saying is I like three I\u0027m in favor of three threes gonna require some design right because there\u0027s an infinite number of tags potentially so there could be infinite numbers of representations one would would depends on the tag right so it\u0027s extensible for one and two it\u0027s easy to implement as Carson said but I think that it it will clutter specifications and make them harder to read and make it much less obvious right so right cuz the literals then go all over the place yeah okay thanks thank you so this is Hank I\u0027m to blame for one and this is due to I\u0027m writing a lot of CDL and a lot of the content comes from the old world and sometimes they have despite offsets and you I\u0027m ahead creating scripts to write my own CDL and and I can compute them and and and so this is why one exists is this a convenient feature and an inference or a convenience feature and CTA per design should be full of convenience features so that is why I\u0027m really also in favor of one and you can do one thing and stop not printing the other so when you can do both I say be and I think it\u0027s not a bad thing and it might be cluttering but if you\u0027re coming from another specification and you\u0027re new to seaboard that\u0027s why CDI and and a translating it it makes the work so much easier for you Sean so I\u0027m all in favor of syntactic sugar that makes things easier to read and understand for one specifically can we have a list or consecutive items where increment is implied or essentially part of the sugar are we talking about plus 1 plus 2 Plus 3 plus 4 plus 5 are we actually talking about complicated mathematical operations like x 2 mod 3 whatever for your different symbols right I mean increments is is great that makes a lot of sense but if you want general-purpose Turing machine as a math then that\u0027s that\u0027s a different thing that it\u0027s not what I want but this is what one implies so as an item one implies so I I would not love to see something I cannot powers anymore because the equation is like two lines long and no no no this is no this was not my problem but but we figure out you\u0027re right it isn\u0027t there\u0027s not there\u0027s no scope to item one and naturally we would have been in scope so yeah I\u0027m with you with the complexity then I\u0027m free and the "
  },
  {
    "startTime": "00:57:34",
    "text": "convenience in one and we have one additional question which is can this be done separately from CD do 2.0 so custom saying yes Paul saying yes so some of this what\u0027s the difference like you know extension versa CDL can you go to the mic sorry custom CD less defined extension points so some of these things can be added without changing the language then for instance the symbol plus operator may be a substitute operator can be added just as a control operator okay let\u0027s we have two minutes left so I\u0027ll just will continuing the menu list anyway for all these features and we\u0027ll get more data with the survey as well variants both Sieber and Jason variants in one\u0027s back that\u0027s pretty self-explanatory I think and co-occurrence constraints there\u0027s a lot of text we don\u0027t have time so I will stop here feel free to go in and read the slides I also wanted to ask two people I compile this I asked it to compile this form if it\u0027s okay to put this up since its I didn\u0027t ask you before so like to upload it and or maybe on the C bourgie tab and let everybody see your answers or I can unknown amaizing who prefer yeah that\u0027s the thing under Mike the question is do you want our permission to yes this close our private information Hank version information the context of this Thanks I I think okay so if you have objections I will have to check anyway with people who are not in the room but if you have objections to your answers being uploaded please let me know either now or later I think yeah so the ways forward the point would be to start a CDL 2.0 document with the features discussed today we could also hear I would like to know who is interested in working on this document helping writing it up we have the usual suspects Hank "
  },
  {
    "startTime": "01:00:34",
    "text": "and Carsten but I would also like to hear if anybody else would like to help out more no one is raising their hands so this is Paul Hoffman I\u0027m gonna possibly volunteer other people I just remember during the CDL during the end of the CDL discussion there were lots of people who aren\u0027t like you know the people in the room who seemed interested in it and they might be more interested in as well so I don\u0027t think we were restricted to it okay so please let\u0027s continue this discussion as well yeah we will send out the surveys to the mailing list several million East and collect more input and feedback also there were several general comments about city DL that we want to take into account about usability and readability and learnability so that\u0027s this will also be reported and blue sheets if anybody hasn\u0027t signed if Jim wants to say anything else now is the time otherwise I think we\u0027re done thank you everybody so those who are interested interested in the next ten minutes I will explain what I will do and yeah so I don\u0027t have answers for the hard problems I think designing your good module structure is hard and we require quite something about requirements and so on designing good co-occurrence mechanism probably also is a significant exercise because we need to understand what are the actual requirements here and before we don\u0027t want to invent this stuff just as we didn\u0027t advance it IDL it\u0027s all stolen from from other things but to reuse things like ocl and schema tron and there are lots of things to pick from and we need to understand which of these we want to pick for but for the earth can you bring up my slides I don\u0027t know if we\u0027ll lose mythical or remote participants or if that is actually just for the people here in this room okay so this is not an official ITF meeting okay so yeah that\u0027s why I wanted to point through this freezer document it hasn\u0027t been updated very much in a while but it\u0027s so useful that there are pieces of solutions already Indian I mentioned that existing extension points can be used for this and the two candidates that I think are pretty much no-brainers here are computed literals and embedded "
  },
  {
    "startTime": "01:03:36",
    "text": "a B and F of course embedded a B and F is a significant amount of implementation work but it\u0027s actually almost trivial to specify so let\u0027s talk about computed literals first those of you who have programmed in Fortran will almost feel at home here for the other C it\u0027s not beautiful and maybe we can limit it to two the things that we really need at the moment which I think are plus minus n CH and concatenation but maybe we need a few more so let\u0027s find out so that\u0027s really easy a B and F well once we have not cared it\u0027s pretty trivial how to do this you need to pull one trick because text strings in c DDL don\u0027t allow new lines so we actually have to write the a B and F pieces as byte strings yeah but with this little syntactic a trick this is really almost usable in in the way it\u0027s on the slide right now so I think we could just go for this and an add syntactic sugar for it later that\u0027s not a problem but for now all that\u0027s I think pretty good wonder the detail that that most people forget when they talk about a PMF a B and F doesn\u0027t tell you how the thing that you are describing turns into a sequence of numbers then described by the grammar and there are two different ways of usage of a B\u0026F one where the a B and F describes the sequence of bytes and the other one where where the ABF describes the sequence of code points and I think we need both so we actually will have to dot a B and F operators and we have to decide how to call them yeah in the donor how many people are aware of that but if you have worked with every other for a while okay and a completely different animal is taking CDL which is essentially just a predicate on this road say C bar in sense just a predicate on a super instance and tells you whether that instance matches or not and turn it into something different which returns quite different pieces of information so defaulting is part of the semantics organization\u0027s transformations and so on this is a big thing and that also requires significant design extending the expressiveness of severe requires design and that would be the cuts a work that we have started and the "
  },
  {
    "startTime": "01:06:37",
    "text": "the co-occurrence constraints so essentially the two things that need to be done for co-occurrence constraints are predicates because we need to be able to say whether something is okay or not and some form of selector so if we say that one number here needs to be less than some other number we need to have a form to point to that other number in the data item and that\u0027s sometimes significant complexity syntactic sugar that requires a way to do transformations so we could pretty easily say the the identifiers in front of a single quoted string is another extension point of CD DL so that would be one way to get away without having an expression language but to do it in a general way requires the transformation mechanism and then finally the the module superstructure and the variants are things that should be composed from from components that are reusable in some form so that requires some design yeah and that\u0027s one of the features that most people want so yeah we should start their design now but we shouldn\u0027t that shouldn\u0027t keep us from doing no-brainers like like this and finally the the Jason stuff really is coming from the other side where we have a number of Jason related requirements that Jason operator is a no-brainer like we have dot C bar we should have taught Jason and maybe judge Jason see as well the variance part essentially requires a way to switch and then finally we have this CD dij thing and I would love to hear from people who are worried by that this is the description of CD DL in CD DL so this is this is the content of the of RC 86n and then you can can take an existing CDN specification and make it almost as ugly as json schema yeah and one question is whether we we actually should expose our planning here a little bit maybe take the freezer document and and actually say what we are setting out to do and and put some of the things that we might be doing in "
  },
  {
    "startTime": "01:09:37",
    "text": "the freezer a little longer why we are working on the other things so that that would be my proposal if we are a little bit further advanced to actually make this the working document Michael I expressed concern about the CD DL in Jason and I would like to understand the use case more I\u0027m worried about CD DL becoming turing-complete and taking over the same thing I realized that but you know now that you can put it in Jason then you can put it into your Turing machine and change symbols on it right oh you couldn\u0027t put pics strings information that\u0027s Church yes I realize that but I\u0027m trying to understand that the the use case better so that I understand what what it is that we\u0027re trying to do because if we if we\u0027re making it adjacent representation then I presume that part of the reasons we want to write programs that both read and write CTL yes and it\u0027s one thing you said I want to read CD DL produced by human and then it\u0027s another thing if I start saying I want to produce CD DL by a machine which I\u0027m then going to feed into a something to produce Jason or something else from it right at which point I get I I\u0027m worried about what happens to the debug ability of the resulting protocol which has been produced by sort of two layers of machine interpretation right that\u0027s all I\u0027m trying to understand who wants to use it in Y and that\u0027s why I\u0027m really concerned about the thing and and then what what things they might prefer not to have in their their version of CD DL because it\u0027s inconvenient to to round-trip through their machine let me give you two reasons why where this is useful one is simply you want to write a tool that does some fall-off consistency Jake some form of search on a CD a specification that\u0027s just easier if you don\u0027t have to write a parser but but can just ingest the CDL in past form the other example what I really want to write this and have written most of the code already is that I want to write a thing that converts from JSON schema org and and other things of this kind to CDL obviously the output of that conversion will not be beautiful but I did this once already in in in 2016 with the ocf specification at the time and I found tons of bugs in there Jason\u0027s email as soon as I could look at the Infinity air for so it\u0027s really useful thing to do and this "
  },
  {
    "startTime": "01:12:39",
    "text": "conversion is again to two parts the actual conversion and the writing out of the human readable city and again I would like to have a tool that does the letter apart so it\u0027s easier to write the other kind of Twitter and for those tools it\u0027s really good if they are interoperable that\u0027s why it\u0027s a good idea to write this off I also worry that you\u0027re gonna end up in a situation where you\u0027re gonna have to parse it and see the D out and parse it in JSON and then say these two things are the same thing it\u0027s really really hard well you first solve the halting problem and then it\u0027s quite easy Sean Leonard I just also want to say since since Carson\u0027s lists include incorporating a B and F things I\u0027ve actually done some work along with Paul cos via and others on improving and extending a B and F so that it can handle things like Unicode and and a few other things that kind of directly related to what CBL is trying to do so I\u0027ll try to post some of those drafts to the mailing lists you can see that and see if it\u0027s useful to incorporate and also resolve ambiguities in how we can use a vnf more formally to define stuff some things thank you okay so I\u0027m done stealing your time everybody and thanks Mexico for staying on session is site or hallway meeting is officially over "
  }
]