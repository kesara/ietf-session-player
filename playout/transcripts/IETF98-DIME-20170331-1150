[
  {
    "startTime": "00:00:05",
    "text": "will fit in this room so um I\u0027ll out well the III didn\u0027t get into that point yet so I can kind of thinking like like the egos you\u0027ll barely fit in I\u0027ll just go and shut the doors it\u0027s right Flores and so we got a bit of arrangement here so I have one of these new use like mac macintosh computer so i cannot show anything so gene will paulo do that there is no connector that fits in this thing yeah I you need to go to the end because the agenda so I have everything in the children it\u0027s built on what note that I\u0027ll ever hear ya data tracker on how well she she will solo so so oh we have one in medical with grief yeah but then it\u0027s saying that as you need a code and I\u0027ve been bested but so they were talking about that and the air daily thing from "
  },
  {
    "startTime": "00:03:36",
    "text": "[Music] now I okay for you know people who are remote we are dealing with some AV issues here so give us a couple minutes I don\u0027t seem to be able to sleep over Oh want to help us then on so he\u0027s trying to get it ha yeah we\u0027re getting feedback all right good fish hey half eh think about is the best so you\u0027d only get bigger no not this one same people have a USB vga adapter oh well salud outfitting the new definitely fit I am but I can\u0027t get anything up there you really walk up with that yes but but to "
  },
  {
    "startTime": "00:06:38",
    "text": "make it go oh I mean I need someone hey hey neither yes here we go hey there\u0027s a reason I take over there okay so you can run it here i have this so the useful deal firm hold heavily open pipe but um free go here\u0027s that Reagan Smosh very public econ so we have a lot acres so thank you and the low seats are here pennies here alright so on again so this idea of eighty ninety eight and diameter extensions to maintenance and the if you haven\u0027t seen the note well during the week you have succeeded avoiding everything quite well but pay attention and read the montville so I have that part of my agenda so for thee that\u0027s the today we don\u0027t have too many kind of topics so we I think we should be able to enter Lee and the any comments on the current agenda you have to loot that okay that\u0027s a aircard use any through I have it\u0027s no scam this is ask yes so one okay so let\u0027s go for to the working group study so first one one thing so we had a chance of ad "
  },
  {
    "startTime": "00:09:41",
    "text": "so Ben is nowadays already oh well calm down yeah we had two chances during this week if you followed emailing this you could see that we have a request Cola for a moment and then then so we managed to wear out Stephen okay so we have been doing actually quite good progress recently so because p.m. so you know HEV have the agent / world and download and we also have the am so deeply some progress on file maybe we\u0027ll be sitting in a misfit for a while so they are waiting for the end great control also to kind of progress and for the red control we have a new version around so Steve posted the update including the N last of the comments that that we receive during the working class call so that is just bending me to submit the app for the writer panel and it goes move out of the working group and then we have the group signaling we are going to hear the update of this work again to it and then we have the actual active working Latin would be hand so the RFC followed to throw sick beats and we are going to hear the update on that and that\u0027s pretty much about this tattoo so any questions regarding the set of current we have the free hair on the air you looking good we don\u0027t tell anyone I prescribe know okay jeez yeah so anything so I would expect that be able to kind of complete all the load overload rated we\u0027re pretty soon it is kind of nice so there\u0027s a one concrete piece of work that we have been doing for a couple of years and another you really see into yet the end of it okay so working group traffic ascaso so we have two things first we hand market subtle about the cooking lane then we also need to kind of decide what we do with this work and then we hell I\u0027ll going through the air parc 400 Dave okay okay so uh let\u0027s let\u0027s get started so mark on up here oh you can do wherever "
  },
  {
    "startTime": "00:12:50",
    "text": "you want so I\u0027ll just pink boxes here\u0027s all you need to come here so then you stretch your rubber neck ll kind of walk around let me bring your you don\u0027t have the can i download them I need one more so where is TS tricky throughout the line for every nine holes abidjan today this one okay good all right all right so very brief update on on this drop it\u0027s currently in revision number eight this draft and work is all for a very very long time but we finally managed to fix the remaining comments and clarification and we provided to updates before this ITF 98 and Safari addresses all the comments which we receive also offers had a week through and data center to check so are the most of the comments were related actually to the group assignment couple of comments where a few comments were about the group operations where we really missed some texts in clarification out of operation pose to be so here we propose text unveiling this and propose options with some preference come out in front of you and got feedback and that\u0027s how it\u0027s covered in current legislation um brief summary under the items that have been fixed which is key words must must not shoot so or here made a proposal and of course we keep a commute that have been colored well most comments asset were about the in group assignment or one comment was about silver rejecting of group assignment so what happens if the server reflects with assignment on this is clearly indicated in the certain location action flags of the second group of AVP and there is no need for the client to retry so we add the clarifying text here and that was coming from funky arm partial success of the client requests from server to assign a new session too much of the groups and some of the groups are fine some of them have been rejected and assignment so we decided to make it clean for this graph which means if one of the groups "
  },
  {
    "startTime": "00:15:52",
    "text": "assignments fails so the whole improve the Thunder fails and the client and Pete server fall back to single session I\u0027m taking more fancy is needed at in future work and do that but I think we need to try to keep 17 years insane no okay maybe I keep it closer and I\u0027m so client fair at service such a group assignment may happen that the client requests from the server assignment of a session to one or multiple groups and the server assigns but in the response the client sees that for some reasons resources whatever the assignment made by the server of fails so what\u0027s the means for the client to feed back to the server and we decided to keep it also clean here which means the client must terminate recession and then we start procedure without request Oh professional Sonya so that has to be clarified in in the current revision next one yeah so what about the solar ejection for a client session group assignment and Steve actually caught that hard assignment because typically on the second group info a BP is included in all the conversations between climate servers or what happens if the client sends a request to server including touching group info every piece but in the response none of these 80 pieces available arm so the client should not retry session group assignment and start a single session request and it may add 50 or new pleasure group assignments for other sessions so that\u0027s the current ex how it\u0027s reflected typically the server can reject group assignments but them includes the session group info abp in response and sets the flag that the session has nothing so I\u0027ve been assigned to the the whole ATP is missing that\u0027s the current solution arm so there was some missing text on the operational part of doing group operations and here we focus in particular unlimited success so what happens if a group operation has been requested and the operation succeeds for most of the sessions in certain group of some of the session from command fails so far we have just indicated that the server responds with limited success but how to how to treat these groups in second so also here we propose back and has been the preferred option who in "
  },
  {
    "startTime": "00:18:54",
    "text": "here and keep a good accurate by first making the whole group operation failed for all sessions of the indicator second group and second the fail sessions need to be removed from all the groups to which you could come out right the moving the sessions could have been made implicit but there were some some issues so we decided to make it offered in here in addition to the single session call back or these fail session we started to have started procedure / leptin 422 which is about the removal of particular sessions from second fluid so this is a little bit more signaling but it\u0027s a cute way to keep unemployment so in sync regarding other session good all right next slide and that\u0027s basically it that\u0027s the main comments that we that have been remained from from the last meeting and so public in the document this in a good shape but we definitely need more reviews on so thank you so anyone want to challenge dish that the document wouldn\u0027t be ready for the last call because that\u0027s the set next thing that I\u0027m going to do they get the document moving forward yep and obviously I complete silence doesn\u0027t mean that the token passes to hear last call I I want some indications that sound actually ready so keep that in mind so you don\u0027t be now you know it okay good so we so we finally get kind of moving on and then complete this piece of work so how many years listen spin around how many years this document has been around many mean that\u0027s really fun to close this work and yeah good all right is there any implementations you know the implementation have you ever meant it but that\u0027s the only work you see so far about amazing diameter to support group signaling castle yep you make you document as it isn\u0027t about implementation or any other status I\u0027m not sure experimental if this is you during the time of his roof okay um Flaubert sprint I\u0027m not aware of any "
  },
  {
    "startTime": "00:21:55",
    "text": "implementations but i will just flat out tell you there are several things related to congestion congestion control in denver that we will not as an operator really look at until this documents stabilized if we start seeing if organizations so i would say this is actually blocking more diameter related applications in the conditioned space then in other SDOs at least their implementation ok sauce thank you for indicating that maybe need to drop this document kind of prevent more work coming in okay all right thank you Michael the next one is here sir Dave yeah let me try to find the yeah so Jeannie will do that hi folks I\u0027m Dave Wilson so we\u0027ve been working with the file and my coworker you thought we were requested by the 3gpp group to refresh this so so we think you know long story short we think this documents in a really good state now I\u0027m going to go over the differences between this one and RFC 4006 you\u0027ve seen some of this before just refreshing everyone\u0027s memory so this slide as would I think of as the mundane changes on because they\u0027re all pretty much things that we knew before we started that we had to do and think fairly obvious we know we updated all of the RFC 3588 references to 6733 which the base protocol which replaced it that caused a few other changes to be required and they\u0027re listed here as well updated 4005 references to 7155 there were references to 3gpp documents that were out of date we updated there was an errata on the 4006 which we which had been decided to to accept and we so we implemented that there were my be sac and TLS references that were inconsistent with diameter base and we updated those the use of the encryption column maybe p descriptions was inconsistent with the the base protocol and the way other protocols hadn\u0027t done so we remove that column and the Security section we updated to be consistent with the way other more recent diameter documents "
  },
  {
    "startTime": "00:24:55",
    "text": "have been done next slide please the more changes first ones a ambiguity about when restrict access and access action applies or just making that thinking that clear there have been some questions about whether used services had two were committed to go above the granted units and we clarified that these are actually you should just report usage and not clamp it to granted units it was it hadn\u0027t said anything on the subject before you just clarified that was possible on the next next one\u0027s been an extension it\u0027s adding a filter rural AVP is now documented as permissible in the restrict access action this is the more structured type of filter rule rather than the gift w syntax the other one called ipv6 representations had been updated in RFC 5952 since 4006 had been done so we clarified that the textual ipv6 representation should conform to that format and there did some questions about graceful media graceful service standard termination this is when granted units are 0 there were some hoops that the client had to jump through doing extra round trip time before was permitted to do the termination action and now it says that determination action is permitted to get the grants 0 the law will correct me if I got that well right another thing that came up was we were requested to add imei to one of the num the num group for user equipment in folk and when we started to do that we realized that the enumerations were not actually extensible so we made the user equipment info extension EVP which you know provides a way it\u0027s a group it provides a way of putting members in the group in an extensible way and we applied the same approach to all of the other enumerations in RFC 4006 so now they\u0027re also expensive subscription ID redirect server finally so and then the final unit indication a BP is also now permitted to use filter rule so we did extra I don\u0027t think I describe this clip properly the final unity no it\u0027s all right it\u0027s the qos prefixes you there "
  },
  {
    "startTime": "00:27:56",
    "text": "was a final unit indication AVP and now there\u0027s a POS final unit indication ATP which permits filter rule with the final identification yeah so a freak no tears oh ok yeah so um just like it the enumeration has turned out to be kind of lasting many times because it would look like kind of natural that you just add something efficient understood you get something meaningful back but that hasn\u0027t been the case so I had healthy intention of fixing this for a long long time but endicott are not doing it not at the year so we did have a discussion about this according intensive discussions yeah but at this promise I think that should be kind of discussed at some point of time anyway we should be fixing it somehow that is also backward completely compatible so it\u0027s not a trivial exercise so while burt sweetheart so could you maybe then after the meeting on the vegan lists bring this up as a subject started kind of the mailing list specialness given to you from this this will be a long yeah long discussion yeah I can kick it off so all those items just listed are in the appendix on what changed I\u0027ve convinced myself that that\u0027s a complete list of the changes i did a side-by-side diff of the two documents and painfully went through all the changes also so also that we don\u0027t believe there any more issues we haven\u0027t heard anything else we\u0027ve finished all this this has been uploaded for a couple of weeks now is it a month yeah so anyway so we think it\u0027s done we don\u0027t know of anything else to do progress and nobody\u0027s asked us for anything else so we would our opinion is that should be no gas golf so do you actually accept pull requests if someone wants to stop with text you pull requests we would read it and consider pulling it so what okay so all the authors think that this document is ready okay so happy have you had any reviews so far outside this is very crowded time working group so I would be very interested to have someone "
  },
  {
    "startTime": "00:30:57",
    "text": "review this document on three ttp excluding Lionel because that\u0027s kind of assumed but dl so because we got this design wish to update this document from frigid it would be nice if you could engage someone there and the like like not mrs. Lee on the same level that they had of the overload but but then we actually got very good reviews from 32 gb and that would be kind of appreciated so if you could go and ask around I think you have some friends in frigid BCT for open be willing to wait this he and a couple of people so basically the am they all they all old relevant and active city for diameter express exit join p.m. the Overlord work so that that\u0027s basic the list of people that needs to be involved yeah we can we can do this as a part of the real google plus CO or maybe before the european applause for Sofia we could actually have so if you have names in mind that we know so when i do the Alaska actually a unique asked a certain set of people in entropy of make Lionel the kind of post that into a city for a scene in a role of gt4 chair because we need to be careful that we don\u0027t step on anything that happens in 3gp on this spec it\u0027s actually implemented my little bit so if I don\u0027t know how to do that so one of you taking action to do that well okay so i can take on action on that so when I kind of broker station to working with plus Cola I\u0027ll i make my life codeshare to kind of poke thiet which is V folks on this and we have get them review how long would you expect you have oh go to the mic okay anyway so are you done with this document so presentation done with this business ok thank you I have a question ok questions so what kind of timeline do you think we wouldn\u0027t give 3gpp to review it or would we soak them ok so I\u0027ll go under rudder next week you won\u0027t hear from you but once I get back "
  },
  {
    "startTime": "00:33:57",
    "text": "I can kick off the working of last call so that would be the timeline and then to same time you reached out the yeah 3 TCP people and we can give this like an extended like a three weeks period for example for them to review so we would be done with the working plus code by the end of april around that hybrid okay all right thank you okay the secret ahead of schedule I actually intended even those only 20 minutes take two or three hours per slide the next to our presentations um I just wanted to talk a little bit about this individual on submission on pulsipher so it\u0027s been more time on motivation rather than the structure with this was already introduced as six individual graphs in Berlin but we wanted to keep this one going based upon feedback so we have a couple of challenges with policies in general and the way they\u0027re actually being sent as an operator the way that being provisioned what users are being provisioned the way it\u0027s being signaled of the dye number and we also have some underlying limitations so what\u0027s important understand is when we bring up different groups of users different projects different products we tend to basically pocket Isley right and then we develop policy around that we also though are very bad at developing unique policies so we tend to actually cut and paste an existing products policy modified a little bit let out let ourselves believe that it was a really great extension or deviation and then about three months later mysteriously will change it back without realizing the change of act because we also by the way don\u0027t have something like version control for policies inside its most of these things are done for you I or Excel spreadsheets which if you\u0027ve ever tried to do or control through Excel spreadsheets for all of your major policy decisions I recommend you don\u0027t do it so we have several partitions then that it gets rendered under so whether that\u0027s a ver for nesting table it\u0027s there we also have to support virtual operators as I\u0027ve said by MVNOs we keep talking about slicing and you know and we\u0027re talking about sharing right we have several concepts for sharing whether it\u0027s radio or multi tendency in general in 3gpp so um no we\u0027re starting "
  },
  {
    "startTime": "00:36:58",
    "text": "to get a lot of overlapping rules or i should say rules we intended to have non overlapping and then we end up having them go right back to the port next slide please so what we wanted to do was you know trying to figure out what we were going to get done and we thought we\u0027d go it alone in the sense that maybe it was just us or a process and so um we started with engineering and stuff we found that it\u0027s not optimal um so forgetting about the the Excel spreadsheets for a second it\u0027s just not tracked all the way we\u0027re doing stuff the other side is um you know the best thing we could do underneath the switch and we implement some machine learning last year in some of our sdn software that was receiving policies that were driven by diameter we be inserted the machine learning and what we found out was it was great but it only implies learning at that machine and so you\u0027re only as good as the amount of information fed to you and in diameter we typically don\u0027t like to pre-provision policies because we don\u0027t send down policies just to actually send them down for their sake we actually have to have a live customers are doing something so it didn\u0027t being the machine learning worked great when we had a lot of customers using a product but up until that moment we stumbled a lot and we ended up basically losing a you know a lot of efficiencies so the best option we have today is really the kind of the filter IDs which are used for shorthand but they only work across the link and so if you think about that your best optimization for developing a shorthand conversation is only point2 points and it\u0027s only between enforcement point and a decision points and so you have no system level optimization so unfortunately each of these links have to learn or you go back to the you know some sort of magical optimization structure so we decided to take a slightly different approach next slide so we look at this and what we realized was the way we\u0027ve been doing stuff in terms of products and services and rules has a really change in probably 50 years we used to have something called a service order code through universal service order code which actually stilts how to wire physically wire the actual services for an individual and believe it or not at least in North America we still use that terminology even though we probably have nothing to do with wires whatsoever so we still group people with products we still group things with code so we treat them still as fits install this this is available this is not in ones and zeros and this was actually reaffirmed by our machine learning what we started doing was we started matching up our service order codes were machine learning was telling us in terms of bit patterns and strangely enough we could equate a service order code which was a long integer back to an individual bit and so obviously the bit representation was "
  },
  {
    "startTime": "00:39:58",
    "text": "much more optimal so what we did was we went to that design so we do basically in policy groups represent the membership of an individual as a bit built we represent the potential matching membership of a policy also as a bit build and then we actually apply a mask this is very similar if you\u0027re familiar with Sdn open flow to the metadata field that\u0027s actually applied in in elsewhere so it\u0027s an extra piece of data has nothing to do with the existing filters and that\u0027s that\u0027s really important treat it as an extra discriminator for filters so so we\u0027re adding something outside of the packet information that\u0027s provided by the controller diameter into this to help us out and just you know once again i want to remind us right so we did this over the current methods which we have been using for a couple of decades right even before diameter even before radius right we have policy group identity but we have the engineering provision those and we make mistakes we have a list of identities and info threatens I mean but you know at the end of the day all this really depends on either sending the whole policy structure or pre-provision so once again this is only as good as what you\u0027re sending over the individual names next slide so this is the relationship model and this is something we actually added since the initial grant we\u0027ve actually added this diagram into the overall document so you see the policy edit e which you know we left as a very generic term but think rule filter rule whatever predominance structure that you send or using today base themes which if you\u0027re familiar 3gpp is just a hierarchy mechanism that\u0027s used for extra discrimination matching but what\u0027s more important is for an authorized user they\u0027re given a membership which tells us a domain so a lot of times domains a pretty generic term but we seem to be a little bit more I think we should say we have a little bit more definition about it with slicing and with multi-tenancy so that\u0027s really where you put in your domain information and the values so any authorized user has a domain and a value I mean that values say a bit string and the policy entity as an assignment and match types of these are all set relations next slide so the end results was we ended up with a well i would say for us a wildly improved minimization of our filters so we as an operator like to think we\u0027re really great we have over 50 million endpoints that we authorized on a daily basis and the initial designs were over 200 million potential rules because of the way it was being done after this technique we went down to about 1100 and then a colleague of mine who\u0027s also in the audience mr. Bayles went through and took another round at it and we\u0027re "
  },
  {
    "startTime": "00:42:59",
    "text": "sitting at sadly well I won\u0027t go to the lowest number let\u0027s just say we\u0027re nowhere near 1100 anymore but it\u0027s it\u0027s pretty depressing but a good example of this is you know one of the biggest advantages is the any any rule the default rule in sdn your default rule is only one per table so if we had five of these rules you need to five tables what were able to do by adding the metadata here right this membership as an extra field is we\u0027re actually able to take these default rules in right into the same table and use the membership as the discriminator so you can take multiple default rules multiple in any accept any traffic rules and then add them to the same table the same grip fib as far as a policy enforcement concerned or routings concern and and get it done so the other side is it the net result is if you have a common filter but you want to treat people differently you can do this in the same enforcement location with this so think of it in terms of its a way to more tightly tie the user to an extra field for discrimination outside of the packet so next slide so I\u0027d mentioned the changes so we added the relationship model we added mr. Bayles as a co-author there isn\u0027t anything else we\u0027ve done in the document so next slide so next steps I\u0027ve actually heard from dave i\u0027ve heard from evil i believe i got briefs i think also said something on the mailing list back from Berlin so we\u0027ve had a little bit of feedback um I\u0027d like a little bit more um but my question would be right if there\u0027s no objections right we will all start pushing for accepting this as a document going forward probably not today given the tremendous amount of attendance that we have but maybe sometime hopefully out before then it\u0027s me okay so I thank you so anyone read this outside the air top losers Oh seldom and the half of the working group as rector document mazal number I\u0027m worried because they almost looked like unilateral I mean almost it was almost unanimous on that would have been shocked yep so for the rest of the working group do you XO think this is useful work Oh Damon you sound "
  },
  {
    "startTime": "00:46:01",
    "text": "okay so uh Dave good thing is useful yeah reading the draft I I don\u0027t think as is it totally explains as well as it does when Lyle explained it to you but hm yeah I totally see how this is it\u0027s useful to avoid applying the same policy open over to involve users create the groups yeah and I\u0027d also like to say Lyle you did a really good job explaining it and it\u0027s it\u0027s not that clear in the draft okay though and so all right we\u0027ll work on okay so why I\u0027m asking like this is DM that I really need to understand that if it\u0027s going to be more than just a document exercise so if it has a customer the real customer we are implementing it in everything we can but also keep in mind we\u0027re an operator so yeah okay so mr. is this specific reason why you are obsessed the wing by yourself and asking for an application ID um I envision these a VPS to be added to existing applications associated with authorization and in any sort of grants so I don\u0027t expect a new application ID as much as these being added as optional a VPS in the existing apps okay alright so I\u0027m not going to ask for now so now so I want to see some discussions going around and the disposition the point for Chino saying right like yeah so these do that and then we come back if you don\u0027t need to wait for the air Brock meeting yes you can do things offline also uh okay the next one all right so this is an easy one and for this audience it\u0027s a lot easier than when i try to present it outside of this um pretty simple motivation we have a lot of authorization for you right whether it\u0027s Nazz or we\u0027re doing the CCA application and as you recall we we have the basic concept of units we have used units and we have granted units the reality is we\u0027re moving more toward a virtual world um and so anytime you grant something where you authorize someone for a grant that\u0027s that\u0027s all well and good but the problem is we also or i should say we also tend to have systems that also have a pretty good idea based upon past usage or profile usage or even an SLA on what "
  },
  {
    "startTime": "00:49:05",
    "text": "that great actually means to the N resource so in other words a lot of the devices that we authorized we actually know their usage habits and and this is typically in other systems and so one of the big problems we have in the virtual world and it\u0027s really the problem that we solved by I hate to say over engineering and paying too much for Hardware in the physical element world is we would actually go in and basically just kind of make our best guess run a number up so what we wanted to do was kind of overcome that in a virtual space so anytime you basically get some sort of authorization we wanted to send an extra set of units that the client can ignore or it can look at but gives it some idea of the resource utilization of what that authorization just minutes and so uh what we did was um basically we started looking into this right so we could do sizing and engineering and we thought it was really dumb to have it as a separate system I mean right now if I get an authorization with granted service units and I wanted to know what\u0027s the impact for me four packets per second what\u0027s the impact for me for CPU what\u0027s the impact for me for time I mean sure we\u0027re giving 24 hours but how much does he really use and how much should use over time right now I have to do that as an entirely separate out of the insistent and so it ends up being more transactions no engineering and other activities that I want to try anymore next slide so what we did was we went ahead and had the predicted service units AVP is being proposed to be sent back in these responses whether it\u0027s the CCA or any sort of access service request any sort of basic authorization or grants we want to send back this so the way to think of it is a couple of times so any time you actually allow a user for access and grant them just base basic authorization you can send this AVP anytime you do a a CCA and you get a response with a granted you can also see this AVP so once again the proposal here is an AVP that goes along with existing apps not new apps so it\u0027s a pretty simple structure but we have made some changes so we did have a fairly complex filtering structure and then we were asked to support time series and so what we did because it made a lot of sense that the structure was fairly flat it was really hard to we\u0027re really having a hard time um trying to get things like well every 15 minutes the guy does this those sort of things so there\u0027s a great structure which is the time of day conditions in five triple seven and so what we did was we just added that structure to the main predicted service unit structure the net result is it removed most of the AV keys and really "
  },
  {
    "startTime": "00:52:05",
    "text": "minified and simplify this fact since 00 so we\u0027ve added that and then the only thing we need to do to represent the time series is create a formal structured list rather than saying multiple occurrences because we wanted to be able to bring that in as a top level structure with some of the applications that we\u0027re doing at at sprint this allows us to be pretty complete I\u0027m actually pretty happy with it I originally started out with I think five maybe seven ABP\u0027s we got the fun we\u0027re down to two so I\u0027m really happy with the changes so if you go to the next slide so what we\u0027re really talking about is your predicted service units looks exactly like your granted service units looks exactly like your used service units the only difference is it has the time of day condition if it\u0027s not present then it applies you know essentially in death right through all time once again why wouldn\u0027t we add this to the granted well it\u0027s a grant it\u0027s not a prediction of usage and obviously it shouldn\u0027t be reported in used service units so we couldn\u0027t really fit it anywhere else so this is the base structure um we also want to be very clear a lot of our systems collect a lot of data so it\u0027s really important to understand that we may throw a lot of predictions if you will or a lot of time usage back to the diameter client we\u0027re also clear the spec the client can do with it what it will write so may not understand every unit that sent back it\u0027s a service unit of type CPU or if it\u0027s a service unit of the type who or bar right this is something that\u0027s coming from an analytics system out of and we have no idea right when we\u0027re sending it back to a clients whether or not that\u0027s useful so the client can ignore it and ignore the entire structure or it can take it for what it what it is the most important thing for us is in the virtual world it gives us an idea of memory usage and basically key metrics so that we can make more informed decisions when the client receives out so um next steps we\u0027ve had some feedback once again I believe Dave provided some feedback and evolved once again before the program draft but we\u0027d like more on this one because we did make essentially the major structural change i made the collapse yes and as far as this we like it you know if there\u0027s not a lot of me bad we\u0027d like to go ahead and push for this being adopted I\u0027ve been Campbell is an individual I haven\u0027t read this so take my question with a grain of salt York you have you considered that there may be any privacy considerations in in talking about user behavior here yeah absolutely i know we\u0027ve got a lot of concerns but what i would say is is yes because you\u0027re you\u0027re assuming that that "
  },
  {
    "startTime": "00:55:06",
    "text": "prediction well i would just always assume worst case that prediction is very user specific on and at best case which is actually bad for the Opera best case it\u0027s a generalization right which is actually isn\u0027t very useful to it\u0027s good it\u0027s not useful so yeah we would like a lot more help on that um but but I\u0027d also like that to point out right we\u0027re already using because this is a user-level authorization or grant we\u0027re already in already halfway into that mess and so I guess arguably the spec is putting the other foot into that situation we\u0027re jumping in both being so so absolutely you\u0027re saying I think the other foot is that we\u0027re including information about how we think the user is going to behave which is I assume it\u0027s based on past experience of how that you could behave or models or yes yeah yeah absolutely so um III think the the minimum that we need to do is probably have what I\u0027ll say is an exhaustively long security consideration section at the minimum it\u0027s becoming popular these days to have separate privacy considerations sections okay yeah yeah that big of a deal oh that\u0027s right yeah absolutely i\u0027m just kind of thinking that at the end of the day we may have a longer privacy considerations section that we do the rest of the spec on this one we have for me to talk that\u0027s the big vilson sandra um back to the list of metrics yeah um so I mean this looks like a Gy type application you said yeah I think the ideas you would report these to any type of application yeah yeah samesies so I probably should yeah verify that to say you know you can report you know usage or maybe the privacy considerations will say should not report usage to like policy enforcement or an application that doesn\u0027t otherwise quack usage yes yeah maybe give us some there might be a way you can help with that also in that list would you report things like you know disk usage and cpu and things like that that might help that more than well if my advice is a for the struggle right so we so we did find or i should say we did kind of follow the standard USU GSU paradigm and so arguably what would happen in that dimension that would be in service specific units right right which is a more complex structure what\u0027s in there yeah but also remember this is just one dimension so if we want to talk about adding multiple dimensions at the same time of day conditions we can we can look at that but but it would have to be a more complex structure here we "
  },
  {
    "startTime": "00:58:06",
    "text": "were just going for what I would say is usual and customary and consistent way of reporting that the service units and so if you go one page earlier again uh yeah so so be down here in the predicted service units series right where you would put individual dimensions or maybe one dimension with multiple different time of day conditions if that filter if you needed multiple representations that so that would be your containing structure with that sorry but inside predicted units I think you can list multiple things yeah yeah so isn\u0027t that multiple dimensions but we can we can without you I would say it\u0027s it\u0027s really there\u0027s there are options there um and and it\u0027s it\u0027s kind of back to when you do multiple service units in a GSU by its very akin to to what\u0027s happening today right so we do see people packing more than one unit in and we also see other people then you know sending multiple type of type of green structure simultaneously so so we\u0027ve seen both so yeah but I we wanted to keep it consistent with the main base specs with us you GSU but if we if there\u0027s a compelling reason to maybe change that and let\u0027s let\u0027s definitely separately talk about on the mailing list see okay so uh what they\u0027ve obviously has read this okay I can\u0027t have to working with amazing so um okay so we don\u0027t have actually we don\u0027t have both of these items in our milestones at the moment and the you actually I don\u0027t even think they fit into current charter as such where\u0027s to be the e in the extensions pieces one yes yeah the evo a and Joe lets them for everything though good non extensions it\u0027s everything right back so okay anyway so uh so what is the ats-v of of bringing you working to on time because that took pretty much undermine the powerseeker etchant of whining this working group down Ben Campbell with a B hat on it is interesting work to do then the group can do it I think yeah it would be good "
  },
  {
    "startTime": "01:01:09",
    "text": "to see more p some people at least on the list expressing an interest that you know this is stuff that they would work out and hopefully implement so honest team of my biggest concern about the about in any new works of completing the two items that we have is that the after the old overload which was kind of peak in our history of of doing stuff tt-this pyramids no interesting in what what we are doing anymore because we have there\u0027s no exit 44 l 4 40 my cat is kind of point point interest of doing something like you have your own implementations coming you want to standardize that which is fine but the young kind of worried about the breadth of interview if the active active number of the working group participant is like counted in one hand i won\u0027t be surprised given some of the things coming out of the 5g space if we start seeing some more things come over as you know we see some things that are hinted at by virtualization here today yeah and they do take some time before they kind of kind of make up right through their way up they\u0027re still operating it more architectural levels i think that they are staged tree hasn\u0027t really started on the 5g so wait until CT for gets ahold of this stuff um I think we\u0027d talk about that I think it\u0027s perfectly reasonable to ask on the list what kind of interest we have in endeth work item I just became the shepherding ad this morning so I don\u0027t necessarily have an opinion yet on the does it make sense to spend the group down versus keep it open late it\u0027s not uncommon for maintenance groups like this to operate in a kind of a dormant mode until work comes in yes is that doesn\u0027t necessarily you know we want to be dormant so we don\u0027t take work right that\u0027s kind of dog way in the tail if there\u0027s work you do it if they\u0027re not dormant but again even just the people on this room with a pretty small set to take on new milestone fulness certainty but if there are more people that are interested in that changes yeah so amazing why need down to something via would be closing its more like a waiting for the maintenance items like these kind of things coming up but the yeah so I definitely would like to kind of first asked to be more around and the I mean I have nothing lyrics about again supportive will proposed here I mean it "
  },
  {
    "startTime": "01:04:09",
    "text": "looks like a sensible piece of book that you have already done it\u0027s not any goofy stuff but the just would you like to see kind of bit more interest on it it becomes easier also for you kind of get input outside Theodore editors about what you are doing and right and by interest I assume you mean interest in at least reviewing if not working yeah on it directly it\u0027s very easy for people say they\u0027re interested in somebody else doing the work yep exactly so but again like like like for the previews presentation so this doesn\u0027t mean than that nothing happens before Prague absolutely that\u0027s all there is this we can do a lot of things on the email list so I would kind of shout out for the a more interest and the then look for where we can add in the milestone is easy step so if you need to kind of take on the world cup ouple there thank you okay thank you think we annoyingly a point on the you have five minutes later flower to skate you still like a 25 minutes so up any other business or if not they can say that we are done for this I ATF and the we will see the retro print control going out of the working group cooks a single income for the working group last call and also engaging the treaty p on the roof down the app and also the 406 Bitcoin working group last call I looked engaging 3gp with that and then asking around a kind of general ambition 11 on working on this with boys a group and the created units work so that\u0027s the evening it next steps after a week most most like being initiated so and the for this new to pieces so he also scan do it by themselves and I will kind of come back "
  },
  {
    "startTime": "01:07:09",
    "text": "to this too because over within one week asking like trying to kind of sense the M the interest let alone working on this so that\u0027s pretty much it so thank you guys and the M see you in Prague and non-dividing is Dixon is KP thank you Dave yeah see ya yep okay aspirants yeah thank you hmm Thank ok I I p Oh Oh then I have 13 ok "
  },
  {
    "startTime": "01:10:12",
    "text": "I yeah that\u0027s unstable so as I said the word you "
  }
]