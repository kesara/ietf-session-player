[
  {
    "startTime": "00:00:05",
    "text": "Thanks. Option. Good. I tested all of them. They're in good shape. Yeah."
  },
  {
    "startTime": "00:02:23",
    "text": "To and the valley, you know, Alright. I think we can get started. Hello, everyone, and welcome to WIP Transport. IETF 119. In Brisbane, Australia, And for Everyone around the world joining remotely. Thanks for being there even though the time of day or night might not always be easy. So my name is David Skinazi. And with my coach here, Bernadaboba, we will start stuff. You've probably used BDECO by now, and the data tracker Here are all the tools, So if you're remote, please keep your audio and video off unless you're speaking. And if you wanna speak, please join the queue. You're in the room, please join the queue instead of walking up to the microphone. Or before walking up to the microphone. Here are some links. If you have the PDFs, And here's the note well. It's Monday. So If you've slept in, you might not have seen it yet. At this IETF. Everything we do at the ATF is"
  },
  {
    "startTime": "00:04:01",
    "text": "under the note well and by being in this room or on this call, you agree to all of the policies in the note well. Well, you probably haven't read every single word of everything. You should at least be familiar with In particular, intellectual prop property requirements that take place if you say anything at the mic? Also with our code of conduct. Which we will be enforcing. On that note, we do what we can to keep a very environment here. So, please keep doing that. Alright. I'll be keeping an eye on the chat if someone wants to say something there. Like, if you're having microphone issues, feel free to Jump in the meet echo chat or in the zulip saying Mike, colon, what you wanna say. And we're gonna need a note taker for this meeting. Do I have a volunteer? Always the favorite part of a working room session right here. Everyone has something fascinating on the laptop. Let I'm let me check out if I can attend demo you tomorrow. I think I have And I I'd down be what I I think I'm presenting in another session, so I can't join mock. But I appreciate being. Uh-uh. Alright. As usual, we cannot be like, remember that the notes do not need to capture everything since we have a YouTube recording, but Oh, Thanks so much, Moe. Much appreciated. Alright. Our agenda today, We're gonna do a quick update On the interrupt runner, then have our w3c update."
  },
  {
    "startTime": "00:06:00",
    "text": "We'll talk about web transport of H2 and H3. Would anyone like to bash this agenda before we move on? Alright. Moving on. So, Martin Seaman was Working on his quick interrupt runner and added web transport support, which is really cool. And now In addition to many of the quick tests that we have, it supports web transport by starting the browser and loading some JavaScript and making sure that it connects with a specific server. He got interrupted between Chrome and WebTransport Go. If you're interested in being listed in all of those glorious implementations that work, Please contact him. He's over there in the room next to the microphone. Alright. Will, are you there? I am actually here Awesome. Especially, let me apologize to the mock group. I had entered the entry items before we move the meeting times. The call. I apologize for that. I will try to catch up and present those items. I sent a message to the chairs. So good morning. My name is Willow. I have problems with calendar management representing the W3cahwebtransport group here and a quick update for you all. Regarding progress on the browser side. So our latest work draft is dated December 20th. It's published. We did extend our charter through to 31st May, which is approaching quickly, we're already in Newark. For at least another year after that. We have moved our timetable back we're still hoping to get to candidate recommendation and proposed recommendation by September and a publication date of November. That is the goal. We have a milestone that reflects the issues that need to be closed before we can get"
  },
  {
    "startTime": "00:08:01",
    "text": "to candidate recommendation. We have, 8 open issues of which 4 are ready for TR so we're relatively close to resolving the outstanding issues. We have picked a meeting time for the t pack face to face, which will be in September in Anaheim and we picked the least egregious time slot for our global audience, and that's 2 to 4 pm. On September 24th. So if you are gonna be there, please mark that in your calendar as Next slide, please. So a couple just summarizing the major updates that have taken place the lost AUTF back on November 6th. So we now have a option when you creating a stream. To wait until it's available. So the promised return will not be settled on the underlying connection is sufficient flow control credit to create stream the connection reaches the state in which no further outgoing streams are causing we also support a web transport supports revival only Boolean enable you to an interrogate the session. It'll return true if the user agent supports web with sessions over exclusively reliable HTTP collections. Otherwise, ulse, pulse, pulse, you can use this for feature detection, of H2 support. Otherwise, there was no no other possible way of doing it. We've also added a new stats. This was just adding symmetry to the stats because had, no, metric here. We had of other Datagram stats, but nothing for expired incoming. Next slide. Right. We awarded a prize here for the very longest name of any attribute. So let me just take explained this. There was a lot of debate. It looks when you're trying to make a slide and fit everything in looks really weird yet."
  },
  {
    "startTime": "00:10:04",
    "text": "It's the anticipated concurrent incoming bio or unidirection streams actually even with the instructor. It lets an application specify the number of concurrently open streams it anticipates the server creating. So the use case here is you're you're an application. You wanna open 20,000 streams. You know you do, but the the, client might when you run out of streams and you ask more and might just allocate a 100a100a100 and it's gonna take you a whole lot of round trips to get up to your 10,000. The idea is when you open up the connection here, you can tell it how many you anticipate. And there was a lot of heartache. Every every item here is decided, to be required. So probably make t shirts or something to celebrate this, but now we haven't just pated concurrent incoming unidirectional streams. I think the max has 64,000 we to that Next slide, please we set a minimum requirement so that an application can at least function and run. So, we require the we are we have we allow the browser Sorry. The browser will allow the server to create at least 100 unidirectional and 100 bidirectional streams. We picked the number. It's a line in the sand. If anyone in this group feels that it is not a reasonable minimum, default, then please give us feedback. We also had an example for our service certificate hashes. It's very simple. I show it there. So we now support the passing of a service certificate hash on the Excellent, please. One question real quick. Sorry. On the on the number of streams, is that"
  },
  {
    "startTime": "00:12:02",
    "text": "number of actual streams, there's that the stream number. So you divide by 4. You don't divide by 4. No. That's the that's the actual number of streams. It's my screen number. Yeah. At the API level, we're working in streams. We're not we're not seeing anything to do with quick Okay. Just a can I use, update? The the the percentage is getting up, we're showing a global percentage of 76 percent, supporting Chrome Edge Firefox, and Safari is coming along, I think. Eric probably has better updates than I cut and paste off web kit right there. But it's nice to see progress. So we hope by the end of this year to have, good browser support across the board. Next slide, please. And just the last one, there was an interim for this group my cochair, Yani Vaah, presented 2 issues exposing TLS keying, material exporter and also removing independence on data safe they both had action items that there were both taken up by this group. So we just wanted to say thank you for reacting to those. We have no further asks of the IETF web transport group this stage other than these two issues, which are still open, but that have been taken up. With that, our slides conclude, I believe, Next slide, just in case. Yep. Yep. You you you have to be going there with 6 out of 7. I did had myself going too. So, Are there any questions for W3C? Yeah. Alright. Thanks, Will. It looks like we have a question for you, Victor. Oh, have it's not a question. I just wanted to say that both of those issues Already both issues and PRs and it be later in flight? It's, I Awesome. Thank you, Victor."
  },
  {
    "startTime": "00:14:00",
    "text": "Thank you both. Okay. Alright. Alright. Step on the pink x. Standing on the tripod while I adjust the microphone. Alright. This is gonna be vaguely H2 focused, but more of just, hey, we split up topics. So pardon our title slides. Next slide, please. We have some notable updates Since the last IETF. One of the big ones is we pulled in some new capsules so that we can now be consistent across h2andh3. Specifically that is closed web transport session and drain web transport session. Next slide, please. As a brief aside, would anybody be upset if we renamed these? It. This is always a fun one because it matters not at all. Sweet. Alright. Onwards, we go. Next slide. Thank you. So the other big update that's worth talking about and that is going to affect interop and what we do in hackathons and how we make all these things work together. Is a single change that resolved 4 different issues, and we spent a lot of time talking about at 118 around, when do you have to buffer different things? How do you start? Does a client need to send different values in its settings than a server does? All of that kind of stuff. So I thought I'd go through just kind of what we had before, what we have now, This is a very good thing to be aware of, especially if you're implementing because it will change whether or not we can interoperate. We think that it is now in a good place. But, in the event that it isn't, we'd really like to get people actually implementing this and make sure that it's it's working well in practice. Next slide, please. What we had before and we had previously agreed upon as a working group, is that both sides would send the max sessions a value, even though a client that is not super meaningful for them because the client is not willing to accept any sessions from the server that is a"
  },
  {
    "startTime": "00:16:00",
    "text": "that the server initiated the client initiates to the server. My server accepts some non zero number of sessions. But we said for the client, just any value that isn't 0 is a great way to say yes I do indeed support web transport, and we can now talk web transport here. And the reason we cared about this is because we're for how H3 handles streams, and we wanna make sure that everybody's in agreement to when I get bytes in from the network. What do those bytes mean? How do I interpret them? What format am I looking for? All of that kind of stuff? Some of the result of that is that because both the client to end the server, we're sending these values in their settings. A server would need to buffer incoming data grounds. And bidirectional streams and everything else coming in, intel it got those settings from the client to say, hey, is this web transport? Should I think of it as web transport, etcetera, etcetera. Now we're never gonna get completely away from potentially having to buffer some things. Because if you have streams come in on a web transport session, in H3 before the connect request that establishes that session. Are gonna have to have some list of things that are hanging out waiting to see if they get claimed by a session. However, you as a server can choose to either limit those or eliminate them. That kind of thing without too much pain. Next slide, please. So the things that you really need to be able to look are Is this web transport? Do we need to do manage than we did with H3. And can I get to a place where I request that establishes the session? If you haven't had the settings or if you can't figure this out, you need to sit there and wait to see if a connect request comes in with that session ID, etcetera, etcetera. Next slide, please. The happy new world that we believe we've established is that a client still has to wait for the server settings. So as a client, you can't just start shouting web transport things or using extended connect with web transport"
  },
  {
    "startTime": "00:18:03",
    "text": "at a server that hasn't said, hey. I'm willing to take more than 0 incoming web transport sessions. The default value of the setting is 0. So all lines up nicely stays the way it was before. Everybody still has to send other settings we already agreed on that a long time ago. We're not changing any of that. We're not going back there. You still have to say that diagrams are a thing. You still have to say that, everything else still works. However, the client no longer needs to send any specific web transport setting. Next slide, please. The reasoning for some of this is because We think it is sufficient to include a note and the latest drafts have a note about this, which we love editorial feedback on. To say that if we ever decide to have a future version of web transport, that changes the syntax of what requests look like. I e, what you do in your extended connect or if you use a completely different mechanism or anything like that will have to change the upgrade token to something like web transport 2. Or or or pick your pick your favorite name. Similarly, anything that we do for streams, will have different stream types or the signal value that we send on a bidirectional stream. Etcetera. So the idea here is that when you go to establish a web transport session, a server can tell from the incoming packets, whether those are streams that are request itself, what version of web transport the client is speaking, and we don't need to do any other kind of fancy, let's use different code points for the setting and make sure that the client sends the setting in us Next slide, please. So, I think this leaves us in a good place. We think this generally is a thing that we'd like to get people going and actually implementing and make sure that this all works servers no longer need to wait for client settings. We had a on GitHub about being able to even accept things ahead of the settings coming in and if the settings don't match what you were expecting because the"
  },
  {
    "startTime": "00:20:03",
    "text": "obvious required. Hey, by the way, I'm gonna use Datograms. Wasn't there? You can always say, oh, you're weird. And then smack them down. Anything that comes into you, whether that's a connect request that says, hey. Please establish a web transport session. Or a stream that's going to be for one of those sessions, whether the session is open or it is a future session that is losing the race of the packets to get to you. You know what version it's going to be. And for those ones that are where where you have a a stream that appears before the session does. Still gonna have to hold on to those up to some limit of however many you're willing to do. Next slide, please. So that brings us to the end of the how do we start talking web transport to each other is now different but I think the the real reason to talk about this is, a, please be very aware that that's different. And be, please, actually implement so we can make sure that that working well with all of our existing implementations Other than that, All of the remaining issues that are open in just open right now or an outline of what that pull request will say. Which I believe is a landmark moment in which we don't have a ton else to talk about. Donching set. So, yeah, we're we're in really good shape with with transfer over HTTP 2. These the issues that Eric mentioned, still need resin. PRs to resolve them, but we, for many of them, agreed in previous meetings on what the resolution should be. So this is just a matter of the chairs, awkwardly looking at the editors into in staring at them until they write the PRs. And then we'll see where we are from there. But we're in really good shape. I'm assuming no one has questions about what transfer over HD you do at this moment. Otherwise, please get in the queue. But seeing none. Victor, Europe."
  },
  {
    "startTime": "00:22:06",
    "text": "I'm going to talk about the author to draft to have that's web transport overview and web transport over HTTP free. For one, we actually have an issue for overview, an slide. So the issue we have for overview is that we have, an event defined forest stream well, data received, and that corresponds to the quick state where, you have samples, the date, including a thing, and all of it has been act. So a bit of background on why we want, Why we, Need that is that as a way, w in this back work, since the wait, what we streams API is structured. Is that, you whenever you can only close the streams that's not been already closed. Well, that's a simply 5th version, but, You we use an abort call to reset the trend, And if we Right. Everything, then we, cannot raise it a stream if we immediately close the duster we sent in, the reason for that is sometimes what you want to do is you send a lot of data, like megabytes of data on a stream, and then the offense fan, but you still won't be able to. Be able to riff to reset that stream and now when you can reset the stream, because otherwise, But you, you, because it will take those megabytes of data"
  },
  {
    "startTime": "00:24:00",
    "text": "bunch of time to process. So we defines us for HTTP free, but the problem is it was not in exactly clear what it means for HTTP 2, 1. And the I made an attempt to define what it means for HTTP 2 in terms of all data committed but where HTTP 2 is basically whenever URI Fin to the socket. And there is a PR already, and it's already has some discussion. So if you're interested in details of strange state machines, you're welcome to read that PR and comment on it. Otherwise, I'll just merge it. And the antitrust also feedback. So it's alright, Etcetera. So that's the over the issue. Now let's go to web transfer to over HTTP free. Next slide. Web transport over HTTP free has bunch of issues. Some of them are not on the slides that are because they're editorial. Some of them are not on the slides because they're marked for, They're marked for a working group plus call in San Jose fairly recent, but there are zones that are. Not of the other sense that actually have slides, and we made some progress. So The first one is the oldest one we have is the issue with free sets we're ability and to remind everyone that was the issue where if you open the web transport stream, and immediately reset. It's a peer. We'll never know because when resetting it, you also receive the header of the stream, and Seth works, Yuri sets the headers that tells you which session that belongs to, and that works, against"
  },
  {
    "startTime": "00:26:00",
    "text": "like, that goes in contradiction of semantics we want to have. This is quick semantics where we set deletes all of the data from the stream but the fact that 3 sets stream happened and this reset has happened is reliable and will be delivered. So reliable bracelet is problem we decided to take dependence see, appropriate solutions that is described in the draft and, there is a PR to access but as a reminder, people should raise that draft and people should implement the draft before it's too late. So, there that's Issue night's number 77. Now, next slide is Somewhat of a summary of happen what happens when they enter in. And Enter 1. Just one quick second. Before we move on from from this. So as a reminder, this document has past working with Black's call in the quick working group. But the main Folks implementing it over here in web transport. So please make sure to, implement that and let us know if you have any concerns because it's either now or whoops. We'll have a problem. Is it already at the last call or was it Martin, do you remember? Yeah. It's past last call. So it's not published yet. So if we still have time, but not a very large amount of time, And similarly, please take a look at Victor's PR. I see Martin did, but I'm sure others have opinions. Alright. Back to you, Victor. Thanks. Alright. This is somewhat of a summary of what we happened to the interim is that it's the interim we discussed whether we want extra flow control in"
  },
  {
    "startTime": "00:28:00",
    "text": "HTTP free, and we decide that we do, and we want to do a similar to how we're doing H2 with capsules but we will only make it required to want to do pulling. And if you don't do pulling, you do not have to pays implementation slash complexity costs for. Doing that. There will be PRs, they're Live. Not been there, is there some question as to implementation details, thinking exactly how we're going to negotiate that. In addition, I know it's Martin Siemens and then then then noticed that this has a head of line blocking issue and He has a proposal, and the I would also encourage him to file an issue to the GitHub because, Otherwise, we might forget about this. As to whether we want to do anything with regards to the fact that by putting everything trim. Now our flow control messages have had a flat blocking. Which is not the case in regular quick. So that suck. It forced this topic. There will be PRs, and we will I will probably actually send out an asking everyone to review since those are complicated. Next slide. Before we move on, Victor, shall we perhaps have some discussion around Flow Control and what was proposing around headline blocking. Because Do you wanna get through your next slide and then we come back to this? Oh, we I mean, we kinda have discussion, like, sure. Definitely. Like, if you think now is a good time because that that The, you know, like, this only came up, like, if couple of days ago, I think so."
  },
  {
    "startTime": "00:30:02",
    "text": "We might have one. Let let's go through your next slide, and then we'll come back to this. Okay. We we have a lot of time or, anyway. So next slide is actually relatively easy. Keeps porters with previously, close-up the shoe because people seemed to not care, then people who cared actually did show up. So we reopened, and fortunately, that issue is Really easy to solve. We just point to TLS back and define the structures that tells you how to make sure that your exporters for difference since the same connections are different. There is a proposal ready ever on this welcome to comment it. On it. And I think this is my last slides, you might want to double check, but we can go to the previous life and talk more or maybe Martin should talk more if because So proposal. On the key exporters bit, so initially, we hadn't landed this because there was interested. We didn't wanna add features that weren't needed. There seemed to be implement your interest. Does anyone have thoughts on this PR, or Should we assume that No objections mean this is good enough, and we can land it. So I would like to Encourage anyone who has objections to please jump up at the microphone. If you wanna say that you need a little bit more time to review, that's also fine, but we'd like to hash out any any objections here before, so we can get it landed soon. Alright. Hearing none and seeing some approvals on the PR. I'm gonna say that if"
  },
  {
    "startTime": "00:32:00",
    "text": "no one speaks up in the coming days, we can just merge this. So then let's go back to Flow Control. This is pretty much The main item we have, we have, almost an hour in the meeting, and I'll save 5 minutes at the end for the chairs to wrap up. But, let's chat through this. Perhaps Martin, would Seaman, would you like to walk us through your what your you mentioned in your email about head of blood blocking here? Sure. I can do that. I'll I'll focus on on the problem. Not on the solutions. So there's a, there's a graph by by Martin Thompson there's a draft by by Martin Thompson, and I think, Eric Heneer, that specifies that all the flow control capsule that look somewhat like the H2 capsules are put on the webprints port console. Crawl stream. Which means because it's a quick stream, all the bytes have to be, have to be delivered in order. If there's packet loss, then, typically the receiver will will need to wait for their packet loss to be repaired, which takes at least 1 network round trip before it can make progress. Reading from the stream. Which means that all the all the capsules that were sent after the packet loss are now waiting to be consumed. If you have a lot of if you're sending a lot of capsules because you you're using a lot of streams or you're you're updating your flow control window frequently. Or you're turning a lot of streams, then, this might matter more to you than a situation where you only have a single stream that's making slow progress. So, it did very much depends, depends on the, on the application. It would be nice to have a solution where"
  },
  {
    "startTime": "00:34:01",
    "text": "We don't put all the capsules on a single stream. And they are different ways to to do that. We could use unidirectional streams, or as I suggested in my email, we could, we could have, a, basically, a quick frame That allows us to put something that that looks more like the, the, the quick flow control, frames, directly onto the quick connection. So they would There would be, send and consumed independently. From each other, thereby avoiding out of line booking. Thanks. I sit. Oh, and that's started a queue. Perfect. Thanks for the overview, Martin. That's super helpful. Victor. I think if we're going to solve that problem. I would probably solve it in a way that's not necessarily web trans specific. There are other cases where we put independent stuff on inter capsules, like a data group capsule. What is something you can do if, also this software from had the flight blocking, and you could theoretically is, in independent and to independent, like, union direction loss streams. Or you could put some into any new transfer to concept. But the point I'm trying to make here is that this is not necessarily web transport specific issue. And Well, I would wanna think I would say is I definitely think that We are. Would not want to block in this now since the since right sounds like an optimizations that can be added incrementally. Thanks, Victor. That makes sense. Luke? Yeah. I'm gonna say I don't know if this will be an issue in practice."
  },
  {
    "startTime": "00:36:00",
    "text": "Especially because With flow control, usually not at, like, the 1 RTT barrier where it matters. Like, you're not sending max streams with a single RTT before it actually applies other ways you're blocked. Usually, you're send you increase the flow control limits a few RTTs, ahead of time, So I'm I'm okay with head of line blocking. I think it just makes things simpler. Is times where we care about latency. And control messages. I think mock is one of those where by blocking out the control string matters. Just don't think it matters for flow control. Thanks, Luke. Martin. Yeah. I was assign much the same as Victor, in terms of Closer to the mic Yeah. I was gonna say much the same as Victor in terms of what We do now. I I think this is an interesting idea, but it requires a bit of exploration. To, to fully understand the implications of, of what it means to to integrate something like this into into quick provide the layer above quick. With these sorts of facilities. So while I'm supportive of doing that exploration, we kinda need web transport sooner than that would allow in this specific case, We'd barely use the session stream in web transport anyway, So, headline blocking while is f a theoretic problem. It may not be a practical problem either. On top of the things that Luke pointed out. Which already mean that I'm not particularly concerned about making this more efficient. So I, I preferred it to stick with what we sort of less agreed with already. Thank Eric. you, Eric Kanir. Dedooping the things that Martin just said so all of that, plus a small piece, which is we've got a whole bunch of people who are reasonably convinced that they didn't really need that much flow control anyway. So at that point, given that this is gonna be going on a reasonably chill stream. To"
  },
  {
    "startTime": "00:38:03",
    "text": "catch those extreme cases where you're bumping into a limit that you should hopefully never reach. I think we've had some really cool conversations about how we could solve this and the kinds of other places we could use that more generic solution. And an ideal world, I would love to use that here. But I feel like that could very easily be a future version of web transport that picks up that solution that we spend the next however long actually coming up with. So, like, I would love to do that work. Given that we're barely over the line of do we need flow control at all? It feels a little bit like, a large lift to go from, do we need flow control at all to, do we need to stop and wait and adopt a new generic thing that makes that the world's most optimal flow control. Thanks, Eric. Back to you, Martin, thoughts, Yeah. I think this totally makes sense. I'm a little bit hesitant accepting Luke's argument now that you're that you don't do flow control within one RTT. This applies to, max streams if you're doing things correctly, but if you have a a a high output stream. Then your stream flow control window will be, roughly the size the BDP and your throughput will be limited by window updates arriving on time. So if you have packet loss here, and you're waiting for 1 RTT to repair that packet loss. This stream will be blocked for that one RTT Thanks, Alan. Alan from Dell Meta. I was just reminded of some early work I did in compression where the original drafts for HTTP 3 had headers frames all going on a single stream, and we thought there might be head of line blocking. And So, I built a simulator and showed that it actually really was expensive. So maybe would help, Martin, if you're trying to advance this is to, like, try to actually build applications that, and and show what"
  },
  {
    "startTime": "00:40:01",
    "text": "kind of penalty you might see from head of line blocking like you just were were talking about. It might might help should people Thanks, Alan. So the Send some getting from the room and Sorry. There's enough chatter going on in the chat that I can't keep track of all of it. But the sense I'm getting from the room here is that While this is a real issue, it doesn't seem to be serious enough. To warrant the complexity of a fix at this time. And that's something that we could fix later. So, I mean, claim to ask, can Everyone live with this proposal of slow control that does have a head of line blocking problem. In particular, Martin, since you're the one who brought this up, can, Martin Seaman, Can you live with this outcome? I I I have a let the minute show that Martin shrugged. 3 There is debate in the room about whether use ASCII art or an emoji. We can handle that. Okay. So so We Victor, go ahead. Yeah. One thing I wanted to know, and I know it's in the chat, we might want to make sure that we have some text telling you to put control stream at the high priorities and data streams because Otherwise, he will definitely run into some weird issues. Okay. That makes perfect sense. Thanks, Victor. Alright. So It sounds like on the topic of Flow Control, we do have plan. This matches what we discussed at the interim. And what we need next."
  },
  {
    "startTime": "00:42:01",
    "text": "Is to see the PRs. So everyone can confirm that the proposal actually makes sense once they hit the spec. The Yeah. So we have, I think all of these issues have, assignees. But we have a plan. So, I think that's Pretty much all we had for today. This tells you how close we are to being done with web transport. And also how dependent we are on the editors, right, final PRs. So you can take the next 48 minutes of the time that you get back and I'll go have a coffee except the editors. But, yeah, I I think that's pretty much it for today. We're we're in good shape. Bernard, any final thoughts. Otherwise, I think this is the end of what transport at 119. Yeah. Just a question. I I think we don't need an interim. Is that accurate? I don't think we have a Topic for one at this time, my intuition would be to see the PRs for all the open issues. And then we'll ask for reviews on the list. If we we agree directly on GitHub and on the mailing list, we can land those. And if a point of contention arises, then we can discuss a potential virtual interim. Between now and Dublin. But for now, I think we might even be able to get these landed between now and then. Alright, thanks to everyone for coming. And also to the Secretariat and our area director overlords. Have a great rest of your IETF week, everyone."
  },
  {
    "startTime": "00:44:01",
    "text": "Sorry. Oh, yeah. I'm better at work."
  }
]
