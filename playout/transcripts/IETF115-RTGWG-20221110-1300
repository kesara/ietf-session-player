[
  {
    "startTime": "00:00:05",
    "text": "thank you it's a high last year yeah I guess quite a few people surprising yeah that's too positive really yes oh it was fun sometime Massachusetts you must be lost open source God hi everyone Seth uh welcome to the second the routing working group meeting uh please make it so familiar with not well so your participation in the ATF by participating in ITF you adhere to the policies that are in effect so the agenda for today we've got a invite talk so it got best paper award at sitcom this year we'll talk about uh Network Define Network simulation and uh thanks Moon Chen to come and talking to"
  },
  {
    "startTime": "00:02:00",
    "text": "us our first ATF please support her then we'll have 15 30 minutes on new routing architectural proposals so first of all detection stuff will also have David thank you David for being here to talk about Envy me and what should and should not be done so we'll have semi-formal five minute David presentation our talking topic and then there are some spring stuff as usual so uh again the fact that you see it here doesn't mean that building routing we offer sometimes people place to present and then dispatch them in the right place foreign for the first presentation we are very happy to have the uh author who received this year's ACMC comes past paper award to give us a talk um so a quick introduction um Dr Huang Shin Chen is a researcher at Huawei Hong Kong research center before joining Huawei she received her PhD degree in computer science and engineering from the Hong Kong University of science and technology in 2020 her research interests include network configuration management intelligent sensing several physical security and their intersection with machine learning so with that that let's welcome Dr chat"
  },
  {
    "startTime": "00:04:03",
    "text": "okay uh could you hear me if I can hear you okay thank you uh thanks for introduction and good afternoon this is a function a researcher from Hawaii Hong Kong Research Center uh actually this is my first time to attend iitf conference I'm so glad and honored to be invited here to share our recent work on network configuration management uh this world is accepted by this year's sitcom and our work is titled self-defined Network assimilation breaching The Last Mile towards Enterprise network configuration management with nursing this is the corroborated work with Dr yukanya dot Legion uh professor hyphoon professor hongshu daughter Libby Leo daughter gonjang and Professor Wei Wang and now let me begin my presentation and as one of the most important infrastructure that will support numerous applications in a perfect world all network devices should have homogeneous device models uh which means that if given the same configuration they should execute the same action and in this way the network operator will be very happy unfortunately the real Network contains a heterogeneous device models because large Enterprise will operate Network device from multiple vendors and because they want to avoid relying on single vendor to maintain sort of bugging power and risk control and in the meanwhile they will gradually introduce a new device model into the network resulting co-existing of legacy and related devices"
  },
  {
    "startTime": "00:06:01",
    "text": "and it is a pen for the network operator to manage such a multi-vendor network so uh in common practice we will have a soft defined controller situated between the app layer Network functions and the heterogeneous network devices it's desired that the network the controller can present a logically centralized control plan to config multivendor devices as if they are the same uh does the network operator will Define a unified model at the controller it's often stored as three hierarchy nodes of the tree denotes some configuration attributes such as IP address of an interface named of a SEO policies and Etc subtrees will generally denote a group of relevant attributes for example some attribute for specific Network protocol and the network operator will construct this unified model and annotate some brief context for attributes and then after that they will go to understand the menus the vendor menus and file correct commands and draft and validate the template and provide the mapping rule from the parameter of a specific vendor command to the attributes in the unified device models and then they should repeat the same process again for a new device model it would be a very tedious and error-prone process so we found that this is the process of introducing heterogeneous Network device into a century controlled existing self-defined Network and we Define it as"
  },
  {
    "startTime": "00:08:01",
    "text": "a soft defined Network or simulation sna in short and we identify that the key problem here is the mismatch between two configuration models uh the heterogeneous device model and the unified model in the controller and we found that the current SMA process will require significant human efforts to bridge them and in this work we seek a more automatic and efficient way to accelerate it and liberate Network operator from most tedious tasks and our basic insight to tackle this program is to design a system to understand the menus as Network operators and with especially automatic system could first extract a validated device model from its menu and then infer mapping between vendor device model and the unified model based on thematic information from the menus however realizing this idea in practice will encounter three challenges the first is the menu formal heterogeneity a device menu are usually the most trustworthy sources to obtain configuration model however there is no standardization for menus they are organized and format uniquely for different vendors let's make it hard to enable automatic menu comprehension the Second Challenge is the error and ambiguity in the menus after all all menus are human written documents it's inevitable to have mistakes and typos and is also impractical to audit menu"
  },
  {
    "startTime": "00:10:03",
    "text": "from the first page to the last and actually some problems are hard to catch by human eyes so we are handling this issue automatically invest is very critical to extract a reliable device configuration models and the third challenge is to bridge the heterogeneity between configuration models actually the configuration language is designed by each vendor to be visibly different with each other for the same concept or intent different vendors could use different wordings or syntax but due to the sheer number of CRI commands and parameters handcrafting mapping is very tedious and error-prone automating this process will require a powerful semantic comprehension model to understand and match similar network configuration context uh therefore we propose nothing uh we design a partial framework to address the first challenge uh it mainly features a vendor independent device model Corpus format and also the test driven development procedure for Reliable passing and we then design validator to adjust the Second Challenge we conduct validation on three levels the command level the intercommand level and snippy level and we finally identified more than 230 errors in the menus of mainstream vendors thank you and we further designed the method to adjust the third challenge we change the network semantic similarity inference model for network configuration domain to Output the mapping between parameters of"
  },
  {
    "startTime": "00:12:01",
    "text": "different models we also release a validate executory data set of past menu copers for future research and this is the overview of Nasim uh in the following let us take a closer look at three key components and the first component is parser the key inside of the parcel is from investigating the major attribute of multiple menus uh despite direct Styles or menu serve the same purpose showing us how to configure the devices uh sorry enjoy I could not see the screen now you see the screen I can flip the slides but oh yeah see it's very slow response oh let me let me begin here the key instead of the password actually is this despite diverse styles of menus all menus should serve the stem purpose showing us how to config the devices they should cover the CR commands supported by the devices and the function descriptions the working views and the parameter description and some representative examples"
  },
  {
    "startTime": "00:14:01",
    "text": "therefore we design a unified format additionally with keys and value type constraints as shown in this table right now uh uh sorry engine and could you hear the screen now uh but because I cannot see this screen I cannot determine you don't see the slides yeah yeah yeah uh it's very slow uh response uh I cannot tell you you can see which size okay you want me to try to present the slides uh but I think maybe it's it's better to let me control but just the the spawns are response this mouse here is very it's a little bit delayed okay let me try it okay uh oh just let me continue sorry and uh and so we designed a unified format here additionally with keys and value type constraints as showing the these tables and for mainstream vendor we build a password to cast this menu into this vendor independent format So to avoid this here we will show the sample uh Corpus generated by our passing framework and actually to avoid the potential bugs in the developed process we will adopt some test driven"
  },
  {
    "startTime": "00:16:00",
    "text": "methodology to ensure the quality so here I will skip this part please refers to our paper for more technical details so in this way we actually can extract all essential informations from the menus and meanwhile normalize diverse menu style into a unified format to facilitate the following processing so the second part is the validator so uh here the key inside is that we want to extract a reliable device model but the key inside here is that the menus are not fully reliable so we identify two main type of Arrow on ambiguities and the first type is a synthetic ambiguities for example this is the CI command from a vendor menus and it has unpaired left bracket before the remote As symbol and actually there are multiple potential valid facing options we can remove the left brain key or adding a red blending after the remote as simple or adding a right bracket at the end of the call command and choosing which require judgment from the experts and the second is the hierarchy ambiguities for example these two views in a vendor menu share the same example snippy so that we cannot tell which where there is msdp command enable the first view of the second or both so quick question AC lindum so you're saying that you just take a PDF goes into the parser and it comes out with this Json that you showed the example of is that is that what the input is it's like yeah HTML document we use HTML documents the input the initial input is the"
  },
  {
    "startTime": "00:18:00",
    "text": "manual and HTML format that you took off the web is that what what that image is yeah okay yeah okay thanks so and our continued uh so despite all the potential errors ambiguity I mentioned uh previous we still want to derive the reliable device model from menus so here we design a multi-level validation schemes and the first Parts actually work on the command level we want to fully audit the syntax of CR commands so we just find out the command convention in menu Preamble and express them into the equivalent backwards normal form and in this way we can use the password generation tool to generate the to generate the a seal command syntax puzzle and call them to identify all synthetic arrows and then the expert can only the incorrect one in more targeted and efficient way and the second part to work on the intercommand level in order to derive this tree base hierarchy which is implicit in menus we actually exploit the example Snippets uh in the menus uh it actually is example generally demonstrate an instance of the current command and its Parent Command so we will construct one model to get their relationship on CRI template level and here we we use to construct a graph from this template energy with the CR instance and so I will skip the algorithm details so in this example we can infer that the CR command template bgps number actually enters the bgp view so the other commands with the same"
  },
  {
    "startTime": "00:20:00",
    "text": "parallel view can also reuse this derivation and in order to handle the hierarchy ambiguities we will quantify the certainty of each derivation and so that to facilitate the expert audit later and the third part of the design to work on the snippy levels here we will leverage the configuration configuration file collected from the running devices because they are collected from the running devices they have the correctness current here to uh to to to be used for validations so for each CRI instance single configuration file we uh oh for each configuration uh lies in the configuration files uh we can derive it uh we can check whether they are matched CLI templates from the correct parent trial relationship on our derived hierarchy and we can record all the image one for the expert to audit later to correct our derived model so let's take a quick look at the results of our Auto vendor device model construction phase and our password plus validator successfully constructs refine and validated vendor device model from four menus of popular vendors and we also identify more than 200 synthetic arrow and ambiguity in the menus so please refers to our GitHub report for more details and the third designs component is the mapper by applying the existing"
  },
  {
    "startTime": "00:22:00",
    "text": "Let Me Wait I cannot see my screen uh this the side component is the existing tedious handcraft mappings we found that the key of the sna is to pair somatic similar configuration items so since uh the path validator has obtained the device model with abundant somatic information from the menus and and those parameters from the unify model is also enriched with contact information assigned by the network or operating experts so we want to design the mapper that can understand the contextual information by applying recent advance in natural language processing so our resultant model is the our resultant semantic comprehension model is collaborate so let's take a look at how it works so for a uh for a given uh configuration item actually we want the model to find out its thematic similar ones in the counter bottom part models so we will run the following process for each pair of them first we will uh we will locate and extract their contacts information actually depend on amount of available information of each model we can we can select different number of contact sequence for the vendor device model we found that the parameter names and the description and its corresponding CR commands and function description and the working views are very valuable for mapping tasks and for the unified device model we just directly retrieve is this description information of each parameter and secondly We Will We Will"
  },
  {
    "startTime": "00:24:03",
    "text": "leverage the most popular natural language processing pre-train model and we Channel domain adaptive version to encode the contention information into the vectors so for one pair of parameters the encode encoder will produce a pair of contacts uh embedding letters and thirdly we will evaluate the similarity of embedding better using cosine similarity and to Quantified the semantic mechanisms so actually we will repeat this process to multiple times to get a ranked list about multiple parameter pairs and so therefore for a configuration parameter our model Network can recommend top case similar mappings so the power of the network comes from two sources and the first is the pre-channel model expert this model is preacher on a large natural language inference data set with the same time matching objectives so it's capable of encoding two semantic similar test sequence into two embedding vectors that are closed in the embedding space however this preacher model may have limited performance in a domain that is never seen in the pre-trained Corpus so we will introduce the Second Source a domain copers of network configuration so to generate it we will leverage a few a few map parameter pairs labeled by the experts but these are only positive pairs so we do random sampling to generate negative Pairs and combine them to focus domain data and we then use this data to do the domain adaptation"
  },
  {
    "startTime": "00:26:00",
    "text": "fine tuning to get the network model so uh now let's have a look at the result of a mapping performance of the mapper actually map is recommended to generate the most likely mappings so here we adopt the record at top k for evaluation metrics which denotes the percentage of test case where the correct matching parameter are in top care recommendation by mapper so higher recall as small okay implies that the mapper is more helpful to assist Network operators we use cross vendor tuning and validation to evaluate the effectives of fine tuning and as shown in this figure fighter Network out for the other models because we adapt this model to the domain of network configuration and regarding the save of human effort we can take an example for the Huawei case we can find correct matching within top 10 recommendation with 89 accuracy so that's if mapper is allowed to provide 10 suggestions the network operator only need to reverse the man menu eleven percent of the time during the mapping phase resulting acceleration by nine times so who conclude we list some key takeaways first the soft Define Network assimilation is very essential for mapping multi-vendor Network for managing multi-vendor Network and our solution Nasim C2 transform the original TDS and error from process to automatically an efficient manner and configuration menus as human written documents are not fully reliable including inevitable errors and"
  },
  {
    "startTime": "00:28:00",
    "text": "ambiguities so nursing feature a universe password framework a routerless validator and a mapper using the domain adaptable model to produce recommendation mapping between heterogeneous configuration models and we also release a validate and executed data set for future research and and this is all of my today's presentations thanks for all your listening and any question is welcome thanks so much for the presentation we've got four minutes for questions answers I've got one comment as someone who's been working on for a very long time so you're trying to do Brute Force attack on inconsistent configuration with inconsistent cli's across different vendors it's a noble task really CLI is really wrong obstruction to work with and you know we wish it would have been consistent within single vendor single release it's not there's usually some product manager who would put some something in it and hope it's working configuration has errors to any degree so I mean running it through neural Nets and trying to figure out what's right and reinforce it it's a noble task but trying to use other abstractions look at young it's not complete but it gives you a very healthy base to at least get consistent Behavior doing the CLI again it's really Noble just but being involved in this for 20 years I don't think it's even possible yeah and actually if you mentioned young"
  },
  {
    "startTime": "00:30:02",
    "text": "I think Young is a very evident Trend and because um I think we at least what we focus on the command line interface it's a very entry-level way to configure network devices we we choose it as the research Target because it's almost supported by all network devices both the Legacy and new but we think that yeah young is a evident trend is a more advanced way to config network devices and a young young but young still don't do not fully adjust the difficulty of managing multi-vendor Network I think because uh although young is a standard but each vendor seems to have their vendor specific young so actually we are also currently working on some topics related to somehow uh try to address the heterogeneous between the different young models between different vendors yeah but I think yeah yeah I agreed uh that this is a this field still need much efforts uh to to address this uh heterogeneity thank you so much for representation yeah thank you from"
  },
  {
    "startTime": "00:32:19",
    "text": "somehow I lost for lost network connection from my laptop so it's just very second it's coming up on the front loading you might want his slope yeah so show me for the first time let's try tradition again on the right way to do it yeah Network right now too but it's been spinning yeah you lost completely effective the strength of the city should not be here try to see other networks yeah"
  },
  {
    "startTime": "00:34:04",
    "text": "let me see something neglected I Research Foundation foreign someone Gold Line uh lending me on laptop you see we'll take a letter in confiscation but yeah this um thank you it's really slow"
  },
  {
    "startTime": "00:36:10",
    "text": "whoever is watching Netflix please connect connected oh no it is foreign sorry for the technical difficulties I couldn't connect to the ITF Network somehow I tried a couple anyway go ahead are you controlling or shall I try to control you should be able to control it okay it doesn't tell me anything though okay mm-hmm okay so let's hope this works um this is about routing on service addresses is a newly submitted draft"
  },
  {
    "startTime": "00:38:00",
    "text": "together with Louise from telefonica who's somewhere else over there I think um I mean it does work um the goal of the draft that but as the name suggests is to propose an approach to transition from locator-based addressing to an addressing scheme where the atlas represents Services being invoked for computation processes and their generated information requests and responses we have um there's a structure that we we've done so far I realized after the submission I forgot the last two sections and they're already updated they were still empty um so we go through a number of use cases I will very briefly go through them uh formulate a number of requirements and then outline the initial design that we've been working with um we also provide the terminology and I want to highlight a couple of things I'm not going through all of them I'm not going to read them but it gives you an idea what we are describing as a service we have the notion of the service instance which is a realization of the service and possibly uh several Network locations across a network um we we well the definition of a service address that we're using um was also important in the in the description is the notion of the service transaction which is a sequence of an initial request which we call the service request and the so-called Affinity requests which are subsequent requests being maintained because of ephemeral state so the idea is that if I if I have been directed to a certain Network location to a certain service instance I'm sticking with that instance because of femoral State once my transaction is over I can be assigned to another service instance so that's important in our model of service interactions to to incorporate in the design we have different architectural roles of the Rosa provider the domain the endpoint that are being explained in the actual text but we put this into the terminology section up front"
  },
  {
    "startTime": "00:40:01",
    "text": "um as I mentioned we we uh outlined a number of use case and we're working on elaborating and adding a few more uh section 3.1 talks about CD and interconnect and distribution so here the main key aspects that we're highlighting is the multi-site replication you have more than one CDN most most possibly you have a dynamic decision making as to where to assign a client to to which of the sites and we also have the ability to actually do multi-site retrieval for Content um to reduce latent civilians we presented yesterday some work in a site meeting where we showed the impact on the latency variants if you do such thing so instead of sticking to one side for the duration of a let's say a long-term video you're actually pulling content from all the different sites and that reduces your variance um quite nicely um Second Use case subscribers distribute user Appliance for mobile and fixed access um so here the idea is to take the so-called user blend functions which is the the data plane in in in a in a 45g system and distribute them uh the the the selection of the UPF that handles your request may be service and therefore policy specific uh and and also some of the use cases there uh are specifically aiming at Edge compute capabilities which you've probably heard enough in in in in 5G type of scenarios the third one is multi-homed and multi-domain services so services that are deployed across administrative domains so for instance for Enterprise scenarios and again in multi-side but in this case multi-site Enterprise facilities uh multi-homing is very often used both at the client and its server side and the the consideration here is to pick the best um service instance where the definition of best may be very very service specific that's hence it's written in quotes so the question really about trying to answer based on those use cases we're working on adding more use cases to the document in the next revision"
  },
  {
    "startTime": "00:42:00",
    "text": "um that's meant to come out after this ITF as to how efficiently steer traffic across these but with possibly significant distributed networks um and enabling also a dynamicity in selecting the best service instance so not doing this for relatively long periods but doing this maybe for relatively short service transactions as well the main idea that we are outlining in the draft as the name suggests maybe routing in service addresses is to replace the typical DNS resolution plus IP data transfer meaning the off-pass discovery of the service name onto an IP locator with an on-pass discovery uh to a suitable service instance location so for that and you'll see this later in a bit more detail we sent an initial IP packet it's directed and again this is an air quotes even though we're using the standard IP semantics we are putting the service oh no don't know what happened sorry for that um they're putting the actual service actress in the extension header uh and it's directed to a special to a shim overlay which you've seen in the in the next slide and well and the shim overlay routes the packet on path uh based on the service name not based on the locator right um it uses mapping which is a bit similar in in role but not in in implementation uh to the DNS records it uses uh these mappings between the service name and the the possible service instance locations to do that once it arrives at the server's instance location it responds back the initial packet to the client which then uses for the subsequent so-called Affinity request the direct IPv6 address of the service instance so only the initial packets one and two go through the shim overlay and after that you're shooting down the IPv6 part um I know you do that as long as the service Direction lasts if you finish the service transaction you go back to step number one you initiate a new service uh Discovery and you may potentially be assigned to a different"
  },
  {
    "startTime": "00:44:00",
    "text": "instance um right if you have stateless Services you may only ask a good step one and two so you never send an affinity request because you have exactly one request in your Rover what so the key point is that the in band Disco recovery is performed at the IP packet level and not at the application Level that's the characteristic of the design so how do we do this we this shows uh the gray part in the in the figure there's the slightly nicer figure than the draft um is a so-called Rosa domain which is identified in the terminology which may connect via a traditional locator based IP to other Rosa domains on for instance the right hand side which have other services deployed um the the rectangular boxes are the so-called service address routers while the round boxes are traditional IB Physics readers so you have the normal ib6 tools as well as the actual saw Roots in there it's located that we call this layer 3.5 it uses Rosa specific IPv6 destination extension headers it's deployed either in the network as you can see here or like Star phones so five for instance are increased nodes into Edge side so they may also be deployed at the edge site it's non-path shim overlay routing for the initial service request and it doesn't do the dedicated off path in Direction like in the various methods like DNS gsrb Etc it is also described in the draft the traffic steering uses server-specific policies you can either do an increased base based selection and I'll show later how this works and how this is differentiated um which selects the service instant location at the increase directly or you use intersile routing meaning you're rooting the request between the individual SAS until it ends ends up at an increase to a data center for instance as I mentioned before the instance Affinity is done over native IPv6 so the the the the the overlay is not involved in that one anymore and routing table sizes are limited given that we introduced a Rosa domain"
  },
  {
    "startTime": "00:46:01",
    "text": "and a Rosa provider the routing table size is limited to the contractual relations you're having right only the services that are being announced to the Rosa provider are in the Rosa routing table you're not hosting if you see a certain a certain Affinity here to information something networking the routing table does not include all the services available in the Internet it's only the Rosa announced service in the routing table that keeps the routing tables as large as you want right there's no client awareness needed so we describe in the draft how a rose enabled client can issue requests to a Rosa service but also to a non-roller service this is handled by the so-called service address Gateway which then gateways to the locator-based IP internet hence you can access anything really it's weird and now my control went away um no this was the right one sorry um we have three different messages so we have a service announcement which is which is used by a servers instance to announce its own IP address in relation to a service address with certain constraints the constraints are being used for the traffic steering I mean after the initial service request which is is being sent to the inquist saw to your to the client specific interests are which hosts the client IP the increase IP as well as the service ID the reason they are you'll see this in a moment in the message you can start there in the extension header is to avoid client-specific state in the increase so we we want to avoid that we you need to carry any particular client-specific state which is why we're carrying this in the extension header the service response has the same entries but it attaches the or it it amends its own instance IP in the response so that's how the client learns where it needs to go for the following requests um the the positioning and the implementation we're currently working on which we haven't brought to this ITF because we're not entirely finished"
  },
  {
    "startTime": "00:48:00",
    "text": "um but we plan on bringing this to the next one it sits under the transport protocol right it sits on top of IPv6 um and it uses ipf6 as well for the affinities uh and it's it's realized under the transport hence the layer 3.5 as we call this the message flow is shown in this graph again looks a bit nicer than the ASCII version in the draft the client sends an initial service request and the the first brackets are the source destination address the second brackets are the extension headers as an explanation of the syntax that we're using it's it sends to the increaser um a service request which carries its own IP the SAR IP and the service ID the service ID is being used to determine the next top and I come in a second there are two different methods that you can use which then sends the uh uh uh the service request eventually to the service instance where derives which generates the response according to whatever the semantic is sent generates the best the service response back which includes its own IP address which is then used in the following request in What's called the Affinity request by the client directly so choose it straight to the um to The Chosen service instance once the transaction is over which is the dotted line um you restart the whole process so in the next iteration the service request may be sent to a different instance that depends on your policy see right so the key point is really that the service only as a service requests are being sent by the by the by the shim overlay the infinitive requests follow the direct IPv6 part my Implement is at the moment through a socket interface um which specifies a different address family rather than IP address you use the address address family for a service address and the entire mapping of the IP address is being hidden from the client you're sending to a socket and if you keep sending it automatically switches to the IPv6 address in the subsequent requests the forwarding engine I show this here the difference is we describe"
  },
  {
    "startTime": "00:50:01",
    "text": "two modes in in the draft one is what's called request scheduling where the increase directly decides what is the destination of the request that allows you to do runtime scheduling or you may use for instance multi-optimality routing this is was actually meant to be a link if you click on the actual underline text you find one of the really nice papers you can use for multi-optimality routing and service specific environments published in sitcom in 2020 and which means in this case you actually forward it to a Next Top saw instead of forwarding it straight to the instance the the difference comes really in the forwarding information base if you look at service.org and this is only written as a URL not to suggest it is a URL if you read the draft you'll realize they are binary encoded names but just for for readability I I wrote the actual domain name there service.org has three Next Tops and if you read in the next hub information based they Point directly to an instance right while the other ones actually point to the next top and that indicates that for service.org you have a a secondary forwarding step that needs to select one of the three possible choices and this is the runtime scheduling that I mentioned before you also can use a special wild card this is the last NV and the phone information basis which is a white card which means if you're asking for anything that the Rosa provider doesn't know it is by default forwarded to the spa to the service address Gateway which interconnects either to a different Row the domain or to the public internet that's how they um client unawareness is being realized so what are the plans moving forward with this job this is the first version I'm quite detailed we worked a bit on it but we want to provide more details on the design realization of this larger section five and incorporate any feedback that we that we received so far proper header descriptions there's all still a little bit schematic um Jens suggested to support to to add support for multi-home service device"
  },
  {
    "startTime": "00:52:00",
    "text": "instances we had that already but we didn't want to have it in the first draft so four for different naming schemes we're reusing the naming scheme that's used in the Isn Community which allows you to actually use naming schemes that are not tied necessarily into phones into domain name name spaces um we can do this so that allows you to also do other service scenarios where you not necessarily use the classical domain name system more use case insights I already spoke of different use cases involvement and implementation insights we've implemented this through ebpf um in a standard Linux router and we will uh combat more performance results in the next ITF we didn't manage to do this in time for the first draft um but there is more and we also plan a demo um thanks what we see feedback on is is the problem space the motivation are we approaching this all from the different and from the wrong angle um comments on the architectural approach on the realization anybody who's interested to contribute or fiddle with a draft please send us an email are very happy to do this and the way forward thank you sorry for the few seconds more Daniel please can you hear me yeah uh from ZTE um trust me I'm um I appreciate it for the wonderful presentation of dark and uh I have two comments and the first one is about the service address or um I I can understand as the uh service identification um my primary understand is that the right here from your terminology the service address or service identification is globally you leaked across terminal and network and the cloud side where the service resides so um here's here's the quite um important issue well"
  },
  {
    "startTime": "00:54:01",
    "text": "um the service address or or in any coordinate the service identification um has has to be managed and published by a a quite higher entity which could coordinate and management the manage and all of the entities from terminal Network and and Cloud site so um it's not simply about um from my personal understanding the network Lord could not alone this kind of service address because it's it's there's a lot of multiple parties and get involved the second question is um um actually uh um what I can say is the first benefit is from from from your proposer the service location Discovery is a processed is removed from the off pass such as the DNS to the on-pass routing so the benefit is the the latency um saving something like that but actually we here is the quite heavy price involved because this is probably we really don't have time for this please cut to the cheese so the first part is we're not rely we are reusing namespace governance in the application space in which you which you work we do this very similar to the ICN Community you utilize the domain name you're obviously relying on the domains governance that exist in the internet and that means if you do a service announcement I cannot announce facebook.com that's not possible I mean it's possible to announce what the announcement will be rejected obviously because I'm not Facebook um so that's that's the only place where this happens where you may of course fake a server's announcement but we are tying into the actual governance that exist and we utilize a certification"
  },
  {
    "startTime": "00:56:02",
    "text": "authorization of the announcement which you can do if you use your namespace I don't care and this is the nice thing about the use of RFC 8609 in in the draft you can use your own namespace um the the the the RFC allows that and then you can do your own stuff right which which I don't particularly care the second part is about is about performance um now the point about the performance is that we are putting this onto the on path and it's distributed which means in the even in the early performance evaluations um we are getting hundreds of thousands of service because we're able to root this is significantly faster than any DNS resolution you can do and that's in a distributed manner which means the increase is only dealing with the actual requests that are coming from the clients it's attached to so it's way faster than doing an edns resolution at high rate so so um I don't think they're that's one of the reasons we did this because the performance could potentially be so much better thank you Robin uh just brief um so while putting application Level things down to the network which provides speed uh drawback could be that the application Level semantics are causing complexity inside the network so what about the ideas what kind of application semantics you can put down into your service Gateway well the only the only applications I'm putting in is is the the description or the identifier of the entity you want to talk to uh and and that's something we we can relatively easily deal with so we're using a hash based lookup which is much faster it's relatively fast uh um and that's the only thing we're really doing at the announcement level you need to do the additional uh verification of the service announcement that's okay but that's not done at data speed right okay thanks thank you thank you please do take your questions to the list and I think would be interesting also to look into what didn't work in the cncc and have some comparison yeah thank you"
  },
  {
    "startTime": "00:58:06",
    "text": "hello so my name is Roland Bliss kit so um I have the pleasure to introduce Kira to you which is a scalable ID based routing architecture specifically designed for control planes um and this is Joint work with martinez over on Archer so controllability is really important uh you may have heard last year's major service disruptions at large providers mainly caused by configuration mistakes they took a large set of services down for a considerable amount of time so Services depend on resilient connectivity and the control plane connectivity is inherently important I in The Meta case for example the guy is misconfigured bgp routing and they cut off themselves from their control Network and it was hard to regain control over their routers again just to SSH to them or whatever in order to to get the whole thing running again so Kira is aimed to provide a self-organized robust control plane connectivity actually so it is designed to interconnect a large pool of network resources uh build compute storage network coverage what have you um and it also should design uh should provide this resilient connectivity for the control entities that try to control the various resources you have furthermore since it's ID based it provides stable addresses for moving resources via the virtual machine what have you or your own um and so uh it tries to provide uh all-in-one features namely uh massive scalability so it scales up to 100 thousands of nodes uh in a single domain so to say it is zero touch doesn't require configuration so we cannot be broken by"
  },
  {
    "startTime": "01:00:01",
    "text": "configuration mistakes um it has a really fast conversion it's Loop free even under convergence or during conversions um it works well in many different topologies which we call topological versatility um so we don't need any special variants of routing protocol in in denser topologies like data center topologies also and last but not least we try to also provide efficient routes there are some related works that um yeah do some things in a related manner but um either dialect Dynamics or um we have a non-id-based not ID based approaches which work in specific topologies only uh so uh Kira is a routing architecture which comprises two tiers one is the routing tier where the r2k routing protocol sits in and it is the 90 based routing protocol uses Source routing and works on top of any link layer while the forwarding tier is some kind of optimization where we use path ID based forwarding which eliminates The Source routing that we use for the source running for the running protocol itself um and it is can be seen as basically similar to your label switching approach and it aims to reduce overhead since we get rid of source routing uh for the control time packets so I briefly introduced what the routing protocol does and how it works um so the first thing that we need to to have is uh to to learn uh the path in our Network and so here we have a very small uh just uh small topology from a larger topology maybe um so the white nodes are basically or white circle nodes are basically a layered link layer nodes and the uh every every node then creates a node ID uh randomly basically and these are"
  },
  {
    "startTime": "01:02:01",
    "text": "the the large letters uh uppercase letters in the in the blue dots um so in the beginning every node discovers it's super physical vicinity uh so X for example learns the context a y b m so we call them contacts and so now is the question uh if x want to reach z uh how does it work and so the idea is here to construct the underlay routes by using the node ID based overlay and we use cademia for that that's why we have K in the name or the cat um and so the idea is that we use Source roads um to the contact that is closest to the destination node ID um I have an example on the next slide and so what is closest if you talk things are closer to each other you need some kind of distance metric and we use the EXO metric from cardamia for that which roughly uh boils down to um if if two node IDs have a longer share prefix the closer they are in the ID space um so now uh let's assume that um X Knows Why um as discouraged in the first step and here also we assume that letter is closer and the alphabet are also closer than the node ID um space just for this example uh so the next overlay Hub would be y for example so um exynosa sorcerer to Y so it's routes via a to y and let's assume that y has known or knows Z Already and so it also knows the source routes you see so X Y will forward the package to Z using that Source route so the complete route um what we call that find note requests in order to discover a path will then um also contain that that small cycle here and naturally uh that could incur some"
  },
  {
    "startTime": "01:04:00",
    "text": "path Bridge uh so the checking routes longer than a shortest path but we can do some optimization so first uh when respond Z responds to X it can shorten the recorded route uh just cutting out the cycles and later pickets actually can use a shorter route because X knows a routes to M which is shorter and then it can use net route for later pickets so the initial stretch that we have can reduce for later packets in case you can um spend some state for that furthermore archicad offers a flexible memory stretch trade-off and this comes from the fact that we are using cademia based routing table which arranges its routing table as tree of buckets where each bucket has a size of up to K contacts K is usually a small number like 20 or 40. and they are arranged by xor distance um so here in this example we have one bucket that covers all contacts that have the different first bit uh in the in the whole other space so so one one bucket also only 20 contacts for example for the the half of the ID space um while uh the closer you get to your own ID um the more information you have so um context in the lower buckets are usually in your on ID wise vicinity um what we now do is store in addition to the uh to to the the node ID we also store the the path Vector so the the path that we learned uh are just attached to these contacts um and so we can do that also uh in a in a way that we prefer shorter routes uh and this actually leads to the fact that we learn shortest path to all the contexts that we know um and yeah the size of the buckets can"
  },
  {
    "startTime": "01:06:01",
    "text": "be chosen so we can have here a flexible memory straight off and basically we have logarithmically large or depending on the number of nodes we have only um algorithmically um dependency on the number of nodes in the network so what about Dynamics so if in case links and my routing is about also covering with Dynamics so uh we assume that once you detect failure in the underlay so let's assume the let's assume the the link between X and B breaks uh then we have a two-step strategy how to deal with that and one is that your first inform your ID wise Neighbors about the faith link and then after that basically uh you try to ReDiscover an alternative path by the overlay route um and we included not via information so that note on the path didn't heard about the broken links that so they can know then they cannot reuse routes that that also include that broken link um we also periodically probe context for broken path and you also have to apparently look up your own node ID um in order to detect any network partitioning and so on and the route information validity is ensured by using State sequence numbers in the concept for path information agents hey sorry that was an animation um yeah so uh briefly about the the path ID based forwarding uh so the the forwarding tier um so the the main idea is to get rid of the source routes and so we simply replace the source routes by using a hash of of this Source route um so the path ID is basically just the hash of the source route and we use the path ID as label for the source routes and basically we use then label switching between the nodes and uh the reason for discovering the two of vicinity in the first place is"
  },
  {
    "startTime": "01:08:01",
    "text": "that we can actually pre-calculate path IDs on your true and natural vicinity uh so we only need explicit path set up for path that are longer than four Ops so uh we also implemented the thing and showed that um basically we use the IPv6 packet format we can embed the node ID into IPv6 addresses and so the idea is that the forwarding tier then has the node ID and a path ID forwarding table and we use in order to use the path IDs we use GRE encapsulation so you have GAE encapsulation header in case you're using path IDs if you don't use or don't need path ID you can just use plain IPv6 header and so any control application that is able to send IPv6 packets um may use keyword connectivity and also the autocup messages are sent by using IPv6 so we simulated that thing on in topologies up to 200 000 nodes various typologies uh just to briefly show that this works not so badly um so for example uh here we have various topologies and a size of 10 000 nodes along the x-axis and shown is here the average multiplicative stretch along the y-axis and so the green dots are the first packet stretch that the first packet C and later practice are the the blue triangular triangles um and we compared here with a ripple and a soaring mode single double deck single direct version and so on and you can see that we can even achieve for the first packets a better stretch values in average and what is really nice is that the stretch to the context so all the contacts that you have in your routing table um you have effectively shortest path routes so you've got two and a half minutes and 14"
  },
  {
    "startTime": "01:10:00",
    "text": "slides one go ahead you've got too many slides to finish yeah no no don't they're backup slides don't don't worry uh that's just showing uh the Dynamics part um so in case you have a hundred thousand nodes 15 of the links very randomly at uh 20 seconds uh then we are able to converge within roughly 10 seconds until we have nearly full connectivity again with uh scalable overheads so uh the the packet rate is is quite quite low in in that case so uh to conclude Cura provides self-organized robust control tank connectivity it is not meant to be a replacement for ospf Isis or bgp because it's not data plane routing right so it puts connectivity first and efficiency second is designed for large provider domains as we expect them to have in in 5G or 6G networks and could be used also even across multiple providers we're currently developing our domain concept where you can keep the routing inside your domain more local so you're not depending on other domains security can be easily added in that sense that we can have safe server defined node IDs and that stuff it is a path Vector protocol so we can also um I have uh hash values or a Max for for path and so on uh we also designed a special end system mode that reduced the overhead even more so in case you're not the router you can still use the node IDs but you don't have to actually send router updates and stuff um it also supports multipath routing also the forwarding scheme the path IDs do that and we can also easily integrate a DHT for a simple name resolution service Discovery and recently we had developed a new scheme that enables also very efficient topology Discovery so you can discover within seconds 100 now a"
  },
  {
    "startTime": "01:12:01",
    "text": "thousand nodes topology with most of the links so um having said that um we have a side meeting for today uh starting at 7 00 pm and it's a small room as a 912. I have to leave for the animal working group because I'm supposed to be a give a presentation also there but Paul uh sitting here next to the the mic will be happy to answer questions in case you have some after the session so thanks thank you Alan any questions foreign so to do the initial Discovery if you get a node you don't recognize a node ID if these are randomly selected it's how do you it's like a how do you find know who you want to talk to the thing is that that you wrote simply to the closest node you know I closest in the ID space and the Excel metric is very nice and because it's Unique so you always can tell whether you're making progress in ID space and in case you don't know a node that is closed so then you choose the target then there's some inconsistency in the routing table or the node doesn't exist anymore okay okay so that's that comes you know you know you want to talk to this guy through some outside mechanism now so when you start this out if you see if you're trying to talk to someone you've never talked to before you just send the discovery out all your interfaces yeah okay not not through all interfaces just through through one right so so what if you send it the wrong way what if it's it's partitioned"
  },
  {
    "startTime": "01:14:02",
    "text": "if you send it if you send it uh right and the and the guys to the left yeah right um we do not see so much stretched so that the the progress is usually very localized in that sense so so if you don't make progress then you go the other way no I mean it's yeah if the ID way is overlay is consistent then we always make progress that's for sure so the ID tells you which way to go and that maybe exactly yeah oh okay okay exactly yeah I think I saw something like this years ago where the IDS were you go right or left or up or down yeah sure I said there's prior work but we have it a bit differently and yeah okay one things in different ways thanks you have 15 minutes okay hello this is hibo from Huawei uh this time I'll present tour jobs the requirement of three faster for detection under the framework of us for detection for IP based Network next please who have control of the slides oh how can I control it bottom of your screen can you help me don't find how I can control those lines just sure"
  },
  {
    "startTime": "01:16:03",
    "text": "it seems ready yeah just go ahead I'll flip it for you okay okay uh this is a motivation of our jobs uh today for most database applications always use a long time out to identify Network failures this will cause the uh ZIP codes but with the also they are very much designed to the faster really detection is especially for high performance applications such as IP based mme and the class computing they can hardly tolerance the long duration of failures included from the tunnel scheme for example for the ones when the failure occurs on IP based on ume the iops will reduce to zero until the equation can identify the failure it's through the key level timeout and also for cloud computing it is similar where IP connection for the server is done the correspond respondent Computing in a phase will be blocked under the whole Computing progress may be affected uh this pillar detection there are also there are there are some resist the failure detection mechanic mechanisms such as BRB also we can deploy the multiplied The BFG to accelerate the fourth tension but this mechanism will typically consume the system resource heavily especially for the host and servers so from IP network Point uh we need an economism to help the host accelerate the 40 passion and provide a better experience for the high performance applications uh such a high performance applications are really wrong in controlled domain"
  },
  {
    "startTime": "01:18:00",
    "text": "such as a data center Network and this should be considered when designing a solution and deployment next please this is the ID based memory use case here show a small activation I mean Network the horse the the all the horse and the storage connected to two switches and the host one creates a mme connection to the storage you want the ip1 but when the ip1 link is failed the host one will not detect it until it keeps time keep live timeouts the failure May last for more than 10 tens of a minute seconds before being handled during this time the connection between the host storage is disrupt the store service storage service is completed stopped next please this is another class Computing use case there are there are now there are many distributed computing algorithm for some for some kind of the Computing algorithm uh the server the servers will be divided to several Pairs and each pair will connect communicate with each other Network about the Computing model uh the server one server three are paired and the server two and the server for another pair they are they are they are both to the class Computing but the servers uh when the server series the link to the leaf three is fair uh the connect the communication the communication between the server one and server three we all will not work this video will block the step of the"
  },
  {
    "startTime": "01:20:03",
    "text": "commuting and the whatever it is further will will block the whole cluster Computing the job scheduler cannot reschedule the Computing task until the detecting the server series failure this thought it may be lasted for one or more minutes next please uh this is this is our requirements and first we we want the network device that can detect the link or network failure second we want the network device can synchronously synchronize the failure to the other network devices because some because there are many there are many many network devices in network uh so the network device can notify local or remote failure information to the local access endpoints and then after the network device they send the notifications to the endpoints one is the test or be notified of the detection over any of any of the endpoints subscribing failure so next please this is a framework of our web reference model uh in this model it will using a controlled domain both the client component Imports and the server endpoints are allowed to register with their IP information and some other information with its access switch Services the third one points must reaches is register its information to that network but the registration is opting optional for einclined endpoints uh each client unemployes subscribe to the network for the reachability of the IPS to its E2 where it where it is"
  },
  {
    "startTime": "01:22:00",
    "text": "interesting the registration and the substitution information is synchronized and propagated through the network when a network device such as switch one or switches to detects is a scheduling failure or awesome on on Commercial Network failure the switch will quickly notify the fault to those client endpoints through subscribing subscribing is the app information when the client endpoint receive the notification it can immediately include the recovery by switching to the backup path next slide please here is an example of a procedure example this is a also a IP based mme and Network in this network the all host and a storage devices register their information to the IP network such as its raw where is the where is the host or storage under correct correspondence PHS or host and client endpoints create mme connection to special specific storage device here is show the host one it creates a mme connection to store the one the ip1 and also he may create a backup connection to story through one the ip2 wants to know if your status and the Subscribe is a request to the app network with me submit the request to the switch one one ip1 link Fields switch one can quickly detect it and notify the failure to host one host one when receive the notification uh then he can to quickly start the reset or recovery progress how to do it it may be defined by the mme"
  },
  {
    "startTime": "01:24:01",
    "text": "scheme that's that's like this this is another particular example it's for cloud computing okay in this in this particular the job scheduler uh he wanted to can also at the four servers are connected to the network the job scheduler here to a tasks and divide the four servers two into two pairs so we want to so on with the server three is a pair under server two with a service to work for so four is another pair uh all the correct connection to to for each other then job schedule wants to know all the servers the IP status so it can it subscribe to all the subscribers to us every servers IP at least one one ip3 is the link fails if three can quickly detect the failure at least one count so if three will synchronize the status the change to other leaves level one receive the synchronized single synchronize the information like it notifies the job scheduler based on on its subscription job scheduler identifies the fourth path and then he can reassign the Computing task to other good servers so the then the then the Computing will maybe continue to go on next slide please so this is uh before is our two jobs so next steps we welcome more comments and discussions and also we revise the jobs accordingly thank you foreign presentation or"
  },
  {
    "startTime": "01:26:00",
    "text": "I think it's both already yeah okay Greg yes uh Greg mirsky Erickson uh can you kindly bring the uh requirements uh slide um in the meantime I just wonder so what your goal uh what you are planning to achieve with this work uh our our goal is to the network help the client endpoint calendar to quickly detect the network failure such as the link IP Access Link value on the app on uncovered just a network failure so the whole network to detect failure or a device to detect failure Network the network will detect the failure and notify its a failure to the access endpoints so uh okay regardless of their size of the network so you you you you plan to do it as a distributed system or you you look at centralized uh system that can needs to know about the failure okay well we are just a tool do it by the network device I mean distributed system we don't have a centralized system to detect detect the failure so each device in the network must learn about the failure yeah this is a this is the first step later maybe maybe do some optimize about how to reduce some information and to the network well uh I I think that that's already can be achieved through the igp protocol uh yeah you mean that how to"
  },
  {
    "startTime": "01:28:01",
    "text": "implementation the network information signalization this is this is not described in our framework now let's take it to the list again this is so uh I'll let David talk about nvme and uh I'll take a second as a working group participant talk about clusters machine learning classes specifically the goal is to converge with a number of attitudes not number of seconds the infrastructure is highly parallel massively parallel so there's no single point of failure the goal is in requirement is to detect failure as soon as possible and Route around it if you're an accurate Network this is commonly implemented on the host today you could you could flow Bender or variety of other techniques to change entropy to your out round failure if you need to notify a controller you're in seconds your machine learning job is dead you lost hundreds of millions of dollars potentially so the requirements aren't suitable for machine learning clusters in any possible way that's my personal trainer okay so uh my name is David black I work for uh dell EMC and I sort of feel like there's one wonderful British phrase for the opposition party in Parliament uh it's now with Charles's King is his Majesty's loyal opposition and I would lay emphasis on the loyal in that please and Frank would like to make a pause contribution here I'm one of the original designers of MV mirror fabrics and the Envy uh me over TCP transport that is of primary interest to the authors I guess the first thing I should say is that I'm surprised the storage networking configuration shown in the uh slides are unrealistic uh it's an active passive uh configuration storage networking is typically moved to active active these days which means as opposed to Second path being backup the second path is active so if you've got a"
  },
  {
    "startTime": "01:30:01",
    "text": "failure on the first path There's an opportunity to immediately use a second path to get that failure and information uh communicated without having to go sort of indirected through all the switches um and that that's probably the the better place to start uh for nvme because uh you're not relying on on the uh the level of switch interactions now turn to those interactions I can't quite figure out what's going on here but it looks like um the failure detection mechanism is building a model of the topology and in particular of Ip accessibility for the cases in which Link in the network fails that's not a good idea to do on doing their own routing system is the authority of what network topology is what the connectivity is and what IP addresses are reachable from where please don't reinvent that and I guess uh one of the major point of minor point the drafts labeled security considerations as n a which I presume stood for not applicable uh unfortunately also stands for not acceptable this class of it's broken gone mechanism is a great Vector for a denial of service attack and and uh that's going to take some serious security thought uh minor point is that um real when we talk about link failures we try to talk about as binary the link is either working or it's not real links fail in really interesting ways the uh draft office said that they don't want to use BFD okay but need to do something so if the switches aside the link has failed turn the link off the other end of the link generally tends to notice pretty quickly that lack of light means means a dead link and then you don't you don't have a problem with the two ends uh disagreeing on link failure okay thanks for the opportunity be happy to take any questions uh including from uh uh hi Beau if he's still on yeah okay thanks for your comments um"
  },
  {
    "startTime": "01:32:02",
    "text": "thank you dude and Versace is coming just to let you know All Storage protocols as well as your Gmail like product calls do Implement their own livability mechanisms at much lower layers than AP and it it's very fast it's actually rtt Mach 2 rtts so we are talking Nano seconds definitely not seven can you please uh show this slide with the storage a network architecture from the previous presentation if possible yeah next there is a the next one uh yes this one uh I just would like to say that in this configuration if switch one and switch two were connected and if access of hosts to storage One turns three two stars three were not uh my IP addresses of these devices on the links connecting them to the switches but on some kind of say Lubeck addresses switch the switches that in Fairfax can detect very quickly the link failures could simply rear out whatever uh our exchange happens between host one and host any specific host and any specific storage without involving any interaction in the hosts whether the host itself the host was remain completely ignorant of what happens in the network which most probably is what most Network operators would prefer uh if the switches are not connected uh this looks indeed like I think David has said a somewhat problematic"
  },
  {
    "startTime": "01:34:03",
    "text": "Network architecture but I did not think that we have to uh I'm not sure where we here should try to address the what personalized see as a poor Network design by propagating some new functionality to hosts okay thanks for your comments okay okay so um thank you for the presentation and all the comments are great so let's go to the next one um oh by the way if you are on site please make sure you scan the QR code and sign into the meeting so yeah just a certain room of course like this no I I passed you the commercial you don't share this life okay everyone and I will give uh uh as a physics deployment use case so you can have this time and"
  },
  {
    "startTime": "01:36:01",
    "text": "okay and about this uh this document is a Services deployment Constitution and this is the zero sixth version so at the first I will give our simple instruction to the document now and uh as rb6 has a significance and other uh what you cause to use Asics and have and as so far one thousand and each controller networks have deployed the SMS sr6 V6 and so and also the SM Sr V6 policy have also been deployed to money networks and also use like as FD and TFA and a filter and like this future also have deployed to improve improve the SOA of the network and uh and currently money um money networker was thinking about the smooth migration to as a Basics and countries so this document will give some design and network design and the migration guidance about about this okay and this as a ZO6 we add a new use case about the agriculture Bank of general diploma in the case and this the agriculture Bank channel is the top top five biggest bank in Channel and the deployment is the"
  },
  {
    "startTime": "01:38:00",
    "text": "deploy the SR srv6 policy and controller in the backbone Network and so first of all we can introduce the all the network status in all the network uh the the ABC they deploy osb2 and it is very six to asset background and to to get the network and to cut the C and P and to save here to connect here and I always through VPN is deployed at the local network to carry the service like the financial services and office service and internet service industration VPN and the SRT is used but it is hard to attention to the branch and to implement and to end as a traffic management and the traffic between the branches and these centers uh has ability all right okay so for the new networker the ABC have deployed the network controller and as a Basics policy over its backbone so to automatically optimize the link"
  },
  {
    "startTime": "01:40:00",
    "text": "traffic and the SR policy is used to implement the and the calculated in centralized and about one 100 are deployed in the internet worker and password since the least launch uh mostly is less than six so use uh use the IPv6 IPv6 original and only Japan so and the compression is not used and the VPN are divided by the service and the based the company of eviction and the tsap okay so and also a service and the VX line are deployed as a DCP and to implement the tunnel in working between the DC and the and Backbone in the worker and spfd is deployed to detect the service policy and connected when the password fails and the traffic will quickly switch to another normal path and also a feature is used to to deploy the two implementing the service level I would say detection so in the ABC networks the future is deployed and the next maybe is we the the is planning to deploy the new future and in the future okay that's all thank you may ask you a question as a working group participant which of the services presented cannot be implemented over the southern PLS you said the service has"
  },
  {
    "startTime": "01:42:00",
    "text": "advantages from your presentation it's unclear you could go to the okay Services countries is not used in the in the campus in the campus so we just used as a bone but for the campuses they can use them so they use asafix country use they use the sr6 from the this complexity to the the remote and the um look we'll take it to the list but looking through the list of features implemented there's nothing that prevents implementation of these teachers there's any other technologies that exist today you mean the advanced I'll comment on the list here from the TCP to another disappear so looking at the list here you said that it requires srv6 in order to implement new services I don't see in single Services cannot be implemented with other Technologies I think you you really need to clarify what are the unique and distinct advantages that would require significant investment into new technology in order to benefit from it once again what you see here doesn't just maybe I can instantly use a detailed department yeah thank you okay thank you yes can you hear me yes yes yeah I just said just a quick question uh you know your"
  },
  {
    "startTime": "01:44:02",
    "text": "SRV says are you but are you using uh is there an inner working that you're using between the data center and the core so the core is srv6 and the data center is VX slave I don't think anyone can understand the word of what you're saying if you cannot get your mind quality better probably would be better if you send it to the list okay okay all right thank you thank you okay thank you hello hello can you hear me chair can help me yeah so this is a for young from China mobile this proposal is a by a joint effort of the China mobile and the h3c you have control of this life yeah yeah I I I guess yeah the background is that you know we have a good definition on the srv6 hierarchy uh the first level is policy as then come to the path and the bottom is a sid list so uh that this is good if we when we got a failure we think and Sr policy as our policy so it's a good protection but in case of about if we consider if the one policy run out of the resources or the policy got some failure in for example some of the sincerely field so the bandwidth"
  },
  {
    "startTime": "01:46:03",
    "text": "got impacted so not not all of the services can be uh can be can be assured with a good quality so we want to what we what we want to do in case of there are still some of other parties that can carry those those uh over traffic so that's a that's a question that's a problem we are we are we are thinking so uh so for example when there are 100 service and voice traffic has have different as our current that means they have they got different of the uh as a policy because each Sr policy has can be mapped to one color so they are carried by different policies part of failure happened with with uh as a policy carried the OE traffic or the voice traffic so uh we we should have some way to uh to to keep our services running so the idea is what we what what we think is first is which we should maximize the failure or the degradation protection in case of there's still some resources we can use the second one is we should minimum the impact after after taking the repair repairing action that means when the general failures happened we need to uh not not not switch over all of the traffic to the other policy but just pick up some of"
  },
  {
    "startTime": "01:48:02",
    "text": "the some of the prefixes from the impacted policy to the the the the the other the other policy so the last one is is that way we can maximize the band-based efficiency because uh in case of there's still some uh bandwidth available we can reuse them to keep our services running so the then uh the best idea is that we need to set some rule on which policy could protect what policy so the idea is to uh to to group the policies together uh and then have some some some some some some priority mechanism to uh to give the order of the uh traffic uh switch over so the uh so this is the basic idea so the zero there will be uh flow classification which will identify the service class and then third class does does map to the color of the as a policy and then we got the flow steering to Stair not uh individual policy but uh policy group and then there is a new uh new new unit or component which is intelligence logging which takes the takes takes the traffic and makes the decision on which which the policy that it should forward the traffic"
  },
  {
    "startTime": "01:50:02",
    "text": "so uh the intelligent blocking unit also takes some input of the network called environment for example the BFD or some of kind of uh latency or loss passing off as an input so first one is uh is a simple just a flu classification and just take a take some some of the uh some of the of tuples or something they are to uh information out and again and to identify the first class and the first Theory unit is also a very straightforward it's just a mapped the search cast to us as a pass group so the the thing is so we come to the Intensive intelligence login unit so this part we takes the as a pulse group as input and also some of the measurement result as input so here is a policy decision decision function which which can just just decide which which policy the traffic should be go so we have the several policies with each with the priority set so prior to just represent a represents the highest so so so the priority is a uh is is defines the manner what's what's the highest uh"
  },
  {
    "startTime": "01:52:03",
    "text": "priority that's the parts policy should take take a spill over traffic from the Imp from the failure impact either policy yeah yeah so uh there is a level called measurement units that takes some some to marry some latency or Twitter or loss so uh last one is a flow foreign unit that is normal so we have the example here is first we Define the some policy policies and with colors and then we combine those the second step we combine some of the houses together with with the color the third step we just mapping the traffic to those those past group so that's that's the idea of what we want to do but uh maybe it's not not perfect but we can improve it so that's all thank you we are not taking questions here present to the list thank you for the presentation we'll go to the next presenter okay um so probably I can already start so um my name is David Rowe from Huawei Technologies this is a work actually um together with my colleaguers Luigi uh"
  },
  {
    "startTime": "01:54:01",
    "text": "Eugene and um training talk about the um signaling in network computing operation um so sorry ah okay okay sorry foreign maybe you can just scan the phone oh okay should work now it works yeah so um things I only have a few minutes left I will be just speed up um so the motivation basically is we already observed a lot of network device on taking some communication tasks to improve the overall Network perform overall system performance and typically they are done in the program switches right um but we are lack of kind of generic and general way to define what to do how to do where I get the data and where to how to process it so that's the purpose of this draft if you look at the use case one of the use case here is happening a lot AI artificial intelligence machine learning happened in the data center where you try to distribute the tasks to different hosts those hosts will take part of the calculation and the send without the back and there's a APS server called parameter server try to aggregate those data and punch back the results so traditionally the way is you build a tree or start topology where the PS server will react to all the results from those hosts but apparently you have an in-cast problem number one secondly the PS server becomes a bottleneck right although there's other Solutions like all reduce try to design the ring topology to distribute the tasks to different"
  },
  {
    "startTime": "01:56:00",
    "text": "servers but still this is not really ideal so we uh we find that let's switch to do that task in the wrong line rates will be the up to uh will be the best option so this is one of the actually um use case there are two other use cases happening in the data storage Network where you want to store some data you just trying to get the right right so you have to really check the lock and then um once you have this you can do that but I will not really dive deep deep into those use cases those are the real use cases um they really need the network switch to help it's not like with networks which you can do better no no they really need the network to do something for them um so the idea basically is to offload those leading coordination Mark and bottleneck Computing uh operations to the network device in order to improve the system uh performance of course we don't want to affect the forwarding performance right um so two things we need one is generic and simple operators are designed to to execute those scenarios you need to know what to do where the data comes from and how do you process it secondly you need to have a expected way to Route the package to the right place so that they can be operate at all executed so a quick overview about that is we have the uh hosts which should tell uh what to do so there's a async header created on top of UDP to say that okay I want to do this aggregation and the data are coming from those resources and how many of them so this can be information this is the first part the second part actually is"
  },
  {
    "startTime": "01:58:01",
    "text": "you have to have a mechanism to look back to the right place because you probably don't know which switch has that capability right so for that we can use a lot of um kind of mechanism to root back to the right place in this draft we use the example of surface function training we can also use as our signal routing or mpls or even others right but in this particular example we use sfc so you will you will see that we have a sfc Ingress proxy try to create Eternal and then to Route the package to the right place um okay so um so first of all the sync header itself this header is used to tell the switch what to do so you will see that um we have a group ID we have date of resources data resource ID sequence number they are all combined to tell the the switch where the data is which data I need to operate on then you you need to specify what kind of operation right is a it's a sum it's a maximum mean or it's uh um CNS FNA or others um of course you have the data offset to indicate where the data is in this package right um particularly there's a loopback flag indicates that after this data operation you need to send the data kind of uh back to the source or you need to continue forward to the destination um so the second part actually is creates a kind of a tunneling in this case we use sfc as I indicated so in the Ingress you just wrap up with the next service"
  },
  {
    "startTime": "02:00:01",
    "text": "header until the egress and then send to the destination of course in the middle there's some nodes with the sync capability to do the data operation um so this is actually encapsulation uh by using sfc um we use the base header pass header and the context header um the context header is the sync header we I just explained um the service pass header uh are defined in RFC 8300 and of course in the base header we have to specify um the a few things like lens TTL or others for the metadata type by quiz coincidence means our sync header is only 16 bytes so we can use MD type 1 that fits very well okay so these are the last slides so basically this is the first trying and there we know that um it's not very clear for us where is the home for this kind of drafts because uh um this is working on the kind of uh data by leveraging the program switch we use the sfc as a carrier but as I said it might be other um kind of uh routing mechanism could be better suited for for this case so we welcome any kind of discussion um and we are going to update the the draft based on that of course and this is only the data playing and Next Step probably we will do the control plane and others yeah thank you thank you for the presentation so with regards to home to the draft sfc doesn't accept any new work and we are looking for guidance from alvare and our ideas to"
  },
  {
    "startTime": "02:02:00",
    "text": "okay yeah okay so we will let you know yep okay thank you and thank you this is very timely interesting work with prolification Transformer models it becomes business I do my best thank you everyone and we are done in London and hope to see you in Japan soon thank you yes I'm just gonna switch so in network computers it's an existing technology it's not new right there are use cases"
  }
]
