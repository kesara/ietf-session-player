[
  {
    "startTime": "00:00:26",
    "text": "good afternoon good evening wherever you are this is the netcom working group 112 virtual meeting um can't you want to go ahead and actually enable the notepad if it has not yeah i'm looking at it right now okay all right um by participating in the itf you agree to follow the following itf processes and policies if you are not familiar with them please do familiarize yourself with them well you are here in this meet echo session so you don't need the link um watch the chat window for comments and i believe it can be made a separate window if you want we have one r uh we requested for one hour a slot for the netcat agenda um we will try to stick to the time that's allocated for each speaker um as pretty much tight on time there will be a countdown timer at the bottom of the screen to help guide the speakers try to stick to that time we don't hope to have to cut off the"
  },
  {
    "startTime": "00:02:01",
    "text": "microphone in case we run out of time the as usual remember to cue yourself in medical by uh clicking on the hand symbol and to speak remember to unmute yourself you know at the end do remember to remove yourself from the queue and we should have a kodi md window up ready for anyone to put in their notes actually do help us i think yeah i'm just gonna say i think it is set up right now if you go to the in the top menu note taking tool click there should see it initialized okay thanks again all right we are going to ask the presenters to do their present their own slides so um it should go relatively smoothly but this is new for everyone so where are we with this chartered list of workgroup items uh the young push notification capabilities is of course past i say review it's in the rfc editor queue at this point kent will talk about his suite of drafts the clients are the suite of trials in the next slide the https notification draft uh kent and i being the authors on it believe have addressed all the open issues and we believe it's ready for publication um rob did you want to go ahead and okay let me grant you i think i can just i don't"
  },
  {
    "startTime": "00:04:00",
    "text": "can you hear me yes yes uh yes thank you for this i'm sorry i think that's that's good um one question to the working group is it be if anyone is offering to be the document shepard for this document that would be appreciated and i can go around asking but if anyone would like to do that and then that would be helpful for me and they can do so okay so drop me an email if you're interested thanks all right thanks rob the yang push notification messages uh expired today um we i know that this draft has been on hold waiting for https notification to get done now that is done um we would ask the authors if they're here otherwise offline to revive the draft and post an update and proceed with trying to finalize the draft the udp native draft is a work in progress and is going to be discussed in this meeting today um can't any comments um oh sorry we let's move to distributed note of draft and maybe we can come back to if anyone has any comments the distributed noted draft is a workgroup document it expires soon if it hasn't already expired um the authors i don't know what the plan is as from the authors do they plan to continue working on it um if they bring they will i think that they would like to bring the discussion back on the mailing list and make progress on the draft so we"
  },
  {
    "startTime": "00:06:00",
    "text": "hope to see some activity the sctp csr draft is um i believe i saw a post today from kent um and you just updated and addressed um some comments correct a um a duplicate paragraph i had had to be removed so i just removed that paragraph and reposted it at this point it should be ready for up all right uh so again do you want to go ahead and um sorry rob go ahead ron uh yes so i think this is done so i will send this on for itaf lascal thanks all right oh it do you can't right okay for the client service suite of drafts uh so first and foremost we've completed the last call on the entire suite of drafts [Music] the last two netconf client server and rest comp client server last calls i think we declared completion on about two or three weeks ago after soliciting feedback and not receiving any objections we've decided to move forward with process and then but there are some issues pending and on the right hand side there's it's two are listed but actually there's a third as well i need to speak to um so firstly you may recall in the tls client server draft there's an open pending issue that came out of the last call for how to support uh raw public keys and pre-shared keys for tls 1.3 pom pets raised the issue and hank dirk schaff was going to help resolve the issue but we've yet to"
  },
  {
    "startTime": "00:08:01",
    "text": "actually resolve the issue so that's remains pending open item secondly in the both the key store and trust store drafts uh i i think it's incumbent upon us to ensure that the language there does not preclude the ability to use the system-defined configuration work that the netmod working group is um engaging in that uh currently these built-in keys that there's discussion about how they show up and operational and maybe they need to be copied into running but um we want to ensure that you know uh if the system work goes forward that you know those keys could alternatively are actually preferably show up in the system data store so just want to uh go over the language there and make sure there's no or it doesn't preclude that ability and then the third item that's not listed is that there was a liaison request from ieee on the key store draft and kind of related to the same point about um built-in keys and the copying them to running and they had some concerns for well you're not really supposed to be copying private keys to running and in fact the they claim ieee 802.1 ar spec says you're not allowed to do that and so i think actually this is just a misunderstanding because you know there's the actual key data and then there's sort of the yang node that is the parent node of the key data it's really just the yang node that needs to be copied into running i don't think that subtlety was uh clear enough to them and we just need to follow up with that liaison request and i think"
  },
  {
    "startTime": "00:10:00",
    "text": "rob was going to suggest having a meeting of some sort go ahead rob uh yes so i've had a a bit of an exchange with glenn parsons the attitude at one um working chair uh and i think we'll set up a meeting between you and the person raising this issue myself and glenn and see if we can informally work out the right solution and then also determine whether any sort of liaison back to is required or not so the next step is for me to set up that meeting perfect and that's it for me thanks the agenda for today consists of one chartered item and that's the udp based transport a configured subscription on the non-chartered item list we have three drafts um thereafter subscription i think that's has been presented before but i guess we'll see an update um we have seen quite a bit of discussion on the transaction id so ian is coming back having updated the draft and i believe uh the list pagination draft has also been presented before all right that's as far as the chair slides are concerned any comments or questions before we jump into the agenda all right yeah this can't i have a comment which is just basically uh to all authors um to please try to be proactive about bringing discussions to the mailing list um you know you know any issues that you're working through um internally you know ask the working"
  },
  {
    "startTime": "00:12:00",
    "text": "group for their opinion as well it's that's the ietf process and how we do consensus documents so thank you all right so we have um the first draft which is the udp note of trap and i believe who's presenting it by the way okay alex is okay will we grant you the permission can go ahead um so hello to everyone this is alex presenting a short update on the last udp native dash o for draft so on the agenda today i'm gonna present the different changes with it between the dash of three and the show for draft the received comments we received so far on the mailing list and finally start a discussion if this draft is stable enough to be last cold so the changes we did on this draft the first one is regarding the encoding types we reserved the zero value as requested on the mailing list and move sieber to the bottom to comply with the existing implementations of json udp notif the second one is regarding the tls on the last etf we submitted"
  },
  {
    "startTime": "00:14:00",
    "text": "at the last moment a dtls version of utp native we were asked on the mailing list that both drafts should be merged so we did that uh on this draft um there was uh just explained uh on that there were we we have to use dtls 1.3 to secure the utb notif message we explain the life cycle of this usage and then that the udp notif message should be sent as application data of the dtls layer we added just this draft as a new section of utp notif and then finally on the ayana section we demanded the creation of two pull requests one for the encoding types and another one for the option types so that's just changes so far the comments so thank you andy biermann for your feedback we were requested to add the reference of the rfcs of the encoding types this one cbor and xml so we will do that there is still a discussion about which where version should be used of sibor the rfc one or the draft one and this morning i guess i i received also a feedback from maish so thank you and yes we will address this this feedback soon as possible"
  },
  {
    "startTime": "00:16:02",
    "text": "and then for from our side we consider that that our draft is uh begin to start we begin to be uh stable enough um so maybe uh we it should be sooner less called but we let the work working group chairs decide that um yeah go ahead rope um so so one sort of question of concern so i um i raised this draft or what has been done with the security ids today i should have asked them previously they have some concern about standards track document um basically sending data over an unencrypted channel so um so something that that we need to work out whether they will allow standards track document to do that and the information document would be okay but the concern is is it over is ever it being a standard track document so that's something that we need to resolve um we could potentially try getting a sec dir review or the other choice might be to see if we can catch one of the security ids in gather dot town this week uh just chat over this but i think that's an issue that ideally we resolve that in a working group um before last call if we could and the other one to be aware of i know some text about this in the document is at the same time asked that question i got some feedback again we need to check that we cover the sort of transport requirements in terms of handling congestion things like that i know there's some text into that document but we just need to make sure that we're quite careful that that's covered as well okay"
  },
  {
    "startTime": "00:18:00",
    "text": "so rob uh just to that point yeah i think um syncing up with this or ad would be great um i do actually have some empathy for uh wanting to support native udp because i think the use case scenario is actually for a private network consolidator it could be inside like literally in the same rack as where the uh log generator is located and um for you know so you don't want the overhead of cryptography but um you know i think so that's that and then also notably that we're not actually defining the protocol we're just simply configuring or enabling said existing protocols to be configured so these are things that can be discussed with the sector or app okay and then just just one other comment actually is if there's anyone can join the um the note taking that would be really appreciated so if people could also help contribute to the notes that would be helpful go ahead bear yes thank you regarding the security support are you saying that now that the dtls section is in so sending uh udp messages encrypt in the clear is an option but the rfc would is defining dtls report as well so is this not good enough and also with respect joining i think kent on this with respect to the deployment considerations that we have and if we review the rfc on udp applications we are clearly in the field where i mean sending messages in the clear would be"
  },
  {
    "startTime": "00:20:00",
    "text": "should be tolerable do you think that there will be an issue with that type of positioning of the draft with respect to security considerations or don't you think personally that this is good enough um so so to answer that question is the answer is i i don't know because it's not it's not my decision as such i certainly have sympathy with the uh the way that both you and ken characterize this that that the network is meant to be secure in that regards and management network and hence that should that should be sufficient i don't know whether that would be good enough for the security ids or not it really needs to be um or in the security area i think it's probably better at putting it we need to actually check with them and have a conversation with them and they may we put sufficient mitigate mitigations in that may be good enough i don't know uh but it may be there they just say no they don't regard the overhead of encrypting this is um is high enough to justify not always encrypting it but i don't i don't know how to ask them okay there are a lot of protocols where we will we would need to redo that discussion then but okay okay with respect to congestion i think it's covered in the draft so on your comment with respect to use of udp and congestion in the network uh when we discuss the applicability and the consoles that you have when you're designing a udp application i think it's covered but uh i mean we can have this discussion offline if you want if it's not good enough we can work on this on this description more thanks all right so i had actually uh one comment and one question or i'm trying to answer one of the questions i think that was asked on the mailing list i believe that the draft talks about you know a transmission timer not a retransmission time but a transmission timeout value to be said at which point um you know there's no attempt to try to but"
  },
  {
    "startTime": "00:22:00",
    "text": "there's no um configuration in the yang model for actually configuring the transmission timeout so i don't know if the intention is to keep that timer or not keep that diamond so that is one of the questions um the other is that is there a request for a one loan udp port in the draft because i i don't remember seeing it in there in a section maybe i missed it right there yeah so with respect to the timeout i'm scratching my head a bit but it might be for the retention time when you use segmentation oh yeah maybe we may want okay okay if it's that then yeah we may want to have it configured i'm not sure people are going to care much changing this with respect to the default value that would be provided by vendors um [Music] yeah and sorry i forgot your last question your second question what was it you just didn't even know that was the well-known udp port oh yeah this i think it was there in the past and we removed it because no one cares so we decided to not i mean to let this go through configuration and that would be it anyway okay and also it does not make too much sense because you are going to you know open multiple ports on the collection side maybe on on the same machine but on different ports to do some load sharing exterior so you're going to end up configuring it and changing this anyway so having a single default value does not make too much sense when we look at the big picture of the deployment so in my opinion it's not really needed and no one was carrying so i think we removed it okay okay thank you uh we need to we're just"
  },
  {
    "startTime": "00:24:01",
    "text": "a little bit over we should move on to the next presentation all right okay and [Music] excellent i saw kefang yes okay so on behalf of the authors uh i'm here to present the adaptive subscription to young notification draft i believe that this work has already been presented for several times an adaptive subscription can fit in the scenario with massive debt collection and processing with expensive data management cost usually the higher frequency debt collection leads to more resource consumption while low frequency data collection may lead to insufficient data for photo localization there is an example given in the draft in a wireless network performance monitoring case when the signal stress falls below or configure the threshold the notification can be streamed at a higher rate for trap shooting via the when the signal strength crosses that threshold the notification can be streamed at a lower rate so our proposal is to enable the client to configure an adaptive subscription of that policy which contains a condition and allows the server to switch to different period intervals based on the condition and the condition is expressed using a standard expat evaluation criteria but in last itf meeting there is one"
  },
  {
    "startTime": "00:26:02",
    "text": "issue i i think is read it was read by rob which is about the arbitrary x-path complexity since the condition expression requires x-path evaluation this mind complexity yes but we all know that young push also needs to configure selection filter to identify a targeted node or subtree and it's it is a similar selection filter used by adaptive subscription and a new section was added in the update to discuss arbitrary expat complexity and and there are four points given as a reminder that although they have already been well supported by expats to serve the following design choices should be very careful to make and they may add extra complexity for implementation first is to support x-path evaluation criteria against every data that objects and the second is to support any data and any type of node set in the expat evaluation criteria the third is to support both objects to be compared in the x-pass evaluation criteria and note sets and the last one is both objects to be compared are in different data types and then also to try to reduce the complexities of this arbitrary express evaluation we give the following design principles recommendation first expat evaluation criteria against minimum set of debt objects in the data model and these minimum set of dead objects could be advertised using the"
  },
  {
    "startTime": "00:28:01",
    "text": "notification capability model defined in ongoing work and second it should be integer best filter which represents signed and unsigned integers of different sizes and last one is about compared objects requirements we recommend that it should be an one-to-one numeric comparison if an object to be compared in the expat expression should be a leaf data node and the other object to be compared is expected to be an integer so under the result of the x path expression is converted to a boring value yeah so i i think this is the end of my presentation so let me just stop here and see if there's any other comments and questions about this yeah rob please go ahead uh thank you could you um go back a slide please so so thank you i saw that you'd sent me a summary of the text that you proposed on changing this and i i think that that's on the right tracks i had intended to send some comments back today i've run out of time um i think that the description about why it's complex i think that can be probably condensed down but in terms of your solution i think that seems reasonable as in i quite like the idea of being able to advertise the set of objects you're allowed to perform this on um through the capabilities draft i think restricting uh it to like interject integer based filtering and simplified uh comparison again i think that makes sense i don't i don't object to allowing implementations to support a more complex filter i think the key for me is that it would be good um if at least every implementation had to at least support these basic filters because those"
  },
  {
    "startTime": "00:30:00",
    "text": "my concern is about running a generic xpath evaluation engine repeatedly that may be too expensive so so i think that that makes sense and then one other thing i would add is that it would be useful to have a well-defined error code or error to be returned on if you do allow more complex um uh queries so they have an error code to say uh when it's when the comparison put in to say no this is too complex i can't handle this yeah okay thank you yeah i think it makes sense yes okay all right i was on the other uh window typing notes and so the the concern for arbitrary complexity and xpath may also be appearing in the list pagination work that's going to be presented later in this session and there there's a concern for you know if you have these arbitrary expressions and you're mapping to a backend database uh how can you do that for you know some databases aren't that rich in their query language syntax and so uh i think it's one thing to say there needs to be a minimum set and then may there may be more complexity but how does the client know what extra complexity is supported by the server and so then we may need to have uh some ability to enumerate or or somehow otherwise enable the server to advertise what all the extra uh expressions that they're supporting and so i see that desire may be showing up here in this work and also in the list pagination work yeah okay thank you"
  },
  {
    "startTime": "00:32:03",
    "text": "i guess we can move to the next deck yeah i think so and also uh while we're moving to the next deck uh in yon europe uh the previous presentation on the udp native alex was that you speaking or was it pierre speaking it was alex speaking during the draft and then i answered and it was answering the questions after okay great thank you go ahead jan thank you so this is the second presentation of this netcom transaction id work that started a year ago and basically it's about the mechanism that reduces traffic and work and decreases reliability when it comes to getting and editing configuration on the server so i presented the initial work at itf 109 a year ago and since then i've made some investigations of how much impact this would have in the sort of real world network and we've made some changes going from double o to zero one and uh just to recapitulate very quickly uh i took a real world application but running in the lab so it was not actually a real world in the true sense of an operator running something but it was running in a lab and it's a real world application and analyze the traffic in that situation with this application running and one um i browse eyebrow razer that a lot of people reacted to was that 91 percent of the traffic was actually in young 1-0 hello messages um so that's something for for implementers to watch out for to"
  },
  {
    "startTime": "00:34:01",
    "text": "move to yang 1.1 to get rid of that but simulating or calculating what sort of savings would have with this draft uh i could see that we went we would go down from 569 to 378 round trips for this particular application running for three hours and almost half the amount of configuration data being exchanged uh so i think there is some value to this but actually the real value that i see in this work is not so much to reduce strong trips or number of bytes being sent between client and server but it is the reliability that a set of clients can work reliably towards a set of servers and not clobber each other so that's really the the main point here and the reduced traffic is a kind of nice bonus so what i did from double o to zero one uh okay i clarified things based on feedback on the list i separated out the e-tag specifics into so it's very clearly in some parts and non-e tag the general mechanism is described in separate parts i changed a few names based on feedback from from the list there was a slight harmonization between the mechanisms that we had with names of transaction ids with rfc 7232 and 8040 there was almost the same before but now it's it's more exactly the same there was a lot of discussion between when it comes to who should set transaction ids should transaction ids be set by the server or could they also be set by the client and since there was so much controversy about that i completely removed the option for clients to set it i still think that's a good idea and i'll make a case for that in a few minutes uh because i removed that i had to add some other i had to adjust the mechanism a little bit so that's transaction that this could be returned"
  },
  {
    "startTime": "00:36:00",
    "text": "in a different way so moving on here this point okay i'm gonna try to text him okay so i think he's going to try to adjust and come back can you hear me now yes okay i don't know what happened there and i just closed and opened the mic again so how far did you hear uh i think you just started on this particular slide all right very good thanks so uh here are the open questions and i'll quickly go through each one of them and explain uh what we have chosen to imp to write in the draft these are all the alternatives that were raised on the list so for the e-tags we have now adjusted the e-tag assignments the transaction id values to match exactly what it says in in rest cons and 72-32 it was almost the same before but now it's more exactly but other alternatives"
  },
  {
    "startTime": "00:38:00",
    "text": "were also suggested but that's what the draft says now and there's no particular text in the draft when it comes to how you format these strings it's left as a sort of open-ended string there are some rules as according to 8040. there is no support for time stamps that's a mechanism that exists in red just confident have transaction ids there you can use timestamps but for a number of reasons uh that i will not go into today i i skip that and only this transaction ie tag style transaction ids are supported in this draft uh we have this question that i mentioned earlier that's is it allowed for a client to say i want you to use this particular transaction id when it sends in an edit config to a server and right now there's no text about that at all in this draft but i'll come back to that in a minute and explain why i think that's a good idea similarly there's uh some people ask that maybe even if we don't assign e-tags this way maybe we could allow clients to send in a free-form string to associate with each transaction because then you can send in things like who was doing this why it was done which custom it belongs to internal order numbers and whatnot if you have if you can put comments on there so you can use the transaction you can add transaction metadata basically but right now there's not no such language in the draft at all and then we have a question about granularity so when you maintain this transaction id for for data storage do you do that only for the data store as a whole or can the server implementers pick some more containers and list elements around in the data model where they think it makes sense and maintain transaction dates for them as well or could server implementers pick any"
  },
  {
    "startTime": "00:40:01",
    "text": "element not just containers and list elements but sort of every any leaf they like and whatever they think makes sense at all or even should it be the clients that decides which elements that we maintain transaction ids for dynamically in runtime right now the the draft explains how this is done when it comes to the data stores and some containers and list elements as picked by the server implementer some other open questions where we could think about new development is to indicate which elements in this in the yang model that have transaction ids associated with them by using system capabilities as we just talked about in the previous presentation here there's of course a lot of config false data being requested by clients as well and by using transaction id sim type of metadata you could actually probably reduce the amount of data being transported for conflict false data as well quite dramatically or maybe with similar numbers as you saw in the in the beginning here but that is not included at this time and we could possibly eliminate some use cases where you use locking if you add e-tags for commit and a few other operations as well so that could be an interesting development but it's not in there right now and let me just use the last two minutes to try to explain the case for why it might make sense to let clients assign the transaction ids when they're sending edit confidence so here on the left you see a client that's sending an edit config with some blah blah blah going over to the server and the server then returns if it's using this transaction id thing it's returning okay and also adding a sort of transaction id said yeah i know and we call all these things that change now ab5636 and so on"
  },
  {
    "startTime": "00:42:02",
    "text": "and the only difference uh if the client assigns the transaction id is that you add one more element in the edit config optionally for the client yeah i want to call this thing 47 390 and then the server returns 47 390 at the end so it's very easy to implement this otherwise the server would have to come up with this sort of random value now it doesn't even have to use the random function anymore because it just gets disserved from the client i want you to call this this and that's what it gets back so it's very easy to implement and i claim that this allowing the client to send this value is a high value thing because if here on the left if you don't allow the client to do that it computes a transaction sends a few edit configs to the number of servers and they respond in their time and the server the client has to wait for the slowest of them to respond before it knows the transaction id and can update this database with what's happened then it can start computing the next transaction sending out a few more edit configs wait for all of the responses to update the database and so on so keep track of what's going on whereas on the right side here if you uh you compute the current control transaction and it sends out this edit configs it already specifies which transaction ids things should have so the database it has locally here is already up to date with what's going on and then the service can respond in their time and we are already on to the next thing and computers it increases the performance quite a bit and of course this this would be an optional feature so i don't think all servers or so all clients and servers would have to implement this but for those that participate in high performance scenarios this could be interesting and i think i'm just on time going to the last slide which is saying are we happy with these open questions following the way"
  },
  {
    "startTime": "00:44:01",
    "text": "more discussion on the list or maybe even an interim thank you um so this is kent uh chair i i think uh you had some open issues and there's no time for discussion i know we're on a tight schedule here with the uh interims i do think we should take items to the list so for each of your open issues please start a thread a separate thread and those can be discussed there thank you okay so actually i'm going to forego my q and let me go ahead so i'll be quick canon and so basically i really support engine id being suited by the client or at least having a way to to label transaction because if we put in there the service request id coming from the orchestrator and it has great value in case we could uh we have multiple client configuring a server and we do we could do a look up there see exactly what was changed for in time so i'll expand on the list because it was a long time thanks man all right since we are on the we left with only 15 minutes maybe we should move to the next deck and chin yeah while we're bringing that up uh i guess jen's presenting and then while i do also i think there's value there we just need to discuss the best way to introduce it hello can you hear me yeah go ahead jen see your slides in here go ahead yeah uh hello everyone my name is ching so i'm here to present the list of designation mechanisms for nanocomp and rest conf we have three dropped and the name we here are also we"
  },
  {
    "startTime": "00:46:00",
    "text": "actually set up design team for this next oh oh sorry i i forgot yeah yeah let's yeah just recap a little bit uh motivation so why we want to do this actually uh actually when you retrieve 90 number the entry from list and leave list actually you may actually uh don't have a very user-friendly client interface actually for a client that may take quite a long time to retrieve these lists so we'll introduce quite a lot of latency and also economy consume a lot of resources so our idea is to try to leverage the server-side processing combined with some back-end storage system and for example index mechanism allow you to allocate the data without need to uh search all the row in the database table so we tried to borrow this concept and and use in this list and leave list retriever so this job has already been presented in iet 109 and we got quite a lot of discussion on rescon for connection problem this actually we have a job that we call the resconf connection which get expired so we actually use these as basis to come up with this idea yeah and so before we uh discuss this pagination we actually have three key uh acronyms first is pagination really it is a standard mechanism to control the filtering sorting retrieve the entry and of less than a lift list and also we have two uh acronym we call"
  },
  {
    "startTime": "00:48:00",
    "text": "the list pagination net conf and this page nation for rescon which focuses on product extension to support this pagination and so what do we do actually since iet109 actually we up one of the this pagination draft from the other two one is focused on nanocock the other focus on redskonf and we rename the cong and escape parameter into the limit and offset because we borrow the concept of secure language from the backhand database so they use nimit and offset and that's why we switch to these two terminology and we also define uh you know uh for list pagination define the five query parameter which will be discussed in detail in the later slides and also for decision list pagination we also introduce one query parameter we call the sublist limit and also we actually extend the server capability extension and to actually define the per node tags and in addition we actually uh in appendix we uh define uh the example young data model dataset and query which will be reused by the nanocon draft and the restaurant job and so the other two dropped the first net conf and we already um you know posed this chart and we made it up data so uh the main change actually is we change a new rpc to uh augmenting uh three out net rpc one is net conf and also we have get config and uh get and get config and get data the second change we actually try to reuse the grouping defined in this pagination job and"
  },
  {
    "startTime": "00:50:02",
    "text": "in in this netcod job and also we actually provide the example to show how how it works and for rest confer and we actually update the rfc 8040 and align query parameter for rest confirm and we also uh declare list and leave list as a valid resource target forget and optionally we can support delete operation based the discussion with design team member and we think for young model we we don't think it is value we don't see any parameter is really needed in this model so we remove this yar model for this pagination rascal and so let's uh drill down a little bit into this this pagination draft and we actually defined uh uh actually uh several uh query parameter the first is where and the second is sold by and where actually actually ken already mentioned we do support this kind of filter expression and uh we provide example for this and for sold by very similar to the order by actually the by default if sort of is not set actually will you know fall back to the uh order by and direction we support the forward and backward direction of the results to be returned and also key parameter is offset and limit and which actually apply to the list and leave list and it could be returned the number of entry to be skipped or the number of entry to be returned and we also uh sample is the limit parameter which only apply to the dissident list and leave list and we also set the processing order the first high priority order is where and then"
  },
  {
    "startTime": "00:52:02",
    "text": "it's sold by interaction offset and limit and uh in this chapter we also introduce a metadata attribute we'll call the remaining and remaining parameter can use together with a limit query or separate list limit query and it can be used to return the number of entry not included due to the limit or sub limit sublist limit operation and here is we show the example how these uh combination six query parameters can be used in the request and response message to guide the whole list and leave list should be returned so you can see this example and we actually use the where sort by and direction and offset and limit another example has already documented in appendix so 3.7 and even in time limit i will skip this and you know in addition we introduce another example to uh to to to discuss how remaining is used in uh in the requested response actually these remaining actually uh can be applied to the dissident list and levelist so we gave two examples the difference is that the target node is different one is just applied to the one data node we call the member who name is alice the second the target node actually is a data store it is a intended data store so response will be different actually we provide the data set and you you can use these remaining to get a different result and so we also introduced a serverless pagination capability"
  },
  {
    "startTime": "00:54:01",
    "text": "discovery this is really actually built on top of the server capability draft actually we augment from system capability with a two key parameters we call the constraint parameter the first one indicates which config force list or leaflet node are concentrated it will apply to the parent node and the second is indexed you know this actually applies to the child node child node actually which will show actually which node may be used in a where and sort by expression and we also allow some future extension uh here we give the example you may not support 100 x pass 1.0 for example you support some of the expanse function for some other experts for you don't support so we can allow such an extension because for back-end uh database system they may have different capabilities so we should allow such a very variety difference and the second is the net conf draft and the the you can see the overview this model structure actually we augment the three netcom rpc statement get get config get data so you can see the parameter uh you know uh actually align with the list pagination shaft and on the same query parameter and also the same the type data type uh i applied to different uh rpc statements and then we also gave an example to show how this parameter can be used in the request and response message pair and the second one is rescon for draft for restconf actually we really actually"
  },
  {
    "startTime": "00:56:02",
    "text": "try to update rfc 8040. the first product chain will introduce we add a list and leave list as a valid resource target for the get and delete operation and we also try to apply it to the related http method for the get and ahead and second actually we add a new media type application young data xml list and for application young data json actually we try to reuse uh the one defined in obviously uh 80 40 we don't need to you know reven reinvent the wheels the third product extension we introduce is we add a six new query parameter and uh we also you know give example how uh this uh can be applied to the delete operation for the list so this uh example already documented in the appendix 3.2 so we we do have two open issue we like to solicit some feedback the first one is about cursor support actually we uh our pagination id actually uh the key parameter is offset and limit actually we usually would call it as offset based pagination but in some cases you you may need to consider whether we need to support cursor-based pagination so what is the pace uh cursor-based pagination so it really enables the paging to continue over the snapshot despite the dataset changing for example you add one more entry or you may delete one more entry for the client actually you may don't know whether the list gets changed so you can assume that the client uh you know uh so the client actually make assumption actually that this doesn't make a change"
  },
  {
    "startTime": "00:58:02",
    "text": "if without uh cursor support actually in some cases so we may have some you know uh corner case it may re return the larger remaining value than the previous fetch so one example you may refashion the paging in a time series log the log can be you know grow too large actually uh can be append at the end and so this will face these kind of cases and so for config actually actually many systems have a internal radar writer uh mixer exclusive actually so the cursor in based on our design design team discussion seems maybe not needed so we also have some mechanism to try to address this for example we have an entity tag timestamp this can be used to detect the dynamic disk change now also we have some error code messaging this error code message can be used to indicate the end of the list so we think uh we seem similar we think we lack a companion use case for this if someone have some concrete use cases please let us know and we will see how to support this cursor in the list pagination job and the second one is about the remaining an annotation so uh the remaining is used to return the number of the elements not including the result set actually the kernel draft uh states that if no elements were removed this annotation must not appear but it uses the minimum value 0 to represent the arnold actually based on discussion some of"
  },
  {
    "startTime": "01:00:00",
    "text": "one of the proposal is whether we can use zero to represent normal entry but for unknown maybe means not return the remaining annotation so for this we haven't reached agreement among the design team member so we like to hear your comments on this so that's it jim we are actually completely out of time so now you might want to take both these open issues to the mailing list add to okay in discussion there okay just want to quickly mention we have invitation one from ken the other from off yeah thank you okay yeah please take it to the list and thanks everyone for attending the meeting see you on the mail and thank you"
  },
  {
    "startTime": "01:02:05",
    "text": "i'm sorry i'm not sure if i was on meet or not i was saying all the authors could please take their open issues to the list and uh and then for everyone uh thank you for the discussion and we'll continue the discussion on the list uh please have a good rest of the day bye"
  }
]
