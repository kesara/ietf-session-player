[
  {
    "startTime": "00:00:04",
    "text": "this region diversity the three together this is not reasonable this is not really would that leave it to you to yeah look at verse 17 you tell people if they should finish short [Music] [Applause] we have less people in the room than per century that\u0027s the bet I so far Association she should be coming no I think we\u0027re fine you go back to the finally told she would come right family I so found me I so funny and I think she will come this is going to be well it\u0027s information just do nothing yes well is "
  },
  {
    "startTime": "00:03:07",
    "text": "that that was this very man so I\u0027m gonna go I suppose you\u0027re pretty soon will be available after the session so we can just grab some food and continue discussing here just with the boy was it some was it was about when do they stop physician recording yeah I mean cuz guess are scary literally okay so people welcome to this audio session so the the working group chairs are not here to to chair the session so Barry and myself will do this on behalf of the chairs so we already identified note takers for this session who will be which will be Richard and Chi thank you rich other than Chi so yeah okay so please take a look at the note well slides okay so as for the status of the working group the focus is currently on finishing on "
  },
  {
    "startTime": "00:06:09",
    "text": "finishing the Charter items and the working group items so the agenda has been set up accordingly with a priority on working group items so the goal is to finish this milestone as soon as possible the problem is that the author the author\u0027s relaxed in finalizing their documents for example the SSC Draft so as a solution that shares will divide the remaining drafts between them and follow up with authors and editors to close them out by the next IETF in Vancouver so the agenda is as follows reflecting the priorities we will have three present a full presentation relating to working group items so performance metrics unified properties path vector footprint and capabilities and we will also have two presentation on personal exploration work for future outer use case is done by Luis to determine service edge and to extend out or by using bgp communities so as for the working group progress since the last meeting in Montreal so we have two working group items that are well progressing and the SSC Draft is basically done the second working group last call is over and all older working group items are very close to being finalized so in more detail so the cross domain server discovery is now in the RFC editor view the cost calendar is in iesg processing as for the SSC there was an old working group last call data has expired so another one has been issued like a week ago and it will expire on December 8th and so we look right now for two volunteers to read the draft I believe we had already identified some during the last meeting so please send us a notice or if you are in the room and volunteer to review it please let us know the CD ni f CI without so so a new version has been published it\u0027s ready but really needs feedback from the CDN I working group so a message was sent out to the CDN I working group to review that document in that perspective with a tentative deadline for December 15th and "
  },
  {
    "startTime": "00:09:09",
    "text": "Jensen will present it today performance metric a new version was published and Richard well presented today as well and we\u0027ll see if it\u0027s ready for working with Pascal unified property and Perfector they asked they progress as a bundle so new version have been published as well Kai will present path vector and will present a unified properties and we\u0027ll see how far it is from working group last call and last but not least we had yesterday morning a side meeting on application and network integration who was organized in two sessions first session with presentation and the other one with discussion so the purpose was to study how application and network can integrate to perform and perform gap analysis what is missing on either side and how this can help defining some work for alto but also be out beyond Auto so there an agenda was as follows so we had for presentation one by ten cent on network away five five g-cloud interactive service another one by a telefónica on integration of telefónica CDN with the transport network another one by way which was about application-aware networking whereas Auto is more our network aware applications and finally we had a presentation by Richard on application and network integration possibility challenges and the next steps so the slides and the minutes have been posted on the mailing list and we hope a second side meeting will happen in during the Vancouver IETF so last is there any other business that you would like to discuss during this session so yes remember the intent is to wrap up all existing work items by Vancouver meaning by Vancouver working group last call is over so at least so I\u0027ll hand now to the first presentation which is Richard and yeah and Richard you have 15 minutes Oh minutes I will say thank you so oh "
  },
  {
    "startTime": "00:12:14",
    "text": "okay so I\u0027ll talk about the updates on the alto problem magic document and this is one documented way which we got a lot of feedback and which I think we are wrapping up I think we made pretty good progress and hopefully by this time and we\u0027ll get the feedback from a working group and then we can really wrap up so and that\u0027s oh I think we\u0027re missing the top so basically and here is the issue I won\u0027t talk about and essentially presentation board consists of you know how to fix it great thank you so basically I\u0027ll first talk about updates and what we deep from version six seven a syndromes from seven to eight I never talk about the single remaining issue which I think we know how to resolve what would you want a cocktail working group I now talk about plan for next step okay and so let me first talk about the changes that we made from version seven to version eight essentially between these two IPs and really for people rhetoric of what exactly why we\u0027re making the changes is remember this is very interesting conversation during ITF last time and essentially is that time limited decision point was do we want to have the phylum LuPone metrics to be consistent of your based on only existing metrics based on impurity I ppm so we have feedback and people from a ppm they can you and give a very increase or pinyons and so on and just to refresh your memory or later bit and on your life and inside is the outer performs matrix example in latency RTP and so on so essentially we have all matrix over there about also matrix and right-hand side would be all the metrics defined by I ppm so therefore is quite a details for example round-trip delay active IP UDP and purity depending which are seeing which section and so on it was quoting the intensive discussion about this topic and I think eventually it was made quite clear of course you post you in the session and right session and the session was the feedback was clarified that also really metrics are really guidance they are really not exactly what Apple for micros really we did and so on so you\u0027re really focusing on that what really central providing only guidance only so therefore that will solve a lot of these major issues so what we do and essentially what we did is very simple and what we did was to remand Cora fire that really the automatic will be just guidance but then of course that\u0027s really even less kind of a principle which we took very seriously but now the issue is there can be multiple types of a guidance even for the same metric for example a macro could be delay I know for example here four people can really maybe it had to "
  },
  {
    "startTime": "00:15:14",
    "text": "it\u0027s a small funds and they are from Sprint and for example a guidance could be service level agreement fuck is I\u0027m over here offering all sub level agreement and you can issue for example month s mission and so on oftentimes you don\u0027t update very frequently Abdi for example as much high chronology then I ppm would do but we should have muscle types for example service level agreement and worse estimation so how do we solve this issue over there so you eventually let the session turns out to be very simple and the way to really solve is to allow multiple types of guidance and you specify what type of guidance you are really providing you\u0027re not respecting the details I ppm but you especially about that you\u0027re providing a guidance and what a type of guidance this for example what people can read the tiny funds to allow so here\u0027s a new tax and that was the version 7 and it\u0027s version 8 and to allow to find green to avoid finding green and information and document introduced cost source to indicate the high level types of guidance which Otto would provide so that\u0027s essentially they are solutions so therefore we usually introduce these field and call the call stars way that\u0027s what we just saw is prime so therefore let me go clean is a guidance it\u0027s now other teachers and so on and then after this one not turns elapse to be a little bit easy and next step when you do is we really define the details remember ITF you can base bias optional and all these requirements and so therefore what we said was and therefore the cost type which is a data type system in our code and we include use an optional optional extension field called a cause source over there so basically document you find this one as a source and essential here to define optional field over there I know what happens is a core source should be registered to a long extension so that\u0027s the second requirement as the essential second in the index introduced optional field and making it fun to be waste like I wish I am a red kitchen right now I was a summation and one is SL a so therefore now we can really solve prom with this one and now turns a lot life could be easy so therefore next change we made it was also pretty simple straightforward now and because we have all examples and the so now what really they are are the I ppm guidance and here I guess I think really make a clear is and we basically said will be put in essentially we have of the COS source but we make estimation as a default value for example we did not even modify all the examples we just say okay for all examples and because there\u0027s no optional car source extend an extension field and therefore the cost is really is an extension so therefore we just add a comment so every single example we said we could remember cost type that\u0027s not included the record source field so "
  },
  {
    "startTime": "00:18:14",
    "text": "therefore the value essentially should be interpreted as the estimation to solve this issue okay and given this one now really given that we no longer dependent on IP p.m. we also made a second change which I think I should also clarify is we no longer with all these when based on IP PM I now we introduced much much simpler representation of alcohol cost backers for example here and we go see for example we metric type value it\u0027s a single Jason number and 59 section 6 and negative therefore become much simpler we don\u0027t know no really need to really tie up with IPP yet we can move on independently and same for other metrics defining online and document so that\u0027s what we\u0027d be okay the only potential complexity introduced by introducing the cost source optional field is backward compatibility so and here is issue which we described in the document potential usually introduced file an optional course view the is backward compatibility consider a an information resource directory and that you find to cast hype and with the same cost mode and cosmetic a one-way source of being as mention the other one being SLA but if you\u0027re really backward is that like old alkyl client and you wouldn\u0027t know which one yes it\u0027s really a submission or you really is SOA because it\u0027s optional field we don\u0027t understand just the other definition so you can just skip and this particular optional field Nadi and that\u0027s potentially can be any issue and now our solution the only define metric in our system if I which is the standard based out of protocol the only metric defendant was cutting cost and we make it a centrist that it would be this one can only be estimation so therefore if you use a new custom metric and for the Newcastle metric and you otherwise your every see just fine so I think that\u0027s the only issue we try to solve and now let me talk about the only remaining issue here the only remaining issue here turns out be very simple is this a moment we have defined to cost source types and the one is SOA one is estimation which was mentioned last time doing the idea 105 a meeting was maybe we should really have third type which called a nominal type for example what\u0027s normal type for example here use normal type means for example for been aware for example PC means that\u0027s really my link capacity and according to my Dingle a bow is hanging so the points got a normal value or nominal value and therefore it\u0027s all estimation it\u0027s not really estimation the card "
  },
  {
    "startTime": "00:21:15",
    "text": "everything from SEO is good enough and good enough we do not really define nominal but there\u0027s some other key discussion maybe if it really introduced nominal essential is a very very simple change we add a wine and most people essentially for example in capacity you probably the most irrelevant you find a central a fixed value and what so that\u0027s what you capacity so that\u0027s the only remaining issue which we won\u0027t get people\u0027s opinions if any so here for the next step and turns out to be pretty simple a number one is for feedback on the remaining item I know will really talk to some people from I ppm I know what we do is we\u0027re gonna some in update and if any if for example we example at the nominal cost source type and then we do everything by a mid-december and then we probably can go down a final version and people can kill last comments and we then we wrap up this document so that\u0027s pretty much what I have and any comments suggestions and Chinua we wanna know cars are thank you thank you Richard to take care of these work actually one of comments for this is you mention one type where you introduce this estimation and I want to make sure it is affordable haver because in some example you you actually make comments actually you think if or doesn\u0027t include a Costas also that indicated is estimation does it mean actually this estimation hyper is kind of default type it is so by default I think for example and yes so other server basically is an optional field if you don\u0027t indicate it and the default value is yes so the application muscle value of course is solution if you skip it okay thank you so know for we do have this people are bad yes you\u0027re right any comments and any other opinions for example should we do for example the nominal type or maybe read as well as and estimation be good enough opinions or no opinions thank you so for La Mina type an interpreter as actually kind of average or mean is I think that\u0027s why the complete let\u0027s really make guarantee right as typically you see all the websites they really announce SLA I think forget for the example we talked to several people is it typical that\u0027s really a so it\u0027s best one because I\u0027ll tell you as necessary and as summation I think from let me show over here promise that\u0027s good example for example so typical visit and your publisher for this information may be hard to use you can essentially they are really like say I need to pass all the websites you don\u0027t have dates and so on and estimation program I think this is the "
  },
  {
    "startTime": "00:24:16",
    "text": "mission they opted everyone Mouse or every once in a while we don\u0027t want to update every get a continue to really like it as a mission I nominal what do we want said we want to say is essentially it\u0027s a value of which for example traditional like a normal value which is expected to be 10 gig but because that\u0027s really more value about if it really not right and something you should really take here because we\u0027re Suze Orman guidance and there\u0027s no guarantee about that but as a crowd okay thank you for everything yeah so actually the nominal value seems to be more useful than the estimate to me but anyway and it\u0027s a mega 10 gig and you might me or me all around 10 gig I\u0027m a normal matter think that\u0027s why she was a normal what makes a lot of sense yeah in the contacts and I actually would take that one as the for to be honest okay okay what my actually point was like we came the discussion we had last time was because there was like some use case where people actually want to use this information on a very small time scale and then like it would it be important to actually understand how it was measured and what the time scale is for the measurement and so on and that has like a lot of problems and like when I\u0027m looking at this light right now I also doesn\u0027t seem to be in the intention here so this draft say anything about this about times typical SLE is not really as submitted as SLE you wouldn\u0027t give you the okay I think maybe I think maybe your question could be learn to perform Union let me clarify we\u0027re trying you\u0027re met for the estimation is always summation yeah Jennifer\u0027s clarify cell we would have over there for exam I say basically typical means how long is SOS ballot for one mouth one day for one year and so on second whereas I also mean for example typically a you really have some kind of definition and say for example you say and it\u0027s really married in this way contract right so the way we want to do is the following is we own is estimation and remember is in the cause a type system we have a cost mode and the cost metric and it cost source we also have description I would suggest in this moment is in Makati description which often or fuel you give a link to describe we are this value for this festival and people can retrieve it but we don\u0027t want to define go to details or for example you find figures as we defined for Mary every five minutes seconds everything millisecond and so on we don\u0027t want to go down that path we won\u0027t give it like a coarse-grained high level to use essential guidance that\u0027s lovely session okay with you or maybe that\u0027s this make sense but like it what\u0027s your expectation what the timeframe people will use here I think typically or number one course is for example estimation we probably expect people to examine other up days mom says that typically like people ugly their wife said proudly up days like a day is mouse is I think oftentimes a tip is like a master every value for example and there are not redefine degree of "
  },
  {
    "startTime": "00:27:17",
    "text": "course much longer often time they publish it a long time so that means definitely per like whatever connection requests or whatever it should be stable right I think that\u0027s a good recommendation to actually write down in the draft sure so we probably kind of essentially you know operational consideration part we protocol a little bit of a quarter depends on the contact well we recommend probably there should be those relatives stationed around values thanks varies hi this is a loose run telefónica a when you have mentioned the nominal the nominal value you have referred to the bank with which is clearly let\u0027s say an absolute value but I was wondering if for other cases that could be the delay for instance we could manage percentiles or I mean not absolute values but 95 95 percent of the time this is to my question is if this also could be consider as nominal value or would be [Music] yeah I think that\u0027s a complex of using introduce a nominal value what exactly it is and and which was normal which was abnormal and you\u0027re right so 95 person hell I up front I don\u0027t know how to specify and yet I would introduce the complex a over basing the complex that we don\u0027t really get into is all these I ppm complexes so complex multiplication don\u0027t need this happen information at all and but the short answer is I think about that maybe I tricked you some comments and you actually probably it\u0027s a moment I think for me if we can give a summation and we can give for example some folk band amazing game normally Allah was you don\u0027t help you find this moment we probably okay with essentially the only panel is phenomenal value is valid and what the label product and d4 to a future document we can try to extend more fine-grain divers like a richer matrix but for later document okay thank you okay okay great any more question so sorry okay so we\u0027ll switch to the the next presentation his own unified properties will be done by myself so this draft has been around for a while and so the the current update is not about the design I\u0027m sorry I try to does it work No okay so at the last IETF the conclusion about this draft was that it was very complicated and the introduction of the features of unified property were so "
  },
  {
    "startTime": "00:30:18",
    "text": "complex and hard to understand and so this is actually not the case as long as it is clearly explained and introduced so the major changes in the present version are on simplification and clarification on how to introduce the new concept so the major changes are on section 1 2 3 and of course we started looking at some type of but that\u0027s that was not the hardest part so in the meantime the draft grew even fatter but we are now working how to make it simple and concise so there is no change in the design as I said but there is a very strong need to simplify the text so we opted for a didactic approach and progressively introduced a concept in with a progressive complexity and of course we did need to do that for the rest of the document and that requires substantial revisions so as a digest the introduction has been made non-technical we removed every text any text that was like specifying already things there\u0027s we added a we the second section is now about the basic features of the new United property extension as they were defined in the first version of the document in the third section is about advanced features for unified property so this section explains limitations in some cases of using the basic features it also explains the risk of an ambiguous client requests and how to solve it and this ambiguity issue was around for like more than a year and caused some head scratching so and you finally found a design that solves it this is now the new talk for the three first sections so in Section two as you will see we introduced basic features what is an entity generalizes endpoints examples what is an entity domain defined as a set of entity of the same type which is also defining the type of the entity domain it also defines an entity ID format and we give examples section 2.4 entity property that can be network aware like an AAS number or network agnostic like a geographical region and 2.5 new information resource because that\u0027s one of the key points of the draftees we introduce a new media type "
  },
  {
    "startTime": "00:33:21",
    "text": "and a new resource which is called Alto property map that you can get half via get Mart of your post lot section 3 and introduces advanced yupi extension features so we have section 13.1 that establish the relation between what an entity identifier and an entity domain with some rules and especially a rule saying that the entity is not the entity points to a physical or logical object but you can have two different entities that point to the same physical and logical object because auto is like it\u0027s a map so the object in an auto map is a identify so you have one endpoint that has a AP v4 address and an ipv6 address you have two entities because different applications use different address formats and so you need those two entities so 3.2 defines resource specific entity domain name why do we need that because the PID for example the entity in which an entity which is a PID domain has any identifier like okay here so that you can use the same identifier in different network maps so if you only use this identifier for a PID you cannot distinguish in which information resource in which property map it is defined so this is why we compose the entity domain name with the resource where it has been defined for example here you you you want to define an entity domain PID so and if you want to distinguish between PID number 10 define in two different network maps you need to compose your entity domain with the resource idea so here if you use this and this you can distinguish between the two entities which otherwise you cannot section 3.3 does well similarly the same we have the similar issue for entity properties same if a "
  },
  {
    "startTime": "00:36:22",
    "text": "property is defined relatively to an information resource the property value can change depending on this information resource so if you and if you require if you query a property for an entity for example defining the ipv4 entity domain this this end point can have two PID properties in two different Network Maps two different Network Maps use this end point and define a PID property so if you want to query the value of the PID property for this ipv4 entity you need to specify in which network map you want it so the resource here is impacting the property value so and in the text you can look up the text and the text explains how to how to do this no comments on section for that 3.4 sorry 3.5 will be in the next slide and 3.6 is the okay yeah that idea that this section 3.6 needs clarification we are not done yet with the clarification it\u0027s about INR registration and so there is a discussion regarding mapping definitions section 3.5 so this actually solves that ambiguity issue we had the use case like more than one year ago on the FCI map capability use case so in the initial design there was one member on the capability you had one member that was defining which entity domain types you can query and the other main member was listing what properties you can query on that on these entity domains and the problems is that well it up actually you can you cannot query PID on every of those entities PID does not exist on country code it does not exist on a SN how does the client figure out so the solution is now to introduce a new member in the capability and this member for each of the listed entity domain types gives you the list of property that you can query on this entity domain type and it specifies it results depend whether it\u0027s resource dependent or or not so here with this design okay you can end up with very "
  },
  {
    "startTime": "00:39:22",
    "text": "long names but these solves the problem in a clean way so and of course we really need to simplify the text but basically it appears to be very pretty clearly defined now so there is another work we studied on illustrative sections as some sections do not provide any protocol specification I meant to explain the design and but they introduced complexity and notions that are otherwise not useful to the implementers given that arif sees meant for implementers so we also want to clarify this so the next steps will be to fix typos and errors that I detected right after sending the the new version continue the clarification and cleanup and this will be required substantial work we also need to make a last check on the IANA section regarding how we define mappings and many things that have been that have been added in this section and once we are done we will propose it for working group Lascaux so we really hope to be done well III don\u0027t dare to promise a date but hopefully in January or February latest any questions I usually am premier so when you say you want to I\u0027m trying to entice again it says I think you give a comment that the current this document is getting very long right I don\u0027t know 50 pages or some page yes it\u0027s getting very long I\u0027m the one reason I think that God pretty law was being caused a lot of examples yes and so when you say you want to clean up do you mean to really clarify remote examples or I\u0027m just want to get a little bit sense about what you\u0027re really meant to really for example I think clarification of course because always sense but when you see coming up what does which direction potentially might be really pursuing definitely as far as examples are concerned I rather tend to be willing to add examples we need to add examples own abstracted Network elements we need to add examples on FCI capabilities because they were the ones who caused actually who who helped us identifying the ambiguity issue and led us to design this resource dependency and more thinking about the text where just the wording that can be really simplified and so I think if there is no "
  },
  {
    "startTime": "00:42:29",
    "text": "question we can move to the next presentation which is by kite thank you name wrong so I\u0027m time here to talk about the auto past Baxter extension so for those who are familiar and not familiar ways past brand extension I like to give a quick summary of the current status of the drafts first what is the motivation behind this draft it wants to provide a what kind of new features it provides so a in addition to the cost metrics before endpoints and we also want to review some internal structures and detailed properties associated way these internal structures find the ISPs point of view for the past between human said also stationed in pairs and example is that driven that the tracks this chats includes water negatives for NARS security and ethics and recently we also receive some inputs from other working groups that for example like five GU Pierre functions and also mobile edge computing and probably service edges as well they might benefit from this information we provided and why this instantly essential to the auto framework there are two reasons first such information is useful as we mentioned we can derive resource correlations of flows and also provide and also enable applications to identify context in the in the path they are for it and also these this information is not included in or supported in a current auto framework so how does this extension provide such information to represent internal structures we introduce a concept called optional elements which will give more details about why we do this later and then for the detail property information we reuse the unified property map for the for the for these optional elements and to represent the path between especially the entry in communications where you reuse the auto base protocol basically the cost map and end point cost services where it uses like source and destination pairs to represent potential communications between hosts and so what problems we need to solve in this draft yeah back to two parts of the problem first when you consider about some privacy concerns and then we need to determine basically this is rate to how we determine the representation of our internal structures and first of course we don\u0027t want to expose the "
  },
  {
    "startTime": "00:45:29",
    "text": "physical properties of the network elements so we want these elements to be abstract and then there\u0027s a question of are these internal structures persistent in the network or they can be dynamic and constructive argument and our current decision that first we need to want to make these natural elements abstract and then because first right now we are making him to be basically the scope of this idea of the end the identifiers for this the elements are assumed temporary in your query but we had a property to optionally expose persistent entities in the network and we also designed this protocol we also consider some performance issues that may arise when the developers are building their servers or end clients and one problem is scalability and also consistency as well is the pattern of walk because essentially we are now requesting information of two resources in Auto for the path vector for the correlate for the application error and in part we need the resource of cosmic or endpoint service but for the properties we we want to use the unified program map so the problem is we are actually now requesting two resources so do we want to request these two resources in a single query or in two separate queries and another separate two consecutive queries and that brings us to a problem of one run communication and to run communication and our current and also there\u0027s intimidation capacity basically when you want to implement you want to up your up creates the auto implementation to supports the prospective extension then from there you want to use a new message format or you want to reuse the old format that is already supported in the auto based protocol our decision is to use one-run communication with multiple responses so that we can first if we use to run communication then the you have to keep track of the previous of the first requests before you can provide the properties for the second request and that means you need to cache the request for you need to catch the first request before you can return the result of the second request and that qu need to get a bitty problem on the server and also the the problem with for the multiple response so so that means we need to use one run communication and then we\u0027ll actually reuse format that we already have for the honor protocol so we want to so the decision is to make them into two different mess "
  },
  {
    "startTime": "00:48:30",
    "text": "parts of a single message and these two paths should be included in one multi-part response and a quick summary of what we did in the last gita IETF so for the NIT f15 basically we did some kind of a major revision and first we finalized the specification for the cost type extension for the extension of the cost type we essentially introduced a new MIT new new cost type the Cosmo is array and the cost metric is any path and we also clarify the property negotiation process because so before 0/8 there is no explicit explanation of how the probably negotiation is happy it\u0027s happening between client and a server and we basically clarified we add a new section to explicitly specify the negotiation process of the properties for a E and we also introduced a persist entity as an initial registry entry for any properties and we Kara Phi the part resource ID in the multi-part message because this is actually related to integration ways incremental updates and so in the last revision it is synchronized with SEC draft version 16 and I recently checked the status of SEC and I see there\u0027s a new version popping up so this is actually a really remaining issue that we need to solve in the next revision and we also prop so before 0-8 we have we will leave the capability of cost Condor of future a work and in the last revision we actually proposed solutions for the cost can of ability problem and so after a ITF on five we basically because before I file we did a lot of work and after alpha we had a minor revision that\u0027s the latest version and we emphasize that action elements can be captured dynamically to rockery and we highlight the benefits of this decision in multiple places in the drafts and here I\u0027m going to talk about some remaining issues first as subbing missioned in chair size there\u0027s a dependency between the past vector draft and also the UFL probably trapped and first that I have identified three dependencies first they\u0027re the terminology dependency and also the pop the format of the property map basically reuses response data format from the unified property draft and also oh we need to register some "
  },
  {
    "startTime": "00:51:32",
    "text": "probably domains and for int oh sorry there\u0027s tab you should be entity domain and entity properties should be registered using the mechanism defined in the unified a poverty trap and currently is synchronized with the unified republican version number zero eight i think it is a newer version yeah okay and also there\u0027s a dependency on the sse drafts basically in sec 17 it includes a section saying how we should handle multi-part message using SSC so this part should be removed from the current path vector extension now and I also identified there as a terminology inconsistency between these two jeff\u0027s so it is called so the same object is called part resource I the impasse factor and is called Content ID SEC and we need to resolve this issue in the next review and here\u0027s a revision plan so first in terms of writing we need to fix the dependency issues and improve the quality of the writing and we also and to improve the quality of writing we need some feedback from the working group as well and another revision is so based on the discussion with a being and also some inputs from other ITP working groups so in our current design the AE is designed to be homogeneous so we will provide the same unified the same properties for all the areas returned by the perspective extension but there is actually a growing demand in the internet that we might want information about heterogeneous and E\u0027s though first for example in the site meeting talks we had yesterday so a Chinese company courtesan they are building a gaming platform which might use this information from the are collaborating with some eyes piece to get the information from the network and also I listened to a talk called compute first networking they are basically trying to do some load balancing for EM EC servers and I think there\u0027s a so the the the ability to expose capabilities in the network to the for in for better into in communication is actually a growing demand in the network today and and so according to the discussion with Sabine and we both agree that at least my understanding that we both agree is that pass factor can be used as a mechanism to expose these capabilities to the application layer and I think if we go down this path it will strengthen the power of our extensions and also extends "
  },
  {
    "startTime": "00:54:33",
    "text": "the scope of our Obi\u0027s right now we\u0027re more focusing on some traditional networking scenarios such as flow scheduling and resource sharing groups and if we can extend a bit it will allow us to bring and to adapt to the going trend today and the reason why I think we can do it is that it actually doesn\u0027t require a lot of work for the past paragraphs so what we need to do is first we need to define the entity type here the structure for this is basically we need we need we need ability to first need to identify what what types of æneas we need and what should be the properties associate ways different types of ease and in order to do that the property negotiation process should be slightly tweaked in the current draft and but this is actually not a big deal because the capabilities are Lansing so right now the we are using a more simplified version because previously we only have one type of anyi and right now we the extension is actually we have multiple types and that is actually a good new because this can be this weekend before different days can be considered as different types of entities that means we can reuse the capabilities from the unified property map so actually I think this is actually a cool new for us because that basically means the unified problem the unified problem draft and password drafts they they have more we don\u0027t have to build a new mechanism to expose the properties for different entities and after we adopt this change what follows we might need to identify more any drafts maybe work with other working groups for example on working groups I related to the mobile edge or like 5g and MIT and then we need show researcher the relate age energy type and their properties to the unified property map but that the part included in what follows is not part of the aspect or extension it should be maybe consider as new individual extensions to the unified appropriate draft and the conclusion that the current status of the job most the motivations and the potential problems I think I think we have already made them relatively clear and most part of the specifications are relative completely unstable except the part I mentioned about the heterogeneous option error evidence and we like to say thanks to the co-authors "
  },
  {
    "startTime": "00:57:35",
    "text": "and also the working group for the feedback and guidance and for the next step first I liked I think we need to make a revision to adopt the changes that we mentioned earlier and we\u0027re gonna stay the milestone for working group Lesko so yeah I was actually more conservative and I think we can do this in ITF Oh 8 but I think the working group chair would like to push us to finish it in the next basically in Vancouver and also we neck to a couple reviews yeah that\u0027s all thank you great so can I ask some questions on one simple and one simple one might more complex and a simple working in the following and so for the proposal matrix we have introduced learn your cost source fueled SLA and estimation and very likely of course right now there\u0027s no dependency but actually I think it passed vacuum most likely will be use cosmetic of a bandwidth available bandwidth that\u0027s probably one of the most typical use cases was a little bandit ways for it\u0027s a cough loss right because I think that\u0027s one of the major use cases which being first of all you so many places and so very likely that particular metric with a bandit would be defined in the problems of magic document which means now you actually really could have a dependency one is you define and measure yourself and one is you use a metric defined unit cost performs a magic document and then you\u0027re gonna have create a dependency very likely my understanding will be the praval metric document a proper go first what probably becomes an iced so what do you mean how to solve this dependency issue so you have for the other one I mean let me be very specific number one is do you think for example about bandwidth would be SLA or to be a summation or you need like a nominal or some different types of a cost source I think for example it\u0027s in the example we have in the past Burger Chef we probably are using some either SEO a or nominal busy waste some care with some guarantees from the ISP but I I don\u0027t think that part basically either it\u0027s SLA or estimation or nominal should be included as part of the past whether Jeff because a special job does not depend has not specify what specific needs or properties there should be that should be using I think they probably need another chance basically at least should be reaches to the unify the property registry this should be registered using the mechanism defined in the unify the party drafts but this one really comes from a coastal metric from cost types is separate and so therefore that\u0027s probably not handled by the unified probably most likely we coupling with the performance metrics so "
  },
  {
    "startTime": "01:00:35",
    "text": "of course we will probably took this week and taking it offline about the high level thing really potentially maybe there\u0027s some feedback which can keep it till the pop-up matrix documents are oh that\u0027s really a new type of guidance and so what exactly really it is I think that\u0027s the one you should sell I realize maybe there\u0027s such a dependence I think that\u0027s one and number two is very common if I may have like user on to me and it\u0027s able to be the dependency if you really wanted to extension to handle Hitler genius can\u0027t go to hatred genius any part that actually number one of course it\u0027s super cool right because even now probably even right now today and in in Denver and Colorado I think it was these people Cal attack and yes not about doing demos I think one of them was was using this like any staff pass vector they\u0027re doing all the demos without the major use cases without the biggest and his big data analytics and so therefore actually I think that\u0027s a perspective well most useful thing but then if you do this extension and that throughout like you mentioned you potentially can add a comp like it so do you really envision the final version would include all these little juniors are not really a single simple most of base class app has any I think we would probably meet first we need to define me when we design protocol we definitely should leave some space for future extensions but I don\u0027t think we should for example consider every single types of Annie\u0027s and put them in this draft in the extra we probably just defined a very basic basically an initial registry to to the as any basically we probably need consider any as a family of entities not a specific type of entities and then we probably want to introduce the very basic anyway some for example like penalize properties and some simple properties before we go in and if we can for example maybe later well we can we want to consider more come complicated use cases such as their MBC and UPF then maybe we need to add put them in another individual traps and for example we want to saying that we want to define a new type of any call the UPF any and what could be the properties associated ways that I think that\u0027s way I think you have sugar just a very very quick comment as a co-author and because I am very motivated by this heterogeneous stuff the metrics that are conveyed by the auto performance metrics are metrics on path and properties here are properties on network element so to me the bandwidth on in performance metric is not the same as the bandwidth is some data center or element and the other "
  },
  {
    "startTime": "01:03:35",
    "text": "quick command is what makes in my view this draft interesting is that it has a design that opens the way to any type of abstracted network element so it\u0027s if it\u0027s only a switch then we should name this extension extension switching listing switches so just you mentioned that you were looking for reviewers you want them to review the current draft or the updated that you will make I think maybe after the IDF we would submit a new version and host a to that to the working group and maybe I think it\u0027s probably better to review the latest one okay are there anybody in the room that would be willing to review that craft when it comes on the mailing list okay then you have to find them on the - I want you to review okay excellent Thanks yeah thank you okay - aw I\u0027ll be quick and like I mentioned and then I had some questions sort of I could be very quick so I\u0027m gonna give an update on the city and I I\u0027ve CI document and this one I could have pretty simple now and it\u0027s a good collaboration between young and cabbing and John and also Jensen so let me go where I don\u0027t you mean I probably can get done in like a five minutes so the change is actually the most such as text ideas I think that\u0027s why it\u0027s a sign that\u0027s a really most ready and text I the in particular mostly all the edits in the two versions will be consistent a user terminology and very thorough check for internal use and also I think one you should why we encounter all the tech side is all the time in lately it\u0027s because all the dependency among all the documents so therefore we an athlete to be consistent with the dependency for example unify the proper document you\u0027re the same terms that\u0027s why we\u0027re cause all these like I text edit okay and so number one the change we made it was very simple is constantly use of terminology within the same document and we sometime called City FC service sometime we call obsidian I\u0027ve seen a map service eventually we will terminology we make sure they all essentially using one so that\u0027s the change in number one it and then we of course we also made it a consistency over to be consistent way so the documents the terminology using auto document program Proctor map and we also do the same thing so basically I don\u0027t need to go to all the essential consistency and we also need to be consistency with essentially the unified properly document and for example there that were using and then the name change from anything addressed to end it here identifier we also start we go through the whole document make sure we were you the same thing I don\u0027t think we\u0027re really depend on a document but I think that\u0027s essential to what we did to to "
  },
  {
    "startTime": "01:06:37",
    "text": "dual updates and for example here is previously we call alternative domain registry and now right now really called auto entity domain the hybrid tree a term changes because it about chasing the dependence say that\u0027s why makes life live your heart but we I think we\u0027re so far were doing pretty good job or maybe we\u0027ll make sure they\u0027re all consistent so work a more as soon as possible so the samurais and I think documents is quite stable now except really a lock a portrayal names we have the follow names any other clever way to do it and we\u0027re waiting for some comments from singing I working group and from over there give us final comments and until they sign off with other changes and then we essentially want to go to a working group ask our I will grab a miss document that\u0027s pretty much it so I know it\u0027s short but we really don\u0027t need to change it too much okay any questions [Music] okay so then we would have the same question as with the other draft so are there potentially any people willing to review these documents of course we can ask afterwards but that it was that and probably review a lot okay okay so the last two presentations are not about working group items but they address exploration work regarding modem networks yeah thank you yes next presentation is about the idea of using altitude at their mind the service edge so somehow thinking in the pollution of the networks and ike i referred to that in the previous talk potentially we will bore by the progeny computing capabilities and so so the idea would be to leverage from their capabilities in in order to help us to identify the better edge for a given service and here the ponies to to differentiate between the physical edge and the service edge so no not all the services necessarily have to go a close to the access or probably the edge for each service depend on the kind of service tree to be honored to be the Liebherr so yep basically the the the situation is that now operators that are starting to the products within covering capabilities across the network the edge environments that more centralized data centers large data centers close to the interconnection etc cetera these data centers all of them had different capabilities in terms of the environment itself the size of the "
  },
  {
    "startTime": "01:09:39",
    "text": "number of CPUs memory bandwidth even for forgiving the traffic and so so the idea the detective would be to think of mechanisms for assisting the decision in which datacenter we deploy a given service according to the restriction on these services in terms of latency bandwidth etc cetera and we consider that the alto could play a role on this so basically the idea will be to incorporate into Alto all the information ready to compute into the computing environments so CPUs memory the storage and so and combine that with the topological information from the network in such a way that the Alto client could request the Altos shared information based on the needs for the computing capabilities but linking these these recommendations this is for let\u0027s say for Alto together with information from the network so how the computing needs are commonly expressed so typically they are structurally in bundles of CPU RAM and storage units and we can see this in commercial examples like Amazon Web Services or make micro service or there is another example that is being from promoted let\u0027s say between Linux Foundation and the SMA which is a common network function virtualization infrastructure telecom tax force C NTT and in this particular case that we have taken as an example for the for the draft the the different flavors or instances are characterized by five different item items the same the type of instance so basically this instance can be characterized as basic network intensity for computing intensive the interface option where basically declares the bandwidth of the interface that is required for for the function to be deployed on top of that the compute flavor which basically refers to a combination between CPU Raman and disk and the bandwidth for the management interface of this instance optionally storage suspensions to request additional storage capacity and optional harbour acceleration graph statistics in order that in case that they design a specific need for the application running on top of the of the of this computing capabilities regarding the set a characteristics of acceleration in the liberty of the traffic here you can see more or less the kind of flavors that are being proposed in this yen TTD initiative and also you have here the link for for that for checking that and we have performed in this graph an initial mapping to the property map seen in alt so this would be an initial exercise that we would like to develop and to complete in future revisions of the other document that basically will be to take this alongside as an example for exercising how the how Alto could be play a role in in this "
  },
  {
    "startTime": "01:12:40",
    "text": "part there in the association of computing capabilities a network topology we have identified so far three potential solutions this does not mean that could be others for sure but these these ones are the potential solutions that we have identified one could be one could be to leverage and possible is ten the service function network topology model that is been moved into T\u0027s working group in fact now in this cell function our topology model we already including the current version so information about the data center capabilities probably the idea that we are considering the Delphis of this graph is to move this forward and get in a specific document for that so no mixing with the surface of Ceres functional stuff itself because the service function referred to there to the function and and somehow they buried in infrastructure from fraction let\u0027s say a second ocean could be to extend the BGP LS or to propose to stand the VPLS RFC including among other attributes the information of the compute part and a third option could be there to combine somehow the information from this researcher profiles catalog with a topological information by leveraging on the AP prefixes allocated here to the Gateway all the data centers basically populating this probably doing this together with a IP Alton gave me so very next steps we are considering to elaborate more on the mapping exercise to the property property maps in Alto so elaborating more in that example that I showed you before this product relatives for the Association of compute capabilities to network topology and this probably the first step will be to generate this need of this document derive from the service fashioned our topology module also here for sure the idea is to collect interest from other working group to understand if this is something of interest for the working group and in so two local men advances for next ITF in mokuba so this the all for this presentation some love comments to move on Howie for the second point actually you mention you want to support a computer capability so have you consider you to support a storage capability or you think it\u0027s not a use cases you want to connect focus on computer capability what I refer compute in a general term so will be four bits even remember CPUs memory storage and also so complete information at the end probably a startling the so how trying to abstract with this idea of bundles of flavors this is this makes this more easy to handle than the individual values of memory and storage but this is something to explore but remember in "
  },
  {
    "startTime": "01:15:40",
    "text": "your question idea would be to address everything not only CPUs but memory storage and so so I referred as computer in a linear dynamical way Junaid general way all the capabilities of data center for deploying services for its compute computer capability there\u0027s some relevant water worker in Si and Fe I\u0027m not sure how to marry together for well in fact this initiative or sorry this one try to standardize the way in which an API capabilities can be requested so normalized on how they the way or not only requested normalize the way in which the nmda capabilities can be somehow exposed in such a way that the different network functions can be deployed in a similar way in different environments so somehow we have this link with an API stuff that\u0027s gonna be a stuff I just remember some open issue in service service aware topology model there\u0027s some open should relate to the NFA actually I\u0027m having followed discussion very closely that seems actually they need to you know talk ways as a younger way to address that open your issue so probably you needed need to you know consider this okay thank you so we can yes I think this is super interesting and I do wanna say comedian it won\u0027t be the intradomain setting and even show to be a single network or eventually this model will involve multiple domains meaning out of multiple autonomous systems and there are competition or what a story resource\u0027 will be aggregated or maybe the eventually only invasion essentially a single one you don\u0027t worry about it eventually information abrogation issues the initial approach is single domain sure so that could be applicable a I guess I presume to to multi multiple level domain case should not be probably too much complex there will be probably issues of authentication privacy probably different levels of a structure maybe I think it can be extended to to multi domain but the initial approach is single domain only to start for for the easy part and maybe to complicate the things sure yeah because if I mean so one reason why I want is following several years ago and IBM guys will trying to use this actually a map to really do the IBM private class to do information aggregation and of course that he was in Kiyomi multi domain setting and turns out the information aggregation turns out to be very very tricky so I can give you a very quick example just like follow record and for example like calcium formation seems to be very easy for example essentially it\u0027s decent vector if for example my cost to you is five years of being is three and the eventual if you go to relay from from stopping from me to you to suddenly five plus three equal to eight very easy to the addition every "
  },
  {
    "startTime": "01:18:40",
    "text": "since I\u0027m still working so I\u0027ve had my house from me to you you fake your cost from you to stop being we had together we got eight everything seems to be okay but but somehow competition has this very weird property of somehow the outreach system somehow seems to be broken and for example the example which I p.m. gasps gasps encounter was very simple use case was for example I will see I have two users I have to use of CPU I got information I\u0027ll tell you and you heard from Kyle that he has two units of CPU he also tells you and he were and you might tell us I mean you have for your new units or CPU but I can funny thing might be my tune you\u0027ll sleep you might hold for exam two units I mean I would also keep example Chi two units we all posted Howie we have two units and you got two units and eventually you got four units and you tell actually for example you control they subpoena your for you know you don\u0027t you only have two units um honey simple mission when the propagate it somehow mean gold may not they cannot be distinguished somehow the information becomes quite a complex that\u0027s why you\u0027re in surely will encounter this issue or an action now most likely the IBM gas eventually I don\u0027t know what eventually how to do it I think then you solve this issue for their cloud aggregation here in the cloud they were using this outer thing using as example but that\u0027s a completely encounter okay thanks for the comment something to consider is - important from Sprint so thank you for the presentation I think it\u0027s very interesting and I support further work in this area in addition to the properties of the data center I\u0027m wondering if we should also consider the the back hall or a transport going into the property for that going into the data center right so it\u0027s something to think about also I\u0027d like to maybe work with you off talk to you offline about possibility of maybe leveraging this idea with at ccsm that I\u0027m working in okay for sure so there are in the back : and so for sure we intend to let\u0027s say mix all they play with all to help us or allow us to mix both words say they never part together with a compute part in a generic way in such a way that we can take their worse decision but looking at both things together at the same time so I my answer will be yes and for the second days at ccsm for sure we will talk of that thank you okay thank you yes let\u0027s go for the next one okay so here the idea is to what of the objective is to present an idea but that would be it was 10 alto by using bgp communities so the the BP communities "
  },
  {
    "startTime": "01:21:40",
    "text": "are BP communities have a BP attribute basically is commonly used for grouping destination so you associate a number of prefixes to a community and you defined this community and you basically use the communities for policy purposes purposes for influencing the delivery of the traffic to certain prefixes so this is basically the fact these communities are represented as an indigent number 32 feet length basically including the information of the autonomous system and yeah and also interesting these communities this community exhibit can be carried across an autonomous system so somehow could help us to to support these multi domain cases in the future as well so the the problem when looking at this issue was the basically we operators used stands extensively the BP communities is a way of putting together some practices or some IP destinations this is basically used for applying policies for the traffic again as I mentioned before for influencing the behavior of the trafficked or different associated associated destinations towards the prefixes the other protocol is based on IP practices and the point here is but--but and we usually use these these communities in aggregation nodes so basically when we allocate IP prefixes to PNG or to a P gateway so how we are identifying the users we handle these happy prefixes with just a single identifier so the point here will be instead of going to individual IP prefixes to play with the PEP communities in order to obtain information to retrieve the information from the from the alto service said well we see benefits on on this one would be probably the reduction in the number of queries to the auto server so we\u0027ve just working with VP communities if we could address information for different number of prophecies and also to fully absorb the natural change in practices because well with all the migration of users and we need to move professors here and there and sometimes this complicates I say the management of a addressing IP addressing in the internal of the network so going to with big communities somehow we are hitting this complexity and we will kept the Altos tough more or less constant without so many changes so regarding their next steps for this idea will be to elaborate more on the proposal this is just to present you they what we have in mind to call any interest for an alto glue to understand if this is of interest or not actually and be sure to document the proposal for the next a team meeting and create a specific draft for it and that\u0027s all for "
  },
  {
    "startTime": "01:24:42",
    "text": "this presentation so I only want to get one go I think this is super clever so for example the the essential a PID is into some kind of like for example a bit if you agree in some way of doing aggregation doing and marking and this one it\u0027s much more junior it is a very clever proposal thank you and more preferring to the multi domain case that we have mentioned before these because this is transitive so we also could use these for the multi domain case in order to to support a multi domain basically [Music] so thanks everybody we really we still have five minutes for open discussion if somebody would like to raise a question thanks a lot to Luis because this is well of course we are swamped with working group documents but it\u0027s really important to have some look out and especially your first presentation leverages actually the on the well the interest of having an open design for path vector stuff like that that are not restricted to particular network topology and context and elements and in the light of these actually we can try to play some scenarios to really test how open and flexible the path effect I think path vector and properties are definitely two items that will open the way for heterogeneous technology because now the trend is end to end path and 20s means a Yanni\u0027s of any type so so any thing needs to be said no in which case thank you very much to everybody no you don\u0027t you oh thank you so much thank you that\u0027s so nice thank you so "
  },
  {
    "startTime": "01:27:46",
    "text": "maybe we should [Music] "
  }
]