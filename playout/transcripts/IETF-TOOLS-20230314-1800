[
  {
    "startTime": "00:00:39",
    "text": "somebody send some audio wake my speakers up I'm not sure that the right thing is happening for me you're hearing me yes I'm not hearing anybody else though somebody else should talk that that worked thank you for a couple of minutes past the top of the hour we'll wait another minute for the join rate to slow and we'll start in if you've not already reviewed the notes um if you have any uh please review them and if you have any"
  },
  {
    "startTime": "00:02:01",
    "text": "agenda bashes well that's the first question I'll ask here in a moment if you can share video we want this to be a meeting around the table but do remember that the meeting is being recorded and will appear on YouTube all right so does anybody have any agenda batches not hearing any the first thing I'd like to bring up as a Hot Topic is to acknowledge that we've had a couple of days of roughness around the draft submission deadline with www.iatf.org itself um things changed at www.itf.org configuration at cloudflare's configuration and maybe with cloudflare's behavior to conspire to put us in a spot where the just www.itf.org was behaving slowly when things were not being served out of cash several of us are looking into this Glenn has made some changes to the Apache configuration that have helped they're a stop Gap measure um we have been making changes to the configuration at cloudflare to try to improve the way that it caches and try to improve the way that it"
  },
  {
    "startTime": "00:04:02",
    "text": "Shields our origin server from nuisance traffic we'll see how well that performs over the next few days but the real answer is that it's really time to go through the effort to move www.ietf.org out of Apache NT nginx and I will be putting together a plan team um see if we can do that as we're working our way up to 116 or if it will be a post 116 activity the Glens current hypothesis is that we have um taken the mod proxy part of Apache 2 beyond what it is capable of doing with the way we have the www.ietf.org site architected where we are slicing out chunks of the namespace to feed through mod proxy versus serving things that a lot of the rest of the um URL spaced directly off disk or through other applications so um there are a few other things that we can try in that configuration to make it better we'll see over the next few days I'm going to move on if someone could take uh volunteer to watch the notes for me I noticed from the last call that there were some people contributing on the notes my windowing I can't conveniently get the"
  },
  {
    "startTime": "00:06:02",
    "text": "notes in in addition to looking at the face if there's something that needs to be brought to the verbal part of the conversation from the notes jump in and do that could somebody please explicitly volunteer to do that for me now yeah this is Rich I'll keep the you talk about the chat tab I'll keep it open thank you all right the next topic I have is ask if there is any tooling that we need to be doing for our ETF 116 that's not already very obvious in action moving along are there any unmet needs that anyone on the call has identified for ietf 116 that needs Focus all right not hearing anything I have a high level question about an act a thing that we do a lot that has its origins in the way people were consuming our data 20 years ago a decade ago many people have old tools that are still consuming these things but we produce a large number of very large artifacts I've listed a few of them in the notes where we essentially take a chunk of our data our database and make a big text file sometimes a big XML file sometimes a big Json file but it's a really big file of everything the RFC editor also does this for all of the rfcs they produce one big dump that has you know a bunch of stuff about the rses in it"
  },
  {
    "startTime": "00:08:00",
    "text": "and I would like to propose and discuss whether or not this is still the right thing to do I would propose that we stop it and work with the people that really want to use these things on getting them to use a more modern ask for the things that they're really interested in um and if they're really interested in trying to get everything convinced them that they get everything once and not over and over and over and then incrementally use apis to get the additional things that they need you know with possible resync but to stop making these big monster dump of all the working group Charters into one great big text file for example um feedback please I mean some people complain causes the change but seems fine to me so this is one where I would expect Carson to have an opinion I don't it looks like he might not have joined us today so unless anybody has any guidance against it I'll just take this proposal and send it to the tools discuss list so we can get some more people talking about it All Right Moving On an update on our"
  },
  {
    "startTime": "00:10:00",
    "text": "um work to move our primary DNS Services into cloudflare we identified that we needed to move our registrars away from the current registrars first um so that we could more easily take advantage of the DNS sec capabilities that cloudflare offers we've begun the process of transferring these domains it has turned out to be a arduous exercise is slow but we have motion we have one of the active domains in the process of set up for transfer will be beginning its transfer later today or tomorrow we're just waiting for the removal of DNS SEC on that particular Zone to expire through cash before we initiate the transfer will be going through this with the other zones um while we might be getting them ready to move I don't plan to move them starting from um now until after we get past 116 so that we don't disrupt the the meeting with this activity so we'll pick this back up right after 116. eBay have any questions I will make a a shout out to Nick here he's built a"
  },
  {
    "startTime": "00:12:01",
    "text": "very nice um set of tooling using GitHub actions and the apis at cloudflare to ensure that we have a um traceable um the word I'm looking for change controlled picture of what the current configuration of the zones are once they're in cloudflare so my next topic is an update on where we are with the postgres database in general and in particular the migration of data tracker to postgres last week we successfully rebuilt well we built a new cluster on ietfa for postgres with modern configuration modern defaults things like having checksums turned on in you know cluster wide having it set up to properly replicate when we turn replication onto ietse which we have not done yet we won't do until after we do the migration of the data tracker into it so that the data tracker migration isn't further slowed and we end up with a longer amount of downtime because replication is would be happening while we're loading it um that happened pretty much almost without incident it took a little bit longer than we intended and I was surprised that there were some pages that weren't already in cloudflare's Cache that were um 500 and"
  },
  {
    "startTime": "00:14:00",
    "text": "um during the few tens of minutes that we were doing this work last week the action items are coming out of that for me are to look into the wagtail websites implementation and its integration with cloudflare to make sure that it is posting um it's letting cloudflare know that things are available for cash and to to see if we can pre-populate the cash at the uh at all of the edges or if we are stuck with waiting for things behind the edges to make the fetch into into Cash um in order to get the cash populated I will be testing um the data tracker postgres transition on ietfa later today or tomorrow it's likely to fall in tomorrow at this point that will give us a finer estimate on what our actual downtime will be on April 11th when we actually make the production move I still expect this to be in the large tens of minutes time frame we may be out for um up my my conservative thumbnail says it would that will be done within an hour and a half I hope that I learned that we can be done much more quickly than that with the tests that I run in the next couple of days questions about this"
  },
  {
    "startTime": "00:16:06",
    "text": "next item is the RPC tools refresh project everyone should have seen the note that Jay sent to the tools discuss list about the plan that we have for implementation Gene and I have started on building out user stories we plan to have many discussions while we are in Yokohama with members of the community members of the RPC pushing to make sure that we're going to as we're making the transition of these toolings we build the right thing um shared understanding a good idea of where we're going and why is the goal of of these conversations um I expect to begin implementation of the parts that we have confidence that everybody agrees on what needs to be done very soon after 1 16. but after we do the postgres and Django for transition because the new things that are going to be coming into the data tracker we definitely want to build on scaffolding that is only going to be available to us once we're on Django 4. so anybody have any questions about this project so Alexa just as a an early introduction and a teaser for some of the Alexis sorry teaser for some of the conversations that we're going to be having is you know where the Errata data lives"
  },
  {
    "startTime": "00:18:04",
    "text": "so in the conversations that Gene and I have been having it seems um to us at the moment to me in particular but I think that conversations need to to continue to happen that the Rada data should live with the RFC data and that's going to be in the data tracker so all right the next item I have I have a pointer t a GitHub projects page that I've been putting together it is in a draft form at the moment you'll note in particular that it does not yet reflect the uh our PC um tooling refresh but it will soon I wanted to get feedback on this call on about whether or not this is a useful and effective way to try to communicate at a high level what the tools team is going to be doing over the next several ITF Cycles to the people who are not on the tools team and the people who are not paying close attention to calls like this one as everybody had a chance to look at it does it make sense do you think it works is it a Miss we should be doing something else um what I'd like to get some feedback now what do people what do people have to say about it uh I like it um it seems reasonable I've seen you know lots of other GitHub projects use it so it seems okay uh probably is worthwhile because it's sheep relatively cheap to do compared to other forecasting and planning things"
  },
  {
    "startTime": "00:20:01",
    "text": "and hey do you want to present the slide at uh the working group chairs lunch absolutely okay we'll talk off on does anybody see anything that we should do differently if we do go ahead and flesh this out and continue to pursue it are there any message opportunities here that did it make anybody particularly happy to see it I mean is this a spot-on thing yeah Jay gave us a good thumbs up so it is good for conveying very big um tasks at hand of having it filled out would be nice for instance clicking um some of these there's no description so somebody unfamiliar with uh these items might scratch their head at what these are and um is there significance in uh where they are listed within a column uh perhaps a small read me all right some description of of whether or not there is any significance there at the moment there is not but it could be that we could organize things that way so all right if anybody has any other thoughts um please send them to me some tools discuss I will go ahead and spread a link to this around a little bit more widely see if we can get get even more feedback"
  },
  {
    "startTime": "00:22:01",
    "text": "I think I will work in just at least a couple of cards about the RPC tooling and then send this to the tools discuss list to have conversation start before we get to 116. all right we're now down to the RFI section so we'll start going a little more quickly but if there is something that needs to be discussed um raise a flag let me know uh for the infrastructure strategy we did get responses to the RFI A team's been formed to digest those responses and turn them into action for the rfps we expect to meet this week um as we discussed at the last meeting we simplified the number of addresses used to report May or issues to the tools team as to help the tools team we're in the process of reconfiguring places like the footer and the data tracker to point to the new tools help Alias let the tools help Alias is in place already um Greg notes that we're trialing transcription at 116 Greg is there anything in particular that you want to point to in the interactive part of this um I think you're there now yep okay yep just um this is a little a little bit of a late ad so let me know if you have any questions but um we'll be taking feedback in expected review and then further develop it or not after 160."
  },
  {
    "startTime": "00:24:03",
    "text": "I guess one quick reaction that I have um be thinking about I expect that if the transcripts are good that somebody might ask to have them scooped into meeting minutes and we might want to talk about what it would take to make that easy or not uh that's um definitely something we discussed so we can talk about it and um Greg sent a note t the relevant lists that we are at the end of the track Wiki migration and a few other Wiki Technologies migrations into wiki.js the track in particular is winding down I expect to do the final Archive of the track wikis um tomorrow that will be tucked away not published something that if we have a need to go back and look at somebody on staff can the uh with the wikis the the information in wiki.js is is now what people should be looking at um for the data tracker Robert go ahead yeah I just wanted a quick update on that one um so far we've heard from um one working group chair that they still need some work on their transition so I don't think that'll stop anything else that's going on but we are working with them but otherwise we haven't heard uh any concerns about the transition plan okay for those chairs is track itself changing or are they just wanting"
  },
  {
    "startTime": "00:26:02",
    "text": "translation always on track uh right they're concerned about the content move they're not concerned about the platform move uh for them but I think we'll have a result this week um for the data tracker things are moving um quite rapidly they're moving as expected you can track what's changed with the links that I've put into the notes I expect to do another release this week um then the next release after that will probably be um what happens on April 11th so unless we end up discovering something that we need to deploy in an emergency while we're at the meeting unless anybody has any data tiger questions because Sarah you can do a just a quick run through of the next several sections foreign GitHub workflows and there are some bug fixes since the last call for auto tools um there are several map fixes and improvements especially on ID Define RFC div there are some cases where IDT fixed slower so I have set up timeouts now"
  },
  {
    "startTime": "00:28:01",
    "text": "to fall back to RFC deep ID is taking long time to give back results to someone right now it's I have 20 seconds of timeout so it's taking too long then it's our IDE fill fall back to our rcd on XML tortc um we haven't cut we have released a new release since last call there are a few changes on the pipeline um the next release probably would be after the uh ITF meeting the notable changes uh we're gonna add a new font uh to support math symbols their current repository that we use for a lot of phones is archived on the on the daughter side so the plan is to maintain separate repository on our site that will include all the forms that we use for RFC publication RFC documentation will be updated to use this it was free to download the fonts and maybe we could write some scripts to use that repository to automate it any questions on the things so far I guess I have a couple points I'd like"
  },
  {
    "startTime": "00:30:00",
    "text": "to add the XML service has um failed a couple of times as we were under the pressure that as we were coming up on the draft submission deadline um we are investigating one and we'll be addressing the failure um so that we don't so it doesn't recur for xmlrc I have a question for the RPC I guess um as kasar mentioned he's not planning on cutting the release it would have this um nodo mask font in it until after 116. if the is going to block publication of anything let us know okay okay yes it is you say yes it is yep correct let's let's uh let's work together over the next couple of days to determine whether or not that's okay and when a release date is is is really needed thanks all right sorry if you want to continue uh yeah so on that day website there's a lot of work happening on getting multi-site set up to migrate iib website to Interactive"
  },
  {
    "startTime": "00:32:00",
    "text": "these are on the testing at the moment on a new server any questions about that website all right so I don't see Ryan on the call I think let me doubles yeah double check yeah I don't see Ryan um do we know who un Duke is um I'll ask Ryan to send an update on mail archive but I will call out that the most recent release added um some pages that are designed to replace a large part of what historically had been called the IMR reports there are pages that show statistics for number of subscribers over the last month whatever for each of these lists and the number of posts to a given list for these times this will integrate with a page on the data tracker that talks about groups close groups open documents published things like this to fully replace what had been in the IMR reports um Eric is also not available I'll ask him to send an update on what's happening in Yin catalog separately off the top of my head the activity that I've seen on the Yang catalog project for the last month has focused on the um the primary user interface particularly"
  },
  {
    "startTime": "00:34:01",
    "text": "around search and singing the correct things about whether or not the data that's being described on a given output page is from a Ying module that has finished going through a process that makes it a an official thing you're using the word ratified it makes me very nervous I don't know that ratified is a great word um given the intersection with the ietf community but the uh that's where the the focus have ever has has been um as best I can see it the last thing that I have to add is a related to the IMAP user remapping topic that we have been tracking um there has not been progress on remapping users but there has been progress on changing the way we authenticate users that will be leveraged eventually in the usually remapping concept we have a an API that we created over the weekend um Alexi hasn't had a chance to review it yet but it's in his hands now that will um move the authorization process for the IMAP server into something that's hitting an API instead of something that is using data record code directly and and speaking directly into its database which is what is currently deployed so and it brings us to um open discussion in any other business is there anything that we haven't talked about that we need to talk about um before we get to this next meeting"
  },
  {
    "startTime": "00:36:01",
    "text": "now all right not hearing anything I thank everybody for uh their time and we'll see you in Yokohama"
  }
]
