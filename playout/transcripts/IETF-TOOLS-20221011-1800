[
  {
    "startTime": "00:00:04",
    "text": "foreign hello everybody so Robert the trick with studying all the cookies didn't work for me to Echo apparently because I'm IP chair now okay just to let you know whatever"
  },
  {
    "startTime": "00:02:02",
    "text": "so we got it people joining at a pretty rapid rate we'll give it a moment or two more a lot of people finish joining do you please share a video if you're able like to have this as mentioned before be as much of an in the room meeting is we can make it we're getting a really nice turnout today hmm all right the join rate is slowing down so we'll go ahead and start in the first thing I'd like to bring up is um how we're going to approach doing the meeting based on what we tried last time and the feedback that we got from Eric I am planning to go through the topics that are listed under hot topics for discussion and detail the rest of it we will just point out section by section as we're going along and give people a few moments to scan in real time in case there was information added since the last time they read the notes but not necessarily read through each of them um take basically taking most of that text as read so if you know that there is something"
  },
  {
    "startTime": "00:04:01",
    "text": "that's currently not in the Hot Topic section that um you know for sure you want to talk about when we get to um that part of the call be sure to to say hey I want to talk about this thing down here and I'll remind everybody that this is an editable web page and um I'm happy to have anybody at it at any time as long as it's a positive contribution towards the meeting if you know something is a Hot Topic that you won't discussed on the call before the call shows up feel free to just edit it into the agenda on the page all right first thing that I want to jump into is the uh what we're going to do for November currently the tools call is scheduled um in conflict with some meeting sessions I think um or maybe it moves into dinner of the ietf week I suspect that that's not what we want to do I know we're going to probably have several side meetings related to tools during the week do we want to have a tools team call the week after or do we skip November and just wait for December's call anybody feel strongly one way or the other I am leaning towards just skipping could we try to cover one that we're place on the Saturday of the Cold Spring just to talk about the tools and allow for remote access well the whole code Sprint is basically that and the intent is to allow remote access for the whole thing if the Secretariat can pull it off with the new pod equipment uh I was most thinking about reserving half an hour on the Saturday around the lunchtime just to talk about generic topic and not I mean"
  },
  {
    "startTime": "00:06:02",
    "text": "very small one like we do let's go spring I don't object to that the remote people it might be easier for them to with weird time zones it might be easier for them to pick to attend that piece but um yeah I don't have a problem with we're now doing code sprinting with the hackathon again in a separate room at the moment um just because of the noise provide remote attendance so I I would be happy to pick up and change rooms for half an hour uh that would be fine um if if that's an important thing to do I don't know I'm I agree with you Robert uh that probably uh deferring by a week doesn't help people that want to want to break and probably just go for December meeting yeah okay and we'll take a look at um putting an explicit half hour for a group discussion and making sure that we um advertise for remote attendees that we'll be talking about stuff during the code Sprint and I'll work out what time during the code Sprint makes the most sense I think allowed the most remote participants to attend all right let's go ahead and move forward um people have seen the note that went to tools discussed about our infrastructure strategy going forward how we're Talent where we're going to run our services and the models that we're going to evolve to we requested that feedback arrive before this call we didn't get a great deal of feedback a few people commented and I"
  },
  {
    "startTime": "00:08:02",
    "text": "believe that their comments are already incorporated into the document has everyone on the call had a chance to look through that proposal and I mean there are several people here that haven't commented explicitly should we just take silences if everything is good does anybody here need more time to look at it I don't hear anybody running to the mic and I'm assuming that people have given some thought to what the document doesn't say that it should perhaps you know we're waiting to dive into the details of of how we would implement um some of the principles that the document calls out um until later so clearly there's still a lot of detail level information that we need to pull together but as a framework for how we're going to move forward I am guessing that people are happy with what they're seeing Jay do you need anything from anybody um no I'm um quite good with all the things that people have done so far I just um need to incorporate fully the comments if people are otherwise Happy I'm ready to basically call this done and um start to work on um with you on uh one or more rfps for um delivery around this yeah"
  },
  {
    "startTime": "00:10:01",
    "text": "all right so I have maybe a little bit delinquent on timing I'm currently aiming for the beginning of December for our next tools team workshop based on the survey that we sent around the one that we should focus on first is how we publish documents on the internet particularly rfcs and internet drafts but including all things like meeting materials and photos and all of these other things right so um I unless somebody who's got a reason not to I'm going to Target the first two weeks of December for this I'm talking with Alexis already on building out a set up questions that we can use to drive the conversation during the workshop point of the workshop will be to um grow mind chair and just get input into what we should do the we're expecting that the topics will Encompass everything from the idea of a a single place that has all of these documents with very short ul's to get to them TV do these things just give you document content or do they give you a metadata page or do they give you both um I know that some of these conversations are also on cue for um possible rswg work um so the Commerce any conversation we have here that gets into the policies that the rswg would be um responsible for would just turn into input into the rswg conversation I will get a more detailed description of what we're planning for the workshop"
  },
  {
    "startTime": "00:12:00",
    "text": "to the list either later this week or the first part of next week anybody have any questions about that or um a desire to change the plan not hearing anything I just wanted to report on a couple of things that happened um early part of last week we had someone report that we had an open redirect point it turns out that that open redirect Point had been available for probably a decade um as far as we could tell from the logs that we have that don't go at back a decade they only go back a few weeks um it hasn't been it was not exploited during that time so we closed the redirect with a patch the next redirect will completely remove it the basic details of where it crept in was at the um Port the original Port of the Pearl iesg tracker into Django um we built a um piece of middleware that would strip the a trailing period off of a URL and we believed that this went in like I said over a decade ago in order to um make some of the Legacy Pearl URLs from that Old instance continue to work properly but the way it was implemented it bypassed the rest of the Django stack at the protection against becoming an open um redirect service and our fix was to"
  },
  {
    "startTime": "00:14:02",
    "text": "just remove that piece of metalware from the stack we also had an issue sorry it's way longer than you said yeah yeah because that was like year two of my chairmanship yeah yeah but whatever I'm glad you fixed it we also had an issue with our role-based um Access Control mechanism thing we decorate functions with to say you have to be a member of the Secretariat or a working group chair or a whatever to do food to this group um it had an edge case that um it dealt improperly with not having any Target roles in the list of things that it might try to match against it failed open it shouldn't have that's been fixed somebody found it they created an account to deface the one group that presented a situation where there weren't any roles to match against and that was the group that we hang individual submission drafts off of um the hole's been fixed the code's been fixed there is still a question about how much cleanup we do of the history of that group now there are some um group events that I suggest that we delete because they contain just the text of the defacement it's not particularly offensive text but the uh who knows what it's a key for"
  },
  {
    "startTime": "00:16:00",
    "text": "Lars when I brought this up mentioned that he would have been happier if we had nudged the isg when we saw this happening so um I don't know if we've got anyone you know just skimming for I guess it's something that um both are our tools team in the Secretariat can take note of when we're adjusting to something like this in the future we can just drop far as a note or a chair of the time a note that it's going on that'll be nice and this time it really didn't matter so much because there wasn't an outage or anything right but if something gets discovered that would actually you know affect data trigger availability or functionality um be very nice if the isgu that so that you could deal with the results of the Fallout okay so my next I am here um Mary Barnes reported that she had some link found some links and some old email um from the Nom come that she chaired most recently that did not work anymore um digging around and investigating I found that the information that she was missing was served off henrik's tool servers by handcrafted Pages there's an example of one of those pages from the the internet archive Linked In the text from the notes here so you can see what they look like the archive did not get all of them so we can't go to that to discrete to get that information back Henrik has confirmed that he does not have that information anymore it was cleaned away after we moved"
  },
  {
    "startTime": "00:18:01",
    "text": "um the capability for the nom-coms to keep their public facing information in the data tracker so that should a non-com ever need to have all of its information removed there was only one place to remove it so that information was just lost at that time it's gone um and I don't think that there is any any way to recover it so there's um we could spend some effort going through what we could find in the internet archive for the the few pages that it did capture and backfill those into some of these older non-coms but I don't know if the the return for the effort that goes in is high enough to actually go through go through the process so well but um I thought at one point um we had Glenn archive as much as he could see on those servers um so Glenn were you able to get that partic those particular pages it's unlikely we can get Glenn to go look but I think that um the time that Henrik removed the information from tools.iatf.org was many years ago all right you know we'll continue to poke around and see what we can find but I think that um it's it's just a a lost opportunity I"
  },
  {
    "startTime": "00:20:01",
    "text": "I may have missed it I may have missed a question Jay were you asking me about this old data uh yes but Robert's explained now that it was deleted some years ago before you started taking backups at tools.ihf.org for us okay so it was only it was never on the iatf servers it was only 100 servers correct okay sorry but I'll follow up with with Glenn and get him to to to verify so all right the next thing I've got is um a short conversation around authenticating with IMAP um we in the process of attempting to add a feature that would allow us to map user identities at the IMAP server so if somebody changed their data tracker account login to a different login stream the configuration that they had that the IMAP server could follow along um we restarted the um the service and discovered that it didn't start and it didn't start because I had removed the Python 2.7 copy of the data tracker that we had running around that I had thought was only there to support mailman integration um turns out that auth P off PD was using it as well um it is reinstated for the moment I'm in an email conversation with Alexi to where we're going to move off PD to the modern version of the data tracker on python 3.9 and then build a"
  },
  {
    "startTime": "00:22:00",
    "text": "different API so that the auth PD code isn't using the data tracker models directly but is rather using an API so that we can separate the life cycles of those pieces of code from each other all right the rest of what I've got on the agenda I am planning to mostly do a take as read just at a very high level we're working on adding using cloudflare streaming service in addition what we have for YouTube um to reach a greater part of the world that's a work in progress the FTP Service has finally been configured to not serve anything but the tombstone file and usage has dropped to zero people have seen the announcement to the lists about when we're going to turn off the uh well we've already turned off the um email list bridging in the zoo open remove the copies of the archives that are in Zulu that's completely done the uh we're still working on the final things that we want to do to ID diff before we have the data tracker use IDF instead of rfcdef I'm expecting that to be in the next release of the data tracker and one of the upcoming releases of authortools once that's in place we'll take the Pui HD scripts that are on www.ietf.org offline so for those that may not remember pyht is a language that Henrik wrote in Python 2.7 to serve web pages and to encapsulate scripts behind them"
  },
  {
    "startTime": "00:24:03",
    "text": "um and they're unsupportable at this point we had two patch Coast post confirmed I should have moved this up into the actual talk about it part of the section we had to patch post confirm because Google became more aggressive about enforcing um their interpretation of what was in RSC 5388 um headers that use the multiple versions of having the header field name two food two bar two baths um Google now just rejects the spam they will only accept two food comma bar comma baz and post confirm was doing it a different way easy to fix but in the process of patching it we it reminded me that the install that we have in production right now was installed by hand not through any packaging system even though there is something sitting out on Pi Pi what's sitting out on pie pie is not what we're running in production what we have at GitHub is what is on production we need to go through building out the the infrastructure to make a release that we can install as a package because I had to go in and install this patch into the system Library System python libraries basically by hand um it's also Python 2.7 specific because it's part of the mailman chain right now and when we go to mailman 3 it's going to have to be Rewritten um in Python 3 either ported or or Rewritten so and there's still some question about how much of the the dmarc rewriting functional analogy we want to keep after"
  },
  {
    "startTime": "00:26:00",
    "text": "we make the mailman 3 transition anyhow so big problems that are still in front of us hopefully people have had a chance to read the bit about non-com eligibility calculations we've just done some improvements there we're in the process of adding a little bit more guts and conversations happening on uh with uh um Jay and Lars about how to count people that are registered in two different ways um we've moved wiki.ietf.org behind cloudflare um the getting the auto-generated cert in place at cloudflare took a lot longer than we expected when we did this last Friday when we moved chairs and authors we're going to proceed differently so that the honor that automatically generated certificates in place before we try to move real traffic over to it in the first place the iatf specific plugin that we have has been merged into a new repo that is building an image that all of our ietf specific instances of Wiki JS are deployed with so that when a new feature comes into wiki.js we just rebuild that image and all of the all the instances pick it up automatically there's a lot of text here about the data tracker I'm not going to call out anything specific if anybody has any questions about anything they see there go ahead and yell now going to say the same thing about bib XML the author tools the Whitetail website"
  },
  {
    "startTime": "00:28:02",
    "text": "nxmlrsc and mail archive and Ying catalog so hopefully everybody's read through this before and would have had any questions ready but I'll give it a couple of minutes for people to skim through if they haven't seen it or in before they got to the call is XML you keep having this problem I'm having a hard time hearing you Ross trout try one more time all right uh the problem with the foreign XML when is that going to get deployed the fix the problem with the witch name four name is what the field name it's the first name it it the parsing uh okay um off the top of my head I can't say I will follow up with you and find where that is in in the pipeline and know that we've got a series of um changes that ribose has made that are queued up for merging to be deployed so it may be fixed in one of those yeah I've been I've been watching the issue and it it is waiting merge or waiting release I forget which but it's it's breaking a whole bunch of X includes okay now I do want to move in the long run and got I sent the the note n to the um our swag that we need to get out of the game of trying to tear names apart and just have blobs and be done"
  },
  {
    "startTime": "00:30:02",
    "text": "so I mentioned earlier that the um we're working on getting this ability to map IMAP users in place it's not working yet but we expect it we'll have it working before we get to ietf 115. there is a conversation that's been started it was triggered by noticing that um our DNS SEC records for the ietf.org domain are using um the crypto algorithms that are no longer recommended we started a conversation about how we would change that to move what is currently recommended it has expanded to include how we serve DNS SEC altogether and right now we have a um a proposal that we're working with to move all of our DNS services to cloudflare and perform the algorithm configuration changes once we're once we're at cloudflare I'm expecting we'll start taking steps on that um again likely after ietf 115 be between 115 and 116. all right anybody have anything else that they want to talk about on today's call this is the um last time that we're getting together as a group before we get to ATF 115 I look forward to seeing any of the rest of you that are going to be attending in"
  },
  {
    "startTime": "00:32:00",
    "text": "person if you can think of anything that we need to be working on as the tools team between now and the meeting that we haven't mentioned that we're working on do please raise the issue so we can get some resources aimed at it awesome well thanks everybody for their time how did the call format work out today was it better to do the short read through and touch that we did no wonder I prefer this way right so so I I wasn't here last time so I don't know what happened last time right um but I'm not sure if I got so much more information than just reading the notes um I don't know maybe focus on the things that actually need discussion makes sense all right well thanks everybody again for your time and everything that you do to help make the ietf successful and I hope to see many of you when we get to London and thanks for the job done I'm going to talk to you soon"
  }
]
