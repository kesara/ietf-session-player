[
  {
    "startTime": "00:01:20",
    "text": "It's nice Thank you Using everyone, that's so funny"
  },
  {
    "startTime": "00:02:17",
    "text": "This one morning. Hello this is Mike working yet, Mike, hello Okay, there we are. Hello, everyone. This is the IETF 120 meeting of the question Working Group. If that's not where you intended to be you feel you can stay, but I would ask that everyone, whether you intend to be here or not, use the onsite tool to record our attendance since otherwise it doesn't count and this is also a how you will join the queue. So please do that that um so now starting off this is the note well it's late in the week, but we're going to talk about it because you never know when people haven't seen it before, but this is the rules and policies under which we all conduct at the IETF And so please read it if you have not and consider this and also the code of conduct and the anti-harassment procedures, since these are all taken pretty seriously here and so we would like everyone to be aware of them so meeting tips you probably know this by this point in the week but you can use the on-site tool. It's really important that you get in the queue And if we run any polls, that's will also be done through that tool If you are remote, it's the same thing, except for you obviously have the audio and video and keep it muted. And yes Administrative, everyone's favorite. We need a note taker we are not able to have minutes if we unless we have somebody who volunteers to take notes and we've already got martin duke. Thank you, Martin"
  },
  {
    "startTime": "00:04:03",
    "text": "Do you think you need, do you anticipate needing a backup? at any point? Yeah, so if anyone wants a backup, Martin's usually very good. Okay, thank you All right, we've got people. I appreciate this And so chats we will be using Meetecho slash Zulip. And if somebody wants, if somebody is in the chat and wants us something there for the mic, please try to get our attention and we'll try to convey that question The queue itself, we will run the queue. You can remove yourself if you want, but I will kick you out anyway if you forget, so it's up to you Agenda So as usual, we start with our adopted working group items In this case, we have substantial time to dedicate to multipathquick. And then we have some more time dedicated to Q-log. And then follow that, assuming we have time, we will have other items and that's Accuracy N. We're going to have a quick mention for H3 priorities and a fun topic about Quick Tokens is there anyone who wants to bash this agenda or otherwise recommend changes or other things? Okay, seeing nothing, moving on. So this is some general notes. We are looking for implementers for some of our documents specifically act frequency and reliable reset have both successfully concluded our working group last call, which is great But there's a sense that we need some more implementation experience before progressing these documents So if you are an implementer or you use an implementation, and you are interested in these features we would great appreciate that you spend some time implementing them and reporting what you find to the list because as of right now, we think that there needs to be a little bit more before bringing these documents forward"
  },
  {
    "startTime": "00:06:02",
    "text": "So some more sort of administrative we had a three GPP liaison request This was basically asking why are your security considerations blank in this document? That's scary And we have a response that we will show a little bit. Let me put it up, which is basically, yes, so they were blank but they have been populated and please give feedback to them So this is this response we sent to 3GPP If you're interested, this is recorded on the Datatracker So yeah, and to talk about the hackathon, I'm going to pass it over to Lucas Hello, yes, I'm a bit poorly, everyone, so I'm sorry I'm not in the room Oh, if my voice is weird. Yeah, I just want to do a quick kind of view at the hackathon We'll hear directly from the multipath quick folks about the interrupt there. You know, that's a working group activity and we do discuss those in this thing but there's other work that's happening that's quick adjacent. And sometimes unless you're directly involved in that work maybe you're missing out so just want to give a kind of a quick shout out to that those pieces of work too and to ask people to get in touch especially if they're more thinking from a quick impact want to give a kind of a quick shout out to that. Those pieces of work too and to ask people to get in touch, especially if they're more thinking from a quick implemented perspective or very much to focus on the transport layer to raise awareness for these other work that's going on so at the tachaton specifically, there are tables on meter over quick and RTP over quick, including some work on QLon on the transport layer to raise awareness for these other work that's going on so at the tachaton specifically there were tables on meter over quick and RTP over quick including some work on Q log that we did there was work on a lightweight quick for open thread I'm not quite sure how that went down I didn't get to see the presentation talks at the end either So if anyone would like to speak to that, that would be fantastic I had Mark's work on quick profiling for deep space We have Reese championing testing congestion control algorithms. That's not just quick, but some of the explicit work being done there was full quick And there were some interesting results presented for a specific extension to Quick"
  },
  {
    "startTime": "00:08:02",
    "text": "both at the Hackathon and in TSV I believe There's something I was working on, which was HP3 low-level testing I'll follow up on that somewhere some open source code to help some things less so specifically about quick but whatever but we also had some work going on on Quick on streams. If you recall, we discussed that last time in the meeting at matthew quick working group meeting we won't be discussing that this time but there are still people busy hacking and so the Quick-Go implementation had their contribution to our it there and there was interrupt with kazoo hoes quickly stack so those kinds of things can help in inform future discussions at the meetings. So I would encourage people, even if they're isn't adopted working happening in this group to just participate That's all, thanks Okay and with that I think we are moving on to our first slides, which are the multipaths You can either try to do the control yourself or just tell me what to move them. Yeah so can people hear me? Yes Yeah, yeah, good. So let's start So I'm Yama and today, Mia and I will introduce about the multifacist extension updates and the left issues. Yeah, first I will give a brief summary about the changes from Dr. 06 to Dr. 10 and also about the Hacker's report for Dr. X10 brief summary about the changes from Drought 06 to Drought 10, and also about the Hacker's own reports for draft 10. And the Mayor will introduce about the open issues and the pool requests which need discussion And that slide, please"
  },
  {
    "startTime": "00:10:02",
    "text": "So first about the draft Darrow 7, the draft Darrow 8. First of all, we have merged the explicit PASID proposal from the LASDA IETF. We have a job Darryo 8. First of all, we have merged the explicit PASID proposal from the LASDA IETF. We have a draw conclusion about that. And then we have a clarification that the both endpoints should use the same PAS ID from both sides And about the pass, max pass frame and the past abandoned frames we change them later in draft zero nine so I'd like to introduce them in the next page So next slide, please Yeah So from the last IETF, we have inter-meeting about the draft zero nine Actually, we have draw a conclusion from the interim meeting that we can use the web value for initial mass pass ID instead of the max pass counts for the transport parameter So we have done the update and all we have changed the max pass ID free for the same semantics and I'd like to second martin thomson for pointing out this idea and also helped update the pull request and help review the last word I'd like to second martin thomson for pointing out this idea and also helped update the pull request and help review the last worship. So big thanks to him yeah and also we rewrite the pass closure section and point should send pass abandoning in each scenario as a signal for the pass closure and also endpoints no necessary need to send the end retire CD for CD's belonging to this pass And also we add recommendations to use the pass ID continuously And also we have other editorial changes and yeah we have the first update for the Security Council consideration section about the potential attacks"
  },
  {
    "startTime": "00:12:02",
    "text": "and how to prevent them Yeah, next slide, please please About the updates for Drafton, post changes are more editorial changes We specify the details for the MP retile connection ID frame, and we also renew the ACK MP frame to MP ACK but we don't change the semantic. And also, we allow the multiple passes to use the same for double. And about the limitation, for initial max pass ID, is for the security consideration for the AED encryption and decryption and also we have more guidance on the past status So other changes are both minor editorial changes So next slides, please Yeah then we come to the heckastole show. This time we have three clients and four servers participate in these times Hacker's show the hackathon. This time we have three clients and four servers participate in this time's hexagon for draft 10, and we have 11 cases. This time we add CID retire case and also migration case for this time episode. We have Joe nearly 14 four table for this time's hexon, so I would like to see that everyone is doing a great job Thanks for all your efforts So next slide, please So I think the next part is for the issue slide I'd like to switch the micro to Mia Do we have a mic at the front? That's not this mic. Is that mic? Now? Okay. Yes. Hi, my name is me. Kulewam First of all, for the updates with it, I want to say thank you for everybody who opened issues, provided feedback The one thing that we didn't update is the acknowledgement sections"
  },
  {
    "startTime": "00:14:03",
    "text": "We will do that and put your name in there. Thank you anyway. We have made like a huge amount of progress I don't think we have like any big issues anymore So what we will try to do is go to the remaining issues which might have some kind of design implications and I think we have like something like 13 or 15 issues and our hope is if we can run through all of them today quick then we are only left with like smaller editorial stuff and we're actually on good path here so let's start It's really weird to stand behind this thing here, but okay Okay, this is supposed to be an easy one So let's make it easy, hopefully We've been thinking about renaming the frame because they have been named inconsistently and this is, you know, we can roll a dice or whatever but we have to decide something. So the proposal was actually to instead of using MP for everything, we actually just use pass, which is kind of more aligned with what we already have an RC9-7 9,000. So anybody has opinions about this? or should we actually roll a dice? To rename? Was this a yes to rename or okay? Easy Easy, next roll a dice? To rename? Was this a yes to rename or? Okay, yes. Okay, easy. Isn't Max so on? or? Okay. Yes. Okay. Okay. Easy. Next. Isn't Mac so-and-so more in line with RFC 9,000? Sorry, say it again. Isn't Max so-and-s-s-and-s? more in line with RFC 9,000? Sorry, say it again. Isn't Max so and so from a Max Path ID? Doesn't that line? up better with RFC 9,000 names? I'm out, forget something I don't care Did you have a similar comment, Christian? Um have comments you can have it, but we just need rain, we name it okay. Then next and this is also about name So this issue was a longer"
  },
  {
    "startTime": "00:16:02",
    "text": "discussion and the original issue was you now can actually already a few versions ago you can actually send past status frames, so there's a step past standby or also paths available for pasts that are not actively open yet so you have issued connection IDs belonging to a pass ID and you can provide a status frame for the even they are not used yet then And that can be confusing because that means the other end, you know, has to pick some of them and then has to accept whatever the status is but you can also update the status at any time. The use case is a little bit for example, if you want to guarantee that you have only one, available PASS and everybody else every else pass isn't standby, you can only issue new PERS IDs that are in standby available pass and everybody else, every other pass is in standby, you can only issue new pass IDs that are in stand by. And so you can guarantee there's only one available pass that is like the preferred one. That's for example the use case But, you know, the whole point is it gives like some flexibility, and that's probably all fine the long discussion on the issue ended into something saying actually passed then by is really confusing we should name it pass back up so we can do that Yeah, really excitement here any thumbs up yes okay let's do it next. OK, that was like the warm up and now we see if we have like more interest here Okay, this one should also be easy, so there was an issue by open by mike bishop, I think, saying the preferred address is not very clear. So we have a new PR there that is trying to clarify this. And what the new PR says, is that you, if you have disabled active migration that means you're not allowed to actively migrate on the path that uses the initial local address from the peer, but you're still allowed to open a new pass and you also then can migrate on that pass and use migration or you can migrate on any other pass so I think this is in line with what the original"
  },
  {
    "startTime": "00:18:02",
    "text": "use case for this is which is like you send something to any cast address and then you want to move it over to a real address So that is only kind of a line, the only is important for like the initial address you're using for sent that but not for any additional addresses that you might use to open and pass. So that's kind of what we clarify, but we want to double check that this is like the only use case and that's the right thing to do so the PR is ready and we can merge it, I think christian huitema. Yeah, I see think that that issue is indicative of something that we are doing that is maybe not explicit Is that the multipath extensions are pretty much taking over the past migration that was in 9,000 and the disabled active migration was actually linked to the old way of the immigration. In multipass, you can only do migration. If the peer has given you permission to open you pass explicitly by providing pass IDs. So I think that we may have some you bus explicitly by providing past ideas. So I think that we may have something there which is still in how much do we keep of 9,000 and how much do we? jettison? I mean, you can also only do migration in 9,000 if you have a connection ID that you can actually migrate to So it's like not that different in that sense But I think there is definitely a point about being more clear about what's migration, which means changing something on one path and what's like actually multiparse, which means opening another person. I think we can be actually auditorium more clear about this in the draft as well. Yeah, and so basically, I think the conclusion that we don't do migration on pass zero If there is that, it's cool And if the peer wants to prevent my"
  },
  {
    "startTime": "00:20:03",
    "text": "migration on pass zero and yet allows you to open pass one, that's what he said yeah okay Okay, perfect. Next one So this is one of the design issues that is open for quite a while, and I'm not sure we have like full agreement, but here that's, here's the proposal So the question is should we use the multipass specific, should we put a show? in a normative should to use the multipar specific and i think this also applies to like multi-pass-specific connection ID management for par-zero and should we recommend to use also these frames for pass zero or could you also be and should we recommend to use also these frames for pass zero or could you also you could also use the old ones from rc9000 for pass zero um there was a bunch of discussion here Some people say they want a must because they don't want to implement the old ones anymore however you need them still kind of in the handshake. As I say, this should be rather may because there's actually benefit of using the old ones in the for pass zero because it saves your bite and so at the end, I think we just keep the shot should and everybody does the right thing, hopefully. So that's a proposal proposal This, go. So my weak preference is doing master because in the application in the application in the application pocket number states we can always use one form and that's probably more consistent in my view, though that's not a strong opinion. I wouldn't mind if people think anybody have a strong opinion I think Jan Mai, you were kind of more on the May side, right? Do you want to speak up?"
  },
  {
    "startTime": "00:22:02",
    "text": "Yeah. Yeah. But actually I don't have a strong point on the ACMP frames but I do think that for the CID retirement and the new CID frames, the initial pass could use the frames from IFC 9,000 so it would be more compatible But for the ACKMP frames, I don't have a strategy opinion on that So I think if nobody has a strong opinion, we just stay with the shoot There we are, Christian Mike, I think, first Yeah, I mean, you have to hand the legacy frames during the handshake so I don't think there is a good argument for me first. Yeah, I mean, you have to handle the legacy frames during the handshake, so I don't think there is a good argument for must to prohibit them later So if you, if either type is acceptable, we can give guidance with a should, we can just say may and let implementations work it out It doesn't really matter so long as if we agree we have to be able to support both, then should or may is the same. It's just what applications decide to do christian huitema, I think it's tight to what we can do before the uncheck is complete And if we are very clear that we are never going to use the past the new frames in zero RTT packets then we can have a must because there is no situation in which you can send one RTT packets and you don't know the state of the negotiation Yeah, it could be a must. It's just a question if it's useful And the value I see with the must is that it's one less code pass in many of the code And one less code pass means you don't have to do two series of tests instead of just one etc etc it's it makes the it makes the"
  },
  {
    "startTime": "00:24:02",
    "text": "of the code simpler I mean, does it really because you still need to support RC-9,000, right? No, no, it's basically once you have negotiated multipaths you can have basically a cutpass that says if I have negotiated multipass, I only do this And you can have, and also way of doing that is if I have negotiated multipath I do this or I do that So that means if you negotiate multipass, you have a mask, you actually ignore the RC 9,000X and Is or ignored? If you have a must then it's not an must, then it's a protocol violation. But then you need also crop my path for that, right? You have to detect it and then Yeah, but it's basically it's easier to test. It's easier to test and you have to write fewer tests i have no opinion at all Cheers I don't think that I mean Christian makes a point, which is that maybe this is slightly easier for an implementation to hand if there's a must there, but it doesn't sound like the group. Is anyone else who's in? implementing this have that same opinion, or is this? like is that going to help implementations? significantly? I will remind you that a much obviously does not really make it so that everyone will do it. So you'll have to write code that to then detect it and all that But, so Is this basically the same point in Casual was making It's a weak preference because it does make your cost a little bit easier But you can tell me it's just God, we can do that, right? Is anyone opposed to? a must that is maybe slightly qualified and remind"
  },
  {
    "startTime": "00:26:02",
    "text": "that, you know, you have to have it for the handshake? Sounds like we just don't care for the most part um i don't i don't think the argument for a must makes much sense but I think it's fine nobody's gonna die on the seal i think Yeah, just to give my two cents in my implementation, implementing both is quite simple, so actually I can keep it as shoot. I think it's fine But I would prefer having a must because we need to support I can employee I can use you Okay. Wait, so just because I was prefer a must I didn't quite catch that, okay It sounds like people would not oppose a must and some people would like it, so I'm kind of inclined for a must at this point. That's kind of the sense I'm getting Do we want to vote or is it? Do we want to vote? I guess we can make a poll but Actually, can you do it so we can, we have it on record. Yeah, okay We will make a show of hands for this, which is going to be, let me get the title marten seemann is in the queue and he just walked in the room Yes, as a point of reference, the reset stream ad has the same problem and we decided that we can use both frames there so my weak reference is as should or me When you say we decided, can you remind me?"
  },
  {
    "startTime": "00:28:03",
    "text": "if the working group decided that and we had the same bike shed there? or did we not? No, this was this working group. Yeah, no, I know, but did we have a, was that? in this room and we, I would like the same sort of? Yeah, so the reset streamette has an offset field, right? Yeah. And in the case, where the offset is zero, it's equivalent to the RFC 90 do we have a, was that in this room and we, I would like the same sort of? Yeah, so the reset stream, it has an offset field, right? Yeah. And in the case where the offset is zero, it's equivalent to the RFC 9,000 reset stream frame. And we said we can use both okay well i'm going to do a show of hands just because you know yeah just because what's are so much fun and then we have it on record and to make you all wake up So also maybe just to confirm, if you do a mask, that means if you receive a one of the old frames, this is a protocol error. You have to close it also maybe just to confirm, if you do a must, that means if you receive one of the old frames, this is a protocol error. You have to close the connection Okay, so I've made the show of hands, even though I could not see what i was typing um frames, this is a protocol error. You have to close the connection. Okay, so I have made the show of hands, even though I could not see what I was typing. So this is yes, no for must Because I did not want to put sure in the must question, so so Oh yes, it's catching up, okay"
  },
  {
    "startTime": "00:30:02",
    "text": "I'm disappointed in the bike shedding here Thank you we're trending towards random.org decided here Okay so that was conclusively inconclusive and I think we're just going to have to pick one so... Should Okay, well should? OK. Well, all right. I guess we're going to have it be should, but yeah, so we'll move on from that one So yeah, we can add a little bit more guidance about why this is should and when it's useful or not useful, whatever, if somebody wants to write text But yeah, okay So we matched our already PR 400, which now says you can, or like, which removes the restriction that you can only have one pass on a four table because that restriction is simply just not needed anymore with the explicit pass ID However, there might still be use cases where one of the endpoints maybe only wants to have one path on one four chapel and then an endpoint could decide to just close the path, it's easy. But the only problem is like if both of the endpoints decide to close the different passes, you might not have any pass anymore But maybe that's not our problem So the only question is, should we give any more guidance on any more discussion about that? The other one is a little bit related to congestion control. If you're using multiple paths on the same four chapel that it's usually the same path, the same link or whatever could be, doesn't have to be, should be say something about congestion control? So as I said, this is already merged in. You can use multiple paths over"
  },
  {
    "startTime": "00:32:00",
    "text": "the, multiple paths over the same four table but should we say more is the question Magnus yes I think one of the one reason I see for using the same four tupper, potential is to actually have different different different one reason I see for using the same 4-toppel potential is to actually have different diffsercode pot, and then you actually have the separation that they are to routing while, rather treatment-wise the two different paths even if they're on the same four topple so I think, think is one reason where one might be habitability be little careful here. And do you think we should talk about this? in the draft or we just don't need to say anything about it? it? I think it's worth mentioning uh as a reason why different endpoints can have different views if they try to do something like that because that's not explicit until you have to see PAC packets over the path and if you're looking at the DPC code What's the last Akamai I think we should add what Marcus, what Magnus suggests because when I came up here, my response is going to be, why would you do this? And now hearing the reason one might want to do it I think it's worth putting in just to avoid the reader having the same initial reaction idea alessandro ghedini Cloudflare I don't understand what the further guidance would be, though Like, do you just say, don't do this? But then there's no way for like, don't try to close the same, the two parts at the same time but then there's no way yes I mean like you could try to deconflict this like formally or whatever I think the minimum we could say is, for example, if like the other end"
  },
  {
    "startTime": "00:34:00",
    "text": "opens a second pass on the same tappel, rather close like either the old one or the new one so you know there's like some kind of guidance guidance Okay. Yeah, I think we should write this the conflicting rule but we have to remember why people do that And typically people, the reason people will do that is because the four topples doesn't discuss entirely what's happening on the path You have also things like the IPV-6-free ID, maybe the question of service thing you might have some local preference preferences So it's not clear. For example, if you have open one pass with a flow ID zero and no QOS and the other pass with some definite CLO ID, flow ID, and some QOS, I mean they're not equivalent. So it's pretty hard to give definitive guidance, say, you shall always close number one and number two Do you anyway want to try to write something? Question? I will write something like just what I just said is basically you have to understand why you are doing something but it definitely sounds like people want more guidance, so we will work on it Gary. Yeah Gori. SRV6 and other things as well which means that the sign fortable isn't necessarily the same fordable i mean i i i necessarily the same fortable. I don't think we have to go overboard here. This is just kind of pointing out that there are other things apart from that portable which can make separate flows The other kind of guidance could be if somebody, if the other end opens more than one pass on the same topic, don't do, don't close anything, please right right just wanted to say but as i said and"
  },
  {
    "startTime": "00:36:02",
    "text": "with my example being matthew quick away amount multi-passing doing the collising the port numbers Okay, error codes, yes So the question that was like, I think we changed this a few times but we still have like four cases where we use error codes and we use four different, three different ones. We have a multipass specific protocol violation We have tensile perimeter frame encoding So I think like using the ones from RFC 9,000, we got straight now. But the open question was still, do we need this like multipass-specific? protocol violation or can we just remove it? and use the normal RFC 9,001? Or alternatively, in this case in the first case that it is here where like you try to negotiate multipass but you don't put a connection ID in which like the doesn't work. Do we want to have an even more specific? error code for this case so you can detect it quickly so that's the two options do not three options actually do nothing remove the multi-pass specific error code or define any one Alessandro Gideon in Cloud benefit of having a specific error code is for debugging maybe, but then I don't know that this specific one is actually that useful in practice So we can, like I don't care that much, but if we remove it, that would be fine fine The casu nodding, then we just remove it Okay. Just a quick question. How much? do we know how many cases there are in the document that would result in a protocol violation? Absolutely. There's two, okay"
  },
  {
    "startTime": "00:38:00",
    "text": "it's a, okay, so it's a, it, from a debugging stamp standpoint, it would not narrow it down a ton Okay Okay Okay, I'm Martin Martin, do Google I mean, I don't care that much. I'm not implementing it, but like we have two to the 62 error codes So like if there's any possible scenario where we're like, you know, you're, you're debugging problems and it turns out there's something, this is for RC 9,000 violation versus something that's actually related to the new stuff that we're debugging, that strikes me as useful, but again, I'm not an implementer. I don't care that much, but like, why not? have more? Well, the reason for why not have more error code is basically a trade-off between debugging and enabling attacks If you are, say, writing a further against somebody's impression the more error code you have, the better it is because now you know what kind of area in your target's code is buggy So you have always that trailer I don't think that having MP protocol violation is a big issue but I also don't think that we should have fine grain error codes If you want to enable debugging, you always have the possibility to use error threads sentences, as comment of your error code during debugging. And you can remove that when you're not debugging If I could briefly respond out of cue Yes, that's convincing. Thank you. I withdraw my comment okay so we remove it perfect next mic"
  },
  {
    "startTime": "00:40:00",
    "text": "If I could briefly respond out of queue. Yes, that's convincing. Thank you. I withdraw my comment. Okay. So we remove it. Perfect. Mike, do you still want to say something? Oh, sorry I was just going to point out that we do have a connection ID limit error in RFC 9,000 So I could see having the equivalent path ID limit error but we could also just read that, have MP protocol, protocol violation I think Christian comment is convinced for why we might not want to, and that's fine Okay, I think we still remove it Okay, this is also related This is the pass abandon frame that we newly defined in this document It has an error code, and we don't say much about this error code And the question is just that we newly defined in this document. It has an error code and we don't say much about this error code. And the question is should we use application protocol error codes? And yeah, what should we say here actually? I think this was your proposal question, right, to use the application protocol error codes Lucas I don't understand why this would be an application error so why would I use application codes? Because it's it's closing a path, right? So that's usually an application action Oh, sorry, the application codes of the application mappings so something related to hd HTTP 3, for an example you know something an error in the application layers additional framing on top of quick for example. On top of that, you'd have your own application layer signaling such as status codes or other things things yes the action of abandoning a path might be powered by an application, but I don't see any reason"
  },
  {
    "startTime": "00:42:02",
    "text": "we would use those codes myself So, yeah, because we discussed that and the discussion is, that basically we could, in theory, split the abandoned frame the path abandoned by the network abandoned by the network pass abandoned by the application the same way the connection closed as a bit in the frame type that says by the network, by the application However, there are very few cases in which we have a network reason a protocol stack reason to do, to use the close by the transport rather than close by the application And I think it's simpler to say the response code is always chosen by the application unless it is zero and if it is zero, it can be used by it it's simpler to say the response code is always chosen by the application unless it is zero, and if it is zero, it can be used by the stack as well speaking as an individual in the queue so christian are you suggesting basically that an hypothetical MP quick specific application would define, for example, I'm giving up on this path? and I want to tell my peer application that I've done that and that would be encoded in this frame similar to like how an application level close would be used or an application level stream error yes Gizuho Because I could be wrong, but if I understand correctly all the number space of application protocol error codes are reserved by the application. So if we say that this field can carries an application protocol error code, then we would essentially be forbidding the transport layer to send this frame"
  },
  {
    "startTime": "00:44:02",
    "text": "No, zero isn't, we can reserve zero or any number So I think the question is if you want to go that path or not Yeah, I'm still speaking as an individual. I should have clarified the first time mind Yeah, like I think this is, this is going to call issues because right now I can kind of port my HP3 app to use multi- without any changes to my HAP application mapping whereas this this seems to make me feel like I need to now describe how all of the error codes map to some path related things and that what the client or the server need to expect if they they receive this frame and the they need to bubble this up to their equivalent receiving peer like it just sounds like it's going to open a can of worms to me and and i don't see the benefit in it need to bubble this up to their equivalent receiving peer. It just sounds like it's going to open a can of worms to me and I don't see the benefit in the first place So would it be okay to just maybe remove the air code at all? Yeah, okay That was actually going to be my suggestion I can't think of any existing error code in a remove the error code at all? Yeah, okay. That was actually going to be my suggestion. I can't think of any existing error code in H3 that would be the reason why we closed a path. Either we're going to close a screen or the connection, but path aren't really affected by the things that are happening at the application data layer other than maybe exchanging what you're endpoints are so I the application data layer other than maybe exchanging what your endpoints are. So it seems to me that debugging is the only reason for the error code, so maybe we might want to leave the reason phrase, but I don't think this is going to carry much value most of the time Do we still know? No, I was not sure Martin was doing. So Christian, so would you? do you think that this is required for?"
  },
  {
    "startTime": "00:46:02",
    "text": "like a multi-path applications to have success or could this? sort of semantic of a application that has an application reason to abandon a path? could that be added later or do you think you need this in the base spec? I'm kind of convinced by what I heard in the discussion okay i says well right now the application doesn't act actually want to provide a reason and one probably to delegate that always to the protocol stack, in which case, the protocol stack, will use existing protocol errors, like no error is just normal thing or maybe it's out of resource maybe it's something, but that's fine okay so basically it means there's no ambiguity And the first priority is that there's no ambiguity and we say this error code is defined as a quick error code. It's not an application code. Or no error code at all I can see a difference between no error and I just run out of this resource, which exists I mean, internal error. Yeah, not as an implement of MBQ, but just quickly saying, like, the almost feels like it's similar to, like, you would have connection close type things that aren't fatal to the entire MPQQ connection. Like, oh, my socket. God, because junk. And I don't want to, I still have a good ones, but I, would have connection closed type things that aren't fatal to the entire mp quick connection like oh my socket got became junk and i don't want to i still have a good ones but i'm abandoning this path for that reason yes next that could be useful to know yeah but I mean I yeah but do you so do you need to have standardized error codes or so if it's for debugging? the reason phrase would be enough, right? Do you think it's useful to have it? in a normal running? I mean, let's see basically what I said before. It's an error code that that will help you do"
  },
  {
    "startTime": "00:48:02",
    "text": "debugging but then use so so basically you either want to have some of it or not and well, we could have no error and no phrase and the phrase is simpler. I am not sure that i mean all the equivalent frames like stream reset or connection closed, do have an error code to explain why you do that So what would be the error code? One is like no error, and the other one is out of memory, whatever, I don't know even what cases are. There is definitely no error and definitely out of resource internal error. There's another case again, jumping slightly, but like the thing I'm thinking of is like, let's say your peer, is repeatedly encountering a certain kind of error on this socket, and it's kind of, you know you could use that potentially as a signal of like, oh, maybe I should stop establishing this path because they keep abandoning it for some reason and that could be encoded in an error code, whereas putting that in a reason is not semantic. So if you're having trouble with a socket, it's not exactly resources, but it's like But you can always retire basically pass IDs and not issue new one, so you can stop the other end from opening new parts. Right, this would be more like an advisor advisory You're saying, yeah. Yeah. Okay, I think what we have decided is it's definitely, if there is an error code, it's definitely a quick error code let's see what martin has to say I think having, sorry, having a reason phrase feels a little bit heavy for this frame We don't have a reason for a phrase for reason streams, and there's a bunch of validation logic I would need to do in my stack to actually support a reason phrase like I need to make sure that that length doesn't overflow the packet and what do I do if it's not a valid UGF8? There's a bunch of corner cases. We have those for connection closed, but for connection close you don't care because the connection"
  },
  {
    "startTime": "00:50:00",
    "text": "is closed. So I'm wondering if we could get away with just having an error code and we can have a separate error code space that's independent from application errors and existing quick errors and then we can just define a few values. One of them could be the application asked me to close this path and the other one is like the interface is unstable. And I'm sure we can add a bunch more works for me Anybody? wants to keep the reason? phrase? No This one was proposed by mike bishop to add a new frame Max Pass, blocked, so this is kind of modeled after also how we handle strut in RC 9,000. And currently we say basically implicit if you if you increase the pass limit, that's also implicitly a signal to the other end that you probably want to have more pass IDs. And this one is like an explicit signal to exit actually provide this information to the other end We have PR ready to be merged but we want to confirm that the group wants to add another frame. Martin Frame sounds good to me, but can we change the name to path blocked instead of a max path blocked? It's streams blocked and not max stream blocked in 9,000 I think we can Okay, nice. Next So pass standby and pass available have a sequence number. And in this case, it's a per pass sequence number So if you're using them for a certain pass ID, and you send a new one or for this pass ID you have to increase the sequence number"
  },
  {
    "startTime": "00:52:02",
    "text": "for um for um an issue and connection ID we actually use the sequence number globally for the whole connection and here we use it per pass, which is fine, but we could do one or the other for any of these So there is a PR out there that proposes to instead use like a connection wide sequence number so no matter on which path you're sending a pass-stand-by-a-pass available you increase a sequence number. The only difference really is it's like kind of who has to check to which path it belongs, is the sender or the receiver Yeah, so both are good solutions It's like a matter of taste. We just have to decide decide Alessandro Gideon, Cloudflare I don't see that much benefiting doing this I'd rather keep the next Okay, changing it. I mean, not changing it Like, it doesn't seem like it makes that much of a difference and I'd rather not, you know As a Hulk, I prefer having consistency among the, among how number spaces are being allocated. Either all of them should be pro-connection or all of them should preferably be preferred proposed or all of them should uh preferably be so that means we would need to change that one because i don't think we want to change the other one. Yeah. Okay, now Direct me if I'm wrong, but these are only ever processed in the context of a given path. So it seems like you could implement it either way you want and so long as they are monotonically increasing within a path, and it doesn't matter if you skip any so long as they increase. It also doesn't matter if"
  },
  {
    "startTime": "00:54:02",
    "text": "they repeat so long as they don't repeat on the same path i'm not sure that we need to specify this so precise how you implement it. No, I think you have Either the sender has to, like, either you have to like a global number and you have to increase it all the time, or you can use the same number for different paths, right? So, like, you have to say something I think if you say that, then, that it can if it is has to increase per path and someone wants to have a global number, it will still be compliant That's true So I feel like maybe we don't want to over-specify that yeah maybe that's a good reason to keep it as it is Okay, no change I think is a decision Okay, so this is an issue about the tokens. It's so I crossed this out because we, I think we already agreed there's no violation of RSD 9,000, but currently what we say is that this is the text in the current draft is that if a server issues a token, it might be used to validate any of the passes. So effectively, you get a token, you don't really know which path this token belongs to, but you can use it next time and it might either work, it might not work But you know, that's life anyway, so you get a token and it might not work, no matter what But the only question is, like, should we actually remove this? ambiguity and say it has to be validating? all the passes and you can use it in any of the addresses? addresses I mean, it might still not work right? Something has changed and then it doesn't work Mike. I don't think we want to mandate what the server must put in there"
  },
  {
    "startTime": "00:56:03",
    "text": "Just said that the client should use the most recent one and it probably should validate all your addresses so far, but nothing breaks if it doesn't Okay, so effectively we could give more strong guidance that in bed case it applies to all the past okay there then a small editorial PR thing We can do that So this one has a PR There was a very short section on which was called refi We can do that. So this one has a PR. There was a very short section on which was called Refusing a Pass. It basically says kind of if you, it did say, if you don't want to open you pass, don't reply to a pass challenge We since then changed the whole idea about how we close paths a little bit because we say effectively because we multi-pass, we always have still one active pass. So it's always better to be explicit about closing a pass. So if you get a timeout, we now recommend to send a pass, or we actually require to send a pass abandon and if you want to refuse a pass, even so like from your side, the past does exist yet, you should still abandon this pass to make sure the other end understands that it cannot use this path anymore it's gone and you will not do anything about it it's always better to be explicit and you can be explicit because you have an active path where you can just send these signals So what this PR does is just removing this section and just incorporating some text in the closure section saying you also have to send pass abandoned frames for passes which are just to be opened and you don't want to have them. Any concern? about that? Perfect. Next Okay, so that is, the next one is also related to pass closure in that exactly this thing what to do on idle timeout so the part that we decided already is that even on an Imit fidler timeout, you shouldn't send a pass abandon. But the question is if you get dan fidler time out, do you actually have to close the path?"
  },
  {
    "startTime": "00:58:00",
    "text": "Or is the idle timeout even useful? in multipass? Because in multipass, you very often have the same scenario where you open, like, your backup or standby path, and your not using it, and you're just having it there in case you need it later because the other path is breaking. And of course, you can send keep alive on that path but especially on mobile networks, waking up the radio and so on to send Keepal Lives is, might be a big barrier So, and then if you don't do anything with this pass, it will actually idle out. And then currently we say you should not use that path anymore but effectively there's no reason to not use that path anymore. Of course, it might not work anymore. You have to test it but like you also don't need to close it And so we have to probably just change this should to a may here or not use normative language and maybe provide a little bit more explanation if that's okay for everybody Alexandra Alessandro Gideon, Cloudflare. I mean either you say, you know, after idle timeout, you must not use the path, or you have to do path upon, like, you can't do both, right? You can't have the applications just right after idle timeout, you must not use the path, or you have to do path upon, like, you can't do both, right? You can't have the applications just try to guess which one to use so either you have to do path abandon or you have to not use the path after the timeout. You don't, you can't just say, you know, you may send path abandoned because then the other side doesn't know so this thing is like if you want to close the path, if you decide there's the idle time out and you haven't used the path and it's not useful anymore, you don't want to use it in future anymore, then you should close it and then you should send a path abandoned, right? But if you get it, I don't idle time out and you haven't used the path and it's not useful anymore, you don't want to use it in future anymore, then you should close it and then you should send a path abandoned, right? But if you get dan fidler timeout because you're not sending in a pass, but you actually think is it still useful path? and you want to use it later in case the other path breaks, then you should not close the path and you should not send a path abandoned So then what is the point of idle time out for the So if you are still going to, you know abandon explicitly? So I think the idle timeout, first of all, it's just there But it might also still be useful to understand"
  },
  {
    "startTime": "01:00:03",
    "text": "like, what the state your path is in. Like, if you are for the idle time out then it's probably you can just switch over immediately if you are past the idle time out, then maybe the risk that the past is broken is a little bit higher or whatever, and maybe you want to like be more careful about using it, whatever. I don't know. We just remove the idle time. Yes, we can also do that I think so the point of the idle timeout in quick v1 is so that you can close the connection silently and automatic if you don't have anything else to say from it other side. So I think there's value in the entire connection being able to idle out Yes. So we need it for that You need a connection I think something that says if all paths have reached their idle time out, the connection is closed. Yes. We need that Yes, true. I don't think we need anything that says if a particular path reaches its idle time out, you must do something. If you just decide to close a path because it's idle, you should include a path abandoned the next time you're going to send a pack I don't think you should start up to send the path abandoned because then you reset the idle time out on a different path just to say, hey, this other path was idle Okay, so yeah, there's actually two cases. One is like you have already a pass where you're actively sending data and then you can send it immediately And then the other cases, you have like only process with you're not sending anything at the moment, and then you should not just wake up the pass for the right yeah that makes sense We shouldn't wake up to send the path abandon if you if you're going to close the path cue it to go in your next packet packet what mike said but which is clear is that we all agree that if you decide to not listen to a pass anymore, you must tell that"
  },
  {
    "startTime": "01:02:02",
    "text": "to the other to the other peer to not listen to a pass anymore, you must tell that to the other peer. You may take your time to tell it I mean, the consideration about not starting the video are great, but you must tell it The question with had was not so much the must tell it. That was it are great, but you must tell it. The question we had was not so much the must tell it. That was, it's not ambiguous. Everybody agreed that if you close some something, you must tell the other guy. That's clear The ambiguity was, if the peer knows that you are doing timing on pass and the peer wants to make sure the pass is still available, the peer is going to send bubbles on the pass to make sure it's still there It will send those bubbles at the interval that is chosen by various algorithms The question was, do we want to have a mean to say, hey, if that past does not see any activity in 49 seconds? I am going to close it Because if we say that the number is 49 and not 42, then that means that the peer has to make sure that it's sends the bubble more than once a minute So basically, do we want to? help people implement? this Keepal Lives in a coordinated way? So if you want to send Keep Alives, then you can use the idle time model and you should send it earlier than the idle timeout? right? But like, I think that's not the complicated part the other one is like do we want to really require everybody to send, like, keep Alives on a path, or can we just keep on? No, we never want to require people to send keep a life Never. That's we don't. It's never a requirement We know that people will do that Yes, that's fine. And the question is,"
  },
  {
    "startTime": "01:04:00",
    "text": "if, for example, they will do that, they have to do it in a useful way And to do that in a useful way, they have to have an idea of how long the peer is waiting So by default, we are going to say, what we have in the dock today is say, oh, how long the peer is waiting? shall never be less than the idle time that you have published for the whole connection so until the idle time out you can be sure the other one shouldn't just close it. So basically, if you tune something, you base that on the global timer And I think that's okay And I think that we don't need the complexity to say, oh that particular pass, I'll close it after 10 seconds if don't say any other one That's, I don't think that we're past specific information. No, no, no. But that's, that was the only, the only thing that was still open, in fact i wouldn't say the, so the other thing that's still open is, can I, if I, if I, if the, I did not expired, I didn't send any keep alive and it didn't get a benton frame, can I still use the path? And I think the answer is yes Yeah. If you have not received the pass abandoned from the pier, you can use the past. That's on the big use. Okay. Okay So I think we have to remove the sentence and maybe provide more explanation to make things with crystal here Yes, okay. And I don't think actually we need any normative language here because that's just the way it works Okay. Okay, so I'm coming at this from just a familiarity with idle Idle Idle clothes on normal quick I at this from a just a familiarity with idle Idle Idle clothes on normal quick I'm finding this all rather confusing like it seems that you have one set for also one thing and a completely different set for paths and what I like this silent closed feature. I like the ability to after a well-coordinated fixed point in time to blow away state, regardless of which pair I am I think that's a benefit of quid compared to the transport protocol"
  },
  {
    "startTime": "01:06:02",
    "text": "What I'm hearing here is, like, oh, it's not, you can kind of set this value and it doesn't mean anything um maybe i'm misunderstanding i'm not I'm remote and I'm not well but like yeah I'm going to take a look at this issue it might have comments that don't necessarily reflect what was being just uh I'm misunderstanding I'm not I'm remote and I'm not well but like yeah I'm gonna take a look at this issue it might have comments that don't necessarily reflect what was being discussed just now so the if I understood you correctly the difference here is that we say you always have to send an explicit signal. So if you want to close the path, there should never be this case where you're like not sure of the class passes there or not, because you always have another act pass, so it's always better to be explicit about closing a path And therefore, you actually don't need to just like close the path on dan fidler timeout and have some guesswork, because you will tell the other end if you close the path. And that's different if you could if you close a connection or if you idle out a connection because when you idle out a connection you don't have a communication to the other end anymore to tell them about it maybe but it makes me wonder if you could keep a path alive by sending a signal on a different path If you want to avoid keep alive, it's on that path so again i'll take it to the issue Interesting. It seems also a little bit like overhead to me, but we can think about it, yes. Yeah martin thomson, I think what Christian suggested here is the only sensible thing to do. The idle time matters about the connection state, not about the path state And you have explicit means to signal path state, use them. I think that's a reason conclusion here. Using idle timeout to mean something else is, I think, an abuse of that mechanism. The idle timeout says, if I don't hear from you for this long I'm no longer there It's a connection level thing The path keep alive and whatnot entirely independent of that. And overloading that, I think, was a mistake Yes. Also, that sentence doesn't make sense to me So double win. I agree That's actually a good point"
  },
  {
    "startTime": "01:08:05",
    "text": "Tengi this one, for the idle timeout part, I think Mamiya, you mentioned about the mobile service narrative here. Because, you know, the mobile UE equipment equipment, want to lower conceptual power, always So every some time, if the active, is low or does not want to receive anything going to put in itself in some specific mode, called RSE inactive. So if we use the Keep Alive for this type of things, that means every sometime the mobile system, the core network has to page the UE to force it to do something actually doesn't want. So, you know, my suggestion here is like using the I don't time out but now the keep alive, those type of things But I don't know what type of, you know, the number, like a the tip, you know, to use here but it's just the suggestion from the mobile work We got this type of, we try to avoid the situation to be paged, you know, every some time. So thank you Corrie, I think we much and much said something that was useful. I think there's maybe a slight mix up between the whether the reward endpoint is alive and whether you want to keep the path active for some reason. And I think these are these need to be separated clearly and the path thing maybe you have local clue about whether you want to do it or not so that's kind of dependent on the path and we will drill there I think we'll find an answer yeah Okay Okay, last issue So we actually"
  },
  {
    "startTime": "01:10:02",
    "text": "when you send, when you open a new pass, means you're sending a packet with a using a connection ID that belongs to a new pass ID, so you can like clearly identify now with the explicit pass ID that this is like, a new path that you want to open. And we actually say you have to send a pass challenge within that packet. So it's not like, because like previously in the migration, case when you have a net rebinding whatever it can always happen that you get like packets which are kind of opening new pass but weren't intended to. But here, with the pass exercise, pass idea, we don't have this case. We always kind of explicitly, open a new pass and there has to be a pass challenge. It's a must But we don't say anything what happens if you receive a package which has a connection idea belonging to an unused pass ID that doesn't have a pass challenge So we have to define that. And there are three options here Either you just like say, okay, whatever, I still want to open the pass and I send you a pass challenge. Or you just ignore the packet completely because it seems wrong, or you actually do a connection error and close the connection Thank you because unless we do, it will require the end point to include past challenges for all the packets that it sends in the first slide. And that's going to be a huge burden. So better quick then also be ignore, right? So you just ignore it and then might arrive later and then you have to retransmit that packet yeah assuming that they are dropped i'd prefer doing as much as we can to rescue them Okay also keep in mind, it's like you open a second pass somewhere, right? So you might have an act pass where you can send all your data and only when the passes open you maybe want to send you data there, I don't know So the purpose of path challenge is for the center of the challenge to be able to validate that the receiver is able to receive It is, I think, inappropriate"
  },
  {
    "startTime": "01:12:02",
    "text": "for us to be requiring particular behavior on the other end of that. So, so yes while there may be cases where a sender sends with connection IDs or whatever that should be sent That's not the business of the receiver to police that They've made that path ID available on that path And I would suggest that you don't have any requirements around these things things things so but that means this is so solution a because you want to validate the path before you use it. So if you receive something on a pass that doesn't have the past change, you have to initiate your past change in order to use the path. That's right. So this is a requirement on the sender on that path to do all these things. But I don't think having an enforcement on the other side is appropriate. So it's, okay, you either send a pass challenge or you don't do, or you like, I guess you still ignore the parts. The expectation is that someone who's attempting to use a new path will challenge on it, use the appropriate path ID sorry use the appropriate connection IDs for that path, all of those things. But the person the endpoint receiving all of that, its peer, there's no, it does not owe an obligation to check that the other side has correct, it doesn't it's not responsible for policing what the other side does in this case because these are not there for its benefit. It's there for the, I understand what you're saying, but I don't know what it means in practice. So you get a bunch of packets from a new path that have not been validated. Should you? accept and process them or not? So valid applies to the thing that's sending, not to the thing that's receiving. So if the packets are valid, accept them. Okay Yeah, pretty much what Martin said"
  },
  {
    "startTime": "01:14:02",
    "text": "I mean, excuse me it's Mike's done. I'm sorry sorry like that. Also echoing what Martin said, both sides are required to do path validation when a new path opens up This is the same as with migration to a new path and RFC 9,000 The fact that the client has not validated it yet does not absolve the server of doing it done validation and the server is not responsible for checking that the client does path validation there might be some the same anti-application requirements on a new path that would apply to the server if it sees these packets come in. But that's true regardless of whether the client does the path challenge. I think the text here would just be when you see packets on a new path you must initiate a validation, and there's no requirement to check that the peer did it. Yeah, so exactly So that's what I wanted to confirm. So we have a must here We keep a must, but we don't enforce it effectively It's, it's should. It really should what I wanted to confirm. So we have a must here. We keep a must, but we don't enforce it effectively. It's really a should. No, it really is a should. It's not a must. It should not be a must So you actually want to change it to a should? Yes Yeah, because, I mean, you cannot, the must will be to force the peer to do a handshake to a shoot? Yes. Yeah, because I mean, you cannot, the most will be to force the peer to do a hand check before using packet on a new power and we do not want to do that So there is one exception which is if you use the path the same tupper recently, then you can skip it, just too that's already there But it's a very explicit exception we have now 9,000 is more restrictive because 9,000 has a lot of concern about using only one pass"
  },
  {
    "startTime": "01:16:00",
    "text": "at a time. And that concern about using only one pass at the time drive a lot of restrictions In our case, first, i receive a packet from you on pass nine, which I have not used before and that packet is good. I mean, it's used a CID that is legit and the checksum validates Of course I'm going to use it. Of course I'm going to accept it. That's not the protocol error. I don't know what's happening with you. Maybe you decided that basically you know from other places that that passes I'm going to accept it. That's not a protocol error. I don't know what's happening with you. Maybe you decided that basically you know from other places that that pass is perfectly good. So you don't actually need to check continuity. That maybe, may not no but then it sounds like this should be a must It should be should, sorry. That one is a should be a maybe, I mean, that's... No, but then it sounds like this should be a must. It should be should, sorry. That is a should, that one is a should be a should. Because, I mean, you may know that the past is perfectly good by other means Yeah Yeah. watson ladd, Akamai. I'm a little confused by what the intent scope of the validation is So let's say I have a client, it has two possible addresses it can send from but it's connecting to a server with one address Does it need to validate that address twice? Is that a choice to server necessary? should be enforcing? So I'm leaning towards what? other people are saying, which is, if you're going to pack it, it's up to you what validation you, the side that receives that packet does before sending But they shouldn't expect to know why the other side made the decision it did And so there shouldn't be any need for valid for rejecting a packet because you think the other side shouldn't have validated it Yep Christian, you were already in the queue, right?"
  },
  {
    "startTime": "01:18:02",
    "text": "Yeah, it's my understanding that if you receive a valid encrypted sign packet, you can use it. There's no reason not to use it I think validation is just you shouldn't send unless you know that path is good for DOS problems basically, right? That's the main concern. So yeah, like if you receive a packet, I just see no reason not to use it. Okay. Makes sense Martin martin duke, Google like on the should must thing, I must thing, it feels like this is, well, I saw I agree that it should not be enforced, but we do have in quick other musts that are not enforced, like the you know, connection ID unlinkability thing because it's just something you really should do is address adjust the, validate the address And like, I'm fine with like, must unless all these conditions, but I can't think of a case where the, uh, address is not, has not been validated where it is like reasonable to not validate it. And so like unless the should has reasons why you might not do it I think we should make it a must, even though it's not enforceable Then we get into interesting territory I think the problem here is that this requirement is specified very, very precisely It says you must perform address validation with path challenge. And I think what we say in a lot of places in RFC 9,000 is that you must validate that the peer is willing to accept the packets of sending. And it doesn't necessarily specify precisely how you do that and it might be that you've recently checked or you have out-of-band information that gives you that. And so if we check this to simply refer to section 8.2 of quick transport and say that you must validate the path before you send on it I think we avoid a lot of these sort of really fuzzy bits"
  },
  {
    "startTime": "01:20:02",
    "text": "and we leave it open to the shoulds by virtue of the fuzziness that's in 9,000. So I would be in favor of yes must, must validate just in accordance with 8.2 or whatever, of 9,000 And yet there's no enforcement, and I think that's okay. So that's right. In this case, I wonder if we, because I don't want to repeat normative language from RFC 9,000, so maybe we can just not use normative language and refer to RFC 9,000 because the requirement is already there I think this is important enough that we should have a must here that's independent of what's in 9,000 but for the most part, just refer to the procedures that are in 9,000 for path validation Question. Yeah, let's be clear The reason we validated the pass is because we don't know that it works. That's the main reason The other reason is we don't know that the peer has the resource to accept a new path in the project Now, with the multipath extension we do know that the peer has the resource because otherwise they would not have sent their connection ID with the pass number So the only test that we are doing is verifying that it works So you receive something It's because the peer has convinced themselves that they can see on that pass for whatever reason It may be that they have checked BGPU What do you know? Okay. The packet did arrive that's cool that doesn't mean that you should immediately start sending responses on that pass because doing so would open the gate for all kinds of denial of service attacks So you must very that the pass works before sending yes. And in fact, I really think it's a should, but, you know"
  },
  {
    "startTime": "01:22:02",
    "text": "works before Sunday. And in fact, I really think it's a should, but the reason I think we should write should is that I disagree with the notion of having must that really means you must do it, but we know you want I mean, there is no all hard for alternative must and should, and we are not using it So if must means also that the peer shall enforce it. And we don't want the peer to enforce it so that means that we shall not use the must verb, but the should verb. I mean, I'm going to you, but apparently that's not how we did it in Quick in some cases, so I don't think it makes a difference here Yes Gori, I think I'm confused again Okay. Are we validating that the service is the server we're talking to, like we're wearing quick? or are we validating that the path has connectivity? Because one of these is a security problem, and one of these is kind of looks like a connectivity problem Have I muddled this up? No, it's we're validating that we have connectivity to the server we actually want to talk to It's not only about pinging the path. Right, but the big thing about path challenge was to kind of figure out we're talking to the right server and that was good. But I mean, we're talking to the same server on a different path Is that, I mean, have we somehow conflated two things? or I just got really confused? I don't think so because you also, I mean, just because you're receiving the packet, it's encrypted you can decrypt it and make sense. You already have you know that like this belongs to the same connection And then the only piece is missing that you also need to reply from the server to understand that this actually happened. So that's what we're validating that the server can reply to you So we just validate connectivity here. If you wanted to find it this way yes. Okay, that helps. Thank you I think that was the last issue"
  },
  {
    "startTime": "01:24:00",
    "text": "and we're over time Yes, but thank you for all for the discussion. It seems like it's very productive and you have everything you want probably. Yes, thank you very much all right so we're going to be for the discussion now it seems like it's very productive and you have everything you want probably. Yes, thank you very much. All right. So we're going to now move on to discussing the work going on in the Q-Log documents Do you want to do the slides or you just going to say next? I'll say next So everyone, yeah, this is QLog the one with Robin. Robin's on holiday, so I'll be doing a job. I came out with COVID so I haven't been able to do as much as I would have liked to So this is going to be shorter than me originally had So hopefully we'll be able to catch up on some time Next slide, please Since the last time round, we've updated the document These are the latest versions we've posted an update to the list but really this has just been focused on well-defined extensibility of the event and schema, along with more use of media types. So we want to register them what I mean there is we were already using media types if you were to use like HTTP to request a Q log or to upload one and we would have that in the content type field but if you go to the next slide please Matt we decided to use media types in the serialization format field as well which is the second one down there in the past we had a value in there that was not a media type it was something else, which raised a question about whether we needed a registry of format strings or whatever And so as part of all of this work, we've decided just to reuse something we're already using"
  },
  {
    "startTime": "01:26:02",
    "text": "that's an open question I got for people if they think that a bad idea I'd love to hear why and I'd love to hear that now, because we have a chance to change it But Modulo, that's what we'll be going forward with Just walk through some of these other fields in bolded values As an example, this is a Q log file that would be using the contain format, the thing where all of the events belong to a single or all of the traces and therefore the events in a trace belong to a single file, and that's structured in a contained format has this new URI that would define them. Because this is an IETF standard, we would use a URN of this format Similarly, for events schemas, this is a new concept that we've had. We discussed those last time around, an ad nauseum, but we reiterated a lot on the tickets and in the PRs within the editors group and landed on this design at a more waste time going into it in detail. It's all in the document but effectively we have this idea of a events namespace and then following from that other namespaces, I just realized that a events namespace and then following from that other namespaces I just realized there's a typo on there sorry but then categories of events and specifically for the process we're in now, we're reiterating on those events definitions, and you might have a Q log file that has events from one version or the other, being able to include a versioning within that is useful and help solve a lot of the versioning problems that we've been tracking as issues for a long time So with all of this, we've closed out basically all of the major blocking issues that we have. And if you go into the next slide, please please We thought we were done. And then kind of the next day that we merged this and i started to work on implementation of it, I realized"
  },
  {
    "startTime": "01:28:02",
    "text": "that there's one more edge case we had covered quite. So there's an open issue The example here is that if you have something like a package, cent event for quick, and you just want to add a single field to it you just want to add a field But the way to do that currently within the whole namespacing, thing that we came up with is you'd have to redefine the event entirely in a new namespace and the category in a new event name to avoid any naming collisions with things. And that's a lot of work and that's pretty terrible and counter to the extantability there's that we had in mind so the proposal is just to add another form of prefix for these things that we and counter to the extantability design that we had in mind. So the proposal is just to add another form of prefix for these things that will have like an event extension thing and you define the extensions that you have and then obviously you could go off and read the spec or wherever they defined and find out what those things are um Watson's asking in the chat we're sure we didn't want to use XML, yes, I'm 100% sure I don't want to use XML. But yeah, if anyone's got opinions on that, this is kind of the follow-on, last big issue to the last big issue that we had Next slide, please. What are the only remaining ones? that person I have is the problem with clocks that we presented back in Yokohama It's exactly the same problem effectively I gave it with a pull request at the time and we decided that actually that wasn't the way we wanted to go. It added a lot of confusion to other folks who didn't necessarily grop this problem the same way as me. And I think that was fine and that was good feedback. So we'll want to go with something simpler and if anyone feels strongly about clocks I'd love to hear now or to comment on the issue or the pull request that there is See Watson in the queue queue watson ladd, Akamai, we've"
  },
  {
    "startTime": "01:30:02",
    "text": "already got a ton of stuff from this in NDP. Use your TC time timestamps. That's what you're supposed to do for interchange between systems. I understand there's complications with doing that, but there's a reason why that's sort of the best solution So I appreciate the comment there I would say from an implemented perspective we only care about relative times of events and we don't want those events to have clocked drift effects. And so internally, for things like packet timings and pacings and everything, we use monotonic clocks same for our server application we don't care about interchange necessarily even in tooling like cubis or some of the stuff I've written, I only care about the relative timing from the start of a connection so uh converting those things is in some ways impossible You can fudge it and kind of with things, but there's always gonna be edge cases that are introduced requiring to log in some form of timestamp is hard if you're on a platform that doesn't actually measure timestamps in say, Unix, for example, and needing fully qualified UTC timestamps is going to cause robustness in log that doesn't actually measure time stamps in say Unix for example and needing fully qualified UTC time stamps is going to cause robustness in logging so you'd be looking at compression mechanism of which we do have some, but eventually what we have in Q log right now is a lot of flexibility to allow people to do what they like to do. And that causes some kinds of I know it's an interrupt, but yeah Watson, if you would care to comment on the issue, maybe with some perspectives, I would love to hear them and consider them We'll do. Thank you you I think this is a lot easier for those people who are managing devices that sometimes get things failing across for instance, clock corrections and"
  },
  {
    "startTime": "01:32:02",
    "text": "various other things to, it's much easier to device with a monotonic clock And you get much more reliable logs at that point It's my opinion that we should have an epoch in the file that has an 8601 for timestamp or the RSC 33 format, whatever and then the of the times the individual events are sort of millisecond offsets or some all of the times the individual events are sort of millisecond offsets or something like that from that point events are sort of millisecond offsets or something like that from that, from that point. That's a lot easier for my understanding a lot easier for most of the implementations as well because they all tend to use monotonic clocks simply because they don't want to be able exposed to the vagaries of wall clock time time Okay, but to respond to that, like the epoch of my monotonic clock is whatever my system decides when it comes up, it's like we put that, it's in a page value that no one else can never know effectively or doesn't care to know. Right monotonic clock is whatever my system decides when it comes up. It's like we put that it's an opaque value that no one else can never know effectively or doesn't care to know. I can grab a current time in some format but the millisecond offset from that isn't my worries it's confusing because people will think it, they can always restore the time delta to come up with an absolute time that's correct and that and then use that to go look in some of the system and that won't be right if there is some form of clock drift or something. Right. So the monotonic clock won't necessarily advance the same right that everyone else's monotonic clocks advance but there's a general understanding that um that won't be right if there is some form of clock drift or something. Right. So the monotonic clock won't necessarily advance at the same rate that everyone else's monotonic clocks advance, but there's a general understanding that one millisecond is appropriate one millisecond in all of these cases. What I'm suggesting is that time zero is established by looking at the walk clock and looking at the monotonic clock and established a reference point. And then from that point onwards,"
  },
  {
    "startTime": "01:34:00",
    "text": "the delta to that reference point in the monotonic clock is what you use for the locks. That's what we do That's fine until you hit something like daylight savings where you go back an hour and you're trying to correlate it Q log. No, no, I'm suggesting that what you have in the Q log then is this connection started at this time, which is the war clock time, which is the war clock time and a time zone, probably in UTC, probably not you connection started at this time, which is the war clock time, which is the war clock time in a time zone, probably in UTC, probably not UT1, logged in the file. And I think most people, as Watson pointed out, most people will be able to turn that into something that makes sense for them. Then all the events are relative to that time in some sort of absolute reference frame and may that's not 100% perfect in the sense that your monotonic clock might not be precisely the same as my monotonic clock from that point onwards, but it's, it's going to be close enough for most purposes I 100% agree, but my only concern is that people will maybe say process that Q log in enrich it so that it goes back to every event has a war clock time. And that's kind of fine, and then they'll want to correlate that to other logging systems that use more clock times and that the monotonic clock didn't actually follow any war clock time and that you get weirdness with time zones or changes and there can be errors. I don't think that's a huge problem. I think we can document it, but I just want to avoid a bit of a footgun night. That's a problem for those performing those translations once they decide to do that, that's something on their on their shoulders Cool. Kevin? yeah I agree you can only stop people from shooting themselves in the foot so much i think like i can see future extensions where you add other reference points to link the two but i think for start like, yeah, let's just add one reference at the start And if it ever becomes a real problem, we can consider other things"
  },
  {
    "startTime": "01:36:00",
    "text": "Okay, cool These comments echo stuff I've heard from other people in internally, too, that they would really like something even if it is potentially wrong So yeah, I can take that away and come up with an answer or sorry, a proposal to bring back to the list Could we go on to the next slide, please, Matt? And so, yeah, we looking ahead, we have a plan update for QViz I say we I mean Robin is going to do a lot of the work there. So now is the time to thank you thinking about updating to the latest drafts I know the past, because Q-Log is kind of not that useful unless you've written your own tooling and not many people have and they rely heavily on QViz and it's been lagging behind, there's kind of this chicken and egg problem but Robbins announced that he has these plans for August and September and I suggest we all start thinking about updating. I did this for Cloudflare's QL Q-log implementation and it took me just a couple of hours Just renaming events here and there and moving stuff around a little bit And I took a pass that making sure my events were actually still up to date I dropped a few fields here and there over the years too So it's really not that much effort On this perspective, we only have 25 issues remaining now, and all of those have been raised by the do document authors as we continue to go through many were editorial some are kind of open questions, none of those are seemed huge, but that I want to identify that that's coming from the author group so I have a polite request for people to please consider reviewing and implementing the spec, if you haven't for a while, because I would love to be able to come back at Dublin with you know, more slides of substantial issues that we need discussion on face-to-face time or the opposite case in that we're just ready for working group last call and we can do that and maybe come back with some final questions or comments at Dublin So yeah, that's all I have"
  },
  {
    "startTime": "01:38:02",
    "text": "Thank you Thank you, Lucas. And before we go on to our other items, I believe our AD would like to ask a question about multipath All right, Jahad I saw a really good progress online MP quick issues and my understanding is like most of the design-related issues out there was like kind of result. So I'd like to get a sense like how far we are from completing this, this text Is it like two more? IETF meetings or two more ITA two more revisions is there any plan like authors can tell us more about like what they think or like the chairs can update me on that You want to start? start? Yeah, I'm trying to join the queue. Mia Kulumin. Ah, they are So yeah, this is, we went through all the design issues, all the remaining open issues that we didn't discuss today are editorial. So hopefully that's kind of actually the last set of design issues that we have I would actually, I think we need quite some editorial work, so probably it's more than one update to the draft. But if new design issues come up, I would actually like to go for like an interim or whatever so we can actually kind of conclude by the next meeting more or less What is your sense on the state of like interoperations? and implementation status? Do you think that's equally good as the design? issues or are they? So there is multiple implementations that interrupt they they are not interrupting on under all the tests that we have so there's still a little bit something to do but i think we can also get there by the next meeting, especially the one thing that we just added newly to our test is like, because now you have"
  },
  {
    "startTime": "01:40:03",
    "text": "actually the pass ID, you can also migrate on the same path, so we're testing this as well now, which didn't work everywhere but you know I think like with those tests we actually can be at a state next time where it works Yeah, I think that sounds really good to me Yeah, there are a couple of things like here would be really good to see on testing, like if you get an invalid on an invalidated path and not valid part, then how do you handle those kind of thing? Like, we discuss today, like we don't care, but it would be good to get some interrupt testing. So you've talked about interim, you were talking about, like, interim from the next item meeting or potential interim? Yeah, so if we get into more issues that would be my preference to have an interim before the next Okay, thank you. That gives me some idea. Thank you just a clarifying question do you do you mean virtual interest or physical? virtual thank you Okay, next we have we're entering our ads time permits I assume Martin, this is you. So we're going to talk about accurate ECN acknowledgments Yeah, someone is in the queue Hi, Alt-9thansa, Khome Rakev On the previous point, I wanted to quickly mention as an obf observer, what I feel is missing in the multipath quick. I don't see a lot of diagrams. I don't see a clear definition on prioritization scheduling So is that in plan? No? Diagrams and tooling? Is that what? the question is about? Yeah. Diagraphs would be nice. I'm sorry? I believe scheduling is explicitly out of screen for this working group. This is a more about the protocol mechanism and scheduling is a different task as in terms of diagrams, I think the authors would be willing to"
  },
  {
    "startTime": "01:42:02",
    "text": "entertain diagrams as appropriate, but I don't believe there's any planned work on that front to change right now Thank you. Hello so I'm here to present a new draft that I submitted together with Viti from Apple. Next slide So the purpose of this draft is to make ECN acknowledges more useful and quick, more fine-grained. So let's take a look at what we have in RSC 9,000 We have the egg frame which encodes the largest acknowledged packet some delays, ag ranges, and then we have ECF counts. And these ECN counts are just three numbers for the ECG zero ECT1, and the ECN-CE package And that's the total count of packets that was received with these respective markings. So when you receive an AC frame, it could acknowledge, let's say, 100 packets at a time And as a receiver of the Ag frame, I know what the ECN counts were before. I know the new ECN counts, so now I can figure out, oh, they were like 90 packets with ECT zero and there were 10 packets with um yeah I don't know, is which of these 100 packets were CE marked And what this extension is introducing is a new encoding of the act frame that allows me to learn exactly this information. Next slide So instead of just encoding"
  },
  {
    "startTime": "01:44:02",
    "text": "the ag range with the number of packets that were received as an RFC 9,000, we now add an ECN marking to an ag range. So now I can say packet numbers 500 to 600 had this ECN marking and packets numbers 600 to 600 had a different easy end marking and I just put these in the act frame instead of the egg range that are seen C-9,000 defines so this allows the receiver to know which packet was received with which ECN marking Why is this useful? If you use one to use LFRS and the congestion controller like Prague when you look at the equations, how to modify your congestion window the thing that goes into the equation is the size of the CE market packet. So by knowing which package number it was, you know exactly what size of the size of the packet was that you sent And we which packet number was C.E. Mark because there's an additive increase and a multiplicative decrease and so the order in which you apply those has an effect on the congestion window Hi, Lars, they're good asked my first question is what is good for, which is Elph Have you looked into how much more? the egg frame would grow if you did this? Because now you're creating ranges when the EC pattern changes and not the lost pattern changes and there might be a lot more changes Yeah, that depends very much on the how the markings are applied"
  },
  {
    "startTime": "01:46:02",
    "text": "We are still encoding ranges, right? And the expectation is that they are lovely... Every flip and the bit pattern causes a new range So two barons and one eight bit So I just wonder, like, if for any, like, easy like, drop tail, sorry red queue or even Elfrescue, whether you had done an experiment that like, said something about the sizes you saw So, so for Elferi, you expect um, two market packets per round trip time, right? So this is creating a few more ranges, but not a lot Gore, I'm not sure. I mean, when we dis there was a little design team kind of thought about this before we did it It wasn't random. And we wondered what happens when every other packet has an ECM mark just because that's the way it is. I mean, like, we don't know how these patterns of ECM markings will actually play out. So adding a data structure around that and expecting to be populated looks like a dangerous explosion in the size of the packet. I'm also not entirely sure knowing the size of the packet that was C marked actually tells you that much. It tells you that packet was marked in the cube. But I mean, do you want a base to see? was C marked actually tells you that much. It tells you that packet was marked in the cube. But I mean, do you want to base decisions on that or do you want to base it on the sizes of packets you were sending at that time? including the ones that you weren't seen marked? So I'm not sure the extra information helps but maybe you have a way of using it that does help. So I was trying to bubble up and ask why does the size matter? Okay, so to your first point every packet having a different is the N mark, that's the worst case scenario right? That leads to the largest frame size in this encoding I don't think it's very realistic to have an on-up pattern there Regarding your second question, why does the size matter, this"
  },
  {
    "startTime": "01:48:02",
    "text": "is what the Prague congestion controller does and takes us in input. I am not sure why it's using the packet size there The average size that we're sending or the size that the particular C-E-Mart segment. No, it is using the size of the particular packet that was C.E. Mark OK, we can think about that one So a couple of points First of all, for the TCP practice also kind of more on the wish list, right? In TCP, you may or may not have this information so you have exactly the same situation Then this is not a new use case. F4S and TCP Prague is exactly what we just discussed when we designed the initial X frame And we decided this is good enough. So I don't think anything changed here so I'm not sure we should we have to change something here There's like a whole long discussion on the issue that you might know. And on that issue, there were also different proposals how to if you want more have more information how to design it and so you took the most complicated one or the most rich one because you can now exact see which packet had which markings the other one that would be much more easier would just be, instead of having packet count having a right counter because you don't know need to know which package just how many bytes, right? So if that's kind of your problem that would be the good solution. But even that part, I don't think it's needed. Just take the average sending side and you will be good enough If you want to experiment with something more accurate, you can also with the current egg scheme, just like egg every mark package separately, and you get exactly the same information if you have control of the other end, of course. But for an experiment, that would be good enough Yeah, so what we currently have is not good enough to implement, because I tried implementing Prague and I was running into exactly these problems. So why don't you just use the average sending? No, I can use the average sending size, but this still doesn't resolve the problem in which order to"
  },
  {
    "startTime": "01:50:02",
    "text": "apply the increase and the decrease The order you're applying it? Yes, because for every acknowledged packet, your congestion window grows a tiny bit, right? And for every CE market, packet, your congestion window shrink by a multiplicative factor So if I do the addition first and then the multiplication is a different outcome than doing the multiplication first and then the addition But does it matter? Does it matter? change the performance? The congestion window will be different. I have no measurements how much of a difference this makes performance wise in the real world So that's the question we need to answer So please tell me that a gap can be zero length. Yes, it can. So you change the format of the ACC. So, um think stepping back a little bit independent of the details of implementing Prague or BBR or any of these things, what we're seeing is the use of ECM markings to carry information. And if that information were maximally useful, or maximum for maximum surprisal, from an information theoretically perspective they would effectively be random from the perspective of the center of the packets the model that's receiving the axe. And so if you're looking to build a system that gives you information on the markings on every single pack the ideal one would be one that's suited to encoding what is effectively random information coming out. And this sort of run link encoding is very inefficient when you talk about random information like that So I suspect that this is not quite fit for purpose in the general sense that you're looking for"
  },
  {
    "startTime": "01:52:02",
    "text": "Thank you, Mr. Magnus says before you, Chris Yeah, actually, so I will tell you how it's done in the mobile system there for us or you see an marking. That's back feeding a marking percent percentile which is then applied to not the packet that actually resulted in the queue unfortunately and this is how it's done in in 5G for a moment at can't be fixed until future maybe in 6G So you're anyway just getting a random application of marking marking ratio So it's not accurate to the level anyway on the specific package which caused this so So it's I think you will have to figure out, I think, is this really, relevant to change, do the for now, or is it enough to basically saying? oh, if you're going to implement it, what's the over this time? I'll have this many C mark packets that made me and then just randomize a sequence that fulfills that marking percentage and see if that does work well enough. But yeah if this I think if it's actually a problem, yes, we should do something but it's i am unconvinced for a moment that is this is significant issue okay so i i have a couple of issues there. First, I mean, as Martin say, in the average case the range will be quite short because if you are applying random marking, by definition, the range will be very short So you are going to have a large size of the arc. Moreover, if you have an adverse an adversary on the pass then you have opened the way for that adversary to mark every other packet and blow your accesses. So you have a security issue"
  },
  {
    "startTime": "01:54:02",
    "text": "there So I think that there is a cost, okay? Second, if you are going to do that, I object to doing that just for ECN. If we were to do at additional data on the ACRange, then we want to have to have the delay as well and if you open that kind of worm, we want information about the transition delay, because the transmission delay gives you as much information, it's not more than the ECN marks Are you talking about your one-way delay extension? Not necessarily one-way delay extension. We already are a delay in the arc that applies to the lettuce packet. What you want there is to have a delay for the ranch. Yeah, there is a draft floating around that does something similar with timestamps. So if we do, if we do that, we need to have some is to have a delay for the ranch. Yeah, there is a there's a draft floating around that does something similar with timestamps. So if we do that, we need to have something like that too. Okay, we can do that And the first thing is that I don't think that plug is the right motivation to do that I think that Prague is making us assumption because they want to do proportional feedback But as Magnus was saying, the marking, the actual marking, implemented in the in the in the necessary based on the length of the packet. It's largely based on the order of the packets so i think that what you really have is that you have a statistical expression that allows you to compute the rate of marking And it's a rate of marking per packet In fact, the routers are not marking per bias they're marking per packet. So what is to be done really is to work on product based on the reality of what the marking is. And if you accept that the rate of marking is marked per packet, not per bytes, then you have to basically see how you do"
  },
  {
    "startTime": "01:56:02",
    "text": "you accept that the rate of marking is marked per packet, not per bytes, then you have to basically see how you deal with that inside the Prague stuff And they probably have to revise the algorithms a little bit to take into account reality and not force a complicated change in the architecture just because of that Finally, if you want to have something accurate, what's we can work with is the arc frequency because really what we want is to see that if there is a change in the marking rate then you want to inform the other peer quickly So basically, I think that to make progress work, the thing we really want probably is first to work on the act frequency modification to make sure that the act frequency are also triggered by the change in marking and that probably will be more productive Okay, so I'm going to jump in here as chair. It sounds like there's a lot of interesting discussion here We're not going to run a poll or anything on this, but I think this is probably worth discussing offline amongst the authors and also the people that had strong opinions about this it would also be great if this could be reflected on the list, because I think this topic has come up on the list to no response which is not ideal. So if the you could maybe follow up at VIDI as well, I'm sorry I dropped you but Lars what do you want to say I would suggest that we experiment with that quick extension because you can do this with another frame type, and then you can try it with L4S and you can tell us whether it works. Yeah, so if you in back, kind of data and then reflecting on the list would be great so yeah cool uh so we have a couple minutes we just wanted to give a quick final thing, which is is yeah, with"
  },
  {
    "startTime": "01:58:02",
    "text": "with regards to time maybe we can skip this and give the two minutes to Mike. I've done this presentation. Okay skip this and give the two minutes to Mike. I've done this presentation already twice at AANRW, so if people are interested, in prioritization, I would just suggest to go like to the AANRW recording. We have also a nice paper on the AANRW website. So it's maybe a better idea in the scope of time. Okay. Thank you All right. Mike all right thank you very much um Can you skip slide? I don't seem to have control It's not. Let's see if I can do it You can just start talking too. Okay so if you can go to the next slide so in RFC 9,000, we have this assert that tokens provided with new token frames and retry packets can be distinguished by servers. If you go on one more slide that comes from a requirement on the construction of the tokens that the server must make the tokens in a way that it can tell them apart. And because of that assertion that we can distinguish them, we can be stricter on retry tokens than we are on new token tokens because the client's address might have changed the new token one is old it might not be valid anymore Let's skip forward two slides Okay, so the problem comes up here when the client gets a new token back from one server at a given name and it tries to use that token in an initial packet starting connection with a different server that can't read that token because they're kind of and it tries to use that token in an initial packet starting connection with a different server that can't read that token. Because they're coming from different servers, one server's new token, token might look like another server's retry token. From the server's perspective it just got a retry token that doesn't parse"
  },
  {
    "startTime": "02:00:02",
    "text": "and so it closes the connection with an invalid token So this is something where the server is doing the correct thing according to the spec, and it is a breaking client connections. Next slide So the reason for the is because we wrote the spec assuming that the token was only being read by the entity that generated it, but in the multi-CDN case one CDN's tokens connects to accidentally get sent to a different CDN because the client doesn't know any better So this is kind of making me wish that we had included a bit in the packet that said whether it was a new token or a reset token but the other way you can handle this most implementations are doing some kind of cryptography to check that it's valid. We should just shift the definition of when it's most implementations are doing some kind of cryptography to check that it's valid. We could just shift the definition of when it is an invalid token to say if it is valid, it came from you, but it doesn't match the client's address, then is when you kill the connection So I filed Narotum on this. We might want to add that bit in quick v3, but this is just something that has come up and I know at least some implementation to fix this, but it's something to be aware of do we want to do anything about this or just leave it for the next version of the document? So if martin duke, Google, so if I understand correctly multi-CDN does not result, when you go to a different CDN, it's not resolved of a different IP address, or rather it does result in a different IP address. And, uh, correctly, multi-CDN does not result, when you go to a different CDN, it does not result in a different IP address. And, or rather, it does result in a different IP address. And, like, if I was able to client, I would not go to a different IP with a token from the previous IP and expect it to work Well, so the issue is you can include it because it's a new token token"
  },
  {
    "startTime": "02:02:02",
    "text": "you can include it and whether it works for not, the connection shouldn't fail. The problem is that here the connection does fail if the server, for example ROC Q. Q Mycel, MPI-N I'm not sure if you've seen my small amount of posting on the list a few months ago about extensible tokens, but I think that would also serve as a way to solve this I guess what are your opinions on? doing that instead of just defining a tiny bit or defining slightly more. So it's we can solve problems like this in future So, yeah, so having a token that you know is of a particular structure and then you can identify what the purpose is. Yeah would give you a solution to this so long as you first are able to check that the token you received conforms to that format. Right, yeah I guess this is not the right places to discuss it. We'll discuss it on the list, but I think that is not option and I'm proposing that we look into it yeah that would that would make this a smaller problem problem And Kazulhawk, two points. First, this is a really issue for multi-CDN. If mask is a involved, because mask does the mask server do the address resolution. So, the token could go to CDN A and then to CDN B. And then the second point is that if I recall correct, three, design tokens based on how we design session tickets in TELF. So they are we kind of implicitly believe that they would have an AET type or whatever for verification and if they are, they don't much re-rejected. So I think that's the design that we intended"
  },
  {
    "startTime": "02:04:02",
    "text": "So if there's something very in the spec, I think it's simply an underspecies specification. Right. So the erotum that I submitted suggested that if it is cryptographically valid, but for the wrong address, rejected. If it's cryptographically invalid, ignore it it Okay, and I think with that, we are, that concludes the, we're over time, so that concludes the meeting Thank you everyone for participating. It's special thanks to our note takers, Martin and Marco And we will see you all in Dublin and on the list"
  }
]
