[
  {
    "startTime": "00:00:12",
    "text": "so the chairs for 10 starting the DTN working group session do sheets are going through the room as usual we\u0027re under note well which says essentially you know everything you say or you write is under is covered under those rules please read when you have time proposed agenda that my colleague eric has put out the call for proposal I guess we ought to get some convergence layer done we had discussions with the ad this this morning in the outgoing 80s and where we would like to get this done ASAP any agenda bashing or changes no change to agenda okay Edie are you still you know available to take notes you take very good thanks accident you will be presenting therefore we would like to have another note takers during at least the time where ed was is going to present any volunteers should I point someone when someone comes to the front and you know shake hands with the chairs then you get a token of being the note-taker that\u0027s why the thank you are you gonna use ether pad for this or are you gonna just type it in a in a notepad on your laptop if you use ether pad pad then Martin could pick up on it but okay well whatever works for you because you volunteered yeah we\u0027ve done less calls I don\u0027t I don\u0027t know if you remember that "
  },
  {
    "startTime": "00:03:13",
    "text": "we did but we did and well conversions layer TCP conversion layer being discussed hopefully the last time this week will progress through sending to the ihe for our ad for his new work you know just as an introduction to his new tenure that is the milestones that we agreed a while ago to work on we on purpose you know use a subset of them because we want to focus on the base spec which is the revision of 50/50 but then other stuff need to be done to get the full solution I think said that I think Nick\u0027s is Scott okay I\u0027m Scott Burleigh I work at Jet Propulsion lab in Pasadena California we talking about minimal TCP convergence layer adapter I can be very brief I\u0027ve got exactly one slide let me just go ahead to that slide the intent of MTC PCL is to provide a convergence their adapter that is simple enough that we can agree on it readily and provide it along with the BP sex specification and the BP disc specification as a as a package so that we can start moving everything together onto the RFC editors queue to that end the M TCP Convergys layer adapter is very short it\u0027s about eight pages you can review it in about ten minutes I think the we talked about it a little bit after the last IETF since then the only changes are first of all changing the the name from simple TCP convergence layer to minimal TCP convergence there that seemed to be more acceptable to everybody it was and and it and the the working group also adopted it so the name now is has got to she can working group in it I think instead of me and the second and really the only really significant change was adding a language about establishing TLS sessions in the same way that TLS needs to be supported in the TCP convergence layer "
  },
  {
    "startTime": "00:06:14",
    "text": "and and in fact the language that I added there is lifted all not exactly verbatim but we\u0027re pretty close to verbatim lifted from the TCP CL document that that had already been compiled and I\u0027m assuming that\u0027s all gonna be workable unacceptable TLS language the only other has changed that I made in the document as I was going through it was there\u0027s one point where describing the structure of the EM TCP protocol data units the the something had come up in another context that there was possible ambiguity in in saying that the encapsulated that the encapsulated bundle that was being shipped in the MPD you was a Seaborg byte string we wanted to make it clear that it was a simple byte string of defined length rather than an undefined indefinite length sepal string those are the only changes the revised updated spec was posted as an internet draft on the 28th of February and at this point I leave it to the working group as to whether or not we can go ahead with it any questions any questions did you think it was there\u0027s one I thought I was looking into the MVC l and also the the bundle protocol v7 and I ran into just a rough question for the working group as far as the policy of seaboard tagging I noticed that tags are mentioned in MVP v7 and not really in the m TT PCL is there is there a policy as far as like tags just shouldn\u0027t be present at all in DC board encodings has that been thought about it looked at at all I\u0027m just wondering from the perspective of the interoperability and troubleshooting and message dissecting I\u0027m not sure I\u0027ve answered for that the intent the VP b7 "
  },
  {
    "startTime": "00:09:14",
    "text": "respect in the M TCP spec was to state all of the C for representational elements that were required and else so there\u0027s there\u0027s I think no intent to say that you can\u0027t do anything else and for example a an extension block but I I think both specifications are silent and I will I will declare intentionally silent on that question unless there needs to be something said about it a scope that Rick Taylor here as a personal comment I seem to remember and I\u0027m sure a sea boar export expert will correct me if I\u0027m wrong that the specification of tags in sea boar is that they are to be parsed as effectively metadata but do not affect the actual fundamental data that\u0027s being transported whether a tag is there or not doesn\u0027t manifestly change the meaning of what you are parsing sure if you\u0027re doing a wire dissector or trying to do this in in Fiji a then it\u0027s an issue but I think if you want to tag that this string is a date that\u0027s useful perhaps for your domain so I\u0027m not sure where I\u0027m going here but I\u0027m I\u0027m not sure the presence of tags needs to be specified canonically within the specification and I yeah and my question was just to make sure that it from from the perspective I was looking at of dissecting messages is should I bother to care and skip tags and the answer is yes I I think the c-more spec says you should what you do with the tags is your business so if you just throw them away because it\u0027s irrelevant to your team to what you\u0027re doing that\u0027s fine but I think to be a compliant Seaborg consumer you must handle tags but we\u0027ll have to get the actual sequence back to determine that must or should that that sounds right to me and and and it\u0027s certainly fine with me inconsistent I think with the specification specification so say you can\u0027t do it though I think my intent has been to to define stuff fully enough in the specification that tags aren\u0027t necessary and I think I would stick with that intent but if somebody wanted to insert a tag - for some purpose I I don\u0027t see any any objection to it okay thank you anything else "
  },
  {
    "startTime": "00:12:19",
    "text": "Felix Walter efreeti and so just another short question about the PDU so I saw in the document that there is a length value before the zebra white spring which represents the bunler yes so isn\u0027t this kind of redundant because the super white string itself has a length I think if it\u0027s a well we\u0027ve gone round the times and I can\u0027t remember why we\u0027ve gone back to having it that somebody should have had some notes on this this may have been a conversation we had in a establishment serving alcohol which doesn\u0027t help if I remember was it something to do with somebody had a situation where the parser they were using wanted is this the indefinite strangest thing again where it\u0027s trying to load the whole thing in one into memory and if you\u0027ve got a 2gig PD you yes they might not want to in memory actually this was one of our problems when writing the serialize ER so I think because the the ppb spec said that the length well you should be the length of the serialized part of the the bundle block data and for that you first had to serialize the block data to determine the length and the length itself was of variable length depending on its value and so it was difficult to implement this in a like a streaming serializer that didn\u0027t so yeah but I I don\u0027t think this would be a problem for the the MPD you because it says that the length is the length of the encapsulated binary bundle right but it I think it would still be redundant and was just just a question why this is needed I mean probably I oversee something there I\u0027m it would have been great to have this question on the mailing list before we got here yeah I would have to research in in seaboard to give you a better answer but I will say that I\u0027m perfectly fine with the removing the length field from the protocol data unit that\u0027s if it\u0027s if it\u0027s not necessary great that\u0027s the Rick with chair hat on sorry to a drunk you this is a classic mailing list conversation and can I recommend we do this properly on the mailing list so there\u0027s a record of why we came to this decision before we get asked again in three months time probably by the same "
  },
  {
    "startTime": "00:15:20",
    "text": "people again because we\u0027ve forgotten yeah so definitely take this onto the list of these guys anything else yes mark you well I think we should do with machine learning so to solve those problems so we do we potentially have to TCP conversions layers in the TCP / IP world then we will connect to a port number the TCP CLV for as a port number as our part of the negotiation no no it\u0027s it\u0027s a port defined it\u0027s our wine port number yeah I own a port port services Ridge 4 4 5 5 6 oh yeah yeah so are 5050 I think yeah yeah so so if I\u0027m using your transport which port do I\u0027m I\u0027m not using and if if it\u0027s the same then we need some kind of a right you know a way to it ought not to be the same it won\u0027t be a different one the spec is silent on that it says it\u0027s established by by management I will I will observe that this is in operation 24/7 now on the space station it can be made to work it is being made to work it\u0027s not an Super Bowl problem if we need to define a port number for it in Ayana I\u0027m fine with doing that but it certainly is different from the port number that we used for the TCP convergence there well that\u0027s my point either we use the same port then we have a way to identify which protocol we\u0027re using or we use another point and I completely Abdur the former right we\u0027re not doing that we\u0027re not using the same port or not that\u0027s fine but no we\u0027re not we\u0027re not either with some sort be it disambiguation cool either way your respect is that is it silent about this and and if the spec needs to say something about it that that\u0027s fine we can establish a a port number in curtain spec that is that is perfectly fine so Rick Taylor here spinning to the top of the document just to check so the latest draftees standards track intended yes so I\u0027m looking at the ad for advice here for a standards track document we ought to have an eye on a request for a reserved port sorry I mean if you "
  },
  {
    "startTime": "00:18:20",
    "text": "actually want to request a port and yes you need to have an a section on it I I\u0027m not we try to keep down the port usage if it\u0027s really I mean and we shouldn\u0027t be spending a lot of ports if it tells necessarily I don\u0027t understand enough about this case to give a recommendation from standing here but do you have other methods of taking route or is it local configuration for which convergence that you\u0027re using etc you might not be if you can use a dynamic port for that each particular or how do you find your bundle and the convergence layers the intent of the specification has been that it\u0027s a local configuration matter and it\u0027s and it\u0027s up to so it\u0027s managed outside of the protocol and it doesn\u0027t have to be as part of the standard doesn\u0027t we don\u0027t have to do it that way I\u0027m happy to find a port if somebody wants to reserve a port for it I I would recommend against referring port unless you really really need it and so Rick responding to what we\u0027ve just heard I I personally not chair hat on personal hats on I\u0027d be perfectly happy to see some text in the document that says we don\u0027t need to reserve a port for this it\u0027s it\u0027s a minimal tcp CL pre configure it in some way out of that and as long as that text is in there then fine that\u0027s proceed there is on see any there is text that says it\u0027s established there\u0027s text that says it\u0027s established out-of-band there is no text that says there\u0027s no need for a preserved port number but that\u0027s an easy thing to add your god given the different encodings wouldn\u0027t it be obvious or fairly obvious for a receiver to figure out whether this is a tcp CL or a minimum tcp CL hecka so that you can at least fail safely or rely in kind of a reliable way determined determined that you have a conversion say I miss me at least on one end so that people could actually max the two protocols on the same port hmm that was my question before no I I would I guess I would advocate against trying amongst the two protocols on the same port I don\u0027t think there\u0027s a I don\u0027t see a significant operational advantage to doing that and and if you\u0027re not going to do that then I think it\u0027s unnecessary to require implementations to be able to distinguish between the two are given that the first few bytes are different how much do you have to do yeah but the first few bytes are a length and then some payload so I could craft something that you know looks just like TCP CL "
  },
  {
    "startTime": "00:21:22",
    "text": "header but is actually a specially lengthened packet I think that\u0027s a can of worms personally I wonder about sure you can write an implementation which does both and that\u0027s great but I think it\u0027s a simple experience in the internet that things tend to get misconfigured occasionally intentionally across all the broad routing protocols and so this is what I\u0027m just saying so if we have some minimal wisdom we can provide in this specification then that should go in there and that\u0027s I I think the you can certainly use this burst so patient and infer from add sufficient wisdom to do an implement an implementation that distinguishes between the two I don\u0027t think there\u0027s anything to add to the specification itself to make that possible or necessary Rick jumping in again what I could hear there is what yoga is proposing is is perhaps is this specification and I\u0027m gonna need to check the TCP CL specification is is there a unique enough header or preamble on the connection establishment such that the I know there\u0027s a there\u0027s a version number in TCP CL then we need to put a preamble at em TCP and ASCII or something on the front end so we can say Oh someone\u0027s pointed their web browser at me by mistake or I\u0027m looking at the room for feedback on this because your look makes a point everyone miss configures everything but is it then their problem rather than the protocol specs problem III think the protocol will will fail as soon as it starts running because it\u0027s because the Miss configuration and and you could infer from that miss configuration that there\u0027s a miss configuration adding protocol elements that help you distinguish exactly what sort of miss configuration you\u0027ve got kit can be done I my personal preference would be not to do that hello Roman felt I don\u0027t particularly care what what you do special pilot for terminal notice at least as you say something I agree with with mark much it there however I would very much like TC PCL to have a port number and maybe reuse is four or five five six for that and and ICMP TCP I teach piano as a sort of a stopgap for now and still sorry PC PCL before as the real thing yeah thank you and I\u0027m perfectly fine with that the intent of the MTC PCL "
  },
  {
    "startTime": "00:24:23",
    "text": "specification is to get us something so that we can move forward yes question uh ed brain just a comment which was I think the value of having both of them is that the minimum TCP CL stays minimum and so I think while there are many features that could go into it having something that is really only that which is necessary to show what we need to for bundle protocol is the rubric for determining what goes into M TCP I agree with that thank you Scott anything else no Brian [Music] okay so I have a very few number of slides and the summary version is that this is very close so the first couple of slides can be skipped for the next no changes have been made to the background this is just for a copy of some of the earlier presentation point is to update what already exists and to make what already exists in PC PC lv3 simpler and more robust where it was possible and add extensions for the benefit of the protocol can you get in the next slide please so still the goals are to not change the scope for the workflow the the CL works in before much the same way as it did in v3 there\u0027s still the same phases of negotiation there\u0027s still the same message headers and message type codes and so ideally this would make it easy for an implementation to be adapted to move to v4 or to be cross compliant with v3 and v4 next slide please so the last edits in the draft based on feedback from George and the other IETF first was to completely remove the transfer in a message which originally was present only because of compatibility issues in TCP CL v3 and I\u0027ll talk a little bit about this and a couple of later slides about PDU sighs so the extension items which were present in the transfer unit message have just been moved into the first transfer segment message which is "
  },
  {
    "startTime": "00:27:23",
    "text": "identified by a start date so this simplifies the state machine if reduces some PDU overhead and I\u0027ll talk about the transfer total length but this is is also moved into an extension item for a simplification of the sequencing and reduction in the message size the total extension item length has been reduced from 64 bits 32 bit there already was some guidance in there about make your extensions small a 32 bit total length enforces small to an extent of putting into still a relatively large bucket of available size but the intent here is is for extension capability so 32 bits allows a lot of potential future stuff the default and minimum session timeout was clarified to be compatible with the recommended values from the CL v3 so there\u0027s no change from v3 here and then reply bit was added to the session termination but just to avoid a feedback loop so the whichever entity whichever peer of the session sends the first session termination the reply bit has not said when the the reply message is sent the reply bit is set so there\u0027s a clear sequencing of the session termination and in a valid session there\u0027s only ever going to be one such and termination message coming out of each peer one of them is going to be initiation and one of them is going to be the reply and that\u0027s it and then the session termination encoding was simplified to avoid variability of the message content now instead of the type code being present or not present that the code is always present and there\u0027s just an unknown type code so this is all simplification and then this has been presented before but I\u0027m just bringing this up to show how small you can get TCP zero before as a reference or thinking about it so in a in a very low and implementation this is not a greatly compatible one but this is one that if you had a controlled network that you knew what was going on wouldn\u0027t use TLS you wouldn\u0027t need to exchange the IDS so those would be empty and you wouldn\u0027t need extensions and if you wanted to use always signals segment transfers then these are some of the numbers and that the summary version is that it\u0027s 33 archives to get a session running and it\u0027s 40 out cuts of overhead beyond the actual bundle itself so this "
  },
  {
    "startTime": "00:30:25",
    "text": "this is the level that PCB CEO is working at right now just as as some numbers to think about in the context of how big are these overheads relative to how bigger the bundles being transported and then in the sequence I break down the individual items so the took the transfer total length was moved into an expansion item and the reason for this is for a couple of things one is to allow that minimum number to be a bare minimum if you do want to do single segment transfers then the transfer that the total length becomes redundant because it\u0027s all in the one segment and segment already has a length and also moving this moving this out of that separate transferring it message into an extension item although there is some overhead with the extension item the overhead of the extension item is actually two out that\u0027s smaller than the overhead of transferring it message so there\u0027s no overall penalty for doing what\u0027s been done here and this this simplifies the sequencing and it actually brings the TCP seal or into more kind of logical line without b3 with structure and even when the transfer so even when the transfer like the extension is used it it still only adds on the order of like 15 it\u0027s of extra message size so separate from the the protocol itself this is more to do with interoperability and working code side of things the example agent that was done in Python has been updated for the draft revision 11 Lester sequencing and there\u0027s some other embellishments have been made just to show what can be done with the v4 protocol it now does graceful session termination and this was something that as a proof of concept as a kind of a justification for some of these behaviors I wanted to do this because there have been four questions coming in about the initialization and in termination sequencing so this just gives some some concrete evidence that yes this is a workable behavior and it does provide actual value to the protocol and also is a proof of concept because it was something that is discussed but it wasn\u0027t really looked at I don\u0027t think at all is the agent actually has a feedback algorithm to have adjustable segment size to hit in this case the target metric is time to acknowledge that the difference between the time when the segment is being encoded and when the acknowledgment comes back for that segment and operation I think this is the kind of thing of it an agent really would look "
  },
  {
    "startTime": "00:33:25",
    "text": "we would be looking for want to work with it you want to guarantee via your urea unacknowledged akkad data is gonna be no more than X number of seconds old on a whatever your screen you never give and I also implemented just this minimum the programmatic generator to exercise text refers to demo agent X by please Vikram one other thing that was done again these days justification I for they were to call itself points up I put together of Wireshark technically and I really your exercises I think all in the behavior before convergence layer it supersedes the stock Wireshark I expected that was what\u0027s called bundle and it was the TCP Co b3 sohave years but this handles all the messaging your handles actually Kiowas yep within sessions and reassembling of individual transfer segments into the total transfer data so I think interoperability and for example of a pack working code this a pretty nice thing to have and then I also did some minimal implementation for the bundle protocol itself but very basic because that was about to be on that next slide please it was just a picture of some of the dissected CLV for messages I mean nothing should stand out it yet I sector like wires from before but again just matter my justification for is a realizable thing and is it a reasonable thing to be organized array this and I mean nothing image here nothing in the corridors are actually too complex in the cutting up they put together with the way that the wire truck is structured next slide please right so the one open issue that is really just a matter of opinion and how much future use extensions are expected to get is the each individual extension item point now is sized for like 32 bit that\u0027s certainly more than would be expected to be used in any individual extension item there was a comment about reducing the individual item extension length basically this is it worth what it is that question but to "
  },
  {
    "startTime": "00:36:26",
    "text": "the working group is it worth saving two octets in an optional PD you to produce the besides the extension items I I don\u0027t see any strong real strong locking reason for or against other than reducing the extension items by two octets if a if an individual extension needed to encode data longer than the 16-bit size would allow it to do then the extension would have to define well if you want to encode this then you have to have multiple items and they get stitched back together somehow because items can be in multiples and repeating sequence so it\u0027s not stopping anything large from happening but it makes it more complex on the extension to do so but even rossik okay sorry retain a quick quick question here on the extension agent data little what was the vision of the authors when they were putting together the extensions of what they felt an extension was it was a small chunk of metadata or was it a whole separate big blob of something because I think that kind of guides whether you\u0027re in 60 minutes or 32-bit land the yeah the the my concept originally of extensions was I had put more more of the negotiated data into extensions so the iya some of the key IDs and some of the individual frames small parameters and even he IDs being related to URLs have processing limits that are in the order of I expect thousands of look that\u0027s not a single digit thousands not hundreds of thousands okay thanks yeah but yeah it\u0027s really intended for metadata associated with potentially information about the things that wouldn\u0027t be part of the bundle of l have to do with sequencing or priority or small puzzle that Rick again that sounds a lot like 16 bits is what you\u0027re suggesting and yeah I I really have no problem with things thinking bits and if you need something larger you figured out yourself for your reference I\u0027m seeing a few nodes around the room in here but that isn\u0027t a any indication of consensus this might be a question for the list yeah yeah this is the last one "
  },
  {
    "startTime": "00:39:37",
    "text": "of them the current status is I do have some that last so like those copy and paste naming big things face I did I\u0027d see that there were there were actual reason codes numeric reason codes included an Diana tabled but not in the actual requirement body tables I think it makes sense they include the reason codes in both just because it\u0027s you don\u0027t have to jump around nothing different but some documents to look up if you\u0027re trying to implement this thing here but it\u0027s not any new data it\u0027s just a little bit of redundant information in the spec and then like I was just talking about there\u0027s both of working implementation pending there any changes in the in coveting a working implementation against the - 11 version and a working dissector in Wireshark they\u0027re available the same place so I I think it\u0027s at least a a good position to say yes this is this is a fully functioning and as somebody had brought up earlier in the backwards-compatible in terms of being able to and there are procedures in the spec about how to interoperate with the TCP CoV 3 on the same port Brian so you need us change do you have an agreement with your co-authors about them please see it on record yes we do we have been happy what is your name we agree and you sign with your blood not in the ITF okay so apart from you know small changes and the length of that field that you describe do you think it\u0027s ready for going to the ISDN right yes I believe the answer was yes can you say again Brian oh yeah yeah yeah do people the people in the room think it\u0027s ready for sending for publication or do anybody think it should not go to publication no comments you don\u0027t care diary anybody opposed okay so I guess we\u0027re going to so Brian "
  },
  {
    "startTime": "00:42:38",
    "text": "if you could liken in one week he get the final version so we can forward it to the ihe with the bundle of the of the other specs Edie you are identified as the document shepherd so we would be looking for you know the Shepherd right up cool thank you very much are we Scott are we ready for sending the your document to for publication - I I would say yes it\u0027s ready to go ahead for publication if discussion on the mailing list uncovers need for a small change that\u0027s an easy thing to do and could be done within certainly than a week if we if we decide that okay do people in the room think we should also send this document for publication Yes No maybe yeah okay some notes okay cool so our beloved ad you will receive Tim convergence later but that\u0027s that\u0027s Christmas for a new ad right so having said two documents to Ciel\u0027s the presence of those two seals means that we can also send BP version 7 and BP SEC are now unlocked and they can also arrive so the ad will be getting for documents and and and those cipher suites extension so that\u0027s five documents we bundled all the work for the last two years and centers a single transmission Spencer we\u0027ve got a real free ride okay what\u0027s good next step where\u0027s the agenda this one I think that\u0027s yes present hi my name is ed brain I wanted to talk about the most recent updates to BP sac and the interoperability cipher Suites the BP sac has been went through a working group last call there were some minor "
  },
  {
    "startTime": "00:45:39",
    "text": "changes to it we had some initial review from over the security area we had some review for a member of an external standards organization security area and we put those comments back in and this latest version o nine represents sort of the fusion of all of that and it\u0027s you know not a lot but we can go through it next slide and I think we already talked through that and then the last part is a comment that had come up was that instead of interoperability cipher suites or as we call them now security context does need to go forward with the documents so that we can do interoperability testing we did not and we chose in the working group not to make those context part of the security specification itself but to publish them as a separate document next slide so from the ITF 103 there was a single question that came out of a review from a different standards body called the CCS yes that review came back and said your specification of cipher Suites is different notionally from how we like to use security associations would it be a good idea IETF if we were to create a security associations block and if you did what would that look like what value would it have in the in the security suite we looked at it and we drafted it to see what it would look like and we presented it to the working group and the working group resoundingly said it\u0027s a terrible idea we think that we can accomplish exactly what we need to without these kinds of large changes and without adding an additional extension block we agreed with that having then presented this comment from another group and so we did not include a security Association block in the spec the compromise was to change some of the terminology so that it was not confusing and in the security document instead of using the term cipher suite ID because cipher suite has a particular meaning to many people to say security context and a security context could certainly be used as a cipher suite identifier but could also be used in a different way particularly to carry an association or Association information other than that there were no changes with the security documents next slide and then in following through well so there were no other significant changes and we just went back and to apply that change we removed the term cipher suite in those areas we replace it with security context instead of cipher suite ID parameters results their security context ID params and results and then because we were only prototyping notionally with the security Association block would look like obviously we took all of that out in the - oh nine and and those were the changes was reacting to that final decision in 103 so VP Seco nine as it exists now has incorporated "
  },
  {
    "startTime": "00:48:39",
    "text": "the comments from the security area which was simply to mandate that any encryption is assigned a Crip Shin using an AE ad cipher suite and to clarify that integrity in this case means signature on open text and then from the CCSD s perspective we had gone back and they gave and actually this might be on the next slide so next slide please yes they went back in and did one more review of BP Seco nine and their exact word was oh this looks very good so we take that as a positive sign they had just these comments coming back three of them were minor clarifications in the text which we will happily make within the next week and they simply said to clarify a little bit of the language when you say ensure integrity services don\u0027t ensure that data isn\u0027t changed it just ensures that if it is changed you can you can detect it so little things like that add seaboard to the terminology list just say in Section three two we don\u0027t allow nesting of certain operations because if you allow nesting you it\u0027s hard to tell when the nesting stops there were two recommendations that we recommend not adopting one of them is to say why do you allow security source and context parameters to be optional because there are cases where you will not need them and in those cases we don\u0027t have to go through the overhead of carrying empty fields and the other is when you say that authenticated encryption is used in a b c b there should be a Showell statement in there not just a note I think the author missed it actually earlier in the document there is a must associated with the use of this suite so I think that the spec actually already does what it\u0027s being asked to do so I I don\u0027t have a full overview that full up overview of BP SEC onine because we\u0027ve gone through it in this working group several times it has gone through the last call and what I have done for the past two IETF working groups is simply to describe the changes that were made coming out of reviews and how we have responded to them other than those three comments from CCS yes to clarify some of the terminology there there are no other open comments about the specification that we are aware of so a question that I had before moving on to the I apologize for the title slide the interoperability security context it is to come back and say are there any other comments associated with BP SEC we have not seen them online we do have evidence that there are reference implementations that people have made for this without issue but at this point we believe that aside from those three nets we are done okay one of the open questions as Rick Taylor here with my chair hat on is the working group asked aides to room well so the SEC IDs asked for the interoperability that the cipher Suites document to be written and to be maintained as a separate document so "
  },
  {
    "startTime": "00:51:40",
    "text": "that it could be updated independently to the to the main document of the main document is sat in last call at the moment it\u0027s ready to go and it\u0027s going forwards of course this document was a personal document until very recently because I forgot to press the button in a timely manner I had not gone to that second document yet this oh sorry I\u0027ll shut up and hope so all of the comments that I made were specific to the BP SEC onine document that there are no comments outstanding for BP SEC oh nine and we think that it is ready to go I will make a dash 10 version that this week that addresses those three terminology changes because I think those are good terminology changes but it\u0027s just an editorial change separately there is another document called the interoperability security context which had been a personal draft and then was submitted as a working group and the working group had decided that we needed to put that together with the BP SEC documents so that the reviewers could review both a protocol and an example of how you would define and use a security context and and that second is is these suites here essentially the only changes from that context is we changed the terminology from cipher suite to security context with the rather notable exception of the title of this slide we updated the references to point to the latest release of BP biz and BP sac and we submitted it as a working group document and I don\u0027t know if I have another slide behind this that speaks what I thought I did and I was wrong yeah so so the the two cipher suites that we proposed as part of these security contexts are a flavor of AES angles counter mode and a particular H max I believe 256 which are which are non-controversial standard interoperability suites that you can use for integrity and confidentiality the H max sha for integrity a s4 for confidentiality that they also have the benefit of being well represented also in C bar with cozy and we were able to point to some references there in terms of how those items would be seemed or encoded which we\u0027d like to have the c4 encodings so we think that those are good interoperability suites and we hadn\u0027t heard any concern from the reviews the personal draft reviews that we have had but we would need some review at the working group level of those security contents so continuing from where I left off the Ed\u0027s personal document is now a working group document that was accepted after the last IETF in Bangkok the and I press the button very late but it is now a working group documents of course the BP SEC itself has been hanging in last call ready to go and we\u0027re now going to send it to the ad so really this document was intended to go with it but it has not been last "
  },
  {
    "startTime": "00:54:42",
    "text": "called yet do we does the working group believe this document is ready for last call and that is a formal question we will ask it on the mailing list as well but I\u0027m judging the room our intention is to last call this get the comments and then move it on as fast as possible so people need to be prompt if they have issues but we\u0027ll get that question to the mailing list on the mailing list as soon as possible thanks ed ed met company MP is that Jean so hello i\u0027m zhang zhehan so I will be presenting the work I\u0027ve done on interfacing the synchronous in synchronous network management protocols next slide please so our network management is administrating and monitoring different set of nodes on a network protocol users are usually very specific for network so on my opinion work we would have an account we would have an protocol would have a low delay high bandwidth and we will make use of these whereas and conferences on dgn we don\u0027t have all of these prerequisites so another we have to do have different constraints so on an IP network for instance we have what we call the pool mechanism on the left so we would send a request and it that I would be sent back directly under reply and each end the way is completely different we would send comments to have some ultimate and some automation with incense for instance packages on the right the graph a report will be sent every 10 minutes and so this would be called the pressure mechanism so both of this approach every optimal for the only networks but they wouldn\u0027t work on the other one so if we wants it for instance to manage some notes on a TN from notes presence on an IP network we would either use one or the other they wouldn\u0027t be very efficient so what we did was thinking we could combine the two mechanisms and exactly so so our goal was to interface in synchronization protocol or amp and network infection protocol negev so we wanted to create a gateway on a node that would be on an IP network and under the chain so I didn\u0027t a phase between the two the we wanted to for that we had to translate the data models that are used by HTTP and so the ATM and by Anakin\u0027s at a young data "
  },
  {
    "startTime": "00:57:42",
    "text": "model and finally we are proposed nian would be from an account manager to be able to send controls to an amp agent to fetch data from this agent and then who gets read and from we can\u0027t measure all of this data in excited so generally architecture is what\u0027s presented here we would have on an IP network you can furnitures that connects you to an interface on the dgn we would have the NP agents connected also 20 phase between NP so we would have only left some synchronous call because requests would have a reply directly whereas on the N side which in synchronous and requests some reports will be sent with some specific role they have been set before next I\u0027d listen so the protocol stack that we used is present here and message would be sent from an approved user interface B since you given to the manager we sent on the IP network we see the make of agents on the Gateway that would be in a face read by an in conduct role that would translate it into amp sense given to an integer if it\u0027s to give it to the on the DTM and we receive only agent and other way around it would do the exact sorry and for this because we have these synchronous and asynchronous mechanisms we need to have something to get that sir evenly so we have a cache on the Gateway meaning to on one side to register if you want to have a value but the value is not available we would register that this value is knitting and on the other side when values I sent from the impatience then we would store all this value on the Gateway so the Gateway itself has this architecture net messages would be sent on the left to the ancients given to the controller we would extract it using the information using transition function then translated into and messages that would be given to the manager in between we also cache the value and on the other side when data sent by the MTA agents they would be given to the manager and the control we extract all of these dates are putting into the cache and but initially send messages to the nakum managers so translation approach should be using is present in here on the left you have an extract of the ATM for amp agents so we have the control here which is called gin rpts or general reports these are two parameters that you can see on the red one to our collections of our ISO recently fire that identifies any element on the right we translated this control into our PC into in Mein Kampf and so this obviously has also two parameters which here leaf "
  },
  {
    "startTime": "01:00:43",
    "text": "lists which correspond to a collection in account so it means all these parameters can have a lot of different values that would be puts a new list somehow but some you can see a comment that we used so we as an account manager we using the young high utility this utility is use as an account manager said so for instance if I want to send general reports comment we use it here T\u0027s syntax so the young that emoji would be read and parsed by this it\u0027s routine and we can it would be all those who use this so we have here two parameters the first would be an air I of value say for instance you want to generate a report that would sense the number of visual diary and the agent so to do so we give as an ID what\u0027s value one generate here the namespace of it and it\u0027s also needd so next time only defined data and its name is BR so all of this is good as one pointer the second point models are the end points of the manager word which the agent have to send messages so here we have two of them we have IPIN 4.5 in a pin 6.5 and next slide please so this command sent by the income manager which translates it as an RPC XML RPC so you have it on you have the parameters in the red rectangle so this point is a PC will be received on the Gateway the Gateway will then radiate sparsit\u0027s and transform it into the dictionary you have on the right so this one is an internal dictionary that we use in the Gateway so you can see the area diptych all the specific parameters so you have we can see it\u0027s an amp agent it\u0027s a control the name is it\u0027s from sorry it\u0027s the ATM is an pigeons control the name is general Hertz then you have the parameters first parameter is again an RI with his name space at the type and everything second parameter is the lists that we sent before and this this structure is used in two with a function that will send the control from the IMP manager and that Delta G is a recruit\u0027s completely to recur CBG so if you have parameters we have partners in the air i that needs to have parameters also itself and we could recursively at them so you can see we have zero and one which has first parameter second parameter and also we have list so if collisions have to be sent and we can send different RI or strings or integers and so on when this message will be sent to the manager to "
  },
  {
    "startTime": "01:03:43",
    "text": "the agents report to be sent back to the manager on the Gateway so you have here an example of this such report the value sent would be the ten this will be stored on the database when then we have created yang module miss no in Moodle with several commands to fetch this data from any managers so we have here gets in key value even 32 to as forums and integer it has two parameters the first one value F is the name of the value we want to fetch with namespace type and name second parameter is two to decide how all hunan the data to be so if we want you if we give a small burden the data to all would be considered still under cache and if we give along a very high number then we can have more data from this guide from those cache so it\u0027s the time it\u0027s the time in seconds for instance if we had a data that is less than the South second all on the cache then the APIs you apply on the bottom left would be sent back to the neck of manager with the value 10 and the three timestamp which are no means the value was requested on the Gateway the moment was persist on agents in the moment it was sent back on the Gateway on the right if we didn\u0027t have any value in the cache or if the value were considered tails at all we would then wait for a value value to arrive and the recent value will be sent as a notification an application like a mitigation to do to the manager so instead of I mean a reply that would be a scary request and any require bit sense that would be it just like a push mechanism the message will be sent directly without any requests except so I would do a small demonstration I have it I have a video on the next line so we create sacra tank agents a gateway and manager I will then starts a comment you create some recent data from the MP agents that will be sent to the Gateway then we would use another comments you fetch this data advertisements in YouTube the resolution is all let\u0027s see what we can do about making the resolution better I hope you I hope you can see dagger was him so I\u0027m using the here the mitre simulator so from a technical detail kids it combines the core simulator for networks and it also uses the iron sword in Ness implementation and I have a very simple scenario with three notes so on "
  },
  {
    "startTime": "01:06:43",
    "text": "the Left it\u0027s under network IP network on the right is a summation of the TN so you have the notes that moves is another new TN in the middle you have the gate wing I have to create some directions and port forwarding because for networking it has to use the normal I P Network so the notes on the dgn is considered as another cell network which means then using the LAN client up left we can connect directly to as if he was directly to the amp agent the gateway in the bottom left you can see the Lightning\u0027s several parameters are used some most of them the SSH layer of neck and others is for the directory where all the young template that we want to use our prisons so these gentle plates are basically translation in yang from no from Adm so on the bottom right you also have the NIP health agents sorry the agent which is working so now I\u0027m connecting to the Gateway but as if he was connected to the agents I\u0027m loading the young data module which is on page ins and then I will add ER so tempest rolled on the Epogen to send regularly time some information like it\u0027s gateway so this has several parameters the first one is the ID of the at the time this rule you can see you can use the jung-un Clyde a compilation so the young is very this data model is very understood by the young high utility so we will send everything seconds we will generate some data on the agent and we would do it five times so the action here is given as an air eyes on MRI which is the namespace the type of the command that will be used the name of the command and its parameters so all given as a string so we have here I\u0027m agent control regions Jinnah reports so I\u0027m first parameter would be a collection of two elements we will ask for the number of its type is rule on the aim agents or not the next year the second parameter would be the number of control the happy one on the end agents and this would be the first parameter second parameter I give it simply an empty list so it would be four sent who asked for which managers and shoes we leave it empty here there was a mistake in the name of the elite not on purpose I would like to say it but I didn\u0027t write it because it\u0027s nice so I can show you that we if there is a mistake in the type check or in the name then Ike we can still check it using the "
  },
  {
    "startTime": "01:09:43",
    "text": "idiom and prevents the message from these things so you can see here on the top on the bottom right that the M agent received the message and in between we look into the database also on the bottom left you can see that the gate where is the message in between [Music] sorry so we have we re on the Gateway and on the database on the gateway so we have all of the ad DS controls in constants prison there as a reference to win the data a sense we can know which to which elements of the database on the a DM it\u0027s connected to also we will be too fast we here I will present all the data that are present on the database so it would be empty for the moments note that I receive no data yes so here I actually had to cut the video because it took two minutes so two round-trips for the data to arrive under the manager on the Gateway here we could see we had more data there is presence so far already reports has been rested on the Gateway and if you use the special yang comment that we created if we always explain before then we can ask for in Santa too so we will ask first parameter for which we ask we see which value once you have so here the agent EDG number of control run on the agent and I will write here is not a cache timeout to show you the if you write a small cache timeout then there is no enough read more reason that we send soldiers in a prettier place sense but if you increase this tigers timeout then we get the most recent send data again with this three timestamp I explained before on the soroban here is the cuts in the video and now we have here more data and we have to request values that have no debt no value so this is just registration to say we want this value we don\u0027t know what\u0027s what is at least the value baby wants these names in between the values have been so this message to ask for the value had been sent to the agents and then reportedly received for a gated value and you have here in ratification certifications and it\u0027s so with the fitted values you can close the video now I\u0027ll try pressing "
  },
  {
    "startTime": "01:12:50",
    "text": "back it\u0027s a crock something\u0027s gonna happen there we go so in conclusion we be able to send any control define an idiom using account we can also have in these controls we can have several parameters for you so parameters in parameters and so on and we can retrieve any data from the Gateway directly using income and also if some dates new data is arriving then notifications are sent to do an account manager and exactly\u0027s so there\u0027s two futures obviously so currently focus is on the supporting detail all templates from NP which are heavily use it in some used in some idioms so we want to be able to get the reports and retrieving letting as make it available for the neck of Niger also we reduce the scope to having only one gateway here if you had several gates aware that could be connected all together but so connected to all through the same GTM then we need to have some synchronization between all the gateways which was not the focus of this work and yes so we have also an irrational to calculate the cash that how long we have to wait we have default values for that also if the data is in the setting acceptance range arrive at the right sound and we directly without asking for a new value this issue here is that we have to get the value because it would be then you work for optimization and it is not the focus again on sweaty any questions so just at borane I just wanted to make one comment on the work which was the other part of the optimization you would see is the need to currently interface with the amp manager which is what is bundled in ion right now that is that is not the cleanest way to interface with something as maybe you would understand but there\u0027s other work going on to create either an RPC interface or other kinds of interfaces that would be more amenable to that so the other part of the optimization is some of the stack that was shown had things in there because of the necessity of working with an existing reference implementation right Erik Voigt Cisco good stuff a question for you on net comp and protocols that can do locking or have multiple clients connecting did you look at all about or have any thoughts about how to handle when you do a database lock on one side and queuing up transactions I haven\u0027t I know about it I "
  },
  {
    "startTime": "01:15:51",
    "text": "know that the conf is usually is supposed to have some commits on the database and everything and so I have some small support that if you comment is done at the time and all that the second all they are waiting for it to be done this is not as developed as in a real net conf database this is definitely something to you days in the development now a Rick Taylor I actually have a question for Erik Voigt who\u0027s just asked who I happen to know as finally got his yang push drafts through net Kampf which is as I understand it and I am NOT a net complex but a it\u0027s neck off notifications on steroids really isn\u0027t it do you have any advice for the guys working on this on whether it\u0027s that push-pull thing you started your presentation with suddenly made me think of the work that Eric\u0027s been working on and whether that interface could be more elegant I think we could probably talk offline some the net comp notifications of to type you can events with net comp notifications and the stuff that yang push does which is you can subscribe to datastore elements to get push on change so this is less relevant for for rights because we\u0027re looking more at how do you push on a subscription changes to the sustain of store in the back so I think that the difference between events which are when an application knows something has happened versus datastore when a some recipient cares to say what they want to receive our different data sources and both can be relevant Oh comment just at Berean again but it so agreed but in the example that was presented here there was a command to say go generate this value you know every X amount of seconds or minutes or days for this amount of time and then a separate query had to come in and say that\u0027s been running for a while now I would like to see if that data has changed and then you get the data cache timeout which says hey do you have a new version of this that is not more than 10 seconds old and and that would be a way to do it and a sort of a standard net comp way to do it I believe but if you had something like what Eric has been working on you could say generate this data every you know 10 days but whenever the value changes send it to me and then that would also help with that that that that push inside of the you talk we talk about push and pull but you don\u0027t always know when to pull and this would help you understand when to pull yes so Rick again says I think we summarizing from my own since you\u0027re saying the gateways data store that\u0027s subscribing to yank push notifications "
  },
  {
    "startTime": "01:18:51",
    "text": "on the gateway data store which is being updated by the amp management system but your downstream net kampf system can say oh hey the amp subsystem has changed the data store in the gateway and therefore I am now receiving notifications of updates yeah so comment at Berean again the the issue that one runs into is when you\u0027re trying to manage assets that are disconnected from the network for a long period of time and why we wanted those time-based rules to begin with was you wanted to say to the disconnected agent make sure every ten seconds you\u0027re producing this value with the appropriate timestamps and with the appropriate history and then when I come and see you again and I haven\u0027t seen you for an hour or a week or a month all of that appropriately time-stamped historical data comes down and and so the the one thing you have to be careful of and in the push case is do you get nothing for 10 days and then 10 days worth of information coming at you all at once and and that\u0027s really the only reason why you might not want to do that what fun what great discussions yes in this case if you\u0027re doing that I would suggest use not subscribing to data scores you subscribe to events we actually built the protocol so that when you log in it will give you the history of events even previously created events as a replay capabilities they have the ability even if you lose connectivity where it will actually give you a new start from a last event that was sent so it\u0027s been designed for filling in gaps yeah mine was to have a question here how big or how much risk for troubles because of the nature of the determine is this type of if you request something to be reduced and then you actually what\u0027s being produced exceeds the delivery capacity of of the DTN what happens then I\u0027m looking at edge to draw it out so that um Magnus while it is going to the mic it\u0027s it\u0027s not a new question you\u0027re asking it\u0027s been it\u0027s been discussed so so the the the short answer is there there is no mechanism to say don\u0027t overdo a quality of service that\u0027s in a DTM because there it\u0027s not always clear that you understand what that breaking point is the way that amp talks about it in terms of DTN is it will create bundles it will so the way that "
  },
  {
    "startTime": "01:21:51",
    "text": "amp addresses it as a protocol separate from this demonstration is to say that we try and have very compact encodings we try and bundle data that is going back to an agent or going back to a manager to not have to duplicate of data which is interesting in the sense that it is an open-loop approach so if if I am constructing a bundle to go to a manager I will put all data destined to that manager in that one bundle even if those data were produced as a result of different requests from that manager so as not to go through those overheads and then lastly because we put it into the DTN with the giving quality of service how it gets back then becomes an issue of the data within the DTN just like if you had an instrument that was producing too much data except that the management data may be of lower priority because it could potentially be regenerated mark here I have a question for the speaker um so my understanding is you have somewhat implemented EMP or parts of it to do your translation no because I use use I you see basically that yet a manager exists it\u0027s CLI somehow and I have a Python script expects which is it\u0027s what is happening and then right so I was hoping you would say I have implemented most of the mmm yeah this is a different implementation you need all the work but mark raises a very important point which is although the ANP work officially comes post are sort of phase one DTN charter items I know we have a current charter item on the architecture of management in DTN but there\u0027s been a lot of interest around what Ed\u0027s been doing and his team have been doing a lot of work and it\u0027s a proposal that we should look at a MP and work on this as part of kind of phase 2 of the DTN working group currently there is only really one implementation so those of you who are grad students have grad students are just generally bored at home of an evening having fun trying to build an amp agents that\u0027s that would be a real interest in the working group otherwise thank you Joe Nexus I think that\u0027s the one so hi I\u0027m ed again and well the two things are working were security and network management we had talked about security and we had started talking through network management the I "
  },
  {
    "startTime": "01:24:51",
    "text": "did not have a video and was not clear to me that I could share my screen so what I have is a series of screenshots and I apologize for that but either John or I could could if anyone wants to stop at the end of the meeting and get a live demo neither of our laptops we can we can show you what is going on we we have a set of specifications they are personal internet drafts right now for an asynchronous management architecture data model and binary encoding and protocol and we\u0027ve broken those out as three so we can reason about them separately within ion which is a an open source with an ion open source which is an open source implementation of those protocols there is a fully compliant amp manager and amp agent we are talking with folks who maintain DT and two who are discussing who will be building an amp agent the thought is that if you build one amp manager then it can manage any agents regardless of whether they\u0027re in ion or DTN 2 but we will have at least two and then other space agencies khari DLR are also considering their own amp agents and there are at least two different efforts currently to build alternative interfaces into an amp manager one being a web interface and other being something that\u0027s driven out of sequel and sequel tables so so there is there is some sense of what is implementable and how easier hard is it to implement and what features would we get out of it what I wanted to talk through and we can go to the next slide is what we\u0027re doing under ion as a reference implementation so just a few reminders of the things that are presented here are based on either personal internet draft or something that you could and all the software certainly can be downloaded off of SourceForge and looked at just as a piece of terminology I know that I see a lot of new faces in the room I know we had talked about network management asynchronous management in the past we draw a distinction between the architecture and asynchronous management architecture AMA which talks about why we need time-based and state-based and other kinds of functions and then we have a data model and the data model says here are the nine types of data that we need tables reports strongly type variables and so on and this is how you would use them and why they should exist and why it\u0027s not duplicative with other elements of a model and then we talk about adjacent encoding of that and how you could represent we call them a DMS but we could think of them as mids or yang modules in the function that they serve a JSON template for their specification so we could write tools to ingest and operate on them and then the ANP is simply AC boring coding of those models separate from a string encoding or a JSON encoding so that we could have more efficient messages on the wire within ion there is a network management subdirectory under the main open source directory called nm and that\u0027s where all of the implementations live in Doc\u0027s a "
  },
  {
    "startTime": "01:27:53",
    "text": "DMS is where Jason ADM files live and in contrib camp Python is where a particular code generator is now show you some screenshots for that when you build and install ion you get a manager and an agent that you can run next slide if you want to start the manager you start it by typing in nm Manager and as a courtesy for bootstrapping just in this reference implementation you give it you tell it what a ID it should have it will come up it will read any persisted definitions from the I on simple data recorder that is there and then it gives you a glorious text-based interface for which you can type text to your heart\u0027s content and while it is functional and we can walk through it if anyone is is so moved to continue to create alternative interfaces into this we would we would very much like to help and support and encourage that with next slide the agent similarly is started up on the command line again once once ion is running you\u0027ve done make install you get animation and a manager the agent takes it Sony ID and a default manager in the previous presentation there is a discussion of the receive managers if you don\u0027t specify a receive manager it goes to a default manager which you can specify here it also comes in sets off and then when it does it sends a registration message to its default manager that says hello I exist it\u0027s not required you can go in and tell the manager that agents exist but it\u0027s a courtesy next slide so what can you manage on the agent when you go into this text-based interface you see the agents that have come up these are the ones that this is the auto registered one you can forget about the agents and and you can print reports or persist reports that come in and then you can really just do commanding which is mostly what you want to do anyway and that\u0027s under build control there\u0027s the ability to send raw hex to to the agents as well which is something that we just have is sort of an expert interface so that we can capture and replay things next slide so what does ion support it right now what we have done is generated JSON encoded ATMs which are also published as personal drafts for the agent ADM itself which is this is the ADM all trolls and the data and so on that every a MP agent should be able to understand and then we have done that similarly for a generic bundle protocol agent a generic LTP agent and a generic VP SEC /sb SP agent and then we then created a set of specific ATMs for ion itself if you have ever used ion you know that there are multiple not too many but a couple of administrative functions that you use to control IP n admin ion second min BP admin and you can control ion by SSH into the machine that it is running on and running these commands but in this way we took essentially the man pages for all these created ATMs Auto generated the code so now you can "
  },
  {
    "startTime": "01:30:53",
    "text": "control multiple instances of ion on different agents over just a bundle interface you know using the N P protocol next slide so on so I just go back one so in general that\u0027s not a very large amount of data it\u0027s it\u0027s somewhat large for for us where we are now with these protocols but it\u0027s 158 data definitions about 94 controls 22 tables and so on next slide so if we take just a few examples if you are in that interface and you say go show me all of the controls that come out of say the BP SEC interface that\u0027s the window on the right a zoom in of just one of them is on below and it\u0027s the example that says go at ABC B rule which anion is a rule that says if you are sending a block if you are sending a bundle from source source to destination destination and it has a block type of that particular target it must have a B C B and the B C B must use this cipher suite ID and this key identifier and you can then you know start playing with those rules and security configurations and policies separately over over the ANP next slide we have tables here\u0027s an excerpt of tables for a generic BP agent one of the tables we call them table templates is for example alt docks if you are configuring ion and you would like to get a general dump of what the end points what are the index out docs protocols supported schemes and so on you can generate that information in a table format and get it pretty quickly and it\u0027s it\u0027s just a nice way to parse that remotely next slide so here would be an example of a poorly ASCII formatted table result coming out of the text interface which is if you just bring up a loopback interface and one of the loopback interfaces that is bundled with ion you will get in this case I used s TCP but this would be the out ducts that are Auto configured on ion or s TCP next slide and then you also have a report and report templates they are a bit like tables the difference is that in our model users can generate custom reports as well that pull in data from various other ATMs as they need to and you could parameterize reports and and that bit of associative look up was pretty motivating to the use cases that we have so the generic BP ADM has two reports one is a full report which is all the stuff that we know about that is specific to the agent at the overall node for the agent and then a specific end point report that says for every endpoint here are a couple of pieces of information that we track separately next slide we can certainly request a report if a report comes in we can print it to the screen it has a lot of it has 43 data items in it but a data item just like a report can also be parameterized there are cases where it is helpful and useful to do that in cases where it is "
  },
  {
    "startTime": "01:33:54",
    "text": "not an example of where we use it and the available storage here is a configuration issue I don\u0027t actually have that much storage on my machine they\u0027re tremendous well to some unit of measurement I\u0027m sure that I do but if we look for example bundles by priority that\u0027s a piece of data but you give it a mask and you could say give me the bundles by priority for all priorities or just for low priority or medium priority or high priority in the JSON ATM when you specify this you can specify I would like this data item with this particular hard-coded parameter or with a parameter that flows in from somewhere else in this case the full report has no parameter and it out lies of these as they are and that\u0027s how you get that particular date and we do it one for each priority type if we go to the next slide you would see an endpoint report and on the slide on the right you would ask the agent to produce an endpoint report for in this case IPIN 1.0 1.1 and 1.2 and it would come back and say the endpoint report itself has taken a parameter IP n 1.0 and it contains three pieces of data which themselves are parameterised and the parameter and the report flows down to the parameter for each of these data items and it pulls it out we particularly like that because we don\u0027t always understand how many different types of things we will have so we don\u0027t always size a static array we also don\u0027t want to have to do one spin of understanding how to match to an array index a particular associative lookup and and we like the idea of being able to put the associative lookup in the request itself next slide so if we look at then with the JSON files themselves are so in this case there\u0027s one called the SP SP in iti think VP SEC agent and this is how you define a control right now we\u0027ve tried to keep it simple as simple as possible you have the name you have the parameters that it takes you have a description there is some other metadata associated with the a with the ADM itself I\u0027m sure there may be over time some of the things we would like to add when we define a control we are all ears for that but again the BCB rule takes 5 parameters when sending from source to destination this target use a b c b with this cipher suite security context at this point and keenan next slide BP endpoint report parameterised report you\u0027re able to come in and and say I have a report and the report itself takes a parameter in its definition and the report template will have three pieces of data in it and each of those three pieces of data also happened to be parameterised listed somewhere else in the ADM and I would like to flow the endpoint ID parameter into the definition of the ones that contain the report so so what is interesting about that is the ADM has a way of specifying whether and how you flow parameters into contained objects and then you don\u0027t have to worry about that when you auto-generate the code or when you specify it in some other way eggs like it can I just jump in there "
  },
  {
    "startTime": "01:36:54",
    "text": "because I know from my conversations because I\u0027m pretty dumb when it comes to these things the parameterization is is a very strange concept and you wonder while this effort has gone in the reason is to make sure that pretty much all these requests are one round trip because unlike you know this is it this is a DTN it\u0027s gotta be one round trip because you could have four hours of latency on this I\u0027m particularly ok guys for the neck home for my grant where you say oh how many items have I got great get me item one get me agent two gave me agent three sorry no I know it\u0027s appreciated ends an important point and I it is also a point that we have talked about in the AMA document which is sort of our architecture and reasons and rationale for why we made some design decisions although we\u0027re certainly happy to revisit any of them and and talk through them next slide then if you if you have these Jason scripts or these Jason files we package a Python script with the I on open source it lives in NM / contribs camp Python it is a capi generator for amp and if you have it and you can see in that first instance if you type camp you\u0027ll get the usage out of it the minimal usage is you type camp in the name of a JSON file and it will auto generate some I on dot H and C files if you had previously auto-generated and hand-tooled some dot H and C files you can give those as parameters back and it will carry your changes through when you do updates and that sort of code round-tripping and what it will produce in an output directory of your choosing our v dot h d-- files that can be compiled into ion to help with its adoption next slide so it will create an agent directory with three files that get compiled into an agent it will create a manager directory with a file that gets compiled into a manager and then a shared dot H file that can go between them what\u0027s interesting is is that the manager file does not need any user edits it has all of the information in it as is and you don\u0027t ever need to look at it again the agent has one file that is non user editable and then two files add a check see where you go in and put implementation information next slide and here\u0027s an example of what that looks like the the only thing that you have to provide an implementation for are things that you have to provide an implementation for is if you define a function you have to provide the body of the function so this would be an example of a function definition at BCB rule and the stub that would be auto-generated for it and the place where you would put your custom implementation next slide would just be an example of the custom implementation coming out of the eye on open source to actually add a BCB rule we have some API parameters for extracting and validating parameters and Aion already has an eye on secondment function that performs this purpose and we just pull the parameters out and call the function with some error checking next slide in addition to if you define a function you have to give "
  },
  {
    "startTime": "01:39:54",
    "text": "implementation for the function if you describe a data value you must find a way to sample that data value we had for example in the BP endpoint report one data item was whether the endpoint was active this is the kind of stuff that is auto-generated for a defined piece of data if you then go to the next slide you\u0027ll see an implementation of how to go get and return that piece of data the last one and I don\u0027t have an example for it here although it is there is a table if you define a table template you need a function that will populate and send back the table but otherwise for reports for macros for variables for time-based rules for state-based rules there is no user action associated with that you implement functions you implement data collection you implement tables and then everything else is auto-generated and compiled in for you and it has made the adoption of these ATMs in Aion go quite quickly and next slide that might be it so so that is where we are there is a reference implementation in ion there are scripts that will parse JSON ADM files the formats for all of these the a MP and the C Boer encoding the ADM and the JSON template the overall architecture and the design decisions and all of the ATM\u0027s that we have talked about which I think total is about 15 documents are are available and they are published as I think personal personal IDs but I think you can get to them in some way from from the DTN page so if anyone wants to see anything else I\u0027m happy to show you on my laptop but otherwise thank you very much thank you sohcahtoa Boris or Martin I wasn\u0027t sure who was actually presenting so these are the guys who\u0027ve been doing some work at the hackathon on the PYD TN implementation and wanted to tell us about it hello my name is Martin Milkha I\u0027m from ex-works and we are working on hackathon we did some work we would like to present to you we do have implementation of pi d TN which is a python implementation of some basic DT and stuff and although we are communicating with Microvision so this is integration work and microfiche TN is developed by D free tea and network from Felix and Felix Walter and Marie\u0027s money like this so basically is the presentation we shot on the hackathon our use case is very simple we do have two ground stations and we would like to communicate with each other they do not have any any other means of communication just a satellite because "
  },
  {
    "startTime": "01:42:54",
    "text": "they might be they might be located on different planets actually we we are not planning to locate them outside of Earth in 2020 so the youth is the actually ground station one get some sensory data like temperature or similar encodes them into the bundle then eventually when the satellite is in sight it will send it over DT n bundle protocol seven satellite will not see the canal station - right away so we will have to store this bundle somewhere and eventually as it continues on the orbit and we will see the connotation to it will send this bundle we are still discussing whether we are going to beacon approach or whether we are going to use or that would be opportunistic routing or deterministic that\u0027s under discussion but for the purpose of this presentation of what be implemented is that we have one docker container per object that would be ground station one - and satellite and ground stations are running parity N and satellite is running Micronesian and we have some demo which we can which you can see on the laptop if you are interested it is really works like slide please so we are touching free free drafts here bundle protocol version seven then there is TCP CL conversion is where we are working with the old version version well not the one discussed today the previous version for now and we are also using IP nd actually there\u0027s a plan to use IP nd code has been written but it\u0027s not used yet we identified some issues there for example the eye pain in draft is expert but we would like to see that up to date because it would simplify testing of our approach because as far as I know and please correct me if I\u0027m wrong of we are not aware of any other way how to how to network discovery name sorry neighbor discovery could be done except this already expired protocol so that was the issue we were trying to address on the hackathon and our solution was that let\u0027s check if the document is still up to date now I mean IP and IDO and bring it back to life maybe up to date means like okay it is expired that something we know but maybe the information contained inside is still valid so that\u0027s what we are trying to to "
  },
  {
    "startTime": "01:45:54",
    "text": "confirm or reject next slide please so this is just an information flight for the hackathon purposes being basically improved our implementation and you can see our code if you are interested it\u0027s publicly available by DT ending in good luck next slide please yeah this is probably the most interesting flight of this ball presentation of which would be the feedback to DTN workgroup or we would like to see IP and it draft up-to-date and possibly adopted by workgroup unless there are some other means how we can do the discovery because what we are doing today is that if you want to test cooperation of multiple multiple implementations and there are some for example there is this as far as I know implementation in go language just recently showed on the on the email list and there is Java implementation VR able quite easily to put them into container and communicate with them but they do not know easily about each other because this IP n D stuff does not work then what we what we notice actually that IP and D he uses Sdn V for encoding and decoding numeric values which is kind of different approach from what we are using in bundle protocol C bar is used so if the workgroup decides that the IP any draft should be brought up to date then probabilities would be one of the things which should be fixed it should be C or most probably involve drugs to be consistent and then there was this recommendation from Felix that IP and D currently obviously depends on IP but it would not have to because the IP requirement is not kind of it would be possible to it would be possible to extract that so we would have something like not IP and D but D T N and E which still can name but that would mean I\u0027d be VIP whoa but it would also support filter clas which currently is not the case other option would be like what we have today that there would be one one draft pair where CLA that\u0027s also an option so this is something we would like to discuss today feel free to express your opinion and that\u0027s it thank you for your attention thank you very much guys um Rick chair hat on maybe discovery is an active charter item and I know about shortly "
  },
  {
    "startTime": "01:48:55",
    "text": "before I started as a chair people were looking at neighbor discovery I was a proponent for I agreed with Felix that I think a DTN nd using clas and maybe event-driven would be a way to go I know there are other people in the room Ronald for example who wants to go the other way so they\u0027re doing it if you want to volunteer to start working on it it would be very welcome your way if there is a will that war group wants to have any standardized it\u0027s a generation do we we have to have it we have to have a standardized we\u0027ve agreed so that we are answering to do that at least start a discussion on the mailing list after here but yeah I think people want to talk about it but even an opening draft of here are some ideas I\u0027ve had and we\u0027ll start the conversation we are especially interested okay well it seems we are in kind of agreement regarding first point that we want to have the draft up to date and regarding second point possibly as well both at this as the end we should be removed regarding third point what do you guys think I mean is it a good idea to remove the IP tendency in IP nd graft and call it DT N and D or something similar do you think it\u0027s this is not no way to go mark here we all know that DT and may not work may not be transported over IP anyway that\u0027s true but I thought so you know the way oh the why we are actually interested into into this is that it all of us very easily to test our application level changes with other implementations so that\u0027s why we care and well you know so you made a point actually that the TCP CL is gonna be the only only convert as layer yeah that\u0027s a valid point what do you what do you think fairly good actually this was proposed by you and we hopefully have some people in the queue already yeah I was about wrong in felt I was about to say that the only converts layer data that we have so far is IP based so I\u0027m not saying that I PMD or DTM E and E should be the only game in town you can do other neighbor discovery protocols later but I presented this in Buenos Aires and it was killed within five minutes which year was this 2016 and I\u0027m happy to bring this back to life and work with you to to do those first "
  },
  {
    "startTime": "01:51:55",
    "text": "two bullets and have a trust out before Montreal but if this is going to be something with a new architecture back to the drawing board let\u0027s do a very generic thing then then I\u0027m often was not interested thank you Ric Bucher there\u0027s nothing to stop us doing both I see real value in refreshing IP neighbor discovery making progress on neighbor discovery particularly as there\u0027s interest here in the room great let\u0027s do it if in parallel people want to have a long esoteric argument I\u0027m happy to join the longer esoteric argument on the mailing list and hopefully that might well it probably won\u0027t be productive at all but it\u0027ll keep us all busy I can do one and somebody else can do the other I\u0027ll do the other staying right off here I\u0027ll sign up for the esoteric argument on the on the e mailing list I\u0027ve got a lot of heartburn and I don\u0027t think I\u0027d be the only one in having a non IP based solution coming out of the internet Engineering Task Force okay no but however Rick here there are other stos such as CC SDS I can see Scott standing behind you in the queue whom who will standardize through their own body convergence layer adapters and they\u0027re looking to the IETF for for guidance on given the IETF owns bps v7 and is driving that forwards then I think that defines the behavior if you want to put on architecture together on this neighbor discovery so that you can slide at different train transports underneath it where IP is the one we\u0027re doing here and somebody else may do it you know some other SDO may do it in a non IP fashion great we can we can all get together and knock our lights out on that one but out of this standards body it well I\u0027m gonna lobby for it until they come to shut up Schiaparelli I\u0027m I think I\u0027m in strong agreement with that last comment is that there\u0027s I don\u0027t see any obstacle to having an architecture that that draws a clear interface between the portion of neighbor discovery that is the exchange of the discovery information and and the portion of neighbor discovery that is establishment of the connection over which that information flows and the "
  },
  {
    "startTime": "01:54:56",
    "text": "latter obviously the first one to build would be an IP base substrate for neighbor discovery but I don\u0027t see any advantage in having a proliferation of vastly different neighbor discovery protocols for different environments I think it makes much more sense to have a standard data exchange of neighbor discovery information and and separate from that connected through and through an interface through a well defined interface the convergence layer connection establishment connection management software that would initially just do IP but could in the future do something like Bluetooth Wi-Fi and and not necessarily rely on IP I I think would be a mistake to require that that the only product of neighbor discovery development be something that only does IP and will never do anything else mark here so it\u0027s great to see mark as a chair great to see people interested in the next topics because that were that are you know neighborhood scurry is one and addressing architecture and a few others have been you know sitting there waiting for you know the ground the basic work to be done which is we\u0027re done almost I have to remind that we also have LTP as an RC that was discussed here right somewhere we\u0027re not only I ve just one short note this is Martin Bilka again I just want short note from what Scott said oh we had a lot of feedback on the hackathon people coming to our to our group asking like I can be used this in IOT world we have this problem that actually we cannot see our sensor all the time so it there seems to be an interest from industry out part of the world of using this because right now they do use some proprietary things so it\u0027s actually net neighbor discovery might not be needed only in IP war but maybe also it could be over over Bluetooth or something something else I agree with that and that\u0027s it thank you very much I think we\u0027re done with the agenda thank you very much for our attention so "
  },
  {
    "startTime": "01:57:56",
    "text": "whoever wants to see the live demo please come to us thank you so I took a few I took a few notes of you know next steps so BP base chairs will send the request for propagation our Shepherd Fred would be writing up finally TCP L TCP CLV for Brian will post last version quick change chairs will request SAP application add bearing Shepherd will submit the Shepherd right up BP sec had to post the last version chairs to request for publication scott burly to write the do the write-up em minimal tcp CL we will have to do a working group last call because we haven\u0027t so we will do if everything goes fine we\u0027ll request for publication we will be looking for a shepherd for this M TCP 10 TCP CL document might be premature II but if anyone is interested in in volunteering for this run out okay well no fine BP SEC interrupt chairs to do working group last call we haven\u0027t done a working group last call on this one if everything goes following request for a provocation we need a shepherd anybody I have someone in mind the same Shepherd that does the BP say because it\u0027s kind of a the two documents Scott do and you know that would be a good results to do all this and I guess probably at that time would be a good time for chairs and the working group to actually revisit that were milestones and we actually started this with you know a topic of interest which is neighbor discovery and obviously management would be another you know clear possible mice on so we\u0027ll have to you know have a chat on this and I guess the chairs will start that discussion you know when when the whole pile is is is gone or I think it\u0027s probably worth getting through those last-minute panic comments as we get the documents out the door and once they\u0027re safely nestled with the iesg then we can start our discussion I\u0027d also say I think addressing we\u0027ve got to start tackling addressing fairly soon because we\u0027re pretending you don\u0027t need to name anything but but you do any last comments sorry just zhang zhehan just for to say "
  },
  {
    "startTime": "02:00:57",
    "text": "that i have its well shown under the video is present in my laptop so if anybody wants to play with it can just come to me from rick one last thing other than thank you is a big thank you to the hackathon guys and the guys showing running code you go to a lot of IETF meetings where people are talking about the status of drafts and then everyone types on their laptops it\u0027s really nice to see stuff happening in the working group involving running code and that kind of stuff I personally really like that kind of thing so big thank you to you guys otherwise are we done mark we\u0027re done thank you very much guys thank you blue sheets everyone sign them sorted goodbye "
  }
]