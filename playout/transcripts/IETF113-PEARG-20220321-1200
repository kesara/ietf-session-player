[
  {
    "startTime": "00:00:24",
    "text": "uh so so so"
  },
  {
    "startTime": "00:02:25",
    "text": "so so sorry does the share preloaded slides optional okay let me try that again this one okay let everybody remote and in the room"
  },
  {
    "startTime": "00:04:02",
    "text": "hear me now yay okay okay so welcome to the perigee pitting at ietf 113. this is a hybrid meeting you will have noticed that unfortunately none of the chairs were able to be there in person so there is a sad little empty desk at the front um i will remind everybody that this thing is being recorded before we go any further and if i can uh if i can ask for a volunteer for a minute taker if you're interested in that please contact the chairs by the chat okay as usual we have the note 12 which we hope that everybody is familiar with and has read and in particular we draw your attention to the code of conduct the highlights on this slide and we expect everybody to adhere to that moving on to the agenda the blue sheets are generated automatically by your attendance in meet echo these days uh shivan will be acting as javascribe we'll be monitoring the chat so if there's anything to put in there you would like asked at the mic please prepend it with mike and he'll bring that to you we have a notetaker thank you very much and our agenda today is uh fairly light we have one presentation on the effectiveness of quick padding against website fingerprinting"
  },
  {
    "startTime": "00:06:02",
    "text": "we have a presentation on gdpr and network privacy and then we have one update on the state of the server worldwide censorship technique draft by mallory before we get going i will just quickly ask that or remind people that participants in the room will need to join queue via meet echo and then they can go up to mike to ask the questions but when they do please do state your name clearly as with masks it makes it particularly hard to see who is speaking and the full participants can keep their audio and video muted uh when they're not speaking that will be much appreciating i see that there is an echo i hope that's not me i will switch to a headset um okay some folks are hearing it and some aren't so i don't know if it's okay maybe the in-room like ah yeah maybe mike is picking something up uh hopefully that will get sorted out um we will start by moving on to the first presentation given by sandra sidney um sandra would you like to request to share your screen drive your own slides hey william yes yeah okay that's good i can see your slides please go ahead uh let me just try to"
  },
  {
    "startTime": "00:08:00",
    "text": "move uh the slides okay that works uh sorry for the echo okay uh hello everyone uh today i'm going to talk about uh work on developing defenses against website fingerprinting of quick traffic this is a joint work with ludovic christopher marwan nick and carmela and we are from epfl and cloudflare so before i go into the details of our work i just want to give a quick overview on website fingerprinting so let's say that we have a client and this client is trying to visit a webpage in this case example.com we have an adversary that's on the path between the client and the destination host and the adversary is observing the traffic between the two parties now since the channel is encrypted uh the client sorry the adversary does not know uh which web page is being visited by the client uh all the adversary can see is some metadata of the traffic and in this scenario the ip addresses uh we assume that there are measures such as ech or encrypted dns so that the adversary does not see the domain uh that the client is visiting so the goal of the adversary in website fingerprinting is to determine uh which webpage is being visited from just observing this metadata in order to do this the adversary has a pre-trained machine learning classifier that's already been trained on some network traffic traces that they've collected so what happens here is that the"
  },
  {
    "startTime": "00:10:02",
    "text": "adversary gets the traffic sample and then creates some features so on the left side of the slide i have some of the characteristics that the adversary uses in order to develop these features and these features are then fed into the classifier and the classifier spits out a prediction uh on what webpage this could be and this is how the attack works so in our scenario we are interested in seeing uh how website fingerprinting works over a quick connection between the client and the destination now uh website fingerprinting on quick traffic is not new uh it's actually already been done and this work was actually presented at the ietf last year and they concluded that it is no harder to fingerprint quick traffic as compared to tcp and the adversary can identify pages over a quick connection with high accuracy what we are interested in looking at is whether it is possible to develop defenses against being fingerprinted by such an adversary so if you look at the quick rfc there is this option for a quick padding frame that allows you to increase the size of quick packets and the rc specifies that this padding could potentially be used to provide protection against traffic analysis and this is what we are interested in exploring further so i want to talk a little bit now about the adversarial model that we are considering uh so we have a bunch of vantage points which can be routers or switches or middle boxes on the internet and they are"
  },
  {
    "startTime": "00:12:00",
    "text": "located in different ass so let's say that we have a client in asx in this scenario and the client is interested in visiting uh some webpages which are hosted on destination hosts uh in another as uh this is for simplification that they're all in the same as but they could be located in different destination holes in different asses now these web pages can host sub-resources which are also located in many different endpoints so when the client tries to visit and obtain these resources the network traffic passes through a bunch of different vantage points uh as seen by the red arrows here so in our scenario the adversary is an as that is interested in finding out which webpage is being visited by the client now these vantage points will collect different subsets of the traffic and as we saw here we have a machine learning classifier which uh which requires collection as well as storage and computation on these traffic traces so because of this we actually have a centralized location in each as and all the vantage points uh transmit the traffic that they collect to this location which actually performs the website fingerprinting attack as seen by the purple arrows so what we want to do now is the goal of the adversary here is to identify the correct web pages uh web page among all the web pages that are hosted on a single ip so since the ips are seen by the adversary they can already filter traffic based on ip"
  },
  {
    "startTime": "00:14:00",
    "text": "address so they just need to identify which web page is being visited among all the web pages that are posted on one ip address in our scenario so we do our experiments with a quick dominant uh data set uh of 150 pages here so we did this by crawling the web pages in popular uh lists such as the alexa one million this is similar to prior work that's been done on free traffic and we looked at uh which web pages have a high proportion of quick traffic uh since uh quick is still being adopted a lot of web pages are still transmitting their resources over non-quick connections but since we are analyzing quick we wanted to build something which has primarily uh quick traffic and we found that for our data set we had approximately 70 percent quick traffic on average uh just want to note that previously we tried to be more realistic and we partnered with cloudflare uh to look at uh domains that are hosted on a single ip uh and get the traffic traffic for those but those had only about four percent uh peak on average so we went with this method to build our data set um as i mentioned this is the process that we have for the for the website fingerprinting but now we see here in the second step we apply a defense to the traffic sample which i'll come to uh in the upcoming slides and then we pass this defended sample into the classifier and we see how well the classifier performs against these defended traces um i'll be using a couple of uh well-known classifiers from the"
  },
  {
    "startTime": "00:16:00",
    "text": "literature which is there in the yellow box below if you have any questions you can ask me about that later so the metric that we are using to evaluate is a common metric used in these kind of works which is called f score now f score is the harmonic mean of the recall and the precision of the classifier so recall means how many relevant results are returned by a classifier and precision indicates how many of those are actually correct so we have 150 pages in the data set which means that if we were to have an adversary randomly guess which web page it was we would have a 0.67 percent chance of getting this right but we see actually that uh for our uh classifier we get a 96 percent f score which means that on undefended uh traffic the adversary has a very good uh chance of identifying the webpage that is being visited by the client so when we look at what features are important for the classifier we see actually that the size based features are very important so how many packets of particular sizes as well as the total number of bytes that are incoming and outgoing are mainly used by the classifier to identify the page so the first thing that we do is we try to apply some defenses to hide these features from the classifier so the first thing that we do is we pad individual packets and hide the packet based uh features as shown in the figure here and we see that that does not uh really decrease the f score by a lot it goes down by about two percent um [Music] the next thing that we do is we hide the"
  },
  {
    "startTime": "00:18:00",
    "text": "total amount of traffic in both directions by applying some amount of padding to each of the packets and we still see that the f score is really high which is about 92 percent and now we look again at the features of the classifier to see why it is doing so well when five space features are no longer used and we see that there is a lot of directionality based features that are still leveraged by the classifier so hiding the total size and individual size does not hide how many packets are going in each direction and this is now being used instead of the size based features so in order to hide the directionality-based features uh we now perform this defense where we inject dummies randomly into the trace and what we actually see is that injecting dummies does decrease the performance of the classifier but it also comes with a high cost so we see that it goes down to about uh six it goes down by about 16 percent in the worst case but with a hundred percent overhead when you add these dummies and this is not including the uh additional traffic just is injected in order to hide the packet based features so what we come to what we conclude is that these network defenses offer low protection with high costs for example just to get a 10 reduction in f score we need more than 50 percent overhead when it comes to dummy injections now so far i've talked about an unconstrained adversary and this adversary observes all the traffic and also performs uh this classification"
  },
  {
    "startTime": "00:20:02",
    "text": "with all the traffic that it sees but in reality it is possible that you don't have a perfect adversary and adversaries can be constrained not just in the amount of traffic they see but also in what they do with this traffic so the first thing we look at is an adversary that has a limited view of the traffic so for example you have a vantage point of as5 you might miss a lot of the other red arrows and the other traffic that the client is uh generating so in order to see what this is actually observed how much of the traffic we generated uh trace curves from the client for all the pages in our data set and observed uh how the stray shots pain so this is the result from one of the vantage points that we conducted the experiment from uh we did this on multiple vantage points and we observed similar trends uh and what we see is that there are only a few large asls that can observe a large proportion of the traffic in the first place so that means that uh here in this scenario on the left plot we see that there are only three yes that can even observe more than 50 of the pages in a data set and on the right clock you see that for those pages about three of them can observe more than 50 of all the routes for each page so this means that a lot of the adversaries by virtue of their location might not even be able to successfully conduct an attack another interesting thing that we saw was that google actually has a large relevance on the pages so more than 80 of the pages on our data set contain at least one resource that is hosted by google"
  },
  {
    "startTime": "00:22:00",
    "text": "and uh found that actually these resources could be um ordered differently and different web pages which means that timing to google resources is a low cost fingerprint and can uh have up to 77.9 percent f score this means an adversary for example like an isp i can just use times to google instead of using all the traffic that we observe and identify with high accuracy the next thing that we noted was how well these advertisers perform with limited uh processing so previously uh i said that random phones are transmitting all the traffic that would observe to this centralized location uh now what we wanted to see if instead of transferring all the traffic whether these vantage points can just transmit uh flow summaries of this traffic to these centralized locations so in order to simulate this we use something called sampled net flow uh so what happens here is that the packet races are sampled and then uh flow submarines are created and these are sent to the centralized location and we perform the attacks this with the submarines instead of the packet traces and we experimented with various uh sampling rates what happens to the adversary's performance so as expected uh we see that with lower sampling rings you also have much lower performance of the anniversary because there is much less traffic for the adversary to make good features from uh just want to note that even at a 0.1 sampling rate it is still much higher than the random baseline then when we applied the padding lenses uh we do see that there is some reduction"
  },
  {
    "startTime": "00:24:01",
    "text": "in the performance of the adversary however we want to point out that in the case of the limited adversary a lot of the gains come from the sampling process here more than the actual application of the defense so what we actually find is that is that the network layer defenses in the case of both unconstrained and constrained adversaries do not efficiently uh hide a lot of the global features and the main reason uh for this is that they do not know the sizes of traces in advance to efficiently design uh padding strategy so there is no application layer information uh that is given here and so you need to randomly inject dummies um or add size based feed size based defenses and this could increase the overhead of these network layer defenses so then we wanted to see whether applying defenses the application layer could potentially help protect against these attacks so in order to do this we started analyzing the structure of the pages uh so here's a quick uh refresher on terminology that i'm going to use uh so let's say that we are visiting example.com uh you might have resources from uh uh exam from the same domain example.com and these are called uh first party resources or you might have resources from other domains so here you have tracker.com and these are called third-party resources and when we look at the web page structure what we see is that in our data set uh 18 of the web pages actually have a very small number of first party resources so you actually have a large"
  },
  {
    "startTime": "00:26:01",
    "text": "prevalence of third parties and there is in a large prevalence of google resources in our data sets so 24 of the pages actually even have more than 50 percent of google resources so what does that mean when it comes to applying a defense it means that third parties are contributing a large proportion of resources to the webpage and in order to apply a defense we actually would need cooperation from all the parties that are supplying some resource to the web page and we actually did do experiments on this where we hid the resources from third parties or from first parties to simulate the scenario of only one of these parties participating in the resources and then we went for the application defenses so we applied the same uh packet and space padding uh to uh but at the application layer so we are protecting the actual resources here and we still see that uh the packing is ineffective here once again because of the because the adversary just uses the ordering based resources however when we apply uh dummies now into the uh uh into the uh resources we actually see that uh this can be more effective than in the network layer case and for example injecting five dummies on average reduce the f score by 39 with a relatively low cost but in reality if you wanted to implement something like this that actually comes with some deployment complexity because injecting dummies here means that you're actually sending some requests for some dummy resources and we'll have to think about how those would be implemented uh and how that would uh impact the client's experience so in short"
  },
  {
    "startTime": "00:28:00",
    "text": "what we found is that at least for the network level if we want to implement an efficient resource we need some sort of information from the application layer otherwise this could lead to large overheads at the same time if we decide to implement things on the application layer they come with a whole set of other complexities so they would require some sort of coordination between parties or we would have to talk to developers on how to uh how to write code so that resources are always fetched in some sort of a standardized manner and finally all of these changes in the application layer could potentially have a large impact on client experience at the moment we are working to see uh further what kind of practices would have to be done in order to develop better application layer defenses and here's a link to our paper and feel free to ask me some questions thank you um i see some people in the queue uh sharon yes i how are you sandra thank you i have a i have a question for you if you think of the definitions uh slightly different where the adversary is actually the client sending traffic because his malware and he's doing some data leak or lateral movement and the one sampling is the protection software really has a very high score by sampling netflow and"
  },
  {
    "startTime": "00:30:00",
    "text": "detect the raw the rogue client so according to your analysis the only way the malware can throw off the detection sampler is by injecting a lot of dummy traffic into whatever it does to avoid the pattern recognition is that correct uh so you're assuming here that the client is the adversary right yeah he's malware and i want to detect him by sampling and you're saying if i use quick it's not going to reduce my f score but if he's going to use a lot of dummy traffic in his malware then then yes but at a high cost something like that yeah so so in this scenario uh what you're saying is that actually uh analyzing the network traffic would be a good thing because you want to detect the malware yes yes uh i mean what i'm saying right now is that generally most of the defenses that we have or rather in this scenario anything to prevent this detection are not going to help much so you would be able to detect this with a large accuracy already and if if the client wanted to perform against that they would have to think of some good way of injecting dummies as you say great great thank you very much we'll look forward to seeing some raw data if it's possible to share yeah we'll be sharing that thank you very much thanks um did you want to go next yeah thank you for this presentation it's very useful for us to think about this"
  },
  {
    "startTime": "00:32:02",
    "text": "type of threat and it's useful to get some data um i'm curious about clarifying the threat a little bit more precisely i've just skimmed the paper but my understanding is that you uh removed all caches and just made a single uh web page load to the index page of each popular domain name and the goal was just can you distinguish loading the index page with no caching of one domain versus another in cases where for example they're hosted by the same cdn or something like that yes that's right and and so i'm just curious like how is this how is this type of attack going to apply to cases where maybe i don't go to the index page or maybe i load a customized resource or maybe i have cached resources or various other situations like that because it seems like many of the times that we're worried about the network adversary we're worried about them learning what i'm reading or um or the contents of my messages or lots of different threats and that's not to downplay the threat of them knowing that i'm even going to a particular domain name but does this threat also apply to learning what pages i'm visiting or or cases where the network traffic is going to be mixed or resources will be cached et cetera uh yeah that's a good question and this is also a field of research in this area so like you said we are working with relatively clean traces here where we are assuming uh no caching and like no background traffic and it's just the home pages but we are planning now for example to do some experiments where we are also visiting subpages of different websites to see how well this attack is going to"
  },
  {
    "startTime": "00:34:00",
    "text": "work and there is also i think work done by others now there are some papers coming up where they're looking at fingerprinting in the presence of all these factors that add some noise but yeah i i would say that this is kind of the worst case for the uh worst case i mean the best case for the adversary and all of these factors would uh possibly lead to a reduction in the f score that's that right we don't know how much of a reduction but yes it will be worth further research uh yeah we'll probably get some numbers when we run this possibly next month okay great well i think many of us will be interested in those numbers too thank you thanks okay sandra thank you very much for that presentation and for all the questions there is some interesting discussion in the chat and i'm sure sandra will follow up there on that as well thanks sarah yeah thank you okay so our next presentation i believe is one by somebody in the room a real person there we go step forward thank you do you want to attempt to share your screen okay sandra you may need to stop sharing your screen please okay great and [Music] okay here come the slides i think okay i think they've loaded okay go ahead then please so i'm luigi i'm gonna present a little bit um the relation between gdpr okay luigi i"
  },
  {
    "startTime": "00:36:01",
    "text": "i'm having trouble hearing you i don't know if everybody else is as well maybe you're okay in the room but it's quite quiet remotely better better thank you okay just to hit the mic with the mask okay i'm going to talk a little bit about gdpr and relation with the ip addresses in general a little bit um as the title say that how layer eight meets layer three okay uh knowing i'm not a lawyer just to be clear so this is my interpretation i spent some time reading and uh so i'll give you some some some interesting point that we may discuss later on so i'll really one slide history some terminology and then we dig a little bit in gdpr and ip addresses there is a a few slides that make a clear link between existing rfcs and gdpr if time we will go over that as well okay so um gdpr came into effect in 2018 so it's not that long ago replaced a very old uh data protection act in europe it is a regulation which means it is slightly more complex than a simple law because there are articles which are the law itself but there are also recitals which are notes that explain actually how to apply the laws okay which is the body of gdpr luigi i think it's still pretty quiet if you wouldn't mind just um just speaking up i guess a little bit speaking even more up okay as much as i can okay thank you the key point is personal data okay what is personal data is anything that can identify a natural person not a legal person like a company is different a natural person like me all of you in the"
  },
  {
    "startTime": "00:38:01",
    "text": "room and connected elsewhere name personal addresses anything that can can identify ourselves information concerning our employment financial information you have the details in this slide which is pretty worthy there are also sensitive information which is like ethnic origins or really religious belief or anything it's real personal choices in a certain way and any other information that actually you you are willing to disclose by yourself for example to your employer okay in this last bullet i put my employer but it's just any employer can or any entity can ask you for some information that you may wish to discuss but is really personal this is about the personal data then we have three key points which are the console processor and processing so the console is who is controlling the personal data okay because if you give the data to someone that someone is controlling your personal data okay and he may wish to do some processing which is the action of taking your data and making something to get some stats for example right this is the processing and the the the entity that does the processing is the processors okay which is actually doing the processing now it's kind of a headache but these three things are correlated and do overlap okay it's like i connected to my isp i sign a contract i give some personal information the isp controls my personal data that i gave to him okay and he may decide to do some stats okay and"
  },
  {
    "startTime": "00:40:00",
    "text": "he decides how to process the data but not necessarily does it itself he can ask somebody else a third party to do it which will be the processor okay now gdpr and ip addresses so in the gdpr is clearly stated that any online identifier is personal data okay especially this applies to ip addresses and the european court of justice ruled that it is personal identification data because you can associate and retrieve a lot of other information even if you use temporary addresses okay so as such it falls specifically under gdpr and privacy protection now um i will go a little bit through the the seven principles of gdpr and try to make a link to what is an example of how does does it apply on the on the protocol stack let's say more specifically to the network layer okay and ip addresses uh the first very simple principle is lawfulness fairness and transparency which basically says that if i give my personal data to my isp i expect that it does use my personal data according to the law gdpr is part of it okay um you know in an undiscriminated discriminatory manner okay and in a transparent manner which includes my explicit consent i will"
  },
  {
    "startTime": "00:42:01",
    "text": "come back to this a little bit later uh second principle is purpose limitation is the fact that uh uh my isp is not allowed to use my personal data for whatever he wants okay he is able to to use my ip address in order to count my packets for billing purposes is not allowed to look what is in my packets in order to measure how much shopping i do online because this is not related to the service that it proposes the isp is proposing internet connectivity okay third principle data is minimization is the fact that uh mysp is allowed to collect as much data that is needed to offer the service but not more for of that okay so he can certainly again access to the ip header the transport header to provide the service but not access the content of my packet in order to look at what i actually do exactly even if it isn't clear okay accuracy for the principle is the fact that anything the isp gathers of me must be accurate okay that or error free if you wish okay uh storage limitation is the fact that uh my my data cannot be archived forever okay there is typically a limited amount of time that my data can be collected then it should be deleted if i do not ask actually to do it beforehand because there is this also this aspect that actually i i have the right to be forgotten so that i"
  },
  {
    "startTime": "00:44:02",
    "text": "can ask to delete all my data okay this is interesting is kind of tussling somehow because on the on the one side we have gdpr that asks storage limitation on the other side load enforcement and for some minimal time to to keep some logs for accountability and traceability of some stuff so there is a balance to strike there at some point okay um security integrity and confidentiality is just that if i give my personal data to the isp i assume that isp is doing his best to protect my personal data and they gonna not do not go out in the wild okay which brings to the fact that is he is actually accountable for my personal data and even in the case as i explained before that my isp is the console of my data and it gives my data to someone else in order to process them okay to perform a processing and in something goes wrong and the processor actually leaks my data the one that is accountable from my perspective is the isp okay it's not moving anymore i don't know what okay so this is really high level uh what happens in gdpr and how we can relate with with the ip protocol stack so"
  },
  {
    "startTime": "00:46:02",
    "text": "you know that gdpr is peculiar for the european union is not the only example okay in this table there is a summary of other laws regulation you can find all over the world okay there are there are more or less or similar and they all more or less consider ip addresses as a personal data there are some legal nuances in a certain way so for example in brazil he is not explicitly stated that uh ip addresses or online identifiers uh are included in in the law but the way the law is expressed ip addresses falling okay another interesting uh peculiarity is the fact that in japan even anonymized data covered by the appi which is the the japanese equivalent of gdpr which is not the case in here for gdpr in europe once you anonymize the data and you are sure that there is no way to go back and find the the the original information gdpr is out of the scope okay and all of the laws are based on on consent usually explicit consent which means that you have to take an expletive explicit action to give your concept which means when you are in europe you have this pop-up window that say you accept the cookies and you have to to to click yes or no and today we have also different settings this is a explicit action okay you cannot just put some place in the webpage oh by the way we are collecting cookies if you have something against"
  },
  {
    "startTime": "00:48:00",
    "text": "please shut up speak up okay so you cannot do that because would be a passive consent okay and in canada on the contrary this is uh allowed okay i would like just to make one one single point uh you can go over the slide there are the rfc numbers um which try to to make a clear link between gdpr and and and what we do here in uh and the atf the only thing is this slide in uh rfc 6973 there are already some wording that clearly points to the same principles that we can find in gdpr so just to state is not out in the moon gdpr is something that in a certain way we already uh share as a principle okay and i think i'm done so that we are in time perfect thank you so much and thank you for giving this talk on a topic which comes up repeatedly inside the ietf um i see we have patrick in the queue please go ahead patrick hello uh patrick tarpie i've come very interesting presentation just an observation really it's a kind of known fact that in the european union area there's a piece of regulation called the data retention directive which requires communication providers to keep call data records for the purposes of lawful intercept and all that malarkey to what extent do you think that new protocols such as mask over quick"
  },
  {
    "startTime": "00:50:00",
    "text": "and oblivious technology to some extent render this conversation about the privacy of ip addresses or indeed you know the actors that you've mentioned in your presentation kind of obsolete really do you think that's a fair comment you know that if the evolution of mask proxies and oblivious kind of make this idea a bit exponential and a challenge thank you for the question it's very very interesting question uh uh top of my head the answer is uh i think this that technology are very useful and can help in in privacy protection there is one thing so that should be considered is uh where the data goes uh because the fact that you have an oblivious methodology in order to to to obfuscate some things doesn't mean that you are gdpr compliant because uh you you have also to consider where actually you do that how you do that and then coming to play the logs that you keep in order to for accountability so does it make sense my my answer but we can chat more it's a very interesting question but it's what complex i think to to discuss thank you again luigi for that presentation that's great and again there's some further discussion in the chat that uh you may want to follow up with yeah sure thank you thanks very much okay and a final presentation is from mallory um it's an update of the survey of worldwide censorship techniques draft so plea do you you have slides you want to show you on screen uh i do have slides i just requested to um share them"
  },
  {
    "startTime": "00:52:00",
    "text": "yeah there we go thank you so much yeah all right thanks and thanks for time on the agenda this is a research group document if people recall i'm presenting it only because um the other authors who've worked on this draft for a very long time no longer have the capacity to continue working on it so um a lot of the content in the slides and the draft itself is not written by me but um i am it's steward at the moment happily so yeah joe hall um he was originally in my position at cdc when he started writing this uh in november 2014. so that's quite some time i think one of the challenges of this draft is that of course it's a you know contentious topic uses the word censorship throughout it's not something that atf is used to talking about but also that um the more time that passes the more sort of techniques can be added refined you know so at some point i think there's a recognition this has been made this this has been recognized multiple times in um perigee that um it just has to sort of be uh published so we're working towards a document that is good enough to be published but also um you know has sort of a time stamp on it when it does get published and everything that sort of evolves after that can be captured in a different way um so yeah there's it's gone through one research group last call we'd like to by the end of this presentation and then on the list very soon move to another last call that's my goal here we're now on the fifth version since the research group adopted it and the changes that we've made most recently have been to scale back the section on self-censorship to the bare minimum there talked a bit more about domain seizure again like not under the sort of technical table of contents which i'll get to in a second and then"
  },
  {
    "startTime": "00:54:01",
    "text": "we now also talk about how tls 1.3 extensions are sometimes being blocked that's again an example of how the longer we wait the more new and novel ways to block the internet um arise uh so the um contents the summary of the draft it's in essentially um four parts there's a section that sort of helps to define what to block um then that's followed by a section on how to detect what to block after you've defined it and then the last part is really about the actions that you can take to block it um and then there's some um discussion of how the network is layered and and how that um actually matches yeah i just saw a list of point in the chat which is absolutely right we've talked a lot about how this could be a living document but also how it might be useful to to actually get it published once and then think about how to keep it up to date so we are tracking this in github you can see the open issues um these this is a just sort of um list of what's open and in my analysis of the way to move forward so um actually since i submitted the most recent version um ecker has given some really great suggestions to how to figure out issue 81 on the tls identification piece um there's been an open issue for quite a while just to sort of incorporate i think this very relevant report thanks to chris wood for pointing that one out um there has been some treatment on issue 64 about the issue around tls um and it's just that the original um the person who opened the issue chelsea um needs to review kind of the change we did and whether or not she's satisfied with that that there are two other issues that are still open and i would actually um i'm here i'm coming here to"
  },
  {
    "startTime": "00:56:01",
    "text": "you to recommend that we drop them one is um to introduce this concept of sensor maturity because again i think this is something that maybe changes over time i'm not sure it adds a great deal and i also i'm just not very sure or clear what the text on sensor maturity should be since there's not been a suggestion and then the other one i suggest dropping um is changing so throughout the document we have a sort of trade-offs caveat under most subsections meaning that you know there's a cost to the censorship of some degree um and there's just been a suggestion that we changed that terminology from trade-off to cost to implement but i'm actually looking at the text i don't think that the terminology change is really warranted and also it would require us to do more word smithing because then we tend to say trade-off colon the cost to implement this you know so it would be really redundant and kind of um yeah i'm just not i'm just not convinced that it's really worth making the change um so anyway that so like i said we're waiting for the re-review on issue 64. we know that we need to incorporate 81 55 and 64 into the next version and then we'll go to the list right after that's done um and hopefully ask the chairs for another last call but um wanted to stop there i think to ask if there were any questions or comments um thanks again for the time we have like three minutes left i think thanks mallory are there any questions from the meeting today otherwise i think i can um to say from the chair point of view we're very keen to see uh this version move forward now that there's been some action on it again so we would be uh very keen to have a discussion about setting a provisional date for getting to the next research group last call so"
  },
  {
    "startTime": "00:58:01",
    "text": "that we have some time-based targets to move this forward because as you say it really needs to be published at this point in time so perhaps we can we can chat about offline when yeah reasonable i think it should be fairly imminent really it's just i feel really confident that the changes i need to make i can make it's just i need the reviewers who originally raised them to just give me their stamp of approval because i want to get it right and i would just also say i forgot to sort of say this in the presentation and maybe it's only tangentially relevant but there's also a new brand new zero zero draft that's going to be presented i think three times at ietf 113 on ip blocking this is i think you know reading between the lines in response to some of the requests that have been made of various infrastruct internet infrastructure to um action russia's behavior um during its war on ukraine and that's a good draft if folks want to read it i think there's some overlap here there's definitely some stuff in the ip blocking space that isn't in this draft so i don't want to open that whole can of worms i just want people to be aware of it and to note you know that this draft has been around for quite a while there's been a lot of really great thinking put into it and i just like to see it um get some attention yeah and if there are particular viewers that um you want feedback from please please let the chairs know so we can help you with that um cool and if you think those other drafts are useful um for people from perigee to provide input on then uh please send that to the peggy list so folks are aware exactly i did recommend that the authors send it to the list the perigee list so we'll see if they if they will or not so anyway thanks all right thank you very much for that uh with that i think we are wrapped up for today thank you to all our presenters today um and uh please enjoy continue to enjoy the hybrid ietf whether you are remote or in"
  },
  {
    "startTime": "01:00:02",
    "text": "person thank you very much everyone thank you you"
  }
]
