[
  {
    "startTime": "00:00:07",
    "text": "okay um so okay thank you hello hello hello then we can hear you loud and clear okay okay that's great indeed welcome"
  },
  {
    "startTime": "00:02:11",
    "text": "all right um we have about 80 people congregated locally and virtually i would like to welcome all of you to the saffnot birds of a feather session this session is being recorded by now given that we're halfway through the ietf meeting in vienna most of you have seen the notewell please keep in mind that anything you say is considered a contribution to the ietf and that civility is dearly important to all of us everybody uh who wishes to comment uh and is locally here in the room in vienna should load up the meet echo light tool on their phone there's qr codes on the on the chairs and that allows you to join or leave the queue if you wish to ask a question or express a comment for the remote participants make sure that your microphone is muted when you're not talking so what is safnet sapnet this session is a so-called exploratory birds of a feather session this means we are not a working group this is a congregation where we look for other interested parties for feedback from the wider community on the problem of source address validation and and we don't know where exactly this work will go after this session but this session exists to help us inform on what potential next steps exist and uh who who the people are that are interested uh to take on this work"
  },
  {
    "startTime": "00:04:04",
    "text": "looking at the space that exists currently there is for instance best current practices document 38 but it has proven to be a bit of a challenge in some circumstances um and other initiatives exist such as manners but they are a set of recommendations rather than a technology so in this session we will hear about techno technical solutions to improve the ability to combat source address spoofing we'll start with a background and gap analysis followed by discussion which i'll try to moderate to the best of my abilities and then two potential solution directions are presented known as dsaf and isaf and at the end of that we'll again have ample of time for questions and hopefully answers with that i think we can move on to the first presentation joe all good from your side that sounds right to me let's hand it the slides to dan and he can present the background and gap analysis okay i'm ready then you have to use the share preloaded slides button on the left hand panel next to your cube next to the cue button and slow down the gap analysis ask share the slides you can you you control the sharing so that you can page when you're ready"
  },
  {
    "startTime": "00:06:03",
    "text": "uh okay okay okay okay okay sorry sorry okay okay analysis here there you are so so can you see the screen the slides we can see the slides we can hear you go for it okay so uh good morning or good afternoon everyone uh welcome to this saturday off uh i'm danny from chihuahua university first i will present the use cases and gap analysis of source address validation so we all know that source address validation or sieve is an important problem for the internet in rfc six line five line it makes a very good documentation of the various malicious attacks that may come from source address spoofing especially represented by reflective ddos attack to deal with source address spoofing network operators needed to deploy safe mechanisms on network devices in order to permit traffic with valid source address and block traffic with invented source address since the year of 2004 there is a new weave of interest in safe mechanisms because manus initiative is calling on network operators to implement sieve and expect that the validation should be as close to the source as possible however we also know that safe is also changing a desired save mechanism should satisfy the following requirements"
  },
  {
    "startTime": "00:08:01",
    "text": "the first is accuracy so we should avoid improper block of normal traffic and should reduce improper permit of sports traffic as much as possible the second requirement is incremental deployment in practice it is difficult to expect all network operators or all routers to deploy safe mechanism simultaneously so we hope that partial deployment can also bring benefit and the third requirement is the cost although we know that any new mechanism will bring the deployment cost but we hope that the cost is affordable so this safe actually is an old problem with a very long history of attention in ietf as early as the year of 1998 english filtering or acl based the safe was proposed in offset 2267 but its problem is that it requires manual configuration after that in 2004 fc3704 proposed the strict erpf feedable erpf as well as lucy rpf however it is aware knowing that strictly rpf in the freedom of erph has a problem of improper block under asymmetrical loading and the physical erpf and then loose the rpf have the problem of improper permit the recent efforts on safe mechanisms is savvy and efp rpf"
  },
  {
    "startTime": "00:10:01",
    "text": "in savvy working groups six rfcs were proposed from the year of 2012 to 2017 with a focus on host level save in access networks or enterprise networks and about two years ago fc 8704 proposed the efp rpf which is actually an enhancement version of feedable erpf with the focus of mitigating the problem of strict erpf and feedable erpf in some cases so why do we need a new interdiment and interdependent safe technology in rc 5210 the server architecture divides sieve into three second levels namely access network safe interdemensive and interdemensive however savvy for access network safe is not enough because the number operators for access networks is very huge so it is difficult to require all access networks to deploy service simultaneously when some access networks do not deploy survey we hope that interdemonstrative and the interdependencies can also help theater spoofing traffic as close to the source as possible without only dealing with the spoofing traffic and the destination and for intro and interdom and save erpf based technology is also not enough as mentioned strictly erpf feasible urpf and lou crpf have improper block or improper permit problems well efp urpf does not completely solve"
  },
  {
    "startTime": "00:12:02",
    "text": "the problem next we will use several pieces to analyze the gap the first example next is this is a introduction network there are seven routers each router uses one port to connect its supplement and uses the other ports to connect the neighboring routers now let's focus on router 7 and assume zotero 7 applies strictly rpf only at the separate port so the effect is that if all the other resulters in the network make the same deployment that is all the other routers applies strictly rpf only under the subway the port that's okay there will be no problem however in practice we cannot require that all the routers makes the same deployment and let's assume that if only router 1 2 4 7 makes a deployment and the other daughters are in in the anti-product area there will be problems so let's see an example when router 3 sends package to that seven by spoofing the source addresses of the deployed area that is smoothing the source of the stresses of p1 p2 p4 then zotero 7 will improperly permit these packets because delta 7 does not enable erpf checking and its port connecting router 3. note that it means the sublets"
  },
  {
    "startTime": "00:14:00",
    "text": "in the undeplored area can spoof the source addresses of the diploid area which will hurt the incentive of routers or operators to deploy safe mechanism therefore it means that applying strict erpf only on the subway the port in introductive has a improper permit problem then we may ask hardbot net each router applying strictly rpf at all the ports okay let's just use the same figure and the same example now loser 7 applies strictly rpf at all the ports but we assume that there is a symmetric routing between launcher 7 and the launcher 6. specifically resulting parts from letter 7 to letter 6 is along the paths of resultant 7 5 and 6 while in the reverse direction resulting pass from letter 6 to doctor 7 is another path of verse 6 3 and 7. now there will be problem when letter 6 sends a valid package with correct source of addresses to letter seven through that three when zotero 7 checks the incoming interface of this package by looking up its local local flip it will find that okay the income interface does not match the auto interface of the field so it will improperly block these packets so it means that in this case applying strictly rpf and all the ports into the receive will have improper block problem"
  },
  {
    "startTime": "00:16:00",
    "text": "as a whole no matter whether we apply strict erpf and a separate port or apply strictly rpf at all the ports there will be either improper permit problem or improper block problem for interdependent network okay then let's turn to the interdiment case in this figure there are five axes it's one two three four and five and the next p special attention on s4 now s5 is appearing s over s4 and s1 and s2 are two customer asses of s4 s3 is a customer of s1 and s2 with the multi-homing connection so due to the new expert community when s3 propagates its roots of the prefix p3 to other domain of the network it only propagates along the path of s3 s2 and s4 and it does not advertise its roots along the path of s3 s1 and s4 okay now let's check the save mechanism for s4 assume that s4 runs strictly rpf or feasible erpf or efp erpf with algorithm a and it's the two customer ports now receivable and s4 is that the packets with source addresses of p3 can only arrive"
  },
  {
    "startTime": "00:18:00",
    "text": "from s2 but now s3 may send packets with valid source addresses to s4 through s1 for this package s4 will improperly block them so it means that in interdependencies strictly rpf failure rpf or efprpf with algorithm a will need to improper block problem okay then we may ask that hardboard s4 choose other urpf mechanisms besides okay strike the rpf feedable and a fp erpf with algorithm a there are two other erpf mechanisms one is loose erpf so loose erpf will cause significant improper permit in the eft urpf with algorithm b proposed some enhancement on that the idea of efg rpf with auxin b is that okay s4 configures its save zoos and the customer pause like this s4 will generate a lot list containing source prefix of the custom code okay that is including s1 s2 and s3 and applies the allow list to all its customer ports the benefit of eft rpf with algorithm b over lucia rtf is that the package from s4's customer cone cannot spoof the source addresses of the outside axes which is finer green than using new crpf because by using those erpf the customer cohen actually can spoof whatever source addresses"
  },
  {
    "startTime": "00:20:00",
    "text": "okay now we can observe that there is another problem that is when the packets from s1 and s2 spoof the source addresses of each other as4 will improperly permit these packets because s4 has no capability to distinguish the package from its customer asses generally we can conclude that loose urpf eft urpf with algorithm b interdimensive may need to improper permit problem okay so we find that there are permit or improper block problem for both internal network and interdependent network by using existing urpf based technologies then we ask a question what is a root cause we think that the root cause of the improper block and improv permit problem for erps for urpf is the safe mechanism is that urpf is a load level technology that means that they all never reach the local feed or rep table of routers to decide the incoming interface of packets which may not match the real data plane forwarding pass so to solve this problem and achieve accurate receive we may need a network level technology instead of the node level technology we hope that electric level protocol can help build an independent and accurate save table in each router which follows the real data plane forwarding pass and compared with"
  },
  {
    "startTime": "00:22:01",
    "text": "strictly rpf this save table is different from the fifth table so the improper block problem under asymmetrical routing can be avoided and compared with feasible erpf loose crpf or efprpf the save table is finer green so the improper permit problem can be avoided there are also some requirements for designing such a network level safe protocol the most important requirement is accuracy because this is the most important problem of vrpf based technologies so we hope that the new protocol can help avoid improper block and reduce improper permit as much as possible and there are also some other requirements such as high scalability which means that the protocol should not cause too much computation and communication overhead incremental deployment which means that only partial resulters in the s or on the partial asses in the internet deploy the new protocol there will also be upper scheme compared with the urpf business as well as high security which means that the integrity and security of the protocol messages should be guaranteed and our basic idea to satisfy all the requirements above is that we can discover the real data plane following paths based on hoff prefix notification and generate save tables insulters along the notification parts okay then i will make a brief summary of this talk uh interdimen in the interdimensive is an important and unresolved problem in"
  },
  {
    "startTime": "00:24:01",
    "text": "our community although it is a old problem in in both interdimen and interdomain scenarios urpf based the safe mechanisms have either improper block problem or improper permit problem and we argue that the root cause of your pf is the safe mechanism is that it's a node level technology and it depends on router's local feed or rib for for checking the source address and to achieve accurate receive we hope that a network level protocol can okay build an independent and accurate save table in each router which follows the real data plan forwarding pass okay that's all the stuff i'm glad to answer in a question thank you thank you so much see that the queue immediately filled up with a number of participants this is good news because it means that people are paying attention to what you were saying first up in the queue is ted lemon hi yeah ted lemon um can you go back two slides or maybe three slides to the last diagram three three no to the last diagram uh one more last diagram this one this one so um please uh move close to the microphone oh sure sorry so uh i had a couple questions one is oh sorry not this diagram it's the one with the uh with the the isp with next left and one more intro yes here we go okay so in this module either one of those is fine in this model um in order for in order for for sav to work um it would need to be the case that the that you trust the routers the as1"
  },
  {
    "startTime": "00:26:01",
    "text": "router the as2 router to enforce uh the behavior uh basically to enforce the address validation is that correct yes so in other words if the the problem that you're stating here is that if cust if a device on the customer network sends a packet to the as1 router the as1 router that's got a bogus source address the as1 router is trustworthy you trust the as1 router to to block that packet is that right so uh no you mean you mean a blocking behavior an s4 right we still focus on the blocking behavior on s4 right no no so so the the or asl yeah the problem you were describing here is that uh it's possible for for someone in as1 or as2 to spoof packets from as3 right uh yeah maybe in this case more exactly is that uh we want to uh uh s4 cannot distinguish okay the uh uh s1 and s2 to spoof the address of each other s3 actually is it's an s2 customer if s1 and s2 deploy save mechanism maybe this kind of spoofing can be can be detected and avoided right so the problem that i'm that i'm asking about here is i'm trying to understand the trust model because uh so so as4 doesn't know where the packet came from right if if the packet came from as3 it's going to look roughly the same as if the packet came from as1 regardless of its source address or for example it might even come from as2 and still as4 is going to have no way to tell where that packet came from because nothing in the ip header to authenticate it so therefore part of the trust model here is that i think if i understand you correctly is that you're assuming that the routers are trustworthy that as1 is going to reject a bogus source address from its own internal"
  },
  {
    "startTime": "00:28:01",
    "text": "network and that that's part of the trust model is that right uh actually it's like this actually for for because either urpf or this kind of save mechanism actually they just make the source address chicken based on the incoming port so for the incoming port actually they can only get the correct direction of this pack of this source address but if there is some spoofing between the ascs along the same path actually they cannot distinguish between them but the the key is that if we can do this kind of port-based direction checking even though there is some source address spoofing along the parts actually we can narrow skip and the hair parts twist back the source stress moving okay so so so you're able to you're able to cast blame essentially yeah okay all right that helps yeah the reason i'm asking about this is because the trust model here is unclear and i think it's actually worth documenting the trust model uh when you're talking about this because otherwise you know when i look at this i think well your solution sounds like it's complex and wonderful but doesn't actually solve the problem because you still have the trust problem but if if so so saying why that model actually makes things better is important um and then the other the other question that i had is just that you know and which actually ties back to what you just said is that in in this scenario as4 is the is the isp as12 and three are customers so uh the enforcement path here is is different than it would be if these were all independent right and it's worth talking about that as well i think so that's all i wanted to say i mean i think this i you know i don't have any objection to any of this stuff i just"
  },
  {
    "startTime": "00:30:00",
    "text": "want to make it i just wanted to ask about the trust model because i think it's really important to talk about that as you're documenting this yeah actually this kind of trust model is also the trust model used in urpf all these kind of okay incoming port based save mechanisms have this same trust model yeah maybe we can just make them more clear okay thank you um small interjection i think it's good if participants coming to the microphone raise one point at a time and then rejoin the queue next stop bow tao please i'm not sure we can hear you hello yep i can hear you please go ahead i have a question i saw you analyzed analyzed the improper permit problem of the enhanced visible past urpf in the inter domain case and mentioned two algorithm you call it algorithm a and algorithm b could you please tell me what is their difference uh okay uh so you mean the difference between the two algorithms of efg rpf right yes yes okay uh actually uh these two algorithms were proposed in uh fc uh as an h704 so the difference is uh that for algorithm a it just applies an"
  },
  {
    "startTime": "00:32:03",
    "text": "individual allow list to each customer port uh maybe just based on the routes received by that port so since this is the customer posts are just configure different independent analysts so it will have improper block problem when okay one customer port does not receive any root for as just like the scenario we use the i think in in this case in in this slide and for algorithm b it just applies the same allow list to all the customer ports and it will also allow the package with source addresses of all the customer asses if they come from okay the customer interfaces so that this is algorithm b so by algorithm b it can avoid the improper block problem in algorithm a but may have improper permit problem but because the aces in the customer code kind of spoof each other so if you have more interest i think you can refer to the office 8704 it has a very detailed description yeah thank you okay okay thank you very much uh next up is my apologies hello can you hear me okay can you speak up a little bit louder please uh thank you okay uh yeah i have a general request thank you for the presentation as you mentioned the need for network level token to achieve accurate sav what is the deployment scope of network level"
  },
  {
    "startTime": "00:34:01",
    "text": "sorry maybe i can can i go ahead because there was an overlapping people talking i i took care of that go ahead giuseppe okay yeah i have to thank you for the presentation i have a general question so you analyze basically the improper behavior of ufcf and the root cause also affording for this in accuracy and you state that the the causes is caused by local fib and rib of routers so after that you propose a network ladder protocol for discovering uh real data plane the real data playing fast right so yeah instead of because i you know we have to pay a cost for for this discovery for this network level protocol so i'm wondering if if we consider that if we can consider multiple feasible paths to apply said rules can also work or you you did you just think about that or oh okay okay i i get your uh question i think in our meaningless maybe yari uh has uh okay uh asked a similar question that is okay if we just uh make this probing of the real data plane path of course we will pay additional cost and the alternative way is that hardware we just use some feasible paths and all the packets arriving around the feedable path will be permitted otherwise they will be blocked actually this is the same idea used in feedable erpf"
  },
  {
    "startTime": "00:36:00",
    "text": "but this idea actually also has improper block or improper permit problem because when the packets okay come from the past that is beyond the feasible parts just like the example we use in the interdimensional okay actually it will cause improper block because okay maybe uh uh is does not learn the routing parts of the uh of the actual okay data plane forwarding pass because of some launching policies so you see we are causing block problem and this kind of a fadeable path solution we are also needed to improve permit problem because this is very straightforward right because there are multiple fatal paths but okay the real data plane falling past is only one so of course there will be some improper permit problem okay thank you thank you for this question so thank you so yeah it does not solve all the problems so maybe it can help but without solve all the problems thank you thank you okay thank you next up tim donna hello hello i can hear you as you mentioned the need for network level protocol to achieve accurate sav what is the deployment scope of network level sav token for example fpuf requests communication between both routers and es okay you mean the deployment and the scope of the network level safe protocol uh okay uh yeah actually in efg rpf"
  },
  {
    "startTime": "00:38:00",
    "text": "it it indeed requires some communication between the border router in the af network level sav protocol yes yes yes i i think i get your point uh but uh okay you yfgrpf although there are some communication between the border routers in the as but if we just abstract the s as a single load actually it's still the information exchange within the single load so in uh so we still regard that fgrpf is a load level technology but we want to just propose a network level protocol uh the concrete idea of which will be presented in the next presentation but generally in the introductory level the network level protocol will be wrong between the authors in the as and an interdimensional this protocol will be one between different ases so uh these are just a network level of protocols and we just see that the urpf is just a load level technology right so they only achieve based on local flip and reap so we just want to use this network level protocol to generate okay more accurate uh save tables to overcome in this problem and of course for this deployment slower we should consider incremental deployment yeah i think that's the that's the deployment scope of this protocol thank you the next person who will speak is tim donnelly nobody else hello i have a question for the entertainment case you only mention the same rules in the customer post but not mention the provider and"
  },
  {
    "startTime": "00:40:01",
    "text": "peer post can you explain the case of provider and peer post okay for the entertainment case oh yeah we just discussed the customer ports because uh uh actually in current practice for the purim ports and the provider ports uh they just use suggested using new crpf and even in rfc 8704 we just made some improvement on the save mechanisms on the customer ports for pure imports and provider ports this rfc actually also suggests using new crpf because the new crpf will okay lead to a lot of improper permit problem so we do not discuss these okay problems in detail thank you okay thank you jarrett's uh yeah i was trying to figure out if i was next so i uh i so i think you've partially answered my my main question here which is uh your goal is uh and this is going to be the next deck is to describe a protocol that will i guess publish a list of ip addresses that should be uh you know that should be able to be permitted on a link okay and and so something to describe that network topology or something and then i have a comment on that which is it's been historically incredibly hard to get not only customers but isps to publish uh you know who their customers are and what address space that they use uh or or want to be used and that has that has been an incredibly hard"
  },
  {
    "startTime": "00:42:01",
    "text": "operational task uh to to go and get done and to describe that topology without it exploding into uh basically a full list of all ip address space on the internet yeah yeah uh yeah uh uh thanks uh for your question yeah actually um for this network level uh notification protocol uh maybe there is some sacrifice on the privacy issue that is uh maybe okay some essays will just uh expose some of its uh exhausting policy it's a business relationship because okay it will just uh send us explicitly send out the notification message so this message will just leak some privacy uh issue but generally we think that it is a trade-off between privacy and security so if we want to just uh use accurate method to prevent this kind of uh okay source of just spoofing uh maybe this kind of uh privacy issue uh okay we can just mix some kind of uh sacrifice but of course we can just uh design more mechanisms to limit this impact maybe we can discuss more details uh uh on this point in the million days okay thank you for this question next up jerry arco we cut the queue so that after jeff haase's comment or question we can move on to the presentations about the"
  },
  {
    "startTime": "00:44:02",
    "text": "protocol proposals but back to you jerry yes thank you um so um this is an interesting discussion and an important uh problem i i've been trying to think about the root cause and like what are the actual fundamental issues here and i actually identified four things um root cause number one is that uh you have information that that you could base decisions on but you don't actually use it or don't use all of it and as an example you perhaps you have like a full network topology model in your memory um based on what you learned from the roping protocols you could use that to make decisions on what addresses are okay or not okay so for this case the answer is just use a better algorithm or use an algorithm to begin with okay so that was one and number two is that you don't have information let's say your routing protocol doesn't provide everything that you would need or for some other reason you don't have information that would enable you to make these decisions on social validation and and then the answer obviously is provide more information either in form of a new protocol or some extensions of existing ones i think uh igor who's after me on the queue uh had some proposal on the list about that uh third option is that or the third route course is that you have information about the feasible routes but you don't have information about the actual ones that are being used at this time and i guess here you have to decide what you want like you could be satisfied with you know some improper permits um and and just look at the feasible routes then you have a simpler solution or you create a more complex solution that costs more but you can catch more issues and uh root cause number four is kind of variation of of third of the third one about this actual uh paths versus um"
  },
  {
    "startTime": "00:46:03",
    "text": "feasible paths and there's an issue that if if there's a change somewhere else in the network um when do you actually learn about that and if you think about it uh from the point of view the note that has has to change for some reason like link is added or removed um they could either wait like inform everybody and after everybody's been informed start forwarding packets to the new direction or they could just make an immediate change and in in parallel inform everybody about the change but you could have a situation where there's a short period of time where uh you as a receiving entity uh appear to get packets from a direction that they should not come from because you had like the network hasn't really coordinated itself entirely yet and i don't think that's actually a solvable problem you either have to wait or or accept some packet drops or or some accepting of packets uh momentarily this also gets me somewhat confused about the network level discussion that we had because it's yeah we can talk about the network level solution but we still have like individual nodes that have to make decisions and are not exactly synchronized to everybody else on the same instant because of you know speed of light and such um that's it thank you okay uh thank you for the comments uh actually yeah we already discussed some of your questions in the meaning list i think yeah i'm highly appreciated for your very deep uh think of these issues generally i think for uh safe mechanisms we can just uh maybe we can come up with some a mechanism which is very easy to"
  },
  {
    "startTime": "00:48:00",
    "text": "deploy the cost is very low but maybe okay there will be some inaccurate uh okay that inaccurate decision improper permit or in public block or okay the other extreme is that uh okay we just to achieve accurate uh decision we will pay the cost of the new protocol the network the network level protocol so my okay design philosophy is that actually for ins for today's internet actually we it seems we have a loss of connection unexpected and fairly serious it's a primary presenter for the next deck that seems to have lost his connection we lost slides we also lost audio from dan lee and we lost connectivity from dan lee are you here yes okay it looks like you're back and your deck is coming back too go ahead let's just quickly answer uh yaris uh i'll just respond to yari's comments just my design philosophy is that i want to that okay first we should satisfy the performance requirement that is to okay improve the accuracy and under this uh assumption we will just try to reduce the overhead just limit the overhead as much as possible so i personally prefer this direction of solution and for the the final uh comment from you is that uh okay when there is during the convergency period"
  },
  {
    "startTime": "00:50:01",
    "text": "okay there we maybe we can we have to pay the cost of uh okay the packet drop just the improper block something like that uh i think uh yeah it's just as similar as the resulting protocol so in any kind of a routing protocol during the converging period there may be loop right and if there is nope this is kind of a temporary loop will also cause packet drop okay so so i i think that this this uh for source address validation actually uh for this question it's very similar as resulting uh the resulting protocol so we just want to okay design okay uh several ways just to try to mitigate this problem instead of okay still paying the cost of general okay improper block or improper permit so i think this way this is a very interesting debate and we can also explore more in our million list thank you okay we've got two more speakers with questions i want to get those questions dan please make your answers a little bit shorter we're running late on time but i want to get through these next two questions thank you okay thank you can you hear me can you say something yes i can hear myself all right uh can you okay good thank you uh so i have a comment and a good question so the quick comment is that in my view the reason we're having the discussion the reason we're having the problem is that all the current methods are using what is effectively reachability information bgp as a substitute for allowed forwarding paths uh for sort of"
  },
  {
    "startTime": "00:52:01",
    "text": "address validation and it's just not the most accurate signal and that's why we're having problems um the question i have is what do you think is acceptable cost of any sort of source address validation solution uh relative to the current cost of forwarding packets so essentially like how much cost do you think the industry will be able to bear um to enable this extra level of security hi eucher we can hear you dan go ahead so eager so uh i'm actually i did not quite uh exaggerate your question uh yeah i i i get your comment but your what's your exact question about this the question i have is what do you think i mean uh save will add cost to the forwarding path uh what do you think is a reasonable cost uh that the internet the the industry will be able to bear like relative to the cost of forwarding packets it is like twice as much hardware three times as much hardware uh like in terms of acid per packet uh okay okay okay now i get your point yeah i think maybe these issues will be described uh"
  },
  {
    "startTime": "00:54:02",
    "text": "presentation but generally icelander for the cost we can we should still just divide this protocol into inter domain and the introduction so for interdependent stuff maybe we can just extend the capabilities of bgp to help carry okay more information required for this uh uh okay the data plane pass notification or discovering and uh for introducing a part because this scope is the smaller i think maybe we can just design a new protocol to ask routers to exchange more information with each other generally i think that the cost for discovering the real this happening forwarding pass should not be higher than launching protocols we just we just want to leverage existing consulting protocols such as bbc or design new introduction uh instrument and network protocols which just shares the same complexity of routing of the intradominating protocol but not greater than that that's my uh generally thinking about the cost that we should pay for this kind of uh social just checking because actually actually this is just a different part noting protocol is for distribution and this uh safe network protocol is for this the source address so that's just two counter parts so i think their complexity should be similar it is your turn to hello yeah so thank you ciao i i think it's very important to"
  },
  {
    "startTime": "00:56:01",
    "text": "operators to avoid the improper blocker and the permit so i think this is this direction is uh valid i have a very quick comment uh i don't think i need some response so you know operators network is very large and the number of the nodes uh such as in the backbone network maybe reach a substance so i guess it's reasonable that put the being suitable for the large-scale network deployments should be uh important requirements when we design the network live protocol so thanks okay thank you all right the next presentation is about i think we start with vsaf yeah yeah okay okay go ahead dan it seems i cannot grant the permission oh can you hear me yeah yes luncheon but uh we're trying to get dan to switch"
  },
  {
    "startTime": "00:58:00",
    "text": "who so i can't tell who's who's got slide control at the moment there we go oh there we are on the right slides okay uh hello everyone the presentation lan check sorry go ahead oh thank you uh hello uh i am lance hunting from qinghai university i'm going to introduce the dc framework validating source addresses via silk tables generated by a distributed control plane protocol server divides save into three different checking levels and savvy is proposed to achieve safe at access networks it is only fully effective when globally deployed however it's impractical to expect all access networks to deploy service simultaneously if an access network doesn't deploy survey spoofing traffic from it should have a chance to be blocked before arriving at the destination host and manners requires operators to deploy sieve as close to the source as possible as we described in the gap analysis existing intra and interdomensive technologies may lead to improper block or improper permit problems so to guarantee accuracy a network level protocol is necessary"
  },
  {
    "startTime": "01:00:01",
    "text": "dcf framework depends on a distributed control plane protocol to generate accurate save table instead of using urpf introducing a network level protocol can bring additional overhead so it's important to improve the scalability of the protocol by limiting the communicate commit complete computation and communication overhead [Music] with an accurate receive table the router can verify the authenticity of the source address by checking the incoming port of the package and packets with spoofed source addresses will be blocked and packaged with legitimate source addresses will be forwarded based on ship table [Music] so the basic idea of dc protocol is to discover the real detail plan forwarding path while help by hope prefix notification and to generate save tables in routers along the path this is protocol is separated into an intradomain part and an inter domain part both sharing the same high level idea here we list some terminologies the node is a router in intra domain dcf or an es inter domain dcf the prefix notification means the process by which a node notifies the incoming direction of its source prefixes to all the other"
  },
  {
    "startTime": "01:02:02",
    "text": "nodes in the network and during prefix notification each node conducts one of three operations message origination means a node generates original notification messages message really means a note generates release notification messages after receiving a notification message message termination means a node terminates the received notification message the d save notification message contains two main fields prefix field and propagation scope field for source prefix field it contains the source prefixes of the node when receiving a message a node generates save rules for the source prefixes and this field will remain unchanged during the prefix notification process for propagation scope field this field contains a list of destination prefixes which take the neighbor node as the next hub from fifth it is used to discover the real data plane forwarding path and change hope i hope during the prefix notification process here i will use an example to illustrate the workflow of this eve there are seven nodes in the network and i also the process of prefix notification for p1 the processes of"
  },
  {
    "startTime": "01:04:00",
    "text": "prefix notification for other prefixes are similar let's say node 1 conducts message origination since p1 is the source prefix of node one from node one phase p2 p4 p6 and p7 take node 2 as the next hope so node 1 generates an original notification message to node 2 in the message from node 1 to node 2 it carries p1 in the source prefix field and carries p2 p4 p6 and p7 in the propagation scope field besides from node 1 save p3 and p5 pick node 3 as the next hope so node 1 generates an original notification message to node 3 carrying p1 in the source prefix field and carrying p3 and p5 in the propagation scope field we can also see node 7 is another neighbor node of node 1 however from node 1's fifth node prefix takes node 7 as the next hope so node 1 doesn't send any notification message to node7 then when node 2 receives the notification message from node 1 at port 2.1 it first generates the 0 for source prefix p1 that is it specifies the incoming port"
  },
  {
    "startTime": "01:06:01",
    "text": "2.1 and um then node 2 checks the propagation scope field of the received message the propagation scope field of the received message contains four prefixes they are p2 p4 p6 and p7 p2 is the source prefix of node 2 so node 2 does not to process this prefix while from node 2 fib p4 and p6 take node 4 as the next hope so node 2 conducts message release and generates a relaying notification message to node 4. the message from node 2 to node 4 carries p1 in the source prefix field and only queries p4 and p6 in the propagation scope it's worth noting that p6 may take different next hopes because of multi-path routing so from nodes to slip p6 and p7 take node 7 as the next hope so node 2 conducts message link and generates a really notification message to node 7 carrying py in the source prefix field and carrying p6 and p7 in the propagation scope"
  },
  {
    "startTime": "01:08:01",
    "text": "next when node 4 receives the message from node 2 at port 4.1 node 4 first generates the c rule for source prefix p1 it then checks the propagation scope p4 and p6 from node 4 fib p6 takes node 6 as the next hope so node 4 contacts message relink and generates a reading notification message to node 6 carrying p1 in the source prefix field and carrying p6 in the propagation scope field similarly when node 7 receives the method from nu2 at port 7.1 it generates the civil rule for source prefix p1 and then it checks that p6 takes node 6 as the next hope so node 7 conducts messenger link and generates a relaying notification message to node 6 carrying p1 in the source prefix field and carrying p6 in the propagation scope field in this way note 6 will receive 2 2 notification messages from node 4 and node 7 at different ports therefore node 6 can discover the multi-parting routine and it specifies two valid incoming ports for source prefix p1 then node 6 conducts message termination because the protect propagation scope only contains prefix 6 and prefix prefix 6 is the source prefix of node 6."
  },
  {
    "startTime": "01:10:03",
    "text": "when node 3 receives message from node 1 at point at at port 3.1 it also generates the c rule for source prefix p1 and then from node 3 fib p5 takes note 5 as the next hope so node 3 conducts message link and generates a release notification message to node 5 the message from node 3 to node 5 contains p1 in the source prefix and carries p5 in the propagation scope field when node 5 receives the message from node 3 it generates the c rule and then conducts message determination because the propagation scope only contains p5 and p5 is the source prefix of node 5. at this point the whole process of prefix notification for p1 is over during the prefix notification process each node generates accuracy rules for p1 and receives only one message except for multi-pass routing we have considered two dc update models for pure periodic update each node generates original notification messages periodically for triggered update when routing city changes the node generates original notification messages to add updated silverware or delete outdated silverware for the affected nodes following the principles of existing routing protocols we suggest intradomain dc supports both"
  },
  {
    "startTime": "01:12:01",
    "text": "periodic update and triggered update while inter domain decel only supports triggered updates as described in the gap analysis for intradomain save applying strict urps only as subnet port may have improper permit problem while applying strict urps at all ports may have improper block problem but if router 1 2 4 and 7 run deceived in the deployed area subnet 1 two four seven cannot spook each other and package from subnet three five six with smooth source addresses of p1 p2 p4 p7 will be accurately blocked at port a b c d while 60 rpf may have improper permit problem moreover legitimate packets from subnet 3 5 6 will be accurately permitted at port a port b for c and d while strictly rpf may have improper block problem overall compared with urpf in the introduction if we deploy dcf in the deployed area thumbnails within the deployed area cannot spoof and subnets in the undeployed area cannot spoof the source addresses of the deployed area for inter-domain save street urpf physical urpf and efp urpf"
  },
  {
    "startTime": "01:14:03",
    "text": "with algorithm a may have improper block problem while loose urpf and efprpf with algorithm b may have improper permit problem deploying dcl and as1 s2 s3 s4 can generate several walls for p1 p2 p3 and p4 in this way as1 s2 as3 and as4 cannot spoof each other while efpur pf may have improper permit problem besides packets from es5 with both the source addresses of p1 p2 p3 p4 will be blocked at port a while loose urpf may have improper permit problem in this case overall compared with urpf in in predominantly interdependencies as within the deployed area cannot spoof each other and ess in the undeplored area cannot cannot spoof the source addresses of the deployed area here we have some open questions about two further improvements of dcf for accuracy the key of this if is to discover real difficulty forwarding paths so any factor that affects forwarding should be considered for example policy based routing like static routing or aclu direction may change the data plane forwarding path of fifth table"
  },
  {
    "startTime": "01:16:00",
    "text": "so how to handle this problem for scalability containing a long list of ip addresses in source prefix field and propagation scope field is costly can we compress dc protocol messages for conscious convergency when updating there may be a gap between the change of flip table and the update of save table so how to avoid improper blood in this time keep in fast routing when a link fields the router can select a backup forwarding path immediately how to handle resultant improper block since the save tables of downstream routers do not learn the backup forwarding path for incremental deployment how about multiple disconnected deployed areas [Music] for security was the threat model of dc protocol messages and how to address for privacy in inter-domain decisive an as will tell its local routing policy information to other esa's is it a leak of privacy thank you we are glad to explore more suggestions and more solutions thank you very much first up in the queue is nalini elkins hi nalini elkins inside products and i'll bring up one issue at a time um if you can go back to the the i think"
  },
  {
    "startTime": "01:18:02",
    "text": "the very very first slide that you had um i'll continue talking while you're while you're doing that we just slide yeah yeah very i think very very beginning one yeah keep going back keep going back back back yeah yeah uh maybe one more back nalini lean into the mic please okay can you guys hear me there yes okay okay all right well so whatever so okay it seemed to me okay one don't get me wrong this is very good idea i think and necessary and and i think we happy to work with you um but i think there's a couple of fundamental flaws and i'll bring them up one at a time let other people talk first fundamental flaw i believe it depends on hop by hop um header and being accurate and not spoof and and that and so if the hop by hop um extension header is bad to start with well there you go and we are happy to work with you on that because we have an idea ourselves because we have another ipv6 extension header that we need to be extremely accurate so if you want we can explore collaboration but let me see what you think about that that's great yeah we are looking forward to collaborating with you yeah okay so then i'll go on and bring another um uh question let other people talk thank you next um antoine freson court nearly got it right thank you so i have a question this slide is perfect regarding the propagation scope here if i understand well you build the propagation scope with the"
  },
  {
    "startTime": "01:20:01",
    "text": "information that are in the field of the node did you explore the possibility to have a propagation field that is built by each op for instance you have a message where you have the source field that you that you certify and then the next node is using the message from the that is going from the from the originating node populate this propagation field and relay it to its neighbors so you build the propagation scope field up by up and you can then verify the path completely rather than just the source uh do you mean how to re discover the real forwarding path from original to the destination um it may be a method for doing that but in fact you can use this uh build this propagation field to and and spread the message to all the neighbors so you can discover all possible paths and not the paths that are used for relaying the traffic maybe the voice is uh where we know i actually we can someone repeat this question uh more clouder uh i will try to speak closer to the mic if you want my question was regarding the propagation scope field yeah do you think that it could be an idea rather than building the propagation field from the information that are in the field to build it up by up with your originator message with only the source prefix field and then the"
  },
  {
    "startTime": "01:22:01",
    "text": "neighbor puts the prefix in the source prefix field message they received in the propagation scope field before relaying the message to their own neighbor and it goes on until you propagate the message in all the network actually the reason that we use a car in a way to okay hop by hop notify the source prefixes by using the publication scope it's just the one to minimize the number of protocol messages during this whole process of prefix notification so uh another possible way is that we just carry okay just uh some destination addresses in the uh in the package in the pay node and just the probe those paths it will bring much more a protocol ever overhead so yeah actually we use the fib for the notification because we want to discover the real data forwarding paths because the real data platform pass is determined by the vape table okay thank you okay thank you next up linda dunbar um so i have a couple questions first is um one question at a time yeah um you consider using the acl as well"
  },
  {
    "startTime": "01:24:00",
    "text": "yes okay so that means here right there they validate um source address destination address and also the port number so do you have analysis like showing different ways incorporating with acl sure we have we do have some solutions for ecl yes you are right ecru direction may check source address destination address or port number yes and we we think dc can use the control plane routing information to generate notification messages along policy-based forwarding paths including easier redirection path or other for example a tunnel path okay so if the tunnel is used do you validate only the tunnel address endpoint address or do you validate the address carried inside the terminal uh only at the point at the incoming port incoming okay thank you next up from future virtual network i just have a comment so you propose two uh method for message propagation one is a one shot the other model is the periodically originate and the related methods i think that if you use the pcp protocol"
  },
  {
    "startTime": "01:26:01",
    "text": "and then one shot is okay so don't need to do the refresh every half hour every uh hour so if you use a bgp if you use the igp then those are already in in the protocol itself looks like you are using bdp and then we don't need to do the theoretical message originating and the propagation okay for for infra domain i think igp cannot learn the real forwarding path because nowadays static routing and acr redirection are common in improvement they also influence the forwarding path but other routers cannot learn this information through idp right so to achieve accurate skill in any scenario a network level protocol is necessary and in dcl a node can send prefix notification to other nodes and as for you said we can use bgp right yeah in the previous presentation by that knee so it looks like you're using bgp so once you use bgp you don't need to do periodical updates right um i think i think i think inter-domain dcf only supports treasured update and if you me we can use bgp to send the prefix notification uh is about a protocol selection"
  },
  {
    "startTime": "01:28:03",
    "text": "question now protect protocol select selection is an open question [Music] we want we hope to get more uh suggestions and reviews and whether uh we design a new protocol or extending existing route routine protocol for example bgp is okay it's an open question thank you next up um we have three more minutes and then we need to jump to the next presentation so the next questions need to fit in one minute uh nancy chen your turn i'm from hcc i have one question in your analysis of scalability of dsav you see that in most cases a node with only one token message originated from every other node could you explain why okay you mean the scalability issue right um okay we can we can go back to the example in in in in the process of prefix notification for p1 we can see node one is text is fifth table and from node lens fifth from node one fifth it finds node two"
  },
  {
    "startTime": "01:30:00",
    "text": "and number three are two next hopes in its theme therefore it takes node two as a nest hope and sends uh and it generates an original notification message to number two the message generated from node 1 to node 2 carries p1 in the source prefix field and carrying p2 p4 p6 and p7 in the propagation scope and for the next hope node 3 from node 5 p3 and p5 take node 3 as the next hope so node 1 generates an original notification message to node 3 and the message from node 1 to node 3 carrying p1 in the source prefix and carrying p3 and p5 in the propagation scope but for the neighboring node 7 also it is the neighbor of node 1 however in nodes 1 5 no prefix takes node 7 as the next hope so node 1 doesn't send any notification message to node 7. so in this way node one only sends one message to each neighbor and during the provocation each node only receives one message and they can generate accuracy rules thank you um i think we we ran out of time so we need to to move on to"
  },
  {
    "startTime": "01:32:00",
    "text": "esaf anybody that's still in the queue please send your comments to the safnet ietf.org mailing list so that we can despite not being able to handle the questions right here right now still take a look at that input my apologies all right next up isaf [Music] see how liang one is maybe how you pronounce it uh is your audio working can you say something please it might be easier to use the preloaded slides it's the second button on the left next to just left of the one you you press to share your screen so stop the screen sharing and then go now all we need is audio can you say something into your microphone please i can see slides"
  },
  {
    "startTime": "01:34:34",
    "text": "charlie we can't hear you okay can you hear me i'm just in this screen we can hear you please speak up a little bit okay good evening and good other times everyone this is young fake and my present president started from here i will show you the e-star framework and under to end the data plane approach"
  },
  {
    "startTime": "01:36:01",
    "text": "for source address validation the internet protocol ip is the most fundamental building block of current network architecture this protocol allows us to allocate address to different us for recognition and deliver package on the internet however it provides no explicit notion of packet level authenticity such a weakness allows malicious actors to spoof ip packets and launch a wide variety of attacks for example the lgcp spoofing dns reflection deducts and the tcp syn flooding to name gaza field however at the main defense mechanism the real world deployment of source address variation in the past decades is far from being said satisfactory there are many reasons for this and we believe one potential improvement direction is to strike a better balance between security benefits and scalability therefore we set three main design goals for itself first having clear and consistent security benefits in various scenarios is the biggest deployment incentive for socialist validation second scalability from partial to large-scale deployment need to be supported thirdly provide flexible verification capability flag flexible requirements for social"
  },
  {
    "startTime": "01:38:00",
    "text": "responsion granularity for different application scenarios need to be achieved let's start with the general overview of how easter works the source s and the the destination as directly from an end to end package tag synchronization after which the package from the source will carry the legal package tag and be received by the destination support packets don't have the tag and are marked as suspicious by the destination and other process the further or dropped directly to implement this design itself will require both a data plane under control plane within a s the control plane will be implement through a device called the ais control server or acs and the data plane will be implemented through an ais border rotor or abr where the api is responsible for adding checking replacing and deleting tags for all upstream and downstream traffic and the acs is responsible for providing the api with the information needed for the relevant tag operations such as the legal prefix to tag mapping the controllers of different as need to work together to maintain a tesla lens and achieve consistence on the information required for tech operations within the lungs this requires the support of existing network in fact infrastructure such as the mapping between as number"
  },
  {
    "startTime": "01:40:00",
    "text": "and ip prefix provided by rpki with the package tag mentioned above itself can guarantee a career security gain within the deployment and guarantees the authenticity of the source address of the traffic that has passed the tag check it's the instead of only checks is owen traffic on the other hand islam is designed with a as community to provide a good scalability so the overhead of establishing a universe uh entertainment trust and hardware fiction mechanism at the internet scale is hardly acceptable with the simple end-to-end tag maintenance is not friendly to change in the network environment in each of a hierarchical structure called as community is designed to address the scalability changes faced by end-to-end tag schemes when deployed at a scale in each of is confirm a community structure with a hierarchy that splits the progress and to enter maintenance between s into a the cross layer tag verification and the replacement the end to end derived task is replaced with a cross layer chain of cluster delivery in es community end to end tag is only maintained between as with the same community quite fake entering or leaving the ais community is operated by the"
  },
  {
    "startTime": "01:42:02",
    "text": "border airs for tag replacement through hierarchical design we can achieve the following three benefits the first one you can reduce the size of the tags maintained between s the second one hierarchy effectively blocks external trends on the provides scalability in large scale deployments the third one cross layer where fiction will fail to manifest traffic as much as early as possible to avoid wasting resources to simplify the tag replacement rules in data forwarding itself propose a logical concept called water s to maintain inter community tax will entering under leaving our community awarding problems such as tag replacement difficulties due to multiplace transmission between s or traversing none itself deployment area such as s one two for example as the one one send package to s 2 3 and after passing through s 1 2 where e 7 is not deployed there are two different following paths at this point since the logical as community one water uh one auto as one is set the package carries the theme tag whether they are sent from s one three or s four both use the tag between water s1 and the water s2"
  },
  {
    "startTime": "01:44:00",
    "text": "in the following we further describe the general working process always so bad by example here there are nine boundary loaders lot of one to load line each ribs each representing one different airs forming the as community as shown in the figure lutheran sent out a package to note 9. in the first step lutheran learns that the destination is not inside this community by the destination address of the package but it is inside the cluster length and it puts the tag between itself and the water s of this community that is as community one three into the package and forming the tag this one to load to water as one three after that the package arrives at rotor2 used to end at the boundary as of the current community confirms by the package destination address that the package needs to be forwarded outside of the community one three so after verifying the validity of the current tag the tag is replaced with the tag between community one three and community one two that is voter s one three and a two vertical as one two similar to the above process after the package across community one three and reached that the board aso community"
  },
  {
    "startTime": "01:46:01",
    "text": "that is loader three those three will perform the same check and replace the tag with the tag between the community one two and under community one one and the form the tag water as one two water s one one next the boundary of s community one one is reached and the root 4 performs the tag check and the replacement the tag a load file since this this router is neither the source nor the destination of the package so it does need to do any processing and forwarding that's packaged directly after that it reaches the destination community and the border as rota6 performs tag checking and a replacement the next one is rotor 7 finally it arrives at s community 2 3 root 8 performs tag check after which the tag is replaced by the tag between root 8 and root 9 through the destination address and the root name receives it and it will verify the tag validity and remove the tag and send it to the in the host so far the data forwarding and verification process from root 1 to root 9 is completed and the direct cluster relationship between root one and root nand is converted to a segmented cluster deliveries method"
  },
  {
    "startTime": "01:48:01",
    "text": "as a summary easter is a corrupt graphic based source of reservation to guarantee consistent security benefits and provide scalability for different deployment skills and validation granularity and the ethers use hierarchy and tag replacement to reduce overhead and improve scalability compare compared to traditional crop cryptography based schemes such as spm or ipsec so there is some questions the first that the install is prepared for ipv4 or ipv6 or both you know for the limitation of ipv4 options header it may be our problem for how you style tag the tag to the package and to how to maintain and manage a hierarchy for itself is it a distributed one or centralized one and third what ipui says option header should install wheels destination hub by half a loading operation header in our design we use designation over shadow and that's all thanks thank you so much and thank you for taking on the duty of presenting this work as very short notice first up in the queue is nalini elkins yes hi this is delaney atkinson inside product um so again i'll keep keep it to one question"
  },
  {
    "startTime": "01:50:02",
    "text": "which is so so okay so say i'm mr bad as number one and my community is my friends bad as number two bad ass number three and we all say yeah yeah good tag good tag um and so what is the i'm not understanding quite the validation mechanism are these are you intending for this stuff to be um encrypted are you i have is there an external uh check external route of trust um can you explain more what this verification of tag entails yeah thank you oh can you hear me by the way nice uh thank you for the question uh so first of all this is haiyan i'm one of the collaborators of this research so what are you asking is if there are bad uh iss out there how we actually uh validate those tax out there is that what you're asking yeah that's that's actually a very good question yeah that's actually a very good question so talking about the esav uh i want you guys to think about the autonomous systems or let's say a set of toronto assistance as a uh at the daycare okay thinking about those ib prefixes and ip addresses they like kids out there okay those kids they don't have driver's license they don't have ids so uh our responsibility is to design a protocol that is running in in the daycares to validate the identity of those kids okay so basically what we do is that uh first of all we don't search actually the actual routing table up there uh we actually only need to check the destination uh ip prefix and to check if this destination is within the daycare or outside of daycare if it's within the daycare we send it to the our inter domain protocol if it's"
  },
  {
    "startTime": "01:52:00",
    "text": "outside then we give this kid a sticker we put that sticker on his head and then we send this kid out what you're asking is that what will happen if we have some evil daycares that does not care about those kids uh the sin is that we are basically going to consider those autonomous systems as uh autonomous system that does not support yes av okay so first of all this is not going to hurt uh the sender of the packet or the receiver of the packet uh it is only going to hurt those evo autonomous systems who refuse to check the tech if that makes sense to you it seems that our deployment we don't require all the daycares to check those stickers okay so for example a kit is generated from uh a daycare with a sticker on there and we are going to eventually have some not evil daycares that is going to check the validation of that sticker i don't know if that makes sense to you for example if we have three autonomous systems one two three connected out there and the atomic system two in the middle is evil or does not have e-s-cb deployed out there it doesn't matter because one three can still validate each other and if you don't feel good or if you don't feel happy to join this esab system you can ignore it i don't think it's going to hurt our protocol but still that's a very good question next up juan xiang cube hi yes can you hear me yes i can hear you perfectly hey i'm from h3c i have a question does esau need to label our package whether this additional overhead will have a significant impact on the"
  },
  {
    "startTime": "01:54:01",
    "text": "efficiency of inter-domain transfers thank you okay so you're thinking about efficiency of the uh attack validation and tech generation is that what you're asking yeah sure uh that's a very good question actually we already test that on the commercial we actually implemented the protocol and the uh we actually test that uh on real-world routers uh in a uh we actually deployed that in a virtual router you know environment that is relatively a large scale virtual network uh i would say the uh efficiency talking about throughput we can achieve around uh 98 percent of the uh line speed uh with this kind of tech forwarding so i don't think that is going to be an issue and talking about latency we don't have very detailed data out there uh but the uh preliminary test showing that the it is going to add in approximately 10 microseconds late delay to your packet processing okay thank you yeah no problem next up benjamin smartz hi uh ben schwartz here uh i wanted to ask about the mtu overhead uh first what is the what is the size over here oh very good question so you're asking the size of our tag is is that what you're asking uh yeah and and any additional overhead associated with it yeah it's actually built in in ipv version six uh option uh have a header out there uh the uh the actual size the thing is that we're not going to actually add extra header or extra information on top of the a version six header if that makes sense"
  },
  {
    "startTime": "01:56:01",
    "text": "to you so our tag is actually a part of the ip version six header where it is okay where does it go in the header the existing implementation is that we put that in the destination option out there okay but that's an extension header right yeah that's an extension header yes so so you know that that extension header works just a little bit not not like a whole lot so how long is that tag i cannot remember exactly it's it's like 64 i guess 64 bytes it's yeah 64 bits so it's like an eight so it's like a 64-bit mac yes okay that's a very good question uh actually the scene is that the existing limitation uh on ipv6 is based on the extension and we're also thinking about the uh adding that for ib version 4 that is probably also going to be added to the extension head that's a very good question yes thanks so overhead is around like 64 bits thanks so uh my my feeling about this is that i would really i'm really interested to see something very much along these lines um in terms of uh end-to-end cryptographic authentication of every packet i think that's fascinating and worth in investigating and investing in i i don't really i don't i have disagreements with all like every detail um in this proposal in particular i really think that we should consider static setup instead of instead of trying to do dynamic arrangements between the asses which creates kind of an n squared problem where all the asses have to talk to each other i think we should consider a static cryptographic handshake setup i think that would allow us to get rid"
  },
  {
    "startTime": "01:58:00",
    "text": "of the hierarchy of communities which which is conceptually confusing increases management and i think that uh i think a big lesson from from the tls is that authentication is is not really uh authentication without encryption is only half of the half of the story if you're going to do all the work to set up a shared secret between two parties then you might as well encrypt the payload while you're at it you now have the shared secret so um i would love to to work with anybody who who thinks that's an interesting direction to go in and uh uh yeah i'd be happy to be a part of that thank you thank you i totally agree with your comments out there and i'm kind of making my answers short because we are running out of time yeah all right um we are at the top of the hour which means that we are basically running out of time [Music] questions that need to be answered in the subsequent period of time is what to do next is this are these protocols worthy worthy is not the right word is there sufficient interest to form a working group to progress the development of these protocols are the protocol concepts feasible in deployments on the internet um but i i think we are uh pressed for time to to address those um in a thorough manner see jared wants to i guess we can spend another five minutes jared you go first yeah yeah real quick jared macha is an individual um so i think that there's the opportunity for there to be some interesting work in this space"
  },
  {
    "startTime": "02:00:01",
    "text": "but i think it also is going to pose some real challenges when it comes to actually deploying it which is basically see everyone who's tried to either do bgp route filtering or bgp path uh scale because a lot of these properties of this are going to scale similarly as uh you know those existing deployment efforts and that is and and that has uh you know that takes a lot of compute resources which quite often aren't going to be on these devices thank you next up zen ben lim okay i can be from hawaii so from my point of view i think that's the in the in the presentation we uh i think that's is agreed that there's the uh drawback of the existing the source address validation solutions such as urpf or eccentro is it truly worth to us to explore the possible solutions to these issues but i think that the concern is the possible cost from my point of view maybe we think that we need go on to discuss these possible solutions for this challenges i think that's maybe we need a venue for this point okay thank you next up yang xian qiu i'm from h3c as a vendor or router switches and gateway devices support urpf nor erpf is a single point"
  },
  {
    "startTime": "02:02:02",
    "text": "cell mechanism and we agreed that urpf is inadequate in addressing a cell such as spoofing i think this cell is a possible direction and seemed worth doing the benefit of this cell is that it can improve cell and does not need to modify packets during the forwarding process in general there's a lot of work to be done with insurer and inter-domain cell as support setting up our working group thank you eric thank them your turn yes so my name is eric wang i am the responsible lady for this buff and i would love to thank the chairs and the speaker for the clear presentation now we got the solutions the problem space has been presented we were presented with two solutions i wonder whether there are there is a third and the fourth potential solution to this so in my opinion i think it's a bit premature to think about the working group right now uh but it's problems pace that really needs to be explored indeed and there is a mailing list safnet at atf.org so i really hope that the conversation continues there thank you yang gao hello everyone i'm from the china academy of information and communications technology we believe that the problems raised by dcl are valid and important and we are also doing tracking of related technologies compared with the previous technologies"
  },
  {
    "startTime": "02:04:01",
    "text": "dc provides some more general solutions and is worthy of more efforts we think it's necessary to promote the standard division of deceiving idf at the same time they intend to carry out the standard promotion in china communications standards association thank you thanks thank you we're now five minutes over i would like to thank all participants both locally and remotely it is deeply appreciated that many people either went to bed very late or got up super early to be here virtually the next place where we can continue discussion is the safnet at itf.org mailing list and this is where we can figure out whether to do another buff to initiate a working group or to do something else the mailing list is the next platform for discussion thank you all this was a very exciting session and i wish you a very pleasant day what"
  }
]
