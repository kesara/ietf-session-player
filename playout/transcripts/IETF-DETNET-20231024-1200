[
  {
    "startTime": "00:00:17",
    "text": "okay with luck this confirms that you are in the right place we'll wait a few minutes for others to join"
  },
  {
    "startTime": "00:02:28",
    "text": "for okay I think we should go ahead and get started it's 5 after um let's see ah hang on a minute me EO says click there first okay this is the this is an ietf meeting so this is the usual uh ietf note well slide um it's been shown uh if you attend this meeting uh this applies to uh you and to any anything anything"
  },
  {
    "startTime": "00:04:03",
    "text": "that is said in in the meeting okay enough of that let's go back here and get the agenda back up which is over there okay so the not well slide has been shown this is an open working meeting of the uh detet working group uh on uh queuing and scheduling mechanisms uh final decisions will get made uh on the list and there's an upcoming uh meeting in Prague in a few weeks this is what the agenda looks like we're going to have a little bit of discussion of process oriented topics including um a quick update from Ping On the latest uh uh revisions to to the scaling requirements draft um and Twan has an uh initial evaluation slide on uh his uh bounded uh delay Q mechanism and then open discussion of all new mechanisms uh I posted something to the list on uh possible categorization um I haven't read the replies yet I promis to read them soon and we can talk about whether that's use in general talking about uh what we would like to be presented to the larger meeting in Prague in a few weeks so that's a quick overview of the agenda anybody want to bash it okay hearing silence and not seeing any"
  },
  {
    "startTime": "00:06:00",
    "text": "uh volunteers I'm going to consider the agenda bashed um so to oversimplify where where we are um we've um managed to get through I think in-depth presentations in these meetings of all of the uh new proposed mechanisms the current count one two 3 four five six seven we have eight of them um their initial evaluation uh slides prepared by the proponents of each mechanism um that are in the uh archives for earlier interim meetings and uh in a little bit we're have Antoine talk about ini evaluation of his bound delay Q mechanism uh but first Pang do you want to say anything about the -04 version of the scaling requirements draft okay uh well um so um I uh post the draft um but it's mainly um follows the discussion in the last entry and most of them are are the same with the last entry um only a little difference um okay maybe I can uh I can share my screen just a little different sure let me go stop sharing mine so you can share yours all righty um ah there we go I click there should work yes okay so C yes it's coming"
  },
  {
    "startTime": "00:08:01",
    "text": "through uh okay sure so uh this are the slides um used in the last entry and it has propos Chang I I want go through uh all of them um the only REM issues uh was that okay for for this one requirement um seven in section three yes and last ENT uh here we have some comments to propos to give some uh sentence to describe uh how to judge that um to meet this requirement uh for example for the latency and we give the uh function related criteria about linear and exposal and also for the dater and for the routing calculation and the results scheduling um but uh J has some comments on it um we could see that there's uh may not uh there's not be the for 40 um consens so um so here say let me check okay here's the difference of the draft okay yeah yeah you you'll need to you'll need to settle on something because uh the yeah the the the finer resolution uh pixels are taking a little while to propagate Halfway Around the World okay go okay so um the main change for this uh requirement is that we just add sentence performance of a queing mechanism can be evaluated based on the lency bound data bound and"
  },
  {
    "startTime": "00:10:01",
    "text": "uh execute time required for the resource schuling and which might be constant or linear functions or exposal functions in terms of numbers so we don't really give a standard of how to judge or how how to evaluate the um C mechanisms uh in this version and uh I think if we want really give some um standard um evaluation Method All directions um women need more discussion um just just here yes yeah I liked where the slide you were showing was going although I think the words acceptable and unacceptable might not be the best choice of words um I think it would be good to capture that um latency is latency almost has to vary with uh the number of Hops uh linear relationship number of hops is kind of unavoidable but that um Jitter ought to be controlled and constant independent of number of hops although I would like I I understand why I understand that the words acceptable and unacceptable were used I'd prefer not to use them in the draft yeah yes and independent HP number is fine um okay um so should the we other CH it or we just to report this is us to the WG in the next meetings"
  },
  {
    "startTime": "00:12:03",
    "text": "I think we need some language for posed on the list and I think I just volunteered myself to do that so this is in section 37 of the requirements draft yeah yeah let me let me make myself a note to propose some language on okay so um maybe should I just to post to this text to the mailing list you could post a text to mailing list and with and that should prompt me to to reply okay sure I think I can maybe I can also find this email um oh okay I I would I would do that yeah and I promise be a little prompter in getting to this one than I have in the the past okay um so I think there's no others problems with the updates of this version is there any questions looks like jinu has a comment go ahead yes thank you so what I'm looking at is the new version updated version right yeah okay but um what I just saw yeah here um I see I see it differently because the new wording you just mentioned the performance of a king mechanism can be evaluated based on lat and so on um so the the right side is the newer one right yes I think just copy of words"
  },
  {
    "startTime": "00:14:01",
    "text": "here so yeah what I what I want to ask what I want to clarify is that this this is this uh sentences what I'm looking at is actually have been updated in the new version of the scaling requirements draft or not [Music] um yeah we should be looking at the 04 version to draft this looks like it's 03 well version okay how um let me see find it th between uh previous version and new version so right column right hand the column on your right hand side is the uh or for version new version okay thank you then the the PowerPoint does not capture that update I think uh yes it's difference it's it's a slid Us in the last in so new version of the text I haven't so okay so soers here well okay sorry it's also not the same yeah but yeah but I would like to make myself clear that the issue I have raised is not clearly resolved yet maybe you can discuss it later thank"
  },
  {
    "startTime": "00:16:03",
    "text": "you okay okay so is there any other comments let not for this we can leave it in the middle list okay okay sure should we move to next part or okay did you have anything else on the uh requirements draft uh yes I like the infite screen regression we had there for a moment yeah uh yeah I actually I I only have one issues uh now about just about this requirement and uh of course I will also uh present there Chang in the WG meeting and to see if there's uh any more comments from others I will send I will send some proposed text for that 37 section to to the list because I think it's I think it's useful to capture that uh Jitter that that Jitter ought to be constant but uh latency varies with uh number excuse me latency varies number of hops okay okay sure thank you and Sh Fu"
  },
  {
    "startTime": "00:18:01",
    "text": "go ahead hi and I think the uh resource scattering maybe not easy to uh I I read the M that we take example that rpte uh uh I inde I think the calculation is difficult uh even for rtt I'm sorry I I didn't understand your point uh my point is that the the resource scheding uh maybe not easy to evaluate okay I think you make comments on knows I on the milon list right if I I understand but we have discussed about some yeah P You're sharing your entire screen so we're watching your email you might not want to do that okay um oh I think Shop's uh comments about this points because uh because J has comments and say about the rvps and we have some discussion about it in the minute yes uh yes if we take sbts an example uh the workload is not just that to uh Reserve"
  },
  {
    "startTime": "00:20:01",
    "text": "resource I each hope uh but the main work is to calculate the pass uh and the head end all and the controller uh so this work uh cannot uh be ignored so I I think this work is not the N relationship with the H count so that is my point point so you mean that you think RVP is not a uh linear function right yes well I think there's I think there's a general Point here which is that the calculation has to be done before the traffic flows is separate from the forwarding be Behavior while the traffic is flowing and the calculation in advance to set up the route could be considerably more complex agree yes and at that level that might be good that might be good to capture which is that um once a traffic flows um then the the the latency linear number of Hop and Jitter has a constant bound properties are highly desirable but you may have to do quite a bit of calculation in advance to set up uh the paths and Al uh allocate the buffering resources yes uh though it is before the forwarding the flow forwarding but uh we expect that it don't be so complex uh but it's also related to the uh"
  },
  {
    "startTime": "00:22:01",
    "text": "algorithms and also hardware and the coding in play yeah I think I more or less agree at some at some level there's no free there is there there is no free lunch here some of these calculations are going to be complex youu you wanted to add something yes yes thank you David uh you're uh you are I agree with you yes the routing calculation and the resource scheduling are control plane functions and it it has to be done before the flow the package flows yes but on the other hand some of the queuing mechanism we are discussing uh has a quite a lot of burden in calculating the resource scheduling how much does it burden um it really a lot yeah as the flows join and leave we have to constantly adjust the control plane functions and uh uh reserve the resources and in some cases we have to allocate the time slots for it flows maybe these are so complex so in some research uh when the the flows more flows are more than 20 200 then it takes about two or three seconds to schedule the slap so it is too late to accept or not so I think we have to consider the control plane functions as well every queing mechanisms follows a a specific Control Function to consider both the king"
  },
  {
    "startTime": "00:24:04",
    "text": "K okay okay I've written a note to myself as part of that I will add that to the text I promis to propose okay Pang we have open issues outside of section 3.7 I think we're I think we understand 3.7 at this the 3.7 at this point in any case next next next step is I I need to propose some text oh okay I don't have any Ops okay anything else go ahead Janu thank you for the shu's comments uh I can I can answer that yeah the routing calculation is certainly a number of um you know it's a function of the Hops and it is likely to be exponential routing calculation it is but the RSB itself it's just the distributed mechanism and as the number of hopes increase the complexity increases as well but it is linear function it is very well known and and about the number of hopes because it is a distributed function the complexity itself is just a constant but the total calculation time is increasing not the complexity itself total calculation time is increasing but it is also a linear function of number of all so um yeah that's why RSVP or the similar reservation mechanism has been very popular because it is scalable I would"
  },
  {
    "startTime": "00:26:03",
    "text": "say thank you I suspect was part of that RSVP ought to be used only as an example answer maybe we come further discuss in my in belief my major point is that the calculation itself maybe based on some con for example B virus uh based on uh the largest G networks uh is not Justice to see that they we have good certain tend to reserve the B resource but it just need to First need uh to pick up the target pass my my my my means to P this target pass uh maybe n this is the yeah I think I think that's right I think we we see some proposals that anticipate a I'll say centralized which is as good a word as any precalculation of where to allocate the resources uh for for the flows and that that that can be complex particularly if a if a complete solution is required for a large number of flows and a large number of nodes yes uh David is yeah David makes a very keen"
  },
  {
    "startTime": "00:28:00",
    "text": "observation yeah the traditional routing and resource renovation is all distributed so it is robust and can be scalable but uh the slot scheduling or flow uh flow mapping into the slots is traditionally in TSN it is it has been centralized so the centralized contral entity has to do a lot of work and in a large scale Network it can be a problem that's my impression so anyway my suggestion is to not to decide whether it is acceptable or not I think the time slot based scheduling has some Advantage as well only problem only problem is that uh it is not so scalable into very large scale meod so in this requirements document we just suggest that this this can be the performance criteria and we do not accept just recommend some uh Baseline for example the for the latency the Baseline recommendation is the linear function and so on that's that was my key suggest I think that's about right and I think the use of the words I think I don't the words acceptable unacceptable did not wind up in the draft I don't think and we should avoid those words I think the way you express it as you knew is very good okay sure okay anything else on the requirements draft"
  },
  {
    "startTime": "00:30:00",
    "text": "all right um thank you very much ping it looks like um oh I should I should check uh what is the draft cut off uh for uh uh for the Prague meeting um oh heav problem we'll probably are we past the draft cut off for the Prague meeting no we can't be one yeah we yeah yes it yesterday okay yeah it was okay um so I think that the thing to do we discuss on the list and present proposed text changes in the Prague meeting uh maybe submit an ' 05 at the start of the Prague meeting week maybe discuss in the meeting I think both of those would work work Yannis uh do you do you have a preference I'm sorry I didn't get the question preference between okay courtesy of what's on the screen now and discussion it looks like there's going to need to be some uh text edits to section 37 of the requirements draft and I guess the question is should Pang submit a new version at the start of the prog meeting week or should he take the new text into the Prague meeting for discussion and submit a new version later on which would you prefer I would suggest a second one because the um uh first that net meeting is on Monday the second one is on Wednesday so we are very early on during the week and uh if there's a new revision I guess people"
  },
  {
    "startTime": "00:32:00",
    "text": "don't really have the time to check okay but of course I'm open that's just one aspect okay all right I think that sounds good um I have to figure out why the Monday meeting is not in my calendar I suspect I didn't pay enough attention to the agenda okay so I I think if we get the better text uh I can present it uh based on the current version I think okay I think that's fine some we won't add or change some text okay sounds good I think that's fine I've promised to to to to help with better text okay thank you thank you ping okay all right I think we're done on the uh requirements draft um anine I think you're next let me see if I can get your slides up here yes uh can you hear me yes we can go ahead great okay uh so uh following a prompt reminder from David I sent uh the long du uh evaluation of the mechanism that uh I presented a few interim meetings earlier about bonded leq uh mechanism via Cur resizing so um I I followed the formatting that was already done by previous work and evaluated our mechanism with regards to the items listed on the slide so I"
  },
  {
    "startTime": "00:34:01",
    "text": "suggest that we go with the items one by one so uh sections 31 ter timings as synchrony so as a reminder in our mechanism we bound the N delay we bound the N Del for flows by reserving slots in qes and in our mechanism each node is responsible for enforcing a local lay Bond and the sum of the local delay bonds that are respected by by inpath node makes the end to end delay bond that is respected for the flow and we use the rpce to Signal the requirements for the flow in term of delay bound so has the each node has uh local commitment to respect delay we we evaluated that uh the mechanism that we present in the draft is tolerating timeing asynchron regarding the second uh requirement support large single up propagation latency um the propagation delay between nodes is uh taken into consideration by the sending node and uh this if we consider the propagation delay between two nodes as beinging a fixed quantity uh at least a quantity that can be bounded and in case this quantity is bounded we take the maximum bound so we think that uh our mechanism can tolerate large single o propagation latency of course at the expense of being able to accommodate flows with low delay bound but this can be accommodated third recomment accommodate the higher"
  },
  {
    "startTime": "00:36:00",
    "text": "link speed uh yes uh our mechanism act on the delay spent by packets in Q as in independent from the link speed in the sense that um the trans the time that a node takes to transmit a packet and the prop the time the inflight time between nodes is accounted as a fixed quantity and we act on the length of Q at the equipment so uh whether the link speed is high or low is a parameter in our mechanism and does not affect its function in functioning beyond the capacity of a mechanism to accommodate low delay bound so we evaluated yes to the third requirement B scalable to the large number of flows um we say that we partially uh meet this requirement because um in fact in our mechanism if if all the Q capacity in the node is uh allocated to some flows we can't handle new flows so there is uh there is a limit with in the scalability of a mechanism which is uh if you look at an netw the node which is the most solated or the node with the least capacity once this node has taken all the reservation then uh there is no capacity to handle more flows uh so this is why we evaluated a partial uh depending on the opinion of people in the in in this uh meeting we may also evaluate it as no and we think it could be perfect perfectly it would make sense but given that we think that"
  },
  {
    "startTime": "00:38:01",
    "text": "this limit is quite High yet there is a hard limits this is why we evated as partial for this uh for this Force requirement with regards to the Toleration the tolerating ey utilization uh given that once we have reserved all the capacity we can't Multiplex those reservation we evaluated as a no uh because we can't once a resource has been allocated to a flow in the que we don't we can't uh allocate it to two Flows In in parallel so this is why we we stated a no on three 42 uh prevention prevent flow fluctuation from disrupting service um yes in fact as soon as the flow fluctuates under the capacity that is reserved by on pass no cues our system toat flow fluctuation in fact handling the fluctuation depends on the acceptance me mechanism at the Ingress node of the network that is responsible for making the reservation and to end to the destillation because in our mechanism we couple the capacity reservation in the cues with um with a strict uh flow acceptance mechanism at the Ingress node um if the the flow fluctuation is in the limit that is um Allowed by the by the capacity reservation then we tolerate this flow fluctuation toate failur of Link or nodes and topology changes um for now uh I would say that our mechanism does not allow this because uh in case of the"
  },
  {
    "startTime": "00:40:03",
    "text": "failure of a node we would require to establish a new reservation using the RSVP protocol and uh in the protocol we didn't describe yet a failover mechanism in case there is a failure of one node on the path so uh for now this is a no um if we if we think if if we consider and if the group considers this could be a good addition to our draft we can describe a failover mechanism uh using RSVP to do an alternative reservation and uh redirect uh traffic on the cter net flow but for now in the draft and its version this is not present yeah that that should not be a problem in evaluations of the other mechanisms generally three St 6 and 3.8 have been uh set aside as not bearing directly on the scheduling queuing in the node but uh as you say being uh affecting sort of more Global framework concerns that are somewhat independent of the actual schedu queing mechanism yeah and and this is where I think that the discussion we had earlier on uh distributed versus centralite mechanism as as a strong Ence because if you are in a central in a setup where you have a centralized controller then the redirection is triggered by the centralized controller on the event of the detection of a failure in a distributed setting you need to put in place some more uh a protocol mechanism potentially using RP to redirect around the failure 3.7 scalable to a large number of Ops with complex networks"
  },
  {
    "startTime": "00:42:02",
    "text": "uh I don't see uh I I mentioned partial because uh uh from a theoretical perspective I don't see theoretical limitations but uh we don't have a large scale simulation evaluation to back this affirmation so for the sake of uh being um inter an inter TR sound evaluation I prefer to mention partial I don't think there is a strong limitation but uh we we fail to have simulation to back this information and on 3.8 support multiple mechanism in s in single domain and multi multi-domain uh I mentioned partial here because uh one thing that we need with our mechanism is that once you play place a packet in Q the time to serve this packet is uh deterministic so in the draft and in our mechanism we assume that the the Q discipline and the Q service is a variation of uh of deterministic um Run Rin where uh cues are served for a given amount of time every uh x amount of time and those quantities are deterministic uh we can accommodate some variation around deterministic round robin but uh change in priority of the packets uh reordering of packets in the cues reassignment of more uh higher level priority to some cues that makes the service time of cues in the equipment non deterministic are not supported in our mechanism so I think I went through all the requirements uh uh I've seen that"
  },
  {
    "startTime": "00:44:03",
    "text": "there there were some remarks uh written uh on the chat I don't know if it was for related to this evaluation if you have any question I'm open to answering to it the best I can let's see trying to summarize on chat I think it's roughly independent of this particular mechanism uh it appears to be a discussion of um of a a path calculation and noticing that that if when you launch RSVP on a path RSVP is linear in uh node count but if you have to do a global calculation to figure out what path to launch RSVP on that could be more complex I hope I haven't misstated what we said in the chat um I agree I agree in fact in our mechanism uh we tweet RSVP reservation one after the other and uh in and uh so we we don't Rec compute all the capacity allocation when a new RSVP uh reservation is uh is happening on the network so I think it makes the it helps with the scalability of our mechanism to a large number of flows I think it's a discussion to. 341 um uh because in fact in in our mechanism we don't recompute the capacity location in the different cues when there is a when there is a new reservation that is coming in the network if the reservation can't be served we we send an error using err zp"
  },
  {
    "startTime": "00:46:03",
    "text": "and we don't accept it so we this is how we this is how we do so this is what makes me say that we are scalable to large number of flows in terms of this capacity to treat the rzp reservations the limit in term of scale in my view is related to the capacity of the node on the network on which we perform the resoltion because at one point in time if one node doesn't have any capacity to allocate it's not able to accept new flows and when you say allocate if I understand this correctly in order to accept the flow you have to allocate a cube to that flow on each node uh that the flow passes through is that correct yes in fact when when I me when I say allocate it means that uh for flow when you have uh an endtoend delay constraint you give you take a part of the end to end delay and you you you say it's a per note delay you look at the cues on your equipment that are able to serve the the in this delay credits and you take uh and depending on the capacity of the maximum capacity of the flow that is going to Traverse the equipment you allocate space in the queue that is able to serve the packet with the within the lad contract so for instance if uh all the space in a que that is able to meet the per no delay contract is uh all the capacity in those SK is allocated the node is not able to take more"
  },
  {
    "startTime": "00:48:02",
    "text": "we have in termos scalability and uh well if if um all the cues in the node are are have their capacity allocated or if uh the only capacity left is not able to meet the end to end delay contract we issue an error in our mechanism does it answer your question or clarify it I think it answered it uh zenu you had had a comment or question yeah I I do have a very basic question for clarification anony if I may so yes of course yeah yeah my first under impression is that um um if if you have some allocated qze for a flow right M what if more than more packets that the Q allowed are coming into uh this is um we in the draft we describe the fact that um we don't allow if you have a reservation is a given bandwidth and um and the delay contract so when you are doing the reservation on each node each node has uh but what you reserve is the rate right flows rate yeah in fact what we reserve is some space in q's and we Translate the rate in the the space that we have in in the queue so if a"
  },
  {
    "startTime": "00:50:02",
    "text": "flow send packets in excess so the excess the rate then the the node that is doing the the flow acceptance is rejecting the packets that are overflowing the reservation that is um that has that has been taken in the network in fact we but even of the flow even if a source of the flow sends the flows very smoothly the the packets inside the Netto can accumulate and become burst and that as hopes goes by and it is not the close F we did the comp we did the theoretical computation uh with the colleague that is is working on network calculus and provided that there is a strict uh flow uh acceptance mechanism that prevents packets to accumulate and provided that the Ser the service rate in the CU in in the network is deterministic we show that we don't have um we don't have this burst um burst accumulation okay uh if that is that is true then every every Q allocated is not uh exceeded I mean yes yeah yeah what what you do I mean every packet is fit into the queue so um what kind of control you have over those allocated packet to send send them five first in first out yes yes EXA exactly in fact we uh in our mechanism we place the"
  },
  {
    "startTime": "00:52:00",
    "text": "burden on the acceptance of the flow so the the Ingress node is responsible for making sure that the the maximum capacity is for the flow is not exceeded then all the computation that we do for the delay bound is uh based on the worst um worst Q delay scenario in fact when we have a queue and we commit that this queue packet located in this queue are served with a given uh delay for instance they are served in five millisecond it means that given the the round ring service of the queue and its size if we place a packet even at the very end of the queue we we meet the delay I see so basic scheduling algorithm is round ring maybe round or something yeah as soon as soon as the service rate of the queue is the terministic round the terministic round robin maybe some more complex strategy we can't think of then we we know that from computation this is um the the bond is met of course we are not tolerating a utilization but at least from the delay Bond perspective we are respecting the contract again I understand but um yeah uh I think you have to make it sure that you're schu round Bas yes yeah maybe maybe we need to stress that in the draft uh I will ruse the text to make sure that this uh this is very clear to the reader okay okay any other comments or question questions foran shafu go"
  },
  {
    "startTime": "00:54:07",
    "text": "ahead uh hello uh hello uh I I have another question is that the uh uh do you need the the B uh the type of B resource uh except that the B Wiest resource um sorry I didn't get your question can you repeat it please uh my means that do you need uh a new type of resource that is past except yeah in fact uh what we need in in case of burst we need in the flu acceptance to uh cut the burst in fact when when a burst occurs either the burst is in the in the in the bandwidth that is allocated in the flow and we can serve it but if the burst I bypass um is larger than the bandwidth allocated to the flow we need to to cut the we we need to cut the flow and eliminate packets that over that are over the the past reservation so the burst is uh is uh is leveled at the Ingress node of the of the network the node that is allocating the resources uh to the destination but uh we make a very strict uh flow accept flow AC acceptance policy so burst are not uh coming in the network um but I have uh just uh uh another"
  },
  {
    "startTime": "00:56:02",
    "text": "impression about the you uh uh statement uh uh you see that uh the flows and the network entry uh are cut to some small pieces uh even for this uh under the intermediate node there may be multiple current flows arrived uh then the the pass agregation uh may be reaches some certain size but in fact no this is the thing as soon as the flows are the Ingress of the flows is controlled by yes by by result uh if you allocate the maximum capacity in each inter intermediate node you are sure that you are not going to exceed the capacity of the intermediate node at the expense of I utilization of the network we completely agree with that but as soon as the flow acceptance is done very strictly and if you cut all the burst in the Ingress of the of the network you are sure that no burst will appear in the network in the middle because uh from from computation but I agree with you that this is not a utilization and when you need to stress that a strict acceptance policy is applied at the Ingress of the network yes that that is the point that the uh uh for the maximum bu that uh intermediate node can uh support uh my means the this maximum s is just the first"
  },
  {
    "startTime": "00:58:00",
    "text": "resource that the not support yeah uh maybe this is seen as a as a limitation but this is the characteristic of the of the mechanism because uh if we if we accept burst all the all the equilibrium of the mechan inside the network is not insured so we took the design decision to cut the burst very very highly so uh this is our stance and uh this is how we manage to to make the network um oper operate in equilibrium and as I think you said earlier this mechanism does bandwidth reservation and so if the average bandwidth is the flow is presenting is lower than the reservation there's then head room between that uh average bandwidth and the reserve bandwidth for some amount of burst Beyond which um you've taken an EF like approach EF is one of the diff serve uh sketching disciplines that says if you've exceeded what has been reserved the excess traffic is simply dropped to avoid building up delays exactly in fact this uh in when we designed our mechanism we did we conceived that uh people may not reserve the average of BWI for the flow that they going to to transfer on the network but maybe 99 98% of the peak capacity they are going to issue on the network so maybe the two five to one to 5% Peak traffic will not go through or not go through with the respected delay bound"
  },
  {
    "startTime": "01:00:00",
    "text": "but for the rest of the traffic we are able to accommodate this delay bound right and that's reflected in your 3.42 line where you're not uh achieving High utilization because quite a bit of the network bandwith is set aside to accommodate the the 95th or 99th uh percentile bursts EXA exactly exactly all right thank you any other comments or questions for antoan uh thank you for your presentation uh I didn't have a chance to read your draft uh but uh uh from uh discussion uh you mentioned this mechanism uh has been mathematically uh uh analyzed right yes yeah then uh could you uh send uh send us a link of reference paper or a document that shows the analysis so we presented some element of the competition in the draft itself and I presented more elements in the in the slides that I presented in the inter meeting a few weeks ago um if you have any question Beyond uh those I suggest that you send me uh an email with a detailed question so I can answer you in detail in written form uh but um let me check um uh I will I will uh send you the"
  },
  {
    "startTime": "01:02:04",
    "text": "reference to the to the slide that I presented in the previous interum so we can keep in in touch about this analysis if you want if there's a separate paper with the analysis and calculus please make sure the draft uh contains a reference to that paper sure but uh all the in the in the draft we presented all the elements for most of the elements for the calculation uh we make sure that uh because we didn't publish it yet this uh this analysis in an academic conference so if we happen to have a publication in the lifetime of the draft I will of course include it in the reference but for now the elements that we have are are in the draft and in the presentation that I that I've done a few meetings back okay okay first I will I will read your draft and right now I don't see any any um reference of paper in your current draft but anyway thank you m okay anything else for Antoine all right Anan thank you very much messy bku thanks a lot for having me here and giving me opportunity to present even if it came late I agree appreciate the participation um want to include if want to include uh the"
  },
  {
    "startTime": "01:04:02",
    "text": "relevant uh technical proposals so that we can make uh make good choices okay so uh Yannis do you want to say or offer any uh guidance as to what we ought to be doing to prepare for the for discussion of these mechanisms in the upcoming Prague meeting for I go go to the uh categories and taxonomy emails actually in my view this uh taxonomy uh would be a great step forward so yes we are working on the agenda with L and uh we hope and expect a report or summary from from you David on his open meetings that would be great um yeah from everyone as usual we expect a brief summary if possible but really the floor for the technical details and discussions the venue is these open meetings and honestly I expect to continue these meetings after hf18 um if we could um like I I see the next step towards for us is this this taxonomy evaluation and and and and somehow uh decreasing the number of uh of uh Solutions on the table okay I think I agree with you I think U there's a I'm going to there's a classic cartoon somewhere I forget what where it was published is likely to be a New Yorker cartoon which shows uh professor at uh the Whiteboard with a lot of calcul top of the Whiteboard the words and a miracle happens here and a lot"
  },
  {
    "startTime": "01:06:01",
    "text": "more calculations ending in QED I think we are we are approaching the need for the end of Miracle happens here stage in figuring out uh what to take forward all right let me go ahead and uh put up the uh taxonomy email um and then there were a few comments on the list thank you very much to the people who reacted quickly and I I apologize that I gave way too little Advan uh notice on the taxonomy so there'll be plenty of time for further discussion on the list but let me hang on can't talk and click at the same time so give me a minute here yeah all right all right apologies for the small font size I hope people can see it so this was some initial ideas for the three categories um periodic scheduling shaping and uh time division multiplexing there have been a couple of commment on the list so let me go deal with quickly deal with those I think both comments are very very useful this was done I put this message together late last night in my time zone and okay so um hasham asks sort of what are we doing here uh and I think the answer is we've done the evaluation s of the TSN mechanisms and found that they fell short of some of the requirements in the"
  },
  {
    "startTime": "01:08:02",
    "text": "scaling draft in particular scaling requirements draft in particular they don't scale well there were two requirements in sections in the scaling draft that refer to scaling um to a larger number of flows and larger number of hops which uh none of the TSN uh algorithms met well and that's why uh we're looking at additional mechanisms ham did you want to say anything okay uh Shong comment is I think she's completely uh I I agree with her that the third category is poorly named that the that uh cqf is not really a Time division multiplexing uh in the classic sense that that's uh used in uh some other communication mechanisms and yeah it needs AIT that category needs needs a better name uh so it's the the the third category is motivated by needing to uh Define some kind of label that captures cqf and enhance cqf and uh at least two proposals that have been made here um that effectively extend uh uh those uh algorithms to uh to to uh to larger number of uh of buffers suggestions for a better name are very very welcome"
  },
  {
    "startTime": "01:10:15",
    "text": "and and I think we're I don't think I'm there's a disag I have a disag the what I wrote and she s comat how to Cluster are in disagreement uh junong did you want to say something go ahead for C how about uh cqf variant um yeah that might be good just maybe just call it uh CQ uh maybe just call it cyclic queuing that might be an easy way to do it and another point that I uh have uh uh I mean another point that I want to mention is that about uh T you classify you put that uh T into a shaping category but the yeah right I mean that since the name of that a2.1 Q BBV is often called uh time aware shaper but I think is more or less uh uh uh it's better put into a periodic scheduling category um no what do you think uh another okay another related uh question"
  },
  {
    "startTime": "01:12:00",
    "text": "is that the uh you mentioned in uh uh periodic scheduling you mentioned TSN defines per priority level time based repeating schedules um I'd like to know what that is my guess uh that might be t as no um no it's not it's something else uh that's very uh very basic um category a was intended to capture as said a fixed cyclic schedule where I mean uh in realtime operating system work this is referred to as hard whe time where there is an absolute schedule that time at at at at a time slot T exactly this is being exactly this is being done and I don't know I had initially calculated uh the time aware shaper as a shaper rather than a a periodic scheduler but uh I mean that's exactly what uh this uh qbv uh gate control uh list is doing right I mean that the you allocate um you uh you control uh gate of uh class Q each class Q uh in uh each time slot whether uh the gate uh would be open or closed and then uh you repeat uh some number of time slot uh uh as uh as a psycle okay I need take I I need to take"
  },
  {
    "startTime": "01:14:01",
    "text": "a closer look then oh okay okay thank you okay no problem hang on a minute shafu okay go ahead oh just uh quick uh uh uh statement that my point is consistent with J uh the in t there is a a gting cycle that is exactly a long time period that uh contains multiple items and each item is to control the open or closed State for the the related CES yes it should be uh uh uh it should belong to the uh p c okay I'll take a look all right hang on so all right okay and then I get to the other message was from jenu and I okay I think that independent of whether we do these specific categories you know I think your your your the biggest point I take away from this is that um work conserving versus nonwork"
  },
  {
    "startTime": "01:16:01",
    "text": "conserving uh is an important aspect and I guess what I don't understand here is whether work conserving ought to be used for categorization or ought to be used for evaluation of algorithms within categories oh yeah my point was that um according to your classification the CIS core or um round robing or Fair queing such a schedule doesn't fit any of the category one two three or ABC yeah one two three so um okay yeah let me just go and ask right there um why would would you consider ccore not to be a shaper well um traditionally shaper suppressed [Music] the you know uh or conserving manners of packet trans transport I mean um shaper does not send packets even if the link ID that's the whole point of the shaper shaper holds a packet and doesn't let it gr but uh all the work conserving scheduler always send packet whenever the link Idols so the link never idles when packet is there packets are there so that's the the main difference so work conserving schedulers and not Shapers but all the uh queing mechanisms in your message is kind of Shapers so it's a big"
  },
  {
    "startTime": "01:18:02",
    "text": "difference so I think that's the first categorization rule whether it is work conserving or not that's the big difference uho I'm sorry to interrupt the uh I have different opinions about uh you uh statement uh in my opinion that the uh fysal maybe uh special shaping uh the finish time is just uh a WR one to uh to sort the the parage yeah uh so it indeed is a special shape but the shape result is not the uh the similar to traditional shap star for example ATS uh or some other regulation that my opinion s so um if I understood you correctly the the shaper or shaping nowadays means just scheduling and it doesn't need to be really hold the packet whenever uh even if the link Idols that's your point the the shaper the term shaper has changed the meaning of the shaper has been changed yes so I understand that the shipping here has a broader meaning okay and I think but uh but I would say"
  },
  {
    "startTime": "01:20:00",
    "text": "um I would like to correct it the shaper shaper in traditional meaning so non conserving something yeah okay I understand yes um yeah so for uh if we take a look at the the external F of ATS it is actually the non work cons as you mentioned but the some opinion uh is that if we Decap the the the whole work it may be a Le controlled and discarding pH so it just the Le controlled but the scening for ATS is water with work conserv I think that point that opinion is also so uh consistent with po s sorry I couldn't understand your uh recent comment what what you mean I could understand could you repeat or refr uh I'm sorry that uh my point is that the uh the total work uh of the scy May decou to two parts the first one is R controlled by a traditional ship such as the interne regulator of Adas that is really controlled but the next component is the the subsystem that is uh scening packet to send uh in my opinion is that the component is always work cons yes yes this that's the whole point"
  },
  {
    "startTime": "01:22:02",
    "text": "yes right uh for example in ATS uh at is composed of the inter regulator plus fif schedule so the schedule Theif is one conserving but IR is will me yeah um traditionally the IR is is already controlled yeah yeah IR is the shaper and F4 is the scheduler so a shaper can be combined with scheduler yeah that's that's correct and yeah I want something I want to uh divide some um well conserving scheduler that guarantees the end end to end later about without shaper that's the there the whole point of the ccore yeah thank you okay so it it sounds like the shaper category ought to be renamed to something else because the term has long usage for uh technology that is not work conserving and maybe a better name for that category that would include both the traditional Shapers and the new work conserving algorithms uh would help right yes but um yeah I agree yeah um so we in in Academia we we just call them just data plane functions because uh shaper is one thing the Schuler is another and any shaper can be combined with any schedule so they are orthogonal but um if you combine two things and call it with one terminology um I cannot I cannot come up"
  },
  {
    "startTime": "01:24:02",
    "text": "with a suitable answer just data plane function I'm not so sure thank you okay J something to say Jong go ahead all right uh but uh for the time being uh how about we uh just make a note for category B such as uh category B includes both uh work conserving and non work conserving mechanisms uh in other words until we find a a better name thank you sounds good to me thank you okay the clicking you hear you might hear is me taking notes to myself in this discussion on what to do and I suspect I need to turn some of this into an internet draft so that it can be referenced okay more comments would be very welcome to the mailing list I list as I said in the initial note I apologize that uh I got that email out less than 24 hours in advance of the meeting um so happy to happy to listen to more comments the list if people want if people want to think further and I will try to start assembling a document uh of some form form uh something here will land on slides for the inter for the uh main meeting in"
  },
  {
    "startTime": "01:26:10",
    "text": "Prague okay hang on a minute um oh um I'm not sharing the right window just a minute here let me go get the right window shared um this was what we've just been talking about for the last five or 10 minutes and my apologies you know I should have put this up before we started this as opposed to putting up putting it up afterwards and I think the crucial thing is that uh Janu is making the point I think J dong and I think shiau agreed that um work conserving versus non-w work conserving is a really important distinction at least in category B and possibly Beyond um and um another point I want to make is that the I I used the I used the term um time slot based schedule but um how long that time slot is is a crucial point and many of our uh Solutions do not specify how long the time slot is for example it can be very short for um to acate to accomodate just a packet that's I think what uh David is mentioned in C category a or category one uh in the another extreme example would be"
  },
  {
    "startTime": "01:28:01",
    "text": "the cqf or um whatever you call it can be based on class so every packet or every flow within the same class can be within that very big time slot it can be very large actually um floran um I cannot remember his last name but floran has mentioned with a nice clear graph with his um terminology of time slot and cycle confusion and I think that figure uh describes our uh lack of common understanding of how long that cycle or time slot will be depending on that the duration of the times the complexity of the control plane and the complexity of the data plane varies a lot so yeah that's my just thought I'm not sure how I can suggest into the categorization is thank you David I will took a note to go take a look at Florian's email you said it's on time slots and what else I'm I missed a word SL gate and cycle intermixed I think okay and got we have to clarify those terminologies thank you okay any other comments or questions on this or anything"
  },
  {
    "startTime": "01:30:13",
    "text": "else all right I think we're probably done yanas do you want to do you have any closing remarks or should we declare Victory and go do some more productive work I have nothing to add looking forward to uh meeting you at the next ITF and continue our discussions yeah I unfortunately will not be in Prague uh I can no longer get uh travel approval from uh my employer so I will be remote for the foreseeable future much as I wish I could go to Prague yeah that's uh that's unfortunate really and that I would like to thank you David and and all of you for for for the work and effort yes now the hard part starts we have to make some decisions okay I think we're done thank you all very much for taking the time time"
  },
  {
    "startTime": "01:32:20",
    "text": "what for for"
  }
]
