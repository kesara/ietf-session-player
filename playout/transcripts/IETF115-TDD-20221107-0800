[
  {
    "startTime": "00:00:09",
    "text": "I checked this morning and I was like where the hell are the slides oh it's too early though sure what she's trying to do presenting here we go I can share pre-loaded slides oh yeah yeah oh you're doing it you can either one you can do it I'll do it um office lights you have to dismiss Christmas here otherwise yes John is here foreign you can come on up Hello wall we're about to get started hopefully people at the remote can hear this someone remote can acknowledge that would be awesome yay"
  },
  {
    "startTime": "00:02:00",
    "text": "there we go hopefully it's better now so if you are sitting in a room called Kensington and you do not see people probably are in Kensington 2 or Kensington 3. which is very confusing because when you first cut the stairs you see Kensington and you walk in and it's not here so if there are not a bunch of people in the room with you you're probably in the wrong place get up walk down the passageway with all the glass and then turn left already so hi welcome to the technology deep Dives on quick I'm Warren I'm Brian and let's skip to the next slide this is the ietf note well um we're the first sort of like official sessions so it's entirely possible you have not seen this you should probably read this and figure out what all it means and talk to Legal Etc if you don't know what it means but Yep this is our ietf note well and thank you everyone for showing up so early um I realize it is ridiculously early and also hello to everyone who is remote and here also hello to everybody who's going to be watching this later on YouTube probably or some remote thing a video streaming service of your choice already and with that done let me hand it over to Brian so um I've actually had this question in the hallway a lot uh so do I have to come to the technical Deep dive on Monday and on Tuesday well that's really early both days um it's even earlier on on Tuesday actually at 7 30 tomorrow and you know I was asked okay that's a joke right no I mean it might be a joke but it's also the truth"
  },
  {
    "startTime": "00:04:00",
    "text": "um the uh agenda is split into sort of like two parts um today is basically the basics of quick right gets you from I have no idea what's going on here or I've heard of quick or you know isn't that just the web over UDP to having a basic technical understanding of of what's going on and quick Jonah will be talking uh about the you know the basic introduction talk call the future with quick and um Martin will follow up on that with a talk about how quick is layered and how that layering is a bit different from you know the intuition that you'll have from you know TCP over IP etc etc um tomorrow uh we will go uh a bit deeper into a few topics uh so this is really about okay now we have the basic fundamentals of quick uh let's talk about how that gets deployed at scale how it is is sort of like used in the internet now uh and things that we've learned uh from running on the scale uh so that'll be Ian or Ian uh and Lucas who I haven't seen yet but he'll be here tomorrow um talking first about the deployments at scale and some of the things uh that we've learned through that and then like how uh to uh observe and debug applications on quick and with the rest of the time tomorrow um we will have a panel discussion with all of the speakers so if you have like interesting questions uh please hold them till tomorrow come at you know 8 30 is when that should start uh and we'll have a panel up here uh with people to answer your questions and have some discussion about quick so with that I will stop talking and invite up John ingar who will talk about the future with quick as soon as I bounce the SlideShare thank you Brian do I have to stand in the spot I think I do no I don't"
  },
  {
    "startTime": "00:06:00",
    "text": "we'll see the camera follows me um well thank you thank you everybody for being here early this morning hopefully hopefully this talk will wake you up if it doesn't uh uh I'll ask Martin to wake you up but anyways let's get started with this thing uh are we doing question and answer everything q a long side what are we doing with q a uh q a will be tomorrow will be tomorrow so if you have any questions write them down you'll forget them through the day and ask us tomorrow or catches in the corridors so I'm going to start with just this brief agenda it's basically what is quick and this is for um well I'm going to talk about Quick's immediate value proposition and I'm going to talk about really what is quick enable next slide so the subtext here is that the first piece is simply a short primer a very very short primer on Quake I can't do more than that um and we want to talk about how did we get the world interested in this like what did we do to make the world interested in this in this particular technology and finally what was the real goal what was the thing that we were really wanting to do what did we set out to do from the get-go um next slide so before I get going on to Quick who am I I am uh janayagar I'm VP of infrastructure Network Services said fastly I am an editor of the ID of quick specifications I'm a chair of the iccrg um irtf iccrg research group and I've worked on transport for for way longer than I care to remember and on quick also for way longer than I care to remember but that's me next and now on to a short primer on quick next slide um I'm gonna tell you this this is going to be a very short primer that's not going to be I don't have a lot of slides here talking about the details of the protocol the details of the bits we've done I and others have done talks on these in various places so if you go on YouTube and do a search you'll find a"
  },
  {
    "startTime": "00:08:01",
    "text": "bunch of these things um so my goal here is not to go into the details of this but to give you a a base from where you can you can dig in and and get deeper um but I'm just going to start off by saying quick is a new transport protocol now if you look at this picture this sort of has a depiction and Martin's going to come in uh thrash this picture and say well that's not quite how this works um later so that's that's fun for later but this is roughly a schematic understanding of where quick sits in sort of the protocol stack so to speak um we have the TCP TLS and HTTP protocols in the traditional stack and where quick sits is basically uh parallel to TCP and TLS and sum of http so yes it's weird but that was kind of the the uh it's all weird it was just a compression of multiple layers so to speak and TLS sits sort of within quick but it's not within quick however it sort of does sit within quick in in depending on how exactly you look at it um but that's sort of the layering picture here it is deliberately uh compresses multiple layers and it deliberately sits at these uh in these spaces because the goal here was to accelerate and deploy something that we could for the web next so what are these these features of quick that really made it viable and useful for the web well first it's multi-streamed multi-streaming is a very powerful feature it's a very powerful service the idea here is that you get within one end-to-end connection you get multiple ordered byte streams now this is not just multiple ordered byte streams it's a more General abstraction now this works really well for the web because the web has that every website has a lot of objects they are all multiple effectively uh parallel independent objects and so on but uh this is a more"
  },
  {
    "startTime": "00:10:03",
    "text": "General abstraction streams are designed to be lightweight they're designed to be built and toned down rapidly efficiently and if your implementation does it right you can use this as even a message abstraction so you can think about this as a protocol that Inc that gives you a message abstraction in the form of streams and for the transport nerds among you you can build partial ordering on top of this thing or you can build complete ordering inside this thing so you have those degrees of freedom with multi-streaming next slide foreign why is this on top of UDP it's a question that people often ask we built this on top of UDP because UDP is what works on the internet today if you want to build something new and deploy it that's the way to do it and that's what we did uh now this uh doesn't necessarily mean that the protocol has to live in user space however remember that if you wanted to build something on top of Ip you are necessarily stuck to being inside the kernel and that is a big problem for us also in terms of building deploying shipping things so being on top of UDP gave us two significant benefits one of them was that we could get through the internet as it as it as it is with middle boxes and firewalls and everything else and it allowed us to deploy in user space so those were two significant benefits which is why we use them however it requires us to recreate a bunch of TCP functions on top of it so we had to redo all the TCP functions on top of this but we didn't simply redo them we uh we did a better job of doing them um because you've learned from the past we we wanted to incorporate all the learnings of TCP and we did um and importantly quick has encryption baked in this means data or everything that is carried by the quick protocol"
  },
  {
    "startTime": "00:12:00",
    "text": "and quick headers are all protected and this uses Steelers 1.3 for key negotiation and this is uh uh basically a really important premise uh and I'll come back to this in a moment and again the Martin is going to go into more detail on exactly how this is done uh in in in quick but this was really important to us why was this important to us well of course it was important to us to protect the metadata we know today that if we were to design protocol that was not fundamentally protected that seems like we're not learning the lessons of the past 20 years so we did that but there was an even more important lesson here or an even more important reason for doing this um middle boxes ossify protocols that are exposed we did not want quick to be ossified TCP is today ossified many other protocols that have been deployed in the wild in plain text are completely ossified you cannot change them on the wire without seeing unexpected weird interactions with middle boxes that have ossified them or have certain expected behaviors expect certain behaviors of them oh that's the next one um so with sorry go back one slide um so with baking and encryption what we were able to do is basically say that only the endpoints can really understand and change the metadata the headers in the protocol as well as the body and that's an important important thing because now middle boxes are unable to change the headers or to obfuscate or to to mess with the headers or even read the headers so they can't have any expected behaviors which means that endpoints are free to change the protocol as they see fit what this means is that quick becomes evolvable so when quick gets deployed it becomes evolvable that was our goal and that's why encryption is"
  },
  {
    "startTime": "00:14:02",
    "text": "baked into Quick next slide um so that is my rough introduction into quick and I'm sorry if you didn't see all the header bits that you wanted to see and I don't want to do that here to you early in the morning on Monday you're going to see plenty of if you want header bits walk into any room this week you'll see plenty of those um I'm going to talk to you about what Quick's immediate value proposition was how did we get the world in so this these are the features right this is what I talked about this is how we talk about quick why did we get how did the world get interested in quick but it's a quick broke new ground in several ways the first thing was the zero RTD transport and crypto handshake again you're going to hear more about that after my talk um and this is fundamentally difficult to do with TCP and the split TCP TLS models you've got dealers sitting on top of TCP they end up having different Scopes when I say different Scopes I mean scopes of identity Scopes in terms of where the connection gets terminated in the network and that makes it fundamentally difficult to do something like zero RTD people have argued people would say you know isn't it the same uh isn't zero RTD in quick so before I talk about the same as TCB what zero Oddity and crypto handshake what what that gives you is a low latency uh connection setup for those of you who've not been paying attention um zero rdd means zero round trip time delay before data is uh exchanged on a connection excuse me so um we've created a zero RTD transfer transport and crypto handshake now TCP could do this with TCP fast open in TCP and with TLS 1.3 and zero RTD and TLS however because of the split model you still end up having different Scopes you have TCP that doesn't understand domains certs things like that it understands only IP addresses TRS operates in a different space and you have a split between an understanding of what the"
  },
  {
    "startTime": "00:16:00",
    "text": "endpoint identity itself is at these two levels you can reconcile these things but there's a lot of nuanced work to be done there if you want to make this work in the split TCP model um next slide collection migration was another thing that we wanted for 20-25 years to build into transport Technologies and we finally got it in and we were able to uh build this into Quick again this is fundamentally different to do with TCP in the split TLS TCP model uh in part because of the the endpoint identities but also in part because TCP we've done this with mptcb IDF has done this with mptcb but I would again challenge you to think about what we should think of as our end goals we want this to get deployed everywhere with mpdcp you still have to play nice with the operators with the network devices and so on I don't mean that we shouldn't play nice with the operators what I mean is that we can't wait for every operator and every metal box Venter to come on board before we consider a protocol deployed that is a very very long poll and that makes the tent unlivable and it's it's too loud too long a pole so that's basically connection migration again we were we've deployed it it's being used already next slide and we are able to build troubleshooting and debugging capabilities you want to hear about this a little bit more from Lucas uh tomorrow but uh the the difference here is this um the the value prop here is this right so with anybody who's anybody here who's done debugging kernel debugging anybody okay a fair number of fans excellent have you also done application debugging have you tried to correlate those traces foreign that is a pain right so when you have certain application behavior and you go okay I've got application trace and I go okay now I need to grab the TCP traces or S trace or whatever it is that you need to"
  },
  {
    "startTime": "00:18:00",
    "text": "do and you need to go down to the kernel and go all the way down the network path to figure out everything you are trying to use completely different pipelines built by completely different people for completely different use cases and try to correlate them companies that have managed to successfully build those things have used them very very uh effectively however it's not a small order it's difficult right so being in user space for uh for quick basically gives you the ability to log it log transport Network level traces alongside application Level traces that is huge because you don't have to go around doing this uh uh uh separately you can log alongside the application traces you cannot log things like what is the conditional window value what is the state of the connection what happened when was when was teams created again you'll hear more about this from Lucas tomorrow we'll talk to you about um about uh logging under the logging format that we're standardizing for quick here um but we get much significantly richer capabilities for doing this in user space next um so actually go back one thing yeah I missed oh right I meant to say this here there is a um uh another really really cool thing which I you know I'll show at the end of today if you have time I'll demo it but one thing that you have a problem with for instance is is if you have poor Behavior at the client side for instance it's you can grab client-side packet traces or you can report it to the server side who whomever is at the server and you can say Hey you know go dig into this particular Trace I'll give you an identifier for a connection for instance go find out what happened with that connection why was it behaving poorly you have no other recourse and on the server side what we would do at the server side is generally we end up having to uh find your connection now that is an"
  },
  {
    "startTime": "00:20:02",
    "text": "impossibility usually finding a connection in the fleet of service that we have and so on is super difficult to do and it's uh and then go trace it track it find the where the client is connected it's really difficult to do um what we were able to do wouldn't it be cool if the client could basically ask the server and say hey can you just send me your view of our connection over the connection that we have right now like your packet race for my connection just send it to me over the same connection that we already have that is what we built uh and we were able to do that next slide I'm not going to show you this demo right now because it's a bit tricky to get going um but the links are here go to the video only link and then go to the self Trace link using the same browser window meaning that you have a connection going over the you'll have a stream going over the same connection and that only works of course if you're using quick and I'm happy to show it to you later uh if I can get it going so this is uh uh really really valuable at the client you're able to see a service uh packet race now uh um I'm gonna move to the next thing which is transforming server architecture so I won't go into the details of this um but deg server return is an ability for a server to be able to hand off a request to another server and have that server serve the user directly so it's sort of like if if a client requests a resource from a server the server doesn't have the resource but knows another server that has it is able to sort of Kick the connection over or the request over and have the response served directly from there this is called direct server return it's called direct server return because normally what what and what commonly happens and the easier way to solve this problem of I don't have the content somebody else does is client connection to the server server connects to the other server"
  },
  {
    "startTime": "00:22:00",
    "text": "receives the content serves it back so there's a full uh path back instead you bypass this intermediating server on the return path that's called direct server return we are able to design this in quick and and some of us have been designing building this into into our server infrastructures and the reason we're able to do this is because in quick again in terms of how we build the transport protocol itself we were able to separate the sender's view from the receiver's view of the world and uh in this particular case that plays very nicely allows us to actually build something like direct server return we can have multiple servers sending with one receiver receiving this is again fundamentally difficult to do in TCP next slide so this is how we got the world interested these are the different things these are the different benefits that we brought out and we when and this is how all of us got excited about quick and so on but I'm going to now talk about what quick is enabling right next slide what does quick enable so quick enables multiple new technologies that you can build within quick so you can hear about you know you won't hear these experiments today but maybe tomorrow uh you're gonna there are new condition controllers that you can easily build and deploy I know that meta has done this Google's done this fastly we've done this so that it's it makes it much much easier easier to deploy these things in in in in quick than it has been in TCP next slide if you've not heard about mask um mask basically employs HTTP 3 and quick to create hidden tunnels right and this is something that you can again quick is enabling this technology was it possible before yes but this makes it much more efficient much uh um more performant and also more efficient at the service tax to be able to deploy uh something like tunneling"
  },
  {
    "startTime": "00:24:02",
    "text": "um and this is not just I'm not just saying talking about things here that could be built this has been built if you've heard of Apple's private relay iCloud private relay that basically use this mask extensively and it carries a ton of bytes today if you have an iPhone and you turn it on you're using mask you're using HTTP 3M quick to do this today next slide and finally media over quick uh or what I call the new world for webrtc refugees um is is as a proposal to do media directly over quick and that's again quickest enabling these Technologies now to happen because it has is its feature Rich enough that you can actually think about doing more interesting things directly with the transport next slide but I'm gonna I'm gonna I'm gonna offer that the real value of quick was something else next so quick I've I've told you that the quick makes the web faster more resilient more responsive but this is just the beginning next slide quick enables these Technologies I talked about so it all it becomes a platform for these new technologies moq mock mask other stuff that we want to deploy next and I've also told you that quick is a transport technology that can be evolved on the internet because we managed to encrypt everything we can evolve this thing going forward it is already continuously evolving in multiple versions of quick already exist in parallel on the internet today and next slide I'm going to offer that we've pulled a sleight of hand we basically convinced everybody that these are the reasons we wanted to deploy this thing HTTP was the reason and uh getting these these milliseconds of latency Improvement and these features were the reasons but next we used HTTP on the web as a vehicle to"
  },
  {
    "startTime": "00:26:00",
    "text": "deploy quick into almost serve all server and client deployments the quickest deployed now widely it also it it almost every server deployment has quick in it almost every client browser and other client libraries they all have quick in them now next but our goal really was to create an end-to-end transport that allowed for end-to-end transports and Technologies to thrive through an ossified internet and I would say that we've we are sort of somewhere not at the beginning of this journey we managed to get somewhere hopefully we'll get to the end of the journey but we are certainly much farther along than I thought we would get to so thank you thank you thank you very much Jonah next up we have Martin who will be showing us some header diagrams I think yes now I had a diagrams all right so Dex coming all right so I'm going to talk a little bit about the quick handshake and in particular some of the security properties uh security being one of the sort of primary drivers behind building this thing do you have a clicker yes but it doesn't work it doesn't work all right well next slide quicker is to say next slide and yeah should I catch your cues so there's a couple of things in here I may not get to uh some of the later things in any real detail uh but uh that layering diagram that uh Jonah was talking about I think we'll spend a little bit of time on that uh quite possibly the most difficult part of getting quick working was integrating the the TLs handshake into quick there is a something of a tight interaction between those those two pieces and it turned out to be extraordinarily fiddly and uh we were"
  },
  {
    "startTime": "00:28:01",
    "text": "given a protocol um from the work that the folks at Google who had designed their own cryptographic handshake and it was broken in tiny subtle and very significant ways that required years of work to get to work so next slide please so you've seen uh what is I think the the standard reference point for how we think about layering in quick uh there's this little TLS slice that sort of jammed in on the quick layer and this is something that I think makes people who like the nice layer cakes a little uncomfortable and we'll explain why that's the case as we get through this one next slide please so um at a very high level quick connection setup does everything that TCP does and everything that TLS does all sort of integrated together and we did that for a number of reasons I think the the primary one being performance so um what we wanted to do was avoid replicating a lot of the security work it turns out they're building a good security handshake is extraordinarily difficult and tls13 is the result of a number of years of work and we didn't want to have to redo all of that work because we're also building all of the TCP bits in tiling on top of UDP which is an entirely new protocol and that's more than enough work and it turned out to be even more work than we anticipated when we we came into this so the way to think of this is that TLS provides all of the cryptographic assurances that you might expect from a protocol uh and quick provides all the things that that TCP would provide being reliable audit delivery and in turn they each provide services to the other TLS requires ordered reliable delivery"
  },
  {
    "startTime": "00:30:01",
    "text": "quick requires a secure a handshake next please so we're taking the core TLS guarantees authentication confidentiality integrity and all of the core TCP guarantees at the handshake level now um other people can talk about streams and and the various application semantics that we're providing quick which include some of the core TCP guarantees like in order reliable delivery but um for the handshake there's a lot of the things around the TCP handshake that I think weren't in the original versions of TCP But ultimately TCP needed to have which are things like being assured that the other side you're talking to is willing to talk to you for instance and that turns out to be an extraordinarily important part of the design of quick and we'll talk about that look as much as we can the other thing is we were looking to do better than any of these protocols we have a new protocol that we we're implementing here we took every opportunity we could to make things better and I'll touch on a few of those points as we go through next please so uh rtts uh TLS 1.3 is optimistic in the sense that a client will guess what configuration will work for a server and that will in the case that the guess is correct save a round trip time quick does the same thing a typical handshake in TLS is a sort of three-way exchange you you have the client send a message the server respond and then the client finishes that off with a confirmation message if the client guesses wrong you have another round trip added to that and one of the sort of themes that we'll have with quick is that it has a very short handshake if everything goes correctly but it turns out that you can add multiple round trips if you have packet loss the client guess is wrong"
  },
  {
    "startTime": "00:32:01",
    "text": "the server is under duress and wants to tell the client to back off and and wait a little long while longer and so we have this very flexible handshake ultimately the um key Insight is we we have sort of this this multiple round-trip handshake and and a lot I say here that typical energy is 1.5 rtt in practice I think the messages we exchange is two round trip times but under normal circumstances if the client guesses correctly and the server is willing to communicate with the client we can send data from either side after that first exchange between the client server we're actually sending before the handshake is complete and in the extreme case if the client has been to that server in the past and set up the zero round trip time thing that there is no delay for either end the client sends immediately application data is Flowing immediately as the handshake is commenced same on the server end as soon as the clock as the server sees the client's first message it can start sending things to the client as well and these performance guarantees were sort of central to the appeal of of quick and and they're the core of the performance guarantees that we're providing here next so this is what the TLs handshake looks like we have some care agreement and configuration that is exchanged more or less in the clear and then some authentication information and you can sort of see here we've got these lighter lines that say where where the data is being exchanged there's a flow from the client there might be some some application data following after that one there's a flow from the server there might be some application data and then finally at the end some more messages lots lots more data at that point next please that's what happens when you put TLS on top of it and um there's a little note there saying that we we had to tweak TLS in order to get this to work and that's going to be"
  },
  {
    "startTime": "00:34:00",
    "text": "a bit of a theme as we get into this one next so um the the quick handshake sort of takes the TLs handshake and builds on top of that tell us messages have essentially uh four types of keys that that are used um and um the no key in the case of uh TLS is turned into a real set of keys in quick so we have what we call Initial Keys which are not secure in any meaningful sense but they provide us protection against ossification to to the points that Jonah was talking about before every single version of quick uses a different set of keys if you don't know the keys you can't speak that version a quick sort of a a nice little protection against someone who might be inclined to interfere with the handshake um but if they don't know the version of quick that's been being spoken they don't get to to interact TLS also provides handshake keys those handshake Keys uh protect the the details of the handshake uh the security guarantees there are very very interesting um those of you who know TLS will perhaps have a better idea of what those properties are but essentially we're providing confidentiality for things like the server certificate and a lot of the configuration parameters that the the protocol has the TLs bytes put into specific frames within the packets so we have packets with frames in them the packets are protected with these keys and we we put multiple packets in the one UDP datagram as it turns out and uh quick after many iterations between first going with something that was based on dtls because why not dtls does UDP turns out to be a bad idea we went to TLS"
  },
  {
    "startTime": "00:36:02",
    "text": "and tell us exporters for for getting Keys ultimately what quick does is runs the TLs handshake and then when TLS produces Keys quick reaches in takes those keys out and uses it for packet protection TLS doesn't uh TLS record protection isn't engaged in in this the raw bytes coming out of the handshake of TLs are used directly by quick so the final two types of keys we have are zero watt CT Keys which the client uses to send to the server if it happens to be attempting zero ITT and then the final application data Keys which are used for everything once the handshake is completed we also have a key update process that that rotates those keys periodically to prevent to prevent them from wearing out next place so this is what the simplified handshake looks like we have the client sending an initial packet which contains a crypto frame which contains a TLS client hello and on the server end we have an initial packet and that contains a crypto frame that contains a server hello and that is all effectively sent in the clear although we're using these special quick version specific keys that are generated the um the interesting thing to observe here is that there is a flow that goes from the client to the server and Back Again in the clear and then in the opposite direction for handshake Keys there's a flow that goes from the server to the client and Back Again using those handshake keys and then finally there is application data flowing from that point onwards now this is a quirk of TLs but um what you will actually see here is the there's a final message that confirms the handshake is done at the bottom there that the server sends once it's received everything from the client and"
  },
  {
    "startTime": "00:38:00",
    "text": "we spent years trying to avoid putting this message in it turns out to be absolutely crucial in a number of scenarios we had the worst problem with handshake Deadlocks and all sorts of weird Corner cases before we decided look let's just put another message in here what this means is ultimately this is a two round trip protocol you can see two round trips on this on this diagram here but you're sending data a lot sooner than that and that's one of the weird things about operating this protocol next please of course all of this integrates with quick and so quick underneath all of this is providing acknowledgments for all of the data that's being exchanged back and forth here and so that's what you see here is that every single message that is sent is acknowledged using packets protected by the same types of keys for various reasons that should be obvious you can't acknowledge something with a different key because well maybe the other side doesn't have that key yet and so there's this weird interlocking thing that that goes on here um including some implicit acknowledgments in the in in certain cases which gets a little bit interesting as well but um this is to sort of illustrate that that quick is providing all of the transport reliability features that uh TLS requires TLS sends very large messages that need to be sent and received in a very particular order otherwise it just doesn't work and provides those those facilities next please so this is ultimately what we have in terms of the layering diagram and I think um thinking about layering in the classic sense where you have a protocol that sits on top of another protocol doesn't really work for quick the uh the key thing to realize here is it's more like a software architecture"
  },
  {
    "startTime": "00:40:00",
    "text": "diagram where there are certain components that provide different capabilities and they have interactions with other components if you think of the TLs stack as taking handshake messages and returning handshake messages and then providing information about State changes and the the various secrets that it might be generating then you have the ability to to build a component that then sits inside the grader protocol and so you have crypto streams responsible for exchanging those handshake bytes back and forth and then you have a packet protection layer that takes uh the the packets that you're sending to the to the other side and takes the secrets from TLS and uh protects those packets or removes protection from those packets and then of course all of the things that we concretely care about uh in terms of streams and ultimately uh the quick datagram work as well is is sort of sitting in there providing more frames that that can be exchanged back and forth so this is this is what I tend to think of as the the the ideal uh the structure of quick on the on the inside and uh it's not that simple but uh this is a gross simplification of that next place so the other part of all of this is actually mostly new in the protocol we've taken inspiration from from protocols that proceeded at TCP and and other things but um the denial of service mitigations in quick as part of the handshake and later uh somewhat more interesting than the software engineering exercise of getting a quick TLS stack crammed in so we have a few basic rules um we had a long debate a little while"
  },
  {
    "startTime": "00:42:01",
    "text": "ago about where this number three came from uh and no one knows uh concretely we had a number of people involved in the design of this and none of them can remember where the number three comes from but there's there's this basic rule that we follow in quick is if you're sending to an address that you haven't confirmed is willing to receive the packets that you're sending only send three times as much data to that as what you've received from that apparent address so your random packet appears from the internet from some arbitrary address you can send three packets in response no more there's an address validation process that we use to say send to that address and get confirmation that that address is live and willing to receive the packets that you're sending to it and we have multiple types of address validation in quick because of the way that we design the handshake and ultimately I'll touch on this later migration and um really what we want to do here is ensure that quick is not used as a platform for denial or service tax against on unwitting and unwilling victims on the internet it turns out that we don't want to be memcache and uh that's probably not such a pretty important ultimately uh for making sure that everything works properly next place so the the basic uh handshake amplification attack is that a client sends an initial packet that happens to have zero rtt in the same datagram you can put a request in the same packet as your your initial thing that might be a totally valid packet that uh a server would accept under normal circumstances it might be very happy to accept that"
  },
  {
    "startTime": "00:44:01",
    "text": "packet from the client but if the client manages to spoof the address the return flow from the server which contains all the quick handshake information and potentially the answer to the question that they asked could be very large and the poor victim who genuinely owns that address might find themselves on the receiving end of a large flight of packets from a very well connected server we don't want this to happen so next slide please so TCP solved this I think a long time ago I don't know when that was but it was before I was involved in any of this and it has a three-way handshake uh of course when we're doing TLS and TCP this adds an extra round trip to the setup uh which is a little Annoying that's slows things down a little bit but essentially uh TCP confirms his willingness to communicate before you start doing any of the TLA stuff uh but in quick we put this all together so we're doing the cryptographic handshake and this confirmation to communicate all at once and of course um not every quick server is willing to participate in all of this extra work before confirming that someone on the other end is actually willing to talk to them so we added a retry mechanism which is very much like the TCP send synac um with the cookies the same cookies next please this looks approximately this like this the client sends a packet maybe some extra packets and the server says hey uh no uh please confirm before proceeding and it sends the client a token and if the clients are genuine type client it will receive that token and can stick it in the packet that it generates for the next attempt and everything moves moves on from there and the server has now received confirmation that the client is able to receive the messages that the"
  },
  {
    "startTime": "00:46:00",
    "text": "server is sending and the client is willing to participate in the protocol that's nice next place retry of course is probably not something that you want to do because you're adding a round trip time to the connection setup it is particularly good for cases where the server is under stress and they want to make sure that every client is genuine if they're under attack then then it might be might be a good way to manage that or if you think that the traffic is coming from somewhere that is unreliable for various reasons the reputation systems that you have indicate that it may be a little a little shonky uh but that round trip is expensive so we have some tricks for the case that uh the handshake is is um shorter next please so what we need to do is prove to the server that the client saw this over initial packet how do we do that um it's very simple the first exchange that happens in the clear uh between the client and server establishes some cryptographic cryptographic keys and it does that based on information in those packets the next set of packets from the client these handshake packets use those cryptographic keys to generate new uh packet protection keys if the client produces a valid handshake packet that is because it saw everything that the server produced and so we we have what what amounts to an implicit token at that point and um until this point the um the the three and three out for for one in rule applies but um next slide we'll show you um the same thing that you saw before but as the initial um from the server reaches the client the client generates some new cryptographic keys to protect the handshake packets that handshake packet is proof that the client saw the server"
  },
  {
    "startTime": "00:48:01",
    "text": "keys and so that allows us to proceed by layering in the address validation process without paying any extra bytes at all I hope that's that's clear but that's uh a trick that we apply in a couple of other places next place um oh but of course um that that goes both ways the server needs to prove that it saw the client initial as well so server needs to the client needs to confirm that the server is willing to talk to it and uh at this point we have a little trick the key these initial keys that I told you have a version specific thing are actually derived based on what we use uh what we call a connection ID and that connection ID is an unguessable value from the client and so when the server responds using that connection ID or using keys derived from that connection ID then the client can confirm that the server is willing to talk to it so not only does This Server proven that it understands the version of quick that's being involved it's also proving that it's willing to talk to the client by responding to it in this way and that retry thing that we talked talked about before we need to have the same sort of mechanism there that has a different mechanism for for managing that that same process but there's an Integrity check in there as well next so that's the implicit token that we have on the server side next okay yeah so uh all of this is somewhat fiddly to get right uh there were a lot of Deadlocks that we discovered in the process I think we spent what the better part of two years going back and forth over some of the the more tricky ones uh certain people had a very good habit of finding new ones every time we thought we fixed them [Music] um"
  },
  {
    "startTime": "00:50:00",
    "text": "one thing that is still a little point of like discomfort for some of us is that we don't really have any formal verification to support the correctness of the of the handshake um we've spoken to academics about this one and and there are systems out there that might might be able to prove these sorts of things but it's it's rather challenging um and I didn't even talk about version negotiation uh which adds even more complexity but I won't talk about that here because uh we don't have the time next please uh brief on migration the migration process follows the same three out for everyone in rule um we have migration for a number of reasons probably the most interesting one is a client that is sitting behind a Nat and they get given an address and they happily talk to us over back and forth and then they go quiet for a little while because well they just don't have anything to say at that point and when they restart the communication after that brief period the NAT has decided that it's going to give it a different IP address on that flow and so what the services is a message from the client that has a new IP address that is completely unvalidated and that could be maybe an attack and so if it were to continue sending large amounts of data to that new address bad things might happen because that might be spoofed of course in a lot of cases most cases in fact it's just the Nats doing what Nats do next please so we want to deal with net binding changes we want to allow connections to move to New Paths even legitimately but we also want to ensure that the an attacker can't force someone to move if they don't want to move"
  },
  {
    "startTime": "00:52:01",
    "text": "we also want to ensure that an attacker can't stop someone from moving if they want to move and um unfortunately if you if if we were to show you a an IP and UDP uh packet header they're not protected and the network rewrites them all the time in fact to some extent we kind of rely on the network being able to rewrite these things maybe that was a bad idea but that's the network that we have and so um we're in this kind of really awkward situation so next slide please there we go so migration looks like this you have an established connection between client and server and maybe an attacker takes one of your packets maybe it's a packet that you had dropped and sends it from a new address the server looks at this packet and says hmm I'm not sure about this one this might be legitimate I don't know and so what it does is probes that address saying here's a token prove to me that you're live on this address but it also and this took a long time to realize it also sends a probe to the old address and says prove to me that you're at this address the client just responds to these probes as it sees them if it's legitimately moving to the new address then it will respond from the new address and proceed if it's still on the old address and the attacker decided that it wanted to force the client to migrate to A New Path then the attacker should be unable to produce the uh the correct response and um whichever one wins whichever one's legitimate will produce a response that the server will then respect and uh migration will"
  },
  {
    "startTime": "00:54:02",
    "text": "proceed next please so in order to get this to work we didn't want to solve the problem that uh ice solves so only clients can migrate at this at in this version of quick anyway servers can ask clients to migrate but only once we have this thing that happens during the handshake that allows it to happen but clients are the ones that initiate the process um migration is very simple um at some levels you simply detect that an address has changed on the other end and you start sending data to that address but you only Follow You Follow the three times rule until you've managed to validate that and the validation process was on the previous slide next please and I think we're up uh so having this very simple three times anti-amplification rule applies to all addresses uh it's uh pretty straightforward to plot to apply uh you need to validate all paths before you speak on them uh and uh simplifying to the client only means that we uh don't end up with complications in the protocol State machine where both sides decide to migrate at the same time which doesn't really work very well um and then that leads into a whole set of other design problems where we use connection IDs on different paths but I haven't spoken about connection IDs and probably shouldn't because I don't have time next so that's only sort of a taste of all the security relevant things uh we could probably spend another couple of hours talking about how packets are protected uh how the packet header is protected which was an interesting story there uh key rotation uh is a part of that we also provide a an equivalent to a TCP reset"
  },
  {
    "startTime": "00:56:00",
    "text": "which we call a stateless reset that allows a server that that loses state to clear up any connections that might be hanging around from from before when it lost that state that is secure so TCP resets cannot be injected by the network we also have a whole version negotiation thing that is nearing publication that requires a whole lot of interesting discussions as well but not enough time to cover all those things here today and that's me done thank you thank you very much so I think my favorite thing that I learned today after you know having scared it quick for most of its development is that nobody knows where that 3x rule came from because I dug into it a little bit too that was that was Ian Ian did it thank you Ian if two isn't big enough two's not big enough right there's too many and four is too many well no well four might be okay but great honestly no one really knows uh I it was pulled out of the air I think yeah that's right all right so Ian knows talk to him talk to Ian Ian we'll talk about that tomorrow is to wear that three three yeah oh yeah that makes a lot of sense cool so um thank you all very much for being with us um so early this morning uh thanks especially to our speakers um excellent excellent excellent presentations uh we hope to see all of you and more tomorrow morning at 7 30 uh not at 8 we have a little bit of extra time for the panel discussion and we ran early as opposed to running late on that one um so yes thank you all very much and enjoy your iedf [Applause]"
  },
  {
    "startTime": "00:58:00",
    "text": "Ryan I think it's actually then I'll count to three then they'll count to three no more no less three shall be the number that thou count hello to rename it to what foreign"
  }
]
