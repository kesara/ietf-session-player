[
  {
    "startTime": "00:00:09",
    "text": "thank you thank you foreign okay welcome everyone to the Privacy enhancement and assessments research group to our hf-115 meeting as always there is the note Bell which I'm sure you're familiar with by now and we want to make everybody aware that the session is being recorded and we also just want to note that the code of conduct that applies to the ietf also holds in these meetings as well a few extra notes for um in person attendees you are required to have your mask on at all times in the room apart from when you're actively speaking"
  },
  {
    "startTime": "00:02:00",
    "text": "for in-person attendees can you also sign in through the meet Echo light client because that replaces the blue sheets and uh in following what other groups have been doing we'll be using a single queue in meter Echo including for people in the room so if you have a question please add yourself into that queue via the tool rather than going directly to the mic we have a very slightly modified agenda from the one that was published uh on the data tracker um due to slight uncertainty of one of the authors being able to attend for the draft updates we will be going through those updates at the start of the meeting and then moving on to the remote presentations um I believe we have a minute taker so thank you go Shabad for that um before we get going is there anything anybody would like to add or change about the agenda foreign no if not then we will start by just running over a quick update of the drafts that we have going through the research group at the moment thanks yep um it's a review of drafts that have progressed from the research group we have a pair of drafts on the history and the generation of transient numeric identifiers we believe they are in the final throws of review and we're hopeful we're One update away from getting those published which will be very nice they'll be the first documents to come out of the research group we also have the survey of worldwide censorship techniques which passed its um last call a couple of months ago and has now been sent on to the Irish irtf chair for further review and we currently have two columns chair apologizes for being slow at reviewing"
  },
  {
    "startTime": "00:04:00",
    "text": "that and hoping to get to it soon lovely okay thank you yes I'm hands up from Mallory yay thank you um in terms of documents that are being actively worked on we have two at the moment we have the guidelines for performing safe measurement on the internet that had a fairly recent update in I believe August of this year thank you Mallory for that and we think that's in relatively good shape um we would love some more review of it but we think we could consider moving that forward um in hopefully not too distant future uh the other draft that is actively being worked on at the moment is one on IP address privacy consideration this is a document that came out of the interim we had on this topic year before last um we have several authors contributing to this at the moment and I'm hoping that uh Brad is available to give us a word or two on the status of that foreign of the draft uh last week and uh we think we have some good content there um although uh it is in uh bad need of uh solid editorial pass uh to make sure it is uh helpful for current topics that folks are looking to use the draft for um so uh really looking for folks to take a review uh let us know what uh applications of the draft that uh would be where that could be helpful and we'll be working on that editorial pass between now and 116. thank you and thank you for stepping in at the last minute to update us on that as well Mallory I saw you sneak into the queue"
  },
  {
    "startTime": "00:06:00",
    "text": "and missed you if you want to go ahead hi Mallory noodle CDT um I just wanted to update really quick on the safe measurement because I appreciate your um faith that this document is good but there are actually some important parts of it that are Unwritten um or in my view aren't aren't elaborated enough so if there are folks who work on this um I could also with maybe encouragement from you all send messages to folks in like PPM or elsewhere that might have some overlap here just to um get I think better text in those places that would be much appreciated so you can reach out to me directly or you can go on the list um and then the other update on that draft is just that at the IAB workshop on um measurement in encrypted networks um I I talked about this draft a bit so others have seen it and it was sort of in the context of like it doesn't exactly speak to that that workshop's mission or or um um statement but I thought that what was in that draft isn't really anywhere else in terms of how you kind of do harm reduction holistically rather than just worrying about you know what um what specifically you're you're sending or what you're measuring I guess of what sense so that was well received in the sense that folks found it useful and um so I wanted to feed that back to the group as well thanks thank you very much and as always we're looking for new work so please get in touch or write the list if you think you have other items the group would be interested in working on okay okay there's slides I've stopped moving there we go okay so I think we are now ready"
  },
  {
    "startTime": "00:08:00",
    "text": "to move on to the presentations um if the thank you I can do that and so the first presentation today is by David Oliver it's on clean insights and we have a 20 minute timer on this including time for questions okay let's just Wrangle your slides thank you are we all seeing that yep yep please go ahead okay very good well I'd like to thank the chairs for asking me to uh for inviting me to present and so here we go we um I put a tldr in the front here because uh some folks uh in in the room may be very familiar with privacy preserving measurement especially the activities at ietf or from other areas and there's going to be some folks see this presentation outside the room so I thought I'd add that here but we can move right along to our origin story for clean insights um which is that we started in 2017 with a hackathon project at the Harvard Berkeley Klein Center in association with with MIT now it's hard to remember this at this point but the the European Union's gdpr had been adopted but was not yet enforced at this time so we didn't have a lot of insight into how that was going to roll out and there was interest um across a set of communities who were involved in civil society and internet freedom and human rights in what was going on with measurement and how measurement intersected positively or negatively with with um privacy and human rights Etc so I think you'll notice the date down to the next item where uh internews uh nonprofit who funded our work later on clean insights you'll notice there's a long time in there and I think that's largely because it was a a period of"
  },
  {
    "startTime": "00:10:00",
    "text": "waiting to sort out what was going on with these higher level uh privacy sort of activities and around the 2000 time frame both the funders for human rights projects and the developers of those projects were sort of stumbling over how to address the problems that they were finding um so I think we started to ask a bunch by asking a bunch of questions earlier that then became even more present later how can funders understand the impact of the ideas they fund without putting their users at risk how can companies strike the right balance between preserving privacy and driving their development towards making it meet users needs better um you know is it really possible to do measurement of digital interactions in a safe and sustainable way especially in the communities that we were interested in and can the sort of privacy precepts be upheld for even small projects so in 2020 mid-2020 there was a symposium held uh interviews in ourselves and several other parties hosted developers who were in the open open source human rights type communities to look at and try to understand their problems that they were trying to deal with the demands of their funders versus their deep interest in their in their communities and I think these sort of key points came out of that these are this and I like I should point out earlier that this is kind of a different you know a vector of Interest into internet into measurement than other vectors might might be so you know understanding the patterns of behavior um in a way that doesn't alienate users seeking up a platform for measurement but one that doesn't harm in individuals the there's an idea here that no measurement isn't an option um every we we need even the smallest"
  },
  {
    "startTime": "00:12:03",
    "text": "projects need to understand their impact or problems with their software so it isn't an option and a challenge is if there isn't a safe alternative then invasive options are easy to implement and we're gonna we're gonna conundrum about personal safety um the the thought process back then also was that if we could increment forward on this that would be better than waiting a long time for a large Improvement so um uh the outcome of of that really is on on trying to bring measurement in line with respect for the user and the idea was to focus on the right questions and answering just on and getting just enough data to answer those questions we looked at um aggregating on the source the populations that we're interested are very very largely on on mobile devices that was certainly a consideration um and that we wanted to have something in the path between generator and collector of information that would that would discard this needlessly toxic um personal personally identifying information also we wanted to make the idea of measurement a legible or transparent is probably the wrong wrong word at this point but uh but in part of a usage experience that would engage the user rather than alienate the user and we looked at techniques for generalizing data d d resolution what's the right word for reducing identifiability I'd like to point out here that also that that the ideas like differential privacy were um were were quite solid in the in in the literature starting really in 2006 but it wasn't until the 2015s and those kind of dates when it really became sort of at the Forefront to bring into this kind of measurement so these kind of ideas are still pretty new at the point we started so we started early we had a very basic"
  },
  {
    "startTime": "00:14:00",
    "text": "piece of technology that worked Back in 1970 uh eight sorry 2017 and you know since then we've we've broadened it a reasonable amount um there are sdks for for both client and and server available and um there's an anonymizing proxy that sits between uh the initial platform we worked with called matomo which can be generalized to be used with other analytics packages um and maybe as importantly uh we started looking at doing user research to Define experiences that made measurement uh collaborative collaborative sort of experience and more more obvious for the user and started on implementations uh this diagram here is meant to show uh the the kinds of implementations of clean insights that are possible the one that's used in the dominant form today is the direct connection where where devices running in operative an operative application for their analytics can connect directly to a proxy that then connects to the analytics engine but there are also Imagine scenarios necessary for us where different kinds of uh front proxies get involved to to assist the user where there is either censorship uh surveillance or additional privacy needs requirement needs necessary domain fronting is it can be used here is a very specific term and then alt is a way to think of other kinds of fronts where maybe Tor is one of those and there are some other tools being discussed at ietf that can be used in this way uh so when it comes to the actual technology we Implement I'd like to first point back to that idea that we're feeling our we were feeling our way initially here and and we're moving uh from com you know no answer towards some answer and iterating along the way so what we wanted to start with was a way"
  },
  {
    "startTime": "00:16:01",
    "text": "to do what it was the general feeling of normal analytics that is counting um cross tab on some on some relatively General metrics doing crash reports and doing surveys and we felt that if if the clean Insight solution didn't provide a solution to those basic things that people would demand or people would use other existing side channels problematic side channels to get what they needed so we wanted enough a bare minimum of of of um capability uh without having but not solving the whole problem right away in terms of improving anonymity we looked at um at batching reports from the client to the to the server and that has a number of effects positive on on usage of networks in areas that are have very deep network problems whether they're generated by authorities or just problematic networks and it also hides time stamps of measured activities we looked at ways to generalize and deres information on the client talk about that domain fronting I mentioned earlier and we did recognize that ethos at the scales that we're talking about the number of users of applications Etc um uh that that there was a tension between respecting consent and privacy and padding the anonymity set so that's a sort of detailed part of this but it was an early criteria about remembering that we have to we have to deal with small scale projects another thing we looked at was really borrowing from law and maybe this is kind of rethinking again from the perspective of the user things about the way measurement has been done canonically and the way we thought our"
  },
  {
    "startTime": "00:18:00",
    "text": "our clientele our community wanted to um to work on this so the first is the idea of time-bound contracts that that um you know the notion that things you're bound to something that lasts forever that's a challenge so we introduced the idea of campaigns which were ways to put a Time binding on when measurements were going to be made the second was consideration and this one ties a little bit to the bottom one which is called contracts of adhesion the idea that people feel that they must opt in because there's no alternative there's disparate power between the measuring entity and those measured and and we wanted and there was often at that point in time issues with refusing consent meant you're just deprived of the service complete lately so we wanted to try to address these sorts of things in in the way we did our work when we created a toolkit and a set of best practices for Developers so I think the the main the main thing that we have focused on early because it is part of the user experience as well as the technology is this idea of consent understanding who's going to use your app what the app is what they're going to use it for and in what situations we have a number of situations around the globe that put really a fine point on user situations and and and the difficulty and challenges people have using the internet especially the communities that we serve and the challenges that we get into when we're creating Network traffic based on simply trying to measure so we need to start as we said earlier start considering about specific questions narrowing the time that we Implement that we measure handling the data carefully and getting rid of it once it's once it's reached its destination and insight has been gained working with developers at that Symposium we've we started developing sort of design patterns around how consent can be handled and um as well as the information needs that developers and funders have um we arrived at sort of principles"
  },
  {
    "startTime": "00:20:01",
    "text": "around consent and this is sort of the user experience of of consent um about making it easy to understand what you're agreeing to that that thing you're agreeing to is is pretty obvious and there aren't hidden messages in there and that that saying yes or no doesn't mean giving up use of the application and that the way we we deliver consent is concentric array is sort of centric around those who need it so giving asking for it in the right way using it in the right way Etc um here are a couple example models this is the umbrella app and here's an example where this app needs to look at patterns of usage so it is in fact going to measure different things and connections between things so it wants to make that obvious that that's going to be what you're consenting to and then that you're going to contribute for a short period of time here 14 days is the is the measurement period on the next page we have another example which is um uh talking about um you know collecting metrics making it feel like a like a focus group um and again this is where only a portion of the user base is actually requested gets gets this request and again A Time bound but a different way to present the idea of consent to measurement um we we of course knew that the number of studies we were we did undertake the number of groups we worked with weren't going to span the uh span the field for what consent models might look like so we came up with sort of guidelines and best practices for for rolling your own con consent and it I would hope that some of these things feel awfully logical and and uh right thinking I guess you could say but in fact the ways that these interact with the different kinds of things that applications do and the kinds of users using applications quite a bit of thought is uh is required here"
  },
  {
    "startTime": "00:22:04",
    "text": "um uh we have done a number of implementations but we also went back and looked at and worked with the teams to look at how did our work work out for you so we actually have impact reports on uh on on some on some subset of the applications we implemented um clean insights for and these are these are the apps here you'll notice that they are uh privacy and security related again that relates to our user base uh we're we're uh sort of going around the world kind of in a lightweight way promoting this idea again we since the Guardian Project is fortunate to um have a number of software libraries that people that we've developed that people use of ours we have a way to we're talking to a lot of uh development uh teams in the in the uh in the uh internet Freedom space so so we do a little bit drive on these messages related to how to implement um uh smooth and en metrics that people can understand and want to be part of um and and I think we have started at the small scale working small creating a new idea thinking about metrics in in a new way and that's I think the key insight for clean insights is that area now on this uh last slide here I'd like to talk a little bit about without go getting into a lot of detail about the commonalities and and differences between uh clean insights which is again a fairly you know now or five-year-old project um and what's going on in in privacy preserving measurement at the ietf today um our Affinity is that we did identify that proxying was going to be necessary to protect the identity of of the user so um we have in our proxy modestly"
  },
  {
    "startTime": "00:24:00",
    "text": "different functionality that that exists um in in the work going on now or tremendously different in that ours is quite lightweight and we are we have a client server balance between who is implementing privacy um we also like this idea of starting with the questions in the in the decisions rather than just dumping uh all the data in raw format onto the onto some server entity so this idea that there's a collection phase that is happens and in an analysis phase that happens before well eyes are on it and then the idea of sort of neutralizing the toxicity and data sets that are at rest once they do get to the server importantly I think what we sacrifice is is that we are placing uh some trust in both the collector and on the implementers in terms of knowing what's toxic being careful about what's toxic and and that there's a best practices way to think about that rather than a structured uh protocol or tool set that that implements those things in a hard and fast Manner and lastly you know we do our we do continue to be concerned about the one-time visit the one-time use those kinds of problems that occur that really are problematic in in our area uh uh okay lastly I I've just put up some um some uh um links here that you can look at I think the consent guide is a really interesting thing to learn it's one way to view clean and clean insights is that in fact because Santa consent is the key piece so um and we also have uh the code out there and the impact reports if you'd like to look at those uh we're at the Guardian Project and uh we really appreciate our friends over at matomo uh also looking at this problem from from a server and analytics package standpoint so I'd be really happy to take your questions at this point"
  },
  {
    "startTime": "00:26:01",
    "text": "thank you David um are there any questions and thank you for inventing a new word in the middle of your presentation we have D resolutionizing to add to the dictionary now you know I also thought that consentful might be plagued out as a uh as a new word too but recently I've seen that elsewhere so I guess we uh we didn't make that one up uh Stephen please go ahead yep hi David Stephen Farrell um yeah thanks for that that's the interesting stuff I was just wondering what how do you kind of treat something analogous to the kind of right to be forgotten or when people change their minds about consent or is that something that you've looked at as part of this project so I'm I'm gonna I think my straight answer would be we haven't thought about that but the other answer which I think is maybe more in line or a way to figure out uh or a way for that gives us a tool is the idea of the campaign um and we we do talk about opt out and being respectful of people who don't want to be part of of a campaign and making it obvious uh um that you're asking that and then and allowing them to say no without you know decrementing the function of the application totally if they do say no so I I don't think we have a um but right to be forgotten like as if I said yes once but now I'm not saying yes um I'll take that back as a to-do that's a great Point Stephen okay thanks yeah uh Jonathan hoylan cloudflare yeah um given that realistically most consent quote unquote we get these days is actually just uh you know that if you click I do not consent it's going to be at least 400 clicks before you can see the website um we shouldn't wouldn't it be better to say actually let's push for the to reject all tracking must be at"
  },
  {
    "startTime": "00:28:01",
    "text": "least one fewer clicks than accepting and you know then you'd find all these websites where I'd like reject tools the big red button like yeah everyone wants that and oh yeah if I really like this website and I want them to track me then somebody could in theory do 400 clicks to say yeah really really trap me I'll be up for that I uh I'm smiling about that that's a that's a great point I think this idea of you know we have some on the in the sort of group that that represents this who we think that that consent has been diluted so badly by the current regime that it's impossible basically that for the reasons that sort of Steven mentioned for the reason that um of the contract of adhesion I idea that the gdpr was initially our friend and now might have been our enemy you know there there's a lot of a lot of issues with with the fact that um the the level of forcing you to give consent is is can be either hardcore or subtle but eventually um so so I I don't think we know how to answer that question at the at a macro level what we've tried to do is sort of put tools in place that allow people who and and by the way we in in the Mobile area looking awful lot at small scale applications um you know we we have an app out of Guardian Project called Orbot you know several million users but most everything else is is below that and the people who um are interested in that are also in a subset so this is not an internet scale thing and and we're looking at ways again starting small to figure out how to to try to make consent be real again I'm afraid I don't have a good overall answer for you Jonathan on that all right thank you yeah hi Conrad cobrook um are there any plans to reduce the Trust on The Collector using cryptography I understand there are a couple of projects that are working on"
  },
  {
    "startTime": "00:30:01",
    "text": "protocols uh that try to do that is there anything on the agenda for um for your project I would say not yet but part of the reason I I did attend yesterday's presentation on privacy preserving measurement and had been interested in it since the it's come up here is that we do have a number of alternatives for increasing um uh uh the privacy of what we're doing via VIA encryption for sure so um uh the the oblivious HTTP aspect is one thing um but there there are also a number of of items possible um by implementing more um uh you know algorithmic privacy measures on the client as well as on the intermediary um the so the proxy the clean insights proxy so yeah I but I can't I'm not willing to speak I don't think I can adequately speak to things directly on on the item or on the list um we're just mapping and looking at and making sure our the architecture can can fit those things as they come along differential privacy ideas were thought of early and we have sort of in-spirit versions of that now done on the uh as part of the toolkit in the client but you know there is DP is uh has a very specific meaning and so I'm I hesitate to use that term um in a generic way I think that's a specific thing that we don't have implemented yet okay thank you okay thank you David for the presentation and thanks for all questions uh move on to the next presentation now Sophia could you uh please try and show your slides yes I think I requested okay okay they are up a little okay uh hi everybody my name is Sofia"
  },
  {
    "startTime": "00:32:02",
    "text": "selly and I'm joined today with Daniel Jones um and today we're going to be talking about uh paper we publish some weeks ago about finding certain practically exploitable cryptographic vulnerabilities in Matrix you can find the paper online and this is a joint work with Martin algorithm Benjamin Dowling so first a little bit of context um we started looking at Matrix because we wanted uh to actually do a formal analysis and a formal model of Matrix and in the process of looking at the specification and implementation we found several practical vulnerabilities which turned into this paper but just to give a little bit of context into the people in the room that don't know about it a matrix is a standard for security centralized real-time messaging and basically aims to do what sntp has been doing for email um one of the biggest thing to think about in Matrix is that it aims to do secure communication in the face of untrusted service which they call the Home Server in a Federated way and it's very important to think about this untrusted server because this will be our thread model when looking at all of these attacks and as I said Matrix uses on trusted server and because these servers are untrusted they also allow end-to-end encryption by default on their channels um because they are in the face of untrusted service one of the flagships clients of Matrix which people are most often familiar which is the element client which is the people how they actually approach into Matrix through the element client but the protocol itself is called Matrix and has been implemented in other applications and clients besides the element one so why should we care where should we care about these vulnerabilities and in general about doing a formal analysis of this protocol is because Matrix and its Flagship client which is element is widely used the website of element for example reports that they have over 60"
  },
  {
    "startTime": "00:34:01",
    "text": "million users and the French and the German government are currently using for internal Communications and other Communications and also Mozilla and kdae um in 2019 announced plans to actually use it so it's a widely used protocol uh as I said this is a secure messenger which means that they have certain or claim to try to have certain uh end-to-end encryption properties such as confidentiality and equity and authentication and they also claim to provide certain certain form of forward secrecy which I think they call partial forward secrecy post compromise security and a form of vulnerability in our research we didn't look at these last three properties but rather we just focused onto the core properties of confidentiality integrity and authentication so it remains as future work that we are doing into actually looking at the more specific properties okay just to give you a little bit of an overview of how the how cryptography is used um in Matrix so basically Matrix you have several parties you have a user uh which you often represent a client and this user has many devices for example a laptop a phone or something like that and all of them uh communicate with each other through the relying of messages via the home service it's on trusted Home Server that I already talked about and this Home Server also used to store communication history and account information of the user and furthermore is also used to provide a device identifier for the several devices that a user holds in order to achieve authentication they use a certain crypto cryptographic identity there's a master cryptographic identity that is called the master BK which is the one that is used to provide authentication for the devices that a user holds and also to co-sign um the devices that all the users hold so you can use all of these identities to for example if your Alice also verify"
  },
  {
    "startTime": "00:36:02",
    "text": "uh the cryptographic identities of the devices that both holds for example and in turn each device also has its own cryptographic identity so you have first uh user identity and also pass device identity and that one is the one that is usually used to establish the key establishment and encryption channels that are going to be used by matrix um those channels are called a megalum those are the cryptographic protocols that I use and I'm going to Define them a little bit late so you want to see how the process of actual verification work is that you have this master public Keys which in turn sign um self-signing key and also a user signing key a sub signing key is the one that is going to be used to verify the pad device key and a user key is going to be the one to verify that verifies the list of devices of the other users so there's this complex critical in which the different Keys may cross verify each other okay as I said uh they use om and megalum as the underlying cryptographic mechanism so let's explain first what's his own home is basically a way to establish a secure Channel between two pairs so for example one device with one another and the reason that they do this is so that they establish a secure channel in which they can share the key material that is going to be used to encrypt it messages during the group chat um what is used on this is that they use a modified 3dh protocol from the Cigna protocol and also the double ratchet algorithm from the signal protocol they use an old version of 3dh because right now signal uses another version which is called x3dh and they use the old version which is 3dh claiming to have certain deniability properties and as I said they also have the channel which is called megalon which is basically the group channel in which once you have established an OM Channel a Payless Channel with each one of the devices then you use this pair with channels to share uh the group share key"
  },
  {
    "startTime": "00:38:01",
    "text": "information that is going to be used to encrypt one each one of the messages that you send through the group and effectively this is similar to how signal users send their keys um megalom also has some ratcheting properties that are very different um not very different but different to how signal does the double ratchet algorithm and the mega loan properties have not been formally analyzed but the community so it remains to be seen what kind of this established properties megalum actually has and here just a little bit of diagrams in case you want to look a little bit more okay so let's go to the meat of the talking itself which are the attacks and in this case I'm going to be studying Define the first attack and then then we'll be um explaining the rest of the attacks so the first attack we have found we actually call it the attack in which the home server has control of the users and the list of the devices so why this happens is because you have as part of a group chat you don't only send user messages but you also send group membership messages so for example that a user wants to join or a user wants to be removed why user wants to be modified somewhere but the problem is that neither of any of these group membership messages are encrypted uh check for integrity no cryptographically authenticated which means that a malicious Home Server can indeed inject any user into the room and those fours are injected users will be able to decrypt any uh future messages that are sent in the channel why they think that this actually this attack happens in practice because we think there was an assumption from the protocol designers but this is just a speculation we think that there was an assumption that the only thing that needs to be protected is uh the user messages themselves but not this room membership Pages um so maybe there was this assumption and in general because sometimes there's practical issues when actually trying to implement and actually be encrypting and"
  },
  {
    "startTime": "00:40:00",
    "text": "authenticated these other messages are not using messages a second type of this attack is in which um on the country instead of adding a new user the Home Server you're adding a new user what happens is that the home server has a new device to your list of devices so I already said at the beginning is that you use cryptographic identities to verify each one of the devices that you own so for example you verify that indeed you're on the phone and need you on the laptop but this cryptographic verification is separate from the list of the devices that the Home Server maintains this list of devices that the Home Server maintains is not authenticated it's not encrypted it's just a list of the Home Server maintains so therefore the Home Server can also inject a new device into this list and again this device will be able to decrypt any future messages that are sent through the room why we Hindi this happened for the same reason that we already said in the fast attack and how we actually go on solve these attacks um is probably by the way that we will have to use a list that is cryptographically authenticated and it's also properly checked and it's not just a plaintiffs list that Home Server controls and in fact indeed we already have such a list because of the crew signing uh procedure that I was just describing is it doing practical right now that for users probably that will be doing practical to have like a list of devices that the user has to individually verify but for now that's kind of the best that we have okay and now then we'll explain the rest of the attacks I think you admitted then okay we can't hear you Dan do you want to just uh try resetting your audio we can see you but we can't hear you"
  },
  {
    "startTime": "00:42:07",
    "text": "foreign I think we still can't hear you so Dan do you want me to continue while you're trying to oh there you go we got it ready uh yes yes sorry about that um yeah so the next few attacks um we're going to go through they vary a little bit in the extent to which they are kind of attacks against the protocol design or maybe the implementation so like if we muddle those up sorry um but uh so this first attack um when two parties want to ensure that connection hasn't been tampered with they probably want to check for like um is there a Mallory in the middle attack and they can do this um by doing out of band authentication um and Matrix provides like a couple of protocols to do this but um the one we're going to talk about now is the short authentication string protocol which kind of very briefly the idea of it is that um these two parties are going to do a key exchange to kind of generate some kind of shared secret and then they're going to compare that shared secret out of band and some of the snidiness of this protocol is you get kind of um they use short strings for emojis to do the comparison and providing they do match um they're then going to send their real like correct cryptographic identities to each other over a secure channel that they've construct constructed using the shared secret um and this works really well in Matrix but there's our attack targets that final final stage where they've got a nice secure channel that the Home Server can track devices into sharing an identity that the Home Server controls and what could you go to the next slide up next thanks um so like how does the Home Server do this trick"
  },
  {
    "startTime": "00:44:01",
    "text": "um well first I'm going to explain this kind of two types of verification and Matrix so sometimes you want to verify to the the identity of another user so two users are going to do some out of balance verification together but sometimes um two of your own devices need to also do a verification um and they use the same protocol for this and for step three of that protocol where they exchange their cryptographic identities um they they send a key identifier um and they use the same field for both of these types of verifications um so when you're verifying other users you send a a fingerprint of your master cross signing key so it's that mpk field but when you're when you're verifying devices you instead use the device identifier and the problem with that is that that is actually controlled by the Home Server oh so if you go to the next slide please thanks um so then well Home Server can do this trick where it generates its own kind of Master cross signing key and and kind of cryptographic identity for a user and a signs of its fingerprint as the device identifier and then at some point when two devices um perform this out of band verification they're going to send a message and the device sending the message will send a key identifier they think it's a device device identifier but the device that receives it will interpret it as a master cross signing key fingerprint and this means they'll sign that user identity and you've kind of like tricked tricked them into trusting a user identity that's actually controlled by the Home Server at that point you can do kind of like an active mother in the middle attack from then onwards um next slide please thanks um so what causes attack well it was effectively just like a lack of domain separation between these key identifiers and the device identifiers using them in"
  },
  {
    "startTime": "00:46:02",
    "text": "the same place um and in general I think it would be really great to like in the future just to avoid using server-controlled inputs and these kinds of other band verification protocols because it just helps with kind of cleanliness um oh and the next slide please thanks oh cool so for the next attack we're going to talk about we've called it the semi-trusted impersonation attack um and the idea of it is um when a user adds a new device they'd like that device to be able to decrypt messages previously sent to that user and there's this thing called the key request protocol that Matrix um kind of provides to do that and here we can see on this slide um Alice's first device on the left receives a message it can't decrypt so it sends out another message asking for the decryption key Alice the second device sees this request and it checks a couple of things it goes well um is a requesting device a verified device from the same user as me or have I already sent this kind of decryption key before and if it passes those checks they'll encrypt using an OM Channel a forwarded room key message is what it's called and they'll send the decryption key to Alice's first device and as part of that message they'll um Vellum include the um the identifier of the device that kind of the claimed owner of that key um and that for that reason it's really important that um you check when you're on the receiving side do I trust this device that I sent it to me and um this is where the checks were missing and so if you move to the next slide please thanks um so what the the attack it can do what a Home Server can do is they can create their own device they can generate their own room session they're in megalom session and they can just forcibly send a forwarded room key message to Alice's device pretending to be say Bob's device um and Alice's device would just kind of"
  },
  {
    "startTime": "00:48:01",
    "text": "accept it so this was this kind of attack worked in practice but the um it is a little bit weak because all keys that arrive via these folded room key messages um will be flagged as like kind of semi-trusted and so you can impersonate on the mega ohm Channel but only in a way that's kind of like um flagged in the user interface of access to the next societies thanks um so what caused this well it was it was effectively just an implementation mistake um but as a general kind of like well this is my this is my reading of the situation the key request protocol um was a little bit underspecified in that it didn't talk too strongly about um like why um what to do on the receiving side and similarly what to trust like it wasn't it doesn't it kind of leaves that up to the implementer like how how should you when should you trust these forwarded room key messages when shouldn't you um so I think like a more prescriptive specification would have would have helped there I'll call next next slide please thanks um so now for the next attack we're going to talk about um a kind of a slight upgrade to this so when you have a mega ohm session set up um you initialize like a mega ohm I'm an imbo an outbound session an inbound session and a signature that kind of links them together um and you send these over like the old channels as before but um knowing that we can kind of do the semi-trusted impersonation attack over Mega ohm the question is can we use this kind of um can we if we can send these messages these session setup messages over Mega ohm instead we can kind of upgrade our impersonation attack to one that isn't kind of tagged as a forwarded key and that's what our attack tries to do also if you go to the next slide please you can see here what we try to do is we start off the Home Server is trying to"
  },
  {
    "startTime": "00:50:00",
    "text": "impersonate Bob to Alice um and it first starts by doing the semi-trust impersonation attack and at this point um they can send the adversary can send medical messages that verify as being from Bob's device they can then generate a second Mega ohm session we've tagged this G star and they send it using a normal session setup message so it's not a folded room key but they do it over Mega ohm and this is kind of where the the protocol confusion and where the main implementation mistake was um and by sending it over Mega ohm it kind of passes all the checks that say this is a verified um this is a like a verified message from Bob's device over Mega ohm and from this point onwards it kind of gets tagged as a session and you can use it um but it's not tagged as like a forwarded one or anything like that um so it kind of get a slight upgrade oh cool uh on to the next slide please thanks um so then for the next attack and the final one we're going to be doing in this presentation um is the kind of a confidential confidentiality break that extends the the issues we just talked about um by by looking at two new subprosicles so the mega ohm key backups protocol allows inbound Mega ohm sessions so kind of like the decryption keys to be backed up on home servers and then um they're encrypted on home surface using a recovery key that's kind of shared between the user's devices um the second sub protocol we're going to talk about and use is to Secure Storage and secret sharing protocol which allows users to backup account level secrets and they're supposed to share them between their devices so this is things like cross signing Keys um and actually the recovery key that Mega ohm used for Mega ohm key backups that gets synchronized using the Secure Storage and secret sharing protocol um so in this attack what we do is we"
  },
  {
    "startTime": "00:52:03",
    "text": "utilize that protocol confusion and semi-trust impersonation attack from before but we impersonate a trusted device and use the secret sharing functionality to force the target device into using a mega ohm key backup that the recovery key I mean sorry uh using a mega home key backup and use the recovery key for them that is actually under the Home Service control so we kind of impersonate a trusted device and send your recovery key and then what happens is the um the target device will then start uploading all of the decryption keys that has encrypted on the Home Server but with a um encrypted with a key that's under the Home Service control and at that point you can kind of decrypt these decrypt all the messages that this target device has access to oh cool um and then if you skip forward again sorry I'm just gonna thanks yeah so what caused this um well again it was it was an implementation mistake and the main one was this protocol confusion um but the there are ways this could have been kind of maybe avoided a little bit or discouraged by the specification because it um there's a they push quite a bit for a kind of like plugable and replaceable encryption algorithms which means that um kind of that's reflected in the code architecture but um different algorithms have different security properties that check like change how they can be used security so maybe a more prescriptive and less flexible specification might have helped avoid this kind of like um this kind of code issue but yes definitely an implementation problem oh thanks Sofia okay um so just a little bit to give you a little bit of a conclusion so what's the lesson learns that we learned after looking at the role of these vulnerabilities first and foremost that they are practically exploitable we even"
  },
  {
    "startTime": "00:54:01",
    "text": "have a private concept that indeed they can be practically exploitable we don't know how much they are exploitable in the world in the wild um some of them have been fixed by Dimitri specifications some of them will be fixed in the future and some of them might not be fixed um the reason why Matrix did all of this protocol is because it's a really complex scene to do properly secure messaging group messaging protocol as we have experience already in the iitf with MLS um it's not an easy task and then the other easy test on actually thinking about group messaging is to actually think what kind of properties you should have and that at least from the specification or Matrix sometimes it's not unclear what kind of a specific properties they aim to provide so that's what is the conclusion of this that we need actually a formal model and Analysis of thinking of this protocol and perhaps also understanding and taking inspiration from protocols as TLS on mls in which there was a collaboration between the academic and vanity standardization body form of verification Community to actually provide protocols that actually had a good threat adversity model in mind and also the specific properties that they wanted to provide and a formal proof that indeed to their Chief said uh property so we probably we want to have a correct uh group secure messaging protocol that is interoperable as well then we actually need to do the work of actually sitting down with several people from several communities to provide a safe critical with that I will just skip these other slides and thank you very much thank you thank you both for um an excellent and very sobering presentation I think you have certainly answered the question secure group messaging what could possibly go wrong if we didn't already know the answer um thank you for your teamwork on the presentation as well um and I'm hoping we have some questions okay uh we do uh Stephen you're up first"
  },
  {
    "startTime": "00:56:06",
    "text": "Hey Stephen Farrell really good work thanks for doing it and Reporting out uh I I just had a question did you have a um or did you spend any time looking at the Federation between home servers and uh are there any issues there that you found or that might be interesting um what happened um we kind of modeled it completely as um kind of all the home servers are a single entity almost like a single untrusted entity um but it'd probably be good to do that I think there is a cool paper that looks at the synchronization algorithm the the state sync algorithm but I can't remember the name of it sure if you could if you could think of it and put it in the chat or mail it'd be great later thanks yeah uh Rafa Robert um yeah so my question is the same vein as stefans do you plan a sequel you when I got done well I think we will be the same so you got it thank you um yeah I think our plan is to we're working on some form of model modeling and those kinds of things so um that would probably be like the natural follow-up is to try and um show that now that Matrix have fixed like the vast majority of these issues and they did it really fast and they were super responsive um yeah just trying to show that now you know we can get to a place where we believe it's nice and secure some other words that we have also been thinking is uh to actually understand what kind of the liability properties seem to provide it was a core aim of the prayer of the Matrix critical to prevent any ability but it has not been also formally modeled so we will also be looking at that"
  },
  {
    "startTime": "00:58:04",
    "text": "what time first time well thank you for doing this first of all I want to check if if I got it I mean are this the same vulnerabilities that were already discovered in I mean in released in September and I think fixed already in a good I'm interested for most of them I think there's a disagreement on one so just just to check if these are new ones or we've had the same that were already disclosed and and the other thing and I also wanted to say I I don't know if you were this morning if you attended the Mimi meeting you know but yeah it's very important that now you go there because I guess in the future you might converge on other protocols not on all my government it's very important that we get them right so yes they have the same vulnerabilities that we disclosed there's not anything you in this presentation besides what we already disclosed I also attended the mini um now future working group and I do hope that on those of them we do take the same lessons learned that we have from less than CLS 1.3 of actually making a group that has a collaboration between the academic Community formal methods and standardization value to put out there's something that's really safe and good thank you again for the presentation and if you do do part two please bring it back here and present it to us again thanks sorry we're so On Cue question that we missed uh not a key question just uh with respect to the formal analysis points on the last slide there's a side meeting in Richmond six tomorrow on doing formal records so we'll move on to the last presentation we have and this is by Simone basma of uni um some of you may have seen the brief presentation that was given yesterday I"
  },
  {
    "startTime": "01:00:02",
    "text": "believe it was concentrating on censorship in Iran and this is a much more General talk about measurements of Internet censorship globally please go ahead Simone thank you so uh it seems you can hear me hello uh so okay um first of all thanks for inviting me um I'm very happy to be here so I want to um basically provide you an overview of uh what one is doing for measuring censorship and I would like to focus a little bit more on measurements of encrypted protocols and I also want to um like focus a little bit more on the more experimental stuff that we are doing as opposed to uh like the mainline measurements that we are doing so let's uh say a few words about universe so it's a free software project it started in 2012. like the idea is to provide people with tools that they can install on their phones on their computers and use those tools to master internet censorship and the uh like over time we have collected the more than a billion Network measurements uh in more than 200 countries the way in which it works is that you have this application for mobile or for a desktop or a command line application and you can choose what category or what which tasks inside the category to run or in a way Flagship experiment is the one for websites where basically we there is a list that the probe is going to measure a list of websites which depends on the country in which you are in or if you want you can choose custom websites for you to to measure and this will be uh part of what I will talking about in the presentation I will not focus much on instant"
  },
  {
    "startTime": "01:02:01",
    "text": "messaging I will just say that we have this specific tasks for instance messaging apps where we measure endpoints that matter to those apps as first circumvention again I will not be focusing on it here but briefly and I think it's also related to previous conversations I've seen in the chat what we have is um we integrate siphon which is a conversion tool and so our task bootstrap siphons and tells you how much it takes we do the same for Tor uh the vanilla version so without any plugable transports we also integrate snowflakes so we can tell you how much it takes to bootstrap to our plus snowflake so and then we have also other kind of tasks that um like so for example Performance tasks and middle box tests and then um while those are the tasks that are part of the application proper there is a huge amount while not huge amount but the fuel experimental tasks that do not run all the time or just from sometimes in the ground if you enable them and those are part of what I'm going to discuss in this presentation okay so um now I want to spend a little bit to explain uh the principles with which we measure and I will use as an example here measuring the web though measuring encrypted DNS is similar as a concept not all the experiments that we have are at this um like are following these principles it took us experience to understand these principles and so only the most recent ones follow these principles though they are the ones that either we are using the most or we plan to be using the most so that's basically fine okay so the um first part is that we want to provide"
  },
  {
    "startTime": "01:04:03",
    "text": "the probe to measure um like we want to pry the probe websites to answer and that is a URL but providing the URL in itself is not enough we need to know more about that URL it's important to know in advance what are non-good IP addresses for that domain which helps us to find out more ways in which uh a websites a website could be censored and then we also have ways to know uh more or less around the same time that the probe is performing a measurement whether the website is expected to be up and it's expected to working as intended basically okay we like so that's the first bubble basically uh the target to measure and contextual information that helps with measuring then there is the first um like uh Act of measuring which for web is a DNS lookup so uh we we in most cases and historically we tended to use got a dreamful and the reason for that is that in many countries so for example in Italy where I'm right now uh and many European countries most censorship um or historical Mass censorship has been uh implemented only by the resolver of the ISP so that's the historical reason why we use data dream for we don't always know what the result is sometimes it's easier than other times to discover it and so that's a way to to use that but more recently we started to add in parallel another resolver and this one is um using the DNS unencrypted over 53 EDP and the reason for that is that um in some cases get under info may be using an encrypted channel so for example we know that with systemly you"
  },
  {
    "startTime": "01:06:00",
    "text": "can use dot etc etc and then what the additional um unencrypted query allows us to know whether there is a blanket interception or tampering with DNS requests which seems to be the case in most countries so it's quite uncommon that you you have targeted filtering for a specific uh server endpoint in general it's foreign queries okay that that that that part of our like measurements give us IP addresses or errors and generally errors are like wait what we didn't expect this because in most cases we know that the website should be uh like addresses so in general when we see something unexpected uh compared to what we know to be true we call this an anomaly and then for IP addresses we are not sure whether they are good for the domain but when we are measuring encrypted websites um we we say they are good if we can't tell us and check with them because we bundle mozilla's CA we hope there is no Rogue CA in there and surely there is no extra CA that the user may have so okay um okay once we have a set of IP addresses which is the set that we already knew plus the one discovered by the probe then what we do is basically construct endpoints from those addresses and then we do the what is required to do so for https that's mostly TCP connect Tela Centric and then trying to get the resource and each of these operations could fail and then if we expected it not to fail if it fails we are again into the a this is an anomaly territory so yeah those are the principles and uh um like users Runway and then there is a backend and the backend uh is actually import very important to us even though users"
  },
  {
    "startTime": "01:08:01",
    "text": "do not see it and it organizes measurements and it has an API and through the API um and for a website called Luna Explorer researchers including us and users they can fetch measurements and they can also um not only fetch individual measurements but also group measurements and try to make sense of measurements uh like looking at charts that show Trends in general slash reports is where we publish reports on our websites and now that I think I covered all the basics what I want to do is to um so basically discuss a bunch of recent words that we did but rather than giving a broad view I want to show some into some aspects that I consider interesting that we are working on what we found so the first report I want to focus on is this one uh that was about Iran and so um this is about the Maza mini protests and it was at the end of September of this month and there was uh already loss of disruption in Iran before the protests but something changed around the protests and so for example here we have uh a math chart of DNS over https each row is a service and um each each bar in in the chart is the its height is the number of measurements collected on a specific day and then it's divided in different colors and each color is a class okay means everything literally everything was okay um then we uh anomaly I told you already what anomaly means it means basically we expected something to happen but there was a networker we didn't expect that's mostly what an anomaly means in this context and then confirm and confirmed um in general means that there are signatures known signatures of censorship and we found some of those"
  },
  {
    "startTime": "01:10:01",
    "text": "signatures inside the data in the case of Iran that mostly means bogans uh Bogan AP addresses that are known to uh be used to implement censorship now if you see basically the colors Trend here you see that after the 21st for most Services it changes from yellow anomaly to rad confirmed uh what I wanted to do here which is um like uh a bit more in-depth I wanted to show you what happened for Doh dnasapple.com on the 24th so um yeah oops Yeah next slide cool okay so um when I told you our principles uh for measuring I told you that we provide the probes with non-good IP addresses this means we can uh regardless of what happens for DNS we can track whether we can establish connections with no good IP addresses and see what happens for that okay and this table shows that so the First Column is the s number the last column is the number of times something happened and the other columns in the middle allows us to classify um how many times we did see specific blocking patterns so DNS means DNS was blocked and TCP means TCP was blocked Etc okay and success means something was okay and um in in uh and like for resital for example the first row uh ddns always failed and it always failed with one of the three bob-ons shown above so that was that basically means that if you just use the DNS uh local yanas uh either the get a dream resolver or our EDP you will not be able to go further but we provided the probe we type addresses and so when we use those AP addresses uh we always fail in the tiller Centric and we failed with this signature that you send the client hello and then nothing happens then eventually you time out because you're tired of"
  },
  {
    "startTime": "01:12:01",
    "text": "waiting um another Network TCI at the similar pattern again DNS block same way however the uh a good IP addresses that we provided to the probe failed into distinct way so sometimes uh it was this it was timing out during the TCP connect for other let's say more luck AP addresses instead you were able to establish a TCP connection but then you were still timing out in the telecentric and that happened 21 times and but five times it happened something that is quite interesting um a few of those AP addresses that we provided they were actually working so they were succeeding and and this suggests and it's not the first time we have seen this opening in Iran that there is not just a um like some if in the network that if the asanai of the client law is such and such you're blocked it's a bit more complicated than that it also depends on DP addresses that are using and it's Dynamic so probably depending on what people do that's a speculation but I will support that that seems I mean that's my mental model of what I have seen basically that it depends on what IP addresses are used and it seems to change okay so this is um it for this specific case now another case was this studied we did for Russia at the beginning of the war and um again I'm not going to bro like uh describe the whole case I just want to flag something that I found quite interesting uh so at the beginning of the of the world in Russia in Ukraine uh what we did see in um opening in Russia what many people did see is that Twitter was very difficult to use and so uh the conclusion was that it was throttle then many people published about this"
  },
  {
    "startTime": "01:14:02",
    "text": "um and we also published about this and the way in which we saw that was there was this form of tracking uh was like like this so we um when we are the lesson shaking we record the time stamp and the amount of bytes received by Raj um and then uh by collecting this data we're able to say uh at the end of the handshake regardless of the result how much data we were able to fetch in how much time so basically that's the speed and the unshake size is more or less the same in the sense that you need to fetch the same data like certificates Etc so um what we saw uh was that you can quite like there was two two populations basically a population of users through which the telecentric for Twitter uh was at let's say the speed that we could saw before this problem so at the beginning of the chart the 24th of February and then uh suddenly on the 26th some users instead were having this very slow handshakes um and then if you go and look you see that those measurements with the very slow handshakes uh they were timing out in the Android or timing outward trying to fetch uh what we were trying to fetch which was an image so that was the way in which we detected the signature of throttling in our data um it was not something that we planned for we actually added these data collection part because we thought it was useful but we didn't think about throttling and that was fortunate that we did this and now what we are trying to do is to have something similar also while we're fetching the body which will help us to detect this form of trucking and I guess the message here is that the kind of throttling that you would expect when you want to disrupt something is very very heavy uh because in a way you want to"
  },
  {
    "startTime": "01:16:00",
    "text": "um like you want to be below a certain bandwidth that makes it very difficult to use the application at the end of the day so uh okay the third aspect I want to focus on is that I so far I basically um discussed only TCP based measurements however we have been starting to look into quick as well and uh while the mainline website measuring experiment that does not contain code for quick we have experimental experiments that we have run in some cases that do and we are looking forward to merge those into the mainland experiment and so again I am not going to discuss everything I just try to discuss something that we are trying to look at uh this was run from China and we had this opportunity to basically have a list of websites that were available with https or HTTP 3 and we tried to test this like both and the idea was to see uh what happens um like if something is blocked for https what happens to the same website on http 3. and so there is this basically diagram where on the left we have the clusters of failures connection reset a TLS timeout and Shake success and um timeout while connecting TCP and those translate quite neatly to other categories that matter for HTTP 3 so for example while other which honestly I don't remember what it is but was very rare uh success and um quick and fake timeout so what we already knew and it was a bit confirmed by looking into this is that in China it's very very common to block IP addresses and we we're not sure whether"
  },
  {
    "startTime": "01:18:02",
    "text": "and honestly we cannot be able to say it's IP addresses or endpoints but certainly the endpoints that were blocked for TCP were also blocked for UDP uh you see that like this 24 percent uh fraction translates to a more or less equal attraction for week instead the majority of the sites that were blocked with connection reset or timed out during the unshake they were actually accessible now this is not recent it's six months no it's far from four or five months ago so maybe now it's not like it's not exactly the same it could have changed though at the time that's what we were seeing um okay so we we we were asking the question whether okay but is this really that they are blocking you for factory European points what it is like so we did this other we created these other small tool called quick Pane and so the idea of quick think is that we want to decoupling way um the the fact that quick quick is like um embeds the transport part and the Telus part in the same um like pocket anyway so so we we sent an initial quick bucket minimum size and in depart that should have been kelas was random but we sent a version negotiation that was um if I recall correctly Baba in hexadecimal so that was invalid so the idea is that we send this invalid um bucket and because the version is invalid we expected to receive something and at the time at least that seemed to work as like we were receiving Pinback from service so we tried this in that context and what we actually discovered is basically that no as far as we could tell at the time the timeouts that we were seeing"
  },
  {
    "startTime": "01:20:02",
    "text": "with HTTP 3 on the left were mostly timeouts for Ping so it did not seem at the time this was um basically caused by uh inspection of the TLs part of quick even though again quick is a new protocol and time flies and so maybe now it has changed so but yeah at the time we didn't notice this kind of potential interference okay now this is the last topic to touch upon the DNS track experiment so this experiment follows the philosophy I described you at the beginning uh like the way in which we try to organize measurements so there is nothing really new to say here but that there is an experiment in uni that is dedicated specifically to measuring Dot and Doh and that experiment tries to follow this principle of providing the probes with IP addresses that are good for the domain so we are happy that we even if we are getting a censored locally we have good IP addresses to try um and the other good news is that this experiment um is now in uniprobe and like as I mentioned before in the uniprobe there is a section called experimental that you can run manually or you can ask the only app to run it automatically along with other tasks and so we now start to add data about this uh even though we have not looked actively into this data because while we are a small team and uh yeah it's uh um like recent months have been very bad in terms of censorship so it I've always wanted to look into this but I could not do much so far though what we can do and what we are working towards doing right now um is we are trying to take our uh let's see scripts that we use for for writing"
  },
  {
    "startTime": "01:22:00",
    "text": "reports and convert them into tools that everyone can use with any data uh and so uh these charts here are produced by these new tools and the uh what I find quite cool about these new tools is that they explode measurements so um like every experiment produces its own kind of Json measurements but these tools they like come back down and so every experiment needs to do TCP connect and it's in the same way and tell us likewise so they will create those tables that all experiments will end up filling TCP tables until last tables Etc and so now we are able to do stuff like okay give me all the TLs connections that we have for this domain um regardless of the experiment and then uh of course those are the ones that arrived to the TCP point so you need to have TCP let us be worked at that point but yeah um so that that's something we are working to do so here is uh data from DNS track and I I tried to like uh yeah the basically the meaning of the rows is cloud Fair Doh domain means the URL that you will use for cloudflare Doh which is quite long so it was not fitting in the chart Etc and we tried to provide like um a view of what it was looking like 10 days ago or something for China Iran Kazakhstan Qatar and Saudi Arabia and that is just connections that are at the TLs stage and they are trying to tell us Centric um and then another thing we are trying to improve on is we are trying to rather than providing this yellow anomaly which is a bit like of a container for anomalies we say Okay um this is the the kind of failure that we have so it's more more interesting to know uh like you can directly see the fraction of connection result or timeouts okay I'm concluding so the final thing I wanted to mention is that um uh we we are trying to improve and I"
  },
  {
    "startTime": "01:24:01",
    "text": "told you already ways in which you are trying to improve and Anonymous our debt in a better way and made this available to everyone as opposed to being Justin for us uh other stuff we are working on I would really love to have better deal doh3 and doq support for DNS Chuck so we have better data about those as well um it's very important to make sure we are using the the I would say the Chrome browser's fingerprint uh because currently our toolizingo and the fingerprint that we have uh is not the one that Chrome would use and sometimes they go fingerprint is associated with their conversion tools so we want to remove confounding factors here that's another thing we want to do then we want to integrate quick into the myelin experiment that's I think uh yeah those are the most important things we want to do and with that I think uh we reached the undend I'm happy to take any questions thank you very much for the excellent work and for the great presentation we'll open the queue for questions now yeah can you state your name you're not in the yes thank you I'm Marco Davis I work for sidn thank you Simon for this interesting presentation um I have a question I was wondering um are you interested and do you look at the the root cause of any blocking of internet access for example uh our company's website as at the end.net is blocked from Iran but that's not because the Iranian government or anything has decided that is because Google Cloud platform has decided to block traffic from Iran to their customers which we are one of them yeah is that relevant for you that kind of distinction between who is blocking and what the reasons why you cannot access from a certain country to a certain site or location yeah so excellent point excellent"
  },
  {
    "startTime": "01:26:01",
    "text": "question it is not something we can uh as far as I know measure directly with our tool but indirectly we can in the sense that yes we are aware of the problem we have a community of users and they have raised this problem with us so we try when we analyze and produce reports to always keep that in mind and my recollection is that the way in which it is blocked on Google is that you got a 403 so that's correct I will say that we can see that in the data because you don't see a connection result or a timeout but you see so in fact you even see a valid TLS connection so that might also be a hinge um yeah yeah so thank you yeah thank you next in queue we have Alex hi uh Alexey Google I was wondering if you're planning any extensions to your quick ping Tool uh from quickly looking at it it looks like you're only sending like the version negotiation aspects and one of the things that I believe we've seen in the wild is that there are some middle boxes which look at specific offsets because they don't understand quick and therefore if they are looking for things like you know Sni which I think moved between draft 29 and RFC uh then they end up blocking because they're trying to allow lists on things in the public handshake which means that you're I believe you're a quick ping tool if it doesn't consider that sort of case would erroneously say that the connection is allowed whereas if you actually try to establish a full quick connection it would get denied yeah so I'm happy to be here because there is people like you that can tell me this stuff that I was not aware of so I'm grateful no we are not doing that we should and actually if we can get in contact with some of the contacts that it's there I would love to know more and improve our tools thank you"
  },
  {
    "startTime": "01:28:00",
    "text": "uh next we have uh dkg remotely hello um thanks for this presentation you're really quiet thanks for the presentation and um and thank you for all the work on New Year if I'm blasting out the speakers I could turn it down further um uh I was wondering if you have uh any insight or if you can share any insight into the decisions you make about what to gather um in particular I was just testing the uni probe and it identified some blockages uh uh which I'm not sure are correct so I'm trying to figure out I'm looking at the data that it gathered um and I noticed that some of the things will say you know this has failed in this way and other tests like the SSL unknown Authority um response I believe actually sends the peer certificates that were gathered so you're actually building or you're you're retrieving a data set of those things I'm wondering how how do you think about how much information do you want to take um versus like it's useful for identifying technical routes and then some of it might actually be cause problems for the users that you're Gathering From I wonder if you could just talk a little bit about how um you know to reflect the the quest you know the first talk of this session uh David Oliver's talk about um you know how do how do we gather measurements in a responsible way I'm assuming you guys have thought about that and I'm wondering what you know gotcha yeah so the I I actually did not mention this but the there is documentation about what we collect and when you install any tool including the experimental command line client it tries to explain in a concise way and it tells you look we are uh not an"
  },
  {
    "startTime": "01:30:01",
    "text": "anonymity tool quite the contrary so your traffic is traffic that may stand and therefore you should read our um basically on inform constant documentation if you consult with that uh which uh yeah and then it's it's much nicer in the mobile apps or in in general in the desktop apps because it it tries yeah like it's not a common line tool so it tries to give you um like more and also another thing that we do is that after we provided these bits of information we ask to the user um questions like uh is the only problem going to do xyzad and they need to say true false to demonstrate that they have understood uh what the tool can do I I don't remember by Art the exact questions but something like a question could be like if you're using uniprobe your ISP could see that you are using unipro true or false and if the user says false we pop up and say no look actually that's not the case because it is a measurement to uh it's not like that so we try to educate the users and we try to have documentation about um about your community does at different levels of complexity and we also have I mentioned that we have experimental experiments and that's part of why we have experimental experiments so uh the the you cannot run experimental experiments with the normal client you need to download the specific client which is not super advertised so you need to know what you're doing if you run experimental stuff which means you are self-selecting yourself already I hope this answers to your questions yeah thanks I I thought it was interesting to see the pop quiz uh approach to trying to confirm that the user actually understands that's it I"
  },
  {
    "startTime": "01:32:01",
    "text": "thought that was an interesting thing especially during the earlier talk thanks thanks um we're a little bit over time is this a very quick class question if you can can you take it to the chat or to the list and that's great so that's thanks again for the presentation Simone thanks uh that's everything for our meeting today thank you all for coming and we hope to see you next time thank you thanks all see ya at the beginning and I thought leave it yeah um do you uh know what happened last time later what time are you heading out to that uh 7pm okay okay I'm gonna be in half between six and seven if you happen to be around yeah that sounds great when is the battery five okay"
  }
]
