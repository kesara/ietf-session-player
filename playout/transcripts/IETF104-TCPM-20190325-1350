[
  {
    "startTime": "00:02:27",
    "text": "[Music] okay and I\u0027d like to welcome all of you to the tea CPM session here at this ITF meeting first of all for those of you who don\u0027t know me my name is Michael sharp and next to me is Michael Jackson and is that I\u0027d like to start today\u0027s session is the with the usual note well so this is not the first session today so I assume that all of you know that this is in IETF working group so everything that\u0027s done here is covered by the node well so please read the note well and please take it into account specifically regarding for example IPR declarations regarding the logistics we do need a note-taker we haven\u0027t found one in at once so we will not move forward without a volunteer so do we have a volunteer for note-taking so if you\u0027re interested in any work in this session here you have to consider volunteering okay we have one okay thanks a lot I mean hopefully you use the ether pet as I will also too as far as I can for example pay attention to the ether pet but and maybe you can put this in a collaborative style but anyway we do need note-taking I will monitor myself the meet echo but of course as it\u0027s something shows up there we be well we appreciate if somebody else can also rely that do we have another volunteer for Chapas crack okay guys doing it and then last but not least in specifically for the note takers if you go to the mic please don\u0027t forget to say your name so that we can put your name into the minutes we broaden the agenda so this is what has been sent out before the meeting so our proposal is first of course to do the usual status update then we have two presentations for working group items first olivier on the colorado traffic and ten million pop on equities Ian and easy and plus plus and then we have today quite a couple of other presentations that are not at all about working through items actually most of "
  },
  {
    "startTime": "00:05:28",
    "text": "them are about documents that are not even in this working group but they are all related into TCP and business and so we thought it\u0027s good to have a discussion on those documents here and last but not least if we end early we will have the final presentation on a more research II talk is there any feedback on this agenda any agenda bashing okay that\u0027s not the case so then I will move forward this or usual status update so first of all we have one recent RFC it\u0027s the alternative back off it\u0027s only one recent RFC but we have a couple of documents that are getting closer to completion in the working group so hopefully in the next meetings this list will I have a couple of more entries then I\u0027d like to briefly go through all working group documents for the first three bonds we will have presentations here so I will not and say too much about them so we will see a presentation on the converter trough which has been recently updated we will have status updates on accurate easy and a briefly on the generalized ecn or recent plus plus so I will also postpone the discussion on that one too with the actual presentations then there was recently quite a bit of discussion on the mailing list on the OTO consideration document which is good there was also be an update or I think even more than one update so there has been progress on that document and at the moment it shows wait for reviews so we have a score in China for reviews of this document and this at the moment basically thing we are waiting on but other than that we observe that the document is improving and we will see if we can go to a working coop last call relatively soon then we have two other documents that unfortunately have expired the first one rec is something that we probably should review what we should do with the document maybe we can postpone this discussion to one of the later charts from trevean I\u0027ve seen some comments on rec in his presentation in any case having expired working group documents is not a good stages for such a document so hopefully we get resubmissions of this document for the right one definitely we have to have a discussion if that document is in in a stable state "
  },
  {
    "startTime": "00:08:28",
    "text": "and if it can move forward but the first thing for that tribute happen is that we need an active document the second document II do has not changed the status recently and so I assume they\u0027re still ongoing testing effort on basically the question whether that scheme can be implemented and what are the potential issues in this implementation and then last but not least we have te 793 pitch document this is all the document that has recently been updated and I\u0027ve put here on the slide at a comment from West who believes that the document is getting into a pretty decent shape we will not discuss this document in this meeting but we the church are discussing with the editor on what to do possibly in one of the next meetings as the document is moving forward and I just like to point out that in his last email to the mailing list Wes has flagged a couple of sections in the most recent version of the document and he is looking for feedback on those sections so please have a look at those questions we do look for feedback and if you have any thoughts on these technical questions then please feel free to comment on them we recently have performed the working group at optional call on the 21:40 bees document and the working group adoption call has run until Friday last week so we didn\u0027t get a lot of feedback but there\u0027s also been no pushback on working group adoption so the understanding of the chairs is that there is consensus in the working group and to adapt on this document are there any comments on that okay see no comments so the consensus on that this to adopt it as a tea CPM working group item and then this is my last slide this is just a heads up on a document that is not in TCP M but we have repeatedly presented the document here in TCP M Templi because it\u0027s quite related to our work here it\u0027s the document on the constraint node networks so this document has been presented in detail last meeting and this is triggered quite a bit of excellent reviews after the last presentation and also specifically I\u0027d like to highlight that we got a pretty good list of feedback comments first word we work on addressing these comments there will be some technical "
  },
  {
    "startTime": "00:11:29",
    "text": "changes in the document to address all the comments that have been made and assume the main author will send a summary of the changes to the list but other than that the feedback in general seems positive so the authors believe that this document is getting pretty close to working group last call and so that\u0027s why I asked the working group to carefully review the most recent version before it\u0027s not a tspn document but it has been agreed in the past that there will be a joint working group last call in the library I be working like that IG working group and TCP M so we will you will see traffic online tests on the mailing list and that is actually on the last slide in the chair part also are there any other open issues on the working group status anything that we have missed here and the status update then I\u0027d like to say thanks and then we will move on and towards the presentations of working group items and we will start this Olivia okay so let me just give you an update on the Geo ftt TCP converter document next slide so just to record was the basic design so the converter protocol is an application level protocol which means that the service is running on a specific port and we are sending commands and responses and this command and responses are encoded as type length values and what\u0027s specific about this protocol is that the comments are sent at the beginning of the byte stream so inside the scene and in the scene kazakh in the next packet and this is a plane mode transport between the client and the converters and the motivation for this work is to allow a TCP connection to be established to a proxy so that you can learn whether a remote server supports a given TCP option or not and the menu CSS multipass tcp so that you can get multipass tcp on the access network through the proxy and then learn whether the final destination supports and p tcp or not next slide let me just show you how it works so next slide so the client sends a scene to the converter to connect to a specific server and this the converter message is encoded as a TLD in the scene payload and the converter will send a syn to the server the server will replied next slide and then the converter can confirm next slide the establishment of the connection by using a TLD information in the payload to confirm that the connection to the remote server has been "
  },
  {
    "startTime": "00:14:29",
    "text": "established and then next slide at this stage we have a transparent byte stream through the converter between the client and the server in post direction and next slide so what are the main changes since the last presentation of this work we got feedback from different implementers and asked to tweak us to tweak a bit the protocol one issue was that in the previous draft we said that the whole messages would be encoded inside reset segments but in practice there are some stacks that have difficulties in parsing data in reset segments although it\u0027s supported by RFC 793 lat and there is no an open source client library which is being started and we also simplified the design so in the previous version we relied on TFO but we know that here who has issues in some deployment use case and what we did is that instead of using the TFO option to encode a cookie to secure the connection between the client and the server we move the cookie to the user space by using a specific TLD so the same functionality is there but it\u0027s not using TCP options anymore next slide so let me show you how the cookie works so next so the clients and the scene with the connect message to the converter the converter does not have because there is no cookie inside the scene and so what the converter will do is that it will compute a cookie and a way to compute a cookie could be like we do compute the cookies in TFO so by using the hash of the IP source address then you can return the cookie in the simple sock with an error message that indicate the cookie that the client should use and then next slide so we can restart the connection again a syn we encode the cookie that was written by the converter now the converter can check the cookie by doing again a hash computation for example but there are other possibilities and then the cookie next ID can establish the scene and then next slide we get the response from the server and next slide you get the simple nak Kozak and the connection is established as before a next slide then you key they are also used edges where the client would send a cookie next slide so you send the scene with an invalid cookie and this can be checked by the converter and the converter can return an error message saying that this cookie was not authorized because for example the cookie has expired on the on the converter and the converter wants to get a new cookie from the client to reopen ticket the client owns the IP address from which its received so it\u0027s exactly the same stuff as what we do in Tier four by using TCP options except that you do that inside the payload so we can have a cookies that are much larger than the ones that we use in the TF auction the main use case for this control to draft is to support multi by CCP in access network so typically what you would have so you would have a smartphone that uses multi pass CCP next slide so you can send a syn with the MP capable option and "
  },
  {
    "startTime": "00:17:30",
    "text": "different options in the example I only show the MSS option but there are other options so used under connect then it goes to the server the server returns back the sync Razak and then what the converter does is that it will return in the next in the sink exact DMP capable option to confirm that this is it\u0027s using an p tcp between the smartphone and the converter and it also provides to the client the tcp options that have been returned by the remote server so that the client can learn with that information that the final server does not use does not support multi path CCP and so if the clients wants to use a multi pass capabilities on the access network then it should use a converter on the next slide we will see what happens when the server supports multi pass TCP and next slide so again we send us in next slide we send it to the server the server next slide will tries with the NP capable option and then the converter will return in the extended TCP header TLV the NP capable option that was returned by the server and so the client now knows that to reach this specific server it can use weekly pass CCP and so for the next TCP connections it can send a syn directly to the final server without using the proxy so that\u0027s a way to learn whether to be able to use MP TCP on the access network through the convertor when the server does not support the capacity and when the server supports multi pass TCP you can learn it and use direct connection to the server next slide so to summarize what happened so we believe that now we have a simplified design which takes into account all the feedbacks we receive from from implementers and on the mailing list there is ongoing work in different studies ation about using this convert protocol and it\u0027s being adopted by to sanitation bodies so one is the broadband forum which uses that as one of the solutions for a grid access network based on eighty by CCP and this is WT three seven eight which is now being with after approbation is being finalized and it\u0027s also used by 3gpp for the ATSs service which will allow to combine treat 5g and Wi-Fi but also other types of network and this is part of the work in twenty three 701 and there was a discussion during last year in twenty three 973 that explained why 3gpp has selected multiple CCP and the control protocol for the a TSS service and the authors believe that with that the document is ready to go for working group black school and then to progress are there any comments on this document proving Microsoft I\u0027m very curious why you decided to not use TCP fast often because fast open does have an option "
  },
  {
    "startTime": "00:20:30",
    "text": "where the cookie size can be zero if the server doesn\u0027t care about enforcing security the cookie size can be zero and the advantage of using fast open is that most operating systems at least on the client side would already support us and India tanderson for you so otherwise you\u0027re looking at like using raw sockets or something to do so so that\u0027s so we have a specific protocol and we want to be able to confirm that the scene comes from a client that we know can receive simply Zak so for that we need to have a cookie and the cookie there are two ways to encode it one is to encode it in G TCP other as a TCP option or we can encode it in the payload we believe that it\u0027s easier to encode it in the payload because we have less restriction in terms of space and if you put TFO option which contains the 0 links cookie and then you put the cookie inside the payload there is no real benefit of having eruption which is a zero length the benefit is that there is an API which allows you to do this without using raw sockets otherwise you\u0027re not going to be able to do this on most operating systems I know there are other ways than using raw sockets in different implementations no I understand but I\u0027m saying that using the TFO api is probably the cleanest way to do this yes but you can use it here for api without using the tea absorption that\u0027s October 9 yeah just one addition to the comment about the the support of the zero cooking for TCP for so we used to have that in previous version of the specification since version 4 but we we have discussions with other implementers vendors and DC that is for at least for their user equipment it\u0027s really difficult to have the additive food supported directly as an option and this is why we have started with ODB to over design and to provide the same functionalities in detail instead of the duty for so we used to have that but given the feedback we received from the other implementers there\u0027s only one vendors Vasya said they are sub disappered was disappear option but for the others the told us that they have more difficulties of to support it I\u0027ll be very curious on you know what kind of MIDI box issues you see when you include the renders and without the T option because you\u0027re going to see two patterns of traffic on the network now one has 30 fortune and the data and one but there is no option there\u0027s going to be data so it just seems to me the TFS the cleaner approach but yeah yeah we have not yet tested that in real network with middle boxes but I think the the deployment use case that I mentioned on the last light there are use case is where the network operator will control the palace and so we know that there is no middle box that will mess up and whether we have a middle box that messes up with having TCP data in the payload or having a TTL option I think it\u0027s the same problem and I don\u0027t see a "
  },
  {
    "startTime": "00:23:32",
    "text": "difference making even so that part I agree I think there are already problems with metal boxes even so you have the option and but I think having the option is the matter you know design approach here if you\u0027re talking about an application protocol because otherwise has changes in antics of TCP and Alain transport but I also need to look at the draft in detail because I don\u0027t think you rule it out completely so depend strongly on the exact phrasing in the traffic what makes sense but so TFO was inserted in TCP to support web applications and to have a way to support the establishment of sin of data in the scene in applications that cannot encode the cookie information in the application itself so we are here in a different situation so we have an application that can support the cookie inside the application itself and I think it\u0027s cleaner to put the cookie information inside the application so that\u0027s fine but from Roman architecture behind a point of huge change just saying I want suddenly data on the sin is change to the TCP protocol right and the only way we support this is like using TFO if the consensus is that we should have a key of TF or option of zero length and then encode the cookie inside the payload because there we could have a longer cookies then I\u0027m fine with that as well if it\u0027s the consensus then we can do that we can live with that as well so I think that would be the clean design approach to go for and then maybe you want to have a section saying if you have if you are in a controlled environment and you know everything is like this you might also do it without option but Lena it would be using the option so you would suggest that eruption with zero length then it\u0027s fine for me we just use a few byte in the header but this is fine Christopher Apple I want to address they combed about the middle box issues when using TFO without TFO option independent from the convertor we have done experiments and it x3 is much it\u0027s not much better but it\u0027s better than with the option so you can use same with data and have more RP 10% higher success rate sure that interesting data but I do think like the way we\u0027ve documented usage of scene and data is with the t4 option I do think that\u0027s clean around the network because otherwise now you\u0027re going to have cases where there\u0027s two types of network patterns appearing on the Internet which is harder for everybody to deal with that maybe a mother isn\u0027t off season four one three also saying that one could use TFO without the option so this is Michael speaking as Cheer so and then "
  },
  {
    "startTime": "00:26:34",
    "text": "we have here on this slide a very unusual thing the other stos directly reference our work so my question to the author is can use or maybe two other people in the room the canyon share more details on how this pack is used by open forum or 3gpp and the specific question that I\u0027d like to raise is if there is an issue that this is experimental work because we\u0027ve made a call some time ago that this is an experimental protocol and I don\u0027t know whether that is an issue for other stos so if you have some insights on that that would be useful information for us yet so as infomercial for the the first question that you asked about the the current aggression in the 3gpp specifications so so far the the converter specification is the only specification which is used for the aggregation there so the they are relying exclusively on the solution we are developing here and the same working group for their work and you have some I would say some time constraint in the final lines in the dispossession so they are waiting for us to finalize the RFC here so if you can finance it by May during this year this will really be great for offer their work because this there is I would say it\u0027s only editorial and notes that is that we need the RFC staff to be published numbers so that we we have to work until write it as this is for your first question for the second one the experimental and for sterner track just for the record we when we started this work we thought we have done that in the in participate working group and at that time the impetus apiece facilitation is experimental so we lift that that header as experimental level there so for us we are opened here if do if there is no extra delay in the development of the specification I would personally be in favor to consider to this work as a candidate for a first solid track but if this will induce I would say additional discussions and in terms of in more long time to have the discussion finalized we can go with the experimental and then see the feedback from the field and the the deployment and then we come back here today it you have to promote the et spec so my favorite option is to go for the sonar track if it\u0027s possible if not we can we can maintain the current the can track you live in a city we do we coordinate this with three GPU and we both sides are aware of this dependency we just had a meeting about it actually and usually it\u0027s not a problem to have an experimental reference there okay so just for my for the chairs information and can I be please have a show of hands on many have read specifically in "
  },
  {
    "startTime": "00:29:34",
    "text": "specifically the last version of this document because the version changes in there so this is about between 5 and 10 so my understanding of the feedback is that we do need an update of the document but other than that we are hearing that this document is moving forward and there seems to be both ongoing implementation effort as well as use in other sto so that\u0027s a good sign so from a chair perspective we would head for working through glass all relatively soon so that\u0027s why we clearly need an update here but after bf GCD update definitely analyzed whether we can go for working coop last call so please pay attention and we might run the working group class called even prior to the next meeting okay thank you we move on to the next topic which is also about working group documents that is accurate ec n + ec n + + and I think Mia is presenting hello I\u0027m increment my co-authors are pop and Richard who are here as well today and this is a quick update and I hope you\u0027re done with this document so first a quick recap was what was the problem that we\u0027re solving here the problem is EC n is there ec n is around for a while and there is feedback from the receiver to the sender to see to tell if there were any markings seen on the past and then the receiver is required to or should be reacting to it with some kind of congestion reaction so to provide this feedback there are already three bits in the TCP header but the feedback itself is limited just like providing one signal per round trip time so you don\u0027t know with the classic easy n approach how many markings have the bin has it been like a severe Kadesh or just like a very light congestion and if you have this information however you can adopt your congestion control to this information make it more reactive next slide so what equity is the N does it reuses those 3 bits and provides more accurate information to the sender so these 3 bits after negotiation are a field which have a counter and provides a number of markings that were observed congestion markings and in addition we also have a tcp option that can provide even more accurate information about the number of bytes that were marked with like one or the other marking and the option is completely optional because it not pass metal boxes or you just may not "
  },
  {
    "startTime": "00:32:34",
    "text": "need it next yes so this is already kind of was addressed the last time I think already there were a main question about what what if this experiment fails we have then like burned all the heads all the bits in the in the header for the negotiation so we make sure that all unused combinations still lead to some kind of accurate easy and negotiation so we have a way open to further extend and update the accurate ecn specification in future do you want to interrupt no at least make the work Michael speaking from the floor so we have the in DTF discuss this question quite a bit the other to me what is presented here is for what compatibility makes a lot of sense if you assure that accurate Sen is the right thing to do forever but it\u0027s experimental so we don\u0027t know what the experiment outcome will be and in specifically the the last sentence so that we make the behavior of occurs accurate easy and predictable for future protocols that assumes to me that the future protocol is accurate Sen and as individual contributor I personally could foresee a world where the iCard ecn experiment fails and we will do something else and then to me the as this specific world doesn\u0027t help at all I don\u0027t mind at the end of the day to me as I said also to me for an experiment what is said here is yes speculating here that the ekor it is an experiment will succeed and I\u0027m not sure if that will be true based on what I know myself but I might be wrong the unexpected oh and yeah pop risk oh yeah that last sentence which I write obviously didn\u0027t write it in a way that Michael would not find an ambiguous because I meant to say for future and feedback protocols in other words if this fails what do existing accurate ACN servers do they\u0027ve got you know one of three choices till they do not ECN 3168 ACN or what they currently you know what they\u0027ve been coded to do which is that crew ECM when a client talks to her ACK only to an accurate easy answer but this isn\u0027t to you know any other server it\u0027s watching that creating server terrific gets a field that currently doesn\u0027t exist you know a value that the current doesn\u0027t exist that\u0027s all this questions ask people gory first and as TS vwg chair culture and this document is kind "
  },
  {
    "startTime": "00:35:37",
    "text": "of related to the l4s environment and it runs an experiment and L for us is an experiment so I\u0027m just kind of calling out that there are no two experiments which have some sort of dependency on each other and maybe this is necessary to have some form of ecn feedback for l4s to work so I understand this I\u0027m just asking for a comfort level amongst the editors and maybe most of the people saying that there are two experiments here just to clarify one point like there is a dependency from alpha s on equity Zn but not the other way around indeed that\u0027s why chemist es vwg char here to say you know we have a document set of documents that depend upon this and or something similar and did anybody come to the mic and scream I think if they have opinions then you should talk to David and I who are here at the idea and tell us if they are concerned about wearing these two experiments in parallel okay in the recent version we also updated based on a discussion from last time which was triggered by Praveen may sleep aid mainly and we try to clarify that the option is really optional and that also means in your depending use case you might have benefits and not even implementing it because that can optimize your code so we did change the wording a little bit to hopefully make this sure no clear no I mean yeah this is the wording or check the draft next slide and then the other discussion was triggered by you Chun who was favoring the DC TCP style feedback over and the feedback we are providing right now we had a lot of discussion about it and part of the problem is that the design we provide right now is probably more optimized for an internet scenario where you expect like a low number of congestion markings while in a datacenter scenario you might have a high number of congestion markings and therefore in some cases the data send the TCP feedback might be more optimal however the optimization really depends on the offloading you\u0027re implementing and there is a way to also optimize the offloading for equities and so we talked a little bit more about this in the draft but more importantly is also that there was at the hackathon there were people working on the accurate ECM page and working trying to get this in the kernel and at the same time also working on offloading and the problems we see with offloading we believe are mostly historical we don\u0027t even know how this got into the shoe and so they\u0027re trying to fix that and provide patch patches for that as well yeah and that\u0027s kind of half way what I already said so Olevia two months is working based on like my original type proof-of-concept implementation he\u0027s basically implementing a completely which is great "
  },
  {
    "startTime": "00:38:37",
    "text": "and he\u0027s bringing this into the kernel and the first step will actually bring it into the kernel without the option to really minimize the changes and we have to do in the kernel and then later on provide another patch to to have that the option part as a compiler option if you want to use it so that\u0027s ongoing I don\u0027t think the patch or the request to come has landed yet but should be this week probably yeah so in this case I think actually we have addressed all comments this draft has been around for a long while we heard that there\u0027s a dependency to a different working group so we really hope that we can move forward okay I\u0027m sorry any further comments first of all as we\u0027ve seen here on the line specifically lasts quite a bit on comments that are actually bought in planetary implementation details such as Jiro so that\u0027s why I wonder specifically to the implementers in this room do we have any further comments on the most recent version of the protocol or you feel comfortable is moving this forward so I\u0027m specifically asking people who own implementations in high pop risk are prevailing myself and a number a couple of other people are planning to get together to talk about this er issue this week so if anyone wants to talk about it get in touch and well maybe put it where we\u0027re going on the list yeah yeah anyway I mean I\u0027m seeing here on this slide that we probably will get an approximate update in any case so if there are any open issues under now we will probably see it in the next version anyway so maybe can you give me a show of hands how many of you have read the latest version or one of the earlier versions of this document so to the note-taker this is of the order of 10 people and specifically among those who have read the document is there anybody who has concerns in starting a working group last call relatively soon as I say after we\u0027ve see and we see in the next update addressing the minor remaining things so this would be an excellent opportunity to speak up okay so for the note-taker "
  },
  {
    "startTime": "00:41:39",
    "text": "so you have no concerns regarding studying and working coop last call so regarding the next step to the first of all I think we are waiting for an update even if it\u0027s small editorials things so that\u0027s definitely something that should be done and then other the chairs will check if we can start working group last call we can do this in that case anyway on the list so that doesn\u0027t have to wait for the next meeting okay and is that we have finished the working group items so we move on to the individual working documents here and I will stop myself so now I\u0027m now speaking from the presenter line and I\u0027d like to present a new document that has not been presented in T CPM before and it basically raises the question whether we have to start working on a young model for TCP so next slide please so the background of this work is mostly TCP implementations on embedded devices so that is something that in key CPM we actually hardly discuss because we focus a lot on the TCP stacks that run on hosts nonetheless obviously on a modern embedded device such as a router for example there\u0027s obviously a TCP stack and a big number of control and management plan protocols that run TCP including EGP and for example network management protocols and that means we do have TCP stacks on those devices and for those of you who happen to visit other areas in the IDF you probably have seen that there is a lot of work in other areas in other working groups in the IETF given by the fact that the management of devices moves from SNMP to net config yang that is something that has triggered a lot of work in the IETF outside transport area but there\u0027s one specific issue that now matters positively to this working group namely the fact that we do have a TCP map so it\u0027s standardized in RFC 4022 and I try to figure out who has implemented it so I\u0027ve found data sheets of at least three different devices from different vendors claiming that they have an implementation of that "
  },
  {
    "startTime": "00:44:41",
    "text": "myth now the IETF has decided to deprecated MIPS more or less or at least to move to a to net config as a superior technology and that now raises the questions of what happens with the management of TCP stacks on devices that will maybe at the moment is full manifest and peep at the management move is to net convey hang there is one candidate solution for devices that have used the myth and there is a way to translate a myth to a young module so there\u0027s an algorithm to do that and in fact I have found signs that vendors might even do that but of course that is a translation of a pretty old myth and if you check the details of that myth and you will see that it\u0027s a very old RPC actually which brings up the question if this is indeed the right thing to do and that\u0027s specifically the question I\u0027d like to raise here and I want to put up a disclaimer right from the beginning so this talk is really about devices that are managed by network management protocols such as net config a risk on seeing I\u0027m not necessarily speaking about an end host operating system here because thought you know very well that there are other means to configure TCP stack so I\u0027m talking here about devices that are natively managed by yang modules in order to analyze a bit little bit more detail what we have right now there and I\u0027ve put on the next slide the content of the TCP mmit but I decided not to use the map itself but instead to convert it to a young module I\u0027m not saying that this is a reasonable thing to do but it at least gives overview of what the TCP map originally has standardized and it also provides solution how a young model could hypothetically look like if we decided to standardize a young module for TCP you can see these auto-generated the immortal here or more specifically the tree version out of it so this is not there\u0027s no editing here it\u0027s an fully automatic convert a conversion of the TCP map and if you\u0027re a little bit familiar is the tree structure of your modules you can see here the key pieces that we have in this young module so the first important point to note is that most information in the TCP mate is weak only so actually it\u0027s mostly amid for monitoring there is hardly any configuration in that map except for one detail as if you go into another part of this slide you can see there\u0027s one read white attribute in the table there and this is supposed to be a means to reset "
  },
  {
    "startTime": "00:47:45",
    "text": "a TCP connection by resetting one of the table entries but in general it\u0027s read-only myth and it contains more or less four different sorts of entries first there is a little bit of information about the TCP configuration but it\u0027s limited to the configuration of the retransmission time mode most notably about the minimum time mode and if you look more detail but it\u0027s actually in the mid it\u0027s pretty outdated they\u0027re pretty outdated references to TCP is back there second the mid includes a number of stat counters for example on connection statistics and then there are two tables there\u0027s a connection table that basically lists the active connections of that device and there\u0027s a TCP listener table and that\u0027s basically what the myth is all about so we see it\u0027s a pretty simple myth after all and that is probably also one of the reasons why it might have being implemented since it\u0027s a relatively simple model and that obviously brings us to the question on the next slide so is this something that we have to care about and I have started this document mostly as a placeholder I mean I will not argue that this is something that can be adapted at that point in time but still if we look at what happens in other working groups how much effort is spent on designing young modules so there are to me there is a question in the room whether we need something in that space that is whether it makes sense to more seriously start working on a young model for TCP specifically as a successor of the myth I would note two observations as a first of all I believe that this world would be in scope of the TCP and charger because we have the wording in there that talks about interfaces that maintained his EP utilities this is the network management interface so I believe if we decided to do something in the longer run it would be in the Charter and second other IETF work in that space is to be standard strict which is we have a very pretty high bar here in in TCP my standards check and with that I think we have a question [Music] Michael Abraham\u0027s it\u0027s a less of a question or more of a statement actually so we are using that company Hank to manage everything we\u0027re trying to move in that direction where a mid administrating servers home routers core routers whatever most most of these things actually speak TCP I would like a comprehensive yang model so please do not just alter translate whatever we had "
  },
  {
    "startTime": "00:50:45",
    "text": "lying in the cupboard but a comprehensive work on typical settings that is available own devices okay that\u0027s a fair point I mean one of the things that we would I could offer is that I would try to reach out to vendors in that space because this is something obviously where we need input from vendors on what this set of typical things is of course we know and there are a couple of parameters that are pretty common for TCP configuration that are probably uniform but obviously that is something where typically as a vendor input would be highly appreciated but as I said one of the potential next steps what I could offer is that I reach out to people asking for input on that and then we can see if there\u0027s a chance for example to agree on such a set of parameters yes that is always the hard part but for instance every all the settings in the Linux kernel I can set using su CDL or /proc that would be something I would like to see in this model that when is related to TCP that\u0027s Laura Secord so I remember when we did the MIPS right because that was the cool thing that everybody needed to manage their networks and it was super painful because nobody actually cared and and and E steps was even more painful and than the basic MIT pride and so unless there\u0027s like a line of operators out the room that that screamed for this I would not want to do this simply because it\u0027s gonna be very very painful and very very hard and you know yeah you can say I want everything that\u0027s in Linux that snobs but that\u0027s Linux what about other operating systems right is there\u0027s almost no commonality even when you have TCP info between the different stacks right and amid poor yang model it\u0027s all about that level of abstraction it\u0027s exactly what made the MIT heart and it\u0027s gonna be exactly what makes this heart so so I would not want to do this unless somebody\u0027s really really really really really committed to doing this and getting like a bunch of operators that are another\u0027s to onboard well that is maybe not a challenge maybe somebody has volunteered to do the painful work exception is if there are others that want to share that pain so it\u0027s gonna be pain for the group for a long time like it was from its and and I won\u0027t want to share that pain so I think that we can find a balance this work I think that\u0027s something which is really interesting that can be useful it is useful because if we see some simple existing models we will say that they are catching on TCP stuff take for example the BGP ongoing yang model you will see that they are defining some generic TCP and parameters there so what personally I would like to see if you have something here anticipate that this are I would say our "
  },
  {
    "startTime": "00:53:46",
    "text": "first level bar in terms of the generic parameters that we we can use to tune the TCP stack for a sense it misses this kind of stuff and so on so this modules can reuse what you you can define here a generic I would say parameters for configure on TCP M so I provided the example of of BGP you know mono but you can can find other models in which they are touching exactly on the same stuff so instead of having something which is sprayed a monic among a list of yang model I prefer to have something which is ready I would say the reference not have everything as mentioned by thickness this one it will be really painful to have something which is already comprehensive from from day one just start with something which is really I would say balanced and then take the work from there I support this work thank you for doing that Michael Abramson again of course I\u0027ll take less if I actually get anything it is not an all-or-nothing proposition and I know there are a few people who like or the best thing that they know is to create the young model for management this has never been a sexy thing very few people enjoy it it\u0027s painful okay I\u0027ll give you that but there must be a bunch of like basic functionality the mouth most TCP stacks share I\u0027ve turned on soon cookies in a bunch of different operating systems so I mean there there must be at least like I don\u0027t know 30 50 parameters that is very common so we can start there that\u0027s a perfect first delivery just the knobs they\u0027re typically there in most operating systems and we can augment later it did it doesn\u0027t have to be perfect from day one and it\u0027s very to deliver something in six months and then another thing in a year more enhancements in a year just keep the pipeline going then to get a prayer to sit on it for four years until we think it\u0027s perfect so just to be clear I don\u0027t believe that we can ever come up with a very comprehensive model I\u0027m so because I mean TCP six do differ what is possibly doable is to it the basic knobs that directly map to aspects so a couple of things where we have an hour see that basically specifies that there is something that\u0027s optional that can be turned on and off and that is something that we can as we can see how how common that is among different implementations this will also in my opinion not be a comprehensive configuration because implementations do with things beyond that but this is something that\u0027s perfectly suited for commentation them yes comprehensive is always subjective and I\u0027d rather take less than nothing so I would like comprehensive but if I can\u0027t get that I would like as much as possible logically I want a pony so this is this is gonna be the same thing we did with "
  },
  {
    "startTime": "00:56:47",
    "text": "the MIT model right it\u0027s gonna get super complicated very quickly even with certain cookies but even like something very simple it changes from kernel version to kernel version potentially right it changes from operating system to operating system multiply this with all the different options and parameters we have that this is and and given that we don\u0027t have one now and we don\u0027t seem to have huge operational problems I really don\u0027t think we need to do this and and I don\u0027t know why the working group needs to do this given how very very painful it was for MIPS that you know everybody want it and then nobody used it well that\u0027s not true I mean as I said I\u0027ve found at least three implementations so there are implementations not in the Linux kernel of course so I\u0027m looking at this at the moment from the taps perspective and we will soon have four taps to define some way to set TCP specific options and I think having a yang model to import there and just say okay this is the list of properties we can import into taps and say these are the see specific options would be really really cool so but I\u0027m only seeing me from a consumer of that model and not as the one who was doing the hard work sorry Michael Jackson from before the step stuff isn\u0027t that connection specific so aren\u0027t you talking about parameters you wanna set on / transport connection thing because some of the stuff we are talking there is about his system-wide settings it is connection with specific but I think going that through that direction could also be interesting to see which of the settings of this Dieng model cannot be applied on a comet per connection basis and which can only be said as a system default so I think these are two different kinds of settings on different branches of a tree which might make sense to say okay these are connection specific settings and these are settings that are globally for the system this makes the game more complex so I think a lot of implementations have the capability to tune several prompt tcp parameters system-wide but if it comes to soccer options it\u0027s much more diverse and much unless stable I mean soccer options come much faster than just Contras okay so as I said before I mean at the moment this is a placeholder so we don\u0027t have to come to come to come to a conclusion in this meeting so technically I think we can decide to do it these four things here in this working group the first thing is what "
  },
  {
    "startTime": "00:59:48",
    "text": "laws has just suggested to do nothing the other two options you have also discussed the could either do a young model that\u0027s relatively basic similar to the mid probably mostly read-only or we can try to do something more comprehensive and of course we I totally agree it\u0027s easy to do an to boil the ocean in yang models and so it can get painful you all know that my proposal is I would want you to have a second talk on that maybe in the next IDF meeting with some additional insight on my site so that would be my offer to this working group but if the working who believes that you should stop this activity just right now then I will also be fine so that is if you in particular if you believe that I should not invest any further cycles on that so it would be perfect to say that no perhaps you want to say something yeah not about this thing I just wanted to give him before the next talk okay so I think it\u0027s still an individual contribution so you can do whatever you want all right but I got but the feedback I got or the impression I got is if you can reach out to come operators and figure out if there is if there is a need for using this stuff then it might help us to address the concerns raised by loss I mean we had positive and negative in if we can figure out if we will have consumers of this work then you might make a positive decision then I won\u0027t see thank you and it\u0027s an intro by Bob yeah at the end of mayor\u0027s talk there was one slide there was an announcement about the other working group draft I\u0027m working on which is the ec n plus plus one and a bit of miscommunication that I asked if you could just have a minute on it sorry about that in details but there was a miscommunication on the next one there\u0027s only one most like just as if you can move on to the next one the last Singapore I guess it was talked a lot about this problem where this whole this whole draft seemed to be completely destroyed because we discovered 84 percent of servers around the world turn off ECM if you set ect on the sin since "
  },
  {
    "startTime": "01:02:50",
    "text": "work out the solution written the patch it\u0027s gone into the limped mainline pipeline Bentham feed bang come out and gone back in again but basically we\u0027ve worked our way so that when you set easy on the sin if you\u0027re using accurate ACN or any future protocol that might replace it the test that turns obviously and won\u0027t happen it will only happen if it\u0027s a an old PCN setup sin so just that\u0027s just a one-line change and so we\u0027re hoping that we\u0027ll get back ported as far back as possible as quickly as possible get also updated and a lot of the problem will go away but we\u0027ll see how much when we measure it in a couple years time maybe any comments if not then we\u0027re up to yes so thanks I\u0027m I\u0027m doing whistles this is a presentation about a draft with co-author John Kristoff I like to thank the chairs for inviting me to come and present this this is work that\u0027s really in the DNS op working group so I don\u0027t normally participate in in TCM but I hope you find this at least a little bit interesting here\u0027s here\u0027s the abstract from from the draft and it talks about how this is a document that\u0027s about encouraging operators to permit DNS over TCP and describe some of the problems that can be encountered if if that is not done next please so a little bit of how we got to this point going back to our C 11:23 it talks about DNS talks about UDP and TCP it says you know servers resolvers and servers must support you to be and should support TCP for for non don\u0027t transfer queries later RFC says that UDP is the chosen the preferred protocol although TCP is used for zone transfers so after this point of time it sort of became folklore that that you know most DNS occurs over UDP and TCP is really only used for zone transfers and and we find cases where it\u0027s blocked in firewalls where you know you would not expect some transfers to occur things like that in the late 1990s DNS started having things happen to it like DNS SEC and Idina 0 and 2010 RC 59 66 starts to address these misconceptions that have cropped up over time but this RFC goes a little bit unnoticed and really kind of "
  },
  {
    "startTime": "01:05:50",
    "text": "didn\u0027t go far enough so next slide so the reality is when in DNS if you have to deal with large responses sort of bigger than MTU size your choice is either to fragment or to truncate and we see problems in both cases fragments or sometimes blocked by firewalls and if you truncate then it leads to TCP and TCP / DNS is also sometimes blocked by firewalls and of course it adds latency and so on so the situation that we\u0027re now is that DNS clients have a lot of complex retry logic to try to work out you know work through all these problems they\u0027ll do things like retrying their queries with different Adina\u0027s buffer sizes to to try to find the the point at which their queries are able to succeed next please so RFC 77 66 was was written to update the older 59 66 this is an in RFC that\u0027s all about implementation requirements for DNS over TCP does not make any recommendations to operators but it talks about things listed here it talks about how all implementations must support UDP and TCP it says that resolvers or clients may elect to use TCP first without without trying UDP it recommends and and to keep idle connections open for the order of seconds or as the old RFC said you know two minutes says the servers can impose limits on the number of TCP connections and devices clients to be prepared to handle out of order responses next please so this draft that we\u0027re talking about today is sort of a companion to that whereas the other one is about implementation requirements this one is about operational requirements and the idea is to you know encourage operators to be aware of these issues and ensure that DNS over TCP is handled equivalently as as a distant UDP so it says a lot of these bullets here just cut and pasted from from the draft and you know says authoritative servers must service TCP queries for these reasons and recursive servers must service TCP queries for similar reasons talks about nameservers may need to limit resources devoted to TCP but must not refuse to service query just because it would have succeeded over some other transport protocol it has a lot to say about how filtering of DNS over TCP is is harmful and in general case also recognizing that there may be you know local policy cases where you would need to do some of that kind of filtering and it says that network operators must allow DNS service over both UDP and TCP so getting it to a little bit more detail there there are different sections in the draft that talk about for example first about connection "
  },
  {
    "startTime": "01:08:50",
    "text": "admission it mentions that syn cookies are effective in mitigating syn flood attacks that services intended for use by anyone should be protected or I\u0027m sorry not not intended for use by by the public should be protected with access controls specifically medicine mentions this except filter in FreeBSD operating system applications must not be configured to refuse TCP queries that were not preceded by UDP so getting back to that earlier point about it\u0027s allowed to use TCP first and there\u0027s a couple of recommendations about fast open so servers should enable fast open when possible clients should enable faster than what\u0027s possible and so on so on connection management there\u0027s quite a bit to say that you know says servers must actively manage their connections you know to avoid avoid resource exhaustion server software can provide limits on the total number of established connections and as an operator sort of ear job to make sure that those limits are appropriate server software may provide a limit on the number of connections per source IP address or per subnet the software should provide a configurable timeout for idle connections and that clients and servers should signal their timeouts with a DNS TCP keepalive option which is an RFC the software may provide limits on the number of transactions per connection and may provide limits on the total duration of a TCP connection and it has a little bit to say about terminating TCP connections importantly it says that it\u0027s preferable for clients to initiate close of TCP connection but on systems where a lot of connections are observed in the time weight State it may be beneficial to tune the local TCP parameters to keep that sort of manageable in an extreme cases it may be necessary to use the so linger option with a value of 0 to prevent those connections accumulating and a few less miscellaneous points the recommendations in this draft apply equally to DNS over TLS which is RFC 70 at 58 as they do to just DNS over TCP this draft does not make any references to DNS over HTTP at this time at least and a few points about logging and monitoring that implementers need to be aware of you know that TCP makes this a little bit harder you know don\u0027t ignore things like connection reuse and pipelining and out-of-order responses and so on and that\u0027s basically the rundown of the draft happy to take any questions if you "
  },
  {
    "startTime": "01:11:50",
    "text": "have any or suggestions is there any like study or large-scale measurement on like how prevalent is a research support for pianist over TCP are you aware of any you\u0027re asking if there\u0027s any studies about the current the current levels of use of DNS over TCP there probably are I I know that so I was a co-author on the DNS over TLS documents and associated with out there was a study sort of theorizing how you know what it would look like if there was a lot more DNS over TLS and I and I think as a part of that there may be some some background on what what are the current levels of DNS over TLS I can tell you for that some of the systems that you know that I get to interact with it\u0027s on the order of one or two percent of the total traffic is coming in over TCP versus UDP follow-up question so you said there was a recommendation that the implementation may choose to use TCP first is there any sort of recommendation about some some algorithms similar to happy eyeballs where DNS queries could be raised over TCP now there\u0027s no recommendation specifically about that it just it just says that it\u0027s you know it\u0027s up to the clients choice it doesn\u0027t mention happy eyeballs by name but I think you know certainly expectation is that if if you\u0027re if you\u0027re doing the NS over TCP and if you have that connection already set up then it makes sense to reuse that connection rather than say go back to UDP years thank you Tommy poly Apple so thanks for doing this I think this is a useful thing to encourage people to do and support more so that\u0027s nice to see just two comments one so I\u0027m glad that you\u0027re saying that the server should support TFO I was a little bit more concerned about saying that all the DNS clients should do TFO I\u0027m me it may be good to like soften that to a may just because you know there are some issues with deployment and this is oftentimes for clients at rare enough case that they actually are using TCP that if we\u0027re doing TFO in those cases it may not get tested as much of they may not notice the edge cases until they\u0027d break in certain deployments okay or so so at this time you would suggest may instead of a should for that but in the future things might get better and right hopefully yes things all be rosy and maybe we\u0027ll hear more from Praveen hey so that was my comment there on the other company was it was surprising to me how much the DNS over TLS references were kind of buried near the end it may be good to just say that up front such that it\u0027s very obvious from the intro of "
  },
  {
    "startTime": "01:14:51",
    "text": "the abstract that this applies across the board because I think as people are looking towards going to DNS over TLS they should be aware that they should take these things into account okay yeah thank you regarding the tier 4 problems I think like the trend seems to be that the operating systems are building and fallback mechanism so the app should ideally be unaware of or be able to use the API freely without having to worry about yeah so even if we recommend should I think there should be a caveat there saying there are known issues with tier 4 which are being resolved so some experimental should be done before rolling out to change so it might be worth adding some texts this will be saying that you know like clients should feel comfortable when abling TFO because our solution yes yes but we should have a caveat there saying that it should be they should measure before they roll out the change the location should measure yes is that something the application can measure when I say application I mean the DNS resolver it could be wherever it could be in the browser or the operating system okay general I\u0027ll push back against that gently to say that yeah don\u0027t punish it it\u0027s it\u0027s it\u0027s not because I don\u0027t think applications can measure it I just don\u0027t think that the people who are building this always have the expertise to understand the failure modes of TCP fast open they\u0027re very subtle and and you know we\u0027re trying we are discussing them trying to figure out how to how to work around those and you know hopefully so then later they will be part of the default behavior in Mac OS and Linux and Windows when that happens it\u0027ll naturally be available so you might say we are available in the underlying platform clients should use it or may use it so I was I\u0027d say me not you you would advocate for me at this time absolutely thank you okay so thanks a lot for these presentations obviously this is not a tea CPM working group document but they thought it would be useful to discuss it here and I think you also got some useful feedback thank you so thanks a lot and this that we would move forward to the next talk that it\u0027s also not about it is TCP and working group documents or please praveen this continuous kind of the series of talks have been doing about what we are doing with improving TCP in the windows networking stack work done with others so this is a quick recap of all the advancement we have recently done the good news is that it\u0027s all these improvements are now on about 800 million plus machines TCP is evolving on the Internet so IW 10 was made the default for all TCP connections the current loss recovery mechanism is rack which I will "
  },
  {
    "startTime": "01:17:51",
    "text": "touch upon later in this talk so rack Australis probe cubic congestion control is now default on all these systems for all outgoing connections tcp faster one is limit is enable for limited websites on the edge browser with aggressive fallback it\u0027s still there still mailbox issues so the operating system API internally has logic to fallback the connection to regular TCP if there are any problems experience with Tier four if you are interested in the details of that algorithm I have done a previous talk in TCP M which has the algorithm led by plus process a new congestion control which I also presented in nice energy I think three IDs back this is also enabled only for limited scenarios currently any kind of background transfers like crash number pods or Windows updates the DL attack timeout was reduced to 40 milliseconds traditionally it used to be 200 milliseconds this puts Windows on par with what Linux is doing this I think over the long term will help a lot because currently the tailless probe algorithm requires you to account for the worst case delay rack time or which is 200 milliseconds in time we hope that we will be able to reduce that to 40 the windows implementation always followed appropriate byte counting so because it does not look pacing the limit was for MSS worth of condition low growth per rack and that has been increased to 8 on the server side we have rolled out cubic and TFO for all the Microsoft online services so this is again much easier to roll out on the server side so that is currently supported on the Internet I meant to ask you this earlier but when did you when we changed from compound to cubic that happened about I think a year and a half back and now is default for all our bond connections we have any data comparing the two like you know what did he ever talk about why it is that he chose to go to cubic yes so I actually talked about that previously but to recap what the problem was that compound was very delay sensitive and we were finding that especially in the virtualized environment because there is another set of hops that you go through in the host there were a lot of latency fluctuations that would throw off compound and have it react very negatively to increase delay and we found that cubic performs better we understand that compound was more well behaved in terms of buffer bloat because it would back off and the roasted latency increase but in terms of raw performance especially when you\u0027re let\u0027s say copying large files across two regions Cuba could consistently win of course there is increased latency but in terms of throughput cubing did better "
  },
  {
    "startTime": "01:20:57",
    "text": "so we have improved how slow-start works in Windows starting with hybrid slow start so previously when time stands were disabled which is the default configuration of the Windows Network stack the network stack was only collecting one IDT sample per round but for high start to be implemented effectively we made a change to collect more RTT samples per wrong this has a little bit of performance overhead but this was necessary for us to be able to implement high stuff the the portion of high start with that we chose to implement was the delay increase alpha rhythm the inter packet arrival algorithm when we experimented with it was not behaving as expected because of LRO as well as the fact that Windows has always done stretch acting I have put in the parameters that were using they\u0027re very similar to what was in the paper but we found that high start actually exits prematurely so especially when testing over by filings or when there\u0027s congestion in the network I start would exit very quickly leaving us at a very small congestion window and immediately entering congestion avoidance so we implemented limited slow start immediately after heist returns so what limited slow start is is a less aggressive form of supposed route it comes from our SCS and it\u0027s three seven four two but that RFC talked about going limited slow start right from the start so what we find was a max ssthresh parameter and the recommendation there was like hundred the value of 100 MSS but what we do we are doing here is that if we do exit slow start too early we\u0027re doing limit or slow start because then the condition window ramp remains at least a little bit more aggressive than what you would have in condition avoidance we test this and we find this to work the best amongst all the various experiments we did for modifying slow start we did choose to modify a parameter from that RSC so the K value was computed using point Phi which means that you know at most MSS by two growth rack we modified that 2.25 so at most passers-by for growth track these these two algorithms are currently only limited to the initial slow start we don\u0027t do this after timeout because we believe that we would have already found a good ssthresh value when we previously approved the network should I just wait unto the end if ever question is about this you can go ahead and ask ok so this is super interesting I believe that Linux actually does have but somebody else has to do to verify that but but did you find that just leaving it at regular slow start after you exit what did what happened when you "
  },
  {
    "startTime": "01:23:57",
    "text": "did that so so at the end of high story inter congestion awareness immediately right so that occurs so that problem is then that if we exit to early life like the min cab there is like 16 MSS is the ssthresh gap and I start so if if a well is higher than that you could exit very early and then you could have ample capacity and just because of congestion you you know you exited too early and then we find that limited slow start allows you to catch up it\u0027s not as good as as fast or slow start but is still better oh I see so you\u0027re leaving the inter packet arrival there you\u0027re leaving you remove the inter packet yeah the interpret of arrival is not implement it is only delay increase so you spot deal increase you exit slow start your inter condition avoidance but you might have exited too early so doing high start with only delay and then you\u0027re doing little slow start and then because we could have exited incorrectly so we\u0027re making up for that using LS s and LS is less accuracy we find that it doesn\u0027t cause time outs to the regular slow start without hi stars would just cost time option C but but Alice\u0027s will keep going up until there\u0027s loss its usual yes but the advantage is that we find that with LS s it\u0027s not a timeout it will do pack bears recovery just works got it I see I presumably the loss rate also goes down with LS s yes that\u0027s probably natural okay thank you just to clarify that this was all of this is done without pacing so I we have not done any measurements on how this would behave with pacing did he do any measurements in the wild or is this lab measurements these measurements were done in the lab and then we collected data about time outs out for slow start and you got it so things are better now thank you it\u0027s like so Rach currently the implementation is compliant with rack which means it follows pretty much all the recommendations in that draft this is done in congestion in conjunction with the traditional packet based measurement which was you know the three do pack threshold so that portion of that allows detection logic has not been removed there are some portions of the RFC that are not yet implemented so there is ad fact-based dynamic reorder window that there are documents which is not implemented but there\u0027s also reordering setting time or that can be used which we are not currently doing there\u0027s an optimization to be able to sort the send packets in time order the reason we don\u0027t do this yet is because we don\u0027t currently have the ability to read it read transmittal a story transmits and if you want to do that then the RFC recommends that you keep a list sorted and time order so these are two optimizations we are looking forward to do next but it\u0027s currently not implemented unfortunately the draft status seems to be expired so my request to the authors and the working group would be to move this draft forward because this has pretty broad implementation and "
  },
  {
    "startTime": "01:26:57",
    "text": "deployment at this point and I think it\u0027s a very fundamental and important out of C that should be published a standard struck here in a quick question how does reckon they\u0027re both complementary mechanisms you can leave both in place so as long as three to paksy you gave you you could get like sack information that tells you that there is three more than three degree of reordering my question was how are you using right now as in which one comes first or smooth or enabled if you have how what detects laws the the packet based on automatically happens when you receive sac information from the network so it will immediately enter loss recovery if the loop delicious exceeded in the time based implementation yes we currently don\u0027t have a timer but that is also triggered by sacking or ACK information but you may not have crossed the to thresh for example and do you is do you have three do packs or you have n do packs where you know so there is no dynamic reordering it\u0027s currently set as three two packs the the only data I have additional is that we mistakenly load it to two and we find that we found that it broke a bunch of networks so clearly people have sort of adapted themselves to our TCP has been doing thanks I have a speaking as chair have a quick question on the last comment in relation to the other points the dimensions here so are you fine with the exact wording of the text or do you think that they are change is needed for example regarding the things that you decided not to implement so we had a bunch of feedback on the working group I think there was one more set of feedback that came on the working group about the draft and and those were supposed to be fixed it\u0027s unfortunate that it was not published but I believe the changes were made and the private working copy or something in terms of text I do think that they probably need to be a little bit more work but in terms of the algorithm I think it look looks good those things that are not implemented or specifically called out as nay so those are just optimizations but all the shows are implemented okay have you looked at yeah so we are currently looking at mirror to avoid the burst losses during recovery Felix following University of Applied Sciences since you\u0027re using both loss detection algorithms do you have any mystic data when do pack is badder than rack unfortunately then it will have to be either/or then we can do an a/b experiment but currently it\u0027s just an "
  },
  {
    "startTime": "01:29:58",
    "text": "addendum I believe that the Linux stack has moved away from packet based detection completely onto rack but I\u0027m not completely sure we would like to do that in the future where currently we are keeping the so sorry I don\u0027t have data to say which one is better or whether removing the toothbrush causes any problems because we haven\u0027t done that yet Thank You Randall Stewart Netflix I have an answer for him in our implementation I have noted that there are times that middle boxes allow the sack to be negotiated but strip ballsacks out and so when that occurs the do packs are very useful not too often very rare but it does happen that\u0027s a great point yeah well next slide please so the initial RTO as traditionally was always at three seconds so and the tin sintering retransmissions were capped at two so the total time out for TCP would typically end up being 21 seconds so we are now lowered the initial RTO to like one second by d4 which is the RFC defined minimum the total time order still kept its 21 so it ends up being more retransmissions but this was done for app compat reasons the other thing I would like to point out is it previously if this change has been done for a while but previously you know some of the options like window scaling would get removed when there was simply retransmissions but currently the only option that we remove if there are same retransmissions is TFO so the other thing I would like to say is that there\u0027s also an API for applications to set more aggressive timeout values if they so desire and there is a global configuration as well general anger so yet this is this is great I was actually going to ask you if if you have any way to reduce it little one second but have you done any experiments to see what happens when you do it better one second no so we there is a nod that is both an A P I and a global knob to lower it below I think we allow you to go down to like 300 milliseconds but no by default we amendment down in X by much lower it further the problem is there is application I can lower it but I don\u0027t have any way of measuring whether that caused retransmissions or not that\u0027s a fair point yeah but in terms of the API we are assuming that the application would do their testing before making such a change from the operating system point of view one second seems like the safe value there is cases for example where if you had if you had previous path RTT measurements we could actually were lower because I mean even if there is even if you\u0027re taking different paths to the same destination if we could have a ballpark value like I mean you could have a function of like 2x or 3x the the max or TT use on the previous connection but currently we don\u0027t implement that optimisation right so just going back to "
  },
  {
    "startTime": "01:32:58",
    "text": "the question I appreciate that as there\u0027s there\u0027s definitely value in exposing the knob to an application that might have information but if I was to do an experiment with this I wouldn\u0027t know how to do it on Windows because I would on the experimental as an application I couldn\u0027t actually gather information about the number of free transmissions that wasn\u0027t oh now you can because there is a TCP info socket option API so you can actually gather statistics on the connection after the connection is done oh thank you that\u0027s it any other questions Michael Abramson again um ECM support what you\u0027re thinking there I think it\u0027s still off everybody fault right don\u0027t easy a non client is off by default on server it\u0027s been on by default for a while okay so server for outbound connections which is rare but you could assume like introducing scenarios where servers are talking to each other ECM is it\u0027s negotiated but for clients it\u0027s currently off are you considering what your thinking on changing the default on the clients so currently we are trying to experiment with TFO so that\u0027s the reason we have not for the bzm it\u0027s something we are interested in doing in the future but currently because the network doesn\u0027t support there\u0027s not a lot of like easy and marking actually happening on the network so the I mean it\u0027s being an operator I have a hard time getting it turned on because people are saying nothing nobody\u0027s using it the second one is um I know I know but Windows is still kind of a large ish layer in the area the the second thing this is relate to the Xbox stack as well yeah so the same network stack runs everywhere like Xbox well and PCs servers everything right so the Xbox is basically a normal Windows client when it comes to the settings and the choice of GCP algorithms and all that huh okay thanks ok so thanks a lot for his total you\u0027re hearing your comment on the REC one so the chairs will talk is the others on what to do and be well do from us um but things look for is very useful information thank you and this dead we will stop talking about TCP and looking at an alien technology but still I mean the charter of TCP actually allows us to think from time to time about algorithms that I use elsewhere and that\u0027s why we thought it\u0027s good to have Janna here talking about some of the algorithms used in quickly so I have no access and apparently this "
  },
  {
    "startTime": "01:35:58",
    "text": "is alien technology so prepare yourselves people just go back one slide so so this is a continuing series of discussing quick loss recovery speeds super weird is there a pink box here am I supposed to be in a pink box yeah okay fine Oh God and we have a German for a chair too so that helps alright so this is a continuing series of discussing quick loss recovery in TCP M and the hope here is to is to get more people in this community engaged in the in then the recovery draft and the discussion of loss recovery in DCP so this is again the intent here is to is to give you a sense for what\u0027s going on there it\u0027s less to litigate the constants and various things here in this room there\u0027s going to be significant discussion on the recovery draft basically a one-hour discussion tomorrow on the quick working group so please show up there and litigate all of these points there or file an issue that\u0027s even better I\u0027m going to start off very quickly with a rundown off basically what quick is again this is for those of you who\u0027ve been hiding under a rock for the last two years no actually this is for those of you who know about quake but don\u0027t know the details of what\u0027s going on in quake so don\u0027t feel too bad if if you find yourself being educated through these slides so quick the quick packet format itself is different than PCBs so it\u0027s important to sort of change your more of thinking a little bit which might which might lend credence to Michael\u0027s comment about oh my god it\u0027s - Michaels I forgot that about alien technology so the first is quick has two types of headers a quick packet has two types of headers there\u0027s a long header and a short header next the long header looks like this it has many bits and it has a version in it it has connection ID is connection any lengths I\u0027m not going to go to the details here but the high order bit is that this header is used during the handshake and handshake only it\u0027s used for establishing a connection after the handshake next line the connection moves on to using the shot header and it\u0027s short because it is short and it has only few fields and those are like the lengths of those fields are negotiated during the handshake and so this can be super short so it\u0027s basically a way of only only having information in the header that\u0027s required for the rest of the communication I\u0027m not going to talk about what part here is encrypted and what\u0027s not because that\u0027s not relevant to our discussion here today but moving along what else is in the packet frames "
  },
  {
    "startTime": "01:38:58",
    "text": "if you\u0027ve seen a CDP think chunks but say frames next slide there\u0027s frames are of different types frames come in many different flavors and each frame has its own set of fields next and here are all the different frame types beat them all I will quiz you at the end it\u0027s alright you have to read them all just know these two next slide the AK and the stream frame you don\u0027t have to just know these two these two are most relevant again for our discussion today there are many other frames again understand that the way this works is if you\u0027re familiar the city it\u0027s quite similar to that but if you don\u0027t it doesn\u0027t matter the idea here is that most of the control information in the protocol is basically sent via these different types of frames and they are not all sent in the packet header the packet header is merely a way to find the destination for the packet the rest of it is basically inside of control frames so the stream frame is the thing that actually carries application data the ACK frame is the thing that carries acknowledgment information we look at these in a little bit more detail next slide so here\u0027s what a screen frame looks like a quick connection first off just for context a quick connection can have multiple streams and every stream has a stream ID loss recovery congestion control all of these things are aggregated across the entire bundle of the connection meaning across all streams but every stream has and within that every stream has a stream ID and within the stream ID a particular frame a stream frame carries a piece of data within a stream ID and that piece is identified by the offset within that stream all right so the stream I readers of the length is the length of that particular stream frame and then the stream data next so here\u0027s an example of what a quick packet might look like the header bit is one what type of header is this pop quiz you all fail it\u0027s about some of you bus it\u0027s a short header don\u0027t but I do only there are two types of headers the first bit in there indicates what type of header this is that bit being one means it\u0027s a short header and then there are other bits in there which I\u0027m not going to go into but these are all again in the in the short header but one thing you\u0027ll note there is there\u0027s a packet number the packet number is basically again we\u0027ll talk about it in a moment but the packet number is the thing that we use for the entire packet next line within a packet you may recall that there are different frames in this example there are two stream frames and one ACK frame why are there two stream frames you may ask next like let\u0027s say for example that here\u0027s a real example the packet number is 56 the first stream "
  },
  {
    "startTime": "01:41:59",
    "text": "frame is from stream ID five it has an offset of 11 23 because that\u0027s a nice even number and there\u0027s data there\u0027s application data on stream ID 5 all right but this packet can carry more streams than just one next slide as in this example you can see that this packet carries not just data from stream ID 5 it also carries data from stream ID 8 this is lovely if you want to tie the faith\u0027s of stream 5 \u0026 8 together but in general you may not want to do that that said you can do this so there are different stream frames in the same packet here stream ID Nate and stream ID 5 and there\u0027s application later on both of these and this is all in the same quick packet so that\u0027s for stream frames next slide and here\u0027s what an ACK frame looks like so this is important a little bit if you want to understand there is soft what I\u0027m going to talk about with loss recovery today so pay attention to this just a little bit if you not been paying attention so far we have the largest acknowledged and so the Akram has basically a few fields right it has the largest acknowledged frame the Rogers knowledge field I\u0027m sorry and that basically indicates the highest packet number seen so far note that while your PCP brain not your alien brain your TCP brain might want to think of this as a cumulative ACT point it is in fact not this is not the highest packet number seen so far that has been received in sequence this is merely the highest packet number seen so far so this maps to the highest end at the farthest end of the father sack block that you have received so far this is the highest packet number I\u0027ve seen so far there may be gaps below this okay it\u0027s an important switch to turn to change in your in your head a little bit we also in quake explicitly encode the AG delay this is basically encoding the time since the largest 1/4 C was received the idea here is to capture the amount of time that the receiver is sitting on an acknowledgment before sending it back if you understand one of the problems with the RTD measurements and in TCP is that we don\u0027t know how much of that time was spent at the receiver which was delaying the acknowledgment before sending it back and this basically encodes that directly into the ACK frame so that sender can make a more accurate RTP estimate it can remove receiver delays from it and blow that or AK ranges and this is basically the the discontiguous ranges below the largest acknowledged much like sag blocks all right is that good everybody any questions anybody\u0027s still paying attention again the same to people what is going on in this room there\u0027s food up front by the "
  },
  {
    "startTime": "01:45:01",
    "text": "way all right let\u0027s move on to the next slide that\u0027s that\u0027s basically the ACT frame and now we get to the fun part of this this is your test I am NOT going to go into the details here actually but this is just showing you how a particular packetization how a particular encoding of an AK frame might look like and these details are you can look at the slides later to get a sense for exactly how this happens but as long as you understand the different fields and things that we are putting in the AK frame that\u0027s adequate for our discussion today so next slide and there\u0027s an example of the same quick packet with a particular act frame in this particular example okay so again remember the largest act that is the highest packet number I\u0027ve seen so far and and that\u0027s about it next slide now this is this is another example I\u0027m going to move past this next slide next slide and next slide and now we get to the more interesting example of loss let\u0027s assume that the packet we were just you know creating back at 56 is in fact dropped in the network also let\u0027s assume that stream 8 was reset why because it\u0027s possible quick allows you to reset screams remember I told you that streams are things within a connection you can reset streams so let\u0027s assume that reset stream eight was reset meaning that the application says I do not care about the data on the stream anymore to send it or to receive it in both directions it\u0027s done kill it and let\u0027s say that the loss addiction dead except Bacchus 56 was lost okay meaning that through whatever mechanism and then we\u0027ll talk about the mechanisms in a moment 56 is marked as lost and let\u0027s say to the last packet that I sent out was packet number 74 okay I\u0027ve been sending packets out 56 was sent I sent out 71 72 73 74 and then I detected 56 as lost that\u0027s where we are stream eight has also been canceled next slide so going back to looking at packed at 56 there\u0027s the packet header should be retransmit everything here come on speak up I know it\u0027s post-lunch no say people nobody says yes this is a room that knows what I\u0027m about to show good should be Bob don\u0027t pick that up now stream ID 5 the first stream frame should be return outs with that yes says somebody in the back and it\u0027s Randall should be retransmit stream ID 8 why not because it was reset excellent you\u0027re all on page on the same page "
  },
  {
    "startTime": "01:48:01",
    "text": "soviet as with the action confusion no we don\u0027t need to we may want to send a new AK frame we don\u0027t read ants with the same one and you get brownie points whoever this was I don\u0027t know it was yeah there we go okay you get brownie points you get a strawberry and what do we do so next slide so we don\u0027t read us with those things and we send a retransmission in an in packet number 75 not 56 75 it\u0027s not TCP it\u0027s alien technology so the point here is that we\u0027re selling a new packet with retransmitted information in it we may not return submit everything we may in fact choose to not retransmitting anything at all if stream 5 was even cancelled that\u0027s nothing to retransmit you detected loss but there\u0027s nothing to eat transmitted right and I can add I can choose not to retransmit 5 right now either we\u0027ll get to that in a second but I hope this general gist is clear next slide so loss recovery it looks like this the packet numbers in quick basically represent transmission order these are this basically the premise of quicks loss recovery right so packets the reply packet numbers represent transmission order they do not however represent the order in which the receiver expects to receive them this is a critical difference remember than TCP receive order and send order are basically the same delivery order and send order are basically the same sequence number but here not so that it\u0027s that\u0027s all the case so stream IDs and offsets within stream frames are what are used for detect for for delivery order meaning that a receiving quick implementation will deliver data up to the application based on the stream ID and the stream offset as long as the stream offset is in line with everything that is expected within that stream that data can get delivered this has nothing to do with the packet number packet numbers and quick are simply moronically increasing packet numbers they do not occur again and this is in fact fundamental to the security of the protocol itself but we won\u0027t go there the point here is that packet number 56 once it\u0027s dropped will not reappear within that connection okay that\u0027s important and finally there\u0027s a caveat about multiple packet number spaces you\u0027re in connection setup I\u0027m not going to go there so packets are basically containers they carry various things various frames and packets are simply containers it\u0027s a really nice thing to be able to divorce that from the way that that stream data\u0027s delivered because for loss recovery I really only care about packet the the what\u0027s in the packet because the unit of drop is a packet and the unit of ordering is a packet from my point of view transmission ordering and that\u0027s useful for me as a sender pair in mind "
  },
  {
    "startTime": "01:51:01",
    "text": "how that retransmissions are not automatically high priority as I said stream 5 need not be retransmitted right now even though I\u0027ve detected it has lost my stream priorities which are application dependent might dictate that stream 5 is the lowest priority thing right now so don\u0027t use any condition any connection bandwidth for sending stream 5 data as long as you have stream 10 data to send so it\u0027s possible that I don\u0027t retransmit right now so we also have to divorce what happens to the congestion window and to loss detection from what is in fact transmitted when loss is detected this is different again from DC okay next slide on generating AG frames we basically follows similar guidelines to TCB except that constants are slightly different there\u0027s a deli rack timer that that is currently recommended at 25 milliseconds meaning that you act every other packet that\u0027s received that is a bit of a ordering thing here where if the received packet is not the largest received plus one then you act every packet that\u0027s not that\u0027s that\u0027s recommended again based on just standard PCB behavior so there is an expectation of ordering here to some extent but a receiver is also free to process more acts before sending more packets before sending it back there\u0027s no strict requirement that it must send an act for every two packets that are received this is to allow receivers and send us in fact as well to experiment with this in fact there\u0027s been there\u0027s an issue open on trying to figure out if we can\u0027t make this something that\u0027s negotiated between the sender and the receiver and made more dynamic that\u0027s a question coming up Eric Cline 25 milliseconds is a fixed number or is it actually a function of measurements of latency and like connection um it\u0027s a oh no it\u0027s a fixed number in the draft it\u0027s a delayed acknowledgment timer for 25 milliseconds okay so for high latency sorry what for a high latency connection or for a long path this is again five millisecond timer right it just kicked all the time so do you know what if I\u0027m gonna say no no because to confirm a seconds is about how long of time how how much time is how much time passes between packets that are received it\u0027s not so much about this is you know the delay rack timer this is not the RTO timer right so so it\u0027s more about inter packet arrival times thanks yeah so so now we get into the meat of this conversation fifteen minutes into this presentation because that\u0027s when it all happens right crystal quick loss detection I\u0027m going to walk through sort of what what current loss detection is now this is has come through a number of changes to the draft and if you show up tomorrow to the meeting you\u0027ll hear and talk about "
  },
  {
    "startTime": "01:54:02",
    "text": "what\u0027s changed in the past four months and and there\u0027s a fair amount of change that\u0027s happened over the past four months what I\u0027m gonna describe here is the current state of the draft okay this is draft 19 so the weight loss direction works is that a high-level loss detection only happens when an act frame is received again that\u0027s a promise this is an important promise and you\u0027ll see one in a moment meaning that when we receive an act frame that nearly acknowledges a packet then we use two different kinds of thresholds packet and time thresholds to detect a packet the packet that was sent previously as lost the packet threshold means that if I see the ordering of greater than equal to three packets this is the same as TCB\u0027s three do pack thing basically if I see a packet that is acknowledged that\u0027s three packets ahead of where this missing packet is then we mark this packet has lost or the time threshold this is similar to Rach again where if I receive one packet ahead at least one packet ahead of the packet I\u0027m looking at I\u0027m considering but enough time has passed since I sent the packet and enough time here is this particular value then I mark that packet has lost okay so there\u0027s time based and packet based packet threshold based in time threshold based loss detection both of them operating at the same time so that\u0027s how loss detection works and I say this is our lost addiction works you\u0027ll see that this is broader than how it\u0027s done in TCP in a moment next slide when no acknowledgments had a seat however so that that works well and fine as long as you\u0027re racing acknowledgments when the knackers receipt I can do loss detection but what if no ICA\u0027s receipt what we do is we set a timer called a probe timeout a probe timer and when the probe time what happens you simply send packets out you send one or two packets that\u0027s what a sender does when the probe timer goes off and the probe timer is set like so and this must remind people of the RTO computation that\u0027s exactly what this is with one important difference there\u0027s no minority oh please don\u0027t come to the mic and yell at me yet there\u0027s no minority oh there\u0027s no minority oh but there is a max act delay the max act delay is in fact what is sent to me by the peer as something that the peer says the the receiver says this is the maximum amount of time by which I will delay an acknowledgment and so the PTO includes that but it removes the minority oh this is very much in line sort of with with the reason rationale for why minority Oh was even there in the first place but that\u0027s the proposal right now and Cory\u0027s gonna yell at me no Jonah Gorizia just a nice question and what\u0027s the prob market contain what so what what does it contain when you send "
  },
  {
    "startTime": "01:57:03",
    "text": "the poor pocket what do you put in the pocket that\u0027s a good question thank you that was nice the the pro packet can\u0027t contain pretty much anything we don\u0027t we don\u0027t actually say you if you have old data you can you can send old data if you don\u0027t have that you can send new data but we we suggest that you send new data before going off to selling old data because we don\u0027t quite know what\u0027s happened yet the point here is that PTO basically comes from it\u0027s an extension of PLP so think of it as at a loss probe that just keeps happening again and again and again that\u0027s one way of thinking about this so so the the premise here is el temor does not mean packet loss again as I said packet loss is detected when an ACK is received until an ACK has received we don\u0027t declare anything is lost there\u0027s an exception but that\u0027s an exception it\u0027s not the common case we do not declare anything as loss on till we see you knock the reason this is useful is because it allows us to not have to deal with spurious lis marking things as lost when we actually do is see an ACK so the idea here is when a time what happens we don\u0027t do anything the congestion window we don\u0027t do anything to anything at all we just send out throw packets and and when an ad comes back we do the actual detection three minutes left persistent condition so when so so when do we actually collapse the congestion window cause there is an RTO thing in TCP right so at some point you need to infer that this persistent congestion in the network and the way we do that here because we don\u0027t we in TCP you don\u0027t wait for an ACK to collapse your rate so in this case the way we do that is when there\u0027s basically been no ax coming back and and all packets are basically lost over a long enough period of time we do not receive any acknowledgments over a long enough period of time then we collapse the conditioner window to the Mencia the long enough period of time is effectively effectively defined just directly in terms of time in terms of the amount of time it could have taken for an RTO to fire right so the the draft right now has a this this expression here and and the idea is to with the default is to which means that this is what effectively would have happened if you had had two talos probes followed by one RTO that\u0027s the amount of time that\u0027s computed in this expression and then we say if there\u0027s been no acts received but data has been going out for this period of time then you mark the connection as in persistent congestion and we collapse the congestion window next slide I\u0027m not going to go into the details of this but that\u0027s the lost detection part next slide there\u0027s a bunch of tooling next slide that\u0027s does active work that\u0027s happening on tooling and there\u0027s a whole hour on this in TSV area to discuss tooling this you can actually use to look at loss recovery behavior and so on in quick connections with quick implementations so please come to that and watch this and that\u0027s the end of my "
  },
  {
    "startTime": "02:00:04",
    "text": "talk going back to what should be sent and in the probe I think like the current rag draft recommends that if there is unsent new data and the window allows it then you send new data otherwise otherwise you send the highest packet that you previously transmitted like the most recent or data I think that\u0027s the recommendation in the correct current in the current recovery draft yeah in the in the rag draft I\u0027m saying we could have a similar strategy in I so we I think we have something that lines in the recovery traffic as well basically the same logic being that you you send new data if you can otherwise you send old data and in the previous slide where the condition windows collapsed yep persistent condition yeah one more like further yep the next next next next yeah that one so this is not just collapsed the means even died just noted that we should probably say that we mark everything has lost that was outstanding right everything is marked as sorry so everything that was outstanding is marked lost at this point I can\u0027t remember that\u0027s the case is that actually done on the draft oh that\u0027s right it gets mugged us lost because enough time has amassed yeah yes so that\u0027s an event that we write yes so this quick follow brac TLP combined draft or not it doesn\u0027t actually follow those drafts I mean this is been the law security mechanism quick for three four years now but what we need to do is basically look at those drafts and make sure that we don\u0027t have very different values for constants and if you have differences then we justify them at least right and and you you went into the setting congestion window a little bit at the end of the talk so that\u0027s a little different than detecting lost part and I think setting transition window would come into play by whatever congestion control is in control at that point in time so right now I think default is New Reno for the through big is there any I mean so the interface in the in the draft is quite clear about loss detection versus congestion control and the idea is you exactly right this is what I call this persistent condition so you would basically call in to be VR for example and say you know the equivalent of a timeout happened but but the the interface is quite pluggable and and there is an API in the draft if you want to use that implementation but the mechanisms are quite divorced from each other even as described in the draft so it allows you to use other controllers Thanks so we are running out of time and "
  },
  {
    "startTime": "02:03:07",
    "text": "so thanks a lot for this talk as and as mentioned so the intention was to raise awareness and to get feedback from that community and I\u0027m sure that you will understand where in other working groups you can contribute if you have any further comments and is that we are unfortunately out of time which means that we don\u0027t have enough time left for the last talk that we had on the agenda if time permits maybe we can have to talk next time and with that I\u0027d like to thank all of you for all the interesting discussions and contributions and see you then next time in Montreal Thanks "
  }
]