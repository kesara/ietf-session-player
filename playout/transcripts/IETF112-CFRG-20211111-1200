[
  {
    "startTime": "00:00:42",
    "text": "so i suppose we can start uh hello everyone this is cephergy uh alexis menninger of nick sullivan and stanislav the chairs and we'll start with our traditional presentation so some administrator session has been recorded we have a min taker thanks a lot to watson led we have a debit relay uh here are the links to the participant guide and you can report issues via this link blue sheets are automatically generated and the minutes are in codemd this is a noteworld c4g is a research group in the ird so you can learn more about the irkf in rfc 7418 so we have the following agenda after the 7g update will have two items on existing drafts let's space and view perf"
  },
  {
    "startTime": "00:02:00",
    "text": "and three items new potential walking items it's verifiable distribute distributed aggregation functions shortcuts and k-mec spdif and private access tokens if we have some spare time we have quite a lot of time for any other business um any last minute agenda version one two three okay uh then let's discuss our current document status we have a new rfc that's are gonna do finally uh we um we walked down there going to for four years i think uh now it's rfc 9106 congratulations we have two rfcs to draft sorry in isg review and in irsg review those one are hpk and spec 2. hpk is in sg review and spec 2 is in irs gpu we have a lot of progress with hashtag you can see that it is waiting for document shepard but actually uh until earlier today uh the shepherd's review was uploaded to the data tracker so now it's it will be waiting for ifts chair and we have a lot of changes in other drafts we have an update in for vprf and we'll have a status update from chris"
  },
  {
    "startTime": "00:04:00",
    "text": "wood uh later today and we have peripheral curves updated and there are some changes in the author team and we have updates on both bank drafts on our opec in nc pace and again we'll have an update on cpace from beyond us later today we have updates and frost and our recipient signatures and we have two drafts in a recessional plus call or collecting some feedback after the group called that's about vrf and kangaroo 12. um we have dls signature expired and we have one draft that was unchanged that is that is 80 limits so a lot of work is to be done and a lot of news since july we have crypto panel in which helps the chairs to review the drafts and helps ic and potentially is ready to help any other working groups so it can be used to review documents coming to c4g to security area from iec possible possibly uh we ask for reviews from cryptography panel members before research group last calls for several documents and for most difficult documents we ask also some reviews in the process of document development for example"
  },
  {
    "startTime": "00:06:00",
    "text": "we've asked the panel for a year of opaque because there was some discussion about mechanisms used inside the protocol of bank the current members of cryptery panel serve until december 2021 so it's about two months left and we'll have a rotation of members we would be happy to work with a lot of as a current experts in panel because we are sure that uh the current uh panel members work really excellent and we have a lot of great reviews but also we will call for nominations to join the victory panel i'll send a message to the cfg maybe at least in a week or two so please eliminate yourself if you want to work in the panel so any questions to the chairs before we start with presentations okay then let's start with our first presentation uh this will be from chris pattern uh verifiable distributed aggregation functions please grace i share the slides yep i uh requested to share my slides i'm waiting for just a moment i hope it will appear now yes you can see them yep"
  },
  {
    "startTime": "00:08:01",
    "text": "got it everyone can see me everyone can hear me well all right um okay um okay so um yeah so this is a this is a new document um uh this it's it's very very early stages right now um i we're not asking right now for the research group to consider adoption um the purpose of this presentation is is mostly to um introduce everyone to this concept and um and solicit feedback on on on the document and and it helps shaping it and putting it in the right direction um so this dovetails with uh the priv buff yesterday and i'm not gonna assume anyone here has attended that buff and i'm not gonna go into much more detail than richard barnes did yesterday as i said the intention here is to kind of um introduce everyone to this idea so what is a verifiable distributed aggregation function or vdaf or vdf if you like so the the the purpose of the buff yesterday um was to form a working group that will work on standardizing protocols for privacy preserving aggregation of user measurements so we're taking a bunch of today uh service providers are taking a bunch of measurements of users for various purposes and typically very often they're often they're interested just in the the um the aggregate and not the individual measurements themselves so what we're after is a way of computing these aggregates without actually having to see individual inputs in the clear so the charters right now envisions doing this by distributing the computation among multiple aggregation servers so um and that way the computation can"
  },
  {
    "startTime": "00:10:02",
    "text": "be carried out basically on secret shared data so no one actually sees any input in the clear um and uh one one thing we have to make sure we do is because we're working on see with secret shared data we have to make sure that um inputs are valid basically we have to have a way of of of of of um uh of checking for invalid inputs submitted by clients so there's gonna be some amount of coordination that's required among the aggregation servers to ensure correctness of the computation so what we're talking about here is basically multi-party computation um but a very uh very specific um kind of shape of npc um not general purpose npc and there's a lots of uh recent work in the literature about literature about this so folks might have heard of prio prio is a paper from henry corgan gibbs and dan bonnay from 2017 and it's basically set out to solve this exact problem and this is what really started our interest in um in uh in in this with you know this is a solution to a problem that we have let's go and standardize it um [Music] so what one finds though there's there's a lot of papers about this and there's one thing that's becomes clear is that there's no one-size-fits-all solution so there's no one protocol in the literature that's going to solve every aggregation compute every aggregation function one wants to compute now creo happens to solve uh like a large class of problems but it doesn't solve every problem um and another thing uh to when when we look at the literature what we see is kind of a wide variety of security and operational consideration so um starting with operational consideration so how do client does the client"
  },
  {
    "startTime": "00:12:00",
    "text": "interact with the servers how do the servers interact with one another what is the kind of communication pattern um and then you know and then from just a just a security perspective like what did it what what is it that we're after so for a multi-party computation it's pretty well defined but there are rough edges in many in many of these in paper so there's there's a certain amount of leakage sometimes so what we end up with is kind of a lack of consistent abstraction boundary for standardization efforts like priv to to build on um so what we want to do in this document is provide this abstraction boundary that's kind of the main purpose so we our hope is to to um to uh to address directly the operational and security considerations that have come up so far in real world deployments and uh a couple of these were talked about in the buff yesterday um and another thing we want to do is provide um basically a design target for crop cryptographers to go and build new schemes so they don't have to think about what you know what is what is the shape of this protocol supposed to be i'm given the shape and i try to find a solution that uh that works in this framework um and at the same time we want to standardize a few video vdifs from the literature in particular those that we've looked at in the priv buff so far so what is a vdaf um so aggregation function basically means we have the sequence of inputs and uh we want to compute some function over over those inputs the order of the inputs shouldn't matter um and then there's also this thing we call an aggregation parameter um and so the function the aggregation function takes the the measurements the aggregation parameter and outputs the aggregate result um for example this could be the arithmetic mean this can be some estimation of the distribution of inputs"
  },
  {
    "startTime": "00:14:00",
    "text": "or um or you know the the function can be a little bit more sophisticated so like let's say we want to count p as a string m one to n are strings and we want to count the number of times that p occurs in the set so the the shape the the overall shape that we envision for this is uh is the following we we we divide the processing of inputs into kind of discrete steps that are executed by all the parties in the protocol and it begins with the clients mapping their measurement to a sequence of input shares um we call this the sharding step and then um and then imagine there's this function that takes these we call this the uh preparation function uh for lack of a better term um that takes the aggregation parameter the uh the in one an input share and outputs an output share and this is a function that's run locally by the aggregator and then in the next step the aggregator takes all of its output shares uh combines them in some manner and uh outputs what we call an aggregate share and then um there's another server called the collector who eventually gets all of these aggregate shares and it can uh combine them to get the final aggregate results so imagine so the reason that this works is imagine you have the uh the output shares or have some algebra have some algebraic structure they might be in a in a ring or a field or just a group and um we can compute the aggregate results just by adding things together so we can find the output shares by adding them and then we combine the uh aggregate shares by adding them so um yeah so this is a mat this is this is how we get privacy so what as you can imagine here when no matter what any of the servers do in this protocol they never see"
  },
  {
    "startTime": "00:16:00",
    "text": "uh out output shares in the clear or uh or learn anything about the measurements as long as um one of the aggregators executes the protocol honestly and that means basically i don't share any of the information any of the um my uh my output shares with the other servers so what can go wrong here is you have a very sparse input share space so the client is uh client maps its measurements to a sequence of input shares and um you know if you're doing secret sharing over some finite fields it's uh it's pretty straightforward for a client to just pick random junk um and when the aggregators process that junk and output aggregate shares to the collector um the collectors nick going to combine them to get just junk um so we have to avoid this problem um and uh systems like prior this is kind of a first class consideration for them um and so we're going to try to bake that into the protocol we want to make that into the protocol somehow and um you know in general what we're going to need to do is is provide some way for the aggregators to interact with one another so what we're going to do is replace this local preparation function preparation step into a multi-party computation so that takes the aggregation parameter the input shares and maps it to the output shares and the idea here is that no matter what a malicious aggregator does an active attacker does as long as the other aggregator is honest it learns nothing about um it it learns nothing useful about the output shares that it would learn otherwise and i want to emphasize again this isn't meant to be general purpose npc often"
  },
  {
    "startTime": "00:18:01",
    "text": "the solution here is going to be tailored to the application so um we have we've been looking at two uh protocols from the two uh basic schemes from the literature that have this shape uh one we're calling prio three this is based on uh so this is this is there's a there's the original prio paper from 2017 and then uh many some authors plus some other uh the original authors and plus some uh new people worked on this really really cool paper called distributed serial knowledge proofs uh well okay i forget what the name of the paper but i call it zero knowledge proof distributed zero knowledge proof systems um crypto 2019 i have reference at the end um so yeah in the use case here is we have we we're encoding measurements as uh as vectors of elements of some finite field and so the input shares are just additive shares over over that finite field and the aggregation function is any any function that can be defined as ad as just adding up these these encoded vectors and um what does what the what the uh distribu the uh uh the prepare the distributed preparer npc thing is going to do is just check for validity where validity is defined by an arithmetic circuit um that's evaluated over the input um i am running low on time and i want to save time for questions so i'm going to skip hits for now um and i'll just say that we um have we're working on some implementations um we have um the the two main schemes we were interested in implementing um they you know they they're in various states but we're very early on here but i can report some you know basic basic metrics here um the very the for preo3 the the computationally expensive part is uh uh proof generation basically this"
  },
  {
    "startTime": "00:20:01",
    "text": "sharding step um and um for for uh aggregate functions that we're interested in um this is pretty performance so the so the main thing i think is um uh uh communication costs but we can we can so these numbers are uh kind of preliminary we can drive these down more with with optimizations um and and i want to emphasize that this is being built on lots of prior work um and uh uh and i won't say much more about that because i'm i i want to save time for questions so um i will leave it here um and take any questions people have thank you any questions yes go ahead watson watson watson lad cloudflare um i i'm not sure i understand with your presentation what you're asking you're saying you don't necessarily want adoption is that just now or in in the future this might come back you might ask for adoption later yeah so i think we're going to come back and ask for adoption later we want to wait until the working group is formed and we have a for the for uh the priv the priv buff yesterday is the the hope is to lead us to form a working group and we want to wait until that's chartered so we have a pretty clear path from the protocol that's being implemented designed there and um and the thing that we're using here basically but i would love it if people read the document and and and told me what they think there's like you know there's a lot of um there's a lot of things that potentially fit in this framework and i would love to i would love to hear about um new constructions that potentially don't fit and uh and consider whether we should"
  },
  {
    "startTime": "00:22:02",
    "text": "change the syntax to to account for them thank you any other questions comments okay then thanks a lot chris when you want some document to be adopted please ask in the list or during this meeting thanks hello thank you uh please be honest the update of the sea base draft please start we can hear you please turn on your mic bjorn we still don't hear you do you hear me now yes no i hear you so again uh i'd like to present an update regarding the sea pace draft so first i'd be speaking about the updates regarding the security analysis papers and then i'll be talking about the major rewrite of the internet draft that we are currently working on so regarding the security analysis there are two major updates first we have uh uploaded a new revision of our security analysis paper which is"
  },
  {
    "startTime": "00:24:00",
    "text": "worked by julia michelanny with the proofs regarding cpace and then there's a second paper by edward eaton and douglas de villa which have been working on the quantum annoying property of cpace so regarding this quantum annoying properties it has been conjectured that the attacker which is able to calculate calculate some discrete logarithm oracles has a hard work of of attacking cpas and in fact what they found out they have formalized the assumption and they found out that the dominating term which dominates the attacker's advantage is dominated by the number but the possibility of having online queries uh testing one password online or alternatively to use a discrete logarithmic rhythm oracle for testing one password offline so that's the essence so what one intuitively expects from a quantum annoying protocol and secondly we have an update regarding our see pace paper and it's now reviewed and accepted at asia crypt for this december and essentially we have several improvements and changes we have aimed at clarifying the security definitions and proofs i'll detail on that more importantly we have now explicitly covered two different settings one initiator responder setting where we have one initiator which first starts the protocol and the responder which is always second so we call that initiator responder protocol and the second option is um the case where we don't have uh a prescribed ordering where it's not clear which parties sends the first message and in the proof we now cover both settings"
  },
  {
    "startTime": "00:26:00",
    "text": "we ended improving readability and most importantly we have worked on clarificatifying the role of the session id that's beforehand we only had the security proof and the simulation based uc model which implied that there needs to be some session id so and this part of the analysis is covered in the new appendix b which is in the security paper and it includes a game based proof which complements the security analysis that we had beforehand so in order to carry out the proof we first had made some adoptions on the existing page models game based proof models so that we also are able to cover the parallel protocol case where we don't have ordering of the uh prescribed ordering of the protocol messages and with this proof we are able to show security of cpace without pre-established session id values so as a result the security we still have strong security guarantees but the guarantees are somewhat different in comparison to the case without uh where we have the simulation based proof so for details it's i think it's too complicated for this presentation it's described in the paper so the second major change that we have been doing in the in the latest version of the security paper is that we describe a subset of functions which are important for cpase implementations and so we distinguish four different sub steps which where the first one is scalar sampling where we have some conditions which needs to be fulfilled here we have a generator function which maps the password on a generator on the group"
  },
  {
    "startTime": "00:28:01",
    "text": "and then we have two scalar multiplication methods where we decided to use two methods in order to make it explicit that point verification and checking for low order for the identity element is important so we split it up so that we can uh mandate the check uh and make a transparent way it's necessary to uh to avoid attacks so and once we're having these four functions we have in an appendix g where we analyze analyze how to best implement these four functions for the different application settings which we might call it ecosystem so we adding one set uh how to implement these functions best when using short wire stress functions in order to main comp best compatibility and uh same using use cases as that we have today for nist's curves and brain blue curves then we have a second uh ecosystem where we um focus on uh constraint devices which one would like would like to work on montgomery curves and use x4 25519 or x448 and then cpase for idealized group abstractions such as restretcher and dcaf regarding the session identifier we come up with a recommendation that it's a good idea to if it's possible in the application to first agree on a joint session identifier between the two parties uh so both users should contribute to the randomness when generating the session id so it's not complicated the only important things are that both users should contribute randomness it's not necessary to have secrecy for this process and the messages for generating a session id can be piggybacked to the messages sent by the application so more details are given here in the reference 3"
  },
  {
    "startTime": "00:30:01",
    "text": "which i understand just in the slides and the main c messages that secure also without a pre-established session id but the pre-established session id makes a difference and specifically the essential point is that there come is less which can grow go wrong if you take pace as one sub step of a larger construction and want to integrate it in a larger application and if you're having a session id and which is unique for this specific protocol run you bind the protocol run to this specific session and there's less than what can go wrong if you have it and secondly there is some impact of the session id uniqueness on the level of quantum annoyance guarantees so for details on this uh minor impact that's i've added the chapters where one an interested reader may have a look for for the ugly details of this this property so as a essentially i think we have resolved the issue and the question which has been raised in the last cfrg meeting regarding the session identifier and the game-based proof regarding the internet draft we are currently making a major rewrite so the current draft version 2 is a mixture between a scientific paper and some guidance document for the implementer and with the new papers we i think we have the basis for uh referring the theoretically inclined reader to the to the paper and so that we can focus on the implementer for the draft and that's what we are currently working on"
  },
  {
    "startTime": "00:32:00",
    "text": "it's the current version is on the on the github it's not yet uploaded and we plan to upload a new version once we have finished uh the test vector generation regarding the new definitions and the new text that we have we are preparing so the structure is what we have changed is that we now consider both the parallel uh sessions which remember for this application such as this magic wormhole which has been discussed on the cfrg list for instance uh so this parallel setting and in the classical initiator responder setting and that's included now and we have a structure where we now first give a generic description of the definition of the protocol the pro definition based on these four functions that i've mentioned before and then we have a second section where we specify how exactly these four functions shall be implemented for uh three specific ecosystems so short wire stress single coordinate letters and uh for a stretcher and decaf so regarding the protocol description there's one change regarding the protocol messages and it stems from as a result of the game based proof which we have in the new security paper and essentially it turned out in order to to reuse the existing game-based security models for instance the game-based model which has been used for spec 2 and other protocols in order to use this model we needed the possibility to have the session the party identifiers as part of the protocol messages so in order to deal with this setting and use reduce the security model there we decided to add the associated data field to the protocol description so that we can"
  },
  {
    "startTime": "00:34:00",
    "text": "not only have the public share y a and yb in the messages but also an associated data field so typically this would include any data that the users will need to will want to authenticate such as party identifiers and this also allows for applications now where we don't where we have no unambiguous party identifier encoding available protocols protocol start for instance if you're having a device which has several mac addresses and the the software which is running the cpase protocol does not know on which of the different mac addresses the communication actually happens uh it's not clear which party identifier or which mac address to use a protocol start so it's this allows us this associated data fields allow for including this later as part of the protocol and the second change we which we have in the current draft which on github is that we modified how we are hashing so the hash functions and the security models both for the ethernet stabila model and in our own paper we model the hash functions as idealized random oracles which calculate a bit string so and we if we don't consider uh imperfections which might stem from mercury dam guard uh constructions such such as uh 256. so in order to deal with that we now are having a prescription that we prepend the length of each substring to the protocol messages to all subfields and that's also helpful first for instance when prepending the length of the public share and the length of the associate data fields it's"
  },
  {
    "startTime": "00:36:00",
    "text": "helpful for passing the messages by the receivers it's also helpful for dealing with buffer flow over power overflows hannity checks don't need to consider the problem of length and extension imperfections that come with merkle dumb guards hash constructions so finally we are currently working on the test vectors so since yesterday we have a first version of test vectors available the first subset of test vectors available on the github but it's not yet finished we the sage code is largely rewritten we have a proof of concept implementation and sake map for all the different ecosystems now um we also follow the directory structure and build system just that is it used for the hash to curt and opirf drafts and the goal is to automatically generate the markdown sources for the for the test vectors from the sage script and once we finish this sub step the plan is to upload a new uh ide revision to the iatf server so basically that's that was it i'd like to express a big thank to christopher wood for his with xml to markdown conversion for the internet draft it's a big difference to i if i knew beforehand that it's not mandatory to use an xml version of the files that's i would have spared a lot of time so thank you very much for that and we'd appreciate feedback and tints on all aspects but specifically i'd invite feedback regarding the object"
  },
  {
    "startTime": "00:38:02",
    "text": "style notation that we have now in the github version of the draft so where we compile for instance the different functions that we need uh together in some kind of object type notation with a class and method then we are a bit discussing in the editor team whether we should be considering explicitly both the initiator and responder version and the parallel version or should we focus on one setting for concise and so as for instance is the case for the spec 2 draft so it adds some complexity and we're not yet decided which what is the best best way currently we have uh both versions covered and as a consequence both two versions of test vectors so then there's the question how to best prepend the field length to the octet strings for the prefix free encoding currently we are suggesting to use utf-8 as it's very compact and in most cases it's just the plain integer as and it's a single byte for lengths up to 127 bytes and finally there's still some issue with the auto magical markdown to html conversion on github so if anybody if there's somebody who has more experience or which might volunteer to ask some questions i'd appreciate that so thank you very much thanks a lot bjorn questions comments uh then my maybe one small question from my side uh bjorn could you please give us the"
  },
  {
    "startTime": "00:40:00",
    "text": "outline of your future plans of when do you want us to ask the crypto review panel for another set of reviews when do you want when you plan to ask for such a group of us calls so could you please give us your current understanding so my plan is to to have a first version with a test picture this week then i think we will um we my suggestion will be that we invite comments for say two or three weeks on the cfrg lists and so that's the feedback and hints may be incorporated so that we might be having a second uh published version of the draft end of the year so and hopefully i have i think the security analysis is now very detailed and very explicit and i think that it might be by end of the year that we could ask for a more a lot larger review of the draft by the review panel but that might also come out from there might be uh result in the first discussion ground on the cfrg list so that there's might be some delay but i think it might be feasible to to ask for more formal review by the by the end of the year by the review panel so that we could proceed afterwards okay thanks any questions to bjorn once and thanks a lot bjorn"
  },
  {
    "startTime": "00:42:00",
    "text": "the second following presentation is from chris food it's about current status of vlp aircraft so please please all right thanks everyone uh good morning good night i guess good good day good evening good afternoon we'll have you what time it is this is an update on uh voprf uh or rf as i should say now um since the the last time we talked about this the draft has undergone somewhat of a significant uh change internally uh the the major change being the transition from uh the sort of classical to have to to hash to the hominoprf uh to what's referred to as the three hash um which is called the three hashtag helmand pio prf or partially oblivious opioid or partially obvious prf um and i'll explain the the sort of difference between that in just a moment um there's also been some other minor updates with respect to cypher suites that are offering in the spec uh changing hash functions to you know better align with the corresponding groups and then as usual um updating test factors working on document editorial clarity and so on on the uh the the poprf difference um or update rather a a rpf uh unlike an opref is is effectively an opr but it has this additional input t um uh so in in the classical case you have um you know an opioid computing a prf over a server private key um which is hidden from the client a uh client's input x which is also hidden from the server then you get some output y and the protocol the interactive protocol takes place between client"
  },
  {
    "startTime": "00:44:02",
    "text": "learn the value of k and likewise the server does not learn the value of x and the client is the only one that learns the output y now this t value that is new to the popuf construction is a shared public value that both client and server know prior to execution of the protocol that's effectively metadata um or you can think of it as metadata that's a bound that binds to the output y um you can think of it as a context string and input string what have you um t here i think just generally refers to tweak um but the the gist is that you have um effectively a a more generic oprf construction and by more generic i mean you can effectively uh implement or use it as an opr uh with an empty fixed uh constant shared value as an input t so if you run the popup vertical with a fixed public input what you have functionally is an opref on the outside and this is quite useful because now we have a construction that is suitable for all of the applications for which the opr construction was already useful but also those that would benefit from additional context where appropriate um so some examples that come to mind um are our privacy pass privacy pass has a dependency on the vo prf in particular for computing tokens and verifying them and for privacy reasons the keys have to rotate quite regularly or for privacy and security reasons the keys rotate quite regularly but not too frequently so as to the airport users into small buckets this requires sort of complicated machinery to actually rotate the key publish the key"
  },
  {
    "startTime": "00:46:00",
    "text": "verify the key um externally and get it down to clients in contrast if you were to have the key change less frequently but perhaps fold in sort of the expiration of tokens in as the public metadata uh your your resulting you know system might be a lot simpler and that you could effectively just pin a key on a on a blackboard or chalkboard somewhere change it very infrequently perhaps it's in an hsn or some other you know privileged environment where it's you know the risk of compromise is quite low and still get the same functionality as if you're actually rotating the key so you can you can imagine i guess using metadata for that particular purpose the facebook private stats paper or meta private sets paper however um we'll call it uh uh used a uh an attribute-based vop ref uh in a similar way um the attribute here was the expiration timestamp associated with the oprf output you can instantiate the exact same system using a pop-rf with the expiration encoded as the metadata input you can also rather than using you know time i guess as your as your public input you could use you know some other value that's it constrains the the pr output in space so for example you can imagine in the context of privacy pass again uh using information about where the client is coming from perhaps it's perhaps it's country or it's like network asn or something like that to ensure that tokens for this particular client are only redeemable in that particular region so you can't have tokens you know being collected in one region and then spent in another um so they're all there in general there are you know a variety of use cases that come up uh where a metadata is quite"
  },
  {
    "startTime": "00:48:01",
    "text": "useful for simplifying you know the sort of ecosystem around which oprs or in which oprs exist um and then as a result um this this more general construction seems uh more applicable to a wider set of use cases without invalidating any existing ones um from a security perspective uh the the the paper upon which this is built uh demonstrates that just like the classical two hash sticky helmet opr um it reduces to the the classical uh discrete log problem uh in the algebraic group model however the the proof of this reduction is done um with a game-based definition of um uh security rather than um it doesn't it doesn't prove that it satisfies this sort of ideal opera functionality that has been used to assess the security of opaque and similar uh password-based constructions um from stosh and hugo and others um we also uh have shown that the i guess superior the security primers for um the static diffie-hellman attack or the xi'an attack um are uh identical to the the classical opioid problem as well meaning that you don't need to use even larger groups than you would for the the classical do hashtag helmand to to combat this particular problem so they're similar in that respect and i guess the takeaway here is that um we have effectively confidence uh equivalent confidence in the scarity of both of these constructions um uh but the lack of a uc proof um for rehashed helmet um is uh it does call into question sort of the security analysis um for opaque in particular because opaque is dependent on the vop rf draft the vo prf now uses this new construction um however uh we are actively behind the scenes working with the authors of all the relevant works to ensure that this"
  },
  {
    "startTime": "00:50:00",
    "text": "analysis is done and all signs point towards it being feasible so um not at all concerned about you know the demonstrating that this new construction uh can sufficiently meet the ideal opioid functionality that is necessary for opaque um it's just the work that needs to be done as is you know for the charter cfrg um there is one important difference that i i tried to know on the list um i'm gonna get much feedback and that is the the classical two hash oprf um is is threshold friendly um meaning you can secret share the private key using shamir um and then uh non-interactively sort of compute um a a or evaluate you know an input uh in a threshold manner transparently to the client which is quite nice if you wanted to do that for your application in contrast the three hash debbie hellman because it doesn't require private key augmentation during evaluation that the same techniques don't apply which means that making this uh threshold a threshold uh or turning this into a threshold deployment would require sort of an interactive protocol between uh the thing that's doing aggregation of different shares and uh the different holders of uh secret share private keys um uh multi-round here being an interactive multi-rom being uh just a single round between them uh we do believe however that um for the purposes of you know a fixed public input uh which again is effectively the same case as if you're um you know using the two hashtv helmand um that we can use the existing threshold mechanisms for uh uh for turning three hash to be helmet into a threshold-friendly uh protocol in practice um but uh that's uh sort of intuition at"
  },
  {
    "startTime": "00:52:01",
    "text": "this point uh we need to write the code to verify that's actually correct um however um uh i i i raised this because uh the the original vopr of spec was not written with threshold friendliness in white in particular had nothing said nothing about how to turn this existing uh two different helmet of virus into or how to implement the server side in a threshold friendly manner said nothing in terms of how to you know actually do the secret sharing how to distribute the key amongst all these different participants and so on um and what the aggregation looked like um so from i guess one perspective you can imagine that this is not a functional regression in terms of uh you know set of features supported by transfer but moving from two hash to three hash um so if we ask the question you know if if we do if we actually care about threshold friendly uh oprs um uh based on the you know the previous scope of the document and the current scope of the document if the answer is no um i think uh we should just press on with what's in there now uh only pick one particular construction that is specifically the more generic popuf based on three hashtag helmet um simply because it's a generalization and it satisfies more use cases however if people think there are legitimate needs uh for threshold friendly oprs um and i say needs rather than once um because i want to distinguish sort of the ability to threshold from the actual desire to use this in practice uh i don't think it's in our best interest to try to specify functionality that people will not use that will just further complicate things but if the answer to this question is yes there are several other questions that i think we need to answer as a group first of which is do we now do the work to try to you know show how to uh deploy three hashtag"
  },
  {
    "startTime": "00:54:00",
    "text": "helmet in a threshold-friendly manner or do we specify three hdp helmet without threshold capabilities and two hashtag helmet with threshold capabilities um and are these treated as sort of separate cryptographic objects with distinct apis and i guess importantly in my view what do we do about distributed key generation which is perhaps the harder problem in this space um indeed the threshold signing draft frost uh kind of punts on this and assumes you know either you have some trusted deal there that's dealing with um distributed key generation um or you have some out-of-band protocol for other out-of-band protocol for actually distributing the keys um peterson's uh protocol does not generalize to or there is no you know security analysis done to convince us that peterson's protocol generalizes to discrete log protocols uh like either these oprs so that's really kind of an open question of an open research question anyways that's it for the update um at this point i think we need to hear from uh you know implementers who uh i guess care about use cases of oprs um and care about what's in the specification um to know whether or not this is heading in the right direction i believe it is um and and to clarify what the current direction is it is uh simply the uh partially oblivious prf construction without any threshold stuff in the in the spec um but i uh i think i think we need to hear from others so i i will pause take questions there's also a thread in cfrg if you have feelings or opinions about this love to him thank you grace uh yes bjorn so regarding this request for the proof for the uc proof for the new construction do you know whether somebody is already"
  },
  {
    "startTime": "00:56:01",
    "text": "working on it yeah yes we're actively working on it behind the scenes because in order to join forces maybe because we considered working on a proof which considers the property of the map since in the current map you are uh treating the map as a ideal randomized random oracle and we are aiming at considering to to write a proof regarding the uh properties of the map just as we we've been doing for sea pace so that might uh might uh enter in the storyline but if you're uh working on this uh so we might discuss so that we um join forces so that we have less effort uh together on that yeah i'll follow up offline and uh we can chat thanks chris so i have uh i've i have one comment but i want to start with a kind of clarifying question so the new construction requires the okay so the the current analysis for the new construction is in the generic group model um algebraic group model yeah yeah uh okay uh so um my question is does two that two hash diffie-hellman make this have the same uh is is the analysis for the two hash diffie helmet in the same model no they're a weaker they're they're not in the same model um the two hdp helmet is in this uc model and three http helmet is in this algebraic group model and uh we don't quite know how to compare them okay okay i mean i think that for that reason it might be worth keeping them both around um just because if it turns out the um the algebraic group models is overly optimistic it's nice to have a backup but um i'm also trying not to"
  },
  {
    "startTime": "00:58:00",
    "text": "make your life too complicated um it's i mean i'm fine to write text um i'm less fine with specifying things that have basically equivalent security um uh but i think you can argue that they don't have equivalent security if one if one isn't provably secure in this in the model of the other so i mean um we can take that question offline i guess um sure okay um the other thing uh the other thing i wanted to say uh the the thresholding bit makes things very complicated and i would say without an explicit use case that someone cares about i think it shouldn't be in the draft just to keep things simpler right um and i think that's my intuition as well uh which means uh you're effectively left with the question you know if you don't care about thresholding do you just have one construction or do you have both constructions and based on this slide um i from my implementers and a use case perspective i see no reason to have both okay thank you jonathan um just as a a clarifying question could you speak a bit more about how you ensure that the uh final parameter the public parameter isn't just like the person's ip address or like how you ensure that it's not like directly bucketing people this this specification does not touch on that whatsoever it is completely application dependent to determine whether or not that's like you know revealing in a privacy specific specific way okay there's nothing you can do with this protocol level to ensure that it's not that ah okay cool in which case maybe we should just stick with the two perhaps like harder to improve uh the the 2dh like if we can just say like"
  },
  {
    "startTime": "01:00:00",
    "text": "this has huge potential for abuse and there's nothing we can do about it then just don't do it so i'm not sure i agree in particular because you can imagine the client just like telling the server hey here's my ip address rather than accidentally mixing it into the opr um there are lots of ways in which you can reveal the same sensitive information so um yeah i i i think uh it's incumbent on applications using the theoprf to ensure that the you know the the width of the metadata and the type of metadata is not revealing in any particular way um i don't think that's uh you know anything we need to constrain further at this layer okay thank you chris are you still in the queue okay hi sophia silly from cloudflare just to clarify also just leave it for whatever that i was saying um in the too hash th construction also there's a way um in which uh kind of a unlinkability attack can also happen because there's no way that you can actually check that the server is not imposing a rotation of the key that is too small as to for example indeed create a linkability attack with the metadata constructions at least you are assured that that is not happening but it is the decision of the application to actually define in such a correct way which kind of metadata you are passing um so it's not of the contraction itself here presented in the cfsg but rather when it's going to be implemented in the application but just to know that in the other construction in the 2-hdh you also can have these problems because if you rotate the key too often then you can also be diminishing unlinkability thank you"
  },
  {
    "startTime": "01:02:04",
    "text": "okay thank you so now bookmarks uh shortcash and gamer sir kdf please book you can select okay let me see if i can share my slides yes uh let's go to here share yes please stop okay so i'm sitting here as a uh as i call myself a crypto plumber i'm the guy who takes your work and tries to put it to some use and recently i have been dealing with small hashes and working a lot with kmac i like to share some of my experiences and some of my challenges here with you and ask for guidelines coming out of cfrg uh let's see how does this work how do i get into my slides uh go this way just past my slides ah there we go uh so first of all small hashes it's hopefully a design compromise why somebody's using a small hatch and hopefully they looked at acceptable risks within a constrained environment and there are two cases that i've looked at dealing with small hashes one is just a hash over clear text or the other case is where it's a keyed hash and point out that small hashes have existed risks to key attacks recognize that and i'll be talking about that later"
  },
  {
    "startTime": "01:04:00",
    "text": "and the other thing that we i've always been using a probabilistic model of what is the risk of a collision but the reason you point out to me on this the cfrg list that modern hashing hardware has changed the game we no longer say oh it's g it's hard to generate a million 10 million 6 million hashes to try to force a collision to try to do an attack it's no longer the case so the math preclusive probability is no longer sufficient we have to look at the problem differently than we have in the past and that poses a problem for me trying to figure out what can i do how can i what is my real risk and how can i mitigate it so i need an understandable guidelines for us developers how to measure the risks to hash compromise and what is the exposure to attack some good guidelines for this i've seen some really bad things out there um i i pay attention i work here um come to you people for for guidelines other people don't they just read what literature is readily available and look at nav link 2 which is the the command and control protocol for unmanned aircraft they put in an authentication field a 6-bit key hash for message authentication you can go look at it and i'll talk about that more later so with the this whole area of of small hashes is there's no real good guidelines you have to be willing to plow through the literature talk with people and find out what are what are things are happening and"
  },
  {
    "startTime": "01:06:02",
    "text": "what can um you do within a constrained environment where you only have so many bytes to work with you only have so much time to work with and you only have so much memory slash processing part of work with so what guidelines can we have can we put forward for making hashes which are eight bytes six bytes don't go that way or the risk to keys and and what that means um there is nothing that somebody can point me to read this through to get um to get a good understanding so one of the first thing i'm asking cfrg form is to work on guidelines in this area i'm a reviewer i can help author it but no way do i have the knowledge to be able to be the principal on such such a document but working out there people talking to me particularly in this area i find that they say well bob what should we do my answer is i really don't know um so that's what i have to say about small hashes um you'll see it in my uh my work in uh um drip for the unmanned aircraft i have a 64-bit hash and we talk about attack against that uh and i just mentioned here a uh a a six spike keyed hash that's in in map link so there's some guidelines needed here that's all i have to have in my slides here on hashes and again it's i'm asking for guidance and putting things together now my work with kmac though is much different to me it looks like a sadly overlooked function um i know that this will say why by the deuce saw three"
  },
  {
    "startTime": "01:08:01",
    "text": "it's not really a processing advantage over saw 256 about the same amount of resources to get it done except kmac is one cat check function where it's hmac is two shaw functions and again when i'm working with constrained environments and i wonder about big heavy hit servers that they may have this the same issue that half the processing cost is something of importance um another thing which i have over over the decades have a deal with well i only need so many um bites for my uh my hash i'm truncating it i need a short hash how do i truncate it which bites do i take out to get my hash and so kmac you tell it how many bites you want there's no designer thought process and what they should do they say i need eight bytes get eight bytes out um and of course we have recently on uh been having a discussion that in and fips 202 um shake which kmac is built on is an x off and there's questions is there a difference between a hash and exoth me i don't see the difference i only see that it's a question of the security strength problem we need some maybe some more clarification on that because that was recently brought up me i didn't see it as as a problem but apparently some do and maybe we need some clarification on that so kmac as a keen hash i look as a winner in terms of design and in terms of when i'm working on these these constrained devices i save that processing i save"
  },
  {
    "startTime": "01:10:02",
    "text": "their time but i take it one step further and that's i want to use as a kdf particular interest here is with ecdh the problem is or the challenges if you go to uh um 856 c release one it does not recommend kmac as a two-step kdf until 108 gets revised but how long and there is no i can't find any draft of revision for 108 what's happening there why do they have why do we have to revision for 108 before we can seriously look at using kmac as a kdf because when you look at hkdf and you look at kmac you ask the question what is the difference you have the expand and contract um function in hkdf you look at feed the input into the sponge you look at squeeze the output out of the sponge you ask the question what is the difference i have some guidance from team ketchup on this that leading me to believe that 8k mac is a valid kdf for a a diffie-hellman uh key extraction function and the big point about this is that whereas kmac compared to hvac is a two to one here it's a four to one at least a four to one because hkdf does two hmac operations where here we're doing one k map function so again i need to derive a key i need to derive it with the least amount of resources on a constrained system and oh by the way one of the summer jokes in unmanned aircraft they have these high-definition cameras streaming a lot of data and you say well can i have some of the processing power"
  },
  {
    "startTime": "01:12:01",
    "text": "no you can't you can't disrupt plus also it's in the special processing so it it still becomes a problem that where i get the processing power for for when i have to um key generation or anything like that and so um looking at savings here is is important to me in the design um and so there's that but then there comes the question of i need multiple shared secrets how to do it i need two 128-bit keys can i run kmac to put out 256 bits and then split it in half to yield two unique case of 128 bit strength i can't find anything in the literature which gives me clear direction on this can i break no does breaking one of those keys break the other again i have not found anything on guidelines on this and what to do it still be cheaper to run the kmac twice than hkdf if i need just two keys um and there's a question of how to do a key hierarchy there's efficient way to do key hierarchy um using kmac versus way that we have done key hierarchies in the past so i look at kmac as this looks like a very powerful tool which has been very much neglected by the community and without the guidelines for protocol developers to say here is something else worthwhile and along this cfrg led on eddsa we still don't have uh this to have come out of 185-6 for using edsa yet we are using edsa so can cfrg lead with kmac broader use"
  },
  {
    "startTime": "01:14:00",
    "text": "particularly note that once this finishes with the light crypto competition there are kmac equivalences in many of the proposed algorithms particularly kudiak which very much it's that's a ketchik function uh so we'd be looking again in the iot world in the constrained systems of looking very heavily at at using one of these lightweight cryptos to be able to use a kmac construction for both keyed hash and for kdf uh so can we get cfrg to produce guidelines encouraging kmac usage and then later a lightweight crypto option for such work and if we were to do this we're less likely to see bad designs elsewhere if you look again at what map link 2 did the fact that they just do a shaw on a shared secret concatenated with them with parts of the message and a time stamp and i was there in 96 when when when um hugo did his first presentation and and why we don't do this and why we need hmac so this is six 25 years ago we said this was bad design somebody doing something now they have nothing to look at they have nothing to look at and say guidance you don't do it this way here is how this thing this server design can be attacked so we have here is a case of a bad design uh at least when you look at literature why we did hmac and yet this is really recent this is only five years old uh and so it's a problem where is our guidance for these these sorts of things i think that is where cfrg comes in uh i think this is a role that cfrg"
  },
  {
    "startTime": "01:16:00",
    "text": "needs to do uh you you are the people this is a place where the experts live on this stuff where the knowledge lives and this is where this sort of guidelines should come out and i be very happy to work to produce these guidelines but i can't leave it i have to turn to you people for guidance on that so that is my my material i'm doing small hashes i need to do small hashes i have payloads i am so highly constrained on how much data i can put out so but i need to then become an intelligent balance or intelligent risk mitigation when i use small hashes i have minimal processing power i have minimal time to get it done how can i do this more efficiently so that is where i'm coming from on this and i'm turning to the people here for your help and i will participate and that's my my material and i'm now open for questions and for comments and i'll grip and grab my kevlar suit and put it on if needed is awesome watson lad at the start of your presentation i was a little confused when you're talking about 48-bit hashtags are these message authentication codes that that serve you are authenticating a message and you can only have 48 bits for that or is it are you trying or they're trying to be used as a hash function um that particular case map link that is a message authentication um and once if you look at what we're doing in the draft ietf drip off um there it is an um we're arguing internally should be an 8 or 12 byte hash can we get by with an 8 byte hash where it's a hash of one message authenticated in a later message because we can't add a an authenticated"
  },
  {
    "startTime": "01:18:01",
    "text": "hash into the original message so we follow it later with another mass hat another message where we take the hash and we authenticate it uh and so how small can we get by with the hash size there such that it's just a hash of a message which we are including in a authenticated frame so i'm using these in a bunch of different ways but what what is my attack what's my risk so i can i can i will post the list to the cfrg list all the places where i'm working with these things and the ways where i know where they are and that's what i'm talking about does that help uh clarify things okay it's very different depending on what exactly you're doing for a mass that's okay because you the only way to attack the mac if it has a key is just sort of send to the 48 messages and see that one you know try every one but for the other things you're doing it might be more or less a problem it's very very difficult to analyze yeah but again if it's if it's if it's a if it's a keyed hash can attack against it uh reveal the key and then you can um slip your own data in particular when this is command and control for them and aircraft if i can steal the key i can now tell that aircraft to do other things like happen to uh the unp unauthenticated messages to the the drone over iran some years ago and how they managed to get that drone to land there so so it's also can with a heat hatch can i steal the key scott okay uh again i would uh highlight uh um watson's uh question about uh there's a bunch of different use cases uh uh"
  },
  {
    "startTime": "01:20:01",
    "text": "please the six byte thing is a mac not a hash and uh yeah me we may perhaps we should there are some macs where doing a forge a single managing final forgery doesn't actually allow you to do anything else other macs you really can we need to publicize that difference in addition in terms of hashes you also need to distinguish between hash hashes where you only need pre-image or second frames resistance and hashes where you really need collision resistance and how do we actually give useful advice to a non-crypto person to able to make that distinction i have no idea if i'd like to see if we could write something up scott at least getting a good start on it and let the community learn uh uh okay on another topic you you seem to advocate kmac for for small devices one problem with kmac is it has a it requires a sizeable 200 byte estate uh state to actually compute uh that may not be feasible on very small devices well that's true and that's why i'm like looking to the lightweight crypto so right now i'm working with kmac where i can um and but looking forward to maybe next month for the lightweight crypto competition to be finished and then we have guidelines on alternatives that will be using the kmac type construction well using kmac type construction is very different than using kmac as is um i i i've been looking at koodiak and and kudiak is really it's uh i ask people for you like other than this some of the size difference it is it's working the same way it's still uh"
  },
  {
    "startTime": "01:22:00",
    "text": "a sponge function okay uh i uh john i think you can kind of continue uh asking questions thank you scott john i i think a guidance document would be very helpful for the community there is a lot of different you have hkdf you have hmac you have kmac and then you have like one or two iterations and there's a lot of this document just guiding the reader to the this document would be helpful i think i think there's also you gave an example of people using uh hash as a creating their own mac but there's also people using there's a lot of cases where people use hkdf without maybe not needing hkdf maybe a simple hmac or kmac would be enough as you say so i think the guidance documents would be good my colleague muhit yes actually yesterday writing such a thing yesterday couple of months ago i don't know if you have talked with him recently but i think him and i would if you want help him and i would probably be willing to help with this yeah okay john i'll reach out to you um i'm like next month to start working on us on such a uh a document and we can maybe uh start getting some people together um and and i i'll supply use cases and we'll start could start framing all the different cases on the whole thing and and i would really because i've been struggling here the past two years yeah hi bob uh i like the work i support it um i'd just like to flag that there's some other thing reasons uh"
  },
  {
    "startTime": "01:24:01",
    "text": "when i was trying to use uh hmac i discovered how you know it's proven correct but that doesn't necessarily mean that it works the way that you would expect it in that uh there are certain cases where if you have a null input to the algorithm that has the same effect as all zeros into the algorithm and you know back when it was written that was considered acceptable and the author insists that that is still acceptable i do not consider that acceptable i think that stinks and i think that that is an error that should at the very least be called out uh as a security concern um and so i i i think that it is worth going back and looking at some of these things because um you know it should take more than a very vigilant implementer to get crypto right particularly when we're presenting something as a construction that we the experts not that i think that there are any in this field yeah it's a bad thing to think think of yourself uh i i think that when we do that we've got to make sure that it really is as safe as possible and as a booby trap free as possible and that brings up another one of my concerns and like how long does a string have to be to be fit into the hash to be safe in terms of attack or other things like i need i want to get out a eight byte hash and i only have um 24 bytes that i'm"
  },
  {
    "startTime": "01:26:01",
    "text": "hashing is that okay or should it be adding how many bytes of a known random string and do i add that known random string at the beginning or at the end so that is a related question to this um that how big how small of a message can you safely hash not how big but how small anybody else john are you back in the queue oh no john just started that and fill up anything else christopher chris i was just going to say um uh describing the use case would be a good start um i think that um depending on depending on uh i mean yeah like like what's been said before like if if if if if you need collisions resistance you shouldn't ever truncate but um if you you know if you're if you have like for certain yeah i i would like to see the use cases laid out that's all start doing that i can put together a use case draft as a starting point and unfortunately chris uh sometimes i only have something bites available in my payload so i need to say this is a size that i can carry what do i what can i put in here which is meaningful so ha control maybe what security properties you need i think i think it's going to depend on what security properties you need uh you know scott that indicated that in terms of for somebody did about uh collision resistance pre-image second pre-image what know what what what what are you dealing with granted philip something else"
  },
  {
    "startTime": "01:28:01",
    "text": "fill up your hands raise okay um stanislav i think then that's all the questions nobody else is in the queue uh yes it's a lot boop and uh if you have your uh some people uh have some specific requests to see to adopt something and so that people can collaborate and come back with specific requests to us and of course we'll be happy to announce some adoption call or something yeah i will take it to the list i'll start a discussion going on on both these subjects and i'll start framing out the use cases leading up up to draft and and others hopefully will will give me the uh the expert assistance on it and i thank you for your time okay thank you thank you bob thanks a lot bye bye and the last item uh the agenda private access tokens chris wood all right um [Music] uh so thanks nancyleff and others for letting us talk about this this is not um an individual draft for cfrg um so we're not we're not explicitly asking for adoption or anything um the the purpose of this presentation is more to uh so it's a wider review of the uh sort of cryptographic techniques that are used in this private access tokens document which you can find by just punching in this name or title into your favorite search engine it was sufficiently different enough that we felt like it definitely needed wider review um from experts in this particular community um and beyond so um i should also note that i'm gonna try"
  },
  {
    "startTime": "01:30:02",
    "text": "problem um uh somewhat out of context uh from private access tokens uh to to sort of best focused on the the core cryptographic concepts um uh but if there's like questions around the the wider use case that might help um you know feel free to jump in the queue and ask um so seeking clarity here um as well as you know whether or not the thing is correct okay um in private access tokens we have the sort of the the arrangement sort of shown on the screen you have a number of clients uh each distinct uh connected to um or interacting with what we call a mediator and the mediator interacts with what we call an issuer each of these entities holds some state the issuer has a sort of fixed private value we call k the mediator has a fixed commitment for each individual client um so uh ev every single client has their own secret value x and the mediator holds the corresponding public commitment to that value um and in this arrangement um our goal is to sort of compute a deterministic function uh or value y uh over the client's private input x and the issuers private input k under the following conditions the first of which is that the mediator only learns this output y if the client specifically engages with the protocol using its secret value that is to say the mediator cannot act as a client um and request uh that the and interact with the issuer to compute why without without having x um we also want a desire for the client"
  },
  {
    "startTime": "01:32:00",
    "text": "to not be able to engage with the protocol for secret values that it does not own um so x prime set are you know different from its own x um and uh the the this the the space of x's is sufficiently large enough that um you know this is this should be invisible but we have additional measures in place to prevent this um and i guess importantly at the end as well we also don't want the issuer to learn x um uh and moreover we don't want the issuer to learn when two x's uh our two requests that sort of come into the issuer correspond to the same acts um the the issuer in this in this sense is kind of just a dumb oracle that's you know evaluating inputs over this secret uh with the secret value k and then responding to the mediator okay um to to sort of uh satisfy uh or to instantiate this particular solution that we have a number of things that we build upon um the first of which is just the primary group um and we treat all of the secret values as c as scalars uh in the underlying field and then um effectively the commitments as uh the public values uh corresponding to these secret scalars um we also make use of a uh non-interactive uh schnorr proof of knowledge to uh prove the discrete log of a particular value um and the the syntax is here very convenience but effectively uh when when we write this we say that you know the the proof is such that the the the proof proves knowledge of the discrete log without actually revealing the discrete log um and the verify the corresponding verification part of that only returns true if that proof checks out um so as a sort of first step leading up to"
  },
  {
    "startTime": "01:34:02",
    "text": "um uh sort of doing something that's on this similar child on the screen here um and you can you can kind of maybe view this this interaction as uh like say blinded dicky hellman in a way um so uh the client uh the very first thing it does is generate a random scalar um and then blinds its corresponding public value x um sends both over the wire to the mediator the mediator forwards that along to the issuer who does evaluation as it would over that particular blinded value and then sends the result back to the media who removes the blind provided by the the client getting as desired a function a deterministic function over the client's input x the issuer's input k um and uh you know insert a suitable hash function and our key derivation functions here to make sure that you know y is sufficiently indistinguishable from random but this is the gist the problem with this is that if you were to assume a malicious mediator who wants to compute why without the client's engagement they can just run the protocol as it would um as if it were the client in particular it does the same exact thing the client does it generates a random blind blinds the the client's public value which it has and then interacts with the issuer to compute the output so we need some way to protect against this particular against this particular problem and this is where the the the zero knowledge proofs come into play um so uh they're basically uh appended to the interaction uh between client and issuer um uh such that when the client generates it blind and it's blind in public value it proves at the same time that it knows"
  },
  {
    "startTime": "01:36:01",
    "text": "um the the corresponding super value x um and presents that proof to both the mediator and the and the issuer and this is important because now this allows the issuer to check that this request that it's about to evaluate the request is generated by an entity which knows the corresponding discrete log does not rev learn the discrete log it just learns that you know only the entity which could have generated the request did so in possession of x in this case um uh the the proof itself um will be different for every single for for a fixed client the proof will be different because the blind is different um the blinded version of the the generator that's sent across uh between um uh from client to issuer is also different and the blinded point p is different each time so uh we still maintain the the sort of ideal property that the issuer learns nothing about you know repeated values of uh acts upon uh you know subsequent engagement with a particular client um and the rest of the protocol is the same um the you still have this divi helmet that takes place um after the issuer checks the proof and assuming it checks out returns the result to the the mediator um the the media removes the blind um and gets a function of x k and um and insert hashing and key derivation as necessary um to to make it initially from random uh that's effectively it um so the i guess the questions for the group are um a we uh uh you know does this sort of i guess security model makes sense um it is and i guess more importantly is the problem statement somewhat clear um does this uh you know about the envelope sketch of a protocol sort of uh intuitively meet these goals"
  },
  {
    "startTime": "01:38:01",
    "text": "um and i guess uh at the end of the day we're likely looking uh that this we're hoping that this is effectively a prf um uh you know and and of course i've alighted some of the the particulars that would uh that would be necessary to make this a the prf but um does this intuitively meet that goal so um i i will pause here at the end and take any questions you may have any questions comments um no no questions is fine it would be useful to know though i had been in chat or elsewhere if the problem statement was clear i should also note that um we're in no particular way bound to uh or tied to this particular solution the the general desire to have this um a deterministic function over some secrets that the client has and the issuer has is uh um i think that's the the the the essence of the the problem so if there is a simpler way to solve this particular problem uh perhaps a simpler protocol um we would love to to use that this is just this is the current proposed solution uh um okay so i'm not seeing any comments or questions so uh i think"
  },
  {
    "startTime": "01:40:01",
    "text": "uh martin's question no certainly not um but these are these are separable problems or questions i think um i i think what i'll likely do is try and condense uh this particular um the essence of this problem and the proposed solution uh to the list and follow up there it's pretty early for folks here or late in fact we have some responses in the chat so there are at least three opinions that the problem is worth solving so i hope those are um those are opinions um that i i i hope it's safe to assume that those uh those those comments uh imply that the problem statement is clear and uh yeah there there is some overlap with the opr um uh it looks sort of on paper similar to an opr um i think the difference is um uh you do note that the there's no there's no hash to group step computed by uh or done by the client on the first step so it's arguably simpler um if you ignore the zero not true stuff than the opr um uh the it's it's closer i would say to like just classical diffie-hellman which is not surprising because the opr is just you know as we saw earlier is just a you know a variant of jiffy helmet okay all right um i will uh i'll take it to the list thanks yes yes uh so chris"
  },
  {
    "startTime": "01:42:02",
    "text": "uh so any other business please just having a remark all the notes that i've seen i think you misunderstood me the note keeper and i think that it's a good idea to have a discussion on the on the list until the end of the year and i think by christmas i have the hope that the draft has a state that can start with a crypto review but i think we need the time until the end of the year in order to get it in a good shape so i'm trying to push things but i don't think that we will will be this fast thank you thank you any other comments maybe some questions to the chairs um i'll be releasing my uh threshold inf structure in the next few weeks uh it's now passing all the unit tests so if people are interested in seeing what threshold can be applied to in to real world problems like managing ssh keys they may be interested in that one thing that i need though is um i'm using threshold encryption and nobody's seems to be very interested in uh looking at the uh drafts on how i do that i think that that might be a uh very useful um common application i did present at this at cfrg and i was told that there would be a uh a review on the list uh deciding whether we were going to adopt it"
  },
  {
    "startTime": "01:44:00",
    "text": "uh that was over two years ago i've asked periodically since and nothing has ever happened all right just wanted to say that chris patton was in the queue no i clicked the button um i didn't mean to put myself in the queue all right then thanks everyone thanks thank you for your attention and see you next hi dev maybe some comments from alexey or nick no there are no comments so thank everyone goodbye have a nice day"
  }
]
