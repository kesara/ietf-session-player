[
  {
    "startTime": "00:00:28",
    "text": "Alright. It's about that time. Welcome to the last meeting slot of the week, where we will be talking about privacy pass. Let's see. So We still need a note taker It's not all that difficult just writing down kind of the main topics and then Any kind of important points in discussion of any resolution of issues. Anybody willing? Will help us get started if we can find a note. I'll it. Right. Thank you. Alright. So next slide. If you can. And or I guess I can control it. There we go. No. Well so it's Friday. You haven't seen this already? And figured it out. Well Shit. It's So please recognize you're under the rules of the note well. Next slide? Alright. So for agenda, we'll have short update of"
  },
  {
    "startTime": "00:02:01",
    "text": "the status of some of the working group documents then rate limit tokens, batch tokens, discussion of key consistency, and then public merely the data tokens. So any agenda bashing? add something or take it off? I I wanna Alright. So just to jump in on on working group documents, I think we have we've closed the last call on main core documents. I think we may need to just There may need to be just one other revision to I think there's I don't know if all the changes have the merge changes have been reflected in the document or if they need to be. So I'll I'll I'll follow up with authors and and see, but we should be good to go. As long as we got all the things. And just wanna don't wanna send something that we know has we'll have to change. And then we have a couple other documents in the works one which we'll talk about now. Which is rate limit tokens. You should have could drive have access to I just I need to select with which deck is here. Think you should it should be working now. Yeah. Got it. Alright. Hello everyone. I'm Tony Paul from Apple. Presenting on behalf the c authors. We do have Chris and Steven in the room here. Alright. So this is one of our adopted documents that"
  },
  {
    "startTime": "00:04:00",
    "text": "kind of not already if your last call, it's one that we get adopted last time, we met And so this is a variant of the publicly verifiable blind ars tokens, that allows for limiting And again, just as background if people weren't caught up on the previous discussions. This is a case where the rate limiting is being enforced on the on the machine. Server that's doing the attest station of clients. It doesn't know what they're going to, but it has anonymous buckets on which it can force rate limits. So there are several recent changes that we put out I think like, the week before the draft submission deadline. That addressed many of the open comments This is largely in line with what we presented last time at the meeting. The biggest and most substantial one is an entirely new section that goes into where we're calling pen of issuers and clients that are detected as mis haven. And so this is something that testers students. And so on the issuance path we have the client is testing its device with the tester, and then if that passes and doesn't exceed the rate limit, then it gets a token issued by the issuer behind that and the issue is able to see the identity of the origin that client is going to but not the identity client. In order to avoid attacks or malicious issuers could leak out information by denying token issuance? We don't want the testers to simply drop token issuance requests if it detects that the issuer is doing something suspicious?"
  },
  {
    "startTime": "00:06:03",
    "text": "So instead, we just describing the text that the tester when it detects collisions in these kind of anonymous it's to say that Oh you someone either the client or the issuer is fu with things and trying to either leak information about clients or business is clients trying to cheat then essentially the test kinda keep penalty count of a, know, bad box for the various issuers and clients. And have thresholds once you've detected enough of those patterns of collisions then you kick out those issues or clients as it may be. And the heuristic that we suggest is, you know, essentially if you see a particular client to getting multiple across different origins and issuers, and it seems like it's client being sketchy, but if you see an issuer inducing these collisions across multiple clients, then it's seems more likely that the issue is the one behaving, and then you can essentially say we're block trust with that issuer until we investigate the root cause of this. These are all things that would happen in exceptional cases when people are violating the protocol. So the main change. The second change was more... Doesn't actually change any of the compatibility or inter interrupt for the protocol. But there's a field which is named currently the anonymous origin Id. This is something that the client presents to the tester as a anonymous version of The the origin name... It's just called random blob that the attest uses to bucket the the counts for rate limiting. And"
  },
  {
    "startTime": "00:08:02",
    "text": "the... It can be calculated in different ways. It could be calculated just off of like, a a dictionary that the client has that it just comes up with random values. We had some text that suggested if you want to derive it. There was a pretty good way to derive it. And we updated this to include the issue name in the der since we want to ensure that anonymous or Id would not be the same across different issuers if a particular origin moved its surface from one issue to another. And then the third change that was made is that we explain If we get a challenge on the client for token very token that includes multiple different origin names, and this is mainly the case if you have some like, third party Content on website saying that it's really limiting for itself working on behalf of the main page. That the client should pick using that main page as the thing that it is doing the token issuance request on. So going through the open issues we have here I think this one Yeah. Chris have you written this you update this text? Yeah. No. Exactly. You do wanna speak to it. I I up the context on this since you had been writing it. Oh, yes. Yes. Yes yes. Okay. Ran with this discussion. So the fundamentally since the state about rate limits is being stored on the testers."
  },
  {
    "startTime": "00:10:02",
    "text": "You know, the corollary is that these rate limits are only enforce her adjuster. And so if you are trying to do effective rate limited token for a particular website. You wanna make sure that even though you can definitely support a diversity of testers that it is not easy for a particular client to participate multiple overlapping ones. And so you would want But you you would want them to be testing things that are appropriate for what you rate limiting based on part you're making funny faces. Let's talk about it. Just why. I mean, if if you say, the limit is five. Then you have five hundred different protestors. The limit is really two and a half thousand as far as I can tell. Right? That's that's just the way it is. Now right but depending on yeah. What it is. I mean, if it's like active I don't know. Email accounts with payment information associated with them I know, like, then maybe you're comfortable with that. But Yep. I think the the general shape of the of the problem is that you don't want to be able to have anyone else in the system be able to re identify the clients such that they know that they're the same Yes. And unless you insist on having the protestors, have somewhere cross cor in this information, which again, is not a not a great thing to have. Then then you will have this property out of the system. And it might just be that you have a very limited set of testers that are involved here. And and unlimited set of station methods as well potentially. But mh."
  },
  {
    "startTime": "00:12:01",
    "text": "The... I think this is just like a natural property of the system. That you have. Yep. Which which unfortunately raises the the question of centralization again. All of those concerns, but I think we can probably bucket does in a in a lighter discussion. Yes. Yeah. So I think the main main thing here is we need to expand the text and discussion of this and kinda give you the caveats of like, Yeah. If you are giving a limit of five, and it's email accounts. So that means, you know, So you have a legit Gmail account. You have a legit account that account. And so if you're reading five articles a month. You get five articles per... Valid email account you have That's the nature of the beast. Sorry I'm trying to use the outside tool. We do have some central centralization considerations in the architecture document. But this naturally forced us to extend them. Yes. For this particular document, which is an issue we should file. Alongside, you know, clarifying the text here, and I will file the issue That okay. Also yeah. And relate the issues sir. Yeah. That's very good. Yep. So this is a fun one. Yep. Okay. Took a long time to get. Yes. Oh yeah. So this is just a bike shed thing. The the names are un wheel. The anonymous order Id is not terrible. But the the name for the thing that the issuer generates in response to that you compare against them in the bucket is pretty confusing and doesn't have a great name. So we should fix this I don't have great ideas. If people do, please by shed, but otherwise, because we'll just put our thinking caps on. That this sort of"
  },
  {
    "startTime": "00:14:02",
    "text": "thinking is not really a good use of time and yep. Meeting... Exactly one. Yeah yeah. So it is more. Apply for help please go if you have ideas go to get up. And then I think what of the other big important things to do is have more of a discussion in more of a reference to key consistency. So we also have our key consistency draft within this group. There is a slight difference here for key consistency from the basic token conditions schemes because there are two keys going on here. There's a key that you use to encrypt the information to the issuer, and then there's a key that is per origin for your tokens themselves. And you want to verify kind of the consistency for the pair of those things. So that's something that we need to work on. And discuss the different strategies that are appropriate and reference the consistency draft. On that. So, yeah. That... That's essentially where we are. I think those are the big issues we have done implementation work to update these. I think we have three or four different implementations of this right now. We are still tracking to see if our g dependency the analysis of the underlying crypto there has been completed. Chris, you were in See I don't know if there's anything Did we have an update on this? We intend to ask for through panel next. And then we'll go through C g research for last call. So... Okay. This formal steps. I don't know what the timeline line will be. There's a lot in the queue right now. But got it. It's moving along. If this won't. This will this will be... This will not be behind that in the queue. Yes. Great. I think that's it. Here of. Okay. Correct questions, but"
  },
  {
    "startTime": "00:16:03",
    "text": "think mainly, if you have thoughts please engage on the Github issues. So it sounds like you really have only one or two issues that two substantive issues bike shed and That... Yeah. And then we still have looming the whole centralization Yes. Exactly. That's right. Okay. K. Thank you. Next up, think we have batch tokens. Want us to share the slides here. Yeah. Excellent. Hi. I'm Rafael. I forgot to put Chris name on that first slide. Sorry for that he's a call for that draft. So Don't expect a huge breakthrough with this one. However, I think it's something practical. Next slide, please. So the proposal here is to have an issues protocol a for batch tokens. The earlier idea behind that is that we have privately verifiable tokens. But they're quite expensive actually. When when you want to issue them in high numbers, that could be pretty prohibitive expensive. And the reason for that is that the underlying primitive is p three at four. That is not notoriously slow. It's to conservative choice. It makes sense to use that."
  },
  {
    "startTime": "00:18:01",
    "text": "But the alternative could be restructure, for example. And then that's what's being proposed here. The other thing is that perfectly tokens use v p. An underlying primitive. And Has these zero knowledge proofs. That actually support batteries and way more efficient when you do that? However the issues protocol a call has no way of using that. So you cannot really compress anything here. You can only request one token after the other. Next slide, please? So How can we improve that? Did it here that we take a single token challenge reduce the size of the proof by essentially issuing multiple tokens. For that one challenge. And so that's why we am the cost per. So both for the proof generation and the verification, actually the payload is also constant size. So smaller as well. Next slide, please. So in terms, the upper abstract is the token request the privately verifiable tokens? The lower one is the one from the batch tokens, so you see the difference is pretty small. In the upper one, we have one b message, the lower one essentially have an array of blinded elements. It's fundamentally there's same thing. Next slide, please. So for the response, it's the same thing, we have an evaluated message for the private verifiable tokens. And an array for the batch tokens. Next?"
  },
  {
    "startTime": "00:20:04",
    "text": "Thank you. Yeah. So on the security side, as I mentioned earlier, p three at four is a conservative choice if you use something with a smaller key size, there's is a warning here. So that couldn't be enough in some scenarios. So this quote is from the V p of documents. And the suggestion or rather mitigation strategy the first two ones also from the document. So I think it's fairly straightforward because those are things that you should do anyway. So limits, the of token seems like a good idea. You shouldn't have a system where you can requests, you know, an arbitrarily high number of tokens in a certain time window. The other thing is You can also mitigate this by rotating keys regularly. This is again something I think you should do anyway because if you don't do that, you have a hoarding problem. That you have with a lot of those variants? All of them. So it's something to remember, something to take care of, but I don't see that as something fundamentally prohibitive. The other option would be to and define another token time of larger group. Of course, we would lose a bit of the efficiency, but it could see be dutch, for example. So this is an open question. If folks feel like we should do that then should absolutely discuss it. Next slide, please? Right. So here's a performance chart. A publicly tokens, primarily very far ones on the bash ones. And the batch ones here, So this is a batch of a hundred tokens and So the execution time is Per token."
  },
  {
    "startTime": "00:22:02",
    "text": "And so you can tell that they're much faster than the primary verify verifiable tokens however, please take this with a grain of salt because This is using rose crypto and I have a feeling that the implementation of missed and ross crypto is not up in terms of performance, but I didn't check this to be honest against our libraries. But still you can see that we are talking about more than an order of magnitude. So yeah, essentially, that's the the motivation behind at all. Next slide, please? So we have two implementations, not currently implemented that and the interrupt, so we have an extensive that of testing vectors. Pass in both directions? So... Yeah. We have the running code. Now let's see if we can get rough consensus. I think that was the last slide. A second. Yeah. Please. Student. Stephen Will Google. So I think I generally supportive of the best half of this. Private state tokens, which is as an older version privacy pass have the the prep batch code is what we're currently using, So having the standardize would be really great. I think there are two parts here. There's the batch part there's also this move to Rest. Think at least an argues case we find that because of some of the privacy properties of like, rotating our keys too frequently, we don't want to be doing at least the mitigation that involves rotating frequently. So it would be good if we could get a version of the batch code that still uses the like, p three four version. And maybe we can just tap both in the spec or something. Yep. Good point. I think it would be for looking into whether or what the exact right limiting requirements would be. And if that is loan,"
  },
  {
    "startTime": "00:24:02",
    "text": "because if you say rotating in keys, it's not an option for you and it's a point. If you rotate a frequently, you do have privacy problem. So then we would have a better understanding. If we really need another curve or not. Any other questions? Good. Are you looking for adoption? Yes. So I would like to propose the list. Okay. And that would be in next option. Sounds good. Yeah. Some discussion on the list and and we can do a call. See there's interest. Alright. Thank you. Alright. Next up is Ben with key consistency. Hello? I think you need to pull those slides. Thank you. Hi. So just to be clear, this is there is not a draft associated with this presentation. And I am not presenting as in my chair. But I am going to talk about the charter. So the the privacy charter says that we are going to describe mechanisms that prevent issuers from presenting any key material could be used to d clients. And there's a little bit of ambiguity there, but it sounds like that"
  },
  {
    "startTime": "00:26:02",
    "text": "means that we're going to do something about Problem. And so we've adopted a draft. That talks in in a lot of detail about the key consistency problem. And at the risk of speaking for the authors of that draft. I would say that what it really does is that it gives us the landscape of the different kinds of key consistency protocol architectures that we might imagine. It lists a bunch of these different potential architectures really in my view there's there's kind of an infinite number of of these things there's always more options if you're designing some kind of system, but it it notes the the most notable categories of these different kinds of architectures. It does not talk to us about implementation details or protocols. It's just a a concept map of the of the space. Basically. Notably, all of these architectures and I think any architecture for this problem necessarily depends on some additional parties that are assumed to be non malicious. I guess I should say that the client assumes to be non malicious. But there are a lot of different variations within that. Who are those parties? How many parties are there what exactly assumptions are are you making? Which way does information flow among these parties start push mechanism or pull mechanism on all of the different legs and where information flows. Should say that in general, there's sort of a trade off where some of these systems involve just one extra party who is relatively strongly trusted and some of them add many secondary parties who are then Italy much less. Just."
  },
  {
    "startTime": "00:28:01",
    "text": "So that's one piece of background. The other piece of background that I wanna talk about is the private state tokens were should say not involved with the private state tokens work on there some people here who are. So I'm probably gonna get some of the history here wrong, and I I welcome being corrected. But this for those who haven't been following. This is the w three c incubator proposal that would expose privacy pass to the web. In my view, this is the real customer for privacy pass. This is the reason to the key reason to to do privacy pass is in pursuit of these web use cases and that would flow through something like private state tokens. So There are a number of private state tokens documents right now. It's in a very early stage, I think at the w three c. But it talks about what assumptions it is making from us as the privacy pass. Working group or the people who are defining the privacy pass protocol. And it says that this protocol should ensure that issuers publish a public key commitment list and the sentence of the large parts. But I think it says the protocol should verify that the key commitment list is small and the protocol should vary verify consistency. Of this. Of this key commitment list. But we we really have not provided any kind of consistency verification. So I I'd wondering if we're actually sort of living up to the requirements that are being set for us. I like the word should here. I kind of feel like somebody has has given us an Rf style should and told us as the working group. Like, this is what you should do if you're the privacy password. So what happens if we're just kind of this? But I think the privacy private tells us what"
  },
  {
    "startTime": "00:30:02",
    "text": "what they intend to do if we don't solve the problem. And it says that the the draft specification for in the w three seat. Format says Each user agent fetch the key commitments from issuers at a regular cadence and con cat them into one big map blob and then broadcasts this blob to all clients. So this is solid consistency solution in my view. Like, it achieves the consistency goals. But I can't say I'm a big fan of it. It it has a couple of, I think important issues. One of them is that only issuers pre selected by the user agent can be used. Because each client is just checking its copy of the global broadcast database. And it's the user agent who's deciding who gets to be in that database. So limit number of issuers. Intuitive different... Right, the user agent has to go through in prove all of these issuers so that they might not go find all of the long tail of potential issuers. And also, even if they were willing to do that, that would create a very potentially a very large map of all of the issuers in the world, which then has to be broadcast to all of the clients in the world every time the keys rotate. So it's kind of for technical reasons. Limited to smallest ish number of issuers. And if you're trying to operate the user and guy participating in the privacy pass ecosystem. You have to take on this role of operating this key distribution service which must be"
  },
  {
    "startTime": "00:32:01",
    "text": "quite reliable or the privacy pass system for your users will fail. And you kind of a curation job to figure out which issuers is to put on the list and and which are you know, not notable enough. I think that this probably would limit the number of essentially, especially sort of open less well less professionally made and user. That are that are able to participate in privacy pass. So it might view this this is strongly consolidating. And that might be a good reason to see if we can do better. And I do think there's a hint about what the right solution looks like. This is sort of repeating myself for people who seen the double check work... But this is again a quote, from the private state Tokens work, which says a version of something that many of our documents say, which is that if the issue door left finger printing, then it can probably break the privacy guarantees of privacy pass. In other words, we pretty much have to assume that privacy passes used through a proxy. In order to conceal the client's Ip address from issuers. And that proxy is trusted in a particular way. It's trusted in a way that looks very much like the oblivious Http relay threat model. Where we don't trust that proxy. You know, to terminate Tls and until the plane all the users commands. But we do not to conclude with the issuer. In order to in order to preserve the clients and it admitting. You can think of this... When we say we trust it, another way to say that is we weaken our threat model. So we we essentially exclude certain attacks from our threat model because we don't know how to defend them. So we just hope that"
  },
  {
    "startTime": "00:34:00",
    "text": "that some higher layer of society solves that problem for So if you if you agree that sort of assess First that a consistency protocol my need to fulfill. For us to think it was a good solution. One important thing is that it allows user agents to solve this problem without having to design their own protocols and then operate their own services using those protocols. That I think is the requirement that causes us to need a concrete protocol. Otherwise, we can just like, our existing key consistency draft provide essentially design guidance. To to here's the kind of system that you should. Design. It would be nice if clients can use any issuer without needing their user agent to have approved that issuer in advance. It would be nice issuers can serve any user agent without the issuer to know about the user agent in advance. Those are go to these consolidation questions. And it would be nice to avoid adding even more trust assumptions. In other words, weakening our threat model even further than we already have. So that's what I'd have with I think they're probably other goals that other people in this group. Might have to Tommy Poly. If if you have more... We can go on, How how much order do you have So this is my last slide. Okay. I think that there are different things we can do here. We can ignore this problem and"
  },
  {
    "startTime": "00:36:01",
    "text": "you know, the the user agent will do something. We can disable all this later, you know, like hunt two. We're gonna say we're gonna treat this as a separate working group and we're gonna start a long process. We could say, you know, this is in scope for us and privacy pass and it now. And if so, we're gonna solve we have different things or there. I wrote a draft that I think happens to meet these design goals that I've listed here. That draft also inside the draft mentioned some sort problems that that that specific approach creates. And so I don't know if that's the best solution exactly. We could create it in design to try to puzzle out what the right approach. We could say everybody submit your favorite solution to the working group and we'll argue about which one is best. Maybe there's another way too But this is my last slide. Over to the queue. Alright. Thank you, ben. Tony Poly Apple. So I totally agree with all of the goals you have and do you mind going back to that? Slides we can talk about him. Yeah. So Yeah. I think these are all a hundred percent right, and I can't think of other things I want to add to the list particularly. Do think this is definitely in scope. And I think we already have one solution the architecture that works well, and we can certainly have more can talk a about more, but at least one of the deployment models, I think meets all of these. So I think, yeah, I I'm not sure when that private state token text was from but Yeah. It clearly doesn't it's not. Talking about things with the split issuer or tester role that basically calls out the proxy. And I think when you do have that, which is exactly but we've been implementing and deploying"
  },
  {
    "startTime": "00:38:02",
    "text": "then it is kind of the natural way to use a clock see and have that double checking and also meet these other goals. So So test to access the proxy and this isn't about the user agent maintaining the list anymore? It's about the attest you're going through. And the nice thing here is not some list that needs to be obligated to clients. It's whatever thing that they're already using for attest station already has to know the different issuers that is able to work with and has the key configurations for them. The key configuration need to be red to the clients necessarily although they could be. Either the essentially you trust the issue attest to check for you or you haven't kinda give you a copy of what it has as a lookup up. I mean we could spell that in different ways depending on what the trust model is with client in the tester, but we don't need to distribute the large list of all of them we just know that in the time that I'm actually getting a particular token from a particular issuer through this tester I can do that check for that one. I don't need to know the whole field of them. This allows you to have an extremely large and dynamic set of issuers. So I think it solves the like, you know, allow clients to use any of all issues clients to need to have zero relationship with the issuer or other than got a challenge for this issue. And I tried it to my tester. Any the testers said, Yep. I know about this one. I checked their key config you're being targeted. And then I think another consequence of the attest being different from saying the user agent and every user agent in the world needs to build this infrastructure Is that Different user agents can share in a tester if your testers is based on the capture or based on your Gmail account login or something, many different user agents can share one. And in that model, it shouldn't be hard for user agents to join. It's just, like, you already have the problem of who is going to do your attest station. And once you solved that problem, you've solved the problem of is going to help you with key consistency?"
  },
  {
    "startTime": "00:40:00",
    "text": "And so we can collapse these. And I think this helps us get the last goal, which is avoiding extra trust assumptions. We already have to have one trust assumption about how we do our attest station and who we trust to do that? And we let's just leverage that relationship to solve our key consistency problem at the same time. Eric, I think it's a statement I've made. Tons of four I'm we're gonna keep making it, but I think this is if you difficult problem to solve, and I think that is pretty good list of tools here and especially stuff about avoiding adding assumptions or adding more party you trust. It's a hard thing, I think... Maybe not necessarily for all usages of these technologies, but were gonna have some that We want to achieve all those things. And if we don't give any Specific spectrum out one clear way do it. Different people are gonna get wrong. And so I think it'd be very, very helpful and is very much needed need to have at least one spec saying, here's a specific protocol you can use to ensure key consistency getting all these things and Yellow well has some problems like can data, I think the the draft that then had any rooms on slides one option that she can say certainly other should we say to, but I think it's a problem that needs be solved and we need at least one spec out there saying, Here's going and path here's has one clear way to do it. Maybe not. Everything we use it, but we need at least one out there. Chris yeah. Tell me, I think I would agree with everything you said. Like, most of the major deployments that I'm aware of do have the benefit just leaning pretty heavily on the attest to help with consistency this particular case. But for some of the deployment models, that might not be true. Like, with these collapse depending on what type of association you may be doing So there's perhaps a gap between, like, what's possible today in current deployments and what would be possible if you did deploy it in a particular case, And"
  },
  {
    "startTime": "00:42:00",
    "text": "you know, navigating that gap via any of the proposed you know, ways forward you have here like, start with double check and try to make that be the standard protocol. Been design team to, you know, explore the gap and, you know, spit out something for the worker to consider. These all seem fine. But I I I Like It's hard to say or it's hard for me to see that this is just generally speaking, not solved problem. It just hasn't been solved for all possible use cases right now. So that is not to say that I'm not I'm not dis interested in you know, you know, carrie... Looking at this the the the particular places is where it hasn't been solved. Just to say that we we wanna emphasize it that we do have a solution right now. That works in practice. That does not require like a a specification or anything to get it right. Steven Well. I think I mostly agree with Chris point about like, Different use cases are gonna require, like, slightly different models I think the private access token faster split, I think works workflow for that use case. I think it might not work as well for, like, arbitrary issues on the web that like, each issue wants to do different things. Because I guess And the Pst t model, like, the tester is like, a testing to different facts. I guess, in the private access token and model, like effective still on testing to whatever fact the test they work with. Just doing guess also some of the problems like, can be an gets pushed off in the customer split. Unless the a attest just like, allows anyone to be in issuer. What seems to... I thought there has to be some amounts of trust from the to the issuer. Yeah. Yes okay. In that case, like, larger issuers, I guess, that's fine. And I think works better where, like, all these are doing this, like, one station promise while other models weren't like lots of different reasons and of stations. Yeah. I I think it's"
  },
  {
    "startTime": "00:44:00",
    "text": "it's that approach this from basically the private state tokens. Architecture question, and the the private access tokens, approach is a little different and maybe doesn't suffer as much from this problem. I think Yeah. I'd be. Very interested in trying to figure out you know, what the path forward looks like at the w three for those two things and making sure that we're providing the the consistency solutions that the W three is going to need. Matthew single. Apple. Yes. I I definitely agree with what you've said and that this is an important problem and particularly if this working group needs to come up with something I agrees with that is a solution, then we should not just defer to in individual implementations and deployments. In terms of the existing to like... It's only informational. Like, the whole point is just to come up with an understanding about what the options are, And I think either building off of your after building out a design team to hash out other details and whether we should build something or you know, design something else that that that does have more general use. I'm Happy you with both and I'm happy to to help with the design team if that's the way we decide to go. Right. I guess one great comment. So a lot of the here was taken from the private state Tokens work, which has been sort of great confusion when talking about these things in practice. Five stage tokens is not based on privacy paths right now, it is not inter with scanner that we're working on here. I think it's really important that when we're talking about consistency in this group we focus on consistency as it pertains to privacy pass the protocol that the It is working on."
  },
  {
    "startTime": "00:46:00",
    "text": "And once types tokens converge on it then like, you know, they we hit the benefit of, like, one solution potentially fixing many problems, but I like, I don't want us to, you know, explore this key consistency problem. On the basis of private state tokens, which is this w three c thing, which completely separate from, you know, what privacy state token, or what private privacy pass, which is just basically what private access tokens is under the hood. So I really hope we can just focus on privacy past the protocol. Not private stage openings or private access tokens or anything. And and and constrain ourselves to consistency in that particular. From space. I guess like ignoring the privacy private access took premise stage so still in the privacy pass document in like, architecture. We do have, like, we have these split mode. There's, like, a he issuer. Like we also have the ability of those two things being the same party. So remember we need to say, like, just not a allowed we're only focusing in the case that they are explicitly two separate parties. And that, like, maybe pushes off this consistency question. But if we don't do that like, it is still a problem in the world that those two parties end up being the same right. So to agree with both Christmas steven try to s what they were saying. So Yes. We're talking about privacy pass private straight tokens needs to be updated to align with privacy pass so there's plenty of opportunity for it to re things. Access Tokens is a... At this point marketing name that we use for a W w talk, it's just privacy pass on a different thing. Well, we should focus on as steve saying is that there are different deployment models in the architecture where you have split a attest to an issuer and you have a joint to test an issuer. And I think"
  },
  {
    "startTime": "00:48:01",
    "text": "what we could do is, like, the step here, yeah. Let's do a design team or something. But, like, let's have a either we have one document that is key consistency approaches for privacy pass, and it has two actions of if you have split a tester issue model, here's the recommended way of doing key consistency and it's essentially what I just described. And if you're doing joint, here's the way of doing it. And we need to talk about that and I think that's the harder problem for the design team. And if we think that's too hard to tackle altogether, Let's write two documents and one is key consistency for split to test models key consistency received for joint to tester models and that I think fits in more generically, you have to worry about like... Yes. It will serve the w three well, whatever the efficiency does, whether or not it has joint or split. Attest station? But it also will serve other use cases if they needed it. Thanks. This discussion has definitely been very helpful for me. For understanding the landscape here. I be really interested to know, you know, which of those... The the split or joint model, we think the w three is likely to end up relying on. I I I wanna add one more one more interesting sort of question to this topic, and that is that this consistency problem is applies to privacy pass, but we're not the only place where where there is a consistency challenge of this kind. There's clearly a closely related consistency problem in oblivious H. And potentially interesting relatively similar consistency problems even sort of outside of this in topics like binary transparency. Can I prove that I'm seeing the same version of this website with everybody else? So as we, you know, if we are designing a protocol, I think it's interesting to think about how many of those use cases we can satisfy. One final"
  },
  {
    "startTime": "00:50:01",
    "text": "I guess, comment. I wonder if the the current sort of of the w c from the It for this group, it is still accurate or still representative, like what this group is delivering. Like, when we were chartered, now like, look at the charter tax talks a lot about this Http based Api that potentially w three c people could use for consuming things. But since its initial charter, we sort of, like changed how we interact and like, do privacy pass H layer. It's no longer like an Api. It's like, just this challenge. It's, like, http authentication. And with that mechanism, it's not clear that there's really much that needs to be done at the w three layer. So I I I'm not very but seat person. I'm not like participating in the group in which that's being develop, but I I wonder if, like we need to perhaps, like, reset expectations about what this group is providing to the layer above. And, like, maybe that means, you know, they will they will change course or align with us or or whatever, but it's seems like things are perhaps not no longer aligned as they once were. Thanks. So I'll say that my preferred outcome here, I think is probably a design team. I would Welcome First of all, volunteers if you'd like to participate in in a design team? And we will see if there's is interest in that. There's enough interest to to pursue that. Then we'll figure out how to get it started just said I have not cleared that comment with my c chair. So don't take it as as the statement of the chairs. No. I I I think a design team is good idea."
  },
  {
    "startTime": "00:52:08",
    "text": "Are you looking for to make this concrete now. Or I mean, I think I'm not sure what the process is for that. If you're interested, let the church know and we'll we'll confer we don't need to do that now. Alright. Moving on to the next we have public metadata tokens. Hi, Scott. Let me get rid of this presentation better. Eric my not. Is in and out here. Okay. Is that... Mine appears to be his as well can you share ben? For some reason, I'm not connected. Yes. Thank you. Just let you know when we go to the next. Everybody. I'm Scott Google. I've been working on this concept of using public metadata within privacy pass tokens. This particular presentation is not presenting a draft to be adopted yet, although there is one that written. We just wanted to introduce the concept and encourage participation in in conversation around utility public metadata in the best space. So this work that we're talking about really relies heavily on the work that. Gauss presented in the Cfr g earlier there today? Where he introduced the concept that builds upon. Blind hours say. To"
  },
  {
    "startTime": "00:54:01",
    "text": "introduce a blind Rsa that allows propagation of metadata. That can be signed and verified. And you by all three parties day. So this work obviously has a lot of help from gauss, Chris, Kevin as well as Steven and tommy. Next slide is. So just to introduce the the concept of metadata and where where it's propagated within privacy pass. This looks like a pretty classic price best flow. The client will make a request get back a challenge. They'll do station And then can introduce our first metadata bit here, which is they'll in their token creation. Also buying their tokens to some metadata data that they come up with. This can be an open up. The metadata they sent off to the issuer this if they're happy with the metadata and they want to sign this particular request, They'll sign. The metadata is not bound to the signature it and have be changed. In the scope of this schedule anyway. Response sent back to the client. And then the client can present their re play the request with this token and metadata. Attached And then if the origin is happy with all that thinking. Continue. We'll now talk about the motivation a bit. Next slide please. Really, you know, what's the purpose of placing this what it did why is it useful? The existing public verifiable token is zero x zero two. Based on blind Rsa, you can build... You can imagine till building a protocol that encodes some small amount of metadata data using this token. You know, for example, you may deploy multiple keys at once and say, this key is for this particular bit of amount of data and the other keys for this other bit."
  },
  {
    "startTime": "00:56:03",
    "text": "You can also imagine saying, hey, I'm gonna have these expert expiry groups that our available can all deploy. One key two key three key. And, you know, clients maybe in a cash deputy contacts can. Try to validate it. I again these different keys to indicate that. They're they're in a particular to group. This can get tricky as your metadata size increases, and this is something that we found in analysis I'm trying to deploy something like this. Especially for x expiry. In in the face of... So imagine let's say we deployed metadata that needed to be for country. Okay. Know have. About three hundred different better data groups. Now you want to have pretty small slices. And so you start saying Amy maybe, I'll have like a one hour ex expiry and the cash reduction contacts. I now need to rotate my keys every one hour. Maybe with some overlap to allow from public propagation. And what you end up creating is kind of this, like, reliability taking time bomb. Where if your key rotation stops, and you haven't implemented things correctly such that you'll continue to validate against these keys that are now expired. It can be very difficult to keep the system up. And that that becomes a concern. There's also concerns around my if you're private key material, for example, stored in the Hs. It it can be difficult to convince these planning on your particular implementation to. Sorry. Continue to to to validate. So these are a couple examples of, you know, how why why not it also why maybe hard to build on the existing protocols to use it. And why we started using a difficult capture protocol. Part. Yeah. I just wanna ask a question about this differentiated differentiation"
  },
  {
    "startTime": "00:58:03",
    "text": "requirement that seems to have appeared here because That sounds like a bad requirement to me and directly at odds with the goals of the group. We don't want be able to give the service the ability to put users into groups as soon as they can do that, that creates stability to I guess track people and other unpleasant things. Can you expand on that up just a little bit more. Yeah. So I think that's actually... This concept already exists in the existing architecture. You can imagine creating multiple issuers. That differentiate clients for different applications. So say for the the country example, I guess. Actually use a different example. Say I want to my applications to differentiate an app version. It's not necessarily a privacy issue to say that I need to differentiate app version at signing time. Is a privacy issue if you don't have enough clients in each group. And so we could deploy an issuer bridge app version and we need way to determine that there are many many clients that are doing based on each issuer. So so like instead, Good. I was gonna say, think there's a distinction between the differentiation that occurs. On the origin side and the differentiation that occurs on the issue side. If the issuer is given the ability to make this differentiation through the choice of for instance, different case, I what have you That's a real problem. Because over time, the amount of information that you release about individuals increases. Whereas if the the differentiation happens on the origin side, then... And it's only based information the origin has there's no information channel that's then being created between the issue and the origin. So which side is it?"
  },
  {
    "startTime": "01:00:01",
    "text": "The metadata data here that we're talking about would be visible to both the issuer and origin and is effectively the same. So unless there's a. In... Because it the metadata. Okay. So so Chris off mike's said the client provides this information. And and causes the client to provide this information because we're not just doing this without information. Someone is going to prompt the client to provide this information on what basis would the client make that decision to provide the information. This is this is the difficult pop and I'm I'm trying to grapple away with. I think if it's it's very easy to imagine a world in which the origin says I would like to to talk to this particular issue. Particular if. And the choice of issuer carry some amount of information about the context in which the tokens are gonna be consumed for instance, it's in this geography as opposed to another one. And that's information that the issue. Already has. It's not gaining any any more information where whereas if this were the case that the that the client is then being sort of prompted to take some sort of extra information and and put it in from some other context, then it would be problematic. Could can I give an example of like, one type of metadata, that I think Scott mentioned it alluded to earlier? So information Of tokens was one of the things that you you you I seem to recall you mentioning earlier. So you could imagine, for example, under the perhaps not reasonable assumption that clients have like, tightly synchronized clocks that they say whenever I go to issue a run the protocol, I'm just going to encode you know, the expert expiry timestamp to be like the end of today. And assuming like all clients in the world have the same clock then, like, That just means that the metadata is not unique to any that particular client."
  },
  {
    "startTime": "01:02:04",
    "text": "It's just it's it's... It it be the same across all clients you might run the protocol in that given period of time. But for other types of metadata, but don't have, like, such an easy way for a client to know that it's not unique to them. Then it's potentially problematic. Which is I think what you're getting at. Like Yeah. I didn't quite hear you. I I always said perhaps. Sorry. I was saying that perhaps it's not the most a reasonable assumption that's all the clients have, like a synchronized clock. So I think I think I think there's a solution. So if we are talking concrete about expiration time, I think there's a reasonable solution here. The issue one knows what time it is and set an exploration during a challenge or something along those lines. In which case, it would would be reasonable for the client to reflect that in to the issuer and get something that's that's come back. In that way. The the problem that I have is where the this information coming from elsewhere other than the issue... Than the origin. Right the the origin that once. Yeah. Strongly great. The the issuer provided expiration time that might work as well. But then like, what happens if the issuer is like you know, playing funny games with that under the assumption that the client has, like, an notice clock. And then uses that to potentially try to convey information to the origin. So there's a lot of, like, interesting edge education to consider here, but perhaps there are ways for some types of metadata to to you know, constrain the information that flows ultimately from I guess the client to the origin in a way that is you know, not particular revealing to them. So There'll be dragons, I guess is the you know, The take here. the Yeah. I like to refer to this type of problem as metadata measurement. You need to understand the size of the group that you're in. And now the size of the group here that there and is not just"
  },
  {
    "startTime": "01:04:04",
    "text": "how many users are on this issue? Or it's how many users are on this issue for this particular metadata set. And I think any deployment that's gonna use Really any version of metadata it probably needs to solve this problem itself. How am I going to show to the world and show to all other their clients that they are still private. They're using this particular metadata data set. And this is mentioned in the drop that I wrote and I think we should expand on this. I didn't get everybody chance to read the draft So so that's that's unfair in terms of this discussion. But I think this particular problem is very important when you look at metadata. And actually, you can also think of it as an expansion of the consistency problem that you will. I'll often do rotate keys. Or that allows you to size. You know, the the the the set of clients that were used on each keep. So this becomes... I I I like to think of them as very similar problems. It's about trying to determine the size of the program. Then oh, yeah I did. Oh, I see. Okay. Cool. So we this implementation is based on the spec that was presented. T that presented. We essentially propose a new data type If you're interested, please do take a look at the draft that's on the data tracker now. And the Github is available. As well. I've emailed the the C g about this work and I believe my progress best as well. So you have a convenient link for it. And I would encourage, like, let's continue to discuss public metadata because it just not a trivial topic by any means, especially the use of this context. Me need to make sure that This right."
  },
  {
    "startTime": "01:06:06",
    "text": "Yeah. I just wanna say, I definitely agree that that there relation to the consistency problem that was just discussed and we if we do go forward with the design team, I would I would like us to also consider not just like key consistency, but more generally, like, sort of configuration consistency or however you wanna phrase it, which includes the key material that whatever other metadata you might happen to use to use the protocol. And it. That might have applications beyond privacy pass like os or whatever, but Good Idea. Scott. Okay. Yep. I think there's David's David's, Google, crypto photography ent. I was told that introducing myself in Cfr as doing julius was a bad idea. So sorry about doing that earlier. I just wanted to say that we're we're working on deploying some mask proxies over at Google to support some privacy features in Chrome. And we're considering using this. So I like to I would love for this to, like, be adopted and get a lot of review from a working group That way, we don't shoot ourselves in the foot So Thanks. Chris. I I do think that we should consider it adopting this draft you know, it it's kind of unfortunate that the different issuance protocols don't support Metadata In fact when the regis that we've identified have this column forward does this protocol also better in or not. So it's varies least exercising you know, and if exploring that space of protocols is useful as a good use of the work group time. So I would support an adoption call. Okay. Thanks."
  },
  {
    "startTime": "01:08:03",
    "text": "I think well, I've try to have some more discussion on the list, but I think this is also a good topic first us. Alright. Any other business that people wanna talk about If not, then the last meeting on the last day. See you Next time in San Francisco. Alright. It seems like. Yeah."
  }
]
