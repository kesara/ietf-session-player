[
  {
    "startTime": "00:00:33",
    "text": "Privacy transfers was here. And it bucked up to 1800. So I got here a half an hour early, opened up everything So when it was just Peter and I, it actually brought down piss. 7 something. Yeah. We just have to stop reading. For those of you who might have been hearing, the air quality is not great in the small rooms, it's been really stuffy, so I've opened up the door. So if you guys get cool, just let me know. We can try and figure out how to adjust the temperature. For the sternum room. That's two factions. We're gonna get you want me to do that? I mean, Oh, yeah. You're oh, I gotcha. I need a shirt with a skin logo for for these days, like, my Right. You want me to get Did you wanna share slides? Do you want Welcome to my from the site you would like I can run time and the cube."
  },
  {
    "startTime": "00:02:08",
    "text": "Okay. Well, while we're trying to get up and set up, we could really use 1 more notetaker. We've got Rohit Oh, and Bart? Okay. Okay. So it'd be great if you can capture as well. That'll make our our jobs easier. When we post the minutes. Get released. Don't feel much. Oh, sir. What's up? Oh, he he just unplugged the queue. That's all. It's okay. See. Were disappeared. I don't know. I'm not worried because I can see the kids here. I it go go ahead. Sorry. I need to put you on a good one for this. Okay. We'll go ahead and get started. I look there. Alright. What's that? No. He's a re month. Okay. We are going to go ahead and get started. Welcome to the SCIM Working Group session. It is Thursday, if you were expecting to be listening to something other than how we do provisioning management of identities, you're probably in the wrong session. So Welcome. It is Thursday. So, hopefully, by now, you're familiar with the note well."
  },
  {
    "startTime": "00:04:01",
    "text": "It gives us the code of conduct and the policies for how we run the IETF sessions. I am going to presume you're all familiar with it so that we can get on with the schedule. So administrative, tasks So thank you ro Rohit and Bart for being the note takers. We no longer need the blue sheets But in absence of that, of that, please make sure you Sign in. You can use the QR code. And if it disappears, there's the Keeping to the old style, there should be a QR code floating around if you need it. Some back. It's on the back. Alright. And I will try and so that we don't need to worry about having a as you look. Watcher. Watcher. Okay. Agenda bashing. So We've got some drafts that have been adopted and not quite adopted that we wanna go through. I'm not gonna list them out by 1, but you can see it. Wanted to see if anybody had any comments or changes to the agenda. We do have a full agenda. So, going once, going twice, Okay. So With that, Are you presenting or is Pam presenting? Help. Percent No, Chris. Yes. Come on. On it. Would you like me to turn up the temperature? No. Okay. So I'll be quick. I don't think I need 15 minutes. It's just 5 minutes just to from last week. Ferex."
  },
  {
    "startTime": "00:06:00",
    "text": "Gonna clock you. Okay. Okay. So from the last meeting in IETF, that I mean, Pam present what we have in the use case. Right? The different slides, explain the challenge. Meanwhile, after that meeting, we had a couple of conversations And we saw that we have 3 new scrub, discovered it before and that we like to share with you and are open to more challenge that you think that exists today. Like, Mike? Okay? Thank you. Okay. Okay. Okay. Okay. So first first challenge and that challenge was brought in the conversations that we have with Delta queries, right, It's about the, reconciliation. That imagine that there is, several, resource objects with resource attributes that are the push from the client to the server. And then for some reason, the server change it or buy some inconsistent, something change there. And we need to make sure that now the client, understands that the server has different records because The client is not aware. So at that point, there is nothing that can happen between, for the client to trigger the. Yeah. So it's a big problem that we have to address today. That you have servers that can manipulate the information, the resource objects and resource attributes, and gets to inconsistent that are never fixed until the client again receive some kind of changes in that record. That is the 1st challenge. The 2nd challenge, and we already cover this as a little bit in the previous presentation. It's about the HR application. So now we have entities that, for instance, work, right, that have, information is about resource objects."
  },
  {
    "startTime": "00:08:01",
    "text": "And resource attributes that they don't they want to update to the clients, and that they want to make sure that then there are different applications that can subscribe to them. So They are not providing that information to other SaaS applications but they are providing that information to the IBMs that manage that information. Right? So we no longer have that simple model of client server that you have an entity that to another entity and that's sitting, this stops there, Now we have different resource objects with different attributes that maybe they are not even authorized, and I'm very careful when I talk about authorized because that is a dirty word in, in provisioning, but think about it. Now the provision source for resource attributes for the IRAs can come from different, scheme elements in the in in the in our use cases. So that is a challenge that we need to address at some point. Not the authorized, but who is the owner or who is the person that needs to be authoritative for that specific resource attributes. And finally, and this is a use case that who was already described before. That we need to give more salt into it. More and more, we start to have models where different saas applications are the authorized element for specific attributes. I'll give you a simple example. Let's imagine that we have, for instance, an IDM something like a knock that. That, as all the different attributes for the users But then one of those attributes, let's say the email address, It's not authorized. It's not Octa. That needs to create it. It's created by an external source, let's say a Google"
  },
  {
    "startTime": "00:10:03",
    "text": "Google provides that attribute for the user. And this should automatically provision. Today, the only way that we have to do that is through manual process or super proprietary APIs. Where you can update Okta or the IDMs to fill up that's that attribute. We need to find a way that now attributes can come from different sorts. And these are the 3 challenge that we decided also to bring to the use case that we need to address at some point with best practice and with protocols that allow us to do that. So Next slide. This is, Uh-uh. Yes. Yes. Exactly. This is what we normally see today. This is normal model. That all of us are used to. Right? So we have an IDM, that is the scheme client. That IDM the resource management and all these terms resource management resource creator, resource updater, resource subscriber, it's covering that use case draft that Nancy show in the beginning that is in the data track. So they will be the ones that are the authorities. Let's call it like that. For the attributes. And they are going to do get in the push. A normal operation, to the SaaS application that is going to receive that information This is what we are used to today. But now, how do you address with this kind of model, the challenge that we described before. We don't have any way. So there are 2 possible trends. And maybe there are more. We only thought about 2, and we are opening to other suggestions that can address that. And that what we need to think as a group. If these two trends are good enough, And then we would need to do best practice. Which one to follow based on different conditions."
  },
  {
    "startTime": "00:12:04",
    "text": "Of the SaaS application, the the SaaS Creator the schema creator of the application and out to address it. Right? So next slide, The first one, and I apologize that there is a small bug in the slides. So where you see scheme server, it should say scheme server in scheme client, and the same thing in the other side that says scheme client should save both. Right? So what one of the options that has been described And again, I don't think we have any implementations of it yet, But the option will be that each one of those components the IDM and the SaaS application, both of them are in servers and scheme clients. This address the case of the reconciliation of the information this address use case of the extra attributes and each one of them will be able to push to the other ones the information that they think that they change. We know that each skin client have their own changed database, So if everything's anything changed, it will be updated to the other direction. Of course, and we were discussing these issues. A couple of minutes ago. This will require a net implementation from this scheme implementers today because normally either they are scheme clients, or they are scheme servers, asking them to implement both will be much more complex. Okay? So we need to figure it out when we go to the best practice. When do. Option number 2, In the next slide, Okay. So Pam wanted just to clarify the acronyms. That are in this resource manager, RC is. Resource creator. ARU is resource updater, RAS is resource subscriber. Yep. All of that is defined in the the draft. K?"
  },
  {
    "startTime": "00:14:00",
    "text": "So The other option, and this option goes to the work that, Danny and then Julia are already already show before to us is we keep the same roles. So a client is a client that's set up, but he's a server but the client will do, will will do get that they can get deltas Now all that deltas specify, it's in the protocol that Angel is going talk about in a moment. Think about it. So Let's say that for some reason, the server detects that something it's not correct. And that mechanism, maybe it's outside skin protocol, And then he's going to return delta since the last checking. And this can address the use cases that we already carried before. And we have question from Josh. And and I'm finished from the slide perspective. George Fletcher, Capital 1. I guess be because we're making the assertion that SaaS application can be authoritative for an attribute the question is is how does the server know who's authoritative for the attribute Right? There's some layer that has to go in here to say, know, Google can update email address, but they can't update age or something else. So we discussed that a couple of times before. Okay. We think, and that's why I say alternative is their keyword in here. Right, because it's outside the scope. I think there needs to be some kind of policy agreement between both that they define their own policies that says between them. This is always a a new one to an agreement. They say you are authoritative for their agreement. But, again, I think that will be a side this scope of the protocol. Logic"
  },
  {
    "startTime": "00:16:04",
    "text": "itself. Yeah. I I worry about it from a deployment perspective, though. If we make it out the protocol, the likelihood is that it will not get deployed correctly. And so, that may be something that we wanna consider. Yes. And dim. We discussed that before go further. Hi, Dean. Saks from AWS. George, I think to address your question. Months ago, we spoke about this and what I heard, and I would appreciate the chairs confirming this. Is that authorization is out of scope for this group to define. That's correct. Okay. So I think that's why you're seeing this approach of not defining it, If we wish to define that, it would probably require us to reach out to the group. So you have a good point. And I'm not we saw how we solve that. quite clear how But it doesn't appear to be something that we can solve today given the current charter. So that it is it would just throw that out there to keep in mind about how do we thinking about that in the future, we should think about re chartering or does it happen somewhere else? But but it's a very valid point that we don't know how to answer in why I every time that I talk about authoritative, I put in brackets, right, because outside the scope. Right? Feel I'll just add a comment and it sort of comes from the shared signals world, One of the discussions early on is even for something like a session logout When you're going across domains, which SCIM is intended to do, Sometimes it becomes problematic and you're dancing around the question of control who's allowed to do what? His service acts allowed to deserve to cancel the login session of a user in domainz. That's always becomes the problem. And the idea that that came out with events was an inversion of control"
  },
  {
    "startTime": "00:18:02",
    "text": "And in that sense, you could have the SAS application saying, I'm not telling you what to do by sending you pushing you a command to change the email to xyz I'm just telling you the email was changed to X Y Z. The receiver is always the one who deals with its own access control and he deals with its own authority and by receiving the event decides what to do in their domain of influence. And that's how you get around the access control issue. This came up with security signals, and it's part of the reason we've been proposing skin provisioning events because it implements this inversion of control and it gets you around the access control problem. I'm not saying though that, per George's comment, how do you know who's authoritative to what that's still side stepping that issue. That's just me. So feel do you see that that is option 3, that we have signals that are going to be push whenever. But but, again, this is not an one time event, right, So let's say the the challenge of the extra are a that are authoritative in the SaaS application, how would signals address that use case? Well, you would each time a change occurs to a subject's attribute you would just send that notification. Yeah. But but there all the time because he's authoritative. Right? That's right. So every time there's a change, it's it it just flows across. And if if that application isn't deemed authoritative. You either wouldn't be taking the events in 1st place. Or b, you would just ignore certain events that that you disagree with because you're free to make your own access controlled Cision internally. I think George wants to comment spit"
  },
  {
    "startTime": "00:20:01",
    "text": "Yeah. So I I think, Phil, your inversion of control would work with the option one described here which is basically to say You know, and and the current requirements that authorization is out of scope, It basically would say that a SaaS application If it believes it has an update to the record, you know, may push that back to the server and it is up to the server to determine whether it should accept it or not. Right? That puts the inversion of control back in the responsibility of the SCIM server. Leaves authorization out of scope for the protocol as a whole, Right. And then allows the server to make that determination of, hey, I received something from Google, and it's an email address. So, therefore, I'm gonna accept it. And, you know, I received some other element from Google, and I'm not gonna accepted. Right? And so you've then then basically put the requirements on how to handle that back into the SCIM server. And and And also, sidestep, the whole who's authoritative for what from a protocol perspective. But let me try to clarify. So what you are saying is that it's not option 1 because option 1 means that it's scheme element will be client and server. It's option 3. Where the server is going to do, a signal to the client saying that there is a new, there is an update or a new value for that field that they are alternative it's an option 3 that is missing in here. Possibly, but I guess my question is is in the context of option 1 where you say the SaaS client the SaaS application is acting as a server back to the IDM, which is acting then as client in that context. Right? In other words, I don't know that you need the pubsub model shared signals in order to get the inversion of control Phil was talking about, but I like the inversion of control as the mechanism to"
  },
  {
    "startTime": "00:22:04",
    "text": "to basically sidestep the authorization and basically force the seever of this message from the SaaS application the IDM receiving the message from the SAS application is responsible for determining whether it can accept it or not. Or whether it should accept it or not. Yeah. Right? Because that basically punts on the authorization aspect I was talking about earlier. Because in this model end, it's a problem of the slide. I apologize again. Each one of them will be client server. Right? Yeah. And in that model, you don't even need signals because the normal process of the client and no communication between them, and they completely upset. Right. So I think the key thing is Should the IDM receive a message? Out of band as a client, as a scam client, Right? Correct. It is responsible for determining whether it should accept that message or not. And that is a policy that we don't want to touch. Right? A policy I I I think you could put that in this bag. Right? Because it's basically saying It it puts the control back on the IDM server as a place, but it stops Okay. So This is a reminder this draft is to capture the use cases and requirements. And I think we're starting to get into the implementation. So in the interest time, I've closed the queue. And for those who are still on the queue, if we can just be quick about it because You've now gone to the 20 minutes. So Go ahead, Pamela. Yeah. I just wanna acknowledge what what we heard. We heard some advice that there's a potential line to add to the spec, and we'll we'll make sure that we address that. Thank you. Yep. Thanks, Pam. Danny, hi. Yeah. I just wanted to, sort of chime in and agree with, Apollo Dean of I guess a few other books, right now it's so much simpler to have do what we'll consider, you know, the the the IDM managed logic for what actually is allowed to go where"
  },
  {
    "startTime": "00:24:02",
    "text": "versus putting a burden on potentially, you know, hundreds of SaaS application vendors to manage, like, the logic of when an attribute needs to be pushed based on what authorization they have. Like, everybody's business logic and flow of data is going to be different Okay. Do you have next steps? No. I think next steps will be to continue to do the document into that. I have one next step for you. It's not an adopted draft. I know. I know. So I think we should do that question now. So my question to the group, Do you know how to run the poles? So We're gonna put in on the poll, so please use the meet echo. So the question is who has reviewed the draft? Tame. We've got 4. 4th Okay. So Of those who have not reviewed, we'd like to get a couple more reviews before we can do the adoption call. So can I get a couple more volunteers? To chime in Dean and Angelie. So I don't. Sure. Answer your hunts. So for the note takers, if you can note. Dean Sachs, Anjali, I can figure out her last name letter. And Hans. We'll review. And then for those who have reviewed it, if can at least acknowledge"
  },
  {
    "startTime": "00:26:03",
    "text": "we wanna get a sense of whether this is a good starting base. For us to adopt and move forward. Because we did, and I'm saying it this way because as part of the charter, we agreed that we needed such a document. K? Alright. Thank you, Pana. Next up. Like, I will recuse myself you want me to share? I can I can Sure? Like, the x on the floor, it makes me nervous. That's because they're recording you. So just directions. Don't move. I love dance. I mean, I may dance, but I won't be You you can. It's would like some music? Well, what what do you have? I wasn't aware that this was a possibility Take your pick. I got Spotify. Well, I can't find that. Here we go. Oh, you got it. Everyone. Mike Kaiser from SailPoint. Just horrendous who I am. Just here to give you an update on the skim events spec that's underway. Next slide from the last time only a couple of updates. One is that we set up a new sub registry for events within the SCIM Sima, you are in registry for Miana. There's a minor fix. You can see the email threads, just basically a wording change and location change. And then an update to, asynchronous event delivery, which we talked about last time. Basically adding an error response sample and then added bulk request for async events. Next slide. A little more detail on that. Just to refresh basically what happens is you add a header with the value respond a sync per RCC 2740."
  },
  {
    "startTime": "00:28:02",
    "text": "And it responds with, yeah, the preference is applied, and it returns transaction ID. For later on correspondence. For events getting back. So the question was for bulk events on the next slide. Basically, obviously, if there's already a use case for async request, bulk is gonna take even longer if it's already an issue. And so there's obvious value in supporting this kind of a response Also, it means that now the the full range of, protocol requests can now be a sync. So the question was, how do you handle multiple operations doing it via a sync. And so the proposal that is in the draft now is the next slide. Give you a little more detail. Basically, the same initial response as any request basically putting that in the header for async. And then an event is gonna come back for each operation in the bulk request. If you remember, when it comes back and says, yes, we're applying a sync. It gives you a trans action number. Now each event each event comes back for each of those operations. They're sequentially numbered dash n dash 38 dash etcetera, etcetera. In the draft, their examples of what this looks like. You can see an example on the next slide basically, if you look at the transaction right here. You can see it's got the transaction number. There's an event coming back for this particular, request in the bulk request, and you can see it's dash 1. It comes back with the, the event response so that the original requester knows what had happened with particular request from the book. Via async. Next slide. So that's that's the only real 2 changes. 1 was minor and 1 was the the bulk. As we talked about, there are a couple of imitations that Paul has going."
  },
  {
    "startTime": "00:30:00",
    "text": "Has going up, Paul, and there are a few more that I know about that I'm not at liberty to closed. I know people are working on these in different different aspects. The next draft will have the minor wording fix that I talked about in the email thread Is there anybody in the queue or any questions? I don't know. Phil, are you in the queue? No. I was just going to help out if there are any questions. Yeah. Oh, okay. Yeah. Goes ready. I'm assuming there are are no questions or comments we feel like think at this point, we've responded to most of the the inquiries and calls for adjustment. And so I was wondering if the next step might be for a working group last call. Are there any questions about this? So far or it just has guess we should do another Another poll, has everybody actually reviewed the changes since since the last, has So has reviewed the latest version of the draft. Do the same poll again. Okay. Only a couple. We gotta get better about doing our homework. I do think we can put out, I do think we can probably put out a working group last call on the list, shortly after this, but it would be nice to get some reviewers before we actually do that. 10 so let's do this again. Can we get some other people to commit to reviewing this. Hopefully some other volunteers so that we're not putting all the work on the same people,"
  },
  {
    "startTime": "00:32:03",
    "text": "I'll I'll have to go on here, but he's gotta hold my feet to the fire a little bit on. Fair. Great. If I might also suggest, as a as a reminder, when we do the work last call, if you're very happy with the way the document is and don't want any changes. Can you just tell the working group list I looked at it and looks great for proceed with publication and I support it. So we don't just need negative you know, knits and kind of comments, kind of on. So positive affirmation helps us Thank you Great. So we got, Elliot Anybody else? Can Ma'am? I'm willing to volunteer too. Oh, great. Thank you. Okay. Pam and Paulo. Fantastic. Great. So that's 3 for that That sounds great. Let's try to follow-up on that. We've been having the, we've been doing our informal biweekly calls so we can follow-up on the mailing list on that schedule and maybe catch up during of those calls, Jennifer. Hey. I do think we need to spend a little more time with the sync bulk. Just I feel like there were a few loose ends in our last meeting, so I wouldn't feel comfortable yet. Moving forward. Okay. Thank you. Could you Can could you have actually, have you put those concerns onto the mailing list yet. I don't know if I've talked about it in the mailing list or broad no. I I think I have, but maybe in the next meeting, we could chat about it, or I can bring them up, though. Whatever we like to do. We do have a few minutes to continue discussions. So happy to use this time now for that. Yeah. So"
  },
  {
    "startTime": "00:34:01",
    "text": "And Phil, I'm I'm not sure if we already discussed this, but if you go to the previous async slide. Yeah. I did have some concerns using the dash 1 at the end. To mark, like, different, transactions over, you know, like, transaction 123. Because often the transaction ID would be a UUID with dash is already in. And if we're not like, restricting I think it's just alphanumeric then it could get a bit confusing. To use the dash as the separator mean, it would be the last dash but was thinking about that. We we with a different separator work? Yeah. Maybe like a hash, could be better. Okay. So it's minor, but of the Yeah. Uh-uh. I I think that's Yeah. It's quite common for people to put dashes in new UIDs. So I do see the the issue I'll try and look into that. I I don't know if anybody has any concerns with hash, I'll look into it. Yeah. The other thing was would it be good to know how many transactions you're expecting for the bulk grouping. So you know, we're marking transaction 1, 2, 3, but how does the receiver know when it's done? I think it should know because it sent the request originally. So it should expect if it sent"
  },
  {
    "startTime": "00:36:01",
    "text": "10 transactions you should expect to get 10 events. I wouldn't wanna overload the protocol with you know, I mean, we could then you'd be going like hashone/10 or something. Yeah. They Also important. Also important. And, this is just another detail. I specify that counter is the operations as originally specified by the requester. If you go back into the skin bulk definition, the group agreed that implementers are free to optimize the order So what you could have if that actually happened in is from the original skin protocol. If the operations are proceeded at a sequence, they still required the results set to be given the way it is and we wouldn't be changing that But what you might detect then is that the time of the event or the issued act for the event is not in sequence. Even though the counter is in sequence. That's how you would detect if it was processed out of sequence if you needed to. That's super techie, but Yeah. No. That makes sense. I think my biggest concern was if you know, one of your Transactions never came back. You're just kind of waiting for it. But you don't know if you should resubmit it. Because you didn't, like, receive an error back. So That might be more like implementation, but We could put in text that says you should You should, be returning"
  },
  {
    "startTime": "00:38:03",
    "text": "an equal number of events for the number of operations submitted. I don't I think that would be good. That it okay. It maybe doesn't add much, but Yeah. Mean, there's no assumption that all your errors would need to be handled in async response back, So it might call her a lot. Well, they so that the bulk endpoint requires that all the errors be returned anyway. So we would be issuing those same events So would have the same behavior as in 70 in the original skin protocol. Oh, then if that's the case, it's fine. Yeah. Time visitor. I should be sure it wasn't Okay. So it sounds like there's, if that That issue is have a path forward on and the other point you raised about the separator gonna go back and change that. So we have a couple of tweaks to make to the draft before we should review the, next version of it then. Right? So Yeah. That means for the people who volunteered to review should wait until the the you're reviewing the next version of it. So you're looking at the most current Yeah. I already had to make a change for the I am a stuff. So, I'll just put this in. It shouldn't take long. I'll have draft four out as soon as possible. Perfect. Okay. So, No. I just wanna process clarification. So what I heard is we're gonna mint a dash 4. And dash 4 is gonna go work in your last call. Is that what I heard? Was unsure. It's that sounds that sounds right to me. It sounds like if if those were the last discussion points, we have a path forward on them. So Sounds good. And the people who volunteer it was in the people who volunteered will review it. Before we"
  },
  {
    "startTime": "00:40:02",
    "text": "put into a working device call. Great. So Okay. Publish draft 4. We'll get the a couple of reviews feedback ideally on the mailing list, so we can keep track of it, and then assuming there's no massive, issues discovered in those reviews. Then we will do the working your bus call on the list. Sounds good. Ready? We've got, Alright. Next up. Wanna try it. 8. There we go. B, Okay. First of all, Sorry. Okay. So I'm speaking on behalf of Mohammed and Hassan who are not here today. This is an update on draft. ETF SCIM device model. Dash 01 is what's currently out. The, next slide, please. So, just as a recap, this this draft, sort of turned the skin around. Whereas, normally, you have the the enterprise deployment, I'm calling out to, a resource server like Salesforce or Webex. Whoever, this the way this works is the device, the device provider is the SCIM client, enterprise's SCIM server. The model is modular. We already have BLE, ZigBee, and and Wi Fi DPP defined. We actually have interest from, Fido in terms of"
  },
  {
    "startTime": "00:42:01",
    "text": "doing fighter device onboarding, probably know we're gonna need to do something like wired. I don't know if it's wired. Gonna be wired DPP. That's something wired. I expect we'll see something from matter, and I imagine we'll see some interest in doing something with an ocean. Now you might not know what an ocean is. Innovation is like a really thin, wireless standard. Roman, you would be horrified by its security properties. But it's the sort of thing where you you you have you're doing energy harvesting with a button, and you get your 8 bites out, and that's that. So the form of security generally has is, proximity. Let's see. The work is also relevant to another draft, draft brinkman Nipsey, which stands for non IP control. And NIPC is being presented in AS was presented ASDF. As they are re chartering. And it will be presented in a an IoT ops just after this meeting. Next slide. Okay. We made rather small changes in the draft this time. I think each of these were discussed on the working group. A mobility bit was added. We intended to add we we we intended to add this actually in, the base draft and somehow I blew a commit. So I apologize for that. This was discussed. We made some non normative corrections to the open API model. There were some their client token became client token. This matched the running code that we have. And, there were some folding changes. As it turns out, the I ETF now has a folding standard. We're not yet compliant to it. I will fix that at some point. So the big news is that we have an implementation and, so on the URL there, which is in the slide deck, and I'll I'll send around the scam mailing list too. It is,"
  },
  {
    "startTime": "00:44:02",
    "text": "github.com/iotonboarding/tiedie. Yes, tie dye is misspelled. There were arguments over this I lost. The so the implementation, combines the work of Nipsey and SCIM. So you provision a device onto the network and then for non IP control. You can actually control it. We had a, side meeting yesterday to talk about this, and we had pretty good discussion about it. Having a lot of fun with the coat. We look forward to a lot more, implementations. Issues wanted. Commiders wanted, PRs to the draft that, that we want the implementation to match. Most welcome. Next slide, please. Okay. So we have some big issues that are still hanging out in the draft. The first of which Danny, I hope you're listening because this one's for you. In in, IETF 17 oh, 17 there was a request to handle non IOT device provisioning. And, where we left things there was that if these were, I, I would say, relatively incremental changes or changes that fit neatly with what's there, then I think we'd go one direction and just incorporate Otherwise, we should, probably bifurcate. We have to figure out which is the appropriate a way to go, but I don't actually know which way to go because I don't know what the proposal would be. So, Again, proposals. Welcome. Had a bit of a discussion, Phil, right, with versioning, and we're not quite, I think, closed on that. And one of the issues that we have to close on first is we do, like, a per model version or a per object version. And we we can actually go both ways. And I I actually have I don't really have a a a strong view on it. I think"
  },
  {
    "startTime": "00:46:05",
    "text": "At the end of the day, we're probably not gonna do a lot of updating of just you know, one document with 1 one one object, but we might do a couple at a time. And so it might make sense to go at the object level. It's sort of direction I'm leaning, but I'd like the working groups view on how best to to to expose versioning here, and I really need a little bit of help on it. To be honest, now, Next point is, security considerations, as we have the security appointed to know that it is really just TBD at the moment. However, I have been being least in my head. The there there are some issues that are substantial that we need to cover in the security considerations for this model. The device provisioning functions require credentials to be sent relating to the device. So this is something that does require some thought some, some serious consideration. And some understanding of when the model is appropriate, when it is not appropriate and what the limitations are. So, It's impossible, for instance, for a device to that only supports a pass key function, it, that the end, at the end, that the provisioning system needs the passkey, for instance, in order to access the device. But if that provisioning system isn't speaking for the end user if the device in terms of control And maybe this function isn't appropriate, so we're gonna have to put some words around that. So the other thing is that it may be possible to split the difference and allow for encryption over the top in some cases. There in fact, that might be very in important. In some, in some examples, like, the one that we are currently implementing. It's in healthcare."
  },
  {
    "startTime": "00:48:00",
    "text": "The last thing with the plumbing us what, what, to have to worry about HIPAA compliance, because we're look be because we have access to the bits. So we really actually don't want to look information, but it means that there needs to be encryption on top. As, as we, but that's mostly that's an issue more for nipsey then for this. Now the ina considerations also need to be filled out this is something I also I'll need help with. So At the skimmers dinner tonight, I'm gonna ask for people to give me some guidance So there'll be homework and maybe as I'll be. Reward to. I don't know. I can send chocolates to the person who has the best example, And then you we we can actually compete because part comes from Belgium, and I'm in Switzerland. And you can look at the chocolate and compare. Yeah. That's right. We agree on that one point. It's just which way the the needle goes. Extensibility, is an issue that we wanna make sure we cover in the draft. It's not quite there yet. Extensibility means that, really, they're gonna be different connectivity technologies. If we go back to a previous slide, you'll notice one technology that wasn't on the list was Laura, believe it or not, we've had requests to to do to do something for Laura on this, and it seems to make sense. So, actually, what I'm thinking about doing is taking one of these and then testing and extensibility mechanism with it. And probably the one that's least you know, may maybe the one that's the least likely to be broadly implemented. So if you screw it up, we don't screw it up too badly. Another approach would be if we screwed up, we better learn quickly. And so maybe we just do that in an implementing, you know, implementation draft. Analogy is the the way that that HTTP HDP had worked. Can you explain what Laura is? Laura Wann is a, it It it it's a low bandwidth, 80254"
  },
  {
    "startTime": "00:50:04",
    "text": "technology that is that that goes a little bit further than say, BOE, it's meant to be on cell towers and such. So you get a little broader coverage, but sometimes it's used indoors as well. Especially in places like factories. Okay. So, A couple of slides forward, maybe. Yeah. Okay. Next slide. So, All this having been said, Sort of towards the end of the spring, we we'd like to be complete. So we actually wanna move relatively quickly. We're we're actively developing code which means we're actively developing the drafts that are attached to the code. And we're looking for collaborators on that too. We've got a a lot of work to to do. So I would also, therefore, like a pony. If we can actually complete this in time, I I think I think I should deserve 1. The code is right there. It's it's the so there are 2 GitHub URLs. The one that was earlier was for the code. This one is for the draft. I think I have an issue with chairs at this point in terms of where you want the draft to to reside I'm only really making any changes to the draft that, assuming they're non editorial only ones that would be made would be ones that are are at least brought to the attention of the working group 1st as is, I think, send you the link Okay. And that's it. Questions, discussion, he got a proposal for me. There you go. Yes. But I'll just apologize for being like, hey. I think and then disappearing off the face of the Earth as far as your concern, but, I I I have been trying to the get to the point of having a proposal for you."
  },
  {
    "startTime": "00:52:00",
    "text": "Yeah. Up, Okay. I'll ping you again before the end of the year if I don't hear from you. Yep. That's good. Okay. Hi, Dean Sachs. Amazon again. Elliot, I I co chair the enterprise plan working group at Fido. And so you and I have some shared interest here. I expect we'll talk at dinner tonight and talk about Pony's as well. But, I I I I I think there's some some really interesting ideas to how you can use skim to pre provision, say, Fido devices, like hardware keys. And I'm not sure that's exactly what's happening. With the recent Okta thing that came out, but, it this seems like an area that we should explore as we talk about the straps. So, oh, we'll be happy bend your gear over that at dinner tonight. Right. So, let me just add a couple of comments on this. So I've been working with Jeff Cooper on this. From, you know, from Intel. What we've really recognized is that what's what the SCIM model here provides is, a dispatch function. In the enterprise. Right? The dispatch function is, oh, This is, a a a BLE device using, pass keys. Here's here's the next process, that you're gonna go to, or this is a WiFi device using, you know, DPP, here's the dispatch function that you're going to go to or a matter of, I for Fido. Right? What that for Fido device onboard, there might actually several different dispatch functions, like one for wire in terms of what you do and and re relating to the rendezvous server or one for, what you might need to do in wireless, which might be a little different. And so, Now I'm not I am not the FTO expert. As it happens, nor am I. Right. So I figured I'd just go to the FTO experts and have them help me. Yeah. I So I I think there's"
  },
  {
    "startTime": "00:54:00",
    "text": "In addition to the FDO use case, I'm thinking hardware keys, Lake. I have a bucket of hardware keys with enterprise adaptations on them, and we can talk about all the details at some point. But, I could pre provision those and then assign them to users and you would effectively you could effectively use a mechanism like that to pre provision that credential And then once the user receives that hardware key, you have to have a way to unlock the hardware key in order to use the credential and that mechanism is is undefined and and probably far out of scope for SCIM. But I think it's an interesting use case that we can we can certainly discuss. Yeah, Dean. The other use case I think is directly related. I think that brings in a couple of different aspects. The access control within the SCIM model becomes a very important aspect there. We have a similar use case involving Webex devices. Where advice might get provisioned from the, from the partner, which in this case would be Cisco, and then the deployment needs to may wanna fill in some detail like, oh, this device is gonna go to so and so. And once they do that, right, you get a really nice, a 0 touch experience from the user's perspective. So, yeah, absolutely. We're we're interested in that use case, and I think it also might bind a to the work that's going on in EEP this week relating to, the heap Fido presentation that was given. And emo great. I look forward to hearing about that from you Okay. Other questions, comments, Like, there's one other person Hands on the Yeah. I have I have one. I live Hello. I wish I was there with you all. So quick question. I think this all makes a ton of sense, and I think it's very straightforward. And I would love to see us get this out of GitHub and into data tracker, if possible, but the One concern I have, you know, this is gonna sit in a pantheon of resource types. And my one concern is that devices are very generic word here."
  },
  {
    "startTime": "00:56:03",
    "text": "And that I think there could be a future need for devices that are not these kinds of devices but might be more commonly used by people who need to have a memorable 4th you know, thoughtful name. Have you thought about whether there's a more specific name you could give to this resource type to to differentiate it, say, from smartphones or lap tops or other things that might be more prevalent in the enterprise. It's a it's a fair question. And and I'll I'll I'm gonna struggle to answer it. But but but Let me give you my best shot. In my view, right, in my world, on, I connect devices so it could be that we're talking about a network device. You know, I have a very network centric focus, and this is about provisioning the network. The the the customer deployment as far as, you know, what I do at Cisco. So we could call it something like network device information, if you would rather. But what is more what is really important to me is to try to provide the appropriate horizontal solution across all the types of devices that you're talking about. Right. Right. Now, I'm I'm up for other approaches. I just I don't have a great answer beyond that Well, I will say that I don't think the industry has a good This is I think a pervasive problem in the industry that we don't you know, that devices is an overused term. So but maybe this is a bug in your ear. Absolutely fair point. We could call it something like IOT device, I mean, I'm not sure that's much better. Network, IoT device networking provisioning information, if you'd rather I'm I'm really up for, you know, anything the the working group might might think more appropriate"
  },
  {
    "startTime": "00:58:03",
    "text": "Yeah. It might also be really interesting to see if we could actually have a generic device category. And if other use cases would fit into it too, So instead of having you know, many different types of devices. If we potentially could get to one device class that you know, covers multiple use cases. So that that was, Bart Brinkman. Bart is an first time IATF Attender. Welcome. And so he hasn't had to suffer the grand unification theory of device models before here. So, there may be there may be some pain hiding there that that I think, Pamela's going towards. Give me 2 minutes, Danny. Go ahead. I dropped out here. Okay. Alright. Okay. I'll give you because we did adopt the draft. We did adopt the draft. So it's just giving you the repo in the Yeah. Skimoid and, yeah, and just working and working and working. And, you know, and as much as we're doing interims, we'll need them. Yep. Okay. Sounds Thank you. Alright. Queries. Delta queries. Hello, everyone. So I'm Angeli from AWS. And myself and Danny have worked together on SCIM Delta queries. Last IETF, we presented, some concepts, around Delta query. We had, at that point in time, 2 options time based approach versus, change database and how we go about it. So during the past few months, we have aligned on an interface"
  },
  {
    "startTime": "01:00:02",
    "text": "layer that, aligns or that abstracts the implementation out of it and would be able to support both kind of implementations. So, I'll go through those. Next slide, please. So what is the goal of of this draft. So we do have provisioning API within scheme. What we are missing is we don't provide efficient APIs where some scheming vendors can implement a reconciliation mechanism or identify changes or deltas within the system. So we we all look forward to an ideal system where things would happen perfectly, and there are no divergent data, but but that's not the reality. So things always go wrong, and we may have divergent data apart even though we have a syncs syncing system. So what this draft goes through is providing a set of APIs can efficiently detect changes within the server and report, and those APIs can then be used by, skim client implementers to compare the dataset, the changes from what they have in their system and then take actions, necessary actions. Maybe it's reprovisioning, of that item or or manual intervention to fix that issue. Maybe they detect a bug which can get fixed. So so The whole draft is around providing a new interface or extending the existing interface to support for getting incremental updates on resources that have been updated or deleted within the scheme server. So we do have existing APIs to list all users or list all groups, which can be used to get the full set of data and compare it with what in the scheme client and detect the changes. But that becomes a performance nightmare when we have large scale of data. And this API provides you changes to be retrieved from us"
  },
  {
    "startTime": "01:02:01",
    "text": "point in, point in time or a reference point of the last scan. So, this is what we are going to propose. So let's go to the next slide. So we have, put together key requirements on, these APIs regarding their behavior, like resources modified since a specific point in time point can be returned by a query. Now it modified. It could be created, newly created, updated, or deleted. What it returns is current state of resources. That you can compare, with your skin client what the current status and find the deltas. Able to convey, that a previously existing re resource was deleted from point in time. Just reiterating that, we want to retrieve deleted objects as well. And ability to convey changes to group memberships. And we want these APIs to be performed at a large scale with accurate results. In any other, requirements that anybody else from the group think about, and we are feel free to provide us as feedbacks, we can add it in the draft. Next slide, please. So how does it all work? So The way it works is the first step is obtaining the first Delta token. So we are extending the existing, resource your eyes. So get users with the Delta query parameter, which is a Boolean parameter. And as the client sends request, in response, it will get everything that the server has. So this is like not different than what your existing get user will do, but with a small change that on the last page, or on the last response, it will return a next delta token. Which can then be used by the scheme client to send a new delta query and only ask for changes that have been done post this, point in reference."
  },
  {
    "startTime": "01:04:01",
    "text": "So as part of this, first query, this we call it as a full scan. It returns all the resources that It does not return any prior deleted records, that have already been removed from the system. Resources returned will represent the latest state of the resource at processing time and in the response it returns on delta token, which is basically a marker or a reference for the server to detect Okay. This is the point in time I have a point that I have returned records records up to in this request and when this client sends a next request. I need to send records that have been modified after this reference point. This token is opaque to the client client should not assume any, meaning out of it. This is just, the server to understand it and decode it to, to execute the next request. Oh, next late fees. So as step 2, once this client has done a full scan, they can, send a next Delta's query, which is we call it as a Delta Scan It's up to the client, at what interval they want to send. It could be 5 minutes, 10 minutes, 15 minutes. The quicker they send, they will get less I mean, the payload size would be lesser and they would be, more closer to what has been, what has been out of sync in the system. In response to the delta scan the server will return, only the resources that have been modified. That means either they are created or updated or have been deleted after the point represented by the Delta tokens value. Resource return will represent the latest state of the resource at the time of processing, and it will again deliver a next error delta token and the last the delta scan response, which can then further be executed by the scheme, sir, client to get the next set off."
  },
  {
    "startTime": "01:06:00",
    "text": "Changes. So this will allow the The the biggest, thing, biggest benefit that this provides is that your amount of, like, data that has been returned is is lesser and lesser and, it becomes much efficient and faster. Next slide, please. So this is just reiterating that, what is the changes to the resource representation? So the newly created and updated resource, does not change. No additional change to their existing, state a response payload, they will use the standard representation, and the current state is returned. For deleted instances, we are proposing, change in the meta, attribute, complex attribute to add an additional field called is deleted, which basically depicts that these are the deleted, resources. We only intend to get some meta information so that the client is able to compare it with the record in their system and understand record has been deleted. Next slide, please. So we have also considered some pagination, considerations just to reiterate, So this draft is, considering, like, if you are using, crusher based pagination, and the server has implemented. So if you are returning the delta query, response, then it will return next cursor to paginate through the responses And only on the last page, it will return, the next delta token. And in each query to return a next page, this client would send the same Delta token that it had provided for the 1st phase this just aligns with what we have also proposed in the cursor based pagination that while you are paginating the query parameters should stay the same. On next slide, please. So"
  },
  {
    "startTime": "01:08:00",
    "text": "The client can retrieve the subsequent pages by providing the cursor value. In the parameter, rest of the URL remains the same as in the first page request. And subsequently at the last page, on the cursor based pagination, on the Delta query response, the server will will respond with the next delta token. This So that's just represented in this, request. Response, you can see here, there is an else next delta token ponded because this is the last page of this current scan. Next slide please. So, we are putting some normative requirements so that because we are not going on the implementation scenarios or giving guidance on how it should implemented, but we are making sure that we the draft has enough normative guidance that it drives the requirements. So service providers must not present resources from being updated while implementing, this query. So we're not proposing that there is any locking mechanism to this to be done on the underlying resources. This query is completely stateless. New items can be added or existing items can be removed while paginating through the response of the the either the full scan queries, all the delta clients can queries. The delta query, however, must guarantee that we do not skip any records while paginating. So if there have been dates to the underlying data source where our new records have been updated, but they were not responded back in the current deltas can query. They must be returned in the next delta's inquiry. So that's something that server has to manage as to what point they are if, they are returning this Delta delta token and that considers, that there are no records missed between the two scans. Next slide, please. This is just addition to server provider configuration. This this functionality is definitely not"
  },
  {
    "startTime": "01:10:03",
    "text": "mandatory. So servers implementing it can, provide an information, whether it's supported or not. So that clients can decide if they can if they are able to use this, API or not. Next slide, please. For group memberships, scheme currently does not support a pagination on large, complex multi value attribute. Such as group memberships. So along with Delta query, how we how we anticipate this can be done is is basically in the Delta query, not only for group review changes, but also if there are additions or removals to the group membership, the the day the group will be returned as part of the Delta query. And for each group returned in a bug query, you retrieve the current active members of each approved by using, filters. That's what is supported today. And then you compare the group members and receive the received from the work query with your current state and and with the source system. Above approach works, but in case the groups contain large sets of members, this approach is is becomes inefficient. So we're looking for inputs of what else can be do in the draft, what extensions can be made so that, we can make this process more efficient. Next slide is. So, yeah, so, we've not able to publish, so we have this draft in the GitHub repository, we will be publishing in in the data tracker probably next week. So we're looking for feedback input PRs and issues, so that we can make this draft better. And for us, next steps are, getting more feedback and updating this route, with those feedback and, and moving forward. With it. So, Angelie, you can"
  },
  {
    "startTime": "01:12:02",
    "text": "post this on the data tracker. Yes. And when you do just remind the people on this give me list and solicit feedback there. Go ahead, Danny. Yeah. So I just wanted to I guess, try and then add what to, sorry, to what, Angelie, presented and say that the draft that get hub that's about to go into the data tracker. We've decided essentially, you know, at certain points, just make decision on something, like, you know, to write something for some of the approaches. I I know within the working group, both on the mailing list and then, you know, previous meetings like this, there's been a lot of discussion on this. It's a very complex topic. There's a lot of history across identity and other generators like LDAP. That, like, what neither of us are I guess, asserting that's, any or all of what we've written is the best way to do something, but they were, you know, laying out a Foundation So curb, start discussion and hopefully get us to, There's something serviceable. So, yeah, feedback. This. Great, Pam. So right now, the spec talks about, have to do what they what the spec calls a full scan query. To get the 1st Delta token. What if the collection is too large to do a first full scan query. I mean, you have to start at some point where you have the full span. And, Like, can you explain, like, when you say that, collection is too large to Like, what other mechanisms you are, pointing to"
  },
  {
    "startTime": "01:14:00",
    "text": "Well, you you may have uploaded a CSV file. For example, like, there are a bunch of ways to bootstrap a collection, right, not all of them are skin based. So is there a way to get a token based on that or a way to get a token on a partial or a a way to get it taken maybe just on a an object like, just only requesting object names rather than entire objects. Does that does any of that work? We we can take that input. Look into it. But I'm not sure if if we can because the the reference point is that what has the server returned? So we can if we make an assumption that the scheme client assumes that whatever the the 2 data's the sis 2 systems are in sync, and we just want to start from moving on from this point onwards, then, yes, we can look into an approach where a a Delta token can be responded back. Instead of doing a full scan. But that just based on an assumption that resuming that Before this point, the 2 systems have the data. Okay. Perfect. Thank you. Yeah. Yeah. Yeah. Phil, did you wanna say that on the mic? Sure. Phil Hutt. Yeah. I was just wondering, yeah, could you just ask for a token as of now? Yes. Because the client already knows, and you'd just don't want the data. Yes. Yes. I think that that's, something that we can add to the draft. Options. Team. Insacks from Amazon again. Angelie, I'm I'm desperately wracking my brain to remember. Can you get the initial query from a search to then get a Delta token. I think that addresses Pam's question about instead of having to do a a full scan of the database. You could do a subset of that with a search. Then get a Delta token from there."
  },
  {
    "startTime": "01:16:02",
    "text": "Yes. And I would like to add. I didn't include it in this slide, but any filter parameters that, apply to any of those resource is they can be appended to the Delta query. So if you don't want to, like, do a full can, you can always have a filter applied. And then, when you're doing the next scan, then you you use the token and apply this in filter. So Perfect. Thank you. Yeah. To, chime in a little more on that as well. When we were writing the first version of the draft. This is a topic that Angelie and I did discuss. Essentially Yeah. It could be summarized as whether or not the, the bullion, Delta query parameter to Pixar things, needed to be tied to an initial sync, or can you pool or, like, can your precisely that's being asked? Can you, use the, the the the watermark for perpet, like, you know, with not the exact same focus necessarily or like, a, you know, a partial query or really anything to say this is the point in time. Can you can you issue the token and then use it to for a different query or different set of results later. And Yeah. We can, I guess, look at feedback and, figure out what the, what the right direction is? Calo, pulp. So couldn't we get the token in the initial sync? So when you have the client doing the initial sync with server, the last thing that is provided in that initial sync will be the token. Because we assume that when you do the initial sync between the client and the server, then the server has exactly same information. Only from there on, the information is going to change. Yeah. So that's what we are saying that once this client has"
  },
  {
    "startTime": "01:18:00",
    "text": "the full sync initial sync. Initial sync. They can, just call this query without doing a scan, like, getting the full result and just get the token. So that just sets the baseline. So we are basically in the first first point is setting up the baseline. Now how do you set up the baseline? You either are sure that whatever right now is in both sides is perfectly synced and we just need a token to set up the baseline. And we don't return the actual full set of resources, we just give you a token back. The server gives you a token back Okay. This is your baseline token. And now you can use this delta token in your sequential inquiries to just get the changes. The other option is if you already have the data in both systems and you're not sure that it's in sync, then you can do a full scan and also get a a baseline to like a deltas scan token. So you have both options. But what will stop you giving the token immediately when you are doing the sync. And assuming that the server is only going to start to create them, I don't want to call it change database. You don't like it. That's the whatever we have after that, after they finish that process. So the token could be given immediately in the initial sync. Right? But, how does server know that now the sync is complete from, a scheme client perspective because Skin client is just sending post request to the server. Server does it know that, okay. At this after this record, the sync is complete. Right? So you the scam, sir, client will still have to send something to say, oh, I'm done. I'm sick. Right? So I think doing that get on a resource with Delta query And maybe we add additional that only need a token, not re need, like, all the resources is just setting up that baseline and getting the token. So so what we are saying in here is that until you receive the token, from a server perspective, there cannot be any change."
  },
  {
    "startTime": "01:20:02",
    "text": "That will be an implementation implementation decision from the server. So you cannot do any change to the data that you are receiving. Until you get that token. No. That's not what we are saying. That's still client driven. So client drives when do they think that, okay, now the systems are in sync. Either they can do a full scan with the delta query, and get the token or they can say, okay. I know I synced it just now, and now I'm so Bennett sent the last record, the initial sync, you can just send a a query to the server and say, give me that, token because now is when I will start doing the Delta Sinks instead of doing like, I'm going to start doing the Delta queries. So let me recap. So client is going to do the push with all the hackers. Yes. Last task that he does. He does. The the the get to the give the token. To get your token. To get the token. What I'm saying is that, server will not do anything will not start to create the audit log or the change database or whatever. Until he receives the get So some kind of Yeah. I'm not sure if we are trying to say that that server will only start to create a change log at some at a specific point in the server can create their change log because when they're getting this client updates, they get they will be managing their internal database to manage But then you can have inconsistencies. I'm not sure because it's going to give you a token back from the point in time that it is sent all the records, Sure. But until the point that he he sends the token back then you are saying that if in there isn't like, he'd only state in the server itself."
  },
  {
    "startTime": "01:22:00",
    "text": "You Yeah. to lock any resources. We'll not lock we're not proposing Between server and client interaction because that doesn't work out when you scale But then we go back to what Pam was saying, right, because it can take a very long while until you get the initial token, and then you have inconsistency already there. I'm not sure if you will have inconsistencies. Why would you have any consistencies at that point in time? Because it took too long for that first token to happen, and that to that point there was record of this course. But it is it is going to give the token at the end of the last page that has been returned. So it has basically given you all the updates when it is return returning you the token until that point in time. And then it will just give you, start tracking the rest of the changes. After the token is given back. Okay. Well, let's discuss offline. I'm thinking Okay. Okay. I will we'll work it out. Mike Kaiser from SailPoint again. Denian Angelique. This is a great start. Thank you. Wanna start there. I'm gonna put in a PR after I talk to you about this, Angelie, about maybe contributing some language to the approach, the early section of the document, saying that if you're doing Delta queries and they're taking forever that you might want to think about doing Delta queries more often because the idea is you're not using huge pagination. Question or 2, is it ever stated, I guess, it's implicit that or implied that each token is sequential, from the service provider side. Is that fair to say? We haven't stated it, but it would be Okay. So you could get 1 Delta token and send the service provider isn't saving state isn't saying I'm giving this token to this client per se."
  },
  {
    "startTime": "01:24:03",
    "text": "It's not client specific. It is global. So server doesn't keep track of No. bot token, it sent it to what server, what client. So it's a global you could you could technically request different resources with the same token. In a I mean, I'm not suggesting it. Yeah. I'm just thinking of I'm thinking of abusive, yeah, abuse of this approach. In case we wanna head head it off, Yeah. So and and maybe, another statement that's basically saying it sounds like and I agree with this. That responsibility for using it well and using it appropriately It's put on client. Client. Yes. Not on the server. The server's not tracking. Son of work. Yeah. Server takes the responsibility that whatever that pointer is, it doesn't miss us any in between if they have changed. By by by how you use the the token that's on client side. Okay. Thanks. only have 5 minutes left. So let's keep this up. We Dean Sachs from Amazon again. I think Mike, to your questions, kind of what we were talking about earlier downstairs. If is, This is specking out the restful APIs and the interface between the client and server we're not specifying what the client does. We're not specifying what the server does. Those those implementation details are outside of what Skim can specify. It is simply about the interface that is between the two. And I think that be begins to address that question. Now it may be unsatisfactory because the client may do things poorly or the server may do things poorly. But that is outside of the realm of what we can specify here in this room. Yeah. Absolutely. You can put that under considerations too, by the way. That's a great idea, Nancy. Yeah. Alright. Okay. Great. So I guess next steps on this is upload it to publish a data tracker, which you can do now the unlocked now. And make sure to"
  },
  {
    "startTime": "01:26:01",
    "text": "post an update to the mailing list. Yes. People can review it. Thank you. Right? Great. Any any other business? I don't. Think so? Any other business? Going once? Going twice. We give you 3 minutes back. Mhmm. Great. Alright. Thanks, guys. So let's just keep the dialogue going on the, mail list. Right? Alright. Thank you. Thank you. Look at that. By them opening the door, it dropped a 100. Oh, not spec up. I don't have time to put the report and decide. Kasan snacks. Oh, it's snacks. Okay. Nest Yes. Do you wanna upload the minutes or the minutes were trying to I can I can I can clean up? Okay. I was trying to fill in some of that because I don't know if you there was like question mark in there. And so I was like, both of you guys need the tag team. Right? So let me know if you need help with coaching. I'm doing a working group last call. So just like I showed you this morning, Yes. You can ask for early review on the skin. Just like I was supposed to do that on the Okay. Yeah. You can call it early review or you can do You can do early review because we may end up doing a couple of workings with last lines I'm I'm either Okay. If we make significant changes,"
  },
  {
    "startTime": "01:28:04",
    "text": "thing. You have to do another work.com. Yeah. Okay. Yep."
  }
]
