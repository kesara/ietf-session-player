[
  {
    "startTime": "00:00:14",
    "text": "so i'm conscious that uh it's now half past two in vienna uh half past whatever the hour is wherever you are so uh i think that's probably our cue to kick off ed are you alive and well yeah excellent so um welcome everyone uh welcome to the uh ietf113dtn working group uh what we were very pleased to say that vinsurf has joined us to say a few words about the operation of the ipn sig and his opinions on state of play of dtm so what i'm going to do is going to run through these chair slides pretty promptly because vince on a bit of a timeline and then we can get straight on to him and then get on with the regular working group business so um as this is an ietf meeting you should be aware of the note well this meeting operates under the note well if you have not attended any meetings before and have not read the note well i strongly recommend you go away and do it in your own uh time it covers ipr behavior the fact that you are uh waving your rights to restrict uh it gives us the rights to record for posterity the any comment you may make at microphone and if you turn on your camera etc uh the bcps which cover this in detail are detailed on this slide please reach out to the chairs the ad or anyone else within an all-time idea it can point you at the actual material uh because this is the first fully uh hybrid i would say post covid but i think that might be a little bit ambitious meeting um there is an in-person participant tool as well as a remote participant tool this is to keep meet echo operating well between those"
  },
  {
    "startTime": "00:02:00",
    "text": "who are set in the room and those of us like myself dialed in uh if you we're operating a single mic queue so if you have questions please download the uh meet echo lite onsite tool onto your phone i think it's all done as a web browser and that should allow you to join the queue correctly and we can manage a single queue without hopefully too much disruption it's been working well so far uh so yeah if you are on site please keep your audio and video off otherwise we get terrible feedback loops remote participants it's just like it's been for the last two years so um just operate the meat echo website as as you always have done so uh here is a little bit of uh boilerplate just in terms of the main agenda for our atf-113 is here we'll cover the working group agenda in a minute uh meet echo further information is also here the irony being that i'm displaying this through meet echo so if you can't see this how do you see the url but hey and if you need any technical uh assistance there's a dedicated issues page if you are stuck in the room and none of this is working i suggest tapping the shoulder of the person next to you maintaining covet distancing and ask them for help and they can hopefully show you a smartphone with some kind of url i'll point you in the direction someone who can help so agenda we uh this is the admins administrator from the chairs a quick five minutes just to cover where we are and what we're doing uh and then we've got uh vint kindly for 25 minutes and then we're kind of into the meat of new charter items updates on existing documents and ed and i both have a couple of questions to put to the working group which we've done as a set of slides which we'll squeeze in at the end we've got quite a packed schedule so we've only got five minutes for open mic so you'll have to excuse the fact that i'm speaking quite fast and clicking buttons quite quickly"
  },
  {
    "startTime": "00:04:01",
    "text": "administrative so there is an integrated note-taking tool it was called codemd but i believe mitocho have moved to a different tool it's markdown based it's interactive our secretary adam is currently hopefully logged into it i haven't checked please help him get the minutes correct particularly around your name which is always difficult to grab off the mic and just double check if you're making comments that it's been captured correctly and and your point was was correctly documented and if you're just feeling generous please help us out keeping those minutes an accurate record for for posterity as usual the the mailing list is dtn at itf.org that's where the main business of the working group happens so long drawn out conversations we will point at the list and please subscribe monitor and contribute on the list would be great if you want to contact the chairs it's dtm hyphen chairs ietf.org that's a great place for procedural questions if you start asking us technicalities we will probably redirect you back to the list and continue the conversation there in public um one thing i did want to add after ietf112 was we did discuss our recharge that rechartering has happened i recommend people to look at the new charter page for the dtn working group it is as was agreed at the previous itf meeting we've had the sign off from the iab it's fully approved and we can move ahead with the topics we wanted and also most important we have four rfcs so the last four six years of hard work updating bundle protocol tcpcl bp sec uh default security context around ppsec are now a nice set of rfcs so well done the working group that nicely bookends the previous epic amount of work we put in and allows us to start a new chapter really"
  },
  {
    "startTime": "00:06:00",
    "text": "from this meeting onwards looking at uh the next steps for the dtm working group and i think that loans unless ed has anything to say do you want to jump in no that was a wonderful introduction i just wanted to say congratulations for getting those first four rfcs done and we're looking forward to the work well that's more charter but now let's hear from ben yes absolutely i'll stop sharing and uh so rick just uh two things i want to say first please scan this one if you want to be because we don't have a uh physical blue sheet this time so please scan this one so that you are in the enlisted so if you don't do that you you will be here but you will not have that in that in the list please do that and second one i would like to repeat that congratulations this this working group it has been nice working with with this and recharging went really well and thanks to the chairs and thanks to the authors to the 48 who has put a lot of effort to get things right so vent after you thanks ahead then we can see your speaker notes rather than your screen just for reference and i think you're on mute afraid i think you're still on mute"
  },
  {
    "startTime": "00:08:04",
    "text": "sorry about that um i'm puzzled because uh his work just fine a moment ago and i don't see why what is it that i need to do to get it to show the full screen it seems to have grabbed the wrong window that's weird that's all right well let me stop let me stop and go back why try again oh i have to click yes okay you want to share your screen yes chrome tab oh i see what happened presenter view is that what i want i get confusing how's that yes that's it you're there wow you know considering i only have two slides this is really painful well first of all let me thank you for allowing me to invade the meeting i haven't been a participant in the dtn working group and so i actually appreciate your tolerance second congratulations on all the progress that you've made and third we you have many many folks around the world who are very very uh excited about the work you're doing the work you will do with under the new charter and the opportunity to demonstrate for many others of the efficacy of the standardization that you've already accomplished so i we are i am representing in this talk the interplanetary networking special interest group which will is in the process of becoming the interplanetary networking chapter of the internet society uh the special interest group was formed in 1998 and it was parallel to the work that began at the jet propulsion lab and has now expanded to a wide range of uh nasa laboratories as well as other"
  },
  {
    "startTime": "00:10:01",
    "text": "space fairing agencies like issa and jaxa and others so the effort over the past what now almost 24 years has yielded a great deal of output including all the work that you've done so the ipn sig group uh is as a small board uh yosuko kaneko is the chair he's also a senior member of jaxa scott burleigh is the vice chair uh and has recently retired from the jet propulsion lab but is still extremely active as you all know in dtn matters mike snell is the secretary treasurer and has uh served the ipm sig for many years i'm just a member of the board oscar garcia who's present today in the call is also the chair of our projects working group and extremely active in implementing uh both the dtn protocols and also applications that go on top of them as is alberto montia and keith scott all of you know is uh extremely active at mitre and then the ccsds program for standardization of the bundle protocols we have over 800 members scattered i won't say exactly uniformly but not not too uniformly around the world which is very satisfying there's a lot of interest in the work that you're doing and and in the prospects of interplanetary networking the ipn cig has created a number of working groups in order to progress its efforts the strategy working group produced a report in 2021 uh which is available on the website and it looks to the next hundred years of evolution of the interplanetary backbone network there's a projects working group led by oscar garcia and it's actively implementing and testing"
  },
  {
    "startTime": "00:12:01",
    "text": "the protocols and i'll come to to that in the next slide there's an architecture and governance working group which is asking the question what does this look like as it begins to evolve as we leave planet earth and we begin to build an interplanetary backbone what are the terms and conditions for operation one of their multiple parties who are implementing pieces of the interplanetary backbone what are the rules by which uh the entire operation functions and uh as we ex extend our human operation beyond planet earth exactly what does jurisdiction look like what are the rules of the game for uh for operating in space so this is uh still uh more or less uh i'm sorry i'm being distracted by the fact that there are a bunch of guys hanging uh on the side of the building cleaning my window there's nothing more slightly uh you know weird feeling i'm on the 16th floor of the building and there are people who are watching this presentation uh there is a library um which is accumulating a great deal of information about interplanetary networking and i urge you to have a look and also to contribute to that of course all the work of the dtm working group will show up in the library there's an outreach working group which is intended to draw the attention of the general public to the uh work that you do the work that the ipm state is doing and ccsds in order to stimulate interest in space exploration and also the commercialization of space speaking of which the last working group is is a business working group which is trying to understand what will be the way in which commercialization of space"
  },
  {
    "startTime": "00:14:00",
    "text": "unfolds and many of you who are watching the return to the moon will know that there are for-profit companies spacex and many others that are quite interested in um what it might mean to operate in a commercial sense off earth ranging from mining on the moon to manufacturing in zero gravity to entertainment and travel all of those things are possible and we are i think at the cusp of that change as we see companies like spacex and others blue origins beginning to explore the possibility of i would say popular space travel and so i think all of you might look at 2022 as a kind of a a knee in the curve of possibilities or we're making use of space travel uh their strategy report is uh mentioned in the last uh line here of this slide and i draw your attention to it because it's our attempt to summarize what might happen over the past over the next 100 years or so here are our intentions at least as i interpret them as the interplanetary networking special interest group the first one is to implement and test a terrestrial and low earth orbiting network based on the dtm protocols that you standardized and the idea here is to make sure that people can see that this actually works that it's a reliable robust uh and resilient system we want to assure ourselves that the technology the implementation of the technology is solid before we start sending things off planet to distant locations because it's harder to fix things remotely than it is to fix them while we're still in a terrestrial operation"
  },
  {
    "startTime": "00:16:02",
    "text": "so this is partly to persuade ourselves and others that we have a scalable and operational system in particular we're very interested in assuring that the network management and security and configuration features of the design are actually implemented effectively and can be used easily by anyone building a piece of this interplanetary backbone i'm sure all of you by this time appreciate the network management in a highly varied delay and potentially disrupted environment does not look like the network management that we've come to know in the terrestrial internet ping is not your friend in the interplanetary environment we're interested in showing that these protocols are capable of supporting useful applications and so we'll be testing messaging and real-time video and federated artificial intelligence and machine learning among a number of other applications and we encourage all of you as you think about possible ways of using the protocols that you've standardized to inject those ideas into ipm sig as well one thing that's uh i believe pretty clear to all of us is that there will be multiple parties operating pieces of the interplanetary backbone in the same way that there are many parties operating pieces of the terrestrial internet and so we're going to have to make sure that a multi-network uh construct actually works well that the independently operated but cooperating portions of the interplanetary backbone can actually uh interwork in the same fashion that the terrestrial internet has uh has demonstrated and so that's a very important uh issue to resolve and finally uh on this line anyway we also need to make sure that various implementations of the"
  },
  {
    "startTime": "00:18:01",
    "text": "bundle protocol will interwork uh successfully so that's another opportunity for us to demonstrate the quality of the of the work that you've done we are expecting to collaborate with a wide range of different parties the project working group involves about 20 or 30 people as oscar garcia can tell you who are all working on various and sundry demonstrations of the of the technology uh the you uh nasa of course has a dtn working group and they are parallel to the work that you do and they're busy uh implementing the protocols and testing them in a variety of environments including the international space station and looking forward to uh the return to the moon lunanet at nasa moonlight at esa among others uh are programs that are being undertaken by the space agencies in the return to the moon and of course we expect the dtn protocols to be a part of all of that at utica college there's a very active engagement in the implementation and test of the protocols as well as uh el modio who is also present at this meeting who has a testing laboratory and i've left out a number of other players and i apologize if if i didn't include you in this list i just want to make sure that all of you appreciate that there is significant and growing interest uh in the in the work that you've already accomplished to say nothing of what you're going to do in this newly chartered period i mentioned earlier that the commercialization of space and the departure from from earth creates all kinds of really interesting questions about the governance of um of operation in space not just of the interplanetary backbone network but all the other ancillary things that one could imagine whether it's mining on the moon or space laboratories uh you know"
  },
  {
    "startTime": "00:20:00",
    "text": "habitations uh on mars you know as we look further out into the future the question is how is that all going to work and it's not obvious now one thing that i can tell you is that in the artemis return to the moon missions a substantial amount of work on governance was undertaken in what's called the artemis accords which are adjunct to the many space treaties that have already been agreed in the past the artemis accords take a fairly broad look at uh what it will be like to function uh in on the moon uh with multiple national and private sector entities all interacting with each other exactly what does that jurisdiction look like how will disputes be um resolved if there are any what does it mean to own private property on the moon how do we fence off historical sites like the landing uh the july landing in 1969 uh among other sites and of course uh extending that to sites on mars and uh and other planets and uh and moons of our solar system so this governance framework discussion is bound to get off into a variety of weeds and it does require substantial attention in order to make sure that we can operate in space in a in a friendly and cooperative way and finally um this is the last slide and also the last bullet point uh we're very interested in drawing public attention to the work that you're doing and the notion of an interplanetary backbone and so we're looking at if you remember the search for extraterrestrial intelligence seti at home allowed people to download an app that would take in radio signal received digitized radio signals to look for irregularities we'd like to do is build an"
  },
  {
    "startTime": "00:22:02",
    "text": "to allow people to help us exercise a terrestrial implementation of the bungle protocol system in order to test its ability to scale up uh and to manage uh various and sundry you know failure modes to identify and recover from them so there is a very uh significant uh agenda that the ipn sig has adopted and i hope that many of you who are already planning on standardization work will join us in implementation test and demonstration as well so i'm going to stop there let's see if i can stop sharing my slides and return to uh to the meeting and thank you for the time i didn't take 20 minutes or 25 minutes and i think that that's good because you have so much work to do that giving you back a little bit of time seems like it's a good thing and you've had enough of it surf anyway so i'll stop there and i have a few minutes before i have to go to do something else if there are questions or observations that any of you want to make or corrections if i've misstated anything so if if we don't have someone uh sort of coming up to the my task of the specific questions uh the one i would have is i i look at the audience participation uh here the the number of folks we have which is higher than uh we typically have and so that says to me that we may have a few people here who are new to dtn as a set of technologies new to the bundle protocol as as as the mind behind the initial uh intention for standardizing store and forward could you give just a couple of sentences to those who may not be familiar with bundle protocol on why this is the protocol for doing this kind of activity uh well i'm happy to do that"
  },
  {
    "startTime": "00:24:01",
    "text": "many of you will perhaps remember that in 1997 a pathfinder robot vehicle was landed on mars successfully after 20 years of failure the previous success was 1976 with the two viking landers and then nothing worked for a long time so there was great celebration that we finally got back to mars uh with a successful landing uh the following spring at the jet propulsion lab i went out to meet the team that was responsible for the communications support for that pathfinder project and we asked ourselves then what should we be doing now that is to say in 1998 that might be needed 25 years later and we came to the conclusion that we should think about an internet for the solar system in order to support demand and robotic space exploration and of course from today's perspective also to support commercialization of space so we said well can't we use tcp it works okay on earth why wouldn't it work on mars and the answer is well it will work on mars however we started doing the math for interplanetary distances and discovered very quickly the tcp with a 40-minute round-trip time has a lot of trouble with flow control so we decided it was time to rethink this very different parametric space recent protocols needed in this very different parametric space and we began to design the bundle protocols and as all of you know we've been through now seven iterations of the bungle protocol design hopefully this one will be stable and we can now stick with implementing and reinforcing and standardizing it but you can tell that the speed of light is simply too slow and we can complain to mr einstein about this but nobody's found any way to fix that"
  },
  {
    "startTime": "00:26:00",
    "text": "so we've had to adapt our protocols to accommodate not only the variable delay which is significant but also disruption caused by orbital dynamics and planetary rotation which we don't know how to stop either so um that's what led to the work that you are now presently engaged in uh and it's uh it's actually been a lot of fun to be forced to rethink uh uh networking protocols in a different context brilliant thank you thank you ven um zahed you've got a question in the queue hello i hope you can hear me right yeah so first of all thank thank vin for being here with us and sharing this really exciting ideas and agendas i mean this this this looks really cool um uh so i think i have two questions to you and not really about this old technology one one was like um for for this itf working group um and we have reached our day i don't know like if you have seen that when we're more looking towards the addressing and how to reach things and maintenance and stuff like that do you have any particular suggestion or like an expectation from this working group that that we can take on with us as you are here i'm sorry i didn't i are you asking about a solution to ad no i'm thinking i'm actually more likely what do you think what is your expectation and what is this ip6 expectation from the dtn working group in itunes oh oh oh well well first of all of course we want you to continue to refine the protocols and take and to take into account that not only do we have to deal with these highly variable delays and disruption but we also want this to work in real time so if for cases where we actually have"
  },
  {
    "startTime": "00:28:01",
    "text": "low latency i would like to be able to do streaming video like we're doing right this moment i'd like to be able to build applications that will function reliably in the same way that they function in the present day internet is just that the architecture has to include the entire range of delay and disruption and so when it when we have low latency everything should work pretty much the way tcpip does but yeah when we don't have low latency it has to work in the way that we intend with the dtn so that's one thing the second thing i think is that we'd like very much to see more energy put into applications uh to understand what it means to build a delight tolerant application and finally uh i mean among many other things i i'd like to exercise the naming and addressing structures in order to regularize them and come to agreement about how that should be managed as you all know we have in the internet the iana the internet design numbers authority and on the ccsds side we have senna and i'm hoping that that will be a parallel operation that we can rely on and finally commercialization you should be thinking what does this mean to use this stuff in this mixed environment where you have government investment in government operations and we have commercial operations how does that actually work and can we make it work in the same successful way that we have in the internet on earth yeah thanks thanks for this i think uh from your what your expectation from this working was like i think we're already dealing couple of things the addressing thing the maintenance things that the configuration part of it i think this this is great and the real time thing i think we then we need to have engage a bit broader itf community to that one like what because we already have some established protocols for those kind of use cases and bringing the"
  },
  {
    "startTime": "00:30:00",
    "text": "boundary protocol and the same kind of thing might be a bit like we need to think a bit more holistic way of looking at it and see like how this fits into current architecture but i think the point you made like getting the architecture uh this electron architecture into the into the so-called internal way of doing things it'd be a nice combination to look on so thanks for those words and thanks thanks for being here well thank you all very much i do need to go off to another meeting but i wish you well and the rest of this one and certainly again thank you for all the work that you're doing because it's enabled us uh to be uh active in promoting the interplanetary backbone work that your efforts support so i'll bid you adieu safe journey thank you very much vint thank you and uh yes run run if you i know you've got a hard stop so thank you very much thanks so much thanks so uh just as i i joined the cube briefly because we i have a presentation at the very end of of the agenda for this meeting covering um two of the points been raised about uh naming and addressing and some of some early steps forwards which would allow some applicability within the terrestrial internet so for those of you who can bear it now that vinta's finished please stay until the end um because we're going to cover some topics there which which should open things and in the rest of our agenda is equally as interesting but a big thank you for vint in retrospect for uh for speaking so ed i'm going to hand over to you because i have spoken a lot oh no that that's totally fine but i i think that now in the interest of time we should go into our agenda items my my understanding uh is that we are going to present slides uh for our presenters and manage them so that uh individual presenters don't need to share their screen and otherwise go"
  },
  {
    "startTime": "00:32:01",
    "text": "through their clients is that correct so uh the latest version of meet echo has the ability to share slides centrally and to effectively pass the next slide please functionality to the individual presenter so they'll get a little strip appears at the bottom of the slide deck in their window and they can click forwards and back so scott i will pass the slide control for this slide deck and you should see within your meet echo that you now have a little strip across the bottom of the presentation view which allows you to step through the slides how elegant uh can you hear me yes we can hello scott hi all right well let's let's start then um and i'll try to get through this in 25 minutes um uh i've got two presentations here one on bundle bundle encapsulation one on quality of service which are a couple of the items that are in the new charter uh the uh bundle model encapsulation presentation actually is a very little change from the one i gave in spring of 2021 this is uh to refresh everyone's mind on uh what this is about and uh and to introduce it to anybody who missed the earlier presentation on it i think this is a an important um technological feature for uh for deploying a useful delay tolerant networks in the future so um i i think it's worth spending a little bit of time on um is this gonna work okay good i'm gonna slide two all right uh the overview of the presentation i'll give a short history of uh vibe uh and uh talk about custody signaling in that context the current uh vibe design and uh possible applications and then just a note on the future use of the thing um you know short history"
  },
  {
    "startTime": "00:34:00",
    "text": "uh uh vibe actually goes back to 2009. uh some of our colleagues at mitre corporation put together this uh internet draft um in uh august of that year and the idea at that point was that uh one bundle encapsulation would be a a bundle protocol application now the basic idea of five is that you use one protocol to send uh bundles um that is the the the payload of a bundle is another bundle um it's tunneling and the same kinds of advantages of tumbling in in the internet uh applied to um a bundle model encapsulation in in dtn the specific motivations uh cited in in in that original draft were uh support for for content centric networking uh forwarding cash bundles um targeted custodial retransmission of multicast bundles which was an open problem at that time and security in particular defense against traffic analysis which nothing else that we were looking at at the time would provide um we were busy with a lot of other things so bob never really went anywhere um for the ensuing four years um and and i picked it up again in 2013 um but with a slightly different um organization that is instead of being uh instead of looking at vibe as an application on top of bundle protocol um i think it's important to look at it as a convergence layer protocol underneath on the protocol so it you know still have bundles and bundles it's a question of where you you stack them in the stack and and in"
  },
  {
    "startTime": "00:36:00",
    "text": "particular the idea at that time was um we were trying to disentangle routing from security there were problems with the original security protocol for for bundle protocol and in particular it was like really locked into this notion of security sources and security destinations that made it possible for security to get in the way of effective routing and this is a a mechanism for for getting around that if we wanted to preserve the specific security source and security destination features um at the same time there was a lot of discussion of custody transfer in 2015 2016. in particular there were a couple of things that were discovered that what made it just not work that is custody transfer as in funnel protocol version 6 had two significant problems one was that the retransmission depended on accurate uh estimation of round trip time so that you could know when to retransmit and the general case that was not possible because you didn't know who was going to be the recipient and from and therefore from whom you should expect a custody signal so you had no way of knowing when to expect that signal and when to determine that it was late uh another uh serious problem was that the bundle fragmentation by non-custodians which is perfectly okay couldn't be prevented and it would defeat custody transfer because the uh uh anything that took custody of of the fragments those custody signals would not match up with any bundle that any current custodian had had custody of uh at the same time though there were scenarios especially um scenarios in involving unidirectional links where"
  },
  {
    "startTime": "00:38:00",
    "text": "uh some sort of delay tolerant asymmetric acknowledgement system is going to be needed uh and bundle protocol is an obvious uh mechanism for delay tolerant asymmetric acknowledgement so why not use it for custody transfer so um the the concept uh that that emerged was that uh and i'll i will put this as a as a proposition that um bundle protocol transmission reliability is something that needs to be accomplished uh between neighboring protocol nodes it needs to be accomplished at the convergence layer because of the same problems that custodial re-transmission um um ran into in in bbv6 uh in in that sense if custody transfer is gonna happen at uh as a reliable transmission mechanism that it needs to happen at the convergence layer so you should use bundle protocol as a as a convergence their protocol and of course hang on blibe is already doing that so why not just add uh custodial re-transmission as a a feature of vibe so that vibe would do uh two things independently or or concurrently um across domain security with sources and destinations and giving us a defense against traffic analysis and also reliable convergence theory transmission over asymmetric path um separately from all of this back in 2012 there were researchers at the university of colorado boulder that had designed a more bandwidth efficient definition of bpv6 custom transfer it was documented in an internet draft that actually never got posted um uh sebastian kuzminski and uh andrew"
  },
  {
    "startTime": "00:40:00",
    "text": "jenkins at uc boulder were the developers and it was very effective uh it was developed as a as a prototype and implemented as an option in the interplanetary overlay network implementation of dtm and uh and has been in use in um in operational transmission from the international space station for um about five years now and and very well received uh it's been highly successful in operations the user community likes it a lot and so uh if if we if we take this uh aggregated custodial signaling concept and use that as as the implementation of of the custody transfer idea in a bundle of bundle encapsulation the result is this uh draft that was posted in may of 2018 and has been sort of sitting there waiting for somebody to do something with it since then what you end up with is aggregate custody signaling as an optionally reliable convergence layer protocol underneath bundle protocol and the encapsulated bundle could can be encrypted and or assigned and providing additional security features that bpsec itself does not um so um here's the the single slide sort of laying it all out the payload of the encapsulating bundle comprises a transmission id which is used for uh linking custom signals back to the bundles that are being acknowledged uh the expected time of acknowledgment for that bundle and and that's"
  },
  {
    "startTime": "00:42:00",
    "text": "important for for signaling to the recipient when to um wrap up the advocate uh custody signal and send it back so so that it'll arrive in time to um to turn off the re-transmission timers for the bundles that are being uh acknowledged and then the encapsulated bundle the acknowledgement itself uh is um an aggregate um structure that is uh conveyed in a new administrative record that is sent you know in a bundle that responds to the the uh bundles themselves and it includes a custody transfer disposition code such as it's a reason code essentially and then sequences of of consecutive transmission ids overseas bundles if the acknowledgement is not received by the expected time then transmission of the encapsulated bundle is assumed to have failed and the encapsulated bundle is uh re queued for reform um something that that uh came up in in discussion of this with um uh with goddard space life center quite recently is what if one or both of the participating nodes don't have accurate clocks uh we have the um bundle lifetime mechanism uh provided for for for operations of you know at the bundle protocol but what about bundle model encapsulation is this going to be an expected time of acknowledgment how is that going to be expressed so that that needs to be addressed in the next edition of of this internet draft uh some some mechanism that enables the sender to say here's when i expect um an acknowledgement and and for the receiver to understand that and"
  },
  {
    "startTime": "00:44:02",
    "text": "and use that as a trigger for sending the acknowledgement uh aggregated signals back uh okay uh given all of that i'll very briefly run over a couple of the applications for this technology and then move on to the next presentation and maybe take questions for everything at the end um i think that bundled bundle encapsulation actually is kind of if you set your mind to thinking about it there are a a a number of weird kinds of scenarios that uh vibe might be helpful for here's the the one that the the nominal mechanism that we use uh before which is uh custodial reliability now that custody transfer has been removed from bundle protocol we still want to have it here's a place for it to be and here's a pictorial representation of how that would work um uh similarly across domain uh security um it may be that uh for large parts of the end-to-end path uh the bundle doesn't uh need any particular security and and then it it needs to to cross a danger zone and in across that danger zone you encapsulate the original um uh uh unencrypted bundle as the payload of of a protected bundle an armored bundle that crosses the no man's land um defense against traffic analysis if you um even if the the original bundle is uh safely encrypted you may still want nobody to know where it's going to where it ultimately"
  },
  {
    "startTime": "00:46:00",
    "text": "comes from and you can do that by um encapsulating it uh in in in a bundle between two well-known uh points of the network and and the the final destination is not revealed until the bundle reaches uh a safe part of the network um uh but that sort of transientness of security can be extended to entrantness of quality of service it may be that the bundle doesn't need any particular quality of service mechanism applied to it while it's in um local subnets but across the the trunk line of of the network it it it needs some sort of special markings so that it's handled in a responsible way and the that sort of quality of service marking can be done uh with bundled bottle encapsulation um again the the transientness of of vibe is um helpful for things like um critical forwarding that is uh one of the features of the expanded extended class of service mechanism developed for ebb six is this critical uh bundle idea that ensures that the bundle has got the greatest possible chance of getting to its destination well maybe it doesn't need all of that is additional sort of multicasting and multi-copying for for all of its and path but maybe for part of the the journey it does and a way to do that is to encapsulate it encapsulate the original bundle in a in a critical bundle and that critical bundle you're sort of guaranteed is going to make it to the to the far end of the"
  },
  {
    "startTime": "00:48:00",
    "text": "danger zone and then the original bundle uh can be removed from that and multicast in the same way maybe only uh part of the network needs to care about multicasting enough in in a way to ensure that that the bundle reaches its destination by sending forward multiple copies um source path routing uh is a a sort of bizarre but actually potentially useful uh thing you can do with with a bundle of bundle encapsulation just encapsulating multiple layers that will sort of guarantee that the the point-to-point uh transmission of the bundle along a specific sequence of uh forwarding elements um and combinations of these things certified multicastle you know there are a number of weird things that that that you can do with unfunded encapsulation and still be well within the the the rules and the guard rails of a responsible bundle transmission um all right so uh let's um [Music] switch over to the other presentation and i'll try to knit through it quickly sorry scott do you want to take questions on this now or i i i can't if there are some that are ready right away uh i wanted to make sure to get through everything and not hold everybody up so um okay i have one very quick question on that sorry uh on about slide 12 or something you said something about uh one or both parties not having uh clocks i wanted to just go into your do you mean they both don't have a a synchronized wall clock or do you mean"
  },
  {
    "startTime": "00:50:01",
    "text": "they both can't count seconds or milliseconds uh uh they uh they uh imagine um one or both of uh well actually imagine the sender in particular um does not have a its clock is zero it's a broken claw and so right and so it's it's identifying bundles strictly on the basis of a counter and um but it can't measure time in any way the only only way it can express the retransmission the preferred rate transmission time is is is in an interval yeah okay thanks yeah yeah uh joshua you're in the queue if it's a quick one go for it or we'll hold to the end uh we'll see if this uh unmuting actually works correctly or not uh so this is joshua deaton over here at the marshall space flight center uh and uh just a quick question might just be my uh ignorance from uh being new to this particular group uh for this vibe are we considering specifically tying vibe and ct together or are we considering it more as bi being a standard and ct being more as kind of like an extension of vibe so i'm going to step in as chair here i don't think that is clear in the charter they are down as two related but possibly separate topics and i want to ask that question as well but can we let scott get to the end of his presentation and pick it up there because i think that's quite an in-depth series thank you okay um let's switch to the other and i'll this one is much shorter"
  },
  {
    "startTime": "00:52:00",
    "text": "one second while i close this is this in the same slide deck scott or is this a different no it's a separate deck okay uh do uh you should be able to change deck by the little button in your little toolbar you should be able to say open new slide deck and find the next set of slides uh oh okay i thought you guys were doing that i can do that if you want uh if you can yeah that'd be great okay so uh oh i have to tell you to stop slide sharing i then share and it is that one chef um give you the control back there excellent um oh and the little bar can i get that bar you should have that bar i have clicked the give control i'm not seeing it and yes i'll keep clicking it or i'll try doing it let me try re-sharing there it is i got it got it okay cool yep okay good uh okay uh the next is a quality service and um in addition to um bundle um to um uh custody transfer being removed from bono protocol in the bpp7 specification quality of service had been in in bpv6 and it also is removed from bpd7 so here's a a an attempt to cover the quality of service um issue for bpv7 and um and elicit the conversation on this topic so what i will uh suggest to start off with here is that the the fundamental job of the bundle protocol agent is to"
  },
  {
    "startTime": "00:54:00",
    "text": "forward bundles to topologically adjacent bp nodes that's basically what a bpa does it needs to do a lot of other things in order to do that it needs to compute robson various other things but but the thing that it mainly does is forward bundles to um to other nodes that are topologically adjacent to it using convergence their protocols to do that so when when multiple bundles are queued up to be forwarded to a given topologically adjacent vp node how does the bpa decide which one to forward next and the bp specification is uh silent on this uh by default the queued up bundles are just forward up forwarded in in queue order in first in first out order quality service would be a mechanism for um uh would be an alternative algorithm for making that decision uh on on various bases and among the considerations here are uh how urgent is this bundle which one's you know the book you should send the urgent ones before others um and and assurance that is a guarantee is that if some um an application has has negotiated a guarantee that it gets 20 of the bandwidth from a to b then uh if it's um if it's if it's time for it to get some some some of that bandwidth then that bundle should go even if other bundles are are a higher are higher priority more urgent so um a quick um survey of quality of service um that that i drew mostly from from wikipedia uh uh the the zeroth order solution for for quality services over provision right if"
  },
  {
    "startTime": "00:56:02",
    "text": "every bundle that you present uh to be forwarded uh is forwarded immediately then quality services move there's there's no queue so the next bundle that goes out is the one that is going out right now you can over provision to some extent but i will suggest that we'll never actually be so over provisioned that this is a total solution so um next quality service in the internet uh i am very very far from being an expert on quality service the internet i hope i will not screw this up too badly my understanding is that um the the two general flavors of uh internet qos have been integrated services and differentiated services um uh inserv is a negotiated service reservations for sender and receiver pairs it was the earliest of the quality of service mechanisms developed for operation on the internet and and it worked fine but it doesn't easily scale because the the number of uh sender receiver pairs that you need to support can uh increase exponentially also it's it's sort of not a a good choice for a dtn because it's not delay tolerant uh negotiation in general is not a delay tolerant mechanism so um diffserv looks like a closer fit um it's somewhat newer in the internet although been around for many years there's a differentially differentiated services code point uh code a value that is asserted in the packet header a six bit number that selects per hop behavior and the"
  },
  {
    "startTime": "00:58:01",
    "text": "parameters of per hop behavior are things like priority subject to admission control uh assurance of transmission uh that's the reservation um uh sort of uh mechanism again provided that the traffic rate that was negotiated is not exceeded and also likelihood of dropping a packet when the link is congested those are are among the parameters that go into the per hop behavior options there is no guarantee that a given router will exhibit the requested behavior for a given packages that is uh there isn't anything that that disqualifies a router that happens not to um conform to the requested services and um that that um the penalty for that uh non-conformance is really outside the protocol it's a matter of business um and then the the last part of this survey is okay what did we do in version six there was a class of service value defined in rfc 5050 uh based on the the idea that uh dtn is somewhat like uh mail and so the postal model of of of class of service was introduced uh three classes of of uh service bulk standard which is like first class mail expedited which is like express mail the processing of this was not defined as usually understood to be a priority but nothing in the protocol said it had to be and it was frequently observed that this is all on the honor system that is it doesn't cost anymore to mark a bundle that's expedited"
  },
  {
    "startTime": "01:00:00",
    "text": "than to mark it as bulk so why would not all data be uh all bundles be expedited why would you say oh my please don't send my my bottle uh slowly i don't care you probably wouldn't do that so the the there was limited um [Music] utility to to the class of service as defined in rfc 5050 which is why it is removed so um there was so an additional internet draft that extended that class of service mechanism uh prototyped in in the ion implementation there was a that extended class of service included an ordinal tag which is a more layers of um of prioritization for expedited bundles so scott um i'm watching i'm watching the clock you're five minutes over at the moment can you uh can you can you accelerate in some way uh yeah yeah i am trying to but i've got a little bit of a late start also uh i have trouble there there are um uh service selection flags best effort reliable critical and um and a numeric label a data label that is undefined and but likewise that's just you know anybody can say anything so um a a problem with mechanism called service quality of service mechanisms that discussed here is that there's an assumption there's no head of line blocking that his course quality service gets a chance to operate i mean fairly frequently and that's that's the case for ip because packets are very small uh bundles are not bundles can be very large so head of line blocking is very possible and that would uh inhibit the operation of quality of service mechanism uh we still need something uh i'm"
  },
  {
    "startTime": "01:02:00",
    "text": "suggesting here that uh what we might do is is add a bundle processing flag for uh quality service handling is requested and and and only allow that flag to be turned on if the bundle is less than 64k so that quality service makes sense and then along with that say that all bundles with quality service flags set to one get handled uh before and it bundles for the set to zero so that quality service wins um and given that you might define a quality service extension block that has uh some sort of uh type of service request something like the the flags and ecos and or a numeric data label um and then adam and i and a registry of data labels and the the corresponding requested per-hop behaviors in future rfcs and again let implementation of perhaps behaviors be a node implement administration responsibility with no guarantees same as basically deaf serve that's the end of this presentation so um any questions talk about now in the remaining 12 seconds thank you scott sorry to rush you though it's um we've got a tight schedule thank you for all of this um i think it's uh particularly the second part i think you're you're heading definitely in the right direction as far as i'm concerned that's me speaking personally not my chair hat on um going back to your first presentation uh the the the the elephant in the room is can we do reliability without uh sorry custody transfer without requiring bundle and bundle encapsulation and and the answer certainly we could have uh i i in my mind it only makes sense to do it as a reliable convergence their"
  },
  {
    "startTime": "01:04:01",
    "text": "protocol i don't i don't think it makes sense anywhere else for the reasons that we removed it um from uh bpv6 uh so it certainly could be a a separate um reliable convergence layer protocol distinct from bundle and model encapsulation my argument here is why i have two when you can use one to do both jobs but uh i'm certainly open to talking about doing a different way my my reason for not combining the two was was simply thinking in terms of overhead if if if the custody transfer mechanism uses an extension block or or some administrative record then you're not having to encapsulate an entire bundle and it's um you know bp sec information or what however you know these bundles can get quite fat if you're not doing a full encapsulation that might give you some more efficiency on the wire or am i misunderstanding that because i haven't got data if you if you um if you're using a if you're implementing a reliable conversator protocol every every reliable every every converge their protocol encapsulates the entire bundle right so you really don't get away from the capsule in something okay thank you thank you i need to go back and reread this but thank you go ahead zahid so scott uh i okay i came up because of the third bullet on the current slide uh so no guarantees as dissolved so basically i think they if you look into the if you would like to learn something from the dip serve that it actually not it didn't get deployed that much or it if it get deployed it didn't used so it didn't deliver what it promised for so i mean i think"
  },
  {
    "startTime": "01:06:00",
    "text": "if you really would like to get the reliability really get together differential service and everything we might actually need to think a bit more before we kind of mimic what is in deep serve just like question here i mean it all depends on what we want but but deep server is a not successful one that's what i'm saying uh right i i uh i i if i came across as as advocating that we implement diffserv then i misspoke i think this serve is uh is a very uh reasonable example of the kind of thing we want to do i don't think it's the model for bundle protocol yeah that's that's then i'm in the same place thank you because that's exactly what i think i think this this reliability thing you know whatever prioritization we talk about what about like kind of different services we talk about this service not really an ideal model for that one i i am further with you on that no problem thank you sure okay i'm i'm gonna draw a line under the the queue at this point thank you very much scott um this is both all three of these subjects are really important and and on charter and we need to continue um possibly even an interim on some of these topics might well be worth it so we have a bit of time to drill into some of this but we'll take that to the list to see if there's an appetite for that so uh right i'm going to retract your ability to show slides and uh thank you very much brian uh it's uh you let me share your single deck of everything and give you permission to take control and um on you go thank you very much all right i can see it and uh i combined all my slides together so i'm just going to go through them uh it's the rough order of priority here"
  },
  {
    "startTime": "01:08:02",
    "text": "um so the first thing to talk about is is maybe the simplest which is the administrative record type registry and what this represents is oops that um in rfc 9171 there was an explicit table of record types and bpv6 itself did not define a pre-existing record but another rfc after bpv6 defined this registry and uh the point of what this topic is doing is just adding bpv7 to the iana registry as a column indicating the applicability in the same way it was done for uh bundle processing flags block processing flags and block types and the other thing that recently i noticed was that as scott just mentioned the ccsds did standardize an aggregate custody signal and that code point was never actually rolled back into the iana registry so i'll talk about that in a second but all this is doing is it's just the bookkeeping of making sure that the registry is accurate and up to date and then as a side effect of that it becomes then usable for bpv7 allocations so vibe and an allocation uh needed for acme to do um node id validation both would make use of this registry and the registry as it sent before was specification required uh there's no plan on changing that and because it's specification required then uh on the next slide here i'll show what the the changes would look like that um code points one two and four were already pre-existing four actually was the one that was"
  },
  {
    "startTime": "01:10:00",
    "text": "missing but because it's documented in a specification it probably does belong there just to indicate that it is in use and then the only other thing this document does is it makes a reservation for high value code points which because these are cbor encoded eventually mean that that last line is 32-bit values so that's four byte encoding all of the unassigned specifications required are 16 bit values and the majority of the specification is just text wrapping around the iana table update um so on this topic then uh this is still an individual draft um i'm requesting adoption of the document and and then at that point details could be worked out about exactly what the text says and what the tables contain but this is really just a currently a placeholder for there needs to be some kind of a record of administrative record type allocations um so that's it on this topic uh are there any questions immediately okay just saying noted your uh request for working group adoption we'll do the uh the relevant um administrative here on the list and and just put it out there see if anyone's got any objection but it's a very sensible stretch okay and it's quite short that's the intent is it's just touching this one table and that's it yeah yeah indeed you've got slightly noisy mic there's a bit of fuzz on that if you can okay thanks try to take care of that uh the next uh topic is a cozy context for bpsec um this was discussed at earlier ietf so i'm going to get right into detail and some of this material is overlapping"
  },
  {
    "startTime": "01:12:02",
    "text": "with previous discussion but the idea is that bp sec has a default security context that's intentionally limited in scope it does the job that it needs to for a number of symmetric key algorithms um it doesn't include things like key identifiers uh that would be needed for uh certain rollover situations um and it it's not a bp stack is made to be extensible but the default security context um are just limited by design so for uh internet facing uh nodes and interpretation especially for things that like scott was just talking about security gateways processing and unprotected external network things like where you have to interoperate retain agencies that's where pki is really the current standard of interoperation and one way to get pki uh immediately off the shelf is using um cose the seaboard object signing in encryption and uh it is almost purpose built for this kind of one directional security application and on the next slide i'll show some information about the the idea here is that this is falling in the existing bp sec paradigm it's using existing parameters and result allocations everything it's very nice that kosa actually does fit extremely well within the bpsec framework that's already in place and uh part of what this is gonna do is it's it's adding more um even more extensibility to to bp bpsec that"
  },
  {
    "startTime": "01:14:00",
    "text": "in a even in a tightly constrained environment there are abilities to use pki uh with cos a that are already in practice and in use in other applications and the last gain is really that the cose as an active working group is already in progress of uh standardizing on some hybrid public key encryption and post quantum cryptography algorithms so these things are already being worked there in active development and a cosec security context would be able to take advantage of these things when they become available so the idea here is that one context would be given for both bib and bcb and it's the type identifiers that distinguish the different uses and this is how kosa already operates that there's one cose structure and within that structure there's a differentiation between signing mac behaviors and encryption behaviors and uh cose also brings with it the ability to use a pki environment and also the the ability to transport pki secondary information so cos a itself can embed um things like x 509 certificates and in the future potential other certification data then uh the one thing that cos a does not define is a real usage profile coset is fundamentally a container for security data but it doesn't give you a tight definition of what belongs in a coset message and so part of this document is defining how do you put a cose message in a bp sec block and the other part of it is what is the profile with which the cosa is supposed to be used so this interoperability profile covers some symmetric key behavior"
  },
  {
    "startTime": "01:16:01",
    "text": "key wrap behavior and the main new addition for bpsec would be the pki behavior and the asymmetric key behavior so this table indicates these would be the minimum interoperability requirements and some of these things are required the symmetric key behavior and some of these are recommended to asymmetric behavior now this is for an interoperability profile this doesn't constrain or require any particular network to use any of these algorithms operationally this is just saying for an interoperability um this is what should be supported and uh none of these algorithms would be surprising uh to anybody who's using modern pki that these are the current um i would say state of the art of of uh current pki and pki over x 509 especially and that is also one thing that the second point on this last slide is that um the main benefit here to a network operator is that this uh structure this cose messaging behavior is going to work i would say off the shelf in an existing environment where entities already have a pki x 509 environment i already have a certification authority already have infrastructure for distributing certificates and keys this is purely on the wire how to get that information embedded into a bbsec block uh so this document hasn't been touched in a while um so the there's a at least one known change that's needed just to bring this security context into alignment with the rfc 9173 it's not a change in the information content it's only a change in"
  },
  {
    "startTime": "01:18:01",
    "text": "encoding and it's not even on the wire encoding it's additional authenticated data encoding there are some secondary questions that this is currently not a working group document but if it were to become a working group document then we would need to deal with more details like processing requirements beyond bp sec related to the fact that when you're dealing with pki environments there's no distinction between identifiers and identity that is authenticated so just little details that uh need to be worked out for interoperability and then the the second item is is really about uh are there additional minimum cose header contents so for example s mime as it stands right now does have a minimum that is more heavyweight than what's in this draft document but maybe that's not really necessary and this would be something that would be worth taking uh advantage of learning from the s mime um upkeep working group uh what is valuable and what's not valuable especially in a large environment like what s mime has to support so that's my last slide on this topic and um it's not stated on the sl oh go ahead yeah all right just to jump in on the queue uh with my chair hat off but but just speaking uh from a bp sac perspective uh i'm a i'm a fan of this work uh i think that the you know part of the idea behind a security context was bpv7 networks are going to be deployed in a variety of different ways and the security context is the mapping of the block level"
  },
  {
    "startTime": "01:20:01",
    "text": "fidelity that bpsac requires to the underlying environments and networks where we will be running uh bundles and so if if we in this working group were to produce um a context that tells us how to perform this block level fidelity in a pkix environment that that makes a lot of sense to me so with chairhead off a big fan of this work and and it would be nice to see it adopted oh and and it's not on the slide but uh i will bring up that there are uh discussions in nasa and i believe in in ccsds about the need for a kind of a interagency pki type type of thing just in the general concept and so i will propose that this uh is adopted by the working group uh and whatever needs to be done to uh to further that along brian i've made a note of that as well i'm watching the clock because we are yeah we never seem to have enough time we might book two sessions this is this is just one of those things so um all right do you want to move on yep uh the next topic is going to be quite short and what it represents is the idea that there are currently applications that are doing processing on bpv6 and b7 at the same time in the sense that the same entity is is processing both types of bundles and the convergence layers are currently shared in these entities between these different purposes and and there's not a well-defined way of receiving a chunk of data and saying this is a ppv6 bundle this is a bpv7 bundle um"
  },
  {
    "startTime": "01:22:00",
    "text": "explicitly and so in in v6 and prior the version has a specific offset v7 because it's using a sebor structure and because it's a nested structure it's not a nested offset and the root of bringing this up is that there are existing tools that assume that a bpv7 bundle is encoded exactly as some of the example bundles and so that if the example has the version at offset 3 and size 1 that that is how bundles operate that that these tools will break when they are given bundles that are still conformant to bpv7 but don't follow the same assumptions and there's also separate from an agent that is processing this kind of data there it can be a need to identify a byte string as a bundle version and not actually have to process the full bundle because the a trivial way of saying how do you differentiate is throw this chunk of data at a v7 decoder and give me a result or an error throw this at a v6 decoder and the point of this document is to be a little more fine-grained than that there's an existing document that defines a kind of a trivial mechanism to do this but again this is not looking at it from maybe an operational perspective of of how a system should really do this so there's two different aspects to this proposed mechanism and one of them is uh in the logical sense how do you distinguish between these things so the good news is that uh the two encodings actually don't have any collision between how they operate so there's an unambiguous way of of doing this uh detection and in the logical sense um the general purpose algorithm of just saying treat it as a stream of sibor content and do a certain decoding sequence will do the job so that's one way of doing it that"
  },
  {
    "startTime": "01:24:00",
    "text": "will work in any case that's the the general purpose given a a arbitrary chunk of data that will work that method will work but part of what would be what could be beneficial to have documented are some optimized uh more optimized algorithms that do more of like pattern matching type behavior and if you're in a network where you know that uh bundles are going to be produced in certain ways that they're always going to use deterministic encoding that they're always going to um to have certain properties to them then we can do things in a more optimized way so this these optimized behaviors are not strictly necessary but it seems like there can be some value in at least having them documented in an informational way so that uh there's no need to reinvent the wheel in some of these cases i'm not gonna go through the dock the optimize methods but what they amount to is doing some non-sebor seaboard decoding so you wouldn't need to use a full-fledged seaboard decoder you just need to do some bit operations that effectively do seaboard decoding and then the optimize two method is is a byte string pattern matching and if you're in a if you're in a constrained environment and a fixed encoding environment you can use pattern matching like that but what this document would it would say is that you only can do this in a controlled environment so feel free to do it but just know that if you're given valid bundles it might break your implementation uh so this is not yet part of a real draft document um this is just saying is there interest in this kind of thing and the main benefit here is is interoperability the the point is just to make sure that people don't create tools that are going into processing a received chunk of data that are going to fail in"
  },
  {
    "startTime": "01:26:02",
    "text": "maybe predictable ways that we can try and avoid and these steps are not parallel steps these are sequential next steps of if there's interest creating a document um thanks brian uh i think really interesting this is me with my uh speaking personally um i think a a short concise informational rfc has value just to to maintain interoperability that isn't that half the purpose of the itf so there is v6 still flying um literally um it's worth making sure this decoder the decoder logic is consistent and that we can point implementers at best practice i think there's some value in that um i'm watching the clock i'm really sorry is anyone else in the queue with comment on any of these documents go ahead joshua uh hey so yeah this is joshua deaton over here at uh marshall space flight center uh in regards to the interoperability for v6 and v7 stuff um for our implementation of dtnme for use with the iss we did kind of follow the same general idea since we were starting with v6 to begin with uh we did follow the path of uh verify uh whether v6 the actual uh encoding for saying we're using v6 is correct and if it's not then check if it's a v7 bundle and if both fail it's obviously malformed uh but yeah this is definitely something that uh at least we think there's some value in okay great joshua uh in which case brian because you're now over time i'm going to hand swiftly on to emery about we are genuinely going to have to have two sessions next time we never seem to have enough time"
  },
  {
    "startTime": "01:28:02",
    "text": "let me share emery's slides and hand over sure so emery you should see a little sort of semi-transparent overlay to allow you to go left and right uh how long have we given you if i give you a 10 minute countdown instead of your 15 uh we can then overrun by three minutes as we do with everyone else that's okay that will make it work can you all hear me i can hear you okay cool um thank you yes i see the slides i've got the button uh ready to roll um and i will make it uh make it short um so first off just to kind of talk about this is a refresh of the asynchronous management architecture uh this falls firmly under the new charter for you know an oam architecture and solutions to meet network management uh so just want to talk about the latest updates to the doc and ask really what are the next steps to move this forward since this is the informational sort of motivation for uh why we need the network financial architecture and uh what are the approaches to that so with that said the first thing we've renamed it uh to dtn management architecture uh and this is just to sort of be more in alignment with what are we trying to solve here right so the new document is posted here uh it maintains basically all the same motivation design principles and concept of the previous document just a little bit of clarity here and there the main focus and and the reason for the renaming is this is a document that is designed to address challenged networks i.e the delay tolerant networks so just to touch on some of the things that kind of have been clarified or updated in this document the document specifies very clearly what are the services needed by a dtn management architecture and one of the desirable properties of a"
  },
  {
    "startTime": "01:30:02",
    "text": "solution that meets these different services so i called out a few here most of these were the same but i called out a few here so authorized administration accounting and error control asynchronous dynamic hydrological architecture model derived and hierarchically organized uh definition of information i call these out because they are new sections but they just are there to try and further emphasize uh you know the scope uh and then in the need of this uh management solution so to touch on a few of those uh this is sort of triple a i mean one of the design criteria you see this across almost every network management solution is the need to authorize those controls that reporting that are coming into the network management solution because this has to be built on top of dtn uh it can't necessarily be built uh within the protocol as a very sort of synchronous uh you know handshake to set up these commands but there is a need to do that so a section and there was verbiage all throughout the document kind of talking about this already but i think it deserved a section that really described that need up front so this new section that states that in asynchronous dynamic highly logical architecture so this really speaks to the need to operate within dtn thinking kind of in the back of the vine how does a bundle protocol work uh how does bp sec work so we're trying to say here that the concept of this topology uh is very dynamic uh the the roles assumed within the network uh can evolve over time in fact as a message moves from a you know sender to a destination a new destination may assume that logical role right so so we still need to deliver that too in the case of a network management a manager but that manager might have changed in addition there might be multiple"
  },
  {
    "startTime": "01:32:00",
    "text": "managers either coordinating or working with a receiving ports to a single agent so we're trying to call that out up front and say that there's a need for this sort of logical architecture um the last change here was say it was just saying up front that what we want is sort of a model driven architecture uh you know that we talk a lot about autonomy in this model which autonomy has often performed in other uh in other working groups or in other solutions as a very much sort of back and forth interaction between those managed elements uh and and the managers um to achieve autonomy in a dtn management solution we very much need a model driven approach and furthermore it needs to support uh you know compression and there's very various different ways you can approach compression so a hierarchy i can't speak organized model driven approach should give means to some of that um and i think a lot of these things that i'm talking about feed right into the approach of amp and the data models that support network management as they've been being implemented worked and discussed this working group for some time um i think as far as the high vision architecture just calls us out up front so a few other minor updates uh this one here simply just walks through the roles and responsibilities of an agent and a manager the agent being the thing that you're going to manage whether it be uh you know the applications behind the space vehicle the protocols that are managing the network on the space vehicle um as well as the manager the the node that is ultimately sending messages to uh those agents and receiving reports from those so just a little bit of clarity kind of walking behind exactly what is the role and the responsibility of each one of these uh of these roles"
  },
  {
    "startTime": "01:34:01",
    "text": "and then lastly uh we have to do some pictures in the back i think to stress a little bit that this is indeed a solution for a challenged uh challenged network management solution so first picture kind of said hey look agent b here might lose connectivity for some time even though it's generating reports to send back to the manager it still is going to generate those reports and it will deliver them asynchronously at a future point in time so it just calls that out in this picture here the next picture uh there is a statement that uh the the agent should try and compress and combine messages where possible so this effectively describes that where agent b has been asked to produce two different reports so from that time on it combines those two reports and passes them as a single message and some of this is actually handled maybe by the bundle protocol agent not necessarily the network management solution these get the working concert to one another and the last update to picture here is showing this multiplex management between fusion between potentially two managers that are both controlling the same or multiple agents uh how are they communicating to one another how are they fusing data and passing it and this goes back to like i said the clarity of the roles of those logical agent and manager so this picture tries to speak to specifically okay using that definition of the the responsibilities of each it tries to address that so my questions to the working group first and foremost uh what is needed to finish this architecture uh what is missing what's wrong um we would like to move this forward so that's the the open question right and then what are are there any accompanying documents that need to go with this one so i'll pause for a brief minute before i give my second section and ask i see ed's hand up"
  },
  {
    "startTime": "01:36:04",
    "text": "so ed with my chair hat off uh is is to make an observation uh which is uh at the beginning of this we mentioned that this document had been renamed from the asynchronous management architecture to the delay tolerant network management architecture and one of the observations there was the term asynchronous uh caused some confusion uh asynchronous as it as it be as we use it in in very challenged networks like a dtn architecture mean that the transport layer is asynchronous that you may have unidirectional links you may have long periods of time without being able to communicate end to end however uh another use of asynchronous means not holding session state and perhaps just using rest restful interfaces over tcp so one of the one of the things that has to be done in this management architecture is to really differentiate the fact that asynchronous is asynchronous all the way down to the transport layer requiring that level of autonomy um when we get to that point and how we use those those autonomy models uh the work is is unique so as long as we maintain that focus of uh asynchronicity all the way down to the transport layer uh that that needs to be there so with that i'll that was just a comment not a question awesome i saw josh's hand go up hey uh so this could be something that i may have just missed because it's been a little while since i've done a true deep dive of some of these documents but uh does this the current state of the standard cover a situation for um handling reports that have not been able to be sent for extended periods of time per se so like obviously the nominal situation is that even if there's been a delay and you weren't able to send it right away that it'll still try and send the next opportunity that it has but does the standard provide a mechanism to"
  },
  {
    "startTime": "01:38:01",
    "text": "say if x happens or something else happens or something else happens do something different with the report so that you don't all of a sudden send a thousand reports down at once so i others might have comments on this but i think the standard doesn't have an answer for that or the proposed document doesn't have an answer for that however um i think that can be accomplished a little bit separately so that the concept of the logical data model that describes uh you know the rules associated with the generation uh or or frequency of reporting um i think personal preference here that maybe we should have a capability to apply policy to those so in the case like you just described maybe there's a system level policy which would be supported by an additional data model that says okay uh the lifetime of this delete after a certain time or when storage gets above this threshold deep delete things that are there older after this time um i think this the ama in particular the dtnma i apologize i've been speaking it too long um is uh sets us up for like i said the motivation for that challenge network management uh need for that logical data model leave need for autonomous driven but deterministic behavior which we can then add what you just described i'm gonna jump in at this point it's rick with my chair hat on uh first off because i'm watching the clock um so i think to answer the question on the screen i think having this is an arc and also to answer that previous question this is an architectural document and so i think it should be able to proceed uh without any accompanying documents the accompanying documents can come after that's commonly how how one does architectural documents in the ietf so i politely request working group participants to go away and re-read this document it has changed"
  },
  {
    "startTime": "01:40:00",
    "text": "noticeably and from my reading is a huge improvement so thank you emery and the rest of the team who've worked on this um please reread please review and let's see whether we can really make some progress on this as an architectural document from which we can start to hang off the accompanying documents and address questions like like joshua's and get into the depths of data models and protocols and policies and all this kind of stuff um does that sound reasonable yeah good so i'm conscious that sarah got bumped out from iutf112 and i really wanted to have an opportunity to present what she tried to present last time so if there's nobody else thank you very much emery and we'll jump straight across to sarah um yep roger did you want me to go through just real quick and let me do this real quick there is some there is some additional information to the slides there is a new document uh it's right now a sort of personal document uh saying we need to have a method to name uh resources in the uh application models they're being defined um so my question i'll kind of jump forward to this and i think this needs to work my question here is is this the sort of thing that the working group is interested in uh and then you know what are the next steps to kind of move that forward so we can take that offline so we can just chair again as chair i think this is within scope of the uh the working group charter i think you should push this out as a personal draft i think uh you should draw attention to it and garner interest on the mailing list and what we're going to have to have two sessions at the next ietf because we have so much content we'll have a proper dive into it and if you get sufficient review we go for working group adoption et cetera et cetera but uh let's separate the track of that kind of thing from the progress on the architecture ed are you agreeing or disagreeing i i am agreeing this they should eventually come into the fold uh but let's go on to sarah yeah perfect"
  },
  {
    "startTime": "01:42:00",
    "text": "thanks very much emery uh i will stop revoke your permission this slide thing is almost very clever uh dude there we go so sarah you should have control yes okay cool okay so um if if you all remember last time i presented about the asynchronous network management system this is a network management system we are creating to be able to operate the the dtm protocols beside terrestrial networks so next i have a quick overview again these you probably saw these slides last time so the the goals of ams are to enable missions to be able to use the disruption tolerant networks um help people use amp and be able to adopt amp and also serve as the baseline for the amp specification um so we will be tracking all the changes to the sec and we'll be incorporating that into our network management system so here quickly is what our layer one decomposition looks like so at a very high level that blue pill shape in the center is a mms we want to enable connections to other machines on the terrestrial network as well as connections to agents in the the space networks and then allow mission operators to have some default visualizations into the system as well as be able to do some command and control from uh or through a ms um the the ams services include you know normal services that you'd see in a network management system such as you know data management and service and storage uh health and status monitoring et cetera but then also agent command and control uh through amp and we are also aiming for a ms to be"
  },
  {
    "startTime": "01:44:02",
    "text": "um incredibly containerized and modular so uh orchestration of the internal amms systems and then also ability to plug in your own systems whenever uh whenever it's useful so for example if you have your own visualization tool that you'd like to bring into anms we want to have the standard interfaces and the modular system to allow you to bring that in instead of using our default visualizations so that hopefully was a review of what i went over last time and now uh the news is we do actually have our first spiral of amms complete and are ready to release it uh open source i would say within a month or so it's just going through the review process at this point um i do have it running in the background but in the interest of time i'll just flip through these pictures we have of it so this is our welcome screen along the top we have a few different tabs that we want to build out in the future in our current version of amms we have built out this monitor tab the agents tab and the messaging tab and i'll go through those in a second the network tab would show the second one there would show like a network topology um alerts would be alerts from agents and system management on the end would be um in the future things like health monitoring of ams itself but going through the ones that we've built out so the monitor tab this is showing uh grafana plugins for various uh variables within our system so on the top left you can see this is actually uh pulling variables from the bp agent full report and displaying them in this in this field the one we've picked for this one specifically is num and cust which is the number of bundles in custody for the agent so here you can see we've been getting reports from agent from an agent on our network and are able to display that variable"
  },
  {
    "startTime": "01:46:01",
    "text": "for for users of the system below that actually in the middle you can see all the reports that have come in in kind of their raw form and then on the top right is the message group per minute which is really just a message rate so how many uh you know reports have we gotten in in the past minute um right now i think in this graphic there's only there's only one agent on the network but we have run this with two and you know you can see the difference between the two and you know compare statistics between agents so the key here is that it's really nice that we can we can now display all the different variables from all of the reports that you can get from you know bp v7 and uh amp and all the different uh idioms so next slide is oh zooming in on what i just mentioned so right uh number of bundles in custody on the on the left side and the uh message rate on the on the right hand side but here we have uh the agents tab so this one is showing the agents on our network and this is where we can actually control agents so we can send them commands and we can uh you know receive reports from them as well so at the bottom you manage agents on your network if you expand that this is what it looks like and this this may be a little bit small um but the rather uh cool new feature that we added recently was that uh you can now automatically construct uh time-based rules here to send to agents so if you select um you know start time period count and then you can pick a report to ask the agent to push back to to your management server on the period specified then you can you can start populating data and displaying that in the grafana pages that i showed previously um so right now this is supported for the reports that you see on the screen there the ltp"
  },
  {
    "startTime": "01:48:00",
    "text": "agent enterpoint report the bpage endpoint report bp agent full report and amp agent full report but the the really nice thing is this allows you to send these commands without having to get to construct them yourself you don't have to construct cbore you don't have to construct res it just automatically does it for you so just an example of some user-friendly options coming in the future um the less user-friendly way of doing this uh you can see below that actually you can send raw commands so that other text box at the bottom there is you can just send the seaboard command to the agent and it'll execute that so if you just wanted a single report you could construct that command and uh and send it and receive the report back on the so i believe this is my last slide so this is the messaging tab um the messaging tab right now uh will help you construct those commands if you if you want to send send one of your own so here if you input a string re then it'll parse that out it'll show you what the c bar is for that string it'll parse it out into json on the there's a tab there that will also construct a uml diagram of what it looks like and it can do the same for seabor as well so if you put in a seabor command it'll parse it out and show you all the same data so really quickly that is what a ms looks like right now in a nutshell um we are really excited to get this out into the community and to start getting feedback um and so hopefully it'll be there soon and we'll hear from all of you have any questions thank you very much sarah uh that's really cool it's really nice to see this stuff starting to run it's really nice to see this as as slightly more than a draft we don't normally do show and tells at the itf but this was very very worthwhile it's just to demonstrate this is um this is getting beyond the concept"
  },
  {
    "startTime": "01:50:01",
    "text": "phase which is is great so thank you anyone else got any questions on this at the moment i know people were asking on the chat about oh can we play with it what's it like and and ed's chimed in to answer some of that um i'm assuming you can hear me because i keep getting a pop-up saying your audio isn't working cool in which case i am going to because i'm watching the clock i'm going to grab the slides and i'm going to jump straight on to my presentation thank you again sarah um i have a very quick he says in advance um i'm going to turn my camera on so you can see me so i've got a very shortish presentation uh asking three questions about endpoint ids so um in classic form i'm still trying to chase down um more detail and drill into uh naming uh and addressing but i'm tackling naming first so uh a quick review and i've stolen this slide from the a similar presentation i did at ietf112 so this is an analysis of what rfc 9171 tells us about endpoint ids so the critical thing is they are a pair so that is the schema and then some content which is defined by that schema and 9171 defines two schemas the ipn schema and the dtn schema um an important other consideration and i'm not going to go into it in too much depth at the moment because of time is there is a multiplicity associated with an end point so you can have the the null endpoint which is is nowhere uh you can have unicast endpoints and you can have multicast endpoints but i'm not actually going to drill into that too far in in this talk but it's something to consider as we discuss the various types of schema so i'm going to ask three questions in fact i uh i may even have some answers to some of these questions"
  },
  {
    "startTime": "01:52:00",
    "text": "question one if the dtn schema is for universal use and the reason i say it's for universal use and i'll jump back one slide because i missed this detail is that the dtn schema no it's not on that slide i'll come on to that the dtn schema in rfc 9171 is registered in the iana user agent schemas registry so that implies that it's for use in things like browsers mail agents on your mobile phone generic user agent protocol handlers that's implied by its registration if i see you in the queue scott if the dtn schema is for universal use how do i write a protocol handler for a tool such as curl uh go on scott i'll bite jump in i mean to interrupt you please go ahead i was only uh i'll respond to the slide before that said that there's no queuing of multiplicity in these things and actually there is the ipm schema is specifically uh always singleton endpoints yes yeah i i think i draw draw that out but it's it's it's kind of hit that was a kind of a passing point and i don't actually want to drill into multiplicity too much it was mostly that slide was stolen from a previous presentation and had some points about multiplicity but that's most relevant at the end but point taken so my second question is given the ipn schema is restricted and as scott pointed out you know they're unicast only what should the working group recommend for its usage because it certainly has value it's very condensed uh it's very concise et cetera so i'm going to try and address that oh i'm going to talk around that question and the third question which both ed and i and various other people get asked is are these two schemas the only two schemers out there and uh groups like ccsds uh sana ipm sig are asking questions such as"
  },
  {
    "startTime": "01:54:02",
    "text": "well how do we use these dtn ids who owns the global registry for these things can we set up our own global registry what should we do about problem x problem y or perceived problem z and so i also address that because endpoint ids are this combination of schema and content and we have only currently defined two schemas i shall answer that as part of question three so question number one external use of the dtn schema so as i said before the schema is registered in the uri schemes registry which implies they are available for universal user agents so my question really is how do i run this curl command using curl as an example is great tool but i want to upload that file to that dtn eid so really by doing a bit of analysis into that looking at the rules in rfc 9171 a dtn schema specifies a name a slash and then a demux part which is some other component so i suggest that oh sorry that's the next slide so you resolve into the name in the demarks according to the rules in 91 71 and you then transmit that uploaded file content using something that you have some information you have derived from that name resolution 9171 quite correctly doesn't say anything more about that because it's the wrong document to do so so i propose the following and this is contentious and i'm very happy for people to step to the mic and shout but i might ask you to hold for a second when a dtn url is accessed externally for example using something like the curl tool if someone was to write an extension to curl then the uri is parsed according to the rules in 9171 into its name in its dmax and this is the contentious bit the name component is then resolved using global using dns not necessarily global could be local so it's resolved using dns into"
  },
  {
    "startTime": "01:56:01",
    "text": "an ip address v4 or v6 doesn't make much difference to me and then a tcpl cl a tcp clv4 session is established to that resolved address in order to transmit the bundle example that curl command takes performs the following operations it's saying send that bundle protocol version 7 bundle with the content of file1 as payload to that destination which is schema type 1 dtn.org some service in some services the dmx part using a tcp lcr the tcpclv4 session i'm going to make that acronym shorter to the agent at that resolved address please don't ping that address i'm not entirely sure where it is um obviously you'll need some other options to set some of the primary block headers but fundamentally that is enough to start using bundle protocol on the public internet infrastructure in order to send messages a couple of clarifications this proposal does not prevent either of the following if you if your bundle processing agent is not something internet focused such as curl but is some system built into a traditional dtn environment so a deep space probe or something in a ground station or something traditional like that doesn't make any difference you can resolve that however you wish you can use intermediate proxies and gateways between the user agent and that tcpcl or and that endpoint id that one might use tcpcl to get to so there's nothing to stop you doing that at the ingress stage and there's equally nothing to say that demux part of the endpoint id after the dns resolved part of the name that could actually be an ipn address or it could be some other deeper into the dtn network beyond the"
  },
  {
    "startTime": "01:58:02",
    "text": "dns resolved part so that dns resolve part is simply saying here is something that is resolvable to an ip address that can be contacted using tcpclv4 that will take that bundle and get it to wherever it finally needs to get to okay i'm just going to quickly pause at that point to see if anyone has any major arguments go for it arguments but rick just because we have two minutes left oh shut up well what i would suggest is that this is of course something we need to address uh can we start some posts on the mailing list and perhaps uh entertain an interim meeting to jump into some of these topics in more detail yes absolutely i'm quite happy to take that to the list uh what i'll do is i'll skip very quickly over the second slide and leave it on the third joshua thanks let's finish up because we're pretty close yeah okay ipn scheme i am proposing that it is used internally for uh autonomous regions that's got introduced so it's effectively a like a landscaped address and this is an important slide for the ipn sig guys i have pointed them at this before if you wanted to find your only id this is how you do it document it request a new bundle protocol uri type scheme number you're there you're compliant so that's it i'll stop uh ed you have about 20 seconds i'm really sorry that's fine why don't you project the slide i'll ask a question and then we'll take it to the mailing list which i think is appropriate and the the question uh really the fundamental question that i have is uh in going back and looking at rfc 4838 which was published in april of 2007 uh based on and seeing some of the work in dtn rg we laid out what the dtn architecture is i well i didn't but the d10 architecture was laid out in in this way my question uh to the working group is do we feel that our implementation"
  },
  {
    "startTime": "02:00:00",
    "text": "experience with bpv6 changes to bpv7 and some of the work that's happening now uh with uh network management with security with quality of service with custody transfer and so on is it time to refresh this document and that is a question out to the working group for anyone that wants to simply make a statement here about it or take opinions as to whether we need to refresh 4838 to the mailing list that's really all i have on this slide and with that we are at the two hour mark i just like to say this is wonderful to have the first dtm working group meeting after having our first four rfcs uh published there's a tremendous amount of work as you can see we really did run out of time quite quickly and we should start we should start planning an interim meeting uh now and then also perhaps have additional time at the next uh ietf 114 which perhaps will be all in person but i also add thank you very much uh all the contributors uh thank you very much for attendees um i'm going to keep talking and communicating on chat until meet echo shut us down because we're so compressed uh ed and i were talking offline i think we're going to ask for two sessions next time because we always seem to run out of time although we are on paper quite a small group there's a huge list of there's a huge set of attendees on here a lot of remote participants and i think we have more work we can do uh at the the next atf as well as in between so thank you very much for your attendance and your good questions so uh yeah i i'm i'm still typing rapidly in the chat but i'm going to close my mic uh thank you very much uh i think the meeting is over"
  },
  {
    "startTime": "02:02:01",
    "text": "indeed it's good to see everyone i will be grabbing the uh chat window uh at the very last second and throughout there is code emd hedge dark as well good plan and thank you very much adam i had a a chance to glance at the at the minute since they were going past great stuff as usual those will be published as meeting minutes uh as ever and uh as usual the itf will uh turn this into a a youtube video much to my embarrassment um at some later dates so you can listen to the recording as well probably focusing on the on the great presentation by vint um so yeah brilliant thank you all very much particularly those in the room oh and thank you very much to ronald thanks ronald for for sitting at the front in case of emergencies really appreciated no worries you"
  }
]
