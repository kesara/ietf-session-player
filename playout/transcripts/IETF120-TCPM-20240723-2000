[
  {
    "startTime": "00:01:35",
    "text": "Yeah, and that's actually a bunch of respect Thank you sorry"
  },
  {
    "startTime": "00:02:14",
    "text": "Talk about ECM in that question One punch. ECM reporting socket options So, Lenox You might have been strange right All right. Six socket works on the four addresses reported in the V6 syntax of a matter. Where are you in? So on DSDs, when you say you want to receive the key class And you get the proper TOS fight as a VE as a D will not, it will record it, I missed, it will report it, it will report it. It will report it. Inval. Which you don't. Which generally which is why macOS was seen in Norris was seeing a bunch of teaspoons I mean, you shouldn't fail the communication because that's all about it should Anyway, we have as going to be. We haven't, that's fine Yeah, yeah. And then a few I think unreachable, we still killed Good I came for? But I'm glad I killed it, because we never I just got like I mean, what could possibly go wrong? No one fixes the bug"
  },
  {
    "startTime": "00:04:16",
    "text": "Thank you very much to issue an IP protocol level socket option on an IPV6 socket Oh, that's the right No, we find life No, it's wrong We just do the right thing when you should be six options Okay, I think we should Hello this is TCPM, so if you're not interested in TCP, you might be in the right room My name is Michael Toog t√ºxen. Ian Sweep And Yossi We are the co-chairs and co-chairs and this is the note well which you should have seen already already And basically we have a JavaScript, but we need a note take tape So anyone willing to take it? we need a note take. So anyone willing to take notes? Thank you, yeah. You will use the note taker tool? Perfect So, if you want to submit documents which are addressed to this working group please include TCPM in the name"
  },
  {
    "startTime": "00:06:02",
    "text": "then it shows up on our radar and as you know this session will be recorded That's our agenda for today We have I think, more time than needed. We asked for 19 minutes We got 120, so we have no time problem We'll talk about the working group status first, then we have three working group items PRR Neil will report about the latest changes Accurate ECN Richard and Bob are not here and Mia is just joining the room, but I'm channeling the slides which will document the differences in the last two revisions And we have a presentation about the egg rate request. At the end, we have a presentation about an individual document, which is related to the presentation we saw at the last IETF regarding Ghost X X and these are the documents we are working on. The green one is the one which is in the RFC editor queue and it's now actually not there because of a misref, but now it's actually the RFC editor is working on it For the blue ones, we have present in this meeting The two black ones, general ECN. We don't have a presentation This is tied to the accurate ECN ones we have shipped the document"
  },
  {
    "startTime": "00:08:02",
    "text": "ECN document to the IESG to the AD. We'll stop the last call on the generalized ECN We don't have a presentation on TCP EDO but we have a presentation about the egg rate request. And I left in the document the dates from the milestones And at the last meeting, between the chairs and the response AD the question was brought up by the AD what we want to do with the milestones so do we want to keep dates there and up update them or don't we need the data? dates? As the working group, I mean, what I observed in the past is that we normally run late on the milestones and pretty often we up I observed in the past is that we normally run late on the milestones. And pretty often we just update the milestones to a later date when we have a better better thinking of when the dog document will be finished But there's the possibility to not use data there. As the working group, any opinion on? keeping dates, not using dates? Fair Houston can't work out the tools to get in the Cuba get in the queue, but yeah, do something that works. I mean, I do like the dates but I think the dates have to be realistic, not retrospect That's totally stupid And you have to work carefully with your editors to give a"
  },
  {
    "startTime": "00:10:00",
    "text": "real date, and when they don't make it, you have to kind of revise it. That's okay but this is rather silly as it currently stands does that help no okay so i say i like them i say please please do realistic realistic dates and tell us when you think things will be. I mean, we try to do realistic dates We haven't intentionally not updated them because Yeah, Barry, why do you like this? I like this because it tells me what I should be reading on my reading list and whether this is actually making progress So that's why I like it. Just follow the mail list and wait for you to ask I wanted to say that opposite. I think like this has no benefit for this group I don't think it would change anything in this group, how we work So I think we can get rid of it an opinion Oh Yes, but as an individual I agree with Miriam that it probably won't change anything whatsoever It's also a little bit annoying to have dates that are obviously like fantastical and it seems like this is not a problem specific to our working group So like I think this goes back to my general principle of like I think trying to keep dates up to date in the IT has generally been like an enormous failure and so like either like we should try to figure out a way to keep them up to date like literally at the beginning of every meeting like force us to update them in the first like three minutes of the meeting or just give up on them entirely i'm kind of inclined to give them up on them entirely, but yeah Just use the mic. Yeah, thank you. Mia Kluo in here"
  },
  {
    "startTime": "00:12:02",
    "text": "Now I'm in the cube. So if the goal is realistic milestone and you look at the history, of this specific group, you have to update them all to show like whatever 35 20 the goal is realistic milestones and you look at the history of this specific group, we have to update them all to show like whatever, 35, 2035 or something, then we're good, right? I don't know I'm joking like you have to it's not enough to just say, oh, we didn't reach the milestone we should bump it by three months it's like you don't know, I'm joking, like you have to, it's not enough to just say, oh, we didn't reach the milestone, we should bump it by three months. It's like if you wanted to realistic milestones, then actually figure out like, what's realistic So we tried to use realistic milestones we failed, and I think it's good we failed I mean, I think it's good that we took the time to continue working on the document. What I have a bad feeling is by inserting milestones is that people maybe not knowing how this working group works expect the document to be finished by that amount of time and then they get disappointed and so I'm I personally think we failed in the past so often to give a precise deadline that we shouldn't do this However, I'm partly with Gorey trying to get some information about what's next or what is kind of a sequence information And I think we can keep the milestones in a sequence where we think this is the sequence we are working on the documents or this is the sequence we will deliver them to the IESG and I find that a important information. So that might be a question think this is the sequence we are working on the documents or this is the sequence we will deliver them to the IESG. And I find that important information. So that might be a compromise between provider the information we are pretty certain that we can fulfill the expectations and not giving any expectations we are not sure"
  },
  {
    "startTime": "00:14:01",
    "text": "Matt, Matt that the milestones showed a different field which is when, what was the date that the document was most recently updated? So I can scan it and say, say who's making progress, who looks like they're making progress You need a check. I mean, you want to stop but I can't look it back Gerard I'm wondering if we just want to just put a sequence number in the docs saying this is the order in which we expect them to be finalized rather than date I mean, that could be the sequence of how we are listing them gorry fairhurst, I don't. I could work with dates, I can work with an order, but knowing which one's coming up first for you guys is important, and it's important when I point other people to groups in the IETF to say this is what they're going to do next. Other people are outside the IETF don't have a clue about the dates, but they do have a kind of wanting to know which ones of these are nearly finished Matt, are you still with the cute phone? I joined the queue newly Mirja Kulevin here. I don't understand actually why we have it order, because these are all independent documents and they might take a different time to get finished and when it's finished, we should chip it. That's it that's true um but for example generalized ECN was serialized behind that, and from my view, PRR is more more advanced than TCPEDO is So we have some partial"
  },
  {
    "startTime": "00:16:01",
    "text": "ordering Anyone else? Yoshi? I'm not I don't have a specific opinion about Myelstone, but I want to mention about EDO draft. Is it okay? If I talk about EDO draft a little bit right now Sure Okay So I think we have discussed this draft intentionally in the past. Right now, it's a little bit quiet for a while I think back then one weak point of this draft was there was no implementation. And but recently the Knew Knew KU from AWS implement EDO ops option, and then he presents a very nice implementation report, and then some updates, some proposal to updates draft and then Joe seems to be agree on it. So I'm thinking that this might be a good chance to finalize EDO document and so I just would like to get feedback if people, you know, think it's a good time to finish it or people think it's not we don't have to work on this one anymore If you have any opinions, I would like to hear Thank you there is no opinion, I just send a message to the mailing list and check the opinion from the mailing list Okay"
  },
  {
    "startTime": "00:18:02",
    "text": "then we take that from the mailing list Any other? questions, agenda bashing? If not, then we are moving on to the first presentation, which will be needed on PRR Neil, will you run your slides or? Oh should I, let's see which button is it? Ask Slash is that the button? Try it Okay, let's see. Hello I see it twice twice twice I don't see where I pick this slides maybe you guys should show the slides I don't see the that the Ah, there we go, okay Great great. Yeah, okay Yeah, so thanks, thanks everybody So I'm going to give an update on the proportional rate reduction draft. This is joint work obviously, with Matt and Nandita and Yuchamp So just a refresher and some context for for so our RFC 6937 was the proportional rate reduction for TCP draft this was published back in 2013 as an experimental RFC. And at the time, it was only"
  },
  {
    "startTime": "00:20:02",
    "text": "implemented by Linux and it was implemented without RAC TLP because that didn't exist yet And PRR, you can basically think of it as kind of a mini congestion control that runs during fast recovery and the high level I idea is to send packets where your current sending rate is proportionate to the delivery rate. And the proportion is chosen by the congestion control algorithm where with Reno it's 0.5 and with cubic, it's 0.7. And the idea is that that proportion is set so that you smooth reduce the amount of data in flight with that ratio given by the target given by congestion control and the multiplicative decrease made by congestion control And if the amount of inflight data drops below the SS threat, then there are two different modes of behavior you could use it back in that spec One is a slow start style behavior, and one is a packet conservation behavior and in the original rFC the implementation needed to pick which option it used and I just sort of as an interesting fun fact for a flow that mostly operates in fast recovery, its congestion window, in in practice is mostly controlled by the PRR behavior instead of the core congestion control behavior And this happens quite often in police video stream flows using Kyivaker, Reno, for example. All right So the 699 BIS effort was motivated by the fact that we've accumulated 10 years, 11 years now, I guess, or even 12 years of experience since"
  },
  {
    "startTime": "00:22:02",
    "text": "RFC 6-6-937 And this effort started in 2021 And at this point, PRR is default enabled in most of the major TCP stacks, including Linux, FreeBSD, Microsoft TCP and so the TCPM group voted to revise and publish the PRR draft as a standard standards track RFC And in the slides there you can find the link to the current version of the draft So we've discussed in previous talks a number of revisions since 6-937 Some of them were algorithm refinements probably the biggest one was sort of automatically choosing between the two different modes of increase wen lin flight is below SS thresh based on a simple but effective heuristic The second one is to specify or clarify that when you're entering fast recovery, you want to make sure that you for a fast retransmit even if the normal computation wouldn't allow it There's also a little more information about how to support non-SAC connections And we also wanted to be more precise or about how we handle the case where there's a higher network reordering which could cause a connection to for many packets to be sacked before enters fast recovery. We also wanted to make some editorial clarifications which we don't need to go into And then also, we removed the experiments section that was in the original RFC RFC"
  },
  {
    "startTime": "00:24:02",
    "text": "So for this most recent update to the draft, this we push in the past week and most of these changes were in response to various detailed comments from from on the TCPM list. And thank you, Mark for the comments. I guess he's maybe not on the call now but maybe he'll watch the video. Thank you They were very thoughtful and very detailed, and they highlighted a number of issues that we think we've incorporated all of Marku's feedback into the track and we responded on the the mailing list about how we think we've incorporated that and then there's a link to the diff if you want to see exactly what changed but then I'm up about to give a sort of summary of the major changes So the first major change was to clarify that peer triggers its initialization based on the start of the congestion control slow down or reduction rather than the start of loss recovery And the main motivation here was that the congestion control algorithm within a given loss recovery episode, a congestion control might actually decide to make several reductions in its sending rate. That is several reductions of SS thresh. And for the behavior to make sense, each of those reductions in an episode would need to re-initialize the PRR state machine so that you get the correct behavior. So we just wanted to clarify that So the new text basically says, you know, at the beginning of a congestion control response episode, that's when we initialize the PRR state And the timing of that response is basically entirely up to the congestion control algorithm And, you know, we give an example where the congestion control might decide to make multiplicative decreases"
  },
  {
    "startTime": "00:26:02",
    "text": "for every round trip in which there is packet loss even if you're still recovering the same sequence room in fast recovery All right. The next change was about the initialization of the recover FS variable. So in this, rev, we no longer use pipe to initialize that. I believe Mark who pointed out that pipe can be incorrect if there's a spurious loss detection decision If there's reordering, that is initially interpreted as loss, then that can cause pipe to fall below the value it should have And then those packets that you marked as loss, might then later show up and actually be delayed which could then cause the arithmetic to work out badly and you would end up sending too much. So instead of using pipe, we use a different approach we have work out badly and you would end up sending too much. So instead of using pipe, we use a different approach. We also make sure in this revision to incorporate data that was selectively acknowledged before entering recovery because there can be for example, if you have an algorithm like RAC data that was selectively acknowledged before entering recovery because there can be for example if you have an algorithm like rack tlp which sort of adaptively estimates how much reordering there is in the path, then you might end up in a situation where you actually have quite a lot of data that's selected acknowledge before you enter recovery. And if you want the math to work out well, then you want to factor that in. And then in addition, the new math incorporates data that was cumulatively acknowledged upon entering fast recovery This is probably a rare corner case that would only happen if acts are lost or things like that But it's, we may as well cover it because actually in in fact, in implementations, it's kind of actually simpler and easier just to incorporate that"
  },
  {
    "startTime": "00:28:02",
    "text": "so the new text basically um you know it makes a more precise definition of recover FS in the text, which I won't read And then it refined the pseudocode to be like the pseudocode here, where you basically start by setting recover FS to the entire sequence range from Send Next to Send Anna But then we subtract out the bytes that were sacked before entering recovery because those will never be marked as delivered during recovery because we are out the bytes that were sacked before entering recovery because those will never be marked as delivered during recovery because we already marked them as delivered And then we also want to include this rare case rare but simple case where when we're entering recovery, there might actually be some amount of data that's being cumulatively act on that acknowledgement So that's the detail there The next change was in the specification of delivery data, which is the amount of cumulatively or selectively acknowledged data that has been noted on the process of this act that we're handling And there, Mark who pointed out that we had some bugs in the pseudocode And so what we opted to do, what we've proposed to do, basically is to go back to the prose definition that we had from the RFC, from RFC 6937 and we just removed the buggy pseudo code So here is the pros definition of delivered data. It's basically the same as 6937 except that we've added a note about misbehaving receivers where they could potentially decide to try tom strickx you by sending lots of DuPAC more DuPACs than is really appropriate in which case you want to watch out for that and not"
  },
  {
    "startTime": "00:30:02",
    "text": "use those dupecks if you know there are too many Yeah, so that's the deliberate data change And then the final major change was the clarification that or specification that PRR should set the congestion window to SS Thresh when it's finishing a PRR episode this was not in the RFC 6-937, but it's actually something that the Linux TCP implementation has done from the get-go in 2011 And so, and there are cases depending on the loss patterns and depending on how you set SS-thresh there are cases where this can be really critical for good performance So we thought, since it can be important for performance and there's more than a decade of experience we thought we'd go ahead and put that as part of the standard Marku was concerned about the potential for bursts, so we did want to mention that that is a possibility just like 6-6-7-5 can cause bursts, PRR can cause bursts in some cases So we recommended if that if you're concerned about that, then you should be using pacing. And so you can see the new texture around this. Basically we say at the end of a PRR episode you should set C-Wind to SS Thresh And we note that that can cause bursts and that if folks are concerned about that, which is totally reasonable and a good thing to be concerned about then you we recommend you use page I mean, we also mentioned that this is not the only thing in TCP by far by a long shot. They can cause bursts. There are mauch more common things like restarting from idle with an RTO that can cause big bursts. But in any case, like the other causes of bursts, this one can be mitigated with pacing And then the we fix it"
  },
  {
    "startTime": "00:32:02",
    "text": "some bugs in the examples that were due just to the fact that the SS Thresh calculation was incorporating the data sent in limited transmit and Mark who pointed out that the RFCs say that shouldn't be done. And so this, the examples were needed to have their SS-thresh reduced from 11 to 10, and then you just need to sort of work through the detail and make the small adjustments in the examples to make those work out. So there are the details there and then the final issue was that folks have pointed out on the list that there were some research paper that where people have noticed in some experiments where because Linux TCP currently and for a while has been using PRR to do sea wind reductions in RFC 3168 ECN, there can be poor interactions with at least some ECN ECN-AQMs, where you end up with because of the C1 reduction is very gradual depending on how the AQM responds to Q length changes, depending on the details there you can have an extra round trip of ECN signals from the AQM if there's a poor interaction So we wanted to incorporate the reference to that since folks had pointed that out on the list And I think that's, yeah, I think that's the final issue Yeah, so chairs, where would you like to take it from here? Are there any questions, I guess we should ask for it Yeah, thank you. I did have one clarifying question Neil, if you wouldn't mind going back a few slides. Yeah which one?"
  },
  {
    "startTime": "00:34:01",
    "text": "Is this one? Yes The pacing one So I agree with this record recommendation as an individual or probably as chair as well But do we have? text, normative text and other RFCs? besides obviously like RFC 9,002 that recommends pacing when we're starting from? idle, or is this kind of a, though it's well practiced, sort of a new recommend? that broadly applies to TCB? That's a good question. I don't know there are probably other people in the room who are more familiar with the other standards and whether they recommend pacing I feel like maybe one of gory drafts about how to have application limited behavior may have mentioned recommending pacing I can't remember. OK okay thanks again I have no concerns about this text whatsoever. I just wanted the working group to be aware that it's sort of adding a much more broader recommendation for pacing than I necessarily was aware of on the TCBR RFCs. Sorry I was good. Maybe the other I wrote say that would sound likely. I think the IW increase documents says, if you're bigger than that, do this which is kind of the precedent for doing this in TCPM, and I do agree. I think it's a good thing to write Yeah, thanks very alessandro ghedini Cloudflare We have implemented a version of this for our QuickStack but that was like a while ago We haven't done the work yet to update to the latest drafts. That's how I looked at the changes They look fine, but I wonder, do you know if any of the other implementations like Linux or FreeBSD? needed any, you know, fixes?"
  },
  {
    "startTime": "00:36:02",
    "text": "for updates to these? to the draft or the updates to the drop? actually came because of, you know, bug fixes in the other implementations So the, the, um, the updates to the draft actually came because of bug fixes in the other implementations. So the algorithm here has been implemented in Linux TCP for a number of years. I could go look it up, but I think it's been exactly like this for maybe two or three years at this point And I think it's been qualitatively like this for maybe eight years, but the details of the heuristic to choose between when to slow start and when not those details changed two or three years ago, but the qualitative behavior has been the same, I think, since about 2015 Okay, thank you Oh to present slides. Is that an error? Okay, I am going to refuse this slide request, but if you'd like to put yourself back in the queue, feel free Thank you other comments? Yeah, actually you are that document shepherd. Yeah So, yeah So I think we have, we have discussing this route for a long time. And then, uh, I think we have we have been discussing this for a long time and then Mark gave very nice feedback and then I think in the current draft, I think the draft that address the most of the comments that Marks raised. Yeah, I think it's the current shape of the draft is fine from my point of view"
  },
  {
    "startTime": "00:38:02",
    "text": "So I'm thinking that it's not ready to go to submit IETF IESG, sorry. And so I think even if the marks, is not satisfied with the courage versions, he can have a chance to comment during the last call. So I think it's okay. Sorry to interrupt I just want to clarify. I heard you right. Did you say it is now? ready to go or not ready to go? Oh, sorry i said it's now it's ready to go So not ready. Now it's now now too ready to go okay thank you so thank you sorry for my bad pronunciation It's not just me. The auto-transcription said not ready as well well well Last second, triggered by Alessandro right? So people are implementing this for quick, and this is obviously T.C right? So if people are implementing this for quick, and this is obviously TCVM, right? Do we need another doc? this for quick, and this is obviously TCVM, right? Do we need another document? Do we need to move the document? Is it implementable as? is for quick? I'm sort of now that we're in this new world versus other working groups right? That's supposed to do the generic generals style, congestion control stuff, we always have to sort of figure out where stuff should live live I mean, it's not just this even like implementing cubic the way that the RFC specified RFC is specified is in different to how matthew quick you know recovery and congestion control algorithm you need to do some work to sort of convert them I'm one of the authors on Kubig and we realize we do need to probably have a how do you do cubic for quick correctly That notwithstanding, this might be another one of these Yes, as an individual who implement this probably like six or seven years ago, not the exact current version but yeah what was standard then it It's a bit tricky to kind of"
  },
  {
    "startTime": "00:40:02",
    "text": "infer everything from, you know, the document and stuff, but it's, it's honestly not as bad as you might fear, because there's a number of things that in quick that I think make it a bit easier The question of process as to whether we want to add a section on Quick to this or a future version of this document or do something in the congestion goal working group, I'm inclined to infer to like an AD or some other some other individual but uh or well not not here but this is kind of my fault so I'll say something anyway. Yeah, I was going to say, I think you have appropriate opinion. So, I mean, obviously, this document was grandfather into the Sorry, great, yes, thank you Grandparented into the CC, into TCV it was already here, even though it could have been a CCWG one So I think there are like a bunch of options One is like no one cares enough to do anything about writing up for quick in which case nothing will happen if we just care about quick we could just do like a short possible document in Quick working group to to port this stuff over with presumably heavily referencing this one. A third option is to just add a quick section here and just run it by people And if we want to make this general to all transparency, protocols, which they're probably energy for, we could do it in CCWG that sort of sidecar document if we want to put it in SCP or whatever, but I guess I'm skeptical of that. I'll stay here I'll stay here, but. Lars. I got a gun again. So yeah, between your options, so that I was going to say something similar. If it's a, you know, page or text that says you know here's how you might be this in quick I think it kind of makes sense to do it in this working group and maybe you do a joint last call with CCWG, and if it's more, complicated, you know, if it's several pages, then we probably talk about a separate document. But if it's a little thing"
  },
  {
    "startTime": "00:42:00",
    "text": "right it's like for Quebec or for this one maybe we get a section, maybe we get some quick people to look at whether this makes sense we'll ship it here and it can obviously update like whatever needs to be updated over on fix that you guys 9,002 would be matt mathis speaking as an author. We're tired Please just call it done gorry fairhurst now has to try and implement this in quick. No, it's nearly always nearly all there in Quick, isn't it? I mean, they base quick spec says refer to the old version of PRR So we write a new version of PRR I mean, at least we should somehow update that quick spec to say point at this one perhaps. And if you could add a few paragraphs or something to say how to do it and what where the pIETFalls are that would be wonderful but another document to do that well um yeah that that's fun but maybe not what we should be doing i mean this has been around for ages I'm saying please add a little bit if you can to tell us how to do it in quick from experience and ship I'm updating things if you think the AD needs to As an individual I would say this is probably less than a page of text to add to quick. If it's more than that, then I think we're probably doing something wrong. As a, as a say this is probably less than a page of text to add quick. If it's more than that, then I think we're probably doing something wrong. As a chair, I sympathize with Matt's point I'd like to see the ship I think if we're going to add a quick section, I want to time down that and be like, if so someone doesn't come up with text in like two months like your your time has passed you become a pump and you will have to like, you know so. Right. So in that vein, first of all, Neil, your your keyboarding is coming through the mics oh sorry okay secondly um yeah i think the operative question is who's willing to"
  },
  {
    "startTime": "00:44:00",
    "text": "figure out and then write quick text and if like the answer is nobody, then I think we have our answer So I don't know if you want to ask for a volunteer That is what I wanted to do. So who is willing to? look at this and at least say there is text needed or there is no text needed? That's, I'm not requesting for someone now saying that he will write or she will write the text which is needed but just give us an indication, a timely indication whether this can, whether this needs quick specific text or not I would do it with I would do it with help, like, oh, Andrew or someone else like ideally help with someone like yourself who's written this for quick before. Like, I do think some text would be helpful just based on what I know already and i'm reading the draft so but if it wasn't there i mean the world wouldn't end so but but I'd rather have a partner personally because it's just hard you go back and forth on text by ourselves, it's impossible impossible So I have a process question Where are we relative towards? relative to last calls? Does this still need both a working group? last call and an IETF last call? It definitely, so it hasn't shipped to the IESG yet, and I think I'm looking at at Yoshi. We are past working group last call so we are going to some bit IESG so this is a phase of working group last call not the rust code so we are considered to have past working group last call and next step is to ship it to the IE, it's, yes. So if I remember correctly, we had a working group last call. We got comments from Marco after that. That's what we have that process has been changed. So if we now get some additional quick text, we"
  },
  {
    "startTime": "00:46:01",
    "text": "might run another short working group class call and then ship it OK, so I think what I'm hearing is that we've opted for option two, which is Alessandro and Ian, are have a time boxed commitment to write some quick text and poor Matt here doesn't have to do anything because he's tired and then like either it happens or it doesn't happen and then we do a second WGLC I can live with that Thank you I mean, if we have a quick specific text, then we can always ping also, we can always ping matthew quick working group for a joint past or something like that Any more comments? Yoshi, did you have anything else to add? I just know, have a very, you know, not related to process question, but a technical question about the scope of the driver So right, so some people think about you know, expanding to this quick. And then so, but uh in case of quick many implementation used to be so, but in case of quick, many implementations is BBR. And then in case of BBR, and in case of BBR, has a pacing mechanism but from my point of view TRR is, you know, the condition control for act driven condition control. So from my point of view, I'm not sure if we can apply PRR to PRR to BBR my naive question Right, that's a good question. So it is not an intended that PRR be applied to BBR? If people think that's"
  },
  {
    "startTime": "00:48:00",
    "text": "worth adding to the draft, we can definitely do that So I mean, we implement PRR specifically for Reno and Cuba and not BBR. I don't know that it would it be useful for people? BBR? BBR? So translated literally, I don't think it's a good idea for BBR BBR um but beat the bbr v1 design for handling loss recovery is very similar to PRR, super similar to PRR actually So I don't think we need to worry about trying to do handling loss recovery is very similar to PRR, super similar to PRR actually. So I don't think we need to worry about trying to port it over for now so if folks seeing maybe it would make sense to basically say that we, to make some statement about the scope of congestion controls that for which PRR is a expected to be useful and say it's expected if be useful if you have an SS thresh and and you have uh and it's known to be useful for reno and cubic something like that I'm sorry, I might have just missed it. So does this document apply to as written currently apply to both Cubic and Reno? Yes, it's intended to. Okay, super yeah I'd want to make Matt storm out of the room to say like what about other Kadesh controls? Lovely, thank From a procedural point of view, I would also prefer that the PRR document does not depend on BBR procedure-wise Okay, Gary Perez. Yeah quick, quick, 9,002 has this House 693C Ferris. Yeah, quick, quick, 9,002 has 6-937 as a informational reference, so that's one where there is a dependency. BBR, please don't because we need another document for that, even if it's short This is not the right place to do that"
  },
  {
    "startTime": "00:50:03",
    "text": "So point of clarification, do you guys mean, do people think, it's worth clarifying that? meant like mentioning bBR to clarify that this is not intended to apply to BBR or should we just not mention BBR at all? I suggest just not mentioning it. It opens a kind of worms And we probably will make a document in the space sometime in the future when we know what to do you could even yeah i agree that it's probably more useful to have a section to see where it applies, like which kind of condition call control. And I believe the answer might be simple if you have a multiplicative decrease, it makes sense Thanks, Mayor. I was going to say something similar And more comments? questions? I just would like to confirm that if anybody opposed to submit this one to IESG, please speaker up. This is a good chance for you seems to be no one day Three, two Thank you The next one is accurate ECN. Are you? Are you entered that? Yep, that's right Thank you Accurate, ECN Bob and richard barnes not here. Mirja"
  },
  {
    "startTime": "00:52:02",
    "text": "is here, but I'm channeling the update. Next slide At the last IETF, you were actually in the situation of the document is done I looked at this one time again and there was one issue and the issue I sent to the mailing list was there's a section about of lower support or implications on off-flow TCP and it was written in the content using transmission offload something like this but the text was actually only talking about the receives side And I looked at the send site of offloading and I played a bit with Nix from Intel and look at the driver specifications and it works basically that the software provides a line TCP segment with an IP head and a TCP header and the TCP payload And then the hardware breaks it up into multiple IP packets. It copies over the IP header. It copies over the TCP header, it splits up the payload And it does some mapping with the T multiple IP packets, it copies over the IP header, it copies over the TCP header, it spits up the payload, and it does some mapping with the TCP flags. So the fin and the push flags only goes in the last segment And the CWR flag goes on the first At least on Intel cards And if you do accurate ECN, you don't want that the um, the, uh, the CWR bit is modified. So it's part of the"
  },
  {
    "startTime": "00:54:02",
    "text": "three bits counters and it should be copied over two every segment and on end the three bits counters and it should be copied over to every segment. And on Intel cards you can actually configure maps so you can say on the first segment which of the TCP flag should go there for the middle segments, which should go there, and for the last segments which should go there which means you can configure whether the TSO works for classic ECN or you can even change the config for Intel cards, you can change the configuration to do exactly what's expected by accurate ECN You don't do this per connection or per packet you pass down It's a global modification I have no idea whether this is configured on cards by other members so I'm not making a statement there I just realized that there might be a problem with some vendors, and problem means that you need to do something in the software or in the configuration if you use classic ECN or accurate ECN and this was not covered in the text text And so I said, please, either restrict your, make explicit that your description is only about the receive path or mention some please either restrict your, make explicit that your description is only about the receive path or mention something about the send path And unfortunately, there was no feedback by the office that your description is only about the receive path or mention something about the send path. And unfortunately, there was no feedback by the authors between the last IETF and I think, two weeks ago So that's why it took a while. There is no text in which describes the situation and makes people aware that they have to"
  },
  {
    "startTime": "00:56:02",
    "text": "consider this if they are using equity ECN and income combination with TSO, which at least is for some people, it's an important factor to reduce the CPC load You have different options so you can possibly just ignore it and don't provide packets with TSO and enabled when they are critical and then you reduce the amount of packets you can use TSO for or you could focus on one of the other configure unique in that mode and don't do the other version. That's also possible So there are based forward. This is not a blocking point, but it's a point you need to address That was the last issue I'm aware of as a document shepherd any further comments on this document? Stuart Escher from Apple I reviewed this document last weekend. I sent an email about it which I actually wrote on the plane, but I forgot to click send. So I realized that and sent it at the start of this meeting So that's in the email, but I'll repeat it here as well, because I think it's important This document has been in the works for almost 10 years It's implemented in Mac OS and iOS It's required for L4 And I'm really impressed with this document. I'm impressed with how much work went into it. If this had been in TCP from the start, it would just be one page"
  },
  {
    "startTime": "00:58:02",
    "text": "And instead it's one page of spec and 71 pages of forwards-backwards compatibility negotiation dealing with TSO dealing with middle boxes dealing with buggy implementations I don't know whether they missed anything, but I couldn't see anything that they missed so it's really thorough it's needed If we still have neal cardwell on the call, he might be able to comment because he's probably better informed than I am My understanding is accurate ECN is not yet in Linux mainline for the good reason that the Linux main maintainers don't want to throw in every random idea that comes along. They want to see IETF consensus before they put something in the Linux kernel and I understand that So we're in this situation now where Comcast is rolling out the Comcast is doing trials of L4S and I think soon to be, launching it for 60 million customers customers Apple has Prague for Quick and coming soon for TCP. We're making huge progress and the Linux service in the data center of have become the bottleneck that's preventing all of this So I would love us in this working group. I mean it's been through working group last call maybe more than once I think it's time to publish this And let me know what I can do to help make that happen Thank you you Mia. Yeah, I just wanted to say there is ongoing work to bring this into the Linux mainline And I think having an RFC would only help that work Yes So as I said, it was already, I mean it was almost finished at the last IETF So I have the shepherd write up on my hard disk and I will basically say that there is"
  },
  {
    "startTime": "01:00:01",
    "text": "consensus in the working group except for jon peterson, which is some of the issues we couldn't address, but it's jon peterson and and there is a way to avoid the problems the person is bringing up that will be documented and the shepherd write up and that has been agreed with the AD So the document will be shipped with this caveat From remote, any comments? or if not then we can move on. Thank you Okay, hello everyone. My name is Carla gomez and I'm going to present the last update of the draft entitled TCP Act Rate Request TAR option. Mike Walthor is John Crowcroft from the University of Cambridge. So first of all, a quick reminder on the motivation for the draft The latex is a widely used mechanism which is intended to reduce protocol overhead. However, it may also contribute to suboptimal performance in a number of scenarios such as so-called large congestion with those scenarios meaning when the congestion window size is much greater than the MSS. In that case, saving more than one of every two acts may help improve performance, or small congestion window scenarios, meaning a congestion window size up to the order of one MSS, where the late acts may improve too much delay or may help, sorry, may limit congestion window growth and so on Next please. So this is the main format for the option. The R field in the the ACC rate, which is requested by the C"
  },
  {
    "startTime": "01:02:02",
    "text": "sender meaning after how many received data segments the receiver should send an AC And then there's the special case of R equal to 0 which indicates the request of an immediate ACC while keeping the steady state up next please so today I'm presenting version 05, which aims to address comments received in the last IETF and actually the main comment was are we going to make something in the network very unhappy because of TAR? And that was in the context of the presence of elements that aim to modify the act rate between the two communicating endpoints. Next please So in order to try to address this point, we have first added a Appendix C where we into analyze, which is the impact of TAR in the present of such elements that modify the acc rate so first of all we start by discussing act filtering and act decimation So act filtering is a technique by which there may be several acts from the same connection between two endpoints stored in a key queue, perhaps at the receiver, perhaps in some middle element between the two endpoints And in this technique, the older axe may be removed so our understanding is that despite the presence of tar there will still be at least one act per congestion window of data And therefore, we don't see any particular problem or any obvious damage that tar would encourage here so however the there's act decimation where ax are dropped, but with less control over which ones are dropped So in this case, act decimation may draw all the acts that correspond to a congestion window of data producing retransmission timer expiration. And in fact,"
  },
  {
    "startTime": "01:04:02",
    "text": "if we use tar with an act rate, the greater than two, it may contribute to this problem because it will reduce the number of acts that will be sent by the receiver. So here we would propose a rather conservative solution, which would be the upon retransmission timer expiration, the sender in this case would request the receiver to reverse to normal delayed acts operation in this case. Next please so um we also uh present receiver site aggregation such as LRO in the appendix We explained that it may reduce also the number of acts In this case, TAR using a request of R greater than 2 may also further reduce the number of acts, may contribute to the same problem of not eliciting at least one act per congestion window of data, leading to retransmission time expiration and we understand that the same proposed solution would apply meaning that the sender would request the receiver to delay to revert to delay tax in that case. Next, please So for this reason, we have added some text in Section 3 delay tax in that case next please so for this reason we have added some text in section 3.1 which describes the sender behavior which is as follows. When the sender knows the the receiver is start capable. And the last accurate requested has been greater than two upon retransmission timer expiration then the segment carrying retransmitted data must carry a TAR option with R equal to two So we would expect this measure to request the receipt to revert to delayed X So next place, yeah, so that's it. I don't know if there may be comments or questions questions NIL"
  },
  {
    "startTime": "01:06:05",
    "text": "so upon RTO, the idea would be to say, to use a tarb value of two with it, and I guess, can you remind me that? means every other packet? Is that right? right? I didn't hear well well So it was the recommendation that upon retransmission timeout, the data center is asking the data receiver to acknowledge every other packet, like every two packets, is that right? Yeah, I realize that yeah, double thing after the drop was submitted maybe there's another way to try to produce the effect of reverting to tireless operation on the receipt but, well requesting are equal to two, in principle should also produce the same effect because in the draft we are also saying that the receiver in any case as in the normal base main TCP specification an act must not be delayed for more than well 05 seconds But perhaps there's a cleaner way to do that, which would be using, for instance, one of the bits in the format of the option There's one reserved bit. Also, we might even steal one of the bits from the R field to signal the receiver that yeah maybe it's also we might even steal one of the bits from the R field to signal the receiver that yeah maybe instead of doing it in this way to just signal okay stop using TAR I guess my concern that I wanted to mention was that when you have a retransmission timeout, the standards and most of the implementation set the congestion window to one. And so if you then send one packet and you're asking the receiver to only acknowledge every other packet, then the receipt is going to give you a delayed act, which might"
  },
  {
    "startTime": "01:08:02",
    "text": "cause 200 milliseconds of extra latency And so if we're going to go to the trouble of having an explicit signal asking the receiver to optimize, their act behavior, I would suggest that when you have a retransmission timeout for the first packet that you send, you ask for an immediate acknowledgement, which I guess maybe is the TAR value of 1 or something And then as you increase your congestion window, you could, you know, maybe gradually increase the R value or something. But I was just going to encourage the text to be sensitive to that fact that after retransmission timeout, usually the C-wind is one. And so if you use R equals two, you're probably going to invite 200 milliseconds of latency when you didn't need to Okay, thank you. Yeah, so we'll take this into account Yossi? just think to comment to address the news comment I think it will be easy to you know news comment I think it will be easy to create a new draft that said initial window is two. That is, I think, must rate for the solution from my point of view view We had a bit of a hard time hearing it. Unfortunately, the audio in the room is not always clear, especially for the chairs. Could you repeat that riochi okay yeah I pretty fast setting initial window too, rather than one. That might be a good solution for the issue that's new rates So am I correct in saying that you like the text to say something like"
  },
  {
    "startTime": "01:10:02",
    "text": "say like the minimum of either? two or the current condition window after retransmission timeout? Right. Okay. That makes sense. Yeah, that's kind of I would agree that's a sensible, sensible approach The goal would be that after retransmission time out, you would always ensure an immediate DAC and then make that So very first, just encouraging that. That also gives you a time also gives you a timestamp because it gives you an RTT measurement Getting it to respond immediately after an RTL sounds a good thing You look puzzled. I shall talk slow I think doing R equals zero or R equals one after an RTO is a good thing because you get an immediate feedback, you get a new time measurement Maybe the time was wrong, maybe that's why you got an RTO So this is good practice to do that. Maybe even good practice after a few packets and then go back to two. I mean, you figure this out Okay, thank you Any further comments? Thank you, thank you So the next presentation is about ghost eggs and the presenter's remote. It's Japan Japan Hello everyone, my name is Yerba"
  },
  {
    "startTime": "01:12:02",
    "text": "Pan. I'm going to give a presentation regarding all recently some media internet drops which concerns the TCP Han handling of out-off window package to mitigate a problem we call GoStuck. So in the link here, you could fund the current internet drops drops So here is a list of what is covered in the presentation. So first, overall, our internet draft focus on the ACN number validation for established DCP connections and we aim to solve a problem that allows segments with out-off window arc numbers to be accepted And we call these arc numbers as ghost arc So first I will provide a review of the current RFC and then a definition of the ghost dark problem. Then it's the proper solution in our draft And then it's finally the implantation stack of operating systems So I drafts and then it's finally the implementation status of operating systems. So as of now, RFC 9903 specifies the arc number validation for TCC ends for our incoming segments for established TCP connection we need to check both the sequence number and arc number for the incoming segments because they internet drop is mainly focused on the arc validation, so I will only cover the arc number validation here. For arc value, we reject the segments. If the segments arc value is after the same next, which is the next spike to be sent by the server This is because, like, we should never acknowledge, let's say, Clanton acknowledge something the server has never since So the current standards allow a server to assess anything before send next, which also covers old aquaulius before sent an unknown acknowledged. Since I acknowledge is the first part, to be since, but not yet acknowledged, and"
  },
  {
    "startTime": "01:14:02",
    "text": "so it means that we could also accept old aquaulies before this point And in principle, this allows a range of two giga sequence number to be acknowledged by the P. And sorry next slide So the current ARFSI allows the basic RFC allows a large range of a separate arc numbers and this allows a TCP injection attack to fund the assessment arc number in two attempts RFC 5961 tropos to apply a stricter challenge for assemble arc numbers which try to mitigate the TCP injection problem So the condition is updated a bit The right-hand side is still the packets cannot acknowledge something that is after the next But in the left-hand side, we also limit the old-zac number cannot be true old within the range of mic-send window Yeah, can you please go to the next side So, but unfortunately, even with the two sanders after RFC-591, it's still possible that an attacker could acknowledge something out of the window, and we call this as a GOSTAC. This happens for newly established this connections and when there is no data only few bytes transferred. As you can see in the flow, here, if we have a newly established connection, then we have sent acknowledge equal to synnext equal to the I send number plus one So at this point, any sequence number before the server initial sequence number are not used by the server, but according to the RFC 5961 specification or the RFC 929 specification is both the server, but according to the RFC 596-1 specification or the RFC-993 specification, these ODUC numbers before the server ICE number, I can see considered as a sample And this allows a TCP injection attack or TCP"
  },
  {
    "startTime": "01:16:02",
    "text": "spoofing attack to inject pillows into a new TCP connection or it might accidentally accept a missing or delays TCP segments in previous connections. So our internet drafts concern this problem and want to mitigate it. Next slide So in the internet draft we provide two implementation choice. The first one is generic and the first one is generic, and it doesn't require any RFC recommendation to be implementing by the TCP stack. And in the summit internet drafts the formula shows on this slide is only from the current Internet draft based on some comments from michael sweet believe there are some conditions we could opt optimize and we are going to update them in the next revision. But as for now, I will only introduce what is on the drafts so to implement the mitigation we need to add the new state variable, no access check for established TCP connections And this basically tracking wider the connection is possible to the ghost arc problem, or it's not possible So for incoming seconds, we check the following condition here and the first step is to check the no asset check flag If the assets checking for the ghost arc, condition here, and the first step is to check the no asset check flight. If the access checking for the growth stock problem is necessary, we continue to the next part of the condition. Here we check whether the arc value is the old arc value before send the arc knowledge, because the ghost arc problem only happens at this time. So if it's indeed a old aqua value, then we compare the segments aqua value with the server ice member. So if it's before the segment, iscine, then it's using something the server has never since So we should drop these segments and maybe send the challenge act otherwise the segment should be continued process"
  },
  {
    "startTime": "01:18:00",
    "text": "So when the connection, it's first established. They know as a check flag, should be initialized to force This means the connection needs to be checked for growth stock problem because for a newly established connection, sequence number before ISN can never be used. So once they send the acknowledge sent satisfy the condition in the second form we say that's the segment sequence number is already sufficient, large enough That's a ghost arc number, a cyber arc number can never before the signal knowledge, can never before the ISEN number, so the checking for ghost arc is no necessary and we should update the state variable Next slide, please please So the second implementation choice is required some RFC 4-888 choice is required some RFC for 889 status variable supports and this static variable here, it tracks the number of bytes that is already acknowledged by the year So a TCP stack implements the RFC for non-8 specification could use the following condition Basically, this condition makes sure that an arc number is only a sample If it's indeed some ODAQA that's acknowledged something, that's already acknowledged. So here is an example Let's see we have a newly established connection where no data is transferred. So the new condition here will constrain the several arc number to only since acknowledged to send next. And all numbers before these notes are separate separate up please next slide So, currently Linux and FreeBSD has implemented the GoStac medication, and Linux use the second choice They have implemented the Axi4-8 specific and FreeBSD has also adopted the"
  },
  {
    "startTime": "01:20:02",
    "text": "input check for GOSTAC and they are using the generics rule solution. But they have some optimized the condition in the drafts so we are planning to offer adapt this optimization in the next revision Next slide, please and how to improve and develop the currency internet drafts So we maybe have several options. The first is we might give this to implementation and the same to improve and develop the currency internal drafts, so we maybe have several options. The first is we might give this to implementation, and the second is we may add this as a arbiter for RFC-903 or RFC-596-1 It's all we could require the RFC-5961 as a prerequisite as our discussion with Michael, this could optimize our condition or simplify the Internet draft debits. The last choice is maybe we could also make this into a short RFC So if you have any questions or suggestions, please share with us. Thank you Thank you for the presentation So the question here is so one of the questions the chairs would like to get feedback on is on the procedural way with how to handle protecting against those acts. So should we specify so we document that, should we specify that? and if so how? Hi, I'm Lars Saga, good that you're asking that another about like the technical merit because I don't have any, I haven't read the draft, but it looks really good, right? Don't be wrong, and it's implemented. So yes, we should definitely do some merit because I don't have any, I haven't read the draft, but it looks really good, right? Don't be wrong, and it's implemented. So yes, we should definitely do something and leaving it up to the implementation, I think, is not what we wanted to do. We want to write down what the implementation should be doing I don't think we can do it as a Narada because it's not actually a bug that like mistake in the text, but it's actually adding something"
  },
  {
    "startTime": "01:22:03",
    "text": "new and valuable to the specs. So it needs to be its own RFC that updates whatever needs to be updated And yeah, we should do this, I think whether we want to have that support as a prerequisite, I'll leave as a question too others. Thank you Microtrix from the floor why I brought up the question on should this be in addition to 59? is that the Linux implementation which is using this byte count variable that way extend the check which is described in our CED 5961. So that way is improving the 5961 check And I don't see why an implementation, I don't see a technical reason why an implementation would like to check for Ghost X but not the check from 50 5961. The ghost egg check only works in the first two gigs gigabytes. So, I choose the term tech works in the first two gigabytes. So I choose the term technical reasons because 51's 59 first two gigabytes. So I choose the term technical reasons, because 59161 has IPR declarations on it And in the BSD implementation this code is protected by assist control variable in secure soon, insecure reset, insecure X act. So if someone does not want to use this IP he can turn it off by sys control variables But from a technical point of view, I would say focal this IPR, he can turn it off by sys control variables. But from a technical point of view, I would say, I mean, write this doc, write an RFC and X, and the conditions"
  },
  {
    "startTime": "01:24:02",
    "text": "used in 5961 5961 Would Lars other view like to summarize? the conversation or is it not relevant to the room? Okay, thanks Pardon? or is it not relevant to the room? Okay, thanks. So I looked at the Datatracker and the Datatracker does not record any IPR for 5961 SBA being submitted. And I think the authors are from Cisco and Cisco has like a general license agreement and I think if there were IPR from Cisco we could like work with Cisco so generally so so license agreement. And I think if there were IPR from Cisco, we could work with Cisco, so generally. So we should double check what the status is, if there's any other IPR that I'm not aware of it might not be from the authors it might be somebody else right But the Datatracker at least on my casual clicking the IPI button didn't come up with anything Thanks Lars. That's all As a chair out of ways we do take this forward. I think we have a number of ways we don't want to take it forward. It seems like there's pretty good consensus that we should do something and not just drop us in the floor. It seems like we can do this as Narata I don't see a ton of interested in doing a separate area although I maybe I miss reading that that It's, huh? Lars, can you, sorry, I can't hear you update another, do abyss on another RFC Microtripsen as an individual"
  },
  {
    "startTime": "01:26:02",
    "text": "I would be helping, willing to help on working on the ROC. It's a chart document Thank you Michael. So it sounds like maybe there's support for moving this forward forward Yoshid, as the other chair, do you have any thoughts on? Yeah, I basically I agree with creating a SOTRIC Yeah, sounds good so um based on that, I'm inclined to say we should have a call for adoption on the mailing list after this week. Okay Oh, great. I think that's all we have for this meeting is that Yep Pardon? You found the IPR. Yeah You did or you did not? Okay, so that has been clarified. Any further comments? comments? So on 5961, Peter Lay. There is IPR declaration on it. The data track is much will happen Thank you. I mean, I don't know We can check offline. Thank you So 19 minutes were the perfect amount of time for this meeting. We are done so we can give you, pardon? Oh, yeah, can I ask some technical question to the draft? It's not a process question it's technical question Oh, also has already gone Sorry so for the option, two, I think there are my idea"
  },
  {
    "startTime": "01:28:02",
    "text": "lapping issues. I think the Bita axe is in 16 two, I think there might be a lapping issues. I think the bi-tax is in 64. So if you receive the data more than 64 bits, the counter has been left. And then it might cause some issue That's my naive thinking To clarify, option two is this one, is that correct? Yeah, that one. Yes I think TCP starts is into 64 value. Stores in in 60 64, right? So if you send more than 64 between then the count will be left That's cool. That's clear enough For today, this is a high number, but that's why the BSD implement is used the other one one It's simple to avoid this overflows Maybe I should send a message to the mailing list, I guess guess guess Yes, so our current draft doesn't consider if it's happening to have an overflow to end this problem, so it could happen yeah, if it's large enough and it's rubber around, then this could happen Any further comments? Then you get 30 minutes back Thank you everyone Thank you"
  },
  {
    "startTime": "01:30:08",
    "text": "Thank you Thank you"
  }
]
