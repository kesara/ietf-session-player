[
  {
    "startTime": "00:00:17",
    "text": "hello everyone welcome to the interior ietf 101 so we\u0027re gonna get started we have a busy agenda this time so first of all not well I guess you\u0027ve heard that there\u0027s a there\u0027s a new not well so please take a look at it especially there is a privacy policy at the end that we encourage you guys to take a look that is a new addition to the node well all the rest pretty much the same as I said used some reminders minutes are taken minutes are the meeting is recorded your presence will be locked and we scribe please help contribute online to the minutes we have the etherpad can we get some help from minute taker yeah okay so thank you very much Ian for helping but please do help um whenever you can to get more notes or to clarify your points if you see them jabber do you have do we have someone that can help us with the Java please thank you thank you perfect so moving down to the agenda now we\u0027re going to give you guys a quick update from all the chairs in the ad on document status and some other topics then we have the presentation from Eric on the PVD IP tunnels quick update from mark if he\u0027s around then we have a gooey generic UDP encapsulation from tom some presentation about iLab there something there\u0027s going to be the debuff that we also have our quick heads up here that\u0027s going to be presented then we we have the presentation about the privacy network address from Tom as well IP fragmentation from Ron toxics from Vladimir and availability of information in criminal investigations from David sorry here this okay could we increase the volume thank you very much yeah all right so moving down to this working group status update so the privacy considerations for i3 broadcast multicast protocols it\u0027s now in the RFC editors q re just a quick answer to the to the jabber we did receive the slides from the presenters their remote "
  },
  {
    "startTime": "00:03:17",
    "text": "presenters as well so privacy considerations for IP broadcast and now it\u0027s an RFC editors queue so hopefully soon will become an IRC GUI we have the presentation from that working group draft the IP over internationally partially partitioned links and that\u0027s a trap type expired and we encourage people to take a look for please if you if you have interest in this topic send comments make a review that would be very useful for the author right now the the draft is stalled because we haven\u0027t had any any update on it and but we do need the community feedback if we want to advance that topic so please take a look at that one probe nights now RFC 8335 so thank you very much congratulations there and IP tunnels in the internet architecture we\u0027ll get a presentation so moving to the announcements is Suresh in the room yeah thanks isis krishnan area to do so we had a like discussion in the iesg so one of the documents that it came in through the independent stream and it was trying to update like are actually change staying and document that was done here which is the recommendations for logging with ports so what we did in the IES G is like sent a note saying like don\u0027t publish this because it needs to be done in interior because we published the original document so that\u0027s the last document on the list over there the draft divorce eg and logging so this like personally me I spoke to the author and he was willing to present remotely the document and daddy has to see is the recommendations like in the RFC\u0027s he\u0027s talking about is like whether it\u0027s practical and how he can actually go about logging the boats properly based on like what\u0027s in the servers and everything so there\u0027s like this one contains like a inventory of what\u0027s in the servers and what\u0027s being done what\u0027s not being done and some techniques in there so I would really appreciate if you pay attention to it and see like you know how we can update our PCB thanks yep so so we\u0027ll make sure that we leave enough room in the agenda for that presentation at the end so Suresh said that is the the one on availability of information in criminal investigations involving large-scale IP address sharing technologies all right so any bashing to the agenda hearing none I guess we can move to Eric please by being here okay anyway so compared to what happens last time we got a big big news and we can show the next slide if you don\u0027t know remember can the discussion whether we can get already anionic code point basically for the option we have now so thank you to the "
  },
  {
    "startTime": "00:06:19",
    "text": "chair and Suresh I don\u0027t know s Eurasia disappear so thank you for this it allows us to make a multiple implementation of sending this array option and receiving this array option to be compatible there and make more tests we use this number 21 and I think you know it\u0027s a fan answer with 21 but at least we got the number it\u0027s late right - answer 41 anymore anyway it\u0027s like a guide is obviously not read in this room anyway so we use this number for di cottan on this weekend next slide other change so we make the things clear there were a lot of section regarding using the PVD additional information remember it is the G is on file that we are fetching to describe and the connection based on the bandwidth of latency for instance we completely remove this from the text I think it\u0027s still valuable to F to use the PVD JSON file to convey some transport level information but for this draft we remove it if we arm no interest later let\u0027s plant for another draft and maybe another document there thanks to Bob the document was a little bit fuzzy indeed whether it was for the network layer or the application layer for the author it was obvious that the JSON file that we fashioned after the array is for the application but it was not in the text so we make it clear that this additional information is for the application we even think to change the name into additional application information to make it very crystal clear we try to improve the security and privacy section of course mostly we can maybe improve it we made a mistake in doing the padding you know all the options in our ASO actually in any neighbor discovery message must be aligned on 8 bytes and we basically at the previous one aligning on the four bytes so easy to fix last time in Singapore there was a huge amount of discussion about all can we send different information to PVD aware host and non PVD aware both so the authors we got a design meeting in a nice room in Singapore we considered as an option such as using another specific multicast group to send this array to PVD away only at this weekend of dirty and a few other one so we end up in an idea not new code container next slide you don\u0027t mind so that\u0027s the new option and you see them in this option we can add at the bottom additional option like Pio array of a row deformation option prefix information option a with other options that can validly exist into a "
  },
  {
    "startTime": "00:09:19",
    "text": "route advertisement can be included into the PVD option as we need as well sometimes to include options like MTU which are not per se an option but our feeling to the array header itself we have the option based on the bid a to include yes or no a repetition of the routing advertisement header so we can add their next slide so example look about this one this is the PVD ID option it includes at the bottom two other option this Rd at the NSS and the PIO all of them makes for quiz 5 bytes but 4 plus 5 times 8 bytes the ID and the header with example dot orc there makes as well 2 bytes by 2 times 8 or 10 so the full length is 12 okay actually I counted at least three used it to make 12 so now we put 12 in the lines there meaning next slide a PVD aware understand deception no he is a duty to look inside the option and now you know that okay the a flag is not set so after the name and the padding and we know the name is finished because they are lengths right is the fully qualified domain name is expressed as a DNS request name we have another option which is our DNS s we got the length of this one we go to the next one and so on so for p video where they will see not only the PVD ID it is used to bundle all information together and present it to the application but we they also got this our DN SS and the PIO next slide and non PVD aware do not understand the type xxi that we just receive so they say okay I skip it and the length is 12 so I\u0027m going to the option which is after so with this we can present Pio aardeen SS or whatever you want to PVD away oast while the options outside of the container as simply use only by non p video a host of course an array can only contain if you want just the PVD ID option okay that\u0027s not a problem next line implementation status nothing has changed compared to Singapore we make progress on Nanak\u0027s obviously next line and the hackathon as I said we work together with two universities relation Aberdeen got some people from Cisco but Kyle is well from San vine and another University three I forget wenching from three Campari Tech and basically it was the mix of pvd\u0027s or "
  },
  {
    "startTime": "00:12:22",
    "text": "9x a neat which is in another taps project source address dependent routing because we like this and Cal port it was done by acharya next so it has really all the piece we touch and all those piece were using the new ini code next so we are not ready fucking room class cold for sure even if the implementation exists and we are working for this for more than a year now but I would love to get a service review by this group as well as I will ask later to six men and v6 ops so review are really important I mean modern mp3 apply two questions of course here and ring the week but you can\u0027t commit to review this document and it changed any volunteer okay done Ted Michael and Yin I don\u0027t know who\u0027s taking notes but you can put this into our thank you don\u0027t forget to put your name right and for me that\u0027s it that\u0027s all I have to say today and thanks again for your support for Unicode okay I have a skip it is to know this okay if you want okay I prepare some slide is a backup in case I got the question right so go on next so we provide into the JSON file some information right and we use a specific well-known URL so if you know the name of the company you can mostly guess the fully qualified domain name and guess the URL it\u0027s well known right as on purpose so you could download from everywhere this JSON file so my advice is that don\u0027t put anything confidential here right because anyone can igneel access and you can also restrict the access on the web server hosting this JSON file to addresses that belongs to you okay working for Cisco I will accept only request from prefixes allocated to Cisco not to say another company that\u0027s one aspect next now even if we provide a PVD ID it could be something like example.org or whatever it\u0027s just information right we don\u0027t provide anything more anyway than array but think about a rock DVD I don\u0027t know what it was really useful to do as Montana Tech but we can F as I said the black ed we can have the JSON file server can be a black hat guy the network can be of style and the first device can be also hostile so they can basically send you rogue route advertisement if a fake DVD ID or they can deliver to you a fake JSON file with wrong information so that\u0027s all we try to do it now next "
  },
  {
    "startTime": "00:15:24",
    "text": "so first one I am layer two adjacent and I want to send you a packet pretending a you are connected to cooperate comma a regard block it right there\u0027s no more dangerous than anything so problem solve as long as you run a decent network next slide so now in this case the router is a bad guy so you I not spot somewhere and the spot somewhere pretends to be again cooperate or in this case good calm so what you do you try to connect to the JSON 5 server and this guy is a wrong one as well right they affect you DNS and they figure the certificate oh but you cannot affect a certificate right so when you try and download the JSON file TLS will refuse to connect and if you have a look at configuration on the end point telling a I only accept PVD that retries the fetch of this JSON file remember that\u0027s an option but if you are configured to download this file and you cannot get it because the TLS session is not established because the certificate is even valid cell sign or whatever you refuse and you reject this PVD next so now another one where again you are in hot spot pretends to be good calm this time it does not pretend to be the JSON file server as well so you can connect with a real SSL or TLS session and don\u0027t know the JSON file now the thing we have in the JSON file a mandatory field key which is prefix which is basically in this case vb8 beef I forget to put a slash for TX or in the slide now when you receive it you need to compare this covering prefix from the JSON file with the prefixes you receive as API or in this case the Pio was including bed / 64 bed / 64 is not including in B / 48 will reject it okay so you need to deliver not only the write JSON file but we need to deliver the right Pio oh I\u0027m a bad guy I am allowed to do not next right so now I am sending okay no not spot I am sending you the array good calm okay the flag is still there now I\u0027m using the right basically v6 address right Pio I\u0027m fetching the file JSON file and indeed it would match right because there is the route in the middle is "
  },
  {
    "startTime": "00:18:24",
    "text": "doing NPT and nothing between the real good traffic\u0027s beef and the bed that is used by the attacker in this case the protection is very simple again pretty much like the confidentiality the server will only serve the JSON file to its own address and the request after being knighted or NPDES is coming from bed so it drops the request it doesn\u0027t receive the JSON file and again I\u0027m configured to use only if there is a JSON file I don\u0027t get it I refuse to use this PVD next now we find a place and it\u0027s actually PA within the room we find this which is can intricate right we can fool everything nothing is really secured 100% what do we have now we have a bad guy bottom left which managed to get access to the real network so his access in the beef Network okay and you know that the PVD is good calm now with a companion somewhere and the victim is on the top left the next router is sending a sending PVD the name is good calm and please use the address beef as well remember the big arrow Janel whatever you want is tuna right GRE or whatever now the victim somewhere on the top left receive oh is good calm let\u0027s do it let\u0027s connect to the server and then this is the small line going via the dinner that\u0027s rotting decision proxy by the bad guy in the good comm network that goes to the server the server sees a good sauce address is surveyed and to NSSL works fine right because the right certificate right address and then in this case the attacker is able to pretend is good calm but on your honestly is already in good calm so what can you do there right so basically in this case we can do nothing more but we never pretend to be a fully secure right PVD are here not to secure erase PVD sorry to give you more information and the application layer and nothing is the last 100 yes sorry privacy so obviously there is some minor issue is that when the goose boat would arrest even a PVD a wants to get information about it it will basically go and fish the error right access your elevator LS so anybody on the path can know that this v6 address is trying to connect to this DVD right it is thus nice in the clear you can even know who is there okay but what\u0027s different than all our "
  },
  {
    "startTime": "00:21:25",
    "text": "device run now here going to captive that example.com or whatever your operating system use right now to detect there is a captive Potter it\u0027s even better because normally when here all of us in the room except some exception right we do not go to our own cooperation to see what there is a captive portal right we go to some other vendors which is not Python the service providers or the user what indeed when you use PVD you stay within one Operator say or support or whatever that\u0027s one thing and we advise in the draft as well it as soon as you have used your ipv6 address to fetch this JSON file you change of a pv6 address and the other one is no more no more used you throw it away that\u0027s basically our status a little bit fast explained its little bit more explanation into the draft all we can deliver some level of security and we simply put and say that privacy nothing is perfect but it\u0027s way better than what we are using right now and I see now that\u0027s the last one okay question any questions so maybe we have asked the the security Directorate to take a look to give us another point of view okay so hopefully they will provide some feedback I guess they were swamped by this he knows this meeting I mean so not yet but hopefully we\u0027ll get some song external point of view and take a look at this answers I don\u0027t know if everything is capturing the in the eye wants to you okay perfect okay so thank you and thank you for asking Thanks okay next is mark in the room No okay so then I guess we can go to to Tom hi I\u0027m Tom Herbert I\u0027m gonna give an update on generic UDP encapsulation so there\u0027s two drafts that we\u0027ll talk about so one is base goo draft that\u0027s in version 5 it is in working group last call not a lot of comments in the last call but we did have quite a few pretty in-depth reviews previously the only major change to the latest revision goo version became goo variant so joke touch had a concern that version implies kind of precedents for obsolescence of "
  },
  {
    "startTime": "00:24:25",
    "text": "previous versions so variant gives us a little more flexibility so it could be kind of like a canonical version or in the case version zero version versus version 1 of goo they\u0027re really different kind of variants version 1 happened to be a very compressed form so just a couple of possible future updates so one of the things we may do the C type field right now if the control bit is said in one of the goo header this indicates a control type it occurred to me that you will encapsulate any IP protocol but there are things that we may want to encapsulate in the future for instance another UDP based protocol so for instance we could have Lisp over go a beer over go the reason to do that is goo kind of provides some general and capsulation features and capabilities it\u0027s not really about specific use cases so for instance if you wanted to add fragmentation of go to something like list we could do that so it\u0027s a possible thing we could add another thing that could be pondered as I\u0027m adding a private data so goo has this concept of private data within the header but we never really specified a format for that conceivably we could add a flag field that says what the format is so it could be some sort of tlvs or additional types of format could be an embedded alternative protocol so one possibility the other thing is goo is udp-based however it\u0027s not really inherent that it has to be in UDP conceivably we can make it an IP protocol in itself or Ethernet code point probably a little easier since it has a larger space the advantage of that is would be kind of a common encapsulation protocol similar to how GRE operates in those three modes but in case of goo might be a little more extendable in the future so the other draft is go extensions this is in version 3 again in working group last call not many comments it has received some some review the current state is there are eight extensions defined and like I mentioned they\u0027re really about encapsulation and an 11 of 16 flag bits have been allocated so the obvious problem here is we only have 16 flag bits so what happens when we run out of flag bits because we had extensions the answer to that which is actually on the next slide the antenna is at the last bit in the flag field will indicate a new set of flags as in another field this was actually an earlier version of good we removed it because the point was that our definition of defining Flags we "
  },
  {
    "startTime": "00:27:25",
    "text": "wanted to find them contiguously so in the future once we hit the limitation that\u0027s last bit is intended to give us another set of flag fields and then that gives us 32 more the estimate that I think is probably pretty accurate about one flag bit per year allocated so 32 plus 5 so hopefully we have about 30 years of lifetime before we have to go through that that again like I said one of the reasons why we don\u0027t think there\u0027s going to be a lot of extent few extensions really are just about encapsulation not specific use cases so for specific specific use cases we would want to put those in a different place in the packet either the private fields or inside like I said we could have an encapsulation of another type protocol and I forgot to mention so we didn\u0027t make one major edition in the latest version of the go extensions that\u0027s an alternate checksum this is something similar to UDP options in this case we have a crc32 CRC 16 and CRC ccitt the reason why there\u0027s two CRC 16 it was really difficult to find which one kind of has is more important they\u0027re both equally used in different contexts so UDP options for instance you is that the latter linux turns out it has the first one implemented so they\u0027re both there the good news is that it\u0027s a configuration thing so you can only use this if both sides kind of agreed on it anyway there was one important point and I think this is actually coming out in UDP options also if we make a CRC or security field or anything like that optional and it covers the header they do not protect the actual option so for instance if this were a TLV and we had a TLV type it said this is a CRC if that TLV type became corrupted it would turn into something else the receiver might not see the CRC so the value of having the CRC goes down if this is one reason why we like to have like TCP check sum UDP checksum are inherent in the packet so that\u0027s one thing we make a note of that the answer here is it\u0027s a configuration option if the receiver expects security or expects the CRC and doesn\u0027t see it then they should drop the packet and make a note of it the GU flag field extension like I mentioned it\u0027s intended to be the last bit of the flags so the idea is the I guess that the 31st bit would be the e bit and that will point to a new flag field so that 32-bits it looks like just like any other Flags field but when we\u0027re processing the flags after the initial flags our process will hop down to that and then continue processing flags and then fields for those flags follow all "
  },
  {
    "startTime": "00:30:25",
    "text": "of that\u0027s fairly straightforward thinking about new possible new extensions I think the OEM measurement bits so there are two of them defined for 8321 that may be very reasonable to put into goo flag fields also a group based policy may be reasonable and as I mentioned if we won\u0027t want it to format private data the format type may be in a in a field and that would indicate what the type is of the private data so that\u0027s all I had any questions Corie Corie first I\u0027m curious about why you think you need three different CRC formats it\u0027s like how long is your data is that not the only thing that would drive that the choices CIC into our ability seems more key to having lots of options here it\u0027s um it\u0027s a two bit field so we have four we have three combinations so crc32 kind of makes sense because that\u0027s either at CRC but the argument there is well that\u0027s kind of expensive so what about a CRC 16 so like I said it was it was kind of a coin toss I did not have a strong opinion but I couldn\u0027t find any good precedence either with an IETF or with in general networking community about which is preferred I don\u0027t think it particularly cost us anything except a couple of flag bits yeah we also cost of and what less interoperability here I mean this is like creating options just for the sake of it I mean and we chose a CIC 32 I think in a CTP and look at the SCTP story and you\u0027ll find why and why we think that\u0027s actually okay there are they\u0027re not a normal CRC the earth you can choose either CRC and 30 to depend on what you want what you think is better I mean it they don\u0027t have that much different properties there is a document actually discusses the difference between the two computationally it\u0027s not that much more expensive than their CRC 16 I don\u0027t have a strong opinion honestly if we can we can chuck the CRC 16 if that\u0027s fine I would point out one thing that we did do all the CRC\u0027s the checksum that we have and the security they all have the length field so it\u0027s kind of like a UDP light thing so we cover so it is optional data included so I kind of like that aspect of it like I said I don\u0027t have a strong opinion it\u0027s that\u0027s good feedback they\u0027ve heard like verbal ink CRC hurts you oughta hey you you\u0027re trying to verify integrity you shouldn\u0027t make it more complex let me give if you want to use more than one format let me give you a second option and explain why it\u0027s cheaper and why it helps the second option is to grab the grab what\u0027s commonly known as the I scuzzy CRC or crc32 see there\u0027s "
  },
  {
    "startTime": "00:33:26",
    "text": "two good reasons to do this one is the polynomial is different so if you\u0027re running over Ethernet you get added cheque as opposed to running the same polynomial over roughly the same data and the second is that Acer processors are a certain well-known processor vendor and possibly others have instructions that directly compute this sucker so it\u0027s cheap so the argument was we have two men and I are suggesting another I\u0027m suggesting and not dropped I\u0027m suggesting a two-stage approach one toss the 16s now you down to one if somebody would like to go explain why crc32 is too expensive in software you could add crc32 C and require everybody to do both because that one\u0027s cheaper and software well I mean I would point out that crc32 is already implemented in the Selfridge and generally right so for implementation wise that is you\u0027d like to stop and step one I\u0027m not gonna I\u0027m not going to complain okay point taken if there\u0027s a preference then you know I\u0027m more than willing to go with one I think it\u0027s a it\u0027s a good concept to have it in general so gory fascist is TS VW culture why don\u0027t you just ask auntie s vwg because if you want to choose a CRC then I think you\u0027ll get some feedback wait which one Oh ask about your chosen CRC is it suitable on TS vwg okay yeah on the transport area will give you some fever a lot and different other prom skills okay that\u0027s a good point thank you thank you thank you very much don\u0027t go too far away Tom Tom Tom Tom you have two more okay hi I\u0027m Tom Herbert I\u0027ll get an update on I Elena so we have the ILA buff on Thursday this is a non working group forming boss the intent is to highlight problem statement use cases this is not intended to be an in-depth discussion in of solutions and we\u0027ve had quite a bit of discussion on the mailing list so since last IETF there was an ila mailing lists created a lot of the discussion gets down into security scalability mapping systems denial service threat and most recently there\u0027s discussion on an Iowa Lisp kind of control plane so the idea is to use list control plane for ila that\u0027s a pretty promising there\u0027s also been some discussions on DMM and the five gang an IP list those discussions tend to be more specific to the mobile use case it would point out that ila is kind of "
  },
  {
    "startTime": "00:36:27",
    "text": "trying to be a generic but mobile is one of the use cases data center virtualization network virtualization or some of the others we\u0027re also looking at the 3gpp steady item that they\u0027re looking at perhaps ila could be part of that solution so that I\u0027m getting a little bit of update on the data plane discussions so ila is explicitly not encapsulation and that means there are no bits at it to do transformations so we have no extensibility no way to encode everything in that sense it\u0027s kind of the the opposite of generic UDP encapsulation what that means is everything needs to fit into basically the destination address and the idea idea viola is that we transform addresses in order to get them to their destination and before the receiver actually gets the packet we always transform back to the original address so it\u0027s kind of like a paired address modification so because everything fits needs to fit into this small space we have relaxed a little bit on the canonical 64 64 split so for instance in il NP there was this idea of a 64 bit locator 64 bit identifier that\u0027s kind of some simple architectural e but when you start thinking about different encodings and different things you might want to do it\u0027s a little less flexible so we\u0027re relaxing on that and that gives us the ability to do some interesting techniques one of the techniques is locator indexing which you would use if we wanted to encode / 64 assignments into il a another one is chaining so instead of just doing one il a transfer transformation we may do multiple ones on the path this is kind of a poor man\u0027s segment routing where we can adjust the destination address have the packet visit certain destinations based on hop-by-hop routing and at the very end again the packet has to be transformed back into the original packet so that the receiver has no idea that this happened this does represent a bit of a trade off so in order to keep the data plane simple that implies a little more complexity in the control plane so that\u0027s kind of the the ILA trade-off the control plane pretty quickly gets to identify your locator split scalability type of issues and this has a lot to do with mapping systems an identifier locator split we do think there\u0027s gonna be mapping systems so imagine a large network everything is somehow virtualized or mobile we need a way to find out where where identifiers are identifiers are basically the logical nodes so for that we need a mapping system this is pretty I guess pretty accepted in the identifier locator space so the question right now is how to do this mapping system it\u0027s little little independent violate I "
  },
  {
    "startTime": "00:39:27",
    "text": "think there are some things that ila kind of implies in a mapping system but fundamentally the mapping system does have kind of four pillars the scalability security privacy and das ability aspects so I think a lot of that will come out in the ILA Boff maybe a little bit more detail but again the solution it\u0027s about the problem of statement right now and the use case is a little bit less on the solution so again that\u0027s Thursday 18:10 and discount thank you very much so that\u0027s a teaser for the buff that will take place and in the interest of time maybe we can move to the to the next presentation and leave discussion for that buff that\u0027s okay next tom okay one more so this is like kind of an out offshoot of some of those things we\u0027ve been looking at ila and this is particularly looking at the privacy and prefix assignment so I we have a few caveats up front just to make it clear so this is only considering privacy at the networking layer specifically in addressing privacy itself on the internet has to be considered every layer we know that this is considering one aspect of that this is also only considering risk from third parties interpreting or inferring information from IP addresses so that specifically means we\u0027re not considering network providers that have say for mapping of IP address device it\u0027s up to them to to secure that data and I\u0027m not sure we can do much technically to solve that problem and equivalent equivalently this doesn\u0027t address law enforcement or authorities who can compel say network providers to release that information so like I said those are caveats up front we understand that and privacy is a multi-pronged problem as we know so what about prefix assignment so / 64 addressing it to host is actually becoming quite common so slack for instance is doing that and it\u0027s actually pretty common in mobile networks you E\u0027s get full / 64 this actually recommended no RC 33 14 so that gives us some properties and since the prefix is being assigned to the device that means there\u0027s kind of a 1:1 relationship between a prefix and a device so given two addresses that share the same prefix even if the ID is different the interface identifier in this scenario they actually would refer to the same device and that becomes a little more problematic in the case that "
  },
  {
    "startTime": "00:42:27",
    "text": "we\u0027re assigning to say a Ewing in a mobile network like a smartphone then there because of much higher probability that that devices actually corresponds to a specific user so now we have a one to one relationship potentially between the prefix and then actual user and another issue prefix may contain fine grain hierarchy for routing and that\u0027s going to have to do become a problem if that reveals location of the device and hence the user so the privacy issue is kind of implied from that the prefix becomes an identifier for the device the addresses are used in the public internet so if a third party knows that a site is assigning prefixes then if it sees two addresses it can infer that they are the same device if they have the same prefix so this exposes the risks of revealing user identity and communicate Shen\u0027s and location location of users if location information is actually encoded in the prefix so this specific issue was actually raised in RFC forty nine forty one seventy seven to twenty one maybe some others and periodically changing the interface identifier in forty nine forty one actually is no help because the problem potential problem is in the prefix not in the interface identifier so we could extrapolate from our C 49-41 to just change the prefix periodically and conceptually that\u0027s possible we do know that changing addresses if there\u0027s only one and you change it periodically will probably kill all the existing flows and they have to be restarted so assuming we solve that problem then the real question becomes what is the correct frequency to change addresses in order to ensure privacy and it\u0027s a tricky question I did pose this on a couple of lists and there really isn\u0027t a very good answer because someone could say a day or a week or an hour and there\u0027s no way to quantify what kind of privacy you get out of that so the conclusion that I posted it was anything less than a different address per connection or per flow theoretically could have a privacy exploit and actually gave an example in the in the draft you can read it about a proposed exploit that I could take advantage of of that so any reuse of a prefix or address could be exploited to figure out identity so from that we can consider what what are we really shooting for and their privacy and addresses so I gave an example of a couple criteria and this is based on if I have two addresses and no other information what can I infer from these two addresses and it is obvious "
  },
  {
    "startTime": "00:45:28",
    "text": "that you can infer they\u0027re from the same provider same organization so they will share say a common network prefix that\u0027s kind of basic and maybe also that they belong to a very broad geographic grouping so would be expected that a large organization would probably want to have some Geographic or regional hierarchy but beyond that the idea is the viewer of these addresses should not be able to do this any other information specifically they can\u0027t tell that the notes that are associated with these addresses are not the same node or in the same rack or at the same location or have any other proximity so that\u0027s I think kind of a I don\u0027t think it\u0027s strict I think that\u0027s just some criteria for privacy addressing that will propose now I would point out that network address translation net can actually meet these criteria if there\u0027s a large enough address pull because basically what NAT does is it obvious gates the underlying addresses of the network and what you get on the wire on the Internet is the address of the net device and some port number and the port number refers to the specific instance but external users they don\u0027t see that so it turns out net actually meets these strong criteria as pointing on the document I do think this is one reason why some some law enforcement agencies are a little paranoid of that because it does such a in sense such a good job job of hiding identity so the document does present a possible solution and like I said this kind of wasn\u0027t sub problem of NAT or not at NAPA to vial a so with identifier locator split the idea is that we can use identifier locator split so the identifier becomes independent of location and we can assign multiple identifiers x\u0027 hence untrackable addresses to host the address is still share a common prefix but if this is done with enough randomization they would share nothing else so to address is assigned to a host the same host would have nothing in common except that prefix so that would meet the strong criterion and then add a privacy and a dressing so for maximum privacy then because of the the result that we need to use an address per flow means we have a lot of addresses potentially that\u0027s obviously a scaling problem so looking at some of the potential mitigations there one thing is not everyone necessarily needs his privacy so in some sense this could be a service if somebody really needed that level of privacy in one of the one time yes address this could be a way to "
  },
  {
    "startTime": "00:48:29",
    "text": "accomplish that maybe there are other communications or aren\u0027t necessarily that private they don\u0027t need that obviously that\u0027s not a great solution because now we\u0027re forcing the user to make a decision and we\u0027d rather give them perfect privacy all the time so another way to look at this problem is what we\u0027re actually trying to do we actually want to aggregate addresses as being as belonging to the same host so we can get the addresses to the right host and that\u0027s the problem that the mapping system has so there is aggregation here so the question we\u0027re pondering is can we do a sort of hidden aggregation where the network can assign a host a block of addresses and to the outside world this block looks completely randomized however the network either through some sort of public key encryption or some type of hash is able to deduce that these addresses actually aggregate to the same node in this case so this is the concept of hitting aggregation so the first level would be local network has a way to create these addresses assign them to the hosts and only the local network would understand this if that problem is solved then the question becomes how do I do a bulk aggregation because we still don\u0027t want to have to give hosts individual address theoretically they could require thousands or millions of these is there a way to give a host a way to create a block of addresses itself and whatever needs a new address it can create an address say we give it blocks of 64,000 IP addresses and it can use them as needed and when it runs out it can ask for new ones so those are kind of some of the things were we\u0027re looking at and again this is kind of along the lines of how identifiers locator may solve they solved that issue any questions hi Tim Chan I\u0027ve got more points than I should probably make here so to say a couple take the rest of this so I think the first one is I think this is useful having prefix privacy I think if you compare it to the privacy for hosts as it stands you\u0027re probably going to want to be able to have persistent prefixes and private prefixes so you need to be able to somehow delegate a prefix that\u0027s Marxist for use as a kind of a privacy review first I guess so so you we would we would do a block some sort of block delegation where it\u0027s not a prefix right it\u0027s actually a block for for privacy that way is that what you\u0027re referring to well if I was say for example in mine something has been allocated to my home network for example then maybe having a rotating prefix out "
  },
  {
    "startTime": "00:51:29",
    "text": "of the ISPs prefix that I can use to initiate new connections for movie good thing while I\u0027ve still got a persistent prefix that I can have my services on without running don\u0027t DNS or other things to update and essentially have to renumber my network every time you continue and privacy prefix I think would be important well I mean so I\u0027m not sure it\u0027s it\u0027s so much for numbering right it\u0027s more temporary address assignment I think is the best way to phrase it so the addresses could be requested on demand in some sense so obviously if you want a persistent prefix because you\u0027re a server then that that might be a different story yeah but otherwise it seems you were potentially going to assign me addresses that might be shared between multiple customers or something and that starts getting quite I had shares lots of problems that we have with cgn and so on today doesn\u0027t it I think as a user I think a lot of users are aware of privacy issues and that\u0027s why they use things VPNs like hidemyass or whatever other ones they fancy using tor whatever so I think this awareness I think what we\u0027re trying to do here is to provide some more subtle privacy that users may not ask for but I would like them on my own network to not affect things I\u0027m running as services in my network I share a problem with doing this big block and giving a host Zeeland addresses that it can use you are into all sorts the other things that have been discussed for things like nd cache exhaustion and so on there\u0027s all sorts of things that if you try and use an address per application they\u0027re going to hit you in in otherwise I mean there\u0027s a lot of legacy towards this right I think it\u0027s it\u0027s a really good topic well I think there\u0027s because I think just throwing a ila it is an answer but I think there\u0027s more pragmatic things that need to be considered first okay I\u0027m cutting the line now here we had someone in mute ago I don\u0027t know if they\u0027d still want to have his place but I think Lauren oh I think I think stating the goals like you stated them is is sudha misleading at the beginning you said it is entirely out of scope to think about anything that the ice P can do to attack privacy or anything that sends anyone that has the power to compel the ISP can do you declared that to be out of scope on slide one but it doesn\u0027t mean that just by making it out of scope you can there is a privacy trade-off there for example a scheme like the one where you assign let\u0027s say that the ISP assigns you want ipv6 address for every different connection right yes you can declare ISP sort of privacy to be out of scope but the fact of the matter is if we build the scheme then the ISP has to maintain a record of everything that you did whereas in the case where it has to "
  },
  {
    "startTime": "00:54:31",
    "text": "keep every base essentially every tea every TCP connection right whereas in the ski where the SP just assigned to your prefix that rotates they don\u0027t have to keep all that information about you so yes you could declare it out of scope but you\u0027re basically moving a slider around where you know different parties have different views of how much activity of what activity you conduct online and the solutions here are basically all on the other side of that slider because one side of its out of scope but I think that\u0027s not a full solution to the problem well so let me ask a question so NAT exists today right and that is not prefix assignment in the sense so externally what you get with NAT is something that apparently is randomized so as far as I know most ISPs are required to keep all NAT mappings correct you know I don\u0027t know that well but this the data is the same so nat effectively gives you a different source address per connection as far as the outside world is concerned so if they want to do an AB you know the down mappings at that time I think that\u0027s that\u0027s the argument that law enforcement is making but it\u0027s not clear to me why that or that argument is because it seemed like the nat logs are sufficient in which case if the net logs are sufficient then the logs of address assignment in this case should also be sufficient at least that\u0027s my understanding of the problem so it\u0027s not clear even I mean it sort of becomes free murky because it\u0027s not even clear whether the the party on the other end like the server actually keeps source ports right so well right but but the server is a different thing because the server can be anywhere on the Internet if you don\u0027t have the source port there\u0027s nothing that can be tracked right well no if I know if I know what I\u0027m looking at if I know then that translation then I can reverse engineer who was sending that if you\u0027re behind in that if you have the logs yeah nothing that keeps lux but so like I said I think it was not necessarily a specific suggestion about these points I think I think basically I think basically declaring that attack vector to be out of scope is an error because it means that we can like because it means that any solution that entirely gives the ISP with access TSP all this information basically we\u0027re completely disregarding that downside because the way we set the goals right but they already they already have all that information you know it\u0027s not true well the people they do they have that because they have the prefix to device information they hope they have that they don\u0027t have to track every connection if you don\u0027t have to track every connection here either what we said is you can you can assign addresses to device it they can use them however they want it\u0027s not necessarily for connection all right that\u0027s right not necessarily but like I said the one scheme that you proposed was different address for connection that requires 100% participation for the person rit\u0027s routing the packets to that address yes but that is that my point is on that "
  },
  {
    "startTime": "00:57:32",
    "text": "last slide where you propose several different arguments the only difference between those is the amount of information the ISP gets which on slide one you declare to be out of scope so I think that\u0027s kind of disingenuous that\u0027s right but look at this way if I saw assign an address now and they use it only for one connection then they only use it for one connection the ISP doesn\u0027t know what connection they use that for it\u0027s not it\u0027s not like NAT now you actually have more information because that is about the actual connection this is I mean it I know it\u0027s a subtle point this is just the address assignment that\u0027s what needs to is what needs to be tracked when the request doesn\u0027t say I want to create a connection to this destination give me an address but you the requester says give me an address but you would like I\u0027m said like I\u0027m saying it\u0027s I\u0027m talking about the goals not the proposals okay so you say their goal but we have to track do connection tracking is that the goal is that we have to provide privacy and we can\u0027t just just hand wave our hands and say whatever the I species is out of scope because one scheme that satisfies your goals entirely is that the ice P logs every five couple no no but but you\u0027re not part of this well that satisfies that too right so what we\u0027re trying not to do now okay we can take this one to the to a list maybe we go to the next one and the line then we have me to go and the last person hi i\u0027m kyla rose this might be a dumb comment but if we\u0027re giving do to the 16 IP addresses to every host could that actually lead to ISPs with millions of posts run out of IPs I know ipv4 his big but do the sixteen pretty big two as opposed to two to the 64 that they\u0027re getting today oh so are we talking about handing out like slash 96 or something won\u0027t block blocks of to box of 2 to the 16th 128-bit addresses sorry ok not Creek sorry that wasn\u0027t done before sensitive Thanks so next we go to me to go Dave hi there it\u0027s Dave O\u0027Reilly here I\u0027ll be speaking later but I just wanted to jump in with a couple of points about and I guess you could call it the law enforcement perspective on this I\u0027m not a law enforcement officer but I do work with them a lot and I understand their perspective and the perspective on a situation like this would be and that if there has been some criminal activity and that activity is associated with a particular IP address what the law enforcement officer is going to be interested in is who was controlling that IP address at a particular time at the moment almost everywhere in the world I can\u0027t obviously I can\u0027t speak for the entire planet but everywhere that I\u0027ve ever worked it has been a requirement a regulatory requirement on ISPs to be able to identify their customers and this touches on what I\u0027ll be talking about later but it seems to me that whether a whole block of 64 IP "
  },
  {
    "startTime": "01:00:32",
    "text": "addresses is allocated to a particular person to a particular host or whether the IP address has to keep connection logs there are two solutions to the ultimate problem which is that ISPs will be required under regulation to be able to identify their subscribers now so that was my first point whatever way it pounds.i that\u0027s gonna be the case the other point that I wanted to make was I am of the opinion I hope this is not too controversial comments that for a plethora of reasons connection logging is a terrible idea and the main reason I think is the risk of loss of that data is is huge to the privacy of the individuals concerned so ISPs have data breaches just like everybody else and if all my connection logs got out they can see everything that I was browsing at every moment and so on and so forth which is why and I I\u0027m resistant to that idea so as long as there is some alternative mechanism by which individuals like ISPs can meet the regulatory obligations to be able to identify to subscribers that\u0027s really the point that I wanted to make okay those are good points but again I point out that the this solution actually is not connection logging it\u0027s more budget address registration so it\u0027s effectively what we have today with a prefix to device but it might be a greater scale so it\u0027d be address to device but it wouldn\u0027t be going as far as NAT which is clearly connection logging so that that wouldn\u0027t occur and I\u0027m assuming that law enforcement has to have NAT logs today already so it\u0027s kind of like that that component at least in terms of scalability should already exist as far as I can tell so that doesn\u0027t require a connection logging you can\u0027t do that but you don\u0027t have to port block allocation so you\u0027re just you\u0027re just your tourist boards horse address okay you don\u0027t have to log all the connections just because you\u0027re running that okay great so that\u0027s less data you can but it\u0027s really like the logging requirements just thanks so let\u0027s person on the mic please I nicked OD UC Berkeley and I\u0027m coming a little bit new to this area I work mostly at the web level but and I\u0027m particularly curious about you\u0027re talking about the timing of rotation of rotating identifier z\u0027 and I feel like there\u0027s a particular concern about like that if we have too many AI identifiers that are getting rotated at different times we might lose the privacy benefit of rotating identifiers so I\u0027m curious about like whether whether the Klein has controller whether the clients like or having some guidance so that we\u0027re "
  },
  {
    "startTime": "01:03:32",
    "text": "rotating all they identify up and diet identifiers at the same time otherwise all the end servers can just line them up and actually sort of figure out every change identified okay so real quick so one I think the client should have the control plane gets addresses from the provider client should use them as it sees fit so I think that\u0027s pretty clear two please look at the draft because I give the example a potential exploit that could defeat any frequency except once per connect or once one per flow that example hasn\u0027t been refuted so it may be may be accurate so if you have any ideas on whether it could actually happen I I\u0027ve received this one thing I think is privacy is probably such a big problem that maybe HAP maybe the attackers haven\u0027t gone down to this level yet but I do think it\u0027s gonna be a problem at some point doing it oh thank you very much yep fine thanks a lot Ron helooo ron Bonica the chairs have asked me to shorten the presentation up a little bit so I\u0027m gonna skip over a couple slides this this craft used to be called ipv6 fragmentation considered fragile and as we were writing it realized most of our criticisms applied to ipv4 as much as ipv6 so we renamed it it\u0027s now IP fragmentation considered fragile what are we doing in this draft well we\u0027ve known for a long time fragmentation reduces the reliability of internet communication in this document we\u0027re going to talk about what fragmentation is a little bit and that we do it with document we\u0027ll skip over it in the presentation we\u0027ll talk about how fragmentation fragmentation reduces reliability and we\u0027ll put out some recommendations for protocol developers and network operators now keep in mind we\u0027re not talking about deprecating fragmentation that just can\u0027t be done what we\u0027re talking about is pointing out how it makes it how fragmentation makes communications fragile and strongly recommending that protocol developers wean themselves off a dependency on fragmentation so there\u0027s some terminology you need to know to play the game I\u0027ll assume that you all everybody in this room knows what an MTU the minimum link MTU and PMT you is I\u0027ll also assume everybody in the room knows how IP fragmentation works I\u0027m just gonna point out two things one is a small difference between how ipv4 fragmentation works and ipv6 fragmentation works an ipv4 you have this thing called the DF bit if it is "
  },
  {
    "startTime": "01:06:33",
    "text": "set a packet cannot be further fragmented downstream if it is clear a packet can be set for the fragment at downstream an ipv6 there is no DF bit a packet can never be further fragment at downstream it can only be fragmented at its source the next thing that fragmentation has in common between ipv4 and ipv6 is when you fragment a packet you divide it into pieces the upper layer header always appears in the first fragment it never appears in subsequent fragments this this observation about where the upper layer header is is what brings half of the fragility into the argument now in an environment where only the source can fragment a packet the source of a packet needs to do one of three things either restrict itself to sending packets that it knows will never be fragmented that\u0027s for ipv6 never sending a packet back bigger than 12 80 for ipv4 and never sending a packet bigger than some arbitrarily small size so that\u0027s one thing it can do another thing it can do is PMT UD path MTU discovery so it discovers the MTU of the path ahead of it and the third thing is packetization layer P MTU discovery and we\u0027ll talk about each of those for a second PM tud the source node makes an initial estimate of the PMT you to a destination that estimate may be too large it then starts sending packets to the destination if the packet is larger than the actual PM tud of the actual PM to you it will not be fordable it\u0027ll get dropped and a downstream writer router will send an ICMP packet too big message to the source the source having received that will update its estimate of the PM to you now this strategy PMT UD absolutely requires the network to be able to deliver ICMP PT P messages if it can\u0027t do that it\u0027s black hole time the next alternative is PL PMT UD here we push the problem up to the packetization layer the packetization layer will say TCP in-band sends packets of different sizes to its TCP peer what it\u0027s doing is probing to find the PMT you it relies on two things primarily it relies on acknowledgments of its probes at the TCP layer it can also rely on ICMP feedback but then again it\u0027s perfect in PLM PLP MTU D the endpoint is perfectly able to ignore the ICMP messages it doesn\u0027t need "
  },
  {
    "startTime": "01:09:34",
    "text": "them at all PLP MTU D is defined for TCP in RFC 48:21 it\u0027s being defined for some other protocols and draft Fairhurst going on in the TSV working group sadly it\u0027s not defined for UDP and it can\u0027t be because PLP MTU D kind of assumes a long live session well a session not a one in dumb packet the other thing about PLP MTU D it doesn\u0027t rely on ICMP ptb messages at all if they\u0027re all dropped PLP MTU D still works just fine so we\u0027ve talked about the status quo now it\u0027s time to leap in and talk about why is it that fragmentation makes communications unstable or fragile well one problem well these problems all link back to the problem that the frag only the first fragment has the transport layer header in it what are the impacts of that well let\u0027s say for a minute you\u0027re a load balancer and you\u0027re a load balancer that load balance is on TCP ports if the TCP port is only in the first fragment you\u0027re bound to suboptimal load balancing next issue is firewalls let\u0027s say you\u0027re a firewall and you have a rule that says block all packets based on the TCP destination port well you can configure that firewall two ways one way is to accept all subsequent fragments that\u0027s a little bit too liberal another way is to drop all subsequent fragments that one\u0027s a little too restrictive there\u0027s no healthy middle ground other middleboxes can have the same kinds of problem because they need access to the TCP header or the transport layer header for instance let\u0027s say you\u0027re a middle box that\u0027s remarking the dscp based on the TCP port number it\u0027s fine for the first fragment what do you do for fragments to through in there are some other well-known problems with fragmentation that don\u0027t have to do with the TC with the transport layer header not being in subsequent fragments there are bunches of security vulnerabilities that have been documented over the over the years overlapping fragment attacks like the ROS attack resource exhaustion attacks and many more we won\u0027t go into them now they\u0027re in the draft but there\u0027s an interesting problem around TCP loss around ICMP loss PM tu PM tu d fails when you are losing ICMP packets ICMP packets can be lost for bunches of reasons one is because network operators are filtering them they shouldn\u0027t there\u0027s an RFC that said that says they shouldn\u0027t another is you know just play "
  },
  {
    "startTime": "01:12:34",
    "text": "don\u0027t packet loss or rate limiting those things happen but they\u0027re not insurmountable problems there is at least one insurmountable problem and it has to do with any caste I\u0027ll give you this example from Jeff Houston\u0027s work let\u0027s say for a minute that a DNS client sends a DNS request to an anycast address it\u0027s a common thing to have happen that it arrives at a DNS server the DNS server sends back a very large response it\u0027s running DNS X so the response is going to be big that people are laughing that response gets to a point where it cannot be forwarded because of an MTU problem so the node that could not forward the DNS response sends an ICMP message back to the of the packet the source of the packet is in anycast address and it goes to some DNS server that has that anycast address unfortunately not the one that sent the packet that\u0027s problematic it\u0027s black hole time another problem is network operators tend to filter fragmented packets there are two studies one by Fernando gods and other by Jeff Houston that that demonstrate this we don\u0027t quite quite know why they do it we just know that they do so okay we have some solutions at the transport layer we\u0027ve talked about them already we\u0027ll go quickly let\u0027s get to the recommendations so I can yield the floor we have some recommendations to application developers that they should not develop applications that rely on a PI P fragmentation and what\u0027s more if there were any that accrue shal to the Internet infrastructure they should be rethinking those applications so they will rely less on IP fragmentation the next is for network operators they must not filter ICMP Petey B\u0027s that\u0027s already in another RFC so it\u0027s not crucial but the big one is for DNS and especially when DNS is using DNS SEC they should be finding ways to not rely on IP fragmentation and anyhow they ask next steps is to adopt this as a working group document okay so can I have a raise of hands how many people have read this draft okay to be starting so as you know we\u0027re running out of time so maybe I\u0027ll take one question and then we keep moving we\u0027ll take it to the list I think before adopting as working group but that\u0027s a good show of interest in it David black I mean--the another transfer area and I\u0027m here to help you Ron I\u0027m going to say a dirty word tunnels please make sure that what you do here is lined "
  },
  {
    "startTime": "01:15:35",
    "text": "up with the int area tunnels draft we\u0027re fragmentation is used to solve some nasty problems with tunnels it we really ought to have a consistent story across the two of them thank you okay thanks a lot so Vlad hi so I\u0027m gonna give you a quick update on our work on Sox version six I\u0027ll start by giving you a brief overview of where we\u0027re at so we\u0027ve trimmed down the are cheating the overhead in terms of our GT down to 0 if 0 RTT authentication is used for in order to protect against malicious l parties we\u0027ve taken a step back and rather than having sox provide an encryption we\u0027ve decided to run run it over TLS and then handle whatever issues TLS has notably TLS TLS only data is prone to replay attacks and we have a mechanism that mitigates such attacks now that we\u0027re running we\u0027re also running stocks over TLS plaintext password authentication is actually viable and finally we have added a new we\u0027ve leveraged stocks options to add a new set saw copped and get saw cup-like mechanism and we\u0027ve used it to implement some stuff related to MPT CP more on that later so stocks version 5 starts by negotiating the method of authentication then it does within the authentication and the client requests that the server the proxy establish some connection to the server and then finally application data can pass through Sox version 6 in contrast sends as much data out front as possible so we cram in the authentication method negotiation negotiation and the address of the server and also some application data we cram it all into the first message sent over to the proxy and of course if 0tt authentication is used the server sends off and can send an operation apply as soon as it touches the connection to the through the remote server speaking of 0rt authentication this is this is how how a password authentication is done in a zero RTD manner so draft so I see 19:29 describes how password authentication is performed for Sox basically we can just take the the the initial message sent by the client which contains the username and password and place it inside a Sox authentication data option now of course "
  },
  {
    "startTime": "01:18:37",
    "text": "there\u0027s a small caveat to that if the username or and/or password I are exceptionally long it simply won\u0027t fit in that option and you have to do it the old-fashioned way which takes up one extra RTT however this is unlikely next up we\u0027ve got socket options there\u0027s been some discussion on the mailing lists notably David he brought up the point that sockets are actually an OS construct and connections are necessarily TCP connections are necessarily done using sockets so we\u0027re going to rename these options in the next version of the draft clients can use these options can include these options in the in the Sox requests in order to request certain behavior from the proxy and proxies can include them in operation reply to advertise their behaviors the fields I want to draw your attention to are like level code and data so the leg baker basically indicates what what leg behavior reply refers to it can either be a client proxy like the proxy server leg or both legs then the next three the next three fields were actually inspired by sets or captain gets a cop we\u0027ve got left operation code and data for possible levels are a genetic socket level then we\u0027ve got levels for eye for the track left three protocols namely ipv4 and ipv6 and two more levels for TCP and UDP we\u0027ve used the socket options to handle GFO so that previously was a field in the request which indicated whether or not the proxy should attempt to use the fo now we\u0027ve removed that field and when a client wants the proxy to use the fo it simply includes this option as part of its request the absence of such an option means that the server must not use must not attempt to use the fo next up we\u0027ve also used these options to implement a use case called proxy bypass so let\u0027s say that a mobile phone once has both a Wi-Fi and the 4G interface and it wants to take advantage of both interfaces now most as you probably know MPT CP deployment is lagging behind on the server side so if you if let\u0027s say a mobile phone wants to take advantage of both of its interfaces it probably has to go through a proxy now some servers "
  },
  {
    "startTime": "01:21:37",
    "text": "my template might start start deploying MP TCP now in case in case on a server does support MP TCP the proxy can place an MP TCP option in its operation reply signaling to the client that the upstream server does indeed support MP TCP then the client can forego the use of the proxy and talk to the server directly in further connection attempts and finally we can use these options which to change the MP TCP scheduler used by the proxy so clients can can place such a request to indicate what\u0027s what\u0027s what packet scheduler they want we currently support the packets Jewellers available in the the lyrics NP tcp implementation and proxies can include them as part of operation replies to tell clients what schedulers they are using we found one possible use case for this option namely low latency services so if a client wishes to have low latency it can tell the server it can get tell the proxy to duplicate data across all MP TCP sub flows such that the delay is always minimal and with that I\u0027ll be happy to take questions thanks can I have a raise of hands who has read the the latest version of this draft ok who has read any version of this draft ok so we definitely encourage people to comment on this latest version if you if you can please take a look and send comments to blood thank you very much we\u0027re ranking short of time so we\u0027re gonna move being be moving on now Thanks so next is Dave remote yeah yes hi okay so hello everybody and thanks for the opportunity to present this I\u0027ll be as close to five minutes as I possibly can so now next slide please yep so I\u0027d like to begin by describing what the currently published best practice is which is RFC 6002 on logging recommendations for internet facing servers okay so what that document recommends is that as well as logging incoming IP addresses servers also log incoming source port numbers and time stamps and transport protocol as well but why and the answer is because of "
  },
  {
    "startTime": "01:24:40",
    "text": "large scale address sharing technologies such as carrier grade math in the presence of these technologies this additional information is required in order to attribute the activity of an IP address two to two at the very least to an ISP but ideally down to an individual from a crime investigation point of view so in the presence of large scale Nats IP address is not enough you need this extra information as well that\u0027s not to say that if you did have all this information you would successfully be able to identify an individual from this it\u0027s just the information that is required to address the problem that is presented by carrier grade nat and and related technologies like ipv4 to ipv6 mapping technologies very similar problem next slide please can so I did a little bit of research and what I found was that while stars recommendation stats that\u0027s fine they are what they are but they\u0027re not enough and here are some of the issues that I that I identified so somebody who was considering implementing those recommendations might find that their server software might not support logging of source ports and that would prevent them from being able to achieve the recommendations another thing that has that I have seen is that certain server software the only way that you can enable logging of source port is by enabling a ridiculously verbose level of logging like debug logging or something like that which you\u0027re never going to do on a production server so whilst it may be it may be technically possible it\u0027s infeasible to implement source port logging now practically no server software enables it by default and indeed no server software that I could find a bar one even has a default configuration sample that includes logging of source port so so somebody trying to do this is battling or pill there\u0027s there\u0027s not even default for them to enable now the next point that I wanted to to raise with the existing recommendations is the existing recommendations recommend that you log against some sort of traceable time source or some sort of central time source like an NTP server or something like that but there\u0027s a whole plethora of deployment scenarios where that\u0027s not possible and nor is it actually necessary for the requirement of the of the recommend of "
  },
  {
    "startTime": "01:27:41",
    "text": "the BCP of the the best practice which is to be able to identify enough information to be able to ask an ISP who was using this IP address at that time because I\u0027ll take a moment to explain why you don\u0027t need to exact timestamp it\u0027s pretty well-known in in the forensics world it\u0027s one that one of the first things you learn as a forensic examiner that you don\u0027t need to know the exact time which something happened at all you need to know is what time the time that was recorded and as long as the time is recorded consistent you can offset the time then to be the real time so if you--if you are analyzing a computer for example and it\u0027s time is set one year wrong you can look at the older times on those computer compared them to real times and then offset all the time so you you know as long as time is recorded consistently it doesn\u0027t need to be retorted recorded against a reference time so I take exception with that point in in the recommendations in the current recommendations and then the last point that I wanted to UM to raise for for whatever it\u0027s worth which is logging information doesn\u0027t exist in a vacuum people log information for a reason and oftentimes people have all sorts of scripts and tooling and so on that\u0027s built based on their logs and by changing log formats you break existing tooling so that data point for discussion it\u0027s another challenge to the implementation of the recommendations next slide please good okay so I\u0027ve only five minutes so I just wanted to summarize and say but the absence of primarily source port information in logs is a big problem from a crime attribution and a public safety point of view and this was a point that was made by Europol in 2014 and repeated again in 2016 in their crime I forget what the document is called some sort of crime problems on the internet and and as I mentioned earlier it doesn\u0027t logging of source port wouldn\u0027t make a crime attribution problem go away what it does address the problem of these address sharing technologies to a certain extent not in all scenarios but to a certain it certainly would improve things and I I\u0027m suggesting that the current best practice needs revision to address more of the practical issues with with locking source port it\u0027s not just say source ports should be logged but also to make some you know a more encompassing set of recommendations that can actually maybe help make it happen and then last slide please and in order to move the discussion along I\u0027m being completely new to engaging with the IETF I rolled up a document and I "
  },
  {
    "startTime": "01:30:41",
    "text": "published it which is now in its second draft and the link is there for anyone who wants to to read it or comment or my contact details are there and everything so and so that was everything that I wanted to say thank you very much Thanks so where the time limit but if people were willing to to ask questions and stay a couple of minutes longer I\u0027m going to let the mic open Christian it\u0027s just a verbal question it\u0027s a question of classification you you are are you asking for this log in the just the network that implements the nuts or do you have also the same requirement from cells that implement the information processing yeah that\u0027s a fantastic question and the answer is it\u0027s the server\u0027s who are logging and not the nut and the nut itself as I mentioned in my intervention in on Tom\u0027s talk most people who are running and that are have a regulatory obligation to be able to identify if if a law enforcement agency comes to them and goes who was using a particular IP address at a particular time they have to be able to tell them the problem is in cases of carrier-grade NAT if the law enforcement officer doesn\u0027t also have the time and the source port they can\u0027t even ask the ISP the ISP will say a million people were using that IP address at that time or you know some large number of people and without the source port on the time stamp we can\u0027t tell you so there\u0027s an information gap between the information that\u0027s being protect aend in that cenar in psalm carrier-grade NAT scenarios versus the information that is being retained at let\u0027s say for example a victim so for example if you were a website and your website got hacked and you would like the person who hacked that website to be caught if you don\u0027t have the source port on the time stamp you don\u0027t stand a chance the IP address is not enough thanks for thanks education okay thanks but back there I am I launched around I\u0027m one of the authors of oxy 6302 and I take your point on the time stamp maybe the recommendation we made at the time was too restrictive we\u0027ll be very happy to work with you to update the documents now about the other recommendation that you seems to be calling for it was not clear to me how they could be expressed in terms of things we could put inside of a updated version of a document that maybe we can have an offline conversation about that would be happy to work with you to update the document okay and if I can just very briefly respond I think what needs to be done in that respect is to broaden perhaps the scope of the documents to include not only server recommendations for somebody who\u0027s logging a server but recommendations for "
  },
  {
    "startTime": "01:33:41",
    "text": "people also who are implementing server software and people who are and you know and so that could include something like for instance server software should be able to log source port and she would be able to do it in a way that doesn\u0027t impact the performance of the server things like that when we wrote the document we were expecting that people were operating the software will go talk to their vendors to do it but apparently this has not happened or recommendation was not strong in us and maybe we can reward this yes yeah and further there are also scenarios for people who are writing in-house software and we\u0027re trying to comply with best practice might be interested in implementing the recommendations themselves not only vendors but also you know end-users are who are writing their own software microburbs so I\u0027ve been successful in in using carrier-grade NAT port block allocation so that one ipv4 address is shared by 16 people and I just say okay you want to know where that IPR is at that point of time it\u0027s one of these 16 it\u0027s not millions it\u0027s 16 and I mean police will immediately rule out most of them and I\u0027ll say it\u0027s one of these three and then then they have something go on it have to be millions if you do the carrier great not right just spraying the connections of millions of users randomly across huge bases of ectopy for others it just doesn\u0027t work does anyone actually do that it\u0027s never done the in one IP address well none obviously not millions millions I\u0027m being slightly facetious but and I am aware that in I think it\u0027s in Belgium they have a regulatory obligation to be only allowed to have 16 people right using one IP address at a particular time and but that\u0027s not the case everywhere and um and yes I am aware of the situation in Belgium and that there are and that has as how did I guess a positive side effect of they are now using ipv6 an awful lot more than carrier-grade NAT but and ipv6 also then comes with its own separate kind of worms but that\u0027s another description and I\u0027m coming through so yeah okay sorry thanks so like responsible lady here so like I wanna like not focus on the content of the graph at this point okay so like the idea of presenting this here is to figure out if there\u0027s interest in updating 6302 like you know Alan maybe there\u0027s like stuff to be done and I want the working group to own that work so that\u0027s the first step we wanna figure out like sit down and like you know ask the working group at some point like on the mailing list or if you wanna go hump here that\u0027s fine but we are probably running out of time you\u0027re asking the mailing list like do we won\u0027t have this date like 6302 to make it like more practical so whatever changes then need to get done so that\u0027s really what I wanted to get out of this saying like there\u0027s some feedback saying the recommendations we made are not practical okay so the question is we need to "
  },
  {
    "startTime": "01:36:41",
    "text": "maintain our work so that\u0027s really the reason I got like Dave to come and present here okay I think thanks in final lyric everything this time a peach is considered of Belgium it\u0027s not a regulation in Belgium at all this is a voluntary code of conduct by eyes yeah and other parties that\u0027s okay I didn\u0027t realize I didn\u0027t know what the what the basis was but I was aware it was done in volume yeah thanks okay so thanks everyone for staying a few minutes longer thanks date for the presentation thank you I mean we\u0027re done do you have some more blue sheets somewhere there that you can pass by please I\u0027m sure what they actually say "
  }
]