[
  {
    "startTime": "00:00:39",
    "text": "all right it is time to start our second session of net Maude Lu Berger I can\u0027t watch them and Joel I think will be joining us on he\u0027s there yet our last session was a little bit rushed and because of it being a joint session with net confer following with net cough we did run out of time to really finish the discussion the visit we mentioned in that session that the design team the versioning design team has a session set up for has a session set up for tomorrow and Rob Wilton just came over and said that they\u0027ll be they\u0027ll be sending out the information to the list so if you\u0027re interested in participating in follow-on discussions please feel free to go there it\u0027s not a formal working group meeting but it is with the members of the design team that are here there should be good discussions and the action from that will be to send any updates send any conclusions from there to the list for for follow-on discussion so if you\u0027re interested please come whoops so for some reason it feels like we\u0027re late in the week but we\u0027re really not we\u0027re still Monday so some may not have seen the note well yeah this is the standard reminder that what you say here is considered an IETF contribution and that it\u0027s governed by our rules and if you\u0027re interested either go to that link at the bottom of the page or please CBCP 79 but basically anything that you say here becomes part of our public record as usual we have audio video streaming and recording if you when you come to the mic please make sure you state your name and if you would like to help out with our interactive minute taking note-taking please feel free to jump on to etherpad and contribute there we are in our second session you\u0027ve found your way here so you don\u0027t really need this information one thing that we wanted to point out is Friday is canceled so this is our last session here there are no agenda changes so this is the agenda that was published so we have two RFC\u0027s that have been published as the last meeting the first one I think is worth noting because that was in the working group a long time so having that published is a really nice accomplishment and we appreciate all "
  },
  {
    "startTime": "00:03:40",
    "text": "those who contributed to it and scheme amount was another one that took a little while to get done and took a lot of hard work and we appreciate that being everyone who could treated get us there so thank you we have to okay so there were stickers or something I was supposed to give out right I have to go see if I find I have those old ipv6 stickers we have two that have been submitted for publication one on the queue one is waiting for write-up I see our ad nodding his head so he knows it\u0027s there and I assumed that will be coming soon so we have a number of working group documents on the agenda we\u0027re going to talk about those more in a moment not on the agenda are that these two documents are listed basically a few weeks ago the authors said they think it\u0027s ready for last call at the last meeting we talked about it being close we felt it was a little too close to come to try to do the last call right before the IETF so we\u0027re planning to start this next week last call on these two documents there is one other document that\u0027s not on the agenda and we received an update from Jan I don\u0027t does any one of the authors want to come up and talk to the slide or so wait till have a chance to do an update before this ITF and we have a cup of opening issues and I will discuss with the people who send their comments during this ATF and we\u0027ll post an update right after that meeting great thank you thank you I think that\u0027s our intro and before we go to the lodge we wanted to have Robert speak for a moment on a change that\u0027s happened inside the general IETF and specifically related to yang catalog so Robert is the project manager for the IETF for Yan catalog so you just give us update what\u0027s happening there so hopefully everyone is familiar with yang catalog set of tools it\u0027s gathering yang modules from min EST o--\u0027s and implementation communities and tools to develop new yang modules the operation of yang catalog org is moving to the IETF Secretariat we have a project underway that is moving the the machine to a Secretariat managed machine and adding a few features such as bringing in the yang validator dot-com "
  },
  {
    "startTime": "00:06:42",
    "text": "functionality and continuing to work on the enhancements and bugs that the community identifies if you go to Yen catalog org there\u0027s a list of the various github projects that make up the whole project and you can see the issues that that are that are being worked there so thank you thank you very much if anyone has any questions they can find Robert at a break or Benoit who\u0027s really instrumental in bringing this thing all about and can also provide information all right thank you very much appreciate you coming by [Music] I\u0027m Bob Sonya from erikson speaking about your instance data format this has been an ongoing draft for some time and we had some new changes so the concept is well are the same we need yang defined data sometimes offline not just from rest confronted core but in the file format or some other form other format so these are some of the use cases not all of them that we need the support for is documenting server capabilities would be if you remember from that Condor yang push notification capabilities that wants to use this already and I\u0027m trying to define a standard file format this draft is only about the file format not the the use case are only mentioned as the reason why we do this and the file format really means defining a metadata for the instance data set naming it giving it revision date or something like that description and then defining the XML and JSON encoding for it so what changed but we have actually to revision changes for the draft first of all we have the concept of tARGIT yang modules so these are the yang modules for which we are defining the yang data and there are three methods now to define which modules we define the data for it\u0027s not just the modules actually it\u0027s the modules which Reverend date of that module which supported features and which deviations because all can affect whether the instance data is usable or not one method would be to put it in line which means that it\u0027s in the same XML or JSON data structure as the data itself contained in the same file "
  },
  {
    "startTime": "00:09:44",
    "text": "another is if you think about the use case where you know providing diagnostic information every five minutes in the file you don\u0027t want to repeat it and repeat it and repeat it the what are the tortured modules then you just use a URI that points out another file which will contain this information and it is repetitive files you only have to have the URI and in some cases you just can say it\u0027s externally defined whatever is the context some someone some method you know what files you are using or what yang models you are using this was redefined to yank choice so it\u0027s easy to add new methods if we want for example package based method if we accept Roberts proposal about yung packages previously I used I proposed the dedicated file extension this ye the yang instance data but as we really have JSON data or XML data so this wide extension was removed from the proposal another big comment was that earlier the draft referred to the the real date of the content data we are delivering is the same thing as we would have as a response for a get or again get operation or get and some people objected that we should not use that we should reference the various RFC\u0027s that and and sometimes drafts that define what kind of data we get back so now with a reference to the yang RFC to the rest conf RFC to metadata RFC hopefully these ones also connected to the same where work it was raised that there might be additional data connected to the yang library that would be useful for identifying the target target modules for example if we ever introduced December version or sample other version number that will help also identifying the target modules so the target pointer which is actually a bit of a data structure we inside the choice allows you to add yes this is the base fire that will tell you the module names revision etc but I also support an augmenting module that would add some semantic versioning or something other useful probably it will not be used for some time so it\u0027s it\u0027s a possibility not a necessary complication then I got one comment that it\u0027s not Oh IETF yang library serves our purpose that it defines module name revision of features and deviations but maybe I would like to use some other yang module to define the same data so now it\u0027s possible to use "
  },
  {
    "startTime": "00:12:45",
    "text": "some other yang module for that also earlier the part that defined the target yang modules was mixed up in the content data with the real data that I want to provide I was commented that\u0027s not a clean solution so it was moved out into separate JSON a separate XML part and one last thing that backwards-compatibility was mentioned with all this speak about yank versioning is yank versioning cataleptic able to instance data files it is not defined and it is it would be extremely hard or impossible to define what backwards compatibility means for them for instance data sets because instance data sets allow you to have partial data set so you don\u0027t if you remove something yeah it might still be okay so that\u0027s for that reason semantic versioning for example doesn\u0027t apply to it there there are a few considerations about backwards compatibility so if you documenting some list data you should not change the key value if there\u0027s meaning is still the same or you should not reuse a key value for something that yet has has not changed and this is just an example how this looks like so we have still have the instance data set name for it some other additional metadata which is not not everything is listed here and then we have this inline target spec which says that dot yang modules are defined inside the same data set inside the same file and then we have the target module separated out from the content data to tell you that this instance data set contains data above about ITF net of ACM provision date which is not mandatory anymore in some cases it\u0027s better to at a timestamp if let\u0027s say it\u0027s a file that\u0027s produced every 5 minutes on the other hand if this is instance data file is something that\u0027s produced by human design activity then the revision date is still or the data is still the good thing to use and then this would be the content part just couldn\u0027t fit it on the same page so this is for access control common example that provides some default access control rules and way forward we have seen a lot of comments to the previous versions for this one I have not really seen much I actually I think I managed to include all the because yeah thank you for your good comments they were good and I would like to ask when can we go to the last call with this hey first off are there any "
  },
  {
    "startTime": "00:15:48",
    "text": "comments before we your machine builder I\u0027m it\u0027s a terminology issue so when you say a target pointer for me it\u0027s really a schema pointer and your target modules already schema modules so they find it confusing that you use a slightly different terminology uh-huh you raise that question that the word dodge it might not be the best for this think that modules for which we are defining data I would really appreciate if someone could come up with a better word for it I don\u0027t want the full sentence there but you but I agree with you that it\u0027s I will say it\u0027s not bad but this is not the best robots in Cisco I agree you\u0027re gonna actually I think that scheme is a better definition for that and one other comment I think I look to the latest version in the in-line schema definition I think you\u0027re still hard-coded to you yang library as the base is that right no maybe I maybe I might check the latest version okay I personally I think it would be acceptable about this some people have wanted it now it\u0027s not mandatory to use the yang library what is mandatory that the first module that you use in these tARGIT yang modules must be able to specify name revision features and deviations because these four are clearly needed okay so first Kent as a contributor I did some email this morning review comments on this draft which we could take potentially as last call comments if it were to be taken into last call but I do think it needs some work still naming you know as part of it and also perhaps some structure like related issues all right sorry I haven\u0027t seen them in any other comments could I get a sense for the room how many people have read this draft raise your hand please this version of the draft yes so it\u0027s a few oh good if we had a little more opportunity a little more comments on the list so please take a look at it and see if you if you like the version let us know if you have comments on it send it and after we see some more review comments we can gauge where we are on last call so it\u0027s really important to to comment on this version because that will help guide us towards whether you think you know whether we move towards last call but I right now I know it seems like we have enough feedback on the latest version was published before the IETF are not that much before the IETF so people were probably busy with other drafts exactly "
  },
  {
    "startTime": "00:19:16",
    "text": "Kent we\u0027re actually jumping okay you\u0027re actually jumping over someone Oh am i it is it is data structure you\u0027re yeah you\u0027re right Martin I guess I shouldn\u0027t listen to my co-chair sometimes okay Marty Marilyn presenting the data extension draft it actually in the last IETF or go to the next slide the last ITF I think it was decided to an analyst to move to a new keyword not young beta but instead structure so the module is now called ITF young structure extensions and the statements are structure and augment structure so those are the two extensions that we define and here\u0027s just a simple example of of a structure that could could be defined one from the subscription draft another change that we did was that a structure is now encoded like in any data or like a container so the name of the structure is going to be the top-level element in XML or the top-level object name in JSON and then everything within the structures just encoded as usual within that element so we believe that this draft is more or less ready for working with plastic all we did recognize that we need an example of so one thing with the structure is that it can be used if I go back to this previous slide a structure we find something that that is not you know part of any data store anything and it doesn\u0027t say where it\u0027s where it\u0027s used we can be used as a top-level thing in an SS document or a protocol data unit or as in this example it can be used in lining something else like in that conf error info you can you can you could put anything in there for example you could put a structure in there so we need to add an example of that probably the example we just saw so we want to do that and then we believe that the draft is ready for working class call but now we\u0027re also working on this yang next thing so a bigger question is should we continue with this as extensions or should we try to fold it into the yang one or two or yang next work instead yes that\u0027s a question for the working group so given the past sort of cycle "
  },
  {
    "startTime": "00:22:21",
    "text": "time for yang revision and where we are now we\u0027re probably talking you know two years from now and before before we would have that 1.2 if we\u0027re lucky 18 months and I think that\u0027s really aggressive so the question is is do you want to wait that long for this or make it an extension and gain experience with it that then can be incorporated into 1.2 and so I think it\u0027d be useful to hear from the authors on it and then from the working group on that yeah so this I mean this is it\u0027s based on the experience of young data that we already have so this is like the second iteration of this so the question is should with at most or third iteration directly but maybe it\u0027s I mean yeah it might be okay I mean this is the documents on is almost ready we can publish it okay so you\u0027re just to be clear you\u0027re saying there\u0027s no reason to wait let\u0027s go forward with it and you can gain more experience it looks like we have a few well I I think Kent was in line as well no I think it\u0027s more of a chair comment is braid the dependency for this document I think zero touch document is no longer having dependency on this it moved ahead with the rest cough yang data approach I think the only current remaining dependency is for the gang push messages instance they died okay so that one would be so there\u0027s a reason why we want to yes okay yes as a dependency that will try resolves just that\u0027s right alright if you wait for young wonder - I\u0027ll probably try to avoid the total together in instance data so I would like to have it\u0027s not an old guy I have one question so now that we have this top level element part of the data does it also mean that it introduces a schema note no it\u0027s just a matter of encoding okay so it means that you still mean the augment structures so we still have any structure so I mean if we were to do this in proper yang we would probably skip the Oldman structure and just say that it\u0027s a scheme on out and use normal augment you know that because this is what\u0027s done for our pcs that that arsenal is actually physically right so I would be really in favor of doing this and - the question regarding the instance data so would it be a real problem if my lashes draft doesn\u0027t use this at all because I think that it\u0027s just a separate egg module so there\u0027s no no interaction with other and defined stuff so I think and anyway somebody can also set up and that conserver "
  },
  {
    "startTime": "00:25:23",
    "text": "keeping this kind of data like yang catalogued us something similar so I I really don\u0027t see any reason for using this extension in that particular document it\u0027s something else for the error information for example but not in that case I think it could simply not use it in those cases and Milosh could just push it I have some problem with the first sentence in the introduction that we need a standard mechanism for defining I think we do have this mechanism is it\u0027s called yang and and as long as it\u0027s usable I would suggest you just yang without this if I may suggest maybe some more some more reasoning would be useful in the introduction to to really see the motivation because I in cases like the instant theta draft I don\u0027t see it I don\u0027t see any any benefit of using this except of a number of complication complications and delay for the other draft so I can\u0027t ensure so I do believe blush this draft could use the restaurant yang data just like a zero disrupted but it would not be possible for the notification messages draft because that one needs the augment facility right and also potentially blush draft would not he stressed itself but other ones might want to augment you know instance data format I didn\u0027t mean to use the rest comes mechanism just to avoid oh my god I want an encapsulation I think we Joe Clark Cisco I was just gonna say a lotta brought up Yan catalog that would be a use for instance data and we would want to augment the metadata that\u0027s found in instance data to add some of the specifics that we use in yang catalog so you also suggest that we do not wait is that what you that\u0027s what I\u0027m suggesting you I have gotten the same comments from others that they want to augment it want to be able to augment my instance data metadata Eric void Cisco and just for the record if we were to adopt this we would certainly bring it up at the neck hump messages draft for gang push so this isn\u0027t our useful thing for us to be just to be clear Eric we\u0027re not it\u0027s already adopted it\u0027s the question of whether we continue with it and really last call it yes and I\u0027m "
  },
  {
    "startTime": "00:28:23",
    "text": "saying yes for that Oh Kent as a contributor and I mentioned this before privately as author the excess right now is underscore ext and I\u0027m just wondering if it\u0027s important to maintain that the structure writes there\u0027s structure underscore or - txt and I mean I guess the only way I can see why we might want to have a convention for extensions always having you know in the module name - extension or ext but it also is a little bit strange I don\u0027t think there would ever be another module that would be needing the name ITF structure so would it make sense to simplify the name is the question think about it when we don\u0027t 1.2 it becomes a part of it do you still want to use this ext well it\u0027s part of the module right so so the module will go away if we did one or two so it\u0027s just a sense matter what what we\u0027ll call the module not the statement itself yeah personally I don\u0027t think it\u0027ll be a big deal either way right I mean if we see different types of modules modules we\u0027ll just types should they be call something special like - TC would inform its I mean multiple just extensions should it be have a saying no I don\u0027t know it\u0027s yeah something but work something to debate Rob Wilson Cisco so two comments one is think about how this is used in the instance data document I\u0027m still not convinced why in issues yank data at all why I can\u0027t just be defined as a regular young module so that\u0027s what well not to say yeah that\u0027s really a different document well it\u0027s a comment on the usage of this so yeah that we shouldn\u0027t do this at all if we if we were to believe that you know if you use plain yang to to mean almost anything I mean so currently if you define something in yang you define schema notes for a datastore conflict or coffee falls that\u0027s what it is and now we we would change that definition so by looking at you a young module with normal definitions you don\u0027t really know what it\u0027s supposed to be used for right maybe today so I think that Andy I don\u0027t know if Andy\u0027s here but you might have some some comments on this I think he\u0027s experience was that they try this and that didn\u0027t really work because the other way of solving that problem is just to annotate the yang much of the top-level Samms used to say just use the same Santa yang structure but you have an annotation with you don\u0027t need to understand annotations so that means that someone that just yes this module ignores the the thing and things that it\u0027s supposed to be implemented on a server that\u0027s fine that\u0027s okay do they want to implement it they if they\u0027re importing what they don\u0027t understand then that\u0027s their own problem I don\u0027t think that someone I worry about it\u0027s the other comments go if you back to your previous slide or you said that now you have a container effectively the top level and you always have to have that "
  },
  {
    "startTime": "00:31:24",
    "text": "extra level where it\u0027s used I just wonder whether there\u0027s gonna be some cases like arrow strings and things whether that might actually become slightly unwieldy to have that way you might just want to include just one value or something and actually haven\u0027t had that extra level in there it\u0027s going to make it slightly less useful and they possibly but I can\u0027t judge bajrangi Erickson instance data actually could use this one or could use a simple yang module but I think that it\u0027s the fake is a kind of a special usage you don\u0027t really want a technical data in the naka model and then once more in the instance data model so it is more correct for to use this structure than viewing it as a normal module can be done Joe Clark Cisco the other thing that this extension allows that I haven\u0027t seen anywhere else is something I\u0027ve used when I was using internally when I was using an rest comp yang data is lists don\u0027t need a key element so I don\u0027t know how you would do that or specify that otherwise you would you would have to specify them as coughing false coffee falls no Ptolemy\u0027s yeah so it is possible but yeah I still this thing\u0027s of this is cleaner and it\u0027s more it\u0027s easier to understand water dust and just having er models but no you know supposed to implement that is supposed to be something else I think this is cleaner okay and also I just want to go back with this was discussed at 103 where I did the presentation when we pulled the whole room in the room agreed that we did want to have this and not use regular yang modules so yeah I don\u0027t know we should try to revisit the course also discuss when how many actually a technical comment at please add to your list how it impacts tree diagrams and how you would use it when you\u0027re right seeing this how we want to represent how you want to represent it did we have that in the draft I don\u0027t remember no no it\u0027s not there it\u0027s like I don\u0027t think it\u0027s there right for the tree diagram we put the yang data in there and you need to probably do the same thing for this button they stopped on fine okay that\u0027s an en Gator was really under it was sort of under specified it was like you can do something really specify what it was right that\u0027s a good point update the but that\u0027s a pretty minor thing so we have I think two open issues you have the open issue listed here right now the accomplice yang data so clearly we need to do address those before our request calls how many I\u0027d like to just get a sense of the room of who\u0027s read it and how ready "
  },
  {
    "startTime": "00:34:24",
    "text": "people think it is with the caveat of these two items just so that we get a feel of whether we try to wrap this up before the next meeting or wait one more meeting cycles so that\u0027s really the objective of these questions so how many have read this version it\u0027s a few how many have read any version I think I see like one more hand I mean it\u0027s not a really really not significant difference other than the objections that have been voiced already there are additional issues that those who have read the document think that need to be addressed so we\u0027ve definitely heard some issues and we\u0027ve heard some rehashing is there anything else that\u0027s out there to me my takeaway is we\u0027re close but we definitely need more reading of the document so maybe a little bit like the last document let\u0027s see if we can get the update out there get some more comments and I think for both documents we\u0027ll have to talk among the chairs including Joel who\u0027s not here whether we if we try to last call before Montreal given how little readership on both documents they had we may use the last call as a way of trying to push reading and getting feedback so I think that applies equally for the last two documents all right thank you and now Kent hi I\u0027m Kent I\u0027m gonna present Hanley long lines for in inclusions for internet drafts and RFC\u0027s this is uh presented before a dream Ferrell presented a 103 I\u0027m not really gonna go through this slide of changes you can look at the diffs that have been submitted to github or actually using data tracker tool there are three issues that I\u0027d like to discuss with the working group today [Music] so the firts sorry too fast okay the first is a fix for the overloaded use of the word artwork so what happened was the draft has been using the word artwork somewhat loosely but from the email thread entitled line with in formats other than plain text that I had with the RFC editor Henrik was cc\u0027d and and in that I had mentioned to him that we haven\u0027t officially moved our ITF hasn\u0027t officially moved to our XML to RFC v3 yet and so the reference to artwork was really you know in in reference to the v2 sense of the word artwork and he came back and said you "
  },
  {
    "startTime": "00:37:24",
    "text": "know I acknowledge but it\u0027s easy to make the wrong Association at the start of the reading and also I think fitting this idea and the tool chain will be subsequently easier who target the v3 output only so he really objected to this idea of using the word artwork and so I changed it so now if you look at it no longer says our work even though the the name of the file the name of the draft is still having artwork folding in the name which actually now been transitioned over to using the word inclusions so you can see in bright yellow therefore I\u0027m sorry for the poke folks and back I understand it might be difficult to see the black background but in bright yellows handling long lines in inclusions in Internet drafts RFC\u0027s so sometimes it\u0027s using the word inclusions which is actually from the ex include draft which you know they are XML to RFC they use X includes too that the use of the word inclusion is pretty commonplace within the tool chain the tools team so so that\u0027s that nice work for them use but it\u0027s kind of not the word I use everywhere sometimes I just say text text content it\u0027s kind of in the nature of the sentence so anyway I just want to let you know that this change is in the current version of the draft I view it as an editorial change but if anyone has any concerns about it please let say so now okay so we\u0027re gonna plan to move forward with this current language next is should we also have a single backslash option and so this has been discussed on a list and but there was no clear consensus on the list so trying to get the consensus here today the proposal is for to also support both headers so current you know so there\u0027ll be one header bright yellow with note with a single backslash line wrapping and then whereby you know you know one folding only occurs on the maximum column and always continues on column one or two the folding could occur on any column with the option for indented continuation so this were like pretty and dense and that second option is actually one that Martin came up with more recently trying to make the single backslash approach a little bit more pretty looking and and then the second which is actually what we have today too is who say the current header is note and there\u0027s the double backslash and and then this is exactly the one that we agreed to when we adopted the draft whereas the folded lines continue after the the next backslash character on the on the next line so the the two headers look similar there\u0027s only the one character difference between them but that one character difference is sufficient for human readers and programs to understand the nature of "
  },
  {
    "startTime": "00:40:24",
    "text": "what they\u0027re looking at and how to unfold it or to read it so so the question is I guess we have some options one is a leave the draft as it is which is to say we only support option number two or B modify the draft to also support option one and two and there\u0027s also a sub question with related to B if we actually agree we would like to support both which is how do we support and that was the math that I sent out the other day and we can talk about it makes sense to do that or not so first I just like to get it and since this is a an already adopted working group document I can ask the room myself it\u0027s not really a chair question right no in fact it\u0027s the author\u0027s or the editor\u0027s responsibility to reach consensus exactly so I would like to ask the room you know if I can get a show hands please or stop any questions yes Krishna so the is Martin suggested the pretty wrapping is is that not sufficient to just have a backslash we all know and love and then eliminate the indention I mean can is that sufficient to actually solve the problem in all cases so if the math that I sent out the other day became like one in 200 was the probability is pretty high that there\u0027d be a collision uncomfortably high so so while it would work most of the time it\u0027s definitely not gonna work sometimes and it\u0027s nice to have that fallback solution where you can I haven\u0027t seen your math it\u0027s hard to believe that it just wouldn\u0027t work all the time and in the case that if it does work all the time then I would support just doing what we all know and love okay so it looked like Martin was gonna come to this yep Martin Richland of course there are cases where the pretty thing doesn\u0027t work if you have if you need to fold them you have you know lots of white spaces that needs to be part of the or even just one weight space well then then if you didn\u0027t you shouldn\u0027t fold that character right so you need to be careful where you fold smart folding well yeah yeah well I mean if yours a human doing it then it\u0027s pretty easy for them to sort of find the natural breakpoints and their alloys a problem it\u0027s fairly easy also for a program to to know fold on the white space or just before just after the white space I don\u0027t think that\u0027s a big thing so I mean the math is I have to admit that I didn\u0027t study or all of them but I mean the the characters are not just random characters that we want to "
  },
  {
    "startTime": "00:43:24",
    "text": "show here right we talked about like XML JSON and things like that so I\u0027m not sure that the math actually works in those cases yeah I tried to account for the some some texts would not have backslash showing up naturally in them so for instance I I think I even said basics before no no base64 encoding includes effects backslash character okay they all have like pluses and equals symbols and things like that but never a backslash basics before is one of the things that typically are very long lines and wrapping is something we want to support for them but like XML and s strings which are also something typically has lone lines never would be fine a backslash in them I don\u0027t think not even in the the end of the element character though there\u0027s one there right yeah I mean you just wouldn\u0027t have the it wouldn\u0027t fold just after back slam right anyway it has to point yes you would have to write a smarter for automated phone you know it had to be a smart folding words if you actually look at the examples who are where you don\u0027t use a smart folder they\u0027re not very nice to read anyway so that that\u0027s my part I would put of course before that and even if we just do you know both both of them 1m2 I would prefer of course the pretty one mmm to the question there Christian hop so to follow up on that I if there\u0027s a choice between having to work a little bit harder in a tool to use a single solution I think it\u0027s better than having a complex standard right I mean I think I mean we\u0027re talking about automatic folding if it\u0027s possible to always do it with one choice I think we should even if it\u0027s a little bit harder I don\u0027t know that\u0027s what I think is a cost benefit okay so maybe there\u0027s in the sort of standards perspective we always try to define one if we can if it covers the cases try not to define - we don\u0027t have to I think there\u0027s an xkcd you know artwork cartoon if it Oakland so okay so trying to get some sort of than the questions I have on the screen aren\u0027t quite right I guess first we need to ask if you know should we only have one solution without even talking about what it is with one is versus more than one and I know that sounds a little bit weird because why would you ever want more than one but again there\u0027s complexity there\u0027s a little bit of complexity involved and the one that we\u0027re talking about if you have a second one it\u0027s just because you have it doesn\u0027t mean you have to use it and it could it\u0027s therefore the fallback right so for the I think I put them female for the programs that are trying to do the automated folding they do the "
  },
  {
    "startTime": "00:46:24",
    "text": "quick test you know can I do this single backsplash approach and one out of 200 times they\u0027ll fail and it says okay I\u0027ll do the double backslash approach so you know half of a percent of the time it\u0027ll have to use the backslash approach if for if it\u0027s not smart it wasn\u0027t written with smarts mind you the doing is without the smarts is just a single line it\u0027s like it\u0027s very simple not to do it yeah I mean when you say I\u0027m picturing like we want to be able to do it with a line of arc verse we\u0027re gonna you know right maybe 20 lines of Python I mean what kind of complexity are we talking about here as opposed to avoiding a double so so robots and Cisco so I would I primarily like a solution that\u0027s guaranteed to work always so I would like it to be able to whatever the input is to be able to fold it however I do also agree that in as Marta\u0027s describes that in some cases we have to do things that look a little bit better having a single slash and not how to tell their second stashes is nice so I guess my preferences I don\u0027t think that doing a single slash covers all cases or pankkar or cases in the case of a with Martin\u0027s solution so my preference would be to support both and in the case of the second one support the one where you eat the white space at the beginning of the line and what Martin proposes okay yeah there\u0027s definitely you know certain conditions it\u0027s you know we\u0027re you know a bunch of white spaces it wouldn\u0027t be able to fold it so whereas the double double backslash approach would work so it always works alright so I\u0027ve heard two who are primarily interested in just having the one solution one I guess two if you count myself as preferring actually having two solutions but still that\u0027s not enough to get a basis for the sense of the room so I\u0027ll ask the questions again I guess a would be leave the draft as it is meaning we only have a single back double backslash approach that we currently have or B we would add also the single backslash approach which would be as Rob says the the one that supports the pretty with the indents and fold can occur on any column can well I hate to jump in because they are running late I think it might help people respond if they could understand a little bit better of what cases fall call apart if you only do a so we don\u0027t have if you all you do all you do is one if you only do one one one double I yeah it\u0027s one delay all right yeah so I mean so if so there\u0027s so there would be a case where "
  },
  {
    "startTime": "00:49:25",
    "text": "if you had a line that contained nothing but spaces the entire line like that went past max care column right so it\u0027s a why would you ever do this I don\u0027t know but that\u0027s the case wait a second so that\u0027s the one that\u0027s unsolvable there\u0027s other cases where you might have some texts and then some like and you\u0027re not doing the smart folding so you know that you\u0027re not writing the extra 19 lines of Python code you\u0027re just using the 1i nook where where you want to do the cut on the max call but the very next character is a whitespace whitespace character so that would then fall into this case it\u0027s not be a false positive now we could write a smarter folder but if you don\u0027t write the cellar yeah it\u0027s not one line of look all right so I think that helps people answer the question a little bit better okay so so if we can get a raise of hands for those who think we should leave the draft as it is with the single double backslash approach nobody show hands for those who think that we should support both the double backslash approach and also the single backslash approach that is the pretty backslash approach and I think you want to know whether or not there\u0027s gonna be a third option okay so there will be a third option which is the only supporting the single backslash okay so again the B which is to support both the double backslash and a single backslash approach raise your hands please so five yeah okay and then lastly C which is not on the screen but to only support the single backslash approach that is doing the pretty print so that\u0027s about the same Oh for over there okay so I don\u0027t know those are authors you get to okay well I saw seven hands on the oh sorry yeah there was what if I ought to write the code it\u0027s not it\u0027s not just you it\u0027s everybody it\u0027s everyone who wants to talk we could give you the awk in the file yeah then the document already has okay so yeah okay the next question the questions about having n markers so this was discussing 103 but again no clear consensus the proposal is to add a footer so right now we just talked about a header write the note but some were discussing the potentially a need for "
  },
  {
    "startTime": "00:52:26",
    "text": "having a footer so you would then change the header to instead starting with the word note to start with the word start and then you would also have a footer that just was the identical thing but ending with word end to me personally as you know at the motivation for wanting to have a footer is unclear nor is there a request by the RFC editor to have one but you know what would the motivation be you know is it to aid extractions you know so I mean I don\u0027t there\u0027s still gonna be lots of artwork slash source code that\u0027s not folded and those those those need to be extracted also so you know maybe would aid some instructions but not all extractions so it doesn\u0027t really solve the bigger problem and besides I strongly believe that we should move away from trying to extract from plain text RFC\u0027s xml is now being published I don\u0027t know if you\u0027ve seen it but now in the link where you know we click on you your choices are PDF text XML it\u0027s now available if you can actually download the XML for any draft so you know why wouldn\u0027t we be extracting from XML instead so I don\u0027t see it really aiding instructions and is it aiding readers so you know again what about all the unfolded inclusions you still have the need for those and then lastly is it even an issue I don\u0027t never heard anybody having an issue with reading and mobiles and Cisco how without the end marker how does the Tony know when to stop okay that\u0027s the framing problem it goes through the extraction and with XML is just the end of the source so you open brackets source code and in brackets or code figure into elements so everything in between is the conclusion but people are going to use this against text RFC\u0027s as well unless that unless you take that outside the scope and say this is not to be used for text RFC\u0027s and the other column the drafter says it says to be used in ITF draft and can also be used in other cases I think there\u0027s many cases where your document you\u0027re running this tooling you don\u0027t want to to carry on through the entire document doing this unfolding where stash might have some other meaning correct yeah it\u0027s not running across the entire document just per inclusion so per source code element it would extract the source code element and then run the unfolding algorithm on that single element but okay so does this tie to the source code element as in this scheme isn\u0027t just using this header it actually requires a source huh no no no so how it got extracted is a separate you know like a precondition to some other piece of tool tooling they did the extraction whether it be from an XML R star seed document or some you know third party s do somehow someone got it extracted it that\u0027s their problem but then they feed it into the unfold er okay so crime then it is the theme put is the entire file yes okay okay so there\u0027s two options and there\u0027s no need for a third option so le the drafters is meaning that we\u0027re only supporting the header and be modified that draft to support both a header and a footer so can I get a raise "
  },
  {
    "startTime": "00:55:27",
    "text": "of hands for those who think that we should leave the draft as it is only supporting the header raise your hands please okay and then or those who think we should modify the draft support both I had her and a footer okay so I I saw some and then a few I saw a clear majority for a very few people participating okay and that is the last slide here thank you okay so the next presentation is gang next analysis I think okay great next all right so there has been some three virtual interims one on February 6 xx and then March 2 xx the focus for all three was on scoring the game next issues there was a total of 70 issues that were entered over the course of three years the the gang next repo was created on March 11 2016 this presentation is reviewing all the this preacher this preacher table reviews the results of those meetings and there will be a deep dive meeting on this Wednesday in carlin 3 between 3 \u0026 5 next please okay so first I wrote a Python script that would reach out to github and extract all the issues and run it through Matt plot and so this is a 3d view it\u0027s impossible to see cuz it\u0027s not interactive with a mouse that you can rotate and it looks very nice but okay but I did then next slide please I did a couple on axes views so I actually didn\u0027t mean to do these because they\u0027re not terribly important but on this on the left hand side you see complexity times importance and I think the the bottom line to take away is that most of the important issues have low complexity that\u0027s how I\u0027m reading this particular view and then on the right hand side you have complexity times backward compatibility and the takeaway here is that most of the backward compatible issues have low complexity okay so most important and most the backward-compatible issues are low complexity next slide please hmm seems like I\u0027m missing something in the background but anyway I think it\u0027s just this one picture anyway so so this slide is is showing backwards-compatibility times importance "
  },
  {
    "startTime": "00:58:28",
    "text": "so it\u0027s sort of an on axis view but these are the two axes that we really care about when we think about what\u0027s important right we want to we want to do what\u0027s important but the backward compatibility if it says it\u0027s a high backward compatibility it means that it could be a yang 1.2 we\u0027re not kind of break compatibility with the existing game it says low backwards compatibility then it\u0027s potentially a gang - dodo where we\u0027re breaking compatibility with existing yang if it says unknown then you know we just don\u0027t know yet right that\u0027s what it means so you can die on this is the only slide where there\u0027s kemp\u0027s so if you\u0027re interested in looking at the how many of the issues fall into the various levels this is the slide to be focusing on to see that but you can see there\u0027s only you know for the low backward compatibility there\u0027s only three issues that have been scored as actually being low backward compatibility but there\u0027s actually eight issues that have unknown backwards compatibility and any of those eight issues could potentially be backwards compatibility breakers on next slide please so this light is showing the same view as before but because the unknowns are kind of hard to interpret I took the value of the unknowns and sprinkled them evenly into the low medium high so for instance if I said there was two unknowns I added two to the low and I added two to the medium and I added two to the high and pretended this view I just really unfortunate that the text is kind of occluding the graphics here but the size of the the circles are representing the number of issues so you get a sense that by and large most of the issues are backwards compatible and having medium importance and then there\u0027s also back compatible with high importance next slide please okay so this is the same as the previous slide but the only difference here is that now I\u0027ve multiplied the size of the circle is representing the complexity so now you\u0027re having a sense of how much efforts it\u0027s going to take us to to work on this if we wanted to tackle the medium importance and high backwards compatibility that\u0027s that\u0027s almost all the work you 70% of the work is right there that big light green circle in the background next slide please okay so where do we want to focus and this is really the the discussion that we need to have on Wednesday on the left-hand side do we focus on importance if we focus on importance what we\u0027re saying is that we don\u0027t care for maintaining backward compatibility we want that topmost row and you know mate but if we\u0027re gonna break backward compatibility if we\u0027re going in with the intention of breaking backward compatibility then we\u0027d also probably go ahead and grab the medium and the low issues that we know we\u0027re going to break backwards compatibility go ahead and do them now because we don\u0027t want to have to break backwards compatibility again any time soon so let\u0027s just go ahead and take care of all those ones that we think that have the potential for breaking "
  },
  {
    "startTime": "01:01:28",
    "text": "backwards pride of work even the unknowns down there that we\u0027re not sure if they might break backward compatibility would so on the left hand side of a focus on importance that\u0027s probably what we would do I mean subject to discussion of course on the right hand side if the focus is on backward compatibility we want that rightmost column those are all going to be giving us the backwards compatibility but then there\u0027s also those unknowns we don\u0027t really know yet if they\u0027re you know how highly backwards compatible they might be and then you see that little medium with a circle it\u0027s just one issue but we probably go ahead and grab that one because it\u0027s it\u0027s a you know medium would when we say medium backwards compatibility is probably a way to at least do some of it in a backwards compatible way so if we were to do that that\u0027s what we don\u0027t end up with so that\u0027s actually the end of the presentation and where I want to stop I\u0027m just gonna ask the group if they could give us some feedback for the meeting on Wednesday what should we focus on where should we focus the discussion for Wednesday focus on importance focus on backward compatibility do we have enough information young-shin vada I think there are two other dimensions that are important one dimension is do we actually know how to solve it so sometimes you have questions where people say yeah that\u0027s how important what we don\u0027t really know how to do this and the other question is typical cases you have something where there\u0027s a solution or even multiple solutions but people don\u0027t agree on that so one one thing you should keep in your mind is what is your timeline and don\u0027t sign up for things that don\u0027t have a solution or no consensus for a solution and then get stuck on that okay so that\u0027s I\u0027d see Tim in line but I think that\u0027s a great point the timeline so which let\u0027s have a conversation about what we think the timeline should be the first simply sorry just a real quick question so if you talk about backward compatible what is the number actually of features that you\u0027re talking about that would be back are compatible that were low or medium complexity what I\u0027m assuming most of the high complexity ones are not backward yes so on the receive they\u0027re just what 14 plus 18 32 plus 4 36 out of 48 issues were highly backwards compatible well say that says 36 out of 48 issues okay so that answer pieces of 75% of the issues were yeah I will say I don\u0027t know about adoption I mean even going from yang 102 one one you know it\u0027s it\u0027s taken time for the industry to to pull into that right you know so putting out a yang 1.2 you would wonder you know just just what that adoption time frame would be that you know people are barely on one one right now if they in there and that\u0027s an "
  },
  {
    "startTime": "01:04:28",
    "text": "excellent point and it goes to the compatibility dimension because things that are compatible we could do as extensions rather than a new as a new language things that are not compatible would absolutely require a new version and either then we can argue about the version number so you know it\u0027s a little hard in the abstract to say you care a lot about a particular one and you see if want to see an extension immediately but the feedback focus on things that are highly compatible so we can do it in a modular way is something that would be useful feedback now if that\u0027s if that\u0027s what the room feels but I\u0027ll take I\u0027ll interpret what you\u0027re saying is be very careful about pushing hard for a anything that beyond yang 1.2 I\u0027m sorry beyond 1.1 yeah cuz they you know the industry\u0027s not even there yet so it\u0027s a question to me of you know it should we you know is it the next one 1.2 or 2.0 and and then it\u0027s really based upon when the industry adoption will curb will happen on it right right but if there\u0027s but then you said there\u0027s you know two-thirds of the features out there are already backward compatible and and if you can box them up and do a release you know I\u0027m just twice right just information okay I think your guns point is it was a really good one to take away which is in your discussion on Wednesday or in the discussion on Wednesday is added the demand we know how easy is it solve so we did have a dimension complexity was the third dimension so these were that was the 3d view I showed you the beginning and and actually think you go to the next slide you\u0027ll see we\u0027re kind of know one more slide please yeah that one so this one tries to factor in the complexity as well it\u0027s kind of hard to read but um you got a sense for it the most the effort it would be doing that the that one thing but your can also made the other point which was when would what\u0027s the timeline what\u0027s the timeframe do we do we as a working group have a sense I mean where we open-ended about this I mean Lou made a point the beginning would be at least two years I think last time I was actually three years before when we started to finish you know is there a hard deadline that were what we need to work towards or should work towards rouble San Cisco so I think it\u0027d be useful I hope we announce you\u0027ve done so far is useful but actually I think with the list of issues we could probably go through that list and then classify them into ones that we think are definitely worth doing because either the scope isn\u0027t too hard we understand the solution etc and we agree it\u0027s worth doing so that\u0027s one set another set of issues is ones we definitely don\u0027t do either it\u0027s not important enough or it\u0027s too complex whatever we just push those officer look we know we don\u0027t discuss those and then there\u0027s a set in the middle of these ones require further discussion is unclear either way but I think then with "
  },
  {
    "startTime": "01:07:28",
    "text": "that saw discussion we could maybe end up with a set I\u0027m more bounded scope of what we think the real problem is bring the back to the working group and say look this is what we think the scope would be - it\u0027d be two feet to fix these issues we know the answers to these or these ones are still open we might should these be included or not so that would be the way I it\u0027s just going right so certainly we can do that on Wednesday that\u0027ll be the exercise we do on Wednesday I was just hoping to collect more feedback like the timeline information but I think that\u0027s it thank you hello could have impaired one this is Hugh from Galway and I\u0027m here to discuss is authority for setting this is not the first time to introduce this chapter and actually recapture a little bit for this province pace actually you know current Nanticoke for the doesn\u0027t allow you to reset the wrong in datastore for Canada so you also cannot reset without changing their wronging and what dynamic you also cannot have reset to the initial state so the same apply to the rest convo so the problem so the solution we proposed actually we defined a method that you allow you to reset the datastore to the initial state to the faculty for contents actually this can be used during the zero touch to certain stage or when the existing convolution actually has some major errors and so in this chapter we define when a piece a were called a reset datastore a PC in addition we actually define a new factory default text or it is read-only it only can be set by the server and it cannot be changed by the imagine of operation like a at config etc and this is a status update actually this chapter the history actually we moved a chart from the netcode to the Nano mode and we have several discussion in master IT meeting we discussed this chapter had a lot of support and recently the change actually based on the discussion we actually have a two minor to closer to minor opening issues that discuss in the last meeting and we actually put back the copy configure based on robust comments and also we have a few reference a potat this is all the changes were made and so we like to you know request the walking "
  },
  {
    "startTime": "01:10:30",
    "text": "boot up top is work I mean how many people have read the draft this version of the draft a few any version of the draft more okay there\u0027s been enough discussion yeah okay so yeah that\u0027s perhaps how many people are interested in the problem a fair number how many people are not interested in the problem no one okay so raise your hand if you believe that the working group should adopt this version of the draft is the basis for a workgroup document good number yeah how many people think the workgroup should not adopt this version jobsworth basis for working through talking crazy it\u0027s no one okay great so I think that\u0027s will confirm that on the list thank you and actual dis confirm it as a last furthers any objections on the list otherwise will be adopted by default thank you okay this is Shingo again and the second route we like to discuss is an empty base a notification and next this actually a very short shaft and motivation to do this because we already have never called Bates event that defines the ups a foot for TC obviously a 60 64 70 actually and this can be used to monitor the knack of searching and to repose some common system event but when we introduce the young empty maybe additional event need to be incorporated can delay the problem is when we introduced like intend pedestal and operation pedestal they may involve some interval process mean you need to you know apply it some competitor from intent with operational so how to keep shadows at some of the event like you summer obviously cannot apply this so we can allow the user to you know to reporter the the fare of the object also to to notify some reason why it cannot apply so we supposed to define one an empty a specific notification and history the tow packages of history "
  },
  {
    "startTime": "01:13:33",
    "text": "actually Xetra also moved from the network over to the net motor and last meeting we received some discussion represent this chapter and two comments actually on a many nice the one is about clarification for the committee committee RPC and this new notification define in this chapter actually we think for for how do you identify the management setting actually we can potentially use the username but it is optional we also can use some other parameter composed use a multi attack to do that another one actually is to discuss the the you know for in Kenda and running really when you config apply the configure stated to the operational this a potato will usually actually happen you know usually immediately so changes since master version actually we add as a mode attack actually to as a another parameter to identify the management sessions in some in some cases the same user may have a different application so we can use model tag to indicate that the second a is we actually remove two redundant the notification why is apply in tennis star the other one is applied in ten and four in tennis star actually we sink because as a clarify it also happen at the same time as the commit operation so it hadn\u0027t ended also for the intend any actually we can use the an MTA apply the updater to in the indicated so this is something seems not an idiot so we remove it plays to next this is the updated for the model structure actually you can see we actually added the application package reuse the module tag to do that identify the management session in addition we actually we can you know use this model together with MMD ativ and to use if to compare the difference between the antenna pedestal and Operation Thetis thought you identify what is the missing obviously which object is not applied next so this is a the the notification with the final it will be used at a stage you know after the committee up republishing and can keep track of this internal process you know set by the server next so we sink this shaft actually make a "
  },
  {
    "startTime": "01:16:35",
    "text": "several revision and and we we sink we like recruit person we go to a top this look how many people have read this version of draft please raise your hand I very few any any version of the strapped just a little more that\u0027s still very few how many think this is an area we should be spending time on a little more but still few I I think I think we have to do a little more education is what you\u0027re trying to achieve and then see if there\u0027s support for it so maybe go back and summarize what the objectives are on the list okay I can do this to this commune spies on discussion yeah exactly thank you alright thank you Chris okay so it comes up every once in a while that we need a geolocation common geolocation object so and I also I had an old boss that was very excited about this so I decided to write it down like sidebar oh that bar oh so why do we need this so many applications have a need for a geolocation you might want to map your data center router firewall files server location you might also want to map your fiber endpoints failures like fiber cuts where your customers are weather stations cameras so forth so it\u0027s good to have a common grouping that you know can be reused throughout all the different models that might need a geolocation so simple right you just do a lat long and maybe a height and it turns out not to be that simple you may need add some accuracy for your measurement and what\u0027s your height relative to is it the mean sea level is it geoid which I\u0027ll get to later or is it to the ground so there\u0027s a lot of standards around this actually as you start digging and digging open open it up where I think the can of worms there\u0027s a lot to actually learn and there\u0027s a lot of work that\u0027s done on this primarily in the area of the standardized reference coordinate reference systems the one that we\u0027re all "
  },
  {
    "startTime": "01:19:36",
    "text": "using with our phones is the GPS one is wgs84 and it\u0027s sort of it there\u0027s there\u0027s lots of like fun things to talk about but originally when that when they sent the satellites up the geode is off by the jig maps where they sort of think mean sea level is it was off by at least a hundred meters in certain places so they they send up another satellite that maps the gravity right because you have a different iron and you know different concentrations of things in the earth and it actually changes where at sea level is so they\u0027ve slowly gotten better and better right and gotten closer and closer so so all these things you have to learn about and you have to pay attention to them there\u0027s other standards as well w3c has a standard object GML KML or markup markups XML that include objects as well as IDF we have one in a URI there\u0027s also things you might need to consider like continental drift right your location is going to change over time so if you\u0027re if you\u0027re referring to a router and a building it\u0027s actually gonna move a few centimeters or so per year he also might be concerned with other planets or asteroids have routers on the moon and then finally you might actually want to map have a database of geo locations in a virtual reality or you might want to have an alternate mapping right where you\u0027ve modified reality you\u0027re still reality you\u0027re talking about but somehow you want to look at it in a different way so this is the grouping and this is the grouping that I came up with it tries to cover all of us a lot of it\u0027s optional so when you just want that long and maybe height that\u0027s all you have to put in there but if you need the other things it\u0027s in here so if you look the alternate system this is sort of a catch-all if you want to sort of go way out there otherwise we have the astronomical body which would default to earth and that geodetic system now the geodetic system is what\u0027s actually gives meaning to your coordinates right so tell you what height is relative what your lips oil values aren\u0027t like Latin long and then so as a part of that the datum value that\u0027s what that would be like wgs84 in other words a GPS one there are others and we\u0027ll talk a little bit about that later but we also might want to specify our coordinate accuracy and our hike accuracy sometimes those are not the same so we can split them and then as far as the coordinates we have we cover ellipsoidal which are lat/long as well as cartesian which would be like a vector from a center of mass the "
  },
  {
    "startTime": "01:22:37",
    "text": "velocity is there primarily for stable movement this isn\u0027t meant to track you know orbital dynamics and stuff it\u0027s it\u0027s to track control drift or something has very stable move and we also need a timestamp when did you take the measurement so in so I define the grouping and then I need to make sure that we\u0027re actually compatible with what other people have done out there we\u0027re not just inventing something new that\u0027s not gonna work so I went through the different of the various different other standardized dopings the IETF URI defines lat/long an optional height a nuptial uncertainty and an optional CRS or geodetic datum it does not include time soon so the this is fully expressible in the Eng I\u0027ll note this on each one we use decimal 64 values in the yang so different different other markups we use different other models we\u0027ll use different values so in this case it\u0027s strings right see the sort of infinite precision w3c we\u0027ve got lat long optional height optional accuracy optional height accuracy and it includes heading in speed I didn\u0027t see that there\u0027s any way to actually change the CRS so it\u0027s just defaulting and always wgs84 the GPS in this case they the types are doubles so the only difference you get here is we we have decimal use vessel 64 we actually map a touch that\u0027s able to have a huge accuracy but doubles it\u0027s a very very extremes that doubles may be a little bit better but for all intents and purposes they map back and forth the GML is a very abstract model it basically abstracts the entire CRS system it can do any number of dimensions it\u0027s much much broader but in the case of if we concern or limit ourselves to trying to do geographic locations it supports ellipsoidal and Cartesian it\u0027s not clear whether they standardized their CRS but there\u0027s a place you know you can you specify what the CRS is I didn\u0027t see if they had a registry though so it could just be writing up strings well not random but it also includes an observation which would include the time stamp but it also the observation object includes things like the target camera you know or result of a measurement so this is mostly expressible again it\u0027s very generic so we\u0027re not going to try to capture everything they\u0027re doing KML is put forth by Google it\u0027s now standardized by "
  },
  {
    "startTime": "01:25:39",
    "text": "I think oh gee see the open Geospatial coordinates of sham geographic consortium this is super Sun at w3c but also modifies and gives you more control over what the height is and they include clamp to ground which means we\u0027re not going to specify the height it\u0027s just the ground relative to ground and absolute absolute would be like the geoid so how far away from the giri you are and the geoid is generally mean sea level it also has a clamp to seafloor and relative to sea floor and and then it includes other things like the camera direction it\u0027s used like for Google Earth so this is also fully accessible although you\u0027d have to map the seafloor values we don\u0027t have a way to do that we don\u0027t have that a seafloor in our urban so some examples um this is a restaurant in New York it shows just a Latin long locatable item is not part of the grouping I\u0027m just using that because that\u0027s where the grouping is used you could imagine so a more complex example the pump they arts in Paris this includes a timestamp lat/long and a height 35 meters above mean sea level an on earth example the Apollo 11 landing site you can see that here this is interesting because we have we had to specify a new reference frame the ask for among the astronomical bodies the moon there is a standard geodetic datum in this case the string is me in the registry that actually is defines what me is and we\u0027ll get to the registry and whether we need one and then a few slides and then the lat and longitude on the moon of the landing the times is actually when the Eagle landed I also heard that um one of our esteemed chairs once did a virtual reality project and design date spotted cow so we have here Kent\u0027s Spotted Cow and it\u0027s in the alternate system of Kent space this is all made up by the way no one\u0027s laughing tough crowd the geodetic system it\u0027s Kent 87 it\u0027s at point five point five of the CRS so the open issues should we have so height height there\u0027s open issue of height should we have more relativity here instead of just to the geoid should we had a options like kml has we had liked to ground verse to be wide and and or you know maybe just have a generic string that allows the local user to you know put a value there to indicate what the height is relative to the other "
  },
  {
    "startTime": "01:28:41",
    "text": "issue that\u0027s probably gonna cause some commotion is the registry we already have a registry in the ietf for that uri and so it\u0027d be nice to reuse it one issue that I see with using the URI registry is that its specification required and iest or approval so it\u0027s very hard to get things in this registry which is fine if you\u0027re just going for very standard values but you know we include things like alternate system in virtual realities the registry I specify is literally just to stop having duplicate values right so I had specified it as first-come first-serve that might be too loose in which case we upgrade it to designated expert and say direction to the designated expert of no duplicates right you do not allowed to have opinions you know put the value in as long it\u0027s not duplicating the value so so we have to decide if you know if that\u0027s useful or you know people will just put the value they want in there and they don\u0027t care they want to get work done right so the other so the other option is if we keep with a with our own register can we modify the URI registry to be less strict would that people you know with the IETF be open to that I\u0027m not sure or and also should we use the u RN is used right now to to standardize the values in the URI registry so you have like you are n o GC for the open geographical consortium standards it\u0027s a very interesting that they use AES PG so the world uses values that are done by what\u0027s now called the International Association of oil and gas producers but that E is for European it\u0027s fun all the different people involved in this so it should be just reserve earned prefix to point at that registry and no one\u0027s allowed to reserve that Prix anything with that prefix re and then we can just use that very standard worldwide registry for most of the values and then we leave open the ability to add things for people\u0027s virtual realities or ultimate systems so that that\u0027s sort of an open issue was the new work that no one\u0027s had a chance to see it [Music] any comments questions [Music] can\u0027t as a contributor the Cartesian coordinate system how important is that from use of user you know perspective that\u0027s a good question I you know I just published this and I\u0027ve started getting a little bit of feedback on it um the Cartesian is actually what like wgs84 uses and then they map to the ellipsoidal so that we can actually make sense of it okay so you know it seems worthwhile to have it in there because it\u0027s how it\u0027s stored okay so with Cartesian coordinate systems it\u0027s necessary to have a reference frame and "
  },
  {
    "startTime": "01:31:42",
    "text": "I don\u0027t I didn\u0027t see that in your model do you have one like where it where\u0027s origin the origin is generally center mass and that\u0027s specified by the geodetic data okay so do you know so well it\u0027ll say it\u0027s the center of mass of the earth right is the Sun it will be the Sun where the vectors Oh for the right for the geodetic that makes sense the center of the earth but for Cartesian it\u0027d be a point on the surface of the earth so right so you have three accesses in spherical right so your X X Y Z looking at you okay and also the one thing I know from my history of mapping back and forth between wgs84 and Cartesian is that the ability to the resolution get the math lose the resolution very quickly I think we can support maybe at a 30 kilometer with kilometers so you would actually have to have maybe that\u0027s sufficient for your use case but it\u0027s much better now so the the it had there\u0027s a couple different things in play with that it has to do with where they have a table because they measured the the the gravitational changes are on the surface right because like you know the earth is not perfectly solid iron and so they have these mapping tables that adjust because the the GPS geoid is a mathematical you know ellipse right and then they have to adjust that based on measurements they\u0027ve taken so the value you\u0027re talking about the accuracy is how accurate those tables are right so that used to be like 200 kilometers or something like that right the egm earth\u0027s gravitational model 2008 which is the most reason one gets it down to it\u0027s a small number it\u0027s like a hundred meters or something and then my last comment the vector was the vectors have three axes but it is equally applicable in both cartesian as well as geodetic space yeah because it\u0027s just from you right so it\u0027s from your location that\u0027s where it\u0027s you\u0027re basically you\u0027re heading in speed right so originally I had the value as heading in speed so it was but so for continental drift the continents not just they don\u0027t just move on the plane or what they big move up and down what I meant is if if the coordinate has been geodetic coordinate then the vector should be interpreted in geodetic space coordinate space and it\u0027s a Cartesian coordinate I mean the vector should be interpreted on computing space no so you so the so the the Cartesian or the ellipsoidal gives you your location the velocity it\u0027s a velocity vector right so it\u0027s it is where you\u0027re at so you\u0027ve identified where you\u0027re at whether Cartesian or ellipse I do now you have a location now the question is what direction are you going and how fast and that\u0027s that\u0027s what that vector is it doesn\u0027t it doesn\u0027t map into like an ellipse ideal case if it was heading in speed that would be in Alex Roy deal because he would have a 360 degree heading and then the speed along that this is a three three XYZ right so it\u0027s just saying where you know how fast am I "
  },
  {
    "startTime": "01:34:42",
    "text": "going in the XYZ direction the magnitude of the vector and where the vector is I\u0027m just thinking the axes what is X what is why they\u0027re different in GX space oh oh I see you\u0027re saying it\u0027s it so it\u0027s that is aligned with with the with the goe oh yeah yeah so the center of mass whatever whatever the the Cartesian would be that would is that\u0027s the same axis okay so that\u0027s it if from contributing any other comments Bravo San Cisco so on I generally think this is useful but I have no expertise to be able to review this and so it\u0027s correct always it covers everything or your other things upside down so I don\u0027t know but I think it\u0027s useful I think it\u0027s worth worth working on I was probably there you know three or four months ago right I had to do a lot of research to make sure I wasn\u0027t screwing this up so you could trust me I don\u0027t think you should trust me I should be reviewed there are I don\u0027t know if David Lassiter is in here no but he he just looked at this he actually does I don\u0027t remember what telecom he works for but he he\u0027s been over those draftkings and specifically he said oh yeah you know and he actually helped me a little bit right with making sure that I hadn\u0027t made any mistakes so we do need to get people who are doing it who would be using it yeah yeah oh yeah let\u0027s get the right technical review I have to review the rest of it yeah so maybe I\u0027ll try to you know sign people up to send something in mailing lists saying I\u0027ve done this mapping you know with for this purpose and I\u0027ve reviewed this and it looks good so that actually brings in an interesting question about you know polling the room for interest if we don\u0027t have the you know people room if actually it\u0027s a separate group of community that would need to contribute to that discussion but nonetheless I think would be interesting to get some sense from the room I realized that this is a zero zero you know and and you know first time being presented but still it\u0027s always interesting to get a sense from the room at level of interest so how many people in the room have actually read the draft please raise your hand wow so few and and there\u0027s only one version of drafts I don\u0027t need to ask any other question there cuz there\u0027s one there\u0027s one oh yeah I grabbed it because you gave me one of three like any things for the velocity all right and and then how many people think this is an interesting work please raise your hand actually more more than read the drafts that\u0027s good and I think it\u0027s probably premature to actually ask for anybody you know to do an adoption to sell or actually I don\u0027t know if it\u0027s premature because there I think more to do so so no I I mean it is the first time I\u0027m presenting I wouldn\u0027t mind asking on the list maybe if or at polling the room if people think we could ask soon about adoption because it has been on the list before right the people have talked about the need of for a geolocation object on the list so it\u0027s it\u0027s work I think we\u0027ve already kind of "
  },
  {
    "startTime": "01:37:43",
    "text": "sort of agreed that we might want to take on does anybody think that we need to do much more before adopting this or you know polling for adoption so this tip Karen okay I was just gonna make that same statement I mean you know to be honest with you long lat height that\u0027s 80% or more of what what we need right and so you know to try to do the you got a long tail hair alright and so you looks like you got everything that you basically need and I know that in fact last week this actually came up and said hey look we need to get some geolocation stuff for some metadata for some network elements do we want to build our own model I said hang on but it depends on how quick the ITF can do this stuff right so but you\u0027ve got more than enough that I\u0027ve seen in any geo low location type of thing and models like and that\u0027s a good point I think it is what almost too much maybe I should ask the questions anyone does anyone think that\u0027s too before you ask that question I\u0027d like to defend it okay this came up from people the the reality is we do have networks right out there we put we put computers on them right we we send we send spaceships to asteroids to land on them there\u0027s no reason to limit ourselves here and I\u0027m not I\u0027m not gonna break anything by putting it here and I did my research right so when I when I when we\u0027re putting uh when I show the Apollo 11 landing site right it\u0027s actually referring to a worldwide standard for the geolocation on the moon right it\u0027s not it\u0027s not like I\u0027m just playing around throwing things in there for games chef I was in a very old life I had internship at the Geological Survey do we have any sorry do we have anybody that does these and work towards know various no station state entities like that I don\u0027t I don\u0027t know anybody lasers to the OGC or anything but um I\u0027d be open to hearing at I will rattle a few trees thank you Bob so I think it\u0027s interesting now if you\u0027re asking a question who has expertise here to review the location aspect of it not the young part right and if there is nobody we have to ask who would be the right experts outside of this working group outside of the ITF wherever but if you\u0027ve got the feedback of those guys selling this is good from a geolocation point of view then we\u0027re fine and so Ben why I agree with you but I think that goes to the last call as opposed to adoption we could go ahead and adopt it as working group and agree to work on it and then collect the experts to do the final review fair enough right that will net will have to do that anyway correct yeah and I know the only dignities will be here okay but it does also look like you\u0027ve "
  },
  {
    "startTime": "01:40:43",
    "text": "already done a lot of research here in existing other other models that modeling the same data so it\u0027s not like this a blank slate where you just sort of come up with this new scheme it\u0027s like I\u0027ve looked at these ones I\u0027ve cholestacare into i think it\u0027s the right one so I think you\u0027ve done a lot of the legwork already here yeah the comparison that was the real point behind the comparison right was that I found three under three other standards right that it didn\u0027t standardize they have stos behind them who have all looked at it came to very similar you know very similar outcomes right and then I and I\u0027m in the draft showing that I\u0027m we\u0027re not doing we\u0027re not deviating from these right and that we can map back and forth to them I do think that does grant some legitimacy to the work there already and then my other companies I think that I think ITF takes a long long time to produce young models I\u0027m gonna showing that again again again whereas I think they would be really really useful so the world in general to have more standard yeah molds coming out of ITF the people can use and either they\u0027re not hundreds imperfect I think we\u0027ll get to the stage where we can fix those mistakes and we get some that\u0027s a ninety nine percent is good enough there\u0027s a starting point okay if you can do it quicker I think actually I\u0027m I\u0027m convinced it seems like there\u0027s a lot of interest in the room and you\u0027ve done the homework so let\u0027s go ahead and move with a poll for adoption how many people in the room so I\u0027ve already asked how many people read the draft and have interest in the drafts now we\u0027re just gonna do the poll for adoption any people in the room would like to see this draft adopters working group as the basis for a working group document please raise your hand as many people have raised her hand and how many people would not like to see this document used as the basis for a working group document please raise your hand that\u0027s none okay so we will confirm that on the list and like the last time if no one controls you know will be a doctor by default thank you yeah young-shin Veda I\u0027m going to talk about an update to the young datatypes the common yang data types almost every young module is importing and I list of things to add on my computer and at some point in time I thought I\u0027d just start putting that into a new document so people can actually look at what might be in there next slide please so what I\u0027ve added is a type for a date and the time for time because we only had date and time but sometimes you only need one of them I added types for time intervals like MIT in minutes seconds what have you you can read the whole list really basic stuff but popular stuff I added something that\u0027s called a revision identifier for "
  },
  {
    "startTime": "01:43:43",
    "text": "the current version of yang kind of telling you which version you are talking about and I copied in a version of the node instance identified at prototype from neck um because it seems to be useful outside of the neck and context and people might not want to have a dependency on a cam if they just want to use a node instance identifier can made a suggestion we should have an email address type so I looked into that and edit something next slide so the issues you think a date is simple a trip is simple but then you think about what does it mean to have a canonical format for a date you think it should be simple you\u0027re looking to access the specification they have a data type of day they have text about canonicalization of that and I didn\u0027t understand it and that\u0027s why it\u0027s here it\u0027s probably a reminder for myself to keep looking into this unless there\u0027s someone in the audience who understands date kind of neck realization if not I\u0027ll just keep it as as a reminder for myself the next one is probably something where more people have an opinion about and as is the number of bits that you need to represent time a different resolution so if you have a nanoseconds timer and probably people would say yeah 64 bits it\u0027s not a bad idea because that takes pretty fast if you have a time that you express some minutes then probably 32 bits are fine also the question is where to draw the line and opinions Rob Wilson Cisco so I think types a cheap type that\u0027s a cheap so just to find it both I know what I want to propose to modify the regex pattern for the domain name because in fact it doesn\u0027t do what the description promises it says that can be use in DNS a and aaaa records this is not really the case because in those because you can also have first wildcards which means asterisks and second slash that\u0027s used for the reverse domain registration basically like I don\u0027t know something / 64 for for cider style domain delegation delegation so I actually wanted to propose it in the mailing list I wanted to to propose some pattern for that but I haven\u0027t had time to test it so but I think it would be a good addition because otherwise it really doesn\u0027t do what what promises on the other hand "
  },
  {
    "startTime": "01:46:44",
    "text": "there is this host type and in this case I think that it it should be strict just to follow the stricter rules for for host names in this case is it just it\u0027s a union of domain name and IP addresses and then in this case it it\u0027s probably not good to permit just a single dot which which which is permitted in domain name so I think it would be useful to extend the domain name type and restrict the host type probably so please send an email because a new issue and I can track I just wanted to to get some feedback whether people think that this is the thing to do because for the host for example it probably cannot be done with the same name which is you likely don\u0027t change anything that is define you but we might create a new definition let us what you need scan your draft really quick right now is the canonical format but I think I actually ran into a problem here with our current one it is for date and time does it just go down to second no he goes you can have a decimal dot and sub second granularity do you remember what the precision was about I did it go down to nanosecond or was it hundredths of a second it\u0027s dot and then to two digits I don\u0027t know if this would be our NBC case but it would be really nice if we had more precision in the canonical format maybe we have it to have a new you know that might be a non backward compatible but yeah and as far as the counters yeah I I don\u0027t know if I would say both I would just say 64 you know it\u0027s because a lot of representations are string I guess the G RPC case might not be right but it\u0027s kind of I find myself arbitrary the limited when we just pick like UN 32 it\u0027s like okay but it\u0027s a string in most cases right so let me have a bigger well you also generate implementation data structures from this that\u0027s true you know I mean it is true but if you\u0027re going as far as to model the data I don\u0027t know yet so Mike Mike choices bigger is better okay can\u0027t as a contributor so I my first thought was maybe we should have some more types in addition to ours we could have days weeks months years perhaps who knows how these models might be is but my second thought was are you defining these because we talked about the missing duration and I mean are these trying to fill in that gap for a duration well there\u0027s there\u0027s a "
  },
  {
    "startTime": "01:49:44",
    "text": "definition for we don\u0027t have a definition for duration but if you look at real data models if people model a time out they usually have something that is a millisecond or a second so it\u0027s very commonly used to which we have these unit specific types or not like an axis the duration which is a relatively complex construct could do the same and it\u0027s commonly what not people implement I\u0027m just thinking about a model where my duration was something I know a couple weeks or a month it\u0027s like this it\u0027s a it was a larger and it would have been convenient to represent it in terms of that like if you had larger granularities days and weeks it makes it more natural to express these kinds of things yes I mean I mean that I believe is even an ISO standard format for durations that\u0027s out there we could add something to that but I don\u0027t think it\u0027s a replacement because if you if you really just model a time out and you know it\u0027s going to be in milliseconds you would just want to have a number rather than something more complex and so maybe ask them quite first to you what are your thoughts in terms of the expediency that you\u0027d like to see this being adopted like is it something that you want to work on for a while before you know moving towards that yeah I\u0027m so I personally I don\u0027t care so much about adoption no we can leave it this way you can adopt it it doesn\u0027t really matter to me personally I\u0027m one of the guys who doesn\u0027t care all right well how many people have read this version of the draft and how many people think it\u0027s as interesting work like that there\u0027s something that the okay our number fair number for both questions and all right so how many people would like to see this version the document used as a basis for a working group document please raise your hand quite a number and and how many would not like to see this document adopted as the basis for a working document none okay so I guess we could confirm an adoption poll on the list and I mean whether or not it ever gets you know to last call we\u0027ll see so this is this is really this is very interesting case right because basically it\u0027s a standard module for defining types that we\u0027re gonna use everywhere and all we\u0027re basically saying is let\u0027s keep doing that right let\u0027s just keep rubbing that thing and adding more common types that kind of makes sense sure yeah I\u0027m just mad whether the process is too heavy here we want to weigh up just getting the stuff out much more quickly yeah so and that was a joke and actually drops that last point I was really thinking does it make sense to Rev this as abyss or to just have a new module that defines these new types and I think it\u0027s a good experiment "
  },
  {
    "startTime": "01:52:46",
    "text": "going back to Chris\u0027s comment let\u0027s see how fast we can do it let\u0027s let\u0027s just use the model of keep revving this okay I\u0027m all the question is how hard it\u0027d be for us to agree on what goes in there and put on github and be done so and that\u0027s the sort of thing is the the the publication delay is does that help us here at all or is this somebody pushing it through that publication queue a lot quicker but otherwise it\u0027s sort of we just delayed by an extra year experiment okay the other the other option is is we just do a new types module and it\u0027s a new different but let me just just I won\u0027t it I\u0027ve mine\u0027s more ease I think this might prove to be faster so a data point this is the 698 91 is the second version and when the second version came along during the isg processing all the comments were on things we didn\u0027t touch yeah so not on the new stuff they had lots of weird new issues on the road stuff so that\u0027s the fun well I don\u0027t care I mean whatever happens I think let\u0027s see how fast we can run the process on this one yeah rather than doing something new let\u0027s see how fast we can run abyss okay but should we also at the same time you\u0027re trying to look at how to modify these things in a more efficient way outside of that process what\u0027s the way because we\u0027re just having some new tires are you suggesting that we should not be looking at producing RFC\u0027s and maybe okay so I its the ITF and we\u0027re in the business of bruising RFC\u0027s so let\u0027s try it but it\u0027s an interesting point let\u0027s think about it maybe talk to Melissa take the talk outside and we have a few minutes left for the next one and by the way I\u0027ll note that we only made it through like a third of your slides so that was effective and please take a look at the the rest if you\u0027re interested in the topic I walk in groups is Michael from Horry and today I want to introduce a document for young G the mother for even the measurement yes this document basically introduced a John Daly model for ESA a business or policy management so it can provide ability to network management function and you can Joana configure the monetary state a change our natural element and take a simple action when triggers a condition on the system estate and this is document at first introduced in Lhasa a Vida meeting and the warden who was just asked to coordinated ways another document so we had to some update forcibly polished the text and clarify the difference between the booing "
  },
  {
    "startTime": "01:55:47",
    "text": "trigger condition and who this recommendation and synchronize some terms always one already published a talk RFC its introduced participative measurement a fragment Fred Fredman Ranma walk and the way he split eight he went management that yeah I\u0027m not doing to treat their trigger young and another is event young makers a trigger when make it a even trigger loops bow and the NASA document areas is grouping and defines there\u0027s a condition and we also change the two leaves the name to help carry there is a understand oxidize okay this is it\u0027s a models change we split is a condition and defend a title reusable grouping and then it can so says it\u0027s a you in the even more do way it\u0027s just grouping can be used and the NASA document also kind of reduces is conditions okay this is where next table would like to select a commons and improve our solution document and if we it\u0027s good enough I think maybe two are seeking to walk umbrella walking grouped option well let\u0027s do it our sort of standard how many have read the draft any version again so that\u0027s a few how many think that this is an interesting problem we should be working on it looks about the same let me ask the counter how many think this is a something we should not be working on no one it may be early but let\u0027s get the feedback anyway how many think the draft should be adopted as a starting point you want to ask Brooke Wilton so I think there\u0027s a couple of other drafts that seems you\u0027ve roughly quite similar or my understanding was no similar the ITSM idea of monetary for some event and then taking some action I think there might have been two other drafts remember one of them and that one seems to have disappeared but I\u0027m not sure so I can\u0027t endorse I could probably try and find them but I just wonder whether there\u0027s one solution that could cover all of them more or they\u0027ve definitely different things I don\u0027t know work together and by if we did decide to adopt one that\u0027s a way of forcing together although it is true that sometimes authors feel that their solution is now adopted that that they\u0027ve won so it can work either right "
  },
  {
    "startTime": "01:58:51",
    "text": "I\u0027m not sure we\u0027re really going to adopt right now I think we\u0027re just taking it as as input and you know I think exploring those if you could send that to the list and exploring those is something that\u0027s definitely worthwhile before even going to a poll but I would like to see what people think unless but do you mind sending those two to the list that you do you think if I can find them yeah yeah all right thanks so this is just to give feedback to the chairs right now I you know how many think that we should be adopting now it\u0027s less than who have read how many think it we should wait a little bit and there\u0027s a few there as well right so I love mentioned some other drafts so two eight years ago we presented a very similar concepts of the models and we didn\u0027t cut there is no feedback we didn\u0027t know if it\u0027s interesting that enough for the working group so we haven\u0027t continued to march on that side so from what I see here this is totally to placate to that pretty much same concept I think that it\u0027d be great to have you work together and see if you can come up with a consolidated draft if you\u0027re willing I\u0027m asking the owner way so I\u0027m looking for you to say yes you\u0027re interested or willing how to talk to all the coursers we have had a working group design team so a lot of people participated in that the young push design team okay so this is coming out okay I actually did have sort of that feeling that there was some overlap here with Netcom one of the so one of the actions I think will be forward to the neck mod and neck cuff chairs to talk to each other talk to yourself and see where we end up it would be good to not try to reinvent something that is already been good work done on so you try to bring those together that would be really good i I think from this we definitely will not be adopting but we\u0027ll have more conversation and potentially move this document over to Netcom because of this this is an area that I certainly view as gray area between the two groups and we just have "
  },
  {
    "startTime": "02:01:52",
    "text": "to work together and it\u0027s not like it\u0027s a hard-and-fast which one does it as long as someone\u0027s willing to do the work we\u0027re clearly over time thank you very much you want to say something no no you asked me to stay here - you mentioned previous after the first session that you wanted to discuss briefly the timing experiment just to want to do that you think you have time I think we are over okay if you want to make one comment on it that would be great so one comment please provide the feedback you will receive a survey after the meeting and please provide the feedback about what you think about this experiment wave the unstructured time that\u0027s one single message thank you thank you very much I know it\u0027s Monday but we will see you in Montreal Norman "
  }
]