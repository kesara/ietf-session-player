[
  {
    "startTime": "00:00:42",
    "text": "statistics make an argument for savings for taking the user taking the number of users watching a stream and multiplying that by the half bandwidth and ran out of your memory like that\u0027s how much data you should read that traffic you - data structure all in a beer an AMT like compare them all just won\u0027t break we get dropped in it was made by a little pasta that we knocked many quantum an analyst would use all right you actually really - I\u0027m a Nikon outside I\u0027m sorry yeah you had to show that it worked yeah yeah so we\u0027re down the stage "
  },
  {
    "startTime": "00:04:11",
    "text": "the Simpsons going high glad someone [Laughter] showers by okay we\u0027re ready to get started welcome to M\u0026D get to know your neighbor introduce yourself to everyone you know hopefully you\u0027re all meant to be in a Modi here\u0027s a note well you probably haven\u0027t seen this yet but it actually can be read in iambic pentameter yes yeah that\u0027s a fun fact it was written in iambic pentameter please note it well here\u0027s our agenda and I think a lot of the folks in here are going to be presenting so would anyone like to bash this agenda I don\u0027t think we have a whole lot of a whole lot of potential controversies on this agenda okay so let\u0027s get started with the status of the active drafts the first two drafts the Dryad draft jakes triad draft did just complete working group last call it is in the hands of the Shepherd and we would like to thank Tim toon town for volunteering to Shepherd that one the EM cast problems draft did complete work last working group last call with there were some minor revisions we\u0027d like to kind of go through Charlie\u0027s going to provide an update on all the changes that made most of them were textual somewhere you know everything was minor but there are a few additions and let\u0027s decide if we think we need another working group last call for that one based on those last few changes that were made and whenever that\u0027s ready though because it did seem to successfully complete we had enough support for it to move on thank you to Jake for volunteering to be the shepherd of that one next we have two drafts that are in active working group last call so here is an opportunity here\u0027s your opportunity as a reminder to please provide feedback if you support or do not support working group the advancement of these documents please "
  },
  {
    "startTime": "00:07:11",
    "text": "speak up we\u0027re running that last call for the next few weeks but we wanted to run it through IETF so that we could remind everyone in the room that hey here now would be a good opportunity to if you forgot the send hit the send button on your email that you have feedback on these drafts now is the time to do it the last active work draft is the yang models and Sandee wanted me to bring this one up because she is she is looking for feedback as well is this ready for working group last call first what what what what is the Stig or Warren what exactly is the process for the young doctors do we send it to them after working group last call do we send it to them for feedback prior how does what are we supposed to do what\u0027s the interaction state so you can actually go in the data checker and request a young doctor review okay you can do that before before last college okay yeah better cool while you\u0027re upstate I I\u0027m guessing you have the highest person\u0027s percent likelihood of actually have read read this have you read it do you have any thoughts I have read it but I feel like I know not that much get involved with young myself so it\u0027s kind of hard for me and I\u0027m afraid it\u0027s the same problem with most people in the working group they don\u0027t mean know young that well okay and also though no ideally there should be operators so they were saying that\u0027s the small include what they need but but yeah okay so we need more provider input on this one yeah Jake Holland I asked sandy about this because my opinion it was basically if it works it looks okay to me I read it also and she said that yes they\u0027ve been running it and it\u0027s in it\u0027s in testing so I don\u0027t know how to incorporate that feedback into the consensus process but I feel like that is the you know if it actually works for deployed systems then we probably should drop her stamp it and get this out the door see you again yeah I agree you know it\u0027s possible that doesn\u0027t include everything that ideally should be there but it can always if we find stuff that this missing later they can always revise it or you send the model there\u0027s no harm in maybe starting with it just the basics so now\u0027s a good time to request yang doctor review I guess okay we will note that "
  },
  {
    "startTime": "00:10:19",
    "text": "[Music] please go back in that doctor though yes yeah make sure those are all in the minutes yes please doctor the notes so that it doesn\u0027t say the cynical things that we mean other Doc\u0027s there\u0027s the Ambu draft and Jake anything you want to say about this or will this be covered a little bit in your hackathon update yeah Jake Holland I have not implemented this yet but but that is the plan it\u0027s gonna be necessary it will I will touch on it briefly in my hackathon update I\u0027d be happy to take questions about it and I think I\u0027ll have my slot has plenty of time then so yeah please it is I\u0027ll just say it is still highly relevant and will be coming up again so we will start with okay come on put together this slide deck he is not here unfortunately but he wanted Stig would you like to speak to this or shall I good if you want to have been discussing it with him and I also spoke to I am I earlier today take take of the pink X all right I haven\u0027t seen this slide so all right so Empress version 2 was published as an RFC recently and they got UDP port number from Ayane but then it turns out that that port number is in the range used by traceroute on linux and I think on some other UNIX operating systems as well so I\u0027m not sure how much I need to explain but basically traceroute uses like hundred ports yourself but they only got one port a sign from Ayane which is in the port registry the the the port numbers coming after that the next several hundred pores are just Markus unassigned and M Chase was the first application or service that got the port number in that range and the problem you\u0027re seeing now is M trace is actually working just fine but "
  },
  {
    "startTime": "00:13:22",
    "text": "if someone does a trace route what trace wrote does is I think it\u0027s like the first packet has like the lowest port number the next one with a higher TTL has the next higher port number and so on and then you you expect from routers on the path to get an ICMP message back because there\u0027s nothing listening on that port and you can then mark the TTL show that the round-trip time and stuff to that router but if something like M trace is listening on the port then there\u0027s no ICMP message going back and it will just show up as a star and kind of like time out and trace route so the problem here is not really an trace but trace route is sort of broken no I don\u0027t think so there\u0027s just lost implementations who maintains treasurers are just kind of like dead code right now I mean they this this being maintained so I\u0027m not sure you know this it\u0027s been around of course for decades and there\u0027s probably several implementations and some of them are maintained some why not yeah I\u0027m just wondering if if it\u0027s been doing if it\u0027s had this behavior for long enough it\u0027s sort of like grandfathered in yeah so but then it would be up to us so basically I don\u0027t know and can we make sure I enter reserve I mean get a different yeah so I spoke to say anything because first we want to have em face work but then basically Ayane needs to block this yeah so I can come and go that far so I have a patient but Lenny Juliana Jennifer so here\u0027s what I don\u0027t get I mean Windows doesn\u0027t do this windows sends an ICMP echo reply and with a TTL and the important part is it sets it with a TTL and it expects a TTL expired the fact that UNIX is sending it with a TC with a UDP port and a different port what does it matter it\u0027s waiting to hear back what why isn\u0027t behaving the same way which is I can pick out any port I want it doesn\u0027t need to go anywhere it\u0027s the ICMP the TTL exceeded message that comes back took why does this break so the problem is let\u0027s see yeah so this is the question I had for hooman and yeah he wasn\u0027t sure either he said just he was aware of an implementation that this was breaking but to me it\u0027s it\u0027s not clear let them squat on these ports do these ports matter yeah so at least at least I can say some implementations like "
  },
  {
    "startTime": "00:16:22",
    "text": "Windows they believe on the use of single port number but I know for instance on the next day for some reason they use a different port for two different distances Warren Kumari as far as I understand UNIX uses multiple port numbers because otherwise you have to send one traceroute packet wait for it to come back send the next one wait for it to come back if you spread it across multiple port numbers you can fire a bunch of them and get your response as fast as what I\u0027d understood whatever the case traceroute has been around for so long and is so widely implemented according to the unix way that I don\u0027t really think we can say you know all implementation should go and fix themselves there\u0027s that\u0027s been deployed for so long I think we kind of fact I think that a Juniper for example does their trace routes using multiple numbers as an example Simon I think the right thing to do here is be like us we\u0027re gonna have to move and then a sky in a nicely turns block who I spoke to I am in the break here and comment before that or you know I like I have to somebody who knows better but I thought there was also something related when you go through a net and a fire water so but so I think you could Mary\u0027s yeah no I\u0027m sure there are some reasons for this but yeah I spoke to Jana in a break and they were saying yeah it should be possible for us to get a different port number they may need our ad to sort of approve of it or something I\u0027m not sure but but I guess though if you were to change the port number it means that we need to update the existing RFC maybe even obsolete it to make sure that people don\u0027t implement the old one with the wrong port number no no but we need a new RFC ities with a new port number and and then ask Ayane to update the registry rot have been filed I don\u0027t know first thing is filing around but it\u0027s not really in there out that\u0027s not a router yet no em trace works its trace route that breaks now I\u0027m serious we have process to create visibility I would be more worried about making sure they are capability than whether or not is under percent matches the intended process yeah something similar kind of happened in sorry Warren Kumari still something similar happened with home net where there was some advice which turned out to not necessarily be great I\u0027m not saying that that\u0027s what happened here but I think the right thing to do is to file an errata errata can\u0027t be used to actually update an RFC and so it would have to be rejected or \u0027rock document update but we can pointed it and there\u0027s some warning I\u0027m and then at the same time there should be a new RFC like a new draft could move to RFC ready he being like identical to the last one with the string change so we would need "
  },
  {
    "startTime": "00:19:24",
    "text": "a new RFC we couldn\u0027t just use errata and just say I\u0027ve changed the court through that yeah and it should just go through the process really easy especially if the only thing that\u0027s changed is one thing there and it should be already fast you know SAS GRC editor to do expedited processing because it should be a single number and maybe like a paragraph explaining why why it\u0027s unfortunate check on do know how to avoid colliding with the next part which is not comment I guess we can google it I do a man on traceroute and see but yeah the other thing the only thing I Anna\u0027s said this weekend report that you know that they are kind of like using some unallocated ports that traceroute is and they can they can kind of block it internally so they don\u0027t accidentally give those port numbers to others but ideally they would prefer if we can find someone from the traceroute community whatever that can you know sort of officially requests and their full range for trace registrations they can send their know where to send I understand that dianna police yeah booted thugs right yeah but yeah we can just find out all like the maintainer or who lost made a change to Linux trace routes or whatever and ports are within jurisdiction I assume now we\u0027ve got somebody on the beat [Music] all right so I guess that the plan is we will file errata and then we will reach out to Ayane to tell them what\u0027s going on and then we will resubmit a new yeah I guess do you need you need someone to volunteer to write a new draft I guess I guess the old did the Office of the old draft whatever well we\u0027ve got Toshi here and you saw that document from for a long time so I assume you might want to be involved in this one as well so this this should be the easiest revision you\u0027ve ever made to that draft after I believe it was 18 versions or were we in the low 20s it was it was yeah 26 all right well and here I said 26 time is a charm apparently I was wrong okay "
  },
  {
    "startTime": "00:22:34",
    "text": "okay next up is Charlie Charlie are you online I\u0027m here can you hear me barely well let\u0027s see how\u0027s that any better each time you speak it\u0027s a little bit better all right well I\u0027m not sure what more I can do okay again all right we\u0027ll I\u0027m Charles Perkins and I\u0027m here to describe the changes since the last IETF for the multicast considerations over uh Tripoli 802 wireless medium so I guess next slide please or is that something I can do to change the slides now okay all right well so after it goes like after the last ITF and during the discussion in idea there are quite many comments some of them were generated at the hackathon and after that I submitted revision number five on April 15th and requested working group last call uh next slide please so here\u0027s a list of some of the changes there was a new section essentially Jake Holland just gave you the text for a conversion of multicast a unicast and included a MT as an existing solution and described some future applications that would emphasize the need for attention to the technical matters that are described in this document there were several places all along in the text that were a generative sort of mean needed to be more generic instead of referring to specifically IETF conference solutions and so that those been sort of caught more and more over time and I hope it\u0027s old done but it could still be interpreted perhaps from a two specific way sent places but added UPnP universal plug and play is a representative multicast protocol incited the bridging code for people who wanted to convert multicast a unicast and then there\u0027s a lot of bibliographic citations and actually there\u0027s more updates are needed which I\u0027ll get to that a little later and then more editorial improvements and grammatical Corrections the next slide please so that was submitted on April 15th and "
  },
  {
    "startTime": "00:25:36",
    "text": "then there was some more discussion on the mailing list it\u0027s been some really good discussion geoffrey zhang made a comment about i think it was a superuser webpage it had a lot of discussion about the problems in this draft and mentioned some more things that hadn\u0027t been considered specifically about how Wireless failures can really complicate problems with multicast group membership so the way of handling that comment was to update the security considerations and really ended up just sort of summarizing some of the text that was on the webpage the other big change that was done was really there was a lot of comments from Bill Atwood who made a extremely detailed and appreciated you review of the document and he also suggested included including Dryad as a relay discovery a possibility next slide please so in that all those things resulted in submitting a revision number six I think that was done in the early part of July so as I mentioned news hacked into security considerations and also including Dryad at the discovery mechanism and I actually did an English refresher course learning about when to use which versus that and a mouth versus number and a few other things and then more bibliographic updates and editorial improvements next slide please well since then there\u0027s been some more email from Bill Atwood pointing out a few other things that need to be taken care of him plus email from Jay Colin and interestingly enough Jake is arguing that Dryad should not be listed as a discovery mechanism because it\u0027s really useful from the remote side and also a few other minor Corrections on the draft so that\u0027s pretty much it but I have for now the next document I thought I would try to get it out this week but that didn\u0027t really happen and anyway is probably better to wait to see if there\u0027s any additional comments during this face-to-face meeting or let\u0027s say almost face-to-face so I next slide please so that\u0027s what I just said I will produce a new draft quite soon and if there\u0027s any additional reviews oh and by the way I guess special thanks to a-1 "
  },
  {
    "startTime": "00:28:37",
    "text": "Kumari for motivating people to submit some reviews for the draft that was very helpful so that\u0027s it for my presentation and I\u0027ll be happy to answer questions but I just want to mention that sometimes yeah I think you have to be close to the mic because sometimes the echoes in the room make it hard for me to hear what you\u0027re saying otherwise Thank You charlie so I think given the changes you\u0027ve described I think after you get that last that next Rev out I think we should have a brief another working group last call because these are you know some substantive additions so we\u0027ll run another quick last call just so that folks have an opportunity to review what the changes have been made and make sure there\u0027s no objections to those changes okay well that\u0027s fine with me I also just mentioned that I try to be somewhat inclusive in the changes section in the bill in the appendix so you can take a look at that and get a hint about what\u0027s been changed or in kumari that\u0027s batino house if you do another well when you do another working group last call is it going to be one where you expect replies or will Simon\u0027s be taken as consent or how do you want to run it just gloucester was really hard to get any comments i would be fine with doing silence equals consent can can the ad thumbs up that one assuming the ad does not object to that isn\u0027t responsible for this document okay I mean if it\u0027s already gone through one working group Bosko like cherries have the flexibility to say you know this is the changes does anybody object yeah that\u0027s that\u0027s how we\u0027ll frame it yeah please speak up if you have any objections to these changes so so charlie when you do submit it send to the working group just kind of maybe a diff between that that shows specifically so the folks don\u0027t have to Day card but that they can specifically see the new text that was added since the original working group last call and that way it\u0027s easy for people to review and if they have an objection they can speak up okay when was the original working group let\u0027s call me like a month ago it was awhile ago I would say something like the beginning of May okay so then I\u0027m gonna in order to satisfy your requests I\u0027ll include all the changes from drab 5 up to dress 7 sounds good okay well that\u0027s it for me I\u0027m sorry I can\u0027t be there in person and "
  },
  {
    "startTime": "00:31:38",
    "text": "thank you very much of the Medeco crew it\u0027s really very good ok Kyle come on down hi I\u0027m Kyle rose I work at Akamai Technologies and I\u0027m this is a work that I\u0027m doing with Jake that is intended for multicast so I\u0027ll set up the problem oh all right so I\u0027ll set up the problem here so the the issue is being able to authenticate all of the packets that you receive in a possibly lossy stream there we go so in say video delivery for instance which is kind of the target application for this they the the data that\u0027s received has some properties that are important first is of the payloads have a deadline if you don\u0027t receive a particular payload by a certain point then you might as well just throw it away you may as well not not have gotten it at all so in some sense retransmits are not are not interesting the other problem the other big problem is that is that with multicast video delivery there are many receivers so one of the things that TLS relies on for efficiency in its in its encryption is that it only uses asymmetric crypto to negotiate a symmetric key the symmetric key is then known only to the sender and the receiver or you know they\u0027re known it\u0027s known to each peer so if you didn\u0027t originate a message encrypted and signed with that symmetric key you know that the other party did and you know not notwithstanding key exfiltration attacks and whatnot the other problems with with video that are or with with unreliable delivery are that datagrams are lossy and that retransmits are not appropriate because in multicast you\u0027re not I mean how would you how would you retransmit a multicast packet right you\u0027d have to you\u0027d have to have it transmitted to you via a unicast you need some signaling mechanism and you don\u0027t even know who the sender is most of the time so so the the naive solution to this is to sign individual packets right so you have you send you know you divide your video into into individual packets you leave enough room for signature you sign it using an asymmetric signature algorithm and you append that to the packet so the pros for this approach being the naive approach is that you can verify every packet that you receive so big con here is that it\u0027s very CPU very CPU intensive four receivers it may also be CPU intensive for the sender but that\u0027s not the case that I\u0027m targeting because typically the sender is also the sending infrastructure is also involved in video encoding which is much more CPU intensive but the client may have dedicated hardware for video decoding it "
  },
  {
    "startTime": "00:34:38",
    "text": "probably doesn\u0027t have dedicated hardware for doing some for doing signature validation so tesla tries to solve this problem not by using asymmetric crypto but it introduces asymmetry by doing a by holding back the key the symmetric key that is used to sign the packets and releasing it after it expects all the receivers have received the packets that were signed with that key right so essentially as you can see in the diagram here there are three packets that were signed with key k1 there\u0027s a deadline at which all receivers must have received that key and then it releases key k1 and the receivers can use it to verify the packets then it has to use a different key for any subsequent packets this is a this is a good scheme in certain circumstances but it does have some it does have some cons the big one is that it requires weak clock synchronization and while this works well in in controlled environments in adversarial environments you run into you run into problems where the we\u0027re attackers can delay packets used for clock synchronization and and therefore cause receivers targeted receivers to process packets that they wouldn\u0027t otherwise have processed the other the other big problem that we have is that if you try to use this inter domain by using say NTP well even with even with n TS which hasn\u0027t even been standardized yet I don\u0027t know that I as an as an enterprise or I as a as a CDN employee would want to trust NTP as a security mechanism for the streams that I\u0027m publishing so once the keys been released all bets are off and any receiver can then can then inject a packet signed with k12 any receipt to any other receiver that is still willing to accept them didn\u0027t get the the trick of this security thing I mean for an invalid receiver who\u0027s not meant to be able to decrypt this how how does the scheme protect against that if the key is transmitted so this isn\u0027t this isn\u0027t an encryption scheme this is an authentication scheme the the idea is that is that the the publisher I mean and this is not the algorithm that I\u0027m that I\u0027m talking about in the rest of my talk right but the idea here is that is that in order to keep a one of the receivers which in order to authenticate the signature has to know k1 from injecting packets into the stream it can\u0027t it cannot get k1 until after all the packets have been received yes sorry I should have made that I should have made that clear okay the problem could "
  },
  {
    "startTime": "00:37:43",
    "text": "just say that this key is valid for whatever you received when in doubt the previous few hundred milliseconds with something I mean do you need to use like common well the problem is that an attacker that is trying to target you can delay that can delay the packets in a way that causes you to authenticate something that you wouldn\u0027t have authenticated if it were just if it were expected network delay I don\u0027t want to get too far into analyzing this though since this is sort of where I\u0027m going with this is that there are situations in which you really do want a symmetric crypto to provide your asymmetry so one approach that I tried and we actually went to sect dispatch with this year ago was a sign manifest so essentially you send a bunch payloads and then every so often you have a manifest that is signed and this manifest contains hashes of all the payloads that you sent previously so the pros of this is that it\u0027s lots of lots of fast hashes only one signature per you know n packets but the cons are well what if you lose a manifest well you know you can send them multiple times but you\u0027re still going to lose some of them and when you lose a when you lose a manifest completely all of the packets that it\u0027s signed are now on authenticate able and so you may have some huge cap gap in your video the other problem is kind of a conceptual problem which is that the which is that the fate of the authentication information is separate from the fate of the data payloads so you can receive all the data payloads and not receive the authentication payload and that would be a perfectly normal situation to expect on the Internet and in that case all of the data you receive is now useless because you can\u0027t verify it so a different approach is to use change integrity right so here you have a series of a series of packets where each packet contains the hash of the previous packet and then occasionally you have a signature that allows you that acts as the as the trust anchor for that sequence of packets so the pros of this are again sparse signatures you only have a signature every so often and there\u0027s tolerance for signature loss because if you lose this signature you just have to wait for the next one as long as you receive all the packets in the meantime that form a chain back to whichever one you haven\u0027t been able to haven\u0027t been able to authenticate the problem with that is that one loss breaks the chain so so it\u0027s it\u0027s not tolerant to loss in a way that is interesting but it is better in some sense because the authentication information is does share fate in in a limited way with the data that\u0027s being transmitted so a slight refinement to this is to have redundant integrity right so here you have two hashes so essentially every packet contains the hashes of the two prior packets so this "
  },
  {
    "startTime": "00:40:43",
    "text": "gives you essentially two ways of getting to of getting to any packet so you have two chances to get a packet ash if you\u0027d have to lose two in a row in order to break the chain but that\u0027s still not good enough because you\u0027re really just instead of having the loss rate of P you now have a loss rate of P squared which is still fairly high presumably in you know when you\u0027re when you really want to be lost tolerant and this can be a lot more often if losses bursty which it often is where you will lose multiple packets in a row so really what you want is redundant integrity that is patterned in such a way that it is resistant to expected patterns of loss and this is what this is what we implemented so during SEC dispatch last year Eckerd just like out of the blue remembered some paper from like you know 17 years prior that described a solution to the exact problem we were we were having and this is the golian mode of dugu paper this provides a dag of hashes with periodic signatures the the so in in this diagram the the arrows are directed in such a way that that a hash of a packet is contained within the the packet at the end of the directed arc right so a sense so in this case for instance the hash of b0 would be contained within the packet a for right I\u0027m not going to go through this believe it or not it\u0027s a dag this is actually a simplified version of what what the algorithm is actually doing but it\u0027s it\u0027s a little bit complicated to read the paper to understand how to do how to do the construction but it\u0027s actually fairly easy to implement the construction because they almost provide a an algorithm in the paper itself so the pros here that you you always get two chances to get each packet hash but they\u0027re better distributed in such a way that even if you lose both packets that are that contain a hash of one of the packets in the stream you are very unlikely to lose many other packets as well because there\u0027s additional redundancy there are many ways to get from a signature to any particular packet and I\u0027ve proved this with with some running code the cons are it\u0027s complicated as I said and there\u0027s also a variable number of hashes per packet which means that you\u0027re the data that you\u0027re transmitting you must be able to segment it into into variable length pieces which might be a problem for some payloads but not for the use case that Jake and I are working on so the key properties of this are that it has optimal resistance to bursty packet loss there\u0027s a nice proof of this in the paper and as I said it has tolerance your signature loss just like the the other chained algorithms because you can just wait for the next signature to come through one of the other nice features "
  },
  {
    "startTime": "00:43:43",
    "text": "there that it follows on from that is that if your receiver is smart it doesn\u0027t have to authenticate every signature you can send more signatures than you expect the receiver to actually authenticate and it can just skip some of them as long as it as long as it knows it\u0027s going to get one eventually within its deadline so the next steps are our running code I have code that is running now it\u0027s not public yet I hope to make it public in the next like week or two just have to go through the legal department Akamai and then there\u0027s a bunch of design choices that need to be made I put one issue in the in the github repo that would be interesting to get some feedback on I\u0027m about opacity versus overhead so the way that I currently have it implemented it is not possible with access to out-of-band metadata that tells you how long specific fields are I don\u0027t know whether people feel strongly about making it possible even without that metadata and then just in general we need to flush out the draft but I\u0027m curious if other people have if people have questions or if they\u0027re interested in doing this work something like infeasible something like 1g make GCM color counter mode for you know the built-in authentication that comes along with it I\u0027m not understanding the that\u0027s understanding the relevance the authentication comes for free with the crypto we can look at the overall complexity of the system GCM seems to be you know something that that I said is working fairly extremely fast in you know crypto hardware so basically that if I haven\u0027t tried to analyze what it means if you have velocity channel but otherwise the question really is why don\u0027t we just use crypto with GCM because that\u0027s help authentication yeah sorry I\u0027m not I\u0027m not sure how that\u0027s how that\u0027s relevant to to loss right to the issue the the issue the issue with the issue with authenticating a lossy stream is that if you if you don\u0027t include if you don\u0027t if you can\u0027t authenticate individual a segments of data that you receive and you need to have the whole like all of the data in order to authenticate it the right answer faster yeah okay that too okay any other questions anyone interested in using this or helping out with this thanks Jake Jake\u0027s volunteered to help sighs one for the one thing I\u0027m wondering about maybe stupid question "
  },
  {
    "startTime": "00:46:43",
    "text": "again but you know you can do like a manifest as you said those every flight packets whatever with signatures so it\u0027s kind of wondering if you take that manifest of hi packets then they use some redundant coding of that and you include you know parts of that in each of the next five packets or something like that so that\u0027s actually that\u0027s very similar to what Jake is proposing so we were not actually the way that we\u0027re the way that we are intending to use this is not to actually put the video into this payload but actually to use this stream to distribute a manifest a rolling window manifest of hashes of video packets this by the way reintroduces the the problem commented about fate sharing so I\u0027m arguing we should live with that but well it being a rolling window means that you\u0027d have to lose an awful lot in a row in which case you are probably going to run into you know a skip in your video anyway that said I my intent is to run the manifests at as part of the same multicast group on a different port so they they have some amount of fate sharing up in the routing layer but that\u0027s so I didn\u0027t really ask the stupid questions intentionally but if we take them as move that so you should you should take my response as I\u0027m confused right let me take these guys I\u0027m the one with it he the stupid guy the other one without the t\u0027s so the as a proof that this obviously is the best working group YouTube the specialist for new crypto or authentication mechanisms right so I think the best role that this working group would have is basically with anything it produces supports the notion of you know the need the requirement to do something like this because I would say the fundamental reason why you know a fast mechanism for a symmetric transmission like that exists a lot more than multi casting than unicast E right because in in in the in the unicasting way kind of all these symmetric things have a lot of good solutions whereas the asymmetric stuff is you know effectively reduced and then basically here your whole argument would be in multicast we can\u0027t do it in the same way we need the asymmetric stuff so if basically this working group is required to produce something that says you already must do this and then some other working group that really knows what crypto means would basically standardize whatever is needed in this case right but I mean this is not a product called work working group right so and him wouldn\u0027t be what protocol working group either right this would have to go whoever does authentication encryption or authentication encapsulation right I "
  },
  {
    "startTime": "00:49:45",
    "text": "don\u0027t even know what it this is this time but I think we could only create the requirement saying this is a cool thing and we really want to have something like this yeah I think you\u0027re probably right I kind of I kind of skipped part of the skill that I had prepared and I probably should have included that which was which was does it make sense for embo need to take on this work the reason I brought her here was that this is the group of subject matter experts about the application that we\u0027re planning to use it for but do we need to reopen m/sec should I go back to sect dispatch what is you know what are the next steps for this J holin what we took this to SEC dispatch last time and this is where we got the feedback we\u0027re happy to do it again and to open a working group for it their feedback was that we need to get support so that\u0027s part of what we\u0027re doing here is this being the the application experts that can talk about the need for it I don\u0027t know if it has to be like an informational draft declaring a need for it or if you can just show up to m/sec and raise your hand two sectors bachelors your hand at the right time but one of those things might be useful yeah I don\u0027t know the security area well enough to say how they want to run their stuff right in terms of to me this looks like whatever ESP or whatever other stuff is defining you you know form of crypto profile for that that would effectively do this stuff I\u0027m not sure about the additional complexity with the metadata or something but I think it\u0027s very viable for them to say we need to see some interest so the question is what\u0027s the best type of interest we can express right so so this is a this is let\u0027s look to the chairs for guidance on this so I would turn to the ideas for direction but what I\u0027ve seen quite a bit in a lot of work we cross boundaries all the time the interest is coming here how do we show interest do we adopt it that\u0027ll wake them up but I don\u0027t know you know we finally push through the is you know much more feedback on a document with creating your crypto stuff then for all these other documents you\u0027re doing here yeah and advantage of the queue and you\u0027ll get feedback to me it does feel like having this discussion and a group that has a lot more crypto people would be much more valuable okay it seems as though there\u0027s enough stuff yeah that\u0027s easy to shoot ourselves in the foot work this is Craig I just I don\u0027t disagree with you but I think it would frame it differently I wouldn\u0027t say more valuable I would say additional value the use case is just as important they they don\u0027t see a reason to do it we do so together yeah right so you know requirements are clear there\u0027s a solution here that may be enough even getting their sanity check on something is uses the case when we cross "
  },
  {
    "startTime": "00:52:46",
    "text": "boundaries is not often to throw it over the wall and have them do the work it\u0027s just to ensure that those experts get a chance to review our work yeah that\u0027s that item say in every case but that\u0027s often the case yeah so not just review our work that hopefully be involved in making sure yeah what partner review say no this is a lame ID and we got a much much better way of doing this to dance in the racks and we go through the process but there\u0027s a process so I would so one thing I would say is that as I\u0027ve presented it here there\u0027s nothing novel crypto wise there although there are some things that we would like to do that probably would you know probably raise the hairs on the you know the back of Ben\u0027s head if we actually implemented them such as like truncating hashes right how much can we do that and still have a security margin right so that\u0027s the kind of thing where we would definitely need security area input well but don\u0027t you feel that you know the amount of crypto Ryu and I mean there is this metadata channel which I don\u0027t know right so there were these parameters that he said right so I don\u0027t know anybody here who could and that may impact whether you need a metadata channel or whether we feel oh we can get to statically define a profile that will be fine forever and then somebody comes around and says crypto agility and so I mean there there\u0027s a lot more stuff which you know I think if we do it with review afterwards towards the end right we do we do everything working for class call and then core issues come up right so I think it\u0027s fine to get started with this one block requirement use cases one block proposed solution worst case is a scheme slipped in the middle and the solution goes to a working group that does it better right thanks anyone else all right thank you all right Jake come on down okay Jake Owen and I was gonna talk about the hackathon so my focus at this with this effort is about getting receivers deployed that can actually do the ingest so the idea is it is it broad deployment for something that\u0027s gonna implement the discovery because the the new discovery that were that we\u0027ve recently passed last call complicates the multicast application and making sure that it\u0027s going to be viable to get it and the the crypto that were that we believe is "
  },
  {
    "startTime": "00:55:46",
    "text": "going to be necessary for the receivers also is going to complicate the application so I\u0027m trying to merge this into a library and get this and and provide a proof of concept that it can be integrated and in fact go ahead and do some integration on some widely deployed clients to that end I published a Lib em CRX library BSD license I have it running with basic SSM receive and it\u0027s compiling on Mac and Linux and in fact receiving data my intent is to add the empty gateway with Dryad discovery with the local DNS SD discovery so the the you know it\u0027s it\u0027s critical to the use case of deploying multicast that we get that when you can discover a local relay you use it so that a locally capable multicast network actually provides multicast if you just connect to a remote relay you will you will sort of ossify multicast before you can get the actual replication it has to go over the access network that\u0027s my that\u0027s my view of it you know the the place you get the most games is in those fiber networks and in the cable networks where you wear there\u0027s physical bits on the wire that don\u0027t you have to get transmitted because you did it in multicast so that\u0027s what I\u0027m trying to accomplish with this and the other piece is that is the authentication which you know on the internet we have to send over untrusted networks and in in actual deployment it\u0027s going to be critical to get that working that\u0027s why we\u0027ve started this work we\u0027re gonna try and make it run and it\u0027s gonna go into that library with the same API or a small extensions to the API that\u0027s there now for how to do the receive and the application side it will be relatively invisible so at the hackathon over the weekend we did I got it running and integrated in the upstream for the app for the taps reference implementation it\u0027s a Python implementation of taps taps is is working on a sort of replacement API for socket libraries so I\u0027ve been participating with that group and I have now integrated this multicast receive library into that reference implementation it was running it\u0027s it is research code so this is not super deployable on its own but it was heartening to see it you know be successful with the API that was there and I think it does represent an worthwhile proof of concept the other thing is the upcoming idea which is I have a prototype running which uses the same API and runs under chromium providing a JavaScript API which you issue a joint and now you start receiving UDP payloads once we\u0027ve integrated the discovery and the and the authentication this is going to mean "
  },
  {
    "startTime": "00:58:47",
    "text": "that you\u0027re going to receive authenticated payloads and you\u0027ll be doing it whether or not you have multicast capability but if the if the local network does provide multicast capabilities then you would be getting it with multicast so that\u0027s the basic idea this also is running and it\u0027s gonna need this is going to need a lot of work in fact yes this is my to-do list there\u0027s uh the this is not going to be you know done in November I doubt it will be done in April but I don\u0027t know depending if I can get any support I I can type all of this I think I know what to type I think I know how to make this go but it\u0027s there\u0027s a lot of pieces to put together and and before it can really be deployed I think all of this or you know appropriate substitutes that simplify are going to have to be there so yeah if you know any grad students that want some good experience or that you know then I would love to hook them up if people are interested in this I would love to get some assistance on on working this out and I\u0027m I\u0027m I\u0027m gonna start typing myself and I would love for people to come join me for friendly mentoring indeed what\u0027s their carrot there\u0027s it\u0027s a wonderful experience you know what I\u0027d have to talk to him it depends on I don\u0027t know stick you know you share libraries so like pre-loading so that you can have like a pre-compiled existing application using the socket API and then they calling your MT library that is an interesting idea so the socket API is arguably a poor choice for some of this you need to you know I\u0027m using a socket API underneath it of course it\u0027s not really cross-platform it doesn\u0027t work cross-platform there\u0027s different sock hops you have to do to actually issue the join there\u0027s you know you get a um you know if you want to write that that would be awesome I don\u0027t know how to write that one actually open source code look at that kill ago that did something like this for SSM so the application just joined star key as usual but then you have this library it\u0027s really app and kernel basically you\u0027re an Eskimo you join or some other group right so that\u0027s that\u0027s kind of what the the role that this library is trying to fill you do have a relatively "
  },
  {
    "startTime": "01:01:49",
    "text": "simple SSM join API and your you know the the hope is that that the receive side use cases for applications actually can work with this app with this API and that that\u0027s going to be somewhat simpler than the then trying to use sockets that has been my experience with messing with it so far I think it you know as as with all code it will presumably get refined along the way but I don\u0027t know sockets or so like one of the lessons from taps is that if they\u0027re working loop is formed because like three different groups tried to do this not for the more complicated cases of multicast with like extra features but but just for regulars you know ease of use on sockets and ended up deciding actually this is kind of complicated and now they\u0027ve been hammering out of for a couple of years and maybe they\u0027ll have a good API for long please do some great thank you alright thanks a good multicast presence at all the hackathons and yes you\u0027re doing the work of the Lord okay we are Leslie come on down and Glen so the media ops buff there was a media ops off occurred Monday who here in this room attended okay so about a freak ball flies a third of the room and this was the first buff after the one in Chicago was that correct yeah I remember she it\u0027s the first for MoMA okay that was the bar Bob in Chicago I remember that and there hasn\u0027t been anything formal but you\u0027ve been you\u0027ve had the list going in right so even we we\u0027ve been talking about video at the ITF had an informal group over the course of the last two years yeah so since since your cognitive Chicago is kind of overwhelming with number of people in the room we went to a much smaller group throw less formal called the video interest group that\u0027s the median every ITF since then and which has been pretty good as a slob they sort of the the nascent ideas to "
  },
  {
    "startTime": "01:04:51",
    "text": "sort of form and say well what would you work on how would you tackle things and I think we\u0027ve developed a really good community of interested parties both individuals and and organizations that would support the topic space but now it\u0027s time to maybe make it a little more formal and do a little bit more that\u0027s why we called for the media ops both to sort of open it up to the rest of the world and so people who were in the bath have heard this part of the song and dance before so part of what we were hoping to do that was to highlight the fact that there are many video activities that are ongoing at the ITF that don\u0027t actually fit in any one particular place and identify gaps in IETF work in areas of incompatibility with video technology development efforts being carried out elsewhere so for example gran gave a presentation about the the sim Tirek dependencies on IETF standards there was representation from folks involved in the SVA the streaming video Alliance in the room and these are all other organizations that use IETF standards in ways that might be surprising to us yes so on that I for people that live in the world of the ITF they\u0027re probably not very aware of what\u0027s going on in some of the other orgs simp T is a Society of motion picture and television engineers basically they do TV and they do broadcasts they do production they run studios they do all that kind of fun stuff that whole industry kind of like the tell us to all 30 guys by radio and we had sip they\u0027re migrating from a protocol called SDI which is a point-to-point protocol that they get all the gears wired with allows them to stream their streaming move content from sources to destinations in studios and production environments and then ultimately do a broadcast tower or a cable network they\u0027re migrating to the single IP and they\u0027re just discovering IP networks and so one of the first things they did was create this suite of standards called 2110 in their parlance which essentially is how do you do all this kind of stuff we\u0027ve regularly been doing over SDI how do you do over IP networks they learned a lot about you know updating their stuff to make it work in that environment they also learned a lot about IP networks things that worked for them things that didn\u0027t work for them and so they l1 things we presented was this long list of normative references that they have back to us in the ICF and unfortunately the director standards Thomas Powell\u0027s and Mesa was supposed to be at the boss but he had to go to LA for a meeting at the last minute or he would have been able to give you a real good in-depth overview on it but the takeaway there is that there\u0027s these groups are now just like so often you guys did they\u0027re starting to be I\u0027m dependent upon IP networks and so part of the takeaway that up for me on this is that there is this new set of parties that are really dependent upon us and they\u0027re really interested in stuff we do here there\u0027s an opportunity here "
  },
  {
    "startTime": "01:07:51",
    "text": "to fire up some working the ITF and bring these guys in as well because they have stuff they want to talk to us about and it\u0027d be us they used to work successful new work for the IDF but also a way for all of us to make our TV shows and movies that we all love a little bit better and I think Charlie says something he wants to talk to us about I\u0027ve seen really crazy ways on how some of the broadcast equipment has been you know abusing IGMP even the way they documented and their stuff and you know we do have existing working groups where they could have come to like this one or pay more others if they have any questions about the technologies that they\u0027re using so I\u0027m just wondering you know what\u0027s what\u0027s the process by really because we\u0027ve we have adoption of IP technologies and all these different technologies for such a long time and there and always the ongoing pain that everybody would ops it thinks they understand this stuff better so I think yeah so I think part of the problem is that for the people who are working in those groups it\u0027s even if they ever looked at an IETF schedule or at the ITF webpage heaven forfend never would have no idea where to plug in right I mean maybe they would understand while I\u0027m using v6 technology and I\u0027m gonna do it this way I look here\u0027s a v6 working group it was like none of the work items are relevant to what they\u0027re doing so the point because I mean I\u0027ve been help mentoring people as well who came in there somebody asked what the technologies are and then they\u0027ve been asking around with a mentor II smooth no sleep I didn\u0027t say nobody succeeded agree to disagree yeah and University work man these are people trying to get the job done they get really paid to do it they don\u0027t care they find a solution and they go after it they can\u0027t get a spec read and clarified in time they do it the way they want to do it you know I think we agree on that what I\u0027m saying is I disagree on the fact that somebody if they wanted to come to the ITF wouldn\u0027t be able to figure out where to go to because we\u0027re helping them with that so so one of the problems is that you you actually stand up in a working group and you say here\u0027s this problem you get told you there isn\u0027t a problem sort of like now well well specifically to this point you know as me as an IT effort when I go and work with my colleagues in these other groups which I\u0027m a member of simpie and I\u0027m on the board of the streaming video alliance I will tell you I\u0027ve received vocal feedback many a time from people who have tried to come in and engage with us we do have a bit of a reputation of not being the friendliest crowd to open the door and welcome people and part of the idea that behind this is it could provide a safe video a group that understands video concerns and also understands the IGF and could help bridge them into it so how that might work in practice for instance would be hey I\u0027ve got a problem that\u0027s video related that I think such as IP networks okay first step step number two I would like to find a bunch of like people at the ITF who understand this problem space and who would work with me to create sort of an essence of ID\u0027s that "
  },
  {
    "startTime": "01:10:52",
    "text": "could eventually either create work in this space or could get take it over into another working group that\u0027s working on the specific stuff such as mbone d1 fields ideas are allowed to be developed and refined so that they\u0027re ready to be brought into a group like mo D or some other group within the ITF by the way time it turns out to be is a huge new topic for a lot of these video guys who knew right but faith has faced that exact problem how do you make those ideas coit before you bring them forward and into those working groups and I didn\u0027t mean to I didn\u0027t mean to imply that nobody succeeds in bringing their stuff in I think that you\u0027ve you\u0027re identifying that you have successfully helped bring some people in and sort of smooth their their access to getting the right answers and and we\u0027re saying there are some people who don\u0027t succeed maybe they haven\u0027t found you but I mean the point is there are people for whom this doesn\u0027t work maybe the gentleman behind you would like to make a remark hi family come on love Harry stone it works I agree I think this is very much needed I know from talking to customers in the kind of media or world that even a concept like an IP address it\u0027s quite keen or scary to them and they always want to try to avoid a lot of cannae technical details so I think we\u0027re suggesting mix our saying so I\u0027m very useful so in terms of trying to do this this type of work some of the challenges we outlined were the fact that this video work is multifaceted covers a lot of traditional areas no clear single home for it and therefore some coordination would be useful as Clem was just outlining and so we kind of went up in the ops space for the Boff in part because it\u0027s not there\u0027s not specific proposals for developing specific technologies at this point but rather more a set of operational issues that people are encountering and finding solutions or creating creative solutions to address them so in terms of the boff we had about a hundred people in the room 100 something people in the room yeah there are a lot of people there and there\u0027s general support that there is work here that is IETF appropriate a reasonable number of people who are willing to sign up to the mailing list here\u0027s a plug the mailing this is the mop set IETF done org mailing list we\u0027ve just set it up because we\u0027ve been camping out on a different mailing list until now so please do sign up if you\u0027re interested and don\u0027t be surprised if there isn\u0027t yet a lot of traffic but also an outcome is that clearly we were not clear in scoping the problem space partly because this is not a traditional ops group for a particular protocol so we heard that we\u0027re willing to work with that and we will be back with some creative solutions at some point so just from the process are you trying to be working group forming or what\u0027s been of the process steps that you\u0027re trying to achieve next yes this actually this this path was a working group for me in Botha that\u0027s the intent to ultimately form or working group so Jake yeah Jake actually "
  },
  {
    "startTime": "01:14:00",
    "text": "has proposed that we consider doing a taxonomy of issues and in this space to help map out the space for instance I think that that\u0027s part of what we actually have to do in terms of clarifying what the scope would be you know the typical thing for working group is kind of maybe not really it\u0027s more like a consultation group would be you know the bigger scope of what this starts out be right yeah what we really wanted was to do something like an interest group that\u0027s why we were informally calling it a video interest group when we were meeting informally but the problem was trying to meet informally is you don\u0027t have bounds on your discussion right so no charge no charter boundaries and also no possibility to actually answering the question because he\u0027s gone off to take a call shall we move on okay I did what I did want to make one point in the video interest group that we ran for two years and and and the notes from it are online the presentations that were done are online and there were repeatedly we ran basically a little mini workgroup so people did come and give presentations and actually have things hey I\u0027m working on stuff here that\u0027s relevant to the IETF and this is work I\u0027d like to do and we have a kept haven\u0027t say well that\u0027s awesome but we\u0027re not a were actual working group but it\u0027s Austin you\u0027ve got work you want to do so there\u0027s a pipeline so yeah I mean this doesn\u0027t look like a normal working group but I don\u0027t think that\u0027s necessarily a problem right it\u0027s fairly clear that there are a lot of people who want to do some sort of stuff it doesn\u0027t fall into the regular working group type design but that doesn\u0027t mean that it\u0027s not worth doing I think that might just be a signal that we need something else other than working groups I think for now we\u0027re gonna try and leverage it into a working group because redesigning stuff and or something else is a really big job I think there is some sort of precedent for this which is things except dispatch sec dispatch doesn\u0027t always do its own work it looks at things and sins then both other places and that kind of seems like a model that we could have used no I think I think that sounds great and I wasn\u0027t meaning to do with the initial stuff to reject this I was just hoping that nobody would have said that em buddy or Pam have been you know nasty to people coming in from the outside right so because I\u0027m hoping we\u0027re not part of my job was great but really part of the solution and from that perspective if we find a way to you know not force this thing to unnecessarily do some stupid you know to work that\u0027s really just there to and but you sound very right and so that actually brings us to why we\u0027re here because we were invited to come and tell you all about this work and indeed given this this sort of dispatched like "
  },
  {
    "startTime": "01:17:01",
    "text": "structure or intention of the other work we could certainly see we well the mocks might working group might attract people to come in and talk about video challenges we can certainly vector participants to come and take actual multicast issues here for discussion amongst people who actually will be able to point them more precisely at solutions so we\u0027re trying to be part of the you know helpful to other working groups it\u0027s not about stealing anybody else\u0027s lunch yeah because it turns out that you know video and multicast kind of have things in common who knew yes so that that\u0027s actually an you know an observation I don\u0027t have a it seems at times that the video folks have gone taken great pains to avoid using multicast when we when they clearly and they will state we have this problem with it\u0027s a lot of data what a man it\u0027s a whole lot of stuff we got to send it everywhere he\u0027s like you know we do have a solution here yeah so so yeah we would love the you know play role because we\u0027ve been trying to solve a lot of these problems and we\u0027d like to know you know we would love to have better feedback from the relevant groups that would consume it that is this helpful is this not is this something they\u0027re they\u0027re aware of you know we\u0027re were you know working somewhat assiduously trying to come up with solutions and tools to solve these problems so right so I mean this is what I throw up on on slide in preparation for this discussion I\u0027m happy to take suggestions for other bullet points and one that pops mine just now as you\u0027re describing that is you know we might want to make sure to have sort of a standing item depending on the scheduling of you know hey the other working group is meeting later this week here\u0027s some topics should be covered or hey we met earlier this week and this is what we went over this relevant to this working group I don\u0027t I don\u0027t see why we couldn\u0027t do some crossed some purposeful cross-pollination on the agenda for instance and don\u0027t schedule in the same time we\u0027re updating our conflict list and we will definitely add you guys in there I just like that from a co-chair that I see this is completely complementary great great thanks thank you was our last slide I think right yes so thank you for sharing and we look forward to collaborating and cool so first blue sheets has everybody signed the blue sheet there\u0027s only one it\u0027s blue sheet we have a second one but I don\u0027t think we need it I think we can fit everybody on it try to save blue trees yes and Greg did you want to we have a little bit of time left over did you want to give a little bit of an update on beer how things are going and more specifically what we and M bone D "
  },
  {
    "startTime": "01:20:02",
    "text": "should be caring about so I guess what I should have done was like have a slide with the RFC\u0027s and status and we\u0027re moving but I think I want to throw it is I I see sure I mean that\u0027s a that\u0027s a chair update of the group itself but what I\u0027d say looking around the room of people who I don\u0027t see in the beer room each I think it\u0027s time to start paying attention from an ops level there\u0027s a lot of pox taking place out there there\u0027s a lot of discussions some quick too early deployments and I think we\u0027re gonna see a lot of discussion around transition mechanisms goodness so what I\u0027m looking for this type of draft that\u0027s a best practices use cases things that are starting to come out quite a bit so if nothing more pay attention maybe pay attention to the beer list itself use cases would be interesting to take a look at and see if you know it\u0027s well representative of what you\u0027re working on nothing better but ops inputs are always in are valued at the protocol site we can\u0027t just be doing the stuff in a vacuum so pay attention subscribe to the list and come have fun okay with that does anybody else have it no furless come on now wait a minute sir what\u0027s your name I was just wondering if the context was really from M Bundy or from him earlier but so the the the traceroute stuff is also question of the API so I was talking with genuine and so in in the ICMP reply the question is always depending on us how are many information you get back you always get the port number back if you don\u0027t have an API where you get more back from from the payload that so the safest way to get the port number back different for every packet otherwise you\u0027d have to have a nonce in the payload and then the API needs to have sent more so cool all right with that I guess we are done but you can\u0027t leave so everybody the meeting is not over until you know 5:50 so everybody hands folded feet flat on the floors eyes forward and please sit in silence for the next 40 minutes thanks for coming we\u0027ll see you in ETF 106 now actually we "
  },
  {
    "startTime": "01:23:10",
    "text": "wasted actually it\u0027s Thomas pointed out today\u0027s use for building new recruit from Hebert are planted solely to prohibited motion so not not in all cases hands on that money species "
  }
]