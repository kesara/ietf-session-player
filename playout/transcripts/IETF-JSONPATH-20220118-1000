[
  {
    "startTime": "00:00:04",
    "text": "um so hello okay there's glenn well there's greg hello greg oh whenever i think i'm the only one in north america here"
  },
  {
    "startTime": "00:02:34",
    "text": "so kirsten i'm starting to really like the iregx document james we might as well go why don't you uh before i do uh for those of you just joined i'm terribly sorry for the food following up by the original meeting booking i put in the wrong day right time wrong day uh which is why you got that terrible error message so sorry about that um i got to do my usual boilerplate so let me just crack on with it uh this is an official ietf meeting so please know well the usual times all right you you guys are familiar with this but i have to say it um [Music] uh just the australia um are we gonna do what we usually do which is try to take links as best as we can and i'll edit them afterwards and send them out does that make sense it seems to have worked out well previously okay i can do that and i can make some time later in the week to edit them up once available because this is such a last minute booking i'll try to make sure that the body is available if there if it isn't i'll chase me don't"
  },
  {
    "startTime": "00:04:00",
    "text": "go about that um blue sheets we don't have to do because this is a meat echo thing uh jabba scribe we can obviously just keep an eye out there's only a handful of us so it shouldn't be too too bad uh and is there any agenda bashing that we want to do before we get started i thought kirsten slides captured um the essentials pretty well cool um although i've put uh these two i've put the regular expressions in the apps and equals apps and those are largely just placeholders i know cast and you have these in your slides so it probably makes sense just skip over it skip over these and then just let you crack on with it um one thing i would like to talk about towards the end uh is uh perhaps have a bit of a discussion around what our what the working group's thoughts are around ietf 113 future meetings uh and so forth particularly given that the iatf has announced that it will be doing in-person hybrid uh meetings this year with uh two european cities so vienna vienna philadelphia london have been announced so with that carsten are you ready would you like to share your screen or do however you prefer you can share the slides sorry would you like me to do it or i can do that but you have to allow me ah sorry thank you you first have to import the slides in the top right corner and not currently imported uh in the meeting materials is that it there is in the top right corner there is a wrench"
  },
  {
    "startTime": "00:06:01",
    "text": "a wrench and a screwdriver and there you can import the slides because we uh we approved them yes but because this is uh because i've created a new meeting i'm gonna have to uh mess around with downloading the slides uh first and then re-uploading them i guess is what i have to do is that right casting well use the the uh button in the top right corner yeah bear with me a sec i will [Music] uh it says it's processing yeah it's actually translating the pdf into individual slides so we don't have it okay okay so let me try to share them again so um yeah i think you know which day it is um i mean quickly summarize the status um yesterday morning we had 37 open issues yesterday evening we had 12 open issues and this is because i closed 25 of them so some of them had long been marked as can we close this now or something like that"
  },
  {
    "startTime": "00:08:01",
    "text": "um well i tried to summarize them for for this slide set and it turned out we had kind of done them or they were about a part of jsonpath that is not part of the jsonpath base document anymore so i marked those with with another tag which was like revisit afterbase or something like that but anyway i closed 25 because they are not relevant to the current state of the document so there are now 12 um open issues and some of them are marked tasks and these just need to be done i mean somebody has to check all the the abnf and and all that so we probably don't have to discuss it it's just work that needs to be done and probably when it's done then then quickly checked by people in in this group but there's not really anything we can discuss uh today so i have like seven or eight for which i have uh slides so just to remind was there a question i consider this a big success to reduce the open issues to merely thank you yeah before i did this i i had no idea how would i would prepare for this meeting but then when i started to try it kind of deflated nicely so yeah it doesn't mean that we are done but it means that we we have a much more manageable set of items before us and of course it doesn't mean that we won't come up with new issues or that that we maybe even will find things in the issues i close that that do need to be uh done but i think in general the cash is a little bit more manageable"
  },
  {
    "startTime": "00:10:02",
    "text": "question my personal feelings on closing the issues is that we shouldn't if they are not done um i recognize that these are these issues many of these issues are not done because we are explicitly not including them in what you're calling the base document or the the i guess the first draft of or whatever this is um and i i just feel that the the issues should remain open put the label on them sure but if they're not done i believe the issue should stay open yeah i have to disagree because as an editor i have to agree i have to focus on on the issues that are open well you can you can focus on issues based on a github filter that filters out these that don't have the filters out the ones that have a revisit tag and you can find the issues that you want to keep around for the next round using the label i created for that sorry right yeah how do i know wins a little bit but how do i know later which ones of those are done or which ones aren't or uh which ones we decided just not to include that's what the label is for all right to me the issue is still open we haven't made a decision on it the issue is still open we're going gonna come back to it later any of them any of the ones that you marked revisit there has not been a decision on it the discussion is still open therefore the issue state needs to stay open let's take 124 we have made a pretty solid decision not to include this in the base document"
  },
  {
    "startTime": "00:12:03",
    "text": "so why keep this open okay so if we've made a decision not to include it then why do we have the revisit on it because when the base document is done we might want to do an extension document and some people think that this include mechanism is useful so let's keep the revision tag on it [Music] in general i think that the things that are left open are let's just say at this point carsten's best guess at what we need to do before we do go to work in group last call and i think that there were a lot of decisions made there and it's perfectly unsurprising if one or two of us disagree with with one or two of those decisions um and if so um uh please uh bring it bring it alive my disagreement isn't my disagreement isn't the the inclusion in the base document my my decision is the management or my disagreement is the management of the issues i think they should stay open that's that's all it okay so the decision hasn't been made on them the discussion still discussion is still ongoing the issue for all semantic purposes is open this is not semantics this is work and the editors need to be in a position to to complete their work and being confused by tons of open issues that are relevant uh to the current work okay so so maybe we need a label that says this is for the base document or no we need to have the filter can i make a suggestion um"
  },
  {
    "startTime": "00:14:00",
    "text": "it seems like greg is asking for the uh issues which are currently labeled revisit after based on to be reopened yes violently against that okay hold on but uh why don't we just do that after the base is done yes then we're all happy and i sent a link to the list that allows you to look at those issues if you want to so that's what these labels are are good for um so yeah let's do that does that satisfy your concern greg if it happens immediately after we release the base i guess i just i've never seen a github issue i've never seen a github repo managed this way ever in a lot of github issues or a lot of github repos i've never seen one managed to wear where discussion is still ongoing and you close the issue intending to reopen it later just leave it open and label it and then if you if you don't want to see that one you have filters that you can deal with github has all kinds of filters that you can put in if you want to have a base filter okay so it's alright so i don't know i've just never seen it run like i've never seen a repo run like this and it's confusing well i live in a different part of the universe apparently because for for repos that have high numbers of issues this is a rather normal thing to do i've never seen this.net doesn't do anything like this"
  },
  {
    "startTime": "00:16:01",
    "text": "i've seen huge repos that don't do this they leave issues open until a decision is made or or a fix has been made okay since this has already been done um the the discussion is uh perhaps not that useful at this point in time particularly given that we've agreed that once we have a a last call uh working group last call we will go and reopen those issues that are that are so marked um and that should get us back to a place where where greg would like to see well the specific point when we reopen them would be when we hand off the document to the isg yeah exactly okay let's move along then so um absent equals absent that was one of the the items where we ended the last discussion with discuss this on the list unfortunately not much discussion has happened um on the list so the question is when we compare empty node lists in comparison are these equal are these not equal so do we do something that we can imagine as converting them to undefined or do we something that we can imagine as converting them to not a and um yeah that's that's just the device in our minds to think about this so um this device assumes that in in the processing of the expression language we are not limited to json values which we apparently not because we have paths in there so i think this i think this issue is reasonably well understood we understand what we're disagreeing about here um and i might you know last time we discussed"
  },
  {
    "startTime": "00:18:01",
    "text": "this some of us some of us thought well obviously it's like not a number and some of us thought obviously it's like absent and so the idea was we get some use cases and help us help and see if that changed anybody's point of view so carson i don't understand the slide at all okay so assuming that we say that equals returns true for two empty node sets somebody who wants an answer of yes has to write f dot a equals b because that's the semantics of equals and somebody who wants no for an answer has to do an existence test first and then do the equals if we decide that we go for the number answer then somebody who wants to to um empty notice to be equal has to add two um existence tests uh and uh all this with the result of the comparison and somebody who wants know for the answer of course can can use the comparison directly so so i'm confused i think that so just to be clear i i like i i would not want them to be equal if they're both you know just not there so and this is the case where uh uh dot a and dot b neither of them are there um i guess and i only should have to make an in a uh distance test on one right if a exists and a not equals b well if b doesn't exist then yeah but you have to check both uh because uh if you only check one the other one might exist right but if one does not exist and the other does not ex if one exists in the"
  },
  {
    "startTime": "00:20:00",
    "text": "other does not exist nobody thinks they should be equal right right but if they don't both if they both don't exist you still want it to return true in that first line under number two so the first yeah in the first line under number two you're trying to consider all the cases that would return a true for the for the entire expression um so either they both don't exist or they both exist and are the same if you wanted to return true you have to have that full expression for both of those cases well unfortunately uh jason power jason doesn't uh defines undefined this is uh the issue here uh i think i would like to prefer uh set preference on on on the first converts to undefined it's of course it's not much intuitive to compare to not existing values but it's closer to the not a number mind solution i would have to agree that i would go with the undefined with the number one on this uh for net it would evaluate those values um it would return null for both of them"
  },
  {
    "startTime": "00:22:01",
    "text": "because it's dot-net and it doesn't understand that null is an entity um but then it would compare null to null and you'd get it true so from programming other c style languages like c sharp and c c plus plus javascript i would say that one is more intuitive than two yeah well i think the emphasis should not be so much on the implementer of the jsonpath engine but on the person who actually writes the queries and right yeah so for me it's kind of more convenient to only have to test one of them so that's why i have a preference for style one in the end somebody has to implement something in in some cases in any way yeah so what's the case for for not having absent equal absent for the case for number two we we choose the not a number style because of javascript where uh the comparison not a number equals not a number is uh uh false this is oh javascript a lot of weird things in it too that's original right say the engine [Music] can you say that again sorry in ieee arithmetic um not a number does not equal not a number i think yeah and the the reason they did this essentially was that um they changed floating point"
  },
  {
    "startTime": "00:24:00",
    "text": "processing from actually producing a value from actually producing an exception in cases like this to producing a value so to make existing code work right they had to make this uh value anti-social so it doesn't compare equal even with itself but that's because uh that that's essentially that the nan a value actually mirrors or reflects what would have been an exception so that that's a kind of retrofit mechanism and it sure hurts when you actually work on floating point uh numbers that you cannot simply compare to a not a number um so you have to have these these is nan um things so you cannot have a table that that says for instance what do you expect uh because if the table has has another number then you have to check that explicitly so so a lot of code actually looks like the the uh second to last color second to last line on this slide and that's why i really would like to go go back it's not exceptional not to find something so i think that c sharp does that specifically for nan as well but this is this is talking about like property presence it's not talking about numbers specifically right so let me say two things first of all um just to me it seems crazy if i write a test saying you know if a equals b and there isn't an a and there isn't a b and it comes back saying equal you know that that just seems deeply wrong to me having said that i've i've never actually done anything like this or felt the need to do anything like this or encountered a situation so i shouldn't put too much weight on my own opinion that's why i think we were looking for use cases um and and i i still haven't seen any um"
  },
  {
    "startTime": "00:26:02",
    "text": "if other people are strongly convinced that this should come out to be equal i i don't have any basis of experience to challenge that if i have a dynamic and again i'm going back to c sharp if i have a dynamic object and i try to reference a property that doesn't exist it'll throw an exception um and in a lot of languages if i have just a hash table and i say you know x keyed by a equals x keyed by b and they're and neither of those are in the hash table i'm not going to get it true right well you probably get an exception i probably can't accept yeah that's exactly right and then you get to decide how to handle that exception what about arrays with with holes in it sparse arrays if you address a uh well non-existing an element error element with non-existing index or an index with non-existing value what is resulting also an exception it depends on it would give you an exception but it does depend on the implementation does anybody have a use case please does anybody have a use case where they where where a desirable result would be produced by either of these options i can guarantee that if we pick one someone's going to write a stack overflow question asking why it's not not the other way no i was asking for a real use case [Laughter] it would be a bad programming style but we we need to handle it somehow"
  },
  {
    "startTime": "00:28:00",
    "text": "so i think the case one is appropriate so we have a poll we have a polling thing here don't we so most use cases that really can use the the first line of one are cases in which properties of an object default and so you essentially don't have it if it has its default value so if you compare to two objects with respect to this value both will be undefined and they will compare the same which is exactly what what's right but again there are tons of other cases but the the absence means default case is actually covered nicely by one yeah i agree since json is used for serialization or data representation uh and very often defaults aren't stored or aren't present in that serialization then that's a great use case for number one [Music] default value for a boolean and the default value for a number are not comparable i mean since it's json you don't know what it is right if it's not there you might have a schema if you had a schema that tells you what data type has to be then you would have a reasonable basis for choosing defaults well the schema might actually have a default mechanism right or maybe you're just scanning the json representation before you deserialize it maybe you don't have j maybe you don't have a schema maybe you have an object model in your preferred language that you're going to eventually deserialize into that will type information as well and"
  },
  {
    "startTime": "00:30:00",
    "text": "i'm on the fence here i don't really know but for not a number style what happens if you compare not equals if you have not a number not equal to not a number what does that produce i believe also false to tell you the truth yeah so that throws me in the direction of the undefined style because at least the predicate logic holds up a bit better um i think i just i think i just started a poll uh javascript yields uh not a number not equal not a number is true really oh god well it can't be it wouldn't be i 754 so i just checked this in another language and there actually equals returns faults and not equals returns true oh wow so one participant is not raising yeah and either way where do you see the score i don't see the score uh you should be on the everybody's face oh there you go where are six people and no they said i said did not raise hands because i don't think i don't think it should be true but it looks like i'm in a majority"
  },
  {
    "startTime": "00:32:01",
    "text": "so i look like i'm in a minority so that's okay if people really want want to run with that's true then i'm certainly not going to stand in the way so we don't vote around here but i'm going to say speaking as chair that it appears to me that the group is somewhat leaning towards the undefined behavior as opposed to the not a number behavior and should we talk about it some more should we just go forward that way i think we should make a decision and confirm it on the list okay so i i suggest that we uh take it to the list that we're going to uh uh treat these as undefined and consider them to be equal both sides are absent we also need to put examples like this into the uh to be worked out uh example section i i consider this very important example section marked as a task and let's take a note for that okay so that was an easy one now the hot one okay i think the the i think this is exactly the same slide i had in one drive so there seem to be about three ways to handle regular expressions um selecting one existing regular expression flavor uh providing a way to plug in regular expressions or keeping the whole subject out of the base"
  },
  {
    "startTime": "00:34:00",
    "text": "uh document um so uh when we try to select one regular expression flavor uh the the implementation check points out that we don't have a consensus there between implementations so we are in the unique position that the working group actually gets to choose it's not like the the we have a majority that pulls us in one direction or the other direction that of course doesn't mean that we we don't have to follow the principle of last surprise um so we shouldn't do something really weird um in other cases where we had to make similar decisions the the first question that came up was do we want to have the parsing flavor of regular expressions that that originally came from the ed editor where regular expressions were used for searching on a line or do we want to use matching regular expressions and it seems to me that the prominent example for parsing regular expression is ecmascript and a prominent example for a matching regular expression is w3c xsd regular expression now both have their complexities ecmascript is an extremely complex language atmospheric regular expressions my estimation would be if you want to implement this it takes about a month um w3c is much simpler but has a weird thing in it that doesn't make it a lot harder to implement from scratch but which makes it hard to map w3c to"
  },
  {
    "startTime": "00:36:02",
    "text": "the other type of regular expression engine so my proposal here was to do something that that apparently jason schema or people also have uh um advocated uh building a modest subset and um of course in a way that this actually fits with both uh camps uh so i actually uh hang on jason's gaming is exactly script yes but it also you should use you should use a subset of that all right i'm gonna go pull it up because i am very deeply into that uh uh involved in that spec well you actually copied the the modest subset part to to an issue that i closed so i could try to find this now but it would take a while i'm getting there ecma 262 should accept should accept all value all valid ecm 262 expressions yeah and this is one of these should but we know you won't which probably should not be in a specification well it's let's see says implementations of validate formats must accept at least the subset of xms6262 uh defined in regular expressions of the specification which there i think the value for for implementers"
  },
  {
    "startTime": "00:38:04",
    "text": "would be alone by agreed to a certain subset so i think the last point building a modest subset is the best way to go at this moment i i've actually changed my opinion i was i was of the opinion that this was just too hard and that i was um i was in favor of leaving it out but having after having had a look at the irex document uh in its recent form i think i'm also with with stefan here um i think that the value to users of having something there for regular expressions even even basic regular expressions has has a lot of value but i think that there's a big 80 20 point in there and you know you get a lot of value from basic regular expressions and the advanced features um uh you know are much less interesting and i think i believe very strongly that our chief priority in um in writing this document is that if somebody builds a json path according strictly to this document they have a maximum hope of interoperability um and and for all of those reasons my path forward at this point preferred would be to to uh to develop the irex document we should clearly do it separately because other people will probably use it um and and when we are discussing things in iregas we should have a prejudice to throw it out if if it's difficult or complex or is apt to be a source of interoperability problems so uh my suspicion is we end up with you know irex minus minus we still probably end up losing a few things that are that are in there now and i think that would be a"
  },
  {
    "startTime": "00:40:01",
    "text": "pretty good outcome now for that to work we probably can't throw it all at karsten and say okay karsten you have to you know own this we're going to have to support him and do some work on on really really looking at our echo spin detail and making sure that we understand what it says and are pretty confident that what's in there would be strongly interoperable right so what uh i've i've pasted a link to the uh the schema core section 6.4 in the the chat to this meeting and it gives some guidance for schema authors not implementers uh it's not validation implementers uh that this is for but it does give some guidance to schema authors on what to limit to in order to maximize interoperability as far as the requirements for implementers implementers should support ekma 262. it's a soft requirement that would still be okay by me but i think you know that's wow comparing this to irig x ray gaps doesn't have lazy versions because you don't need lazy versions in a matching regular expression this is just confusion in in this document what iraq has is the backslash p construct so you can use the unicode support that that is in your regular expression uh library for instance to distinguish numbers from"
  },
  {
    "startTime": "00:42:01",
    "text": "from digits and to distinguish punctuation that's certainly something that could be discussed but we have some optional tests around that too so yeah i see no problem for certain implementers to implement ecmascript regular expressions as long as they take care about the subset is included which is defined by jsonpath but not by jsonpath but by regex which is and this is a charming uh aspect from i regex that it's also usable by other uh drafts i can tell you as an implementer that i'm not going to implement red regular expression i'm going to use what's in dotnet and most implementers probably will use whatever ex already exists in their framework of course over over trying to um bend over backwards to implement their own thing well of course so i mean nobody is disagreeing so we need to select the common subset so that when everybody just does that um it works the same that's fair you know i'm i've been in this seat i have a strong so back about three or four years ago now we were building uh a product called step functions over at aws which has become quite popular and familiar we didn't think about this you know we just said oh we'll use jsonpath right and and then it turns out that um it just depends the behavior of the product depends on what library happened to be chosen four years ago and it would have been so much better if we had said okay here's a set of regular"
  },
  {
    "startTime": "00:44:01",
    "text": "expressions you can use safely so maybe i'm being overly hurried here but uh are people comfortable with that path forward the last bullet point here in the slide is there anybody comfortable just plus point doesn't make a if it doesn't make our spec too verbose by including that then sure okay so next good thank you greg that leads us to the next question are we comfortable with uh having a separate document and i regast internet draft and eventually probably rfc as opposed to wiring it straight into json jsonpath i mean i i like keeping it separate but my main concern is will we get the right um constituency of people interested um you know if we as jason path working group start this red xp thing will it emit certain other interesting parties you know how do we how do we socialize it how do we draw people in who would have a good input to it so the advantage advantage of having it in a separate document is that we can shop this around with all the people who already have regular expression scars on on their face uh and i think that that's something that we could get very good feedback for another consideration that we should uh make as well as if we're going to do it this way the interdependency we're effectively saying that uh we can't move we can't move to the point of having an rfc until"
  },
  {
    "startTime": "00:46:01",
    "text": "we've got the the regex document as rfc or something like that right i think that's correct yes okay yeah you have to reference the rfc in in the jsonpath dock um i would probably be willing to say that the uh the jason schema folks would be willing to also or would be happy to also include such a document into jason's schema um we've been having some discussions on uh what specific versions of of regex we should be supporting with the upcoming drafts because what we're using is quite old um so there's there could be some support from jason schema as well for a separate document if we start to build the example section we will also include examples with regular expressions and if we do so we we need or we we can reference to that subset which is called i regex and uh and then tell that it conforms to exactly this i agree and i agree that's super important because 95 of implementers don't actually look at the abn f or anything like that they just go look at the examples it sounds like we have a quorum of build an external dock"
  },
  {
    "startTime": "00:48:03",
    "text": "right okay given that i'm going to record that because i i don't know i'm hearing anybody last chance to really disagree with that because now i think since we're making good progress and stuff go ahead should we take this to the list if there's a final sense check not to block but just i think that would be smart yes we should take it to the list but since we're making good progress there's lots of time should we should we argue a little bit about what's in iraq today is is the selection there correct yeah i think procedure wise um we should make a decision now uh confirm it on the mailing list that's different from taking it to the list which means we are not ready to make a decision so i would like to make sure this is captured um then if if we actually go for a separate uh document then right now we have a hole and we could fill this hole by writing a new document or we could fill this whole by adopting an existing document as a working group document obviously i have a slight uh preference here but that's procedurally that's the decision we have to make at some point uh then so i personally i think the readiness of iraqis was even larger than the readiness of of jsp the json path document but uh yeah that's my personal view yeah my proposal would be that we would adopt irex uh 0 0 as a working group document zero zero not zero two are you up to zero two now yes okay the latest can you just clarify how many working groups we'll end up with here would there be an i regix working group as well no no a single working group can have multiple documents there's nothing controversial or surprising about that"
  },
  {
    "startTime": "00:50:01",
    "text": "okay thank you so we may expect people to come along with a specific interest in regex and join the jason path working group to just work on that new document sure okay go look at the http working group my god you know the number of documents they haven't played at any one point is much bigger than one yeah i haven't thank you does anybody object to that you still have to have a formal adoption call if you want to do it by the book yes of course of course this is an interim meeting right we're not uh we're not decreeing consensus but we're going to take this for confirmation to the wg good oh god i feel good about this and thank you so much kirsten for all the work on that to to make it obvious that there is a real thing here we're not just talking about something hyper theoretical here here okay we are a little bit head off sched ahead of schedule but i think we still should try to finish the rest hey kirsten before we move ahead are there any like open issues in ireland that you think would benefit from a little attention at this point because i think we have the time let me check that so the document occasionally uses the word issue and let me try to find that out"
  },
  {
    "startTime": "00:52:02",
    "text": "that is not really an issue yeah i think that the main remaining issue is uh what about backslash p and uh do do we keep this in and uh if yes do we make any further restrictions on that because that's uh for somebody who comes from from a non-ascii version part of the world this is kind of important i absolutely agree i don't think i think it's totally unacceptable for the iatf to do anything that is ascii limited um i would i would hope that the iasg would would kick um which is such a draft um i'm a little bit out of touch with what the implementations do do they have good general coverage of like the uh unicode character classes and so on well all implementations that that are not the original posix regular expression implementation have backslash p now yeah i i i agree but is the is the universe of things you can say on uh backslash p uh well agreed on well the the only two um the current draft is very explicit for with respect to what you can put in a back hp and i think that what's in there is is universally supported by backslash p implementations because as an implementer essentially at some point you have to decide oh oh my god i have to pull in the unicode character table"
  },
  {
    "startTime": "00:54:02",
    "text": "and once you have that character table it's kind of trivial to do all the things that are in in that backslash p syntax it's more taking the giant step to pull in this giant table it's not that big a couple hundred thousand it's less than that's like a hundred and fifty thousand something like that now yeah i come from a slightly different environment where 100 000 is big right okay now i think this is in a good place so so i think we have a mental work item figuring out um what needs to be done to iregas to finalize it to start with i think it needs a whole lot of examples okay so it doesn't look like we really have any open issues here that we have to argue about that i think well there's there's one issue that we haven't really discussed is uh what is actually the syntax we put around those regular expressions so there's probably something like equals tilde and then there is the the question do we actually use slashes uh for the regex but do we just use standard string syntax i would prefer to use standard string syntax so we don't have one more problem uh to work with and also it's it's a little bit of an alert that uh this is not necessarily compatible with existing uh implementations that use"
  },
  {
    "startTime": "00:56:00",
    "text": "uh slashes right you're correct that's an issue um and i think it's not controversial to like the string but the compatibility argument is strong if by using slashes we would get regex just work with a bunch of existing implementations that would be very attractive i'm a little bit more on the side of uh trying to prevent false intervality um so i think that this actually can be argued but i think that that's the secondary consideration okay so i'm just gonna let's just take a note that we need to uh work on the embedding sequence okay anything else to say about this going once going twice that's enough this is very good okay so this has been said a few times um we need those examples and there is an open issue for that labeled as task and this is just a reminder that yes we should make that appendix and it would really be great if people were contributing um examples we can uh put uh in there we still need to find a structure for that appendix so i'm not necessarily suggesting that you put them in as a pull request but sending a simple message to the mailing list here's"
  },
  {
    "startTime": "00:58:00",
    "text": "examples i'd like to see covered uh that that would be really useful prs would be fine too but either way yes i mean if you already have an idea how this should be structured are there um is there anything we can steal i mean are there are there are there good uh example suites out there in open source places or other rfcs where we can go and uh just import them sure they're not i don't think they have a an example section they might but it's most of what you'll most of what you can do is just in my experience schema does generally does not provide examples yeah we do a lot through having an external website understanding scheme understanding json schema is is most of where the learning is done yep okay so i think we should look around and and see if anybody else has provided a uh a set of examples so we don't have to create them yeah we have to be careful that we don't pull in a whole test vector set but really examples that are for human consumption yeah yeah json comparison project of course is a set of examples yeah but that's really more a set of test factors yeah yeah but i mean we could what we could go through that and see if they're only worth worth keeping it's an example source yeah i think i'd like to just emphasize this that would really appeal to working group members to put a little bit of work into this go find some things that because for two reasons first of all um i believe strongly that the value of a spec is is greatly increased by having good examples in it and secondly doing this"
  },
  {
    "startTime": "01:00:02",
    "text": "often reveals disagreements where we thought we had agreement so so getting a bunch of these in here i think would be real value so would it be fair to say that each example should have a adjacent document a json path expression and an expected result or perhaps a single json document followed by a bunch of jsonpath examples showing what results are expected or a few json documents but not one for example yeah let's paste it in the uh the json pointer spec it's got some measly examples down at the bottom i don't know if it's an example that we want to follow but it is an example of something it's uh rfc 6901 yes all right way down in section six yeah so it it does exactly that it gives you the the sample data that you're going to be pulling from the pointer and the expected result yep and to be fair stefan's um original blog post had examples as well oh good we should steal those for sure the example the the examples go to the mailing list or or should they go to a github issue i say post them on github"
  },
  {
    "startTime": "01:02:04",
    "text": "i feel like they'll get lost in the in the emails i don't want to be prescriptive on this because you know the uh per itf principles the mailing list is a first-class citizen but i would agree that in this particular case it would be nice to have them on github the formatting with markdown is much better than the mailing list yeah yeah okay let's move along yeah speaking of uh json pointer uh we still have uh to do in the document right there um that we need to explain what the difference from jsonpointer is this again is something that just needs to be done and this is just a reminder that that we need to do that i'm not aware of anything controversial about that but maybe after writing the text i will be uh people in my experience people get the two confused all the time um i think it i think having something to describe what the different intents are is is quite important cool i completely agree and that's why it's not anyone in the introduction actually not that anybody will actually read it but i think it's important to have it in there but you can point people to it that's this one it should be short right it should not it should address it the issue at a an issue of principle yes yeah"
  },
  {
    "startTime": "01:04:08",
    "text": "we could always add an appendix that explains how to translate between the two which actually actually is rather interesting because jsonpointer loses information that jsonpath has so it's not easy to actually translate from jsonpoint to jsonpath numerical indexes are kind of weird okay good um so if there is nothing controversial there the next item on the list is number 55 which i think is essentially covered but this this was input that that is a year old and i think we we actually have to go back to the web of things people and ask whether they are now happy with uh what what we have um so we have to find the right point in time when we actually do that we can do this at working with last call time or we can do this a little bit earlier what specifically was number 55 i'm looking for here's the url i'll just paste that in that was essentially a statement of interest by the w3 web of things uh project and and a couple of requirements that they came up with yeah but i think this is where i clarified about relative json pointers"
  },
  {
    "startTime": "01:06:01",
    "text": "okay so then see his geolocation proposal geolocation is out of scope for us so i'm not understanding really what they're asking yeah i don't understand the request either well it's taken us at face value they want to use jsonpath and they want us to be aware of that and uh we probably need to to talk to actually find out whether we we are done but they want to do their requirements are they wanting to use the json path in the url like in place of adjacent pointer yes i think i think so does that mean that we have to have a url encoded version like jsonpointer does or do we just say take the string and url and code it and that's your ul encoded jason yeah yeah i'm sorry i was wondering [Laughter] why wouldn't you just do that but this would be implementation specific and not baked into the standard yeah i think i think it's specific to their application more than any implementation yeah they don't want to reinvent json paths but they probably do have to invent the embedding of jsonpath into whatever they are doing that seems orthogonal to what we're"
  },
  {
    "startTime": "01:08:01",
    "text": "doing yeah i i'm not really sure they're asking us for anything [Music] okay there was a review um 10 months ago and we maybe want to ask for a refresh of that review at some point and implicitly we'll be doing that if we go to working group last call yeah so the only question would be do we want to do this any earlier than that i would think not security considerations another thing we have to write so what what do people have in mind apart from the regular expression security considerations which i think are important well given that jsonpath is a declarative the thing that would be the top of i think most people's list would be denial of service you know maliciously craft adjacent paths designed to overload the recipient overload the implementer and obviously once again once you said that then jason then regular expressions come to the top of the list of course nested expressions as well so query expressions inside query expressions inside query expressions those are the two examples that i recall seeing in the in the issue 6901 seems to uh bring reference to um null character unico characters uh and that implementer should handle"
  },
  {
    "startTime": "01:10:01",
    "text": "those and uh trying to summarize the other the top one in 691 basically saying that uh dead end pointers um and the implementers should anticipate those but i think that we've largely covered both of those points already correct i didn't quite get the last point uh i'll just read it out verbatim uh in jsonpointers applications using jsonpoint you should anticipate situation where a reference to an actual json value is not guaranteed which is all of them right i mean yeah so so the worry is that somebody could i'm still trying to figure out the scenario in my head because i i think our semantic is very clear you know if you try and and reference something that isn't there you just get nothing back yeah yeah yeah like i said i think we've already covered these but just thought it would be worth mentioning yeah it's usually easy to to point to security considerations in other arguments so we probably would just say hey look at the ones in 6901 well i noticed that in in json itself in 8259 and this has always been true way back to the very first specification it's always said that implementations may impose limits on sizes and number ranges and and things like that and you know as greg said you know deeply nested queries or something like that it was perfectly reasonable for"
  },
  {
    "startTime": "01:12:00",
    "text": "implementations to defend themselves um you know somebody sends a json path that's three megabytes long so perhaps a statement there that implementations are explicitly allowed to to limit things such as nesting depth and total size of jsonpath and perhaps another one to look at would be graphql they have very because you can very easily do loops referential loops in graphql and make absurdly long queries um that are perfectly valid uh so what they've done is in the spec they've actually said that implementations need to support like a max depth and they have various calculations and stuff for that but their security considerations are fairly robust and might be some reference material where there are implementation limits like that do we specify any minimum values for interoperation and then so so i became specific that would be hard yeah i mean things that would be reasonable in um you know a simple uh event filtering thing where you might be handling very high volumes it would be very reasonable to have quite modest you know limits on that whereas for somebody who's doing large-scale document transform work the minimum value the minimum value is one or zero almost i think it's very implementation dependent i'd have to agree"
  },
  {
    "startTime": "01:14:00",
    "text": "so someone could um sort of turn all the knobs to zero and miss out points of the spec and still claim uh an interoperable implementation good point i mean it's not okay to say well i'm just not going to do reg f at all because you know the maximum went through record for zero um so if you don't expect it that can happen well we could say that turning to zero is not not an appropriate upper limit that might be good enough i mean historically the thing in the the language in json has worked okay in fact in in in in json um it actually does give you some guidance specific guidance such as you know assume that numbers are basically uh javascript numbers which means you know 754 uh float64 um and don't assume you can do any more range or precision than that um and that's useful guidance so if somebody could think of specific things to watch out for um those would be welcome that's given us an interoperability constraint not a security issue yeah in some spaces we actually require implementations to document what these artificial limitations are but i still have all these scars from the profile implementation conformance statements from osi times so i'm not sure i really advocate doing that"
  },
  {
    "startTime": "01:16:01",
    "text": "okay so this is another to do i think when somebody bites down on it it's not so terribly difficult so just one more point on the previous one if an implementation hits one of these implementation specific constraints do they have to fail in a standard way um two two two two we don't really have runtime failures right by definition no yeah so well you have failure to parse and stuff like that yeah sure but once you've accepted path once you've accepted the jsonpath as being syntactically okay that's a really good point glenn because we should in fact if we are going to allow implementations to express these kind of limits we could say that they can only express limits that can be detected at compile time basically um so it would be a syntax error then yes so they'll be handled as a syntax error yeah so once it's got through parsing you're not going to hit one of these random implementation errors later on no defacto you will if you do something that blows somebody's memory or you're running an alarm to function it runs for longer than 15 minutes or something like that you know it's uh interesting yeah so you can always have a 500 so we cannot do anything about that but uh silently failing for instance is uh probably not a good thing because if you rely on the absence that the jason path expression told you uh that that can lead to grave mistakes but nonetheless i've taken note of glen's point here and i think it's"
  },
  {
    "startTime": "01:18:00",
    "text": "correct is that if we're going to allow limits there should be limits that can be detected at uh i don't know if we have a term for this but you know at parsing time right yeah we have well-formed and and uh valid and so on so i think we can use that terminology there right so in this case they would be treated as violations of being well-formed i guess okay duplicates so right now the word duplicate doesn't occur in the document yeah i don't think we ever put anything about this in because we were still discussing it but we didn't ever give license to removing duplicates is what i was trying to say my intuition is that writing the rules for where duplicates can be removed is a big complicated task both to write and to understand and whereas people won't be irritating it's probably the less house of everybody to just deal with it than to try and get these rules right maybe i'm being pessimistic my issue with it from an implementation from an implementer point of view is that if i have i i understand let me start off by saying i understand the there being a distinction between values and nodes um but even"
  },
  {
    "startTime": "01:20:02",
    "text": "if i'm processing a specific value and that value occurs let's say that value is an object um with the same keys and the same values for those keys um if i'm processing that object once i've processed that value i shouldn't have to process that value again i can handle that internally in my implementation by saying oh here's a here's the hash for that object and i don't have to i don't have to process that object again i just go fetch its results and insert it in in here if we want duplication or if we want to filter out the duplicates then i can know to do that but when my clients are or when my users are saying you know we want performance you know it doesn't make sense for me to have to process the same value multiple times whether it was selected whether it actually appeared in the json tree multiple times or it was just selected multiple times right but from this but from the viewpoint of somebody who's writing the json path and then processing the results that come back from you know executing it um at what point is their life can be made better by i mean it depends do they want you know what do they want do they just want the values in which case or do they just want the resulting values in which case duplicates don't really help them do they want the duplic do they want nodes in which case duplicate nodes don't help them but duplicate values could or do they want like the raw selection set of of the query"
  },
  {
    "startTime": "01:22:00",
    "text": "which do showing the duplicates would give it seems like there's three levels of possible output that we can have well as karsten pointed out in the current shape of the document we don't say anything so you would assume that if you haven't put anything in if so if you took if you interpret it the way it is today if you execute a json path against a great big blob of json that produces a result with a lot of duplicates in it you would not be surprised but you might not i would come to you and i would ask the question i would i would come to the people who who wrote the specification and say hey what do we do in this case i would ask the question looking at the document in its current state knowing that this duplication issue is happening i would say what do i do with this somebody create a case for some examples wouldn't it which do have duplicates in the output yeah i think there are a few in the issue the the context is uh not using the term node set except where we talk about xpath so it has a node list and that to me implies that there is no duplicate detection going on and so we we could save this explicitly which probably would help with not getting that question too often but i think we we don't have a very good structure to put duplicate detection points into our expressions"
  },
  {
    "startTime": "01:24:00",
    "text": "so in sql you have something like select distinct which is duplicate detection on values and we don't have that and we could add that but i would be against editing that in the base document if i put two identical selectors in a union selector i get the same value twice do i expect that from the user's view or [Music] should i really get only a single value it's an identical value the notes are identical why should i get two different values of of the same value well because i put it in there twice if i put it in there twice presumably i had a reason having said that i don't really have a strong opinion here but in the next example it's not clear for the user to put to different selectors in a union but you will get the the same note twice and but you only see the same uh value and you might be astonished to where does these two"
  },
  {
    "startTime": "01:26:00",
    "text": "values come from it's i'm thinking of being the person writing the code who which is processing the stuff that comes back and i know if there are two selectors in there my it's reasonable for my my code to expect there to be two things to come back and if they happen to be the same thing is that jason passed a job to detect that or is it my job to detect that i'm just worried about writing the rules you know that that people will read to try and figure out what to we need examples for that i think the dot dot selector will be surprising here but it's not allowed in unions if i remember correctly the proposal is don't uh don't uh remove duplicates in this slide is this correct exactly yes the only thing i've heard said positively about removing duplicates is that it improves performance well it doesn't always because you have to add duplicate detection i was just about to say that so i agree [Music] can we put it in the spec that it's"
  },
  {
    "startTime": "01:28:00",
    "text": "that implementers or implementers should or are required to um have an option like a switchable option and then we specify a do we have any other switchable options because uh start right now starting to introduce switchable options is a big step and one that we should be very nervous about taking it's much more the responsibility of some kind of post-processing to remove duplicate nodes well no i wouldn't say it's post-processing because i would actually take this i would actually remove duplicates as i'm processing them i was like oh i've already processed that i don't need to process it again i could do that down in the you know at the fifth selector depending on how long the map is i think the optimization you suggested greg of having a kind of memento uh pattern and and saying i've already computed the answer to this i'll reuse the result it's perfect because it's it conforms to the the spec without complicating the spec and it gives the kind of performance that maybe your users are looking for it's internal so that's a good approach yeah so you get a lot of duplicates two bad things can happen one is you spend a lot of cpu computing them but if you're smart you shouldn't have to and the second is that you get very large results from applying the json path um and well yeah you know you asked for it right"
  },
  {
    "startTime": "01:30:01",
    "text": "i i think all of these in contrast to the the whole absent equals absent thing i can think of a lot of use cases for all all of these options remove any duplicate values remove duplicate nodes or keep everything and it's really dependent upon what the author wants what the what the path author wants that's why i proposed the option so rather so rather than some being some sort of option thing there would be syntax in the json path for so saying would be self-contained right the json path by the reasons that tell whether to expect uh duplicates or not i don't know about that i don't know i think there's a little thanks for having a global option is not very smart because you need different kinds of duplicate processing if you need it at all in different places so it really would be would need to be part of the syntax like select distinctives as part of sqa yeah as i said you know sql make this explicit so we would need the equivalent really of select distinct in fact removing nothing is uh the mud the most intuitive thing and uh so jsonpath does what what it is supposed to do and a lot more makes sense yes the most minimal effort to do and the outcome"
  },
  {
    "startTime": "01:32:00",
    "text": "uh corresponds to exactly this philosophy so i get the sense that the working group is leaning towards minimalism here which is don't try and be smart about removing duplicates obviously if an implementer can optimize their computation path by not recomputing them that's obviously excellent but they would still appear in the output so so greg i think you're you're kind of the outlier here um but i think what what i think would help is a proposal about see because i think what a lot of what we're worried about is how complex it would be to specify what happens and what to expect um if you think we're overthinking that and there's a simple straightforward way um could you write it down okay i think the most complex bit will be um the the final output and tying that into the the the ordering that we had had talked about previously like node ordering in the output because if you're removing nodes then you know which ones do you keep in the final output do you keep the last one the first one etc yep no no duplicate values wasn't discussed we only duplicate nodes you you don't need to order duplicate nodes they are identical well i mean because we had previously talked about the the sequencing of the output um because we're do you do the the node"
  },
  {
    "startTime": "01:34:00",
    "text": "and then it's children and the children or the children yes yes i remember okay okay yeah it's it's tangentially related to this okay so my my feeling is that at the moment we are probably uh you know absent some new thinking on this we're going to go forward uh i've also heard that we need to make sure that we have examples that make it clear that duplicates can come back from the application of a jsonpath it's actually not not that easy with the json path we have to actually have duplicates so you you actually have to construct examples uh to do that yeah as i mentioned i believe there are some in the in the issue some weird ones where they're explicitly selecting paths that like path ranges that overlap to select the same nodes those make good examples okay we can take down that we have to write examples for that so next one number 21. since mine this is our last chance to to create a different name than union i don't know why we need more description for unions"
  },
  {
    "startTime": "01:36:02",
    "text": "we we merely have a comma delimited list of selectors yeah so that's that's the the thing that took me forever to figure out was that union was the was a common limited list of selectors i was for probably about the first year of this project i was taking the word union to be synonymous with selector and that's what was confusing me if we have defined union uh if we have since defined union as a collection of selectors then i'm fine with it okay if you uh are confused because of uh it may mean that we we indeed need more description but it may also uh be a historical confusion so yeah users simply get it comma delimited list of selectors yeah yeah so so the question really was can we get rid of the word union because that that implies something to people who grew up with said theory and and that's exactly not what it means here oh it kind of is yeah it is as a collection of selectors it it is a union we're taking each the we're taking the output of each selector and unioning those sets together well that's not what it says at the moment it says it selects the concatenation of the lists of nodes selected by the union elements there is no union"
  },
  {
    "startTime": "01:38:00",
    "text": "operation ironically [Laughter] so do you suggest the the naming is uh that could be a better naming renaming of union to something else yeah the word union wakes up the set theory guy in the back of my mind thinking oh they all get united um he's reading this election a union selects any node which is selected by at least one of the union selectors and selects the concatenation of the lists in the order of the selectors of node selected by the union elements and right here it explicitly says huh note that any node selected more than one of the union selectors is kept as many times in the node list that's not all that yeah that's not that so we've actually been quite clear here about duplicates in this case i think we we don't have a clarity problem anymore the only problem we have is that the the term is kind of lagging the clarity that we have achieved yeah i would i would certainly welcome a replacement for the term union i can't think of one myself but this selector yeah the collection i like list list but it's not a single selector in itself though it's it's just a collection of or a list of selectors i'll turn it around it's a selector list that's that i like that that sounds good"
  },
  {
    "startTime": "01:40:00",
    "text": "select the list selector no note list list selector well it's just a list selector you know that's okay i propose a pr turning this into a list selector and we will see how people like it i like selector list because list selector says that so list selector implies that there's one selector and it's selected the whole thing is one selector the the whole thing bracketed by the square brackets is one selector the whole section 3.5 describes different kinds of selectors and the list selector will be one of those selectors hmm it's it's not perfect but i prefer it to union the word union is just so many semantics i i just prefer it the other way selector list because it's the problem with the structure it's in a section called all the selectors and so as somebody said you'd really want to say list selector or selector list selector which right but you can't have more select the list but you're not going to have more than one list selector you're going to have what are you going to separate the list you're going to have a bracket with a single list of selectors that list maybe one this director contains a list of selectors the selector list okay but if you have a list selector then"
  },
  {
    "startTime": "01:42:01",
    "text": "that implies that one of the elements in your list selector could itself be a list selector it doesn't apply which is good can't but we made it so it can't but yeah so because that's true we explicitly wrote a rule saying you can't do that so so i suggest this i suggest that we go ahead and look at the actual um you know make a pr and see how it reads once it's actually in front of us so the the one thing that still needs to be done is that the the slice index which is in the airbnf actually points into the void this needs to be extracted from the slice selector i didn't understand what you just said carmen the the slice index production doesn't exist i would be happy with slice selector i i proposed using uh index because that's that's what the square brackets mean to me it's an indexer slice selector has enclosing square brackets and this is meant to not have those included enclosing spare square brackets so we actually have to take apart the production for slice selector uh into the brackets and the slice index that is inside the slide selector and then we can use the slice index inside the list selector as well right list selector"
  },
  {
    "startTime": "01:44:00",
    "text": "yeah the the disadvantage of of the current selected terminology is that the thing that is in front of the term selector sometimes describes the result and sometimes describes the form of the selector so a filter selector doesn't give you a filter at the end it gives you uh it employs a filter and similarly a list selector doesn't give you a list well it actually does but this is not the one that the selector is about um it employs a list uh to to create the selector so this yeah this is a common english problem so i don't know how to avoid that you could read it in german right well that certainly would be my preference [Laughter] okay i think i think the sense we're hearing is that people generally prefer list to union but nobody's con but if somebody something else were proposed that was better nobody would be surprised so but at the moment the list seems to be the best option on the table the sequence would be another option yeah but then it would we would call it sequence selector yeah and this puts too much emphasis for for my taste on the the sequencing aspect so i think list is exactly the right i also would prefer list list is short and you know to be consistent if you want to be consistent with json terminology you call it an array selector no because yeah no no we have an array slice collector selector and uh that's why we want to keep it away from the data that you're selecting in yes that's why we are using non-json"
  },
  {
    "startTime": "01:46:01",
    "text": "terms here okay okay so um time is running short a bit so let's go to the next one um yeah there is one of the issues that i didn't dare to close but really it's a won't fix uh we currently don't have an automatic commit check for the abn f and we we we don't need it let's not waste time there okay submit can you close the issue so i don't get accused for closing another yeah thank you please please include a summary with your closure yes i think the summary is already in there so the next steps that i would propose is actually processing these issues here uh of course doing doing another sanity check after we have done the the processing and then do the working blast call because that's the only way to get people to actually review review things in detail and we also should send this working plus call to a number of places for instance the the json working group mailing list would be one of those places so we make sure that everybody who actually needs jason path finds out about this so are you suggesting um we're not talking about meetings here not yet but that's the next step for"
  },
  {
    "startTime": "01:48:02",
    "text": "discussing meetings yes so i guess the real question you're raising is are we have we closed enough stuff and settled enough stuff that once the follow-on from this meeting is done we're in a position to go to work in group last call uh i believe so that is correct so yes i agree yeah if we want we could actually do a poll quick poll on the waiting list does anybody believe we are not yet ready for working class call and do the working glass call after silence so my timeline i i didn't i usually use a rose colored slide for timelines because i need to wear my rose colored glasses to to do timelines um my timeline would be that we get this written up within about three weeks and uh then we have a document where we do the sanity checks maybe we need to re-spin this once more uh but we should do the wrecking blocks call uh within february and and preferably early february i mean there's nothing there's nothing left that is rocket science so assuming people can find the cycles to work on it i think this is achievable is there any concentration in terms of the doc multiple documents have you got our regex and jsonpath can they go to working group last call in either order yes i think they should go simultaneously okay well i don't know i'm a parallel processing guy so i try to minimize barrier synchronization in my life"
  },
  {
    "startTime": "01:50:01",
    "text": "is it possible to do them both simultaneously or do you have to reference the regex spec in the no it is certainly possible and frequently done for a working group to fire off a multiple drafts together that depend on each other okay well i regix doesn't depend on groups correct yeah we would need to do an adoption at some point yeah i think we already know that that complicates it um with other working groups referencing other documents in their own uh working groups that are incomplete is fine but there's a timing dependency thing well jsonpath already references the iranix document but the point here is that it would be a normative reference now yeah so so just explicitly we need to formally adopt a as a working group document or a different one yeah does that mean we've got to do a call for adoption yes yeah okay so that sounds like an action yes um does do we need to uh cast and does a new version of it need to be cut in order to have it ready for that call for adoption or do you think it could be done in its current state i think it can be done on its current state okay so uh as chairs we can do the call for adoption yes and i think we should okay action noted something i might pick up later the week"
  },
  {
    "startTime": "01:52:00",
    "text": "oh back to the question about meetings yeah so ietf 113 is in march um in vienna it sounds like we we've got about what six eight weeks until then i'm unsure if it makes sense for us to do another interim before then uh so we have a couple of options uh one of the options is that we do a meeting again at 1 13 like we did with 112. um i know that it's unclear whether or not there'll be a fee waiver or at least unless somebody here knows more than i do um so that will obviously have an indication for some people wanting to attend i know this has caused issues in the past with some people uh i guess what i'm liking fielding from the working group is should we have a meet at 113 um it just just to be clear it's unlikely that i'll be able to attend in person because of corona and scheduling and such uh so whatever it is it will be a largely online affair i presume but just just filling thoughts from the working group what do you all think i'm pretty sure we should try to have one granted that it's probably going to be largely or at least partly virtual um you know the ihf is our hosting organization and when you sign up to do a working group there's sort of an implicit commitment to give people who are attending iitf a chance to wander in and hear what's going on so so now we had the unfortunate experience of the where we tried to do one and it was on north american time and basically nobody showed up um but this is going to be on european time yeah there are working groups that never"
  },
  {
    "startTime": "01:54:00",
    "text": "go to itf meetings and that only do interims like the seller working group so this is this is not unheard of the advantage of going to an itf meeting is that it might be easier to get uh other people pulled in but also there might be a conflict in this slot but which makes it much harder to uh pull other people in and the the advantage of going outside the itf of course is that we don't have the registration fee waiver and so on hassle that that is just a practical reason why people don't show up because they don't want that would anybody here propose to attend in person sorry glenn here is anybody here thinking of attending in person i'm not i'm not i'm thinking but i think it's currently unlikely because omicron will not be done by then so it sounds to me like um the working group is not wildly enthusiastic about having uh a meeting i'm certainly not going to insist james what do you think shall we shall we book it as an online only for 113 or book uh another interim meeting around the time of um around about the same time either before or after i'd say before if we actually managed to do working brush call in mid-february then we have something to discuss in in early march so before should probably be"
  },
  {
    "startTime": "01:56:01",
    "text": "the next meeting okay um the only thing i'm working then is uh draft submission if that's going to interfere when is that going to be uh thank you sir when was that march 7th if i remember correct so maybe we should try and do one roughly four weeks from now or four or five weeks from now third week in february kind of thing we cannot do an interim in the week immediately before the itf yep so that uh itf 113 is 19 sorry week starting the 21st of march so the latest we can do it is weeks starting monday the 7th of march yeah we could look at the week starting either the 21st of february or the um 28th of february no no not february we we are still uh waiting for the working rubles call to complete at that time yep so either we do it the first or second weeks of march so 28th of february or 7th of march or 7th of march so not doesn't explicitly have to be the monday i'll put out a poll like i usually do excellent rich okay we'll do it like that i'll put a poll out leave that as an action to put the poll out i'll put it out probably as part of my racking up of all this the work i have to do for this meeting"
  },
  {
    "startTime": "01:58:04",
    "text": "excellent okay anything else we got two minutes left this has been very useful yep yeah very good fine in that case fine thank you for your time and we will speak again yeah we'll see you on the list okay goodbye today bye thank you"
  }
]
