[
  {
    "startTime": "00:00:21",
    "text": "hello everybody give people a few more minutes to join and then we'll get started"
  },
  {
    "startTime": "00:03:28",
    "text": "okay well go ahead and uh uh get started uh can people uh can people hear me I hope yes we can hear you great always good to check the audio works thank you so this is an open uh working meeting on uh uh detet uh queuing and scheduling uh mechanisms uh let me quickly show the"
  },
  {
    "startTime": "00:04:02",
    "text": "note well slide so that we can get that dispensed with on okay this is this is an iff meeting this is the not well slide uh you're expected uh to uh understand it uh because it applies to uh applies to everything that anyone uh said says or shares in this meeting alrighty so clicking around we want to go back there so as I think I hope I said in the mailing list uh since there was so much structure to the last meeting going to try to uh this one the my intent is to leave a lot of time for open discussion as uh I think we ought to be spending some time figuring out what we would like to do what what what it makes sense to do so this is propose agenda maybe spend uh uh the rest of this half hour on on uh process uh oriented stuff um Pang has a slide deck showing uh the update to scale requirements draft that would be good to go to and then beyond that uh I did a real quick pass over the uh evaluation slides that were done for the last uh interim meeting I can put up a summary slide and we can discuss from there we can go back and put up uh uh other slides from the prior"
  },
  {
    "startTime": "00:06:01",
    "text": "meeting anybody want to bash the agenda okay so consider the agenda bashed um I guess where we are is we've done an initial airing of these these were the six mechanisms uh for which we were able to get material into uh the last meeting um I think uh jinu has had a draft another mechanism uh and he said he wanted to focus on ccore for now and uh did not see any participation from Antoine um don't know what to make of that any pro ESS oriented comments questions um or should we ask Pang to go ahead and uh talk about uh the updates to requirements draft yeah sure sh I share screen let me see if oh gee hang on let's see the button there I may get your slides yeah let's try that okay okay well no that's not what I wanted to do um I got to go there all right hang on I'll keep clicking here we'll get slides I promise"
  },
  {
    "startTime": "00:08:04",
    "text": "okay uh sure thank so I come okay so here's a title slide um not quite sure if somebody remembers where's the magic button on the uh um here to give pen control the slides to requirement DRFT for uh 03 version I also send send it to the main list before um there's only a little changed so next SL please um so it's the proposed change of the technical requirements okay the last one is for the section four is about data plan and requirements um so uh there's a little change to the title in the uh section three the first one is U section 3.1.3 yes and change the title to proide mechnism not requiring strict time uh synchronization and for the 3.4 we change that to be scalable to the large number of flows and tolerate High I ization of bandwidths um so the we have the slid for this section later so I won't really um speak too much about this points and for the section 3.6 we make it clear to that net flows rather than all the network flows and for for the section 3.7 uh we propose the requirement of latency data uh in the case of complex um to according to ch's suggestion and"
  },
  {
    "startTime": "00:10:02",
    "text": "it also wants to meet the proposal of add a requirement or uh evaluation method of support type data um or sync control loops um and for Section 3.8 we just change the third type of flows in the figure to non priodic uh lower latency requirements and change title to support Pro in of multiple mechnisms and for the section four we add some reference to the control controller plan framework draft um so next SL please um so it's uh um changed over a chang of the technical requirements about the titles um about the uh not requiring strict times synchronization and add more words of the tolerate High utilization and last one is supports the provisioning of multiple mechanisms um so this slides can be discussed later if needed so we just go to next slid please okay uh so for the requirement four we think we might have some problems about this requirement and this meing for tolerate High utilization of manway um so we changed some words to uh to explain what it means because uh in the last meeting we may have different uh ideas on this um paragraph or text so uh the words the text now is to uh is that in order to guarantee deterministic"
  },
  {
    "startTime": "00:12:00",
    "text": "Laden and data in this environment the environment is that the flow of the the um band we utilization is near near to 100% uh utilization and it is desirable to provide skillable queing solutions to improve the bandwidth utilization of currently available Tes or any other standardized method and we give the examples uh to reduce the results uh space required by the current method um for example is based on the Q or the cqf um the updated method is uh a type of over provisioning and can be improved with more skillable queing add arms so we think uh this qu is uh to see that based on the existing method um is there any space to reduce uh resource um to um to uh to be more uh utilized of the um band WDS and there are also a comment to add uh some some words is that when the large number of flows with different SLA demands is aggregate to link it is desirable for the cing solution to provide multiple level of the um deterministic capabilities and schedule the reasonable reasons to achieve the optimization of network Z utilization I think this paragraph is to see that to provide different uh methods um or or different uh um configuration um for the different flows um so also to improve the the bandwith utilization"
  },
  {
    "startTime": "00:14:01",
    "text": "um in my mind I think that the method proposed the que method um proposed now um is not intend to solve this problem but some of them can solve the problem so I uh uh I prefer to uh set this requirement to be optional and uh I also want to ask if anyone um has comments or problems with uh um proposed text or the proposed added uh text for the for this re comment Janu do you want to ask the question you posted to chat yes yes I just I just put a text in the chat um when we say tolerating High utilization I think it means that we have to guarantee the Ender latency even in the case of the high utilization you know uh improving improving or um optimizing the Bandu itself or the utilization itself is quite a different problem and I don't think we are talking about that aspect that's my understanding thank you um well so I think that it is to see uh even in the environment of high utilization and the the queing method also can guarantee the latency yes yes for some reason uh when I turned on the mic"
  },
  {
    "startTime": "00:16:00",
    "text": "uh the my voice is delayed I mean from turning on the mic and the voice hearing is quite some delay anyway yes uh that's the that's that's my point uh we have to guarantee even in the case of high utilization that's what the tolerating means but uh the text with the red uh highlights for example um um the guard band thing can improve the utilization I don't think that's the point here of tolerating High utilization thank you okay uh so you mean you have the questions about the instance right I think I think he's pointing out that there are two goals here in fact the text on the slide uh sort of reflects two goals the red text is about improving utilization of the link whereas the paragraph at the bottom uh seems to be about high utilization of the link and perhaps High utilization of the link U mostly by debt net flows yes uh David uh David is correct you mean the tolerating the util High utilization is one thing and improving the band station is completely different thing so we should not confused between two okay you sure maybe maybe tus uh do you want want to explain something on on"
  },
  {
    "startTime": "00:18:00",
    "text": "this point um I I think yeah I had a different point I wanted to make but on this point maybe we should simply clarify that the only High utilization we're interested in is high utilization by the Deb net traffic itself because um any other traffic I think we do well understand that it can simply be in a lower priority um and that net traffic uh can push it aside um best effort traffic um and at worst case we incur the latency of one still pending packet from that uh lower priority traffic so that that's not a distinguishing uh factor between the different mechanisms that we have right they all can be set up in the network to push aside best effort traffic so I don't I don't think we need to uh dwell on on that aspect okay it sounds like a little bit of text revision would be useful here um not quite sure what to propose I'll leave that to the uh draft authors yeah I I think the problem within the Deb net traffic is what what type of utilization for Deb net traffic itself does a mechanism support because we don't simply can add up the um uh the guaranteed bandwidth of the flow to 100% of the links but we also have to take the bursts into account and uh what impact they will have for latency so I think that's a little bit tricky to to get right and maybe we can can start with comparing examples um to to"
  },
  {
    "startTime": "00:20:01",
    "text": "finalize that so T's direct question take a look at the first two lines in black on the slide starting with meanwhile um that look those look like bandwidth lines uh do they need to have be gently adjusted to point out uh uh that bursts uh are also consideration yeah I mean we we we even when the bursts are as small as a single packet and we have 20,000 of flows um these these bursts cannot be ignored right so that's kind of implied but of course it might be helpful to make that more explicit how exactly uh to do that with the least amount of text is not clear to me which is why I was saying that maybe we can um Circle in on this with running through some examples in the meetings as well okay so I think I think the conclusion off of this slide is that some revision is needed um to focus on that the high utilization is by debt net um and to consider Flows In addition sorry to consider bursts in addition to uh bandw okay sure Sean I think uh the bandwise utilization is the uh the goal of the death L traffic and this is the uh important uh um difference between the TDM mechan mechanisms I think uh for the uh use cases uh uh used a TDM mechanism before um the maining requirement is uh to"
  },
  {
    "startTime": "00:22:01",
    "text": "reduce their their the cost so I think uh it's a a goal to uh optimize the B utilization so I suggest to add this uh um requirement U but based on the different uh requirements um between the uh requirement uh 3.4 and 3.8 I suggest to to add this uh test to the 3.8 um to uh support the different uh and multiple uh Qing mechanisms and multiple levels over uh deistic cap capabilities to uh uh optimize their resource utilization thanks okay so peng and turist do you think act all draft author do you think you've heard enough just to figure out uh and propos and uh propose new text we don't need it now but uh does look like some some uh adjustment is needed well I I heard it before um up to Quinn so maybe if she can Quan if if she can provide some example text she would suggest that's always you know a a great help um you know on on the list and I think we can take it in from there cool okay I have okay I have sent emails uh last mon last uh last Friday I will resent it on many list thanks great thanks and and just one one more comment on um the the notion of optional or not right so I think um all of the mechanism that we have have pros and cons and I"
  },
  {
    "startTime": "00:24:01",
    "text": "don't think um it is clear right now which which use case kind of prefers which one so i' hesitate of trying at this point in time to distinguish the requirements by by severity um i' I'd rather think that is something we can take into account in the evaluations in comparing the evaluations and making judgments about them yeah I tend I tend to agree that I believe the exercise here uh that we're looking at is one of uh engineering tradeoffs different mechanisms are better or worse at different things and figuring out uh what makes sense what makes sense to take uh to take forward based on the strength and weaknesses of each mechanism okay any other comments on this slide okay so uh goes next okay sure uh it's the requirement seven bable to large number hubs with complex and for the data and for the routing calculation maybe in the control plan and also gave a explanation of the case that didn't match uh that's that doesn't match um the above three uh cases so for the latency uh it is acceptable when the relationship between the upper BM dat of end delay and home number is lar but is accept"
  },
  {
    "startTime": "00:26:19",
    "text": "is a little strict it is that only acceptable when the dater is in depend uh indep of Hope number otherwise it is unacceptable and for routing of calculation and resource scheduling the and uh uh some of the method can be evaluated directly according to the methods above so uh and so uh they may need more other methods to to evaluate uh itself um yeah I think for the third Bull on routing calculation um I might tone down the linear relationship is expected because I think the real requirement there is that um the necessary computations be tractable and implementable and they might not be strictly linear obviously fully exponential is not going to scale but uh I don't think strict strict linearity is an absolute is uh AB requirement although the language you've got here kind of says linear is a goal"
  },
  {
    "startTime": "00:28:02",
    "text": "so that's not bad but I'd like to see some mention of tractability and implementability in that bu so maybe uh this points is worth to be moved or um I I I would change it I think the real requirement is that uh it is that it can be done it can be done in running code that works okay Chu yes thank you uh regarding the second blood the Jeter so I understand that the Jeter bound is better to be not a function of the hope hope number but the region you give you gave is quite um I would say uh not very persuasive you know the the latency can also be very tight the latency bound can also be tight as well as the GTO bound but the latency bound can be a function of C but GTO bound cannot be the function of Hope at all um I think we have a more concrete reasoning for claiming that I agree on the second bullet itself but we I think more con Vision or explanation I think thank you okay if you could suggest some texts on the list that would be greatly appreciated um thank"
  },
  {
    "startTime": "00:30:01",
    "text": "you um also with the looking at that Jitter bullet with the um incorporation of the raw uh activities into debt net um is there more going on there that we ought to that we ought to be concerned with I'm thinking for example Wireless links may be using aggressive uh FEC that results in some uh some uh some Jitter impacts tus that was uh one of the points I was making in the evaluation and added as an evaluation point which is to um the the the extent to which a mechanism supports um uh non-clock synchronicity um and uh delay uh variation on the link right because those doesn't have to be the the a single point right so the delay variation I think in the evaluation of the Cs qf uh TC qf mechanisms I added as a separate point to I think section three um and the reasons for delay variation on the link physic So Physical propagation latency variation um and and the reasons that that I found was on one hand um the uh length um variation in in wired links and the other one was of course all type of different um reasons on radio links right so one of course being um a lower layer um retransmission um which then if a packet needed to be retransmitted cause for that packet to have a longer latency then the packets not be retransmitted and then Al Al Reflections and all other crazy radio uh causes that uh make make"
  },
  {
    "startTime": "00:32:03",
    "text": "the signal take longer the extent to which they're really relevant I think would best be you know gotten from folks who have worked on the raw side such as Pascal yes thank you so I conquer with what T said but in row it can be even worse than just retries what we think in our discussions is probably we will have to constrain the number of retries uh to ensure that one particular heart cannot exceed a certain Jitter um on the other hand it might be and that's the role of this new entity that that trow is defining um that the path effectively changes and when we say path it's it's kind of a multipath it's not a linear thing right I mean that your packets copies of your packet might go along a certain path or along another path or just pieces of your packets to be reassembled may go over different path and those path May evolve because of radio interferences which show up in a different place in certain place and you have to go around it so yes there would be Jeter I mean the we could signal or identify you know some Max Jetter on some segments of the possible path and so we could bound the Jetter because yes we bound the number of L will bound the time that we can spend on one particular hop so we could we could bound the possible path to get to one point where we can do a tqf or something like that uh but but it's that will be Jitter so that must be enough signaling to figure out which packet that is that that's kind of your discussion in your versions of the"
  },
  {
    "startTime": "00:34:01",
    "text": "cyclic curing and foring um we must be able to identify which window this packet belongs to because CH will happen okay I'd like to do a small separation of concerns here um I think Pascal's discussion of Pascal and tr's discussion of link a variable link delay which of course looks like Jitter I think is completely relevant here I think the path reroute is out of is out of scope for what we need to get done here because we're mostly looking at what are we doing in an individual node where the control plane or other mechanism that selects the path through noes would would would be at a higher level I think what Pascal was pointing to is that similarly to TSN we may have dead net subnets which by themselves are con constructed from multiple uh you know um radio links across which there may be rerouting so it's it's kind of to us a subnet and the reason for variation and latency across that subnet is within that subnet rerouting or alter okay and if you can model that subnet as a link with bounded variability in the latency then I think it works but I but but you really do need to model it as a link as opposed to uh as opposed to uh to pull pulling in the control plane here yeah referring to when that know for each of those could and each of those hubs along those path we could bound maximum Jeter so we can bound the overall work Cas okay um Pascal do you think uh actually pasc do you think you could uh suggest some text on uh variable link Laten see that manifest is Jitter uh on the"
  },
  {
    "startTime": "00:36:03",
    "text": "list yes I I can I can try I can do that yes okay starts you know with row you can have this situation and because of that situation we can bound the individual yeah yeah just please can take so we can bound from a to be we can B the worst latency right right okay yes and and please be careful to avoid dragging in the control plane here the control plane is just the cost of the Jeter but we don't need to yes we we it's mounted but it does but the bound can be quite High because yeah it's for for cqf you expect very little overlap between one window and the next but here you could have like if you if you the really there is a faster R taking place um yes there could be confusion between Windows which take different place path consecutive Windows which take different path okay any other comments on this slide all right one more okay uh this one uh it is simple that we just change CH the Ser type to non perod um periodic and lower latency requirement so just change the name to make sure uh uh it's different from what uh T proposed but it's just about the name so and also want to ask if anyone has comments on this okay uh maybe I I need to explain more"
  },
  {
    "startTime": "00:38:01",
    "text": "on this figure uh it's just two um we have um three uh three types of the D flows maybe um the first one is industrial T tip Jer and has hard latency limit and also for the uh industrial flows there's hard latency uh limit but there no that uh applications like cloud gaming or others U XR uh it has a lower Laten requirement of the uh datat but it also has the requirement for the bonded latency and the test in the so we just okay haven't not hearing any comments I guess this is okay [Music] okay go ahead when we say lower latency it means um it means very small value so I understand that you mean lower requirement right reduced yeah yes uh yeah I think in the old version it is a relatively lower lense requirement yeah I I would like a little more explanation in the main text thank you okay thank you Pang are when you say"
  },
  {
    "startTime": "00:40:02",
    "text": "lower are you intending that to be with respect to best effort traffic um now it's lower requirements than the first two typ I mean not so hard yeah okay needs a uh needs a different needs a different word words perhaps less perhaps less tight latency requirements I'm I'm not sure ISU for hard ISU can you get closer to your mic you're not coming through okay can you hear me now yes that's better okay uh so the first two excuse me for the first two types it says the Hardy limit so my guess is when we use hard then something like a soft is expected so uh the red font says lower latency requirement actually I guess it means the lose lose latency requirements so maybe we Lo and the stct or the hard versus So Soft something like that yeah that's just a wording thing maybe loose and strict is more more the more appropriate here I don't know or looser but yes that that that sounds like a really good suggestion thank you can I um uh make a"
  },
  {
    "startTime": "00:42:04",
    "text": "suggestion um we do have uh the GitHub and the GitHub has a nice way um to open issues um so could we try to use this on this document as well I I I feel that the more you know small issues we're bringing up the easier it is for for people who raise them to make sure that authors for the working group are taking care of them well by you know having such a better structured mechanism than hoping that the notes will all carry that over uh it would be a good idea although we probably ought to if we're going to do that probably ought to be an email to the list pointing from uh some of the uh from one of the authors of the draft pointing people to the GitHub and how to raise issues so that uh there's a connection between the issues being raised and um a promise from the authors uh to to use that for uh text proposals okay anything else on the requirements drap we've run a little over but I don't think that's a problem okay Pang thank you very much hope uh you've taken notes on what we've talked about okay thank you and uh anyone if you want to propose some text please remember to um send it to the Min list and we are we expected to update the draft before the cut off it's about only"
  },
  {
    "startTime": "00:44:05",
    "text": "20 yeah that would be good and speaking just as an individual here as I can't claim to to channel the working group chairs on this um a discussion in Prague about uh working group Last Call on this draft might be appropriate I mean sooner or later we need to declare Victory on this and I think a lot I think a lot of good changes happened from these meetings okay yeah okay thank you all right okay so rest of this is sort of discussion around uh the evaluation let me go put up a couple of slides quickly to to to give some idea of where we are and then I'll just simply open the floor for whatever people would like to suggest so first thing is to put up a reminder of what we initially concluded about uh the TSN uh mechanisms these are ones already exist and we basically concluded um and some of these Reber some of these T been renumbered 35 and 36 have been swapped in uh more recent versions of the requirements draft we basically concluded that um the two the two scalability uh criteria a large number of flows and larger hops with complex technology were the places where we had visible opportunities to do better okay so having looked at that let's go have a look at um and this is this will contain mistakes as I put this slide deck together very quickly um"
  },
  {
    "startTime": "00:46:00",
    "text": "o o over the weekend um hang on I want that one just a minute I need that okay hang on there we go that one um so this this was I simply went over all of the slides that um that that been been uh posted for the last meeting and just did a summary and the good news is here's the scale here's the first scalable large number of flows we have uh multiple mechanisms that said yes and large number of hops multiple mechanisms said said uh said yes and with that happy to take comments suggestions what do we do next Carles go ahead so I I had a um an updated evaluation slide of um the TSN mechanisms in the slide deck for uh the cqf and glbf ones right so and and and that particularly added um the the negatives on these points uh sub points that we're um still doing right so for example the the lack of um supporting um uh clock drift uh in um in in cqf which which was solving in TC qf and CS qf um and uh link VAR link propagation variation which we just discussed right so those are the additional main points I remember there might have been other detailed differences right so"
  },
  {
    "startTime": "00:48:01",
    "text": "um I I don't think I would agree to this initial summary to be what what I would feel to be an appropriate final summary for the TSN evaluation um and I guess maybe I need to merge this slide or Pro suggest an update to this slide based on what I had in the uh in the slide deck I presented last time okay well this this this slide is actually not the TSN slide uh here let me let me quick go grab summary yeah okay right this this is this is um the new mechanisms yeah we definitely this has the additional right I don't think this has the additional points that I was putting in right um and the let me me try to compare this uh so I think the additional points need to be reflected in the scalability uh requirements draft well remember that 341 and 342 were already you know from I I think Yu when she initially did the TSN evaluations a split of three four right so I think it goes either way right so there may be some things which really need to be better written in the uh in the requirements document but other uh wise it can also be sub bullet points that are um taken from existing text don't have a problem with that I just would like to make sure that what we what what goes up here as evaluation points um is is mat is is is matched uh in some reasonable fashion to the requirements to to uh to the requirements draft of course"
  },
  {
    "startTime": "00:50:00",
    "text": "um yes I have to to that side of yours and and and see how I how how I would think um what what may be uh Missing there um um do you want me to try to find that slide you referring to from the last meeting yeah that was the uh uh the slide deck that I was presenting all right which has actually all righty has 20 slides in it um ah okay here's okay I okay I found the slide hang on a minute I also need to um I need to tell PowerPoint to be nice to me today I need to bring up your slides for comparison okay um give me a minute I will put the I will put the template slide up all right so what I need to do is drop that and so I think this was was this what you you were proposing for the uh the uh the new template slide uh sorry give me just a second go back to that window yeah so that was that was it and then obviously the um the filling of that with a different mechanism I'm just so let me try to bring up so compare that with the slide that you had um I was working off of uh U's uh template that we'd start using for uh the for for the TSN 31 32 31 yeah so so primarily I was breaking up 31 into the subsections so that's not new text that that's just um good the the the sub bullet items one two and three so uh"
  },
  {
    "startTime": "00:52:03",
    "text": "then uh 32 is unchanged so then then I was uh suggesting to add this uh propagation Jitter that we just discussed in the context of raw and other links as as another sub bullet item to 32 33 is unchanged 341 and 342 are unchanged I I think I I had some additional thought on the evaluation of the TSN mechanisms there not quite sure 35 36 um yeah so they they changed the order um 37 is unchanged and then 38 was grade out and I was interpreting um uh we were just showing from from the draft the different um traffic classes that we wanted uh DEET to be able to support and the strictest one was the tight Jitter um and uh the the the the industrial traffic that needed uh tight Jitter support so I was in the same way as jizu was doing it for 34 I was interpreting that as a requirement from 38 requirement number one but if we want if if if we if we feel that we should more explicitly put that into text um in the requirements document as well um that's fine but I was using the same Freedom as 341 and 342 was done previously at 341 and 342 there was text in the document um it sounds like we definitely need to make sure that we get the single thought propagation jit in addition to a raw if memory serves power line networking uh has some uh variable uh link propagation delay based on heat stretching"
  },
  {
    "startTime": "00:54:00",
    "text": "cables yeah yeah so so but that is 321 so that is clearly a new requirement bullet point whereas in 38 um the section does talk about the different type of traffic classes and it's it's kind of a question I mean the question is how do we how do we formalize the evaluation sheet going forward because right now we're doing a a little bit ad hoc with with which is fine for the time being but please propose a [Music] process so I guess the question sort of hiding in there is whether uh the folks working on other mechanisms would be comfortable with what's been what's being shown here as the new and improved uh uh uh uh template for recording uh how the new mechanisms are doing against requirements it's another it's it's it it's another round of slide work man and we don't have to do it right now right I think what what we need to do is to get to a point where everybody agrees that we have a complete evaluation sheet yeah and actually we we need to get beyond that because the real job here is to try to get to some initial I'm"
  },
  {
    "startTime": "00:56:01",
    "text": "going to say suggestions I'm not even sure I can do recommendations out of here um some hang on let me go get uh what I'm thinking about here there it is some uh suggestions about um which and it might be multiple which one or ones of these uh new mechanisms um it makes sense it makes sense to take forward ultimately that's going to to be sorted out in the work group as a whole but some suggestions out of here hopefully based on uh requirements discussion um would be helpful uh jungong go ahead can you hear me yes okay thank you uh I have uh one question or concern on the uh evaluation slide uh evaluation template slide there is there are two let me go get let me go get that hang on here we go go ahead yeah uh 3.2.1 uh it says uh new mechanism must or should shall support single hope propagation as C uh I'm not so sure about this uh single of propagation G is this single H propagation T meaningful to the end to end uh I'm not so sure I mean that the uh"
  },
  {
    "startTime": "00:58:00",
    "text": "certainly uh our concern is on uh end to endend CER C of uh de net flow end to endend flow um so uh is this coof CER or single hope propagation CER is it meaningful to the end to end is it uh my my opinion uh is uh uh this is not so meaningful because end to end cter uh is not the summation of all the poop sitters along the path is simply it's not just summation so uh uh yeah that's my concern yeah okay thank you would that requirement be better expressed as tolerate uh um and there there were two examples given of links that have variable propagation delay one was uh Wireless links that are using uh FC or retransmit and the other is power line links where the propagation delay uh can vary based on temperature due to Cable stretching so would tolerate be better than support I think so the tolerator is a better word yeah and we use tolerating 342 which is isn't so much that that this is a something a feature we like but something that that that we need uh we we need to deal with is just before we do anything and junong did you want to talk about 381"
  },
  {
    "startTime": "01:00:15",
    "text": "also it's uh 3.81 um I'm okay with this for now uh but uh you know I'm I mean uh once uh uh text uh is available I might have uh a different opinion but the uh uh for now it is okay to me okay thank you yeah and if I recall Ping's last slide correctly not all detet traffic is going to have uh um that tight that tighter control Loop um David Janu go ahead yeah thank you um yeah uh so there is there are two new requirements 32. one and 3. A.1 I think I think 3.8 is not about the scalability itself so we are scaling that net and we are we are considering the requirement M for the scaling itself three eight is about the Jeter and Jer itself so we should support tight Cher yes and we should support tight latency as well but we do not specify that explicitly in this requirement right uh that's the that's because the jiter itself and the latency itself is the two two basic requirements of the the working group itself I"
  },
  {
    "startTime": "01:02:00",
    "text": "think so I think 3.8 is quite unsuitable in the scaling requirements that's my suggestion and the 3.2.1 um it is about tolerating the propagation tter um yeah I understand it is a it will be better to support or tolerate the propagation gter but I'm not sure it is that important in scaling um for example propagation delay itself we should support a larg propagation delay but according to the larg propagation delay the G will be increasing that's something for sure I'm not I'm not so sure why why we should repeat the same thing here again uh I so I suggest to merge three that2 one into 3.2 I think the current statement is is is enough that's my suggest thank you but but sorry if I if I if I may have a Q&A on on on what you were saying because I'm not quite clear on that 32 itself does not talk about um links propagation Jitter that different packets over the same link experience different latency that is not covered by 32 and we obviously have a lot of links that do not have such propagation Jitter and we we also have I think all the TSN mechanisms built against the expectation that there is no such propagation Jitter so I think um if we were just doing a single point 32 and we're saying no uh in all the TSN"
  },
  {
    "startTime": "01:04:02",
    "text": "cases on that point because they don't support the propagation Jitter well or at least the the cqf and test right so obviously ATS would would support propagation J latency Jitter right but I I think we're not getting a good enough evaluation um if if we just made it one evaluation criteria as opposed to two which this slide is proposing J go ahead yeah my point is that yeah we can list all the necessary requirements that we have to tolerate but it can be hundreds of them so I think the current evaluation uh platform itself is quite uh Broad and covers almost all the aspects of the scaling um I'm not so comfortable uh expanding the tablet um too much and that's my impression it's going hang on let me get in here please I would one of the things that just happened here is that we've we've uh merged uh the raw efforts into Deb net and I I lean towards adding some explicit text uh for uh tolerate single thought propagation Jitter because a lot of the wireless links will exhibit propagation Jitter because they can't repeal they they can't repeal the laws of physics uh the flip side though is I don't know about 381 in part because after tus you proposed this we"
  },
  {
    "startTime": "01:06:01",
    "text": "have text that just showed up this meeting hang on let me go find it um way too many windows here have to make sure I grab the right one um I think it's I think it's that one let's see we have Texas sh up this meaning that basically said uh that the tight uh Jitter and sync control loops um fall under requirement 7 and that that's new text that wasn't available when you put that when you put the template when when Turles put that template together so as I said I I would I would definitely lean lean towards adding the um variable variable uh propagation delay on links primarily because raw has been added to our scope but it looks like this new text um merges the uh uh or covers uh the gener in control loops under seven and and I think that that might be then 371 or something instead of 381 that's fine yeah yeah no and and with respect to what what J was saying in terms of there may be a the document that we have mentions a lot of um details right and I think what we're obviously trying to do is find the smallest subset of the details that allow us to sufficiently distinguish the pro and cons of the different mechanisms right and and that's why I I feel that the 321 for example is a crucial distinguisher between you know"
  },
  {
    "startTime": "01:08:00",
    "text": "the existing TSN mechanisms and uh the proposals that we made for that net right um how how we judge the different evaluations in the end that's that's a different question but if if we don't if if our evaluations are not able to highlight The crucial differences um then I think we've done Mis mservice in the process I would I I take a a my thinking runs along a different but probably complimentary path which is that um with detet now encompassing uh the the uh the wireless links um that were formerly uh in the separate raw effort um I think that's enough of a change uh that it makes sense to introduce um a requirement that has very strong Affinity to those links I'm n nervous about um the evaluation criteria being a moving Target um we've been working with this scalability requirements graph for quite some time and I don't like moving the goalposts but I think the uh addition of the raw efforts is a reason to move at least at least to add the add the 321 goal and i' hope to keep it limited to that in the hopes of get of of getting somewhere uh in the near future I don't think we're moving the gold posts on the things that we understand right I think the further we're going through the process um the more we may may may start having a better understanding of of of specific details and these these these bullet points 321 and 381 I've I've been talking for them for for quite a long time already right so they're not particularly new we just have process right and I don't think the I don't think 381 is controversial I think the the only thing we're busy having discussion about it whether 381 or 37 something or other uh I do think 321 is is new to the scalability requirements draft and I"
  },
  {
    "startTime": "01:10:01",
    "text": "think it's fully Justified because of the raw effort yes okay Turles and I been having interest critic dialogue anybody else have have any any useful comments all right junong go ahead it just question I mean the then uh text for uh this new requirement uh of 3.2.1 uh who's going to prepare the text for for this requirement is there any uh proposed text already or turist do you want to take a initial attempt at sending text to the list and see where it goes or maybe we could nominate Pascal being I opened an an issue on the GitHub um and yeah would be would be great if Pascal the if you Pascal if you could if you and Pascal could uh do conspire Perhaps Perhaps in private email come up with some initial text that that would be good I'd very much like if Pascal is comfortable with the text I'll be much more comfortable that we've got the uh the wireless links that are the motivation here cover"
  },
  {
    "startTime": "01:12:01",
    "text": "okay the then another uh question is that the text for uh the next uh second uh new requirement uh which is 3.8.1 uh uh is the text is actually what you've seen from uh pang's uh slide right yes and that was uh s yeah yeah let me go find that I'm sorry me go find that text it would be hang on all right just a minute I'm having trouble finding the window I want uh it should be that one right I believe the text is going to start from here and I think I heard some comments that this is going to going to um uh go going to need some editing uh to pull this right apart from apart from this point right right right if you or uh or J knew or anybody wanted to propose how to rewrite how to edit this Tech edit revise this text list I think that would be good okay we really welcome on that on that okay thank you thank you okay the um evaluations that that that I was presenting last time there was also for the existing text of section 3.7 um you know a uh difference in"
  },
  {
    "startTime": "01:14:03",
    "text": "interpretation so um I think the prior evaluations were always saying 3.7 um is something we cannot evaluate against the scheduling mechanism itself um because it's it's it's not scheduling mechanism related I was trying to make another argument and I made that in explanation and then in I think um slide 10 of my slide deck I made that comparison between the TSN and the dead net mechanisms in this case specifically the cqf ones um and and the point was that um this may be Network related um but a lot of aspects for scalability that we have like um the um SE routing traffic steering um are things that we can do hopefully you know in conjunction with all our mechanisms but TSN cannot do this right we cannot we cannot simply take a large service provider Network um make it a layer to TSN domain and called success right so when it comes to comparison of TSN and datet that's a core distinguisher right so and we can also not simply try to say oh wait a second we're going to take large Network domain every link we're doing a separate uh TSN domain and then we're doing segment routing for a large scale Network on top of it right so 3.7 is really me the core thing that sets TSN aside and says well you know however we do it we cannot use TSN alone in a large Network we we need to do our own slow down please alms turus slow down please yep okay so I understand the point you're making and I think you've accidentally gotten a couple of things confused de net was originally started"
  },
  {
    "startTime": "01:16:02",
    "text": "based on I think the primary observation you're making which is that layer three matters and matters in some of these use cases I don't think there's any argument about that um I believe that the reason for pulling TSN in here was not to try to say G we just fall back to layer two but rather if you look at the original Deb net architecture it is a layer three architecture that initially says you could use the TSN scheduling mechanisms in the individual nodes even if the cues are at layer three so I I don't think the layer 2 versus layer three uh comparison is apt but we did find uh some limitations in those existing TSN schedule me so isn't about using TSN it's about using the TSN scheduling mechanisms with debt debt neted layer three except that we do not have have actual proposals to do so right so we're talking against not really existing graphs we don't need proposals to do so the existing RFC is to say to go do this no I don't think no I don't think that's true what the what the existing rfc's for TSN are doing is that they consider um a TSN uh domain as a subnet and that's exactly what I was saying isn't scaling right you you cannot take a lot service provider Network and do consider it a single TSN subnet where only on the edge I'm going to I'm going to I'm going to agree to disagree with you on that um I believe that the existing rfc's propose the use of the TSN mechanisms at layer three with Deb net no I believe I I believe that's the Baseline uh to start from rather than uh automatically saying that TSN cannot be used in layer 3 Network because it's not layer no no it's it's always TSN as a subnet in a de net domain that's that's"
  },
  {
    "startTime": "01:18:01",
    "text": "that's what they all do the said I'm going to does not model I'm going to G discre with you on that for the time being yeah but but then please show me a single RFC or tell me the number of a single RFC of our DET net TSN work that is not using TSN pure as a de net subnet all right I will make a note to go look for that mhm thanks okay so I thought I'd go put this slide back up again see if that engenders any any other comments as to uh what we got to do from here or is the right Next Step to go uh update all of the uh evaluations of new proposals to pick up uh at least the new uh 321 the new a new template that includes uh the 321 uh uh single hop latency requirement sorry sorry single hop single hop uh latency variation requirement anything else any other comments concerns questions on"
  },
  {
    "startTime": "01:20:06",
    "text": "anything let me go get the agenda back up tles give me a minute here I have a hard time picking off these windows with the uh with with the uh miniaturized display that that the cloud detects Turles go ahead um we had uh what hopefully was is is is a useful discussion on um comparing um and trying to understand the latency behavior of of the different mechanisms G and I particularly um and um I I was just uh proposing um two two slides with the example that I was making and I think in general um I think it would be useful to have a little bit explicit examples of um the actual worst case endtoend latency um calculation and when we need to also the Jitter calculation but I think uh the more advanced mechanisms seem to have some math which may be a little bit um difficult to grasp unless we we get to um explicit examples and I was trying to do that to see if we can get common understanding of that because I think at this point in time Janu is telling me something different from what I'm coming up with um and uh I think this this is also so what I've I've been seeing over the decade all the people struggling uh trying to understand RFC 2212 um that there is a complete lack of"
  },
  {
    "startTime": "01:22:04",
    "text": "explicit examples um of of that worst case latency calculation um in in the ITF and I think also in in other literature that was trying to do the calculus staff is a hard thing on on those mechanisms so if if you can um uh David uh find the two slides I was proposing and bring bring them up working on it just a minute um are we here I think ah that one okay um okay ah all right um hang on I need to go okay I've got the slides into the materials but I have to go share them from my desktop because whatever conversion they have to do uh the uh that M EO has to do is not yet done oh wow so that's crazy well know this is Meo is doing some kind of conversion"
  },
  {
    "startTime": "01:24:01",
    "text": "uh uh to show them okay all right um just a minute about about three or four more clicks and we'll be there all right all right this is the slide you want to start from right yeah so so so the next slide and uh is is the actual example and and the uh third slide is the the there we go right so what what this is showing is a uh flow under test from Source One to receiver one on the right hand side going across 10 routers which could be a ring um and then um on each hop namely on each router's output interface R1 up to um uh R9 um that flow is competing with other flows and for for the sake of Simplicity there is always 100 flows arriving on each of the routers R1 to R9 um and there're always going just a single hop before they're leaving the ring again so on every hop um the flow from Source One to receiver one is competing against 100 other flows and let's say for the sake of Simplicity the ring is a gigabit link only um the flows are one megabit Guaranteed Rate so you know uh nowhere close to saturating the gigabit and the burst size is that each of these packets has one packet and and"
  },
  {
    "startTime": "01:26:00",
    "text": "the we're not even looking at at at Continuous Flow I was just looking at the worst case um uh of what could happen and so so my argument was that on every and and the links from from where the flows are being fed into the router let's say um have unknown um bandwidth so it could be very fast because each of these flows could arrive on their own incoming interface right so these routers can be aggregation routers um so uh we we don't know the bandwidth so let's say it's unlimited fast bandwidth how they can arrive and now on on every hop I look at it I can have a queue of 100 packet that just uh for for sake of bad luck arrived at the same time and my flows packet is behind them so in my opinion whatever mechanism I'm using um for for the single packet the worst case latency is really 10 times the latency of being behind 100 other packets which kind of on the next slide okay before we go to the next slide let me let uh Janu in since he's the other major participant in this discussion Janu go ahead okay oh thank you yeah before into going any further um I'd like to say that the Tas uh brought up an important issue I think that the the solutions we we are suggesting now has have all different latency uh performance we all have different latency performance we can guarantee different latency balance now I think we have to be able to show it with mathematical expression explicitly otherwise um all our saying is kind of a"
  },
  {
    "startTime": "01:28:01",
    "text": "void so uh currently I know the uh Laten bound of the 8S and faqing or C score but uh other than that I'm not aware of that aare of the mathematical expression so I suggest all the authors of the solution come up with the mathematical expression then we our discussion will be much more fruitful I think thank you and I I think that's fine I'm just saying that the the formula you showed me I couldn't map that to my example here and if I was trying to map it I couldn't come up um with the same results as I'm very frustrated I I'm I have I have been trying to uh understand you for like two or two or three months but you're still not getting so I I strongly suggest you to read the papers I I did read the papers and I did read the papers and um I'm I'm asking you if you can tell me um what in this example the the guaranteed latency for the flow is and when as I think you're coming up with a lower latency then I was uh just explaining how um that can be what is wrong in my thinking about uh this worst case endtoend latency as I was just explaining it because I think your formula does not arrive at the same worst case end to end latency in this case yeah I think um discussing this example"
  },
  {
    "startTime": "01:30:01",
    "text": "will be better suited in the email because uh I think people here will'll be hard understanding the example itself and the detailed parameters and all the equations you can you can try I'm I'm not sure the 30 minutes will be enough that's my suggestion yeah I mean what what what you're saying is that um the way understand it is that there is only one consideration for the burst but the example shows that there is a new burst on every hop that I need to take into account and um that I can have to add up the worst case latency of each of these hops independently that's that's the argument that I'm making and I'm I'm not getting because I had this example for for several emails and I I don't think I got um a reply from you that's taking that into account I think email is probably going to be a better way to uh uh to do this I hope that I hope the topology is clear there are certainly an enormous number of flows here I mean there are a thousand uh flows that are uh that that that are showing up and uh competing for each router to router hop no it's only 101 flows on every hop but it's a new set of no no no no T tus across Source Two To Source 10 you've got nearly a, flows that's that's true yes so there there a thousand flows that are competing with flow number one yes yeah near near Thousand actually I think if I do the math it's 900 but yes you're right 9001 yes yeah so that so uh"
  },
  {
    "startTime": "01:32:02",
    "text": "junong light that uh to is prepared are there any any more slides the math that I was trying to explain and yes there there is a bug it's just nine competing hops not 10 there so it's okay there is the bug here it's not 10 hops times 101 but it's nine hops by 10 sorry I was doing it rather quickly okay yeah I don't uh I I will say right now I don't uh I'm pretty sure that the simple summation that was done here uh in particular uh the 101 uh numbers is almost certainly wrong and and and what's the argument for that uh the argument is um consider a strict priority queue don't don't don't don't don't don't don't even look at the stran mechanism gu consider a strict priority queue where the arriving packet that's running horizontally has absolute priority over everything else if there are 100 packets in the queue that arriving packet is going to skip ahead of all but one no no I mean all the other flows are also dead net flows of course um don't think it's quite that simple in particular as I said I don't believe uh look looking at the calcul at the at the computation you've done I don't believe that number is my immediate reaction and when you the other flows are when you say all the other flows are debt net flows um at that point um uh you're not looking at uh what was set up in the data plane to make this"
  },
  {
    "startTime": "01:34:02",
    "text": "work and I think I did right because the the point is if if these packets the the these 101 packets can arrive at the same time which is what I was predicating then they have all the same priority in Fair queuing um and uh they're they're just being processed in order and that means okay t uh T what what what is your point here what do you want to say what I'm trying to say is that I'm looking um from very concrete and easily without complex math done examples like this one and then I'm trying to map it to the uh to the math that you're providing um for example for ccore um and and that's yeah I I I will tell you the reason now the the the the previous example you gave me the email the link capacity was 100 gab BPS okay and the service rate is one gab BPS the link is 100 Gig and the service rate was one gig and now we come up with the different numbers here yeah of course yeah that's the reason your Calculus is different from mine that's the only but your formula didn't change you you you you you didn't give um examples with numbers you please look getemail get the email again then you'll find the error here please look get their email again yeah I I think this is I think this is this is better this is better worked out emails I said the the right now the number number that's bothering me is I think the simple the the simple summation of the interference across all the flows is striking me as peculiar well the the let's work it on"
  },
  {
    "startTime": "01:36:04",
    "text": "email yeah and I I I just think that these type of things we've already spent so many um emails Cycles back and forth and seems like we're not getting the answers from the other side we're looking for um so I think that you know High speeed communication with audio is is actually working better on things like this but of course in person would be even better okay so I'll put up this slide to make sure people have a chance to see it since I've not uh had up for up for all that long but uh and uh this slide is is now is now in the meet is now in the meeting materials so people will be be able to get to it there as well all right any other topics okay so I think we're looking forward to uh some more discussion on the list of some of the updates to the uh to the requirements draft and with luck I'll have time to better prepare for our next meeting in about three weeks um I hope to be able to put something on the list to suggest uh how we can start making progress towards some sort of uh expressing some sort of preference uh among the mechanisms we're looking"
  },
  {
    "startTime": "01:38:07",
    "text": "at any other comments questions concerns also a quick General reminder in case folks aren't uh aren't aware of it um to the extent if if you got any problems with how these meetings are being run um feel free to go bug me or or bug the working group chairs uh is you new yeah uh I just want to repeat what I have said before um yeah uh explicit mathematical expression for the latency bound I think everybody has come up be that that's my suggestion thank you yeah and and I think that's a I think that's a good one because in particular whether the Jitter gets summed across the Hops or not um becomes evident when I when when when you look at that sort of expression so I think that's a good good suggestion okay any other comments or questions all right I think we're done a little bit early thank you all very much for taking the time wait a minute Pascal yes it's just just a commment David it's it's not related to to the discussions we had today but it's related to the fact that a row is being folded back into that net and we have that longstanding discussion about the row architecture um so I just wanted to give a status to to the group that we we have published the uh version 14 of the raw architecture after the ATF meeting so"
  },
  {
    "startTime": "01:40:02",
    "text": "sometimes mid August and it covers the changes that we decided at the ATF on terminology Etc and U there are still a few um minor editorials that are not pushed to version 15 they are in GitHub for Greg M's Commerce but apart from that it's my belief that the row architecture is is ready for replication so for work group last score at least so just to let you know that I'm asking for this work group last score to to take place okay and with that I think we're done thank you all very much sh"
  }
]
