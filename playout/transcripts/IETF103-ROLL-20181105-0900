[
  {
    "startTime": "00:00:25",
    "text": "[Music] okay good morning thank you for joining us to the wrong meeting please sign the blue sheets okay this meeting is under the not well please read carefully okay they meet him at Dylan\u0027s this is the a pant if you can join thank you very much - Dominic for be they mean the minute taker and Raoul Michael for the charts progress okay this is our agenda for today some comments we have two hours okay this is are the milestones I think we are working kind of welcome on that yeah okay our active internet draft we are going to have some on discussion today this is the related we are going to have two from George\u0027s today these are the open three of them were consequence of the last meeting like a we need a new version yeah okay we have new new tickets consequence of the last meeting so if we need a new version of 6550 like so I think every per observation drive is going to help to us for that and if we need a new mode of operation for ripple and if we have to include this lbr us into the dock route and I think we should okay toilets if you want to join us for the next for a discussion of the role Middle East thank you yeah all right thank you yeah "
  },
  {
    "startTime": "00:03:37",
    "text": "okay yep so so this is about the whole idea of using its strings as addressing in role and here is a little bit the marketing slide of what we are trying to achieve high level you know as something to sell it to a user so the design team has the following email address so if you want to contribute ly subscribe to it and a little bit too small tools to see it completely but let me quickly try to summarize what the goal is you have your role domain with the root node and you want to have efficient forwarding in here so you wanna especially in the stateless mode be able to use the bits to route the packet all the way to a destination and then also one of the things you would like to be able to do is that an application can in a server indicate which receiver should receive a packet and so the example used here is let\u0027s say a lightning control application where you have a large number of lights and the controller application would like to be able to say for a particular command switch ON switch off which light should be switched on and off and in the classical IP multicast model you don\u0027t have that option you wanna interrupt immediately or yeah I just wanted to make it terminology comment when you use the trance client and server you are trying to say small thing and big box oh yeah that works using the terms client and server not as in client-server communications which is a risky request response scheme but in the sense of things that are small and might be on batteries and thinks they are big and iron Rex right so the thing in your Rick yeah so this is this is a small ten thousand line of piece of software running somewhere and these are you know all the lights in hotel whether they\u0027re small or large so yes so the terminology is right yeah at least let me know what the preferred terminology let\u0027s say on the application side is and then we can adopt it I\u0027ve just you know introduced in some slides down the terminology for the components but yeah we I don\u0027t know what the right terminology is at the application side so yeah so that basically would be one of the things we\u0027ve never done in in in beer working group proper so far which is bringing the ability to set bits up "
  },
  {
    "startTime": "00:06:38",
    "text": "to the application level and especially here in these control applications where the control software would like to be able to you know for individual commands very quickly changed the set of receivers that would be really a very big benefit and the other as I mentioned is the power cost efficient forwarding higher compression by using the bits on this client and server thing servers upstate Lions don\u0027t sorry server servers help state clients don\u0027t that\u0027s where it comes from so light has a state it\u0027s on or off and the client has a procedure to turn the light on and off that that\u0027s where it comes from well maybe again címon címon slepak what would be maybe good to to work out in the design team or terminology we want to use at the application level great Shepherd Cisco on behalf of the veer working group Taurus you mentioned that we haven\u0027t specified in position in the application layer within the working group architectural II it\u0027s always been the intent so I don\u0027t think there\u0027s anything omitting that if you think we need to do something document something in a way that\u0027s unique to what the architectures not cover please bring that up because there\u0027s a lot of work in that space right now not necessary just here is kind of cropping up all over like you\u0027ve seen beer as a service kind of same idea there\u0027s also a datacenter warrant taking place like this so if you\u0027re gonna present you\u0027re doing te at the working group right are you talking about this at all no no no there was just the the basic cuz I think you\u0027ve been come up as a use case and maybe entered in the use case draft so we can track that and then if there is a gap in the architecture for hosting position please bring it on by the way much more fundamentally and I think I forgot to put this into the slides but I wouldn\u0027t like to have role do any things that should better be done in the beer working group so anything on this I level for the application or so I think should not be specific to role but let us in the design team I\u0027d rather get far along to make that argument and the the terminology thing there\u0027s also another pair of roles here which is the sender and the receiver source and the member and so on the movie can focus on that energy and not try to call the the sender servers of the time render receivers client right there would be one level further down into the technology that\u0027s a lot more easy right so the multicast sender model where it\u0027s in control about the set of receivers for each individual message that but yeah at the app we would still need to kind of talk about the application level you know how you build what is a controlling server and then these client devices so yeah okay so that was basically the idea to to market the scope of the work but it\u0027s not only "
  },
  {
    "startTime": "00:09:38",
    "text": "multicast but it\u0027s also meant to support the efficient transmission of unicast and then of course the cool thing coming over from the beer working group is we don\u0027t have to bother about the constraints of working in Asics that support terabits of bandwidth rather the opposite so everything is software in the forwarding that you know for us coming from the beer working group is a complete shift because what was done over there was very much focused on supporting Asics so here is a little bit the the first round of trying to come up with a shorter Entomology for the components involved so we would have these the software or boxes the server and I call this six server node application it wouldn\u0027t be running role in beer but it would need to be able to send packets where the beer bitstrings or an equivalent like the set of receivers would be able to be indicated so that this new model of the multicast would be accessible to that application server then the root node that would basically be one of the roles of these blue boxes which are the ripple routers so 6rr as a proposed term for the root 60 r would be a transit note that doesn\u0027t necessarily have to have a in the the beer string so it wouldn\u0027t necessarily have to be a receiver in beer this is just called a VFR BIA forwarding router and then 6lr would be the leaf the receiver router which has a bit which can act as a receiver which you can explicitly address and then also Pascal brought up the need that we also want to support even more lightweight notes that wouldn\u0027t be part of the routing domain that would just be hosts receivers that just would and that I think is the conclusion that we\u0027re reaching so far we\u0027ll just be receive able to receive IP multicast but wouldn\u0027t have the feature of being directly addressed by bits so that\u0027s basically you know the current state of the overall architecture and then that means there are two type of applications right one is the bureau where application that does know its address through a bit and then basically the applications here that would only be able to see IP multicast Greg Greg again Cisco I\u0027m sorry if I missed this and maybe we should pull this off line digging deeper but you\u0027ve got bit assignments - links like te and bit assignments and nodes like traditional beer yeah we\u0027ll get to that part me we\u0027ll get fit Oh gotcha okay the expectation of six l ends are also bit assigned no that was exactly the idea that at this point in time we wanted to make sure that we can support two different type of nodes one that would be part of the beer domain and then one "
  },
  {
    "startTime": "00:12:39",
    "text": "that wouldn\u0027t be part of the beer domain that would just be accessing the unicast and multicast services being poured the beer domain right so at this point in time we would cut it down because the whole you know exercise right now is to cut down to figure out the you know minimum delivery so let\u0027s not do right yes there could be direct addressing to bits for them but maybe the the point right now would be let\u0027s cut that option off let\u0027s keep that option to the full people fear browsers so this was my kind of first attempt we haven\u0027t reviewed never found time to review it in the design team of how I could see the forwarding plane and in here working group proper we have some differentiation which I\u0027m going to talk about in the year working group about the beauty forwarding and the beer forwarding and now we have here in the road side we have one big differentiation or what we\u0027ve done in beer which is that we wanted to introduce also the ability to have lossy compression fit forwarding versus the explicit forwarding and so there a bunch of issues to work through that are detailed in further slides but on the forwarding side really maybe we could think about it in this simplified manner where no distinction between I actually think I missed one update here I think I said okay yeah so I thought I had written something here but so the the interesting idea here was that we may not need any distinction in the forwarding plane between the te notion and the native beer notion because in the end the only thing we\u0027re trying to do is you have a bit for that bit you are trying to figure out where to send a copy what is your next hop the question is how is the next hop calculated right in the beer te model the next hop comes from an explicit assignment in the controller and would be different on every node whereas in beer proper it\u0027s calculated locally from the routing table the next hop right so that that fundamentally means that the control plane could be different but hopefully we can come up with a forwarding plane which we call you know beer forwarding table that wouldn\u0027t have to distinguish between beer and beer tea now there is one more key thing which for which I have all these crazy not finished slides which is that India proper we\u0027re resetting bits and the resetting of the bits is something we\u0027re doing in beer and beer TV for different purposes that\u0027s detailed in in the further slides so I\u0027ve basically put these resets bit in here but we also know we can\u0027t do the reset of the bits when we\u0027re compressing the bit string in "
  },
  {
    "startTime": "00:15:39",
    "text": "a lossy fashion so here we wouldn\u0027t have it and the question also in the non compressed forwarding is whether we want to have this reset bit mask because it maybe if we don\u0027t compress it it may be fairly expensive right so if we have a bit string table of 256 bit let\u0027s say this is kind of here the example then every forwarding entry would need to have of course they could be compressed right but if we look at uncompressed we have 256 by 256 bit for the reset bit strings for for these fbms forwarding bit masks which are basically resetting the bits and maybe that is too much state so we don\u0027t want to have it from the state perspective now they could be very well compressed right so but in any case this is kind of the current state of the slide of a slider not right Pascal yes got to be here I mean we are we are documents from which we started this work right before this design team formed and I think it was pretty clear in every document that we never need to receive reset any bit and and if you see a need then you need to come up with it and justify it with a group design team but so far there was there\u0027s no need to reset those bits when one of the big reasons why peer would reset those bits is to avoid loops because this thing gets flooded but in repo it goes down a geotag and it\u0027s a nice property of the geotag that you know you can only go down it if you start going down I mean you will never loop and so there is there is no need to reset the bits so is that I know right so if you\u0027ve sees another good reason then come up and we\u0027ll discuss but no I think I think Noah merrily we need to be very explicit in documenting the the reasons why we\u0027re getting rid of the reset and I wanted to make sure that we you know in list and document them correctly right because so far I\u0027m not sure that we have actually done that work okay and then the benefit of Greg being here and and you know the draft right we have we have another draft which has nothing to do with this work also written so far which is about in the tea world managing duplicates and replication and finding out which transmissions failed and that\u0027s going to be very very useful in the wireless space I mean you\u0027ve presented the drafted beer I guess III had a collision but yeah yeah and and so actually Thursday we laughs a bar buff that I could power for predictable unavailable Wireless and this is the sort of work which would be useful for both the bath years at eleven and we don\u0027t have a room yet but if you want to attend because you\u0027re not I own the data at least I don\u0027t think so I copied six - I copied six lo I copied that Matt now if she just dropped me an email you want to see what Paul is doing "
  },
  {
    "startTime": "00:18:40",
    "text": "then please just drop me an email we\u0027ll add you to the list okay but but this so in this case we do need to reset bits but it\u0027s very practical operations not at all this design here this design here we go down the do Doug we don\u0027t reset the bits right let\u0027s I mean they\u0027re bad and these are you know not really finished slides for for these are working slides right by the way there there is a version update missing so I had already replaced all 6lowpan with six low RH in in the slide deck that I thought I\u0027d sent you so sorry for for the mistake so basically the kind of encapsulation that we\u0027re planning to use there are slides missing I had a slide here that so because I had I had a slide with with all the relevant documents including Pascal\u0027s 6lo document for for for the encapsulation option that would compress the beer header and then also the encapsulated IP packet here are these these are complete wrong the least man really nasty so right so this this was just you know the reasoning why even you know Pascal is saying that we don\u0027t have to reset the bit string right but even more so if we have the bloom filters we cannot reset them [Music] [Music] right so I I think the question of where do we have duplicates and/or loops right so in the in normal I GPS we\u0027re saying we have micro loops right so and we wanted to avoid creating duplicates and problems there with with the reset right so you say Pascal are you saying that for example because of the way a ripple works we would never have micro loops let\u0027s get in summary yes practice in "
  },
  {
    "startTime": "00:21:42",
    "text": "ripple we have a additional header which allows us to to track if you\u0027re going up or down the structure and we have we have this rule which says that if you\u0027re going down you cannot go up again and even if the nodes are not in sync in the routing table they still have a sense of up and down and the mismatch is found and so the packet will never move there are the routing table themself can indicate a loop but the packet as they follow this loop will discover that they are having a problem so we would originally so we would implicitly ignore bits that would have us go up again basically yes I mean the bits the bits is kind of a match right you\u0027ve got some bits which might match next a child and so you go through your children and you kind of and the bits which identify this next hub so all the routes which goes through this guy if it\u0027s during mode or this thing if it\u0027s non storing mode and and you it could be a blue and so you add the back yet and this thing and then gives you whether this child or not is next time right so we basically would have a local reset mask so to speak to do that that would be populated from the routing table excluding the bits that are not caught down from here yes each child you need to have the bitmap of what\u0027s relevant to be sent through this child and you could reset the bits but we\u0027re just ending the with the bits of interest that I think in child so that that\u0027s what makes this so great install mode because now you\u0027re rotting table is just a set of bits per child I supposed to rot per leaf right okay so we need we need to correctly capture that and also look into what the memory impact is of that implicit you know ant mask but I think that that sounds more like it\u0027s not it\u0027s it\u0027s a per note reset mask it\u0027s not per bit so I think that should be fine yeah no it basically your particular ripple note so you\u0027re doing an end operation before you\u0027re even looking at the bits your ending to figure out which bits you want to look at your rotting table and storing mode looks like you have a state per child in the geotag right and this state is kind of the bits which are below this guy but that would be stateful that\u0027s in storing mode in non storing mode do you have a bit per interface which is well anyways for adjacency right so so without the same wire or wireless or if it\u0027s multiple different interface you don\u0027t really care you have a bit per adjacency a bit "
  },
  {
    "startTime": "00:24:42",
    "text": "a bit mass progestin see in non stirring that bit mask will be basically the bloom filter of this link or the bit of this link if you are not using bloom filters and in storing mode it\u0027s going to be the collection of all the bits of all the leaves which are somewhere down the dyrdek via this guy anyway you take the bit mask the bits in your packet you end that with the stage here for that child if the and operation is not a zero you have a match if you have a match your four okay so let\u0027s let\u0027s let\u0027s fix that up accordingly I think we\u0027re running yeah yes so my question I\u0027m a bit confused about those bits because this is a graph not a tree so at some point somebody lowering the tree needs to find out whether somebody more up in the tree has designed the lower tree forwarding responsibility or not and she never reset bits then then multiple paths down that I\u0027m not a hundred percent persuaded either but I think we\u0027re running out of line I wanted to make sure that we really worked on this so yeah so but this was the slide that I was missing right specifically just to figure out if I have the complete understanding of the documents that have been written for the scope of this work here right so a Pascal has the you know his proposed architecture purely the beer and row level not the you know IP multicast overlay Carsten has the role C cast which talks purely about the solution assuming IP multicast on top of it for the bloom filters there is a Pascal\u0027s beer dispatch in 6lo which talks about the six low RH extensions for beer to the best of my understanding and then the unaware leaves is I is that related to basically these these notes that are supposed to not be doing so this this I think starts this work it\u0027s not meant to you know define right now the multicast part of it yeah so so that would basically be the part of these leaves that should be very lightweight don\u0027t have any knowledge about role and beer but would also need to get IP multicast through role beer then and then yeah so please if there\u0027s anything more drafts please let me know so that I keep the the the list of relevant documents so right so there a lot of things here and I think I was trying to "
  },
  {
    "startTime": "00:27:43",
    "text": "yeah so we\u0027re trying to continue limit the work scope by eliminating below the line or it doesn\u0027t work options and I have more detailed slide on those so I think first consideration was even when we want to address receivers directly with bits from the server application we could still put everything into an IP multicast header because that one would be compressed by six low RH anyhow and you know we already have socket API so it helps a lot if we don\u0027t at this point in time try to figure out how to receive native beer packets that don\u0027t have IP multicast in them I was first afraid of the overhead of IP multicast we don\u0027t need it but you know that would be the proposal of just thinking that the stack always has an IP multicast header and that were appropriately compressing that with a six low RH then we did discuss to an extent how we can basically send packets optimally I I was thinking fake IP packets or we don\u0027t have an IP multicast destination and we figured out that we don\u0027t want to do it right so remember all these discussions that that we had when we\u0027re multi casting a unicast packet and figured out that\u0027s not something we really want to do because there are so many problems Pascal yes so just did this the prime is if you want to sound the same packet to multiple unique as destination you\u0027ve got this prime of Rick well you could reconstruct the IP destination based on a bit that would be easy but the problem would be the UDP checksum and and so we decided that for multicast we would not choose a bit to indicate this nation and set multiple bits at the same time because then it for you different packets for unicast but for unicast we could send one unicast to one person and we could see the bit as a compression of the IP address right so I think I think you said a little bit wrong so if we send in the IP unicast packet across this beer rippled solution then you can only have said one bit to indicate a destination of course they can still be false positives but they would be recognized as false positives because of the IP unicast destination address right only one node is supposed to have that IP unicast destination address even if we use a bloom actually because if the bloom gives delivers to two destinations if if the check sum is still part of the packet that can be recognized right exactly so I\u0027m saying that even if a packet gets delivered to a unique aspect it gets delivered to more than one destination it would be discarded by all but the one right destination so we\u0027re not changing the unicast semantics true you would have said it differently it\u0027s fine we can we can we can think about you know an interim we have more time "
  },
  {
    "startTime": "00:30:45",
    "text": "right and then I think what then basically I think what I was saying here about the transport I don\u0027t want to bring in the definition of Pascal right now but I think that was basically the conclusion that we look into this transport mode only for the be a ripple routers and tunnel mode to the light banknotes and then I think one of the open questions is where exactly do we want to have the destination semantics right because is it really worthwhile right now to consider this for the storing mode we\u0027re kind of you know summarize the benefit of the storing mode because I think primarily we\u0027re looking into the non storing mode no I think we\u0027re going we were going back and forth on that so beer is critical for storing mode because it allows you to save a lot of state I mean it basically it allows storing mode in constrained devices I mean Kirsten has been telling us so many times that he has never seen any storing mode ripple Network in IOT right I\u0027ve seen them in non iut because it\u0027s a rotting protocol you can use it everywhere we ship it with storing mode with Cisco but in in IOT you usually don\u0027t see it because of the load of information you have to store that\u0027s because it\u0027s one at least one address per leaf in the nto tag with beer storing mode becomes becomes feasible because it\u0027s one bitmap per child okay and the final let\u0027s write the gun and the karate because I think that value proposition wasn\u0027t clearly laid out for me a lot more interesting in story mode because it makes such a huge difference it becomes feasible okay Oh Michael Richardson so if I understood Pascal what you said is that beer reduces the cost of routing entries in storing mode to such that it\u0027s now low enough that it\u0027s maybe workable but it doesn\u0027t it does not change the order in dependency that storing mode has it just reduces the constant significantly not not not true where\u0027s non storing mode has no that the individual nodes have no specific limit on how many they can support because they\u0027re not storing any any content per per note I you still need to have information per leaf but the point is if you have sized your bitmap to say 256 just for this example because you\u0027ll know your network is going to be 256 or something then you need one of such bitmap per child regardless of how many leaves you have now you cannot have more than 256 leaves because that\u0027s the size of your bitmap right if you want to go beyond that then then you you have the she want some "
  },
  {
    "startTime": "00:33:46",
    "text": "elasticity that\u0027s why you use blue but then then the more you extend this elasticity the more false-positive you\u0027re gonna get well in the traditional networks that we built they are not so big that I mean usually we\u0027d be like 30 devices in the network right and and so 256 is already a very big network oh I was not talking to you right now a storing mode is 90 is no more beer routing that\u0027s when you have state it\u0027s the week do we want it I mean because they said the core of the work and I think you know because I just wanted to point out two things there\u0027s a small state of end here because by limiting the thing to 256 of course we make story mode much more manageable and then by reducing the state by a factor factor of 64 we also gain something the other answer is the bloom filter is one important parameter for room filter is how many members you actually have in the whole group so if you have sparse groups you can address the whole network with a pretty small filter if you have dense groups you need larger filter I mean if you but but let\u0027s go back so let me say what I just want to make sure is that for every option that we\u0027re saying we want to work on let\u0027s make sure we have sufficiently agreed-upon value proposition right and I I think this discussion was good it I think showed that that is necessary and that I think we should reconverge for example on exactly the value proposition Pascal claims for the beer mode so I I had started here to kind of look at you know the stacking how this stuff works probably not correct here but this is basically what what what what I think we would need to work out so this was the IP multicast overall beer to ward in this case it 6ln right so in this case we have the server application I mean in this section that\u0027s saying IP multicast should mean SSM really so then basically there should we should be able to have a user level SDK that the whole stuff can be written at user level that you know on the application server we can just send things into let\u0027s say UDP tunnel which is typically the encapsulation we can do at application layer that would have to end up at the root node and then from there on we would have to hop by hop forwarding beer Purity and then basically on the 6lr node where the bit is set it would basically be uncompressed must be compressed as a non bit string multicast packet again gets "
  },
  {
    "startTime": "00:36:47",
    "text": "into the six an application right so that was kind of a little bit the starting point of these are the type of diagrams I think we need to work through the end-to-end solution of the stacking of pieces and to me the core part is really also understanding the six low RH kind of how small these headers can become with the bit strings and confessing the IP multicast overhead away so the unica stuff wasn\u0027t done this worse all these consideration I think running out of time these were the things that we think wasn\u0027t working and yeah so I basically started to write down the multicast layer and yeah so yeah so way too much text but I think one of the discussions were having in the multicast architecture sat in the ITF overall is can we do things more efficiently better with SSM only and yet now obviously that\u0027s you know one of the things I wanted to review if that\u0027s sufficient enough if we\u0027re you know requiring IGMP bees or ml d v2 with SSM indicating the source and the key part to cut to the chase here why I think SSM would be highly valuable for this type of solution is because the source address in the membership join could exactly indicate the unicast address of the server so that we don\u0027t need to have an in-network discovery which server is basically responsible for particular clients to receive multicast packets sent by a particular server because that would otherwise be the typical ASM issue that we have multiple application servers for different clients they all set multicast and you need to start assigning IP multicast group addresses to different applications so you can forego this complexity from we\u0027re also adopting SSM as the mandatory multicast delivery mechanism that was kind of the high level and this is all details arson yeah I have one comment on choosing SSM in in a single ripple domain of course the source is always the route so it\u0027s no no no that\u0027s why I brought that so the price like there would be different application servers the direction that\u0027s that\u0027s why you now can steal that and use it for something else which is an interesting idea I haven\u0027t thought about much but basically the reason why my recon says is to solve the root problem and since everything has to go through the root we don\u0027t have that problem no I yep well now I think but the the rendezvous point is primarily overhead in administration and paying for the network operator it\u0027s not an application-level issue right the application level issue is kind of indicating which source am i wanting to get traffic from right now and as you "
  },
  {
    "startTime": "00:39:48",
    "text": "said we can nicely abuse that to basically have the server source discovery built from the application level that way okay I have to think about that the point I was really going to make is the the whole thing seems to assume that the whole group is within one River domain and that\u0027s not IP multicast anyway so we have all three of the world to design something completely new here because we know that\u0027s true but the more I can avoid having to you know do something new and whole stack of hundreds of different you know client OSS I mean IGMP v3 itself took 12 years to get adopted everywhere right so yeah I don\u0027t know what what the client is but the the the guy up there who sends the data right is going to use a UDP eternal to the route exactly so that that\u0027s where I definitely want to have a solution we have no OS changes no offense meant to you know we have a completely on the client side I think we should be very careful about how basically they would receive packets and and also make sure that we don\u0027t need OS changes there especially the 6l are the ones that don\u0027t have any ripple beer functionality uh Greg again I\u0027m gonna avoid that last piece but just going back for clarification if the intent with SSM is to use it to identify one of a number of servers or source discovery that makes a lot of sense but don\u0027t forget the discussions around an RP or moot with beer in fact beer doesn\u0027t care of his ASMR SM and actually becomes effectively the beer domain is like a virtual RP so if you need to do some sort of redundancy or you needed to have sort of multiple source you know the argument on the RP is just avoid that and state logically within the arc no I wasn\u0027t making the argument about the RP Carson was making the argument I think the argument that you made afterwards that we might have multiple domains and need to figure out on application works across that I think that\u0027s more important to understand I tend to agree with Gaston on a lot of what he said we have a new environment here that and there are things that we prefer doing and things we less prefer using injecting an address which comes from outside the ripple domain is very costly to us we would not like to see it in the packet if we can avoid it because we need to compress it or if we don\u0027t compress it sixteen bits in year sixteen bytes in year so for instance having every multicast packet sourced at the root for us can be comprised with six where extra one bit right because it comes from the root bit you know so that\u0027s very efficient if every multicast packet which is compressed this way can be sourced at the root and this nation set of bits then we have the most efficient efficient compression my argument would be that the amount of state that I think I need here in the last hop ripple router is the same that "
  },
  {
    "startTime": "00:42:51",
    "text": "I would need for the clients having unicast IP traffic to a particular application server so if to you know improve the performance of the system all these application servers should use the IP address of the root node so that basically you don\u0027t have to keep state for new IP unicast addresses that\u0027s fine with me that doesn\u0027t change the concept right the thing that we could leverage is the fact that we have multiple instances in rapport so you could you could have the same multicast address which can be derived in 2d okay anyhow so that was kind of I think what we should stop here even two hours maybe a bit short so what about having an half day or a day at the next IDF meeting oh yeah this well no unfortunately I\u0027m in some other place I have to leave on Wednesday night but no I\u0027ll basically resend after all these daylight saving times just the weekly meeting stuff and then we can discuss in in a weekly meeting if we want to have an interim with longer time how about that and I think I still like to have a couple of weeks to you know bring this into shape that we have the different components really clearly laid out or salutely [Music] that\u0027s the good interim I\u0027m not sure I mean they\u0027re also the WebEx entrance I wish we could do an in-person interim but I\u0027m not sure if we find the opportunity for that okay we\u0027ll discuss this on the mailing list and so we see how many days if you have an interim apart from or next to the next idea okay fine thank you very much for the work I\u0027m happy that this progressing next time Rahul Jadhav this is a quick update about what\u0027s happening with the efficient route invalidation draft we there we have so so we have we had aggressive lot of comments from Peter "
  },
  {
    "startTime": "00:45:51",
    "text": "from lubing from George\u0027s thank you and most of the updates are based on that so so this is the first one I\u0027m presenting so one of the one of the major changes that has been done or one of the thing that has been explained more is related to how to handle multiple parents so ripple has this notion that you can have multiple routing you can send the same Dao to multiple parents and in such a case how will DC you or the D COO handle the route invalidation this is explained with an example so this is the major update other updates we are more in line with the security considerations of 6/5 6550 especially there are three modes of security and secured or not authenticated and pre-installed so we have aligned our draft in the security consideration as to how these three points these three modes are to be understood then there are some clarification the d KO sequence number choosing the initial value some terminology especially the require that order into link failures so this is this is the section titled we had used and this caused a lot of confusion we had to reword the whole thing based on the comments from Peter and George\u0027s then the terminology we had made a consistent use of terminology we had made some duplicate text in this document from ripple and 6lo so as to just make it more readable thank you Peter and everyone else including Pasco judges and looking for the review comments I\u0027ll quickly move on to my next slide which is the ripple observation now this is just want to mention this for me this document is finished implication thank you okay so we move on to the next presentation so this is the draft which talks about most of the most of the observations that we had while while while developing a solution around ripple for metering solution having said that it\u0027s not now limited only to the matrix metering solution but more more other problems as well so this working this document was out of 10 but we have clearly mentioned in the document that maybe this document might not get published we want to still keep this document around so that if any one ends up fixing this issue in some other way this would prove to be like a reference material material and this can explain this explains the problem in more details like it gives tech wise explanation of what the problem is okay so there had been a big discussion on whether DTS n is a lollipop counter or no most of the things I\u0027m going to repeat from the last presentation so yeah this is in continuation to what we had presented before whether DTS n is the lollipop counter or no now implementations are clearly confused about it we have two implementations making use of different I mean different notions basically quantity is using DTS and as a value pop counter and Wright is not and this is going to I mean this will have issues on interoperability so we had a big discussion on the mailing "
  },
  {
    "startTime": "00:48:51",
    "text": "list eventually we realized that maybe DTS n could be a lollipop counter or there are pros and cons with each of the approach the primary problem with using a lollipop counter is that within the linear part of this lollipop country you have to maintain the state in a persistent storage now this this problem is in general with all the lollipop counters including DTS into our sequence or not now sequence is not a lollipop photo but all the other sequence numbers the problem is for the linear part you have to maintain the state in the persistent storage now you have a application which is a very minimalistic application and you just are hosting that application in a mesh network now you have this cost of keeping the data in the possessor storage now we\u0027ll a deployment afford this cost can this cause be mitigated by using some sort of signaling tech signaling mechanism this is what we have checking if it is possible Michael okay so the next slide is about the DTS in so we had a discussion right the primary problem with non storing mode is the memory efficiency on 6 l RS but there are other issues that we found we observe while deploying storing mode of operation and DTS intends to be one of the major I mean the way DTS Sinha is handled eventually decides what kind of control overhead you have in the network so DTS in is Dao trigger sequence number essentially what it means is whenever a new DTS end is received by the 6lr it will in turn generate its 6 lr 6 7 it will in turn generate its own Dao so what happens is when in case of parent switching node switching should the DTS end be incremented should so the first implementers dilemma is that should the DTS and be incremented with ability I have to cut people timer if it is not incremented with regards to DI electrical timer then we don\u0027t have enough doubt redundancy now there is another problem with regards to doubt that the acknowledgement mechanism of dau which I\u0027m going to represent in the subsequent slide because of that issue we cannot really increment we cannot afford to not increment DTS in on every iota and you can see implementations struggling with that if you if you actually see the quantity initially decided to use incremented DTS and in every di tackle then it was a law lot of control over it and then they decided to remove it so clearly there is some room for clarification or maybe a text saying how to handle it ok yeah so the the second point here is during panel switch should note increments it should the 6 lr increments at DTS n now this is important because now the route update for the subdue dag routed at that particular 6 lr has to be updated now let\u0027s say for example "
  },
  {
    "startTime": "00:51:58",
    "text": "so doing parents which also the same procedure the primary problem with doing parents which if the 6l r which is switching if it increments a DTS in the question is other sellers downstream should also increment it or not if it don\u0027t if they don\u0027t increment then how how how would the route updation for all the subdued attack take into a will be handle now one solution is that the 6l r which is switching also has the complete routing table and it can push all the information so that is most likely the the way to handle it but yeah I mean this this these are some things which I feel may be may be clarified in the text some area so I completely agree Pascal here I completely agree with how that we have to clarify these things just for history it was a huge fight with in repose some people where for the pool model of like DTS end course not a Daoist a to the parrot and our case is why you want this pole just like when you were a parent and some people said you know we can be lazy those networks you know they work when they work and so so the child should be free of sending down anytime and so there is no restriction when the child sends it out so even if you don\u0027t increment the DTS and each time you Treecko if you don\u0027t do that then you have the expectation that anyway the children soon enough on their own will decide to trigger her dau so the the basic spec doesn\u0027t tell you that and and it\u0027s probably because we we could not agree and we really did not know if there would be use cases for repo where the push model that the child pushes the down theoretically whenever it likes or the pool model where the parent pulls with a new DTS and all the dolphin the children which one was the right model for which use case we were not clear right ripple was there before we had enough experience so we left that open so what role is telling us is is now we need to be more specific Oh is there a type of shoes case well one applies the other applies what benefits of each model etc I mean ripple is fat enough like this we didn\u0027t have much text on that but this is a great great discussion to have and you know at some point ripple will be implemented in some vertical standards like I don\u0027t know TVA or whatever else and and when you implement in RFC in an Aryan standard then you actually say I\u0027m using this feature this it show this teacher like this so they will design is like they will have to decide if they want to push pool or to both what kind of timers you have for the sending down what kinds of when do you trigger the DTS etc it doesn\u0027t have to be the same for every particle every particle industry we don\u0027t know that there is a good on Safari but if we knew then we would have "
  },
  {
    "startTime": "00:54:59",
    "text": "written it in ripple so so Michael Richardson here and we have microphones I didn\u0027t we had local AV so so we could have we should have as Pascal just said some things I\u0027m not really fond of alliance profiles because I just I just think they\u0027re dumb but we have applicability statements that we wrote and clearly this was something we should have a should have covered about push/pull and this kind of stuff if that was a clearly articulated option and I don\u0027t think in 65 50 that\u0027s clearly articulated that there\u0027s two models rather here\u0027s some here\u0027s some tools put them together in some way right so I\u0027ve advocated this before and a kind of bit lost as to why we\u0027re not further down and I said that to you last week right this should be a draft we were talking about leaving observations as a collection and I would really like you to pull that text out this text about this thing out into a single draft that we can you know now can get consensus on and it\u0027ll be update 6550 I don\u0027t think we\u0027re ready to do this I think we should have three or four clear updates right now where we try to revise it and I mean if we were to do Biss sorry one of the things you probably would rip out is all the security part because no one\u0027s implemented it okay however that statement is no longer true I\u0027ve learned that someone has implemented that the security parts of ripple and so that\u0027s kind of interesting so so I\u0027m glad we haven\u0027t started this because we would have no I think it\u0027s still important but I would really like this to be in there and there are other observations are you going on to those other ones now yes yeah so the other observation is with regards to the acknowledgement handling there are multiple interpretations already and there are different implementations with different interpretations one is the hop-by-hop acknowledgement so in this case the acknowledgement is immediately sent by the receiving 6lr there is a so what happens is if if if the acknowledgement is sent here and then the acknowledgement is sent above like for example in one sense a two border router or some other 6lr if it gets rejected then there is no way of informing the the 6lr no downstream whether that the dow has been rejected so there is no way so this is much much easier to implement the primary reason why dow AK is needed is so that an application on the node or the node knows that it has connected in the in the whole network and that it can start its application traffic what I\u0027m trying to say is the current action acknowledgment mechanism doesn\u0027t help you with that and that there has been a lot of debate on this but so so kontiki initially implemented this then went on to this style of aking which allowed like and tools in the Dow to N 1 and N 1 won\u0027t respond back with an "
  },
  {
    "startTime": "00:57:59",
    "text": "acknowledgment immediately it will wait for the above upstream parent to send back the acknowledgement and then send an acknowledgement in response so this model is okay but it has it has issues like in terms of it has to maintain state it has to maintain state for a long time and that is that is costly another employee interpretation now this the the this discussion I had with Pascal so one of the things that he mentioned was that whenever an upstream node takes up a Tau it accepts the responsibility of pushing that Dao all the way upstream well and if it sends an acknowledgment downstream it means that it the Dow will reach upstream well well it the the problem with this approach is that if if there is a negative acknowledgment anywhere upstream this this node doesn\u0027t know that there will be a negative acknowledgment upstream so it\u0027s not possible for him for this node to eventually negative acts because positive ACK has already been sent for them right so two things first I try to get from the kontiki people but they are not in the room right now why they did that they said it\u0027s a hack they made for a particular customer so yeah because they are actually shipping their code and they\u0027re actually products being built out of that and I think this one was for intelligent plugs or something and they they really wanted to have like very quick acknowledgment and it\u0027s a very popular use case where this behavior kind of works it\u0027s a dairy case I don\u0027t believe it would work just because of scalability your timers or all those things right so don\u0027t I don\u0027t think it\u0027s right to say that kontiki understood this it\u0027s just that they knowingly did that hack for a particular use case right it was actually better for them easier and just do the trade more nicely right so the design in the left is the official one in repo and like you said you the official thing is you take responsibility meaning you take it to the end if you can\u0027t if you if you push it to your parent and your parent cannot accept that you have to repair it yeah and if you\u0027re completely broken then you you have to poison but so so it\u0027s it\u0027s wrong to say that the child will never know either the parent will and all the responsibility and push it or it will detach it might find a new parent and push it through that new part and even if that fails then it will completely have to detach because now it cannot end oh it\u0027s rotting right so the whole point here is yes you can you have methods to accept the responsibility and I\u0027m sure it won\u0027t just stay there right something will happen so the method that you\u0027ve just described it actually requires a lot of state again because now while the parent switching is in progress and if you are holding the Dow information that means you\u0027ll have to you\u0027ll have to keep it with you for longer time you you\u0027re supposed to keep a state for every Dow you have not in any sequence right but "
  },
  {
    "startTime": "01:01:01",
    "text": "every child every address you have a state and you have to know if your parent is aware of it that\u0027s one yet you have to track her at your peril technology what did not and you retry what your parent did not acknowledge till the point where I did and that\u0027s that\u0027s part of story mode I mean I don\u0027t think it\u0027s a national state it\u0027s just what you have to do if you have acknowledgements right yeah but the I got the point so basically what you\u0027re saying is the routing table already has that information along with the state so which and we can have a flag saying that this has not been sent upstream it\u0027s right off report stomach mode the hack is oh I\u0027m synchronized with them you see so when you have this now that you got from a child and it\u0027s not yet acknowledged by your parent you need to know about this there must be a bit somewhere which says but what about the lake for the problem that we faced is let\u0027s say for example the acknowledgement is received by in six in six and the application traffic is going to get started let\u0027s say for example it\u0027s acquired traffic now while all these things is happening in parallel repo doesn\u0027t give you that so you know that the state is progressing through the network you don\u0027t know if it reached the destination so we discussed about and that could be in one of those draft that Michael is talking about but an acknowledgement by the route you know all the way down okay now I get it you could you could add a mechanism like this maybe it\u0027s one of your side yeah yes so it\u0027s just that last time and yes this one I would I would agree with okay okay okay so so essentially what we so the although all the observations that we have on what we have quoted is in context to quantity all right we also have our own private implementation though which which ran into similar problems and then we check how open sources are handling it and that\u0027s when we actually went ahead and actually included a lot of other things that are not handled properly no processes we have not quoted those because those are just implementation works you know so we have not included those points so the easiest way to handle this is and without much storage requirement or any state requirement is by having route acknowledged the DAO this will be much easier much the only problem with this approach is that you cannot do tag aggregated acts you can\u0027t aggregate multiple acknowledgments in the same in the same package so you\u0027ll have to send an individual because this is essentially unicast traffic back from the root to the know so that is one of the downside another problem with so now act whether it is ripple is not very clear on how to handle aggregated targets it certainly allows handling I aggregate targets but it doesn\u0027t do failure handling what it means is if you have multiple targets in the same Dao if one of the target fails what to do there is no clear explanation other implementations already which enable aggregated targets by default in the implementations and it is absolutely "
  },
  {
    "startTime": "01:04:01",
    "text": "impossible to get anything to interrupt the open source implementation at multiple hops multiple hops if you put five notes on the table all the odds are talking to the water out of everything works fine but the moment you try to scale a little bit nothing works that is how it assisted a handling node reboots now this we had a big discussion lollipop counter sort of handles again the point here that I\u0027m trying to make is lollipop counter requires some sort of persistent storage even though it is a little very small only it is only required for the linear part it still requires purses or storage if you want to get a if you want to get a deterministic way in which the node can join the network deterministic means within a particular time bound not like in a few milliseconds but at least in a few seconds it should be possible yeah the primary question here is should deployment provision persistent storage for network stack even though app does not require any persistent storage so this is this is a big debate that we had internally inside our deployment solution handling resource owner ability now this is the this problem is with I think this problem is you know we handed by other drafts now it\u0027s about neighbor table and routing table getting full and how to handle it if if if the routing table or neighbor table at an upstream node gets full so how would the down sink node come to know about it and how to handle all this ignorance I won\u0027t go into the details of this because there is some work going on in the context of this decision should transit information be optional now currently the transit information is optional transit information contains key elements like path sequence and the path lifetime parent address for non storing mode of operation it is optional there is no way parent address can be an optional element for non story mode of operation so it has to be mandatory so these are some of the points that you know aggregate a target container aggregation can be optional but at least the reception of aggregated doubt should be made mandatory so that the implementations care to follow that how to do it I mean this is something that is left to discussion but this is there is some idea that we have proposed here maybe some of the work will require separate drafts like Michael mentioned even the acknowledgement or acknowledgement work might be a separate draft because it requires a different is it is a different discussion for all the other parts some the handling resource owner ability there is already a work in progress I feel six dish the enrollment around sort of handles it for the six dish the rank priority the same mechanism can be used here in ripple as well so that it informs the downstream nodes whether there is enough capacity on the upstream path there so our plan was to actually work on these problems get some data statistics prove that the control over it is much large in certain cases and then come back to the working group that is the way that we had thought about one more thing that we wanted to discuss is there are other implications when it comes to multiple link like use of multiple link so in our "
  },
  {
    "startTime": "01:07:02",
    "text": "department we are actually making use of PLC and eight node 2 dot 15.4 in sub gigahertz at the same time and there are some issues that we saw one of the issues mentioned here but maybe in I won\u0027t go into the details of this problem maybe the reason why I\u0027ve just mentioned here is so that I just want to highlight that should we take into consideration these problems which are related to multi use of multiple linklater technologists add they\u0027re great okay then maybe this is something that we can add to the term cancer Thank You Veni questions I\u0027m Charlie Perkins I\u0027m here to talk about a ODB ripple we not too long ago released a update for the draft and so this is in response to comments that were received during last call and I\u0027ll just take a couple of slides to go go over that so there were some questions about sequence numbers and that was a clarified in the draft there was a sort of it\u0027s been mentioned a couple of times have requested why don\u0027t we use the NotI version number and D TSN well the main reason was because early on when the draft was being done the large part of it we didn\u0027t understand exactly how DTS n was supposed to work and I asked a couple of people and still didn\u0027t get a full understanding so now I think I do have a better understanding of it but it still doesn\u0027t really seem to be appropriate to use it in the same way because it\u0027s designed within riffle because the version number is always zero and and the DTS n is further down and there\u0027s not a Down message and a ODB riffle well that\u0027s not to say it couldn\u0027t be done but since we have a different mode of operation we could change the meaning of things and and use that but it seems anyway already the sequence number operation is handled well the way it is in the current draft and and it does what it\u0027s supposed to do so these sequence numbers are now weather ignore a bit so in the recent draft it was suggested that we make those into the lollipop counter sorts of rollover operation and so that was done and it\u0027s a discussion that Rahul just had with lollipop counter I think applies in our "
  },
  {
    "startTime": "01:10:02",
    "text": "case too and so we probably do need to make further clarification on what the linear part is and then so on on that and that I think is but right now you just refers to the event that the lollipop counter is done the same way as it\u0027s done in ripple so that that might be good enough but I think we should be sure about that and then to answer some other questions about how the sequence number is used so the originating node increases the sequence number same way and whenever it wants to find a new route and that\u0027s in the request d io message also our originating node can put in a target sequence number which is meant to say that it\u0027s not interested in getting routes unless the sequence number is greater than what it already has for the target sequence node and that is intended to eliminate the possibility of accepting route updates for operations where the packets are still somehow being forwarded in the end the network this is all pretty much modeled on the way Mao Devi did it in RFC 35 65 35 61 and also iota V version 2 which is currently under review but so that\u0027s that\u0027s how that\u0027s supposed to work and then the intermediate routers also follow pretty much the same sort of the philosophy they only use they only update their route entries when the sequence number is greater and finally the target note includes its sequence number in the route reply when it sends a rail reply back to the originating node another one thing that I didn\u0027t put in a slides but I at least like to mention is that there was in the earlier there was requested that a ODB ripple also enable handling of multiple targets and that was done by having an AO DV ripple target option and one of the larger editorial changes in this version of the draft was to just instead of always writing out a devii ripples target option now we have the AR T option so that made some of the text a little perhaps easier to read in addition to that it was pointed out that our lifetime maybe wasn\u0027t quite big enough so that the values now for the route lifetime that are indicated by the L field which is a two bit field have been increased I\u0027m running out of water "
  },
  {
    "startTime": "01:13:02",
    "text": "in my mouth so that\u0027s really a great organization thank you okay question okay so the and it\u0027s worth routing just this is another feature that was added earlier in response a lot of comments were received earlier this year and last year about well why don\u0027t we have some features that were present in RFC 6997 and so now I ODB what ripple was improved to handle source routing as well and so these address vectors only exist at the originating node in the target node and so that\u0027s where the real lifetime would be effective and hop-by-hop mode if you have routers along the path then they threw out entries will be updated when they receive router replace route replied with larger sequence numbers and if the routers aren\u0027t on the old path and eventually I mean on the on a new path that\u0027s I\u0027ve created but for the routers that are not on the new path then now route entries will just be expired and so that\u0027s pretty much the way that works also modeled on what was in RFC 6997 so that is pretty much it there wasn\u0027t very many changes if you do a diff between version 4 and version 5 you\u0027ll see that it\u0027s mostly editorial especially with this a or T nomenclature and I think that the draft has responded to all the comments that were received during last call but it could be the terms needs to be a little bit more tuned up according to some of the discussion about lollipop Powner kind of rum specification and so on so I guess we\u0027ll take a look at that and see what to do next and maybe we\u0027ll be done I want to look through the document to see if I understand it completely and scold and for this document ok that\u0027s I mean that would be appreciated and I think we\u0027re sort of in last call but more or less called us yeah no problem great and yeah email on the list or whatever you know thank you very much "
  },
  {
    "startTime": "01:16:05",
    "text": "[Music] [Music] hi I\u0027m iris I will be presenting our the next of our the next steps in our work for the traffic aware objective function so since the previous version we have changed definition of what the value reported in the metric container was we used to report the packet transmission rate which is similar to what Rahul has mentioned in the mailing list and now we actually report the remaining throughput and I will explain the difference we have also addressed parent selection and other direction and we have defined some configuration values for how to measure the there\u0027s something that how to measure the used throughput in order to calculate the remaining throughput and finally we\u0027ve also described how to use this within a Ruhlman in relation to Michael\u0027s work so as a quick recap there are multiple objective functions to use in order to pick a preferred parent you have objective function 0 which uses the X and has no doesn\u0027t use a hysteresis then you have mr. Hoff who chooses basically any additive metric and uses hysteresis and there was also draft which is called LBO F which reported the child count of a parent and used hysteresis in order to do load balancing now the problem that we\u0027re trying to solve here is related to load balancing so we have note which are overloaded and you might actually have tow docks which are overloaded in terms of traffic which leads to a lower life time for the network and notes because the energy consumption is not smoothly distributed and depending on scheduling you can also have higher packet losses or in the higher packet delay due to extra queuing on the nodes so what we propose here is a combination of an extra metric called remaining throughput and an objective function for the metric we use it in aggregated mode with a minimum function and it basically does tracking as the not operate of how much throughput has been used how much forwarding a node has been using within a specific window of time here configured row variable and then if you "
  },
  {
    "startTime": "01:19:08",
    "text": "know how much capacity for doing the forwarding you have you subtract what you have used out of that and you get the remaining throughput so that that\u0027s basically a metric of how much space you have extra for sending data around in addition we also define an objective function which basically picks the node with the highest remaining throughput as preferred parent and you can also do a hysteresis like mr. Huff to limit how much switching of parents you do there\u0027s a small example of a Dao here and we basically add this within the Dark Matter container and here is an example of the remaining throughput so it\u0027s just a normal metric object we request a new type for the routing MC type it\u0027s noted that we need to use a minimum function in the agar in the a field and it\u0027s basically two octave to two bytes which report the number of packets sent within the the last throughput period so this is quite similar to Rahul\u0027s work the only difference is that we report the remaining throughput not they use throughput and I will show in a few examples now so in this case on the left hand it\u0027s the same network on both sides on the left hand side you have the unbalanced network on the right one the balance one and in this case all the leaf nodes the ones yes the leaf nodes down here all require the same traffic it\u0027s one packet per second as an example as you can see a here has a total throughput available of two packets per second which yet it can handle and B as well however since it has three children its overloaded whereas B has some spare capacity so if you want to balance this one of the three nodes here c1 to c3 needs to move over to the B as parent now in this case the lbf objective function would work quite well because it have it just so happens that you have the same number of the all the children have the same throughput requirements however in this next example if all the children or the leaf node don\u0027t have the same traffic requirements then LPF won\u0027t work so in this case for example a has some spare capacity and B is overloaded because this child requires three packets per second so in this case you\u0027d basically need d2 to remain with B and you want to switch over here so that both are within capacity we also have "
  },
  {
    "startTime": "01:22:10",
    "text": "some examples relating to the other collection so in this case you have a node C which is trying to pick a daughter to join to and you have to do dogs 1 \u0026 2 both of them are within capacity but one is right on the limit so it can handle 4 packets per second and it is actually using 4 packets per second right now now if you don\u0027t have this remaining throughput information what will happen is that you might pick Doug want to connect and in this case your overcapacity and if you don\u0027t use our tu ztx or something like that maybe after some time you\u0027ll realize that you\u0027re losing you\u0027re getting some packet loss and you will switch to the other one but it will take some time to do that switch yes let\u0027s go here should I go back throughput is a very dangerous metric to be used in a routing protocol we\u0027ve known that since after Nets it\u0027s kind of not new news because you tend to to create Aussie Asians in your network I like this kind of a ties is more capacity people everybody moves to the side and and then then obviously the capacity is bloated and so everybody moves to the other guy and so III don\u0027t see that you can do a lot better than a Pinet in the distributed fashion if you stick to the idea of a preferred parent or or just one next half so the knowledge of throughput is very useful but it\u0027s useful to slowly rebalance across multiple parents so if you have those parents and you use them like this and you see that one has a bit more capacity then you move a little bit of your traffic to that parent but just a little bit at a time and then you see how the whole network rebalances and then if there\u0027s still more capacity to em you switch a little bit more traffic but you keep using all your parents otherwise you\u0027re in a pennant and your network will bank bank buying Aussie lights so so as long as you present it like you do with just IRA parent so you think that hysteresis function won\u0027t be good enough for this to control this abrupt changes I think that you need to use multiple parallel if you use that metric not just one okay and and slowly adapt and see what your change does etcetera so that you go from a stable state to a different stable state I supposed to create why this patience okay so as far as I can tell your objection is not so much on the idea of carrying this information as to how the objective function will be use it or how the each node will use this information I don\u0027t agree on the "
  },
  {
    "startTime": "01:25:11",
    "text": "behavior which would be change your default your preferred parrot and send all the traffic to the preferred route okay do you think there\u0027s a meaningful way for a node to know how to switch this information so it will have to have an idea of how to split its traffic around right thing that you slowly to report gives you a dag right so you have multiple parents this is metric that comes in a world while you use all those parrots and and and you tune different facets that\u0027s that comes with it so it\u0027s a cool thing to do in RIT because of those multiple paths but don\u0027t turn to up on it okay thank you well now I have the rest of the presentation using this so one of the issues it relates it\u0027s actually good that we finished this because one of the things that we are discussing the next one it relates to data collection with multiple metrics so in this case for example you have multiple docks to pick B to choose one of the dogs so for example here you have a pledge knot in the middle and it has to pick between three dogs and the three dogs have different remaining capacities but each of the potential parents this pledge node can connect within those dogs have different ETA X values so if you you can use a combination of two matrix for example with highest priority being the remaining throughput and seconds prior to being the et X and using that you can pick both the best the highest remaining throughput and the lowest etyek so if you do that for example in this case the highest remaining throughput is Indo that one and within the two children that are accessible here it\u0027s not B which has the lowest etx however it might be interesting to check whether you want to filter out some values of EDX so maybe it takes seven is too high so then you also add a constraint in the matrix and you tell it you know what if I need to only pick a parent which has an EDX lower than seven and that means that these two nodes are filtered out because they both have an ATX 7 or above and then from the remaining options from this daughter can they stock you pick dok2 with C being the highest value now the problem is that you might actually be too restrictive in your filter and in this case if you use an etx of more than "
  },
  {
    "startTime": "01:28:11",
    "text": "five for example then both of these dogs are filtered out and you only end up with this dog however this one has no remaining capacity and in this case it would make sense to use a non-optional constraint in which case you would do some extra backtracking and use a dog which normally doesn\u0027t cover the constraints however it does have a valid value for remaining throughput we also handle enrollment in in the new version of the draft so one of the interesting things is that while what I said does make a lot of sense maybe it\u0027s not that important for the joint process itself so for the ones joint process you might want to directly use the best parent I don\u0027t know if he agrees so for the enrollment process for layer two we have defined how you would convert the remaining throughput into the pump priority field Michael describes since the pond priority value is basically opaque we don\u0027t really require it\u0027s not really important that you require the exact remaining throughput it\u0027s just a relative value between different tow docks so in this case we\u0027ve decided to use a log function because the remaining throughput is a 16-bit value and we need to compress somewhat smaller value so we take a look on it and we convert it into the prior one priority by doing a subtraction so that lower so that a higher value of RT turns into a lower value of contra or ax T using the log function actually helps that we have higher accuracy in the lower values of remaining throughput so there\u0027s a bigger difference between if you have a remaining throughput of one versus three whereas for higher values of remaining throughput it doesn\u0027t make us a big difference and while I know that it\u0027s not generally a good idea to implement such complement a complicated functions at least for this case you can implement it with a bunch of shifts and doors and lookup so it should be efficient enough finally something that we\u0027ve already mentioned the arraignment for ripple so again as this example shows we can use it for picking dogs as well so one is for layer two and one is for layer three so finally we\u0027ve we have some we\u0027ve had a review by Derek and we have addressed comments in that we have presented our paper in a conference in 2008 and we have a Kentucky implementation which is "
  },
  {
    "startTime": "01:31:13",
    "text": "very close to release for this draft so I would like to ask what next steps would be if someone else would be willing to review the draft or if there\u0027s changes we should make and what the paths if any for adoption would be thank you thank you hey someone will review this document okay thank ya - so the next test would be like a dress fancy and go for adoption okay thank you very much thank you very much hello my name is Jorge from unit Atlantic and I will present you some updates basically we\u0027ll be simulations that we\u0027re on set of simulations and we\u0027ll show you some results on the draft that we are working on on NSA extension so we got reviews from Diego during the previous day\u0027s so thank you do go I\u0027m not sure if he is online No so we are like polishing establishing comments on the draft so the zero 3 version applied these Iago comments and the second point that I would focus today is about the results that we run since ITF to 102 I\u0027m not sure if I have time I will go through briefly what\u0027s the concept of this draft and then I will show you the results so basically what we have here is to employ PR e over 60 sixties Network and the objective is to bound the delay and to provide reliable communication and to do so we have these three operations the replication elimination and the overhearing procedure so basically we have the reputation when s since his data packet to its preferred parent and then he replicates the same information to his alternative parents then elimination procedure is the reception site when the Divine\u0027s once it received the original packet and then he receives its duplication he will eliminate this copy while the third operation is the overhearing these things to nature of the wireless communication when s transmits to a B may overhear this transmission and vice versa when as will replicate the packet to be a my over here as we double the opportunities for a packet to go up in "
  },
  {
    "startTime": "01:34:15",
    "text": "the duct so in this draft we propose a way how to select the alternative parents and we define to select all transparent based on common ancestor and here is the example so basically in this use case this will select B as an alternative parent because they are having common ancestor which is the so d is the preferred parent of a preferred parent of s so we call it grandparent and apparently D it is within the parent set of B so B it\u0027s a good candidate for s to be an alternative parent to so we need to update the CIO control packets where within the metal container we and we think the NSA option we define until V called PS parent set and we think this parent said we least set of ipv6 addresses where the first one is the is the preferred parent so for s for instance sorry for a when able forward is di yo abled yes will send this di u packet we have three basic addresses where first will be it\u0027s a default parent the preferred parent and see II will be the parent set I will go quickly from this slide where we have the example of the di u format then we go to doc MC type 2 and then the next slide here is our NSA option where we think this we define PS parent set type where we have this set of ipv6 addresses or compressed thanks to my comment from last two ITF meetings so so far we implemented three different versions of a common ancestor alternative parent selection and the first one we call it strict where the alternative pattern 4s will be only the device that has a common explicit preferred parent basically my grandparents will be the preferred parent for my potential alternative parent in this case it\u0027s valid only for b2 because b 2 has a preferred parent F which is my direct current power so this is called strict mode then we have the medium mode which basically says that my grandparents my preferred part of my preferred parent will be within the parent set of my potential alternative parents should give you some examples so apart from b2 b3 can be my potential alternative parent because F which is my preferred parent of my preferred parent it is within the parent set of B 3 so b3 consists of F and G so in the medium version B 3 can be option to choose as "
  },
  {
    "startTime": "01:37:16",
    "text": "an alternative parent and finally we have this relaxed version it basically is intersect of two parent sets so basically if any of my if any of the parent set of my preferred parent is missing its overlaps with the preferred with the parent set of my potential alternative parent then this other inspiring can be my altar and defined as my altar and so in this case even b1 we have the overlap of e can be potentially my other difference so this is the relaxed mode and we did not run yet ex experiments with this because it really makes flooding in the network but I will show you some results for our two previous options so here we run a set of simulations so on the left side we have this default ripple with single parent and then we have two packet replication elimination options so the first one here is again the default version of the ripple where the default parent and the parent are selected by default based on the best to rank parents and then we have the option packet replication elimination see a common ancestor with a strict mode so the result shows that definitely PR improves the reliability when you compared to default ripple and little bit the PR e we called here e TX in it\u0027s better than the strict CA by 2% but there is a cost to pay for this and the cost is the for instance in this case the number of devices that the single packet traversed in the network meaning that how many devices this single packet went through based on these duplications so you can see here we these PR e with e TX been through more than 14 devices failing links or all the links they are released more than 70% yes between 17 to 100 so that\u0027s our variable link thank you and then in this slide you will see when you the cost but you have when you traverse too many devices so the more you traverse the devices or the more you duplicate if you can see that with common ancestor we have a difference of more than 40% in terms of the duplications in the network so basically it\u0027s the an Ethernet packets but we say when you around this packet replication elimination with common ancestor algorithm so what we wanted to do next is to see how it works in the topology here this is a snapshot of default ribbon with a single parent with single "
  },
  {
    "startTime": "01:40:17",
    "text": "path nothing no surprises here and then we have this packet replication elimination with based on default ripple with two best parents basically and you can see here the level of the flooding that you have in the network right and of course this improves the reliability but you pay the cost in terms of the energy and duplication that you have in the network and then we are the solution the scheme that we propose here the see a strict you can see the ladder topology that we have here we achieved so you have these two parallel paths to until the destination but the only issue is that sometimes we may end up not having the alternative parent so this is when we running CA strict because not always the two potential parents and having the common parent like the class it won\u0027t have sometimes alternative parent so this is not always but sometimes we have this case now to avoid this case we thought to run the medium CA so the second version of the common ancestor and our results shows pretty interesting results so you can see that we improved the reliability we even overpass suppose the packet reputation elimination with it based on ETA X so have a really good idea what we play the cost as well so the cost is we increased the number of devices that we went through traversed in order to get the packet to this nation which eventually are the cost in terms of energy because we have more transmissions we have multiplications but in order to somehow mitigate this problem we discussed with Paschal Park no conferencing in September the idea is that to avoid having this problem here of too many devices that forward the same information so the idea was if you end up in a use case where you have only one device in the network we we introduce a bit in the packet so that we will allow to move from the stick mode to the medium mode and actually this this use case tells us basically every time we call it this strict to medium so all devices are around CA strict mode and once we are low the devices when they are having in trouble not fighting the alternative parent we allow them once in the network to switch to medium CA to find the alternative parent if they cannot to open the branch basically so by doing so we improved improved the PDR with some committed gate is the number of devices that we went through and this helped us to reduce by 14% more than 14% the duplications in the network so this "
  },
  {
    "startTime": "01:43:17",
    "text": "is ongoing work these results we got like two days ago so we are still working on even more to improving these to put some intelligence how to reduce even more these duplications okay so that\u0027s all I think so wrote forward oh yes this work was presented last for ITF we have partial code online so we have the configuration of the NS extension you will have here the link with of these Wireshark detectors for the tlvs it\u0027s online as well we could reduce so this is good for us now from Diego and from Derek we want more something interesting we start using this in education as well so we first did a tutorial this year in GIS conference of to our tutorial we had 25 to 38 and this is quite interesting discussion later and we are using pyaari in our teaching so it when we are employing 6 to 9 hours of teaching contiguous of the fluctuations it\u0027s quite interesting for the students as well and then we have some research on both conferences and journals here\u0027s some credits to all guys who helped us so far yes from Huawei Technologies my first question is regarding regarding how do you apply BRE only for the subset of traffic for example I might have maybe 1% of traffic where I am okay with to induce such kind of energy cost so that I can have more I can use this technique on basically my point is I want to use this technique only for the subset of traffic how do I do that because there is a cost in water this is my classification we did not touch yet so what we do is push so far it was like forward traffic but nice point you can try to do this for our portion we do not try you Pascal here okay so these periods from work which has been done in that night and things like that and certainly that net identifies the flows for which a particular attention needs to be taken and pier itself has a header that indicates like a sequence number and he and so that you can eliminate replication and and which flow it is and this sort of thing so this is this about how you can transport this in the network but obviously there will be something else which is not this draft which will indicate whatever is needed to do replication elimination etc and this is why we have this power discussion on Thursday right how do we enable mechanisms to get better results on wireless which take us closer to the spirit of deterministic networking even if people won\u0027t like to call we\u0027re less deterministic for number of cycle Jayco reasons still we want to get similar benefits on wireless as we do in wires with deterministic and so power is "
  },
  {
    "startTime": "01:46:19",
    "text": "all about this and this is one of the ways to do it so it just shows you as an example that are things we could do at the IETF which would below a modest domestic use more deterministic delivery of your packets and that is nothing to do with I Triple E right it\u0027s it\u0027s really a negative problem here Holy Thursday I mean in this in this paper maybe I will show you some results in the next ITF in this journal we show that we bomb the delay to 15 milliseconds look I feel personally in my opinion I cannot use Kuja for such kind of experience experiments you know where it does not have realistic error if you do the same experiment in n is 3 Orchestra Lea you have a different result all together that I\u0027m very much sure about okay so so if I heard it correctly I\u0027m saying that the actually actual data traffic will the forwarding plane will have some sort of ipv6 extension header inserted in it so as to know what flow it belongs to as far okay thank you just based on this present day route route based on this presentation and we would like to know what do you think about the if we should adopt this document so please hum against reasons the reason so there are all sorts of traffic now that we are seeing in here in my space which is more in the control area that needs the pure metric right so those networks now that we deploy are going beyond pure measuring and need more reliable transport for some more control type of activity and for those things actually our customers asking something like story mode and something like deterministic and we cannot really give either of them but we can approach that and this is typically a technique that can help approach determinism on those networks so so it\u0027s actually something we need in the field so that\u0027s why I\u0027m humming for for for the storing mode but "
  },
  {
    "startTime": "01:49:21",
    "text": "that\u0027s really where this fraud projection comes in because the current means we could not do storing mode in large scale so we came up with with rot projection but for reliability we need something like that and actually you should think about combining this with rod projection then you could call a project two rods and decide to do PR you about those two rods kind of that\u0027s what one example of things so you instead of having to discover those two paths like we do automatically now if you combine this with rod projection the controller could decide the two paths and this decide all the crossing so that there is there is a way in front of us to provide more detail mystic behaviors on those networks so that\u0027s that\u0027s what\u0027s behind all this thank you I\u0027m Charlie Perkins I don\u0027t have a actually opinion for or against but was just a little bit surprised about technique for picking out effectively grandparents I mean the reason behind this technique is to avoid the first flooding so the idea is we want to keep as close as to the main path that you pick up from the ripple yeah based on the ribbon in the rank so it\u0027s right the other parent to be always close enough to this path so that we avoid these flooding in the network as you can see maybe in this figure we sort of narrowly constraint missing and in order to do that you want to exert some control over their grandparents and then presumably as part of the mechanism the grandparents exhibit control over their grandparents yes exactly this is what we want that you but I\u0027m not sure it fits into an actual meaning you have Network degree maybe like as much as 9 there is a density where these things make sense and basically you the whole benefit of meshing is that you have multiple possibilities and if you have multiple possibilities then hopefully you get you get them all the way through to the root and if you get that think about it for a minute right radio is lossy so your starts of thinking a can I use radios for my application if it\u0027s kind of important for me right and on the other hand if you realize that radio has this "
  },
  {
    "startTime": "01:52:21",
    "text": "benefit that there is more than one guy who can hear you when you talk and you can use that other specific thing of radio to balance the first one in the one hand you talking to just one person is lossy but in the other hand other people\u0027s can call that people can hear you which which gives you extra receive can you balance this you can the solution of the problem is found in the same behavior of the radio which is the fact that multiple people can receive you and can you balance that that\u0027s exactly what we are doing here so at the end of the day we get a reliable transmission because we balance the listeners with the fact that multiple people can receive you so you must get away from the wired paradigm of this harp and then this happened then this hub and start thinking in I am progressing like a wave from A to B and what we are doing exactly is what Charlie said we are kind of constraining how this progression happens you don\u0027t recarey it progresses like through those guys through those guys but you\u0027re kind of building a multi-lane way between you and the root and you could use at each heart any of those lines to progress but you\u0027re progressing like a wave inside this waveguide that we are building here what yes it\u0027s a field everything is a field so in this field so but that\u0027s exactly what you\u0027re doing right you\u0027re progressing like a wave across this medium which is this if you think like a one hop and then one heart and then one hop if you think wire then you end up with a very lossy medium if you think like a radio now you can be reliable yeah make red you\u0027re great on yeah so I don\u0027t want to belabor the point it\u0027s probably better on the mailing list but I think it would be better to show some more general simulations and also there has been a lot of work done on what\u0027s called backup routes no words instead of having one path through you have a couple that may be a relatively closed track controlled by the metric and okay thank you [Music] hi this is Aras here so two point one regarding Dow projection so this solution is basically refers to when you don\u0027t have a central controller which can define your route so if you don\u0027t have that available this is basically the best I can do right the second thing is as far as the draft is concerned we "
  },
  {
    "startTime": "01:55:22",
    "text": "George\u0027s has presented more simulation stuff like that but at the end of the day the draft just proposes another option or TLV inside the NSA metric Ontario so the the size of the draft is very constrained and I would like to ask if if it would make sense to add more of the Pieri stuff inside it or if it makes sense to remain like a relatively focusing on just this extension okay thank you for the comment as we just a 5 minute so the rough projection did not progress much because I didn\u0027t get much review on it so let\u0027s I mean please look at it give us review so we can progress because for the time being it\u0027s kind of stuck so we\u0027ll just keep that and you will see there are many slides here for those who are not so familiar with it how it works and what happens etcetera etcetera the whole thing is the dahle projection is taking repo into the SDN world you have a controller you can establish storing mode along non storing path to compress the the rotators and you can establish horizontal tunnels so as to bypass between the source and destination avoiding going all the way up to the current part and with this I will go straight to unaware ripple anywhere nice well four minutes so giving you news there are three things really that these drive does and the number of things that it does not and what I would like the group to tell me is what what we want in this draft and we don\u0027t want in this draft so right now what the draft is doing is very simple you\u0027ve got this host it\u0027s not ripple aware we are using RFC 6775 update for a leaf node which is not aware of people to register to repo for unicast transmissions and that\u0027s where Tallis needs to think about it for a minute because that\u0027s that\u0027s the point you made and I\u0027m confirming it we are using this just to advertise an ipv6 address between a host and a router so the router can do repo on behalf of the host we don\u0027t do multicast so if you if you want to do multicast the idea today is you use MLD the way it works and that\u0027s how you would register a multicast address now the router based on that on MLD or this could term the IP address registration into a bit if it\u0027s aware of beer and advertise that all the way up as a beer thing as opposed to a multicast address in repo or a unicast addressing people that would be one way and that that\u0027s what we called kind of tunnel mode of something well anyway that\u0027s because you had so many names but that\u0027s when the leaf is not aware of beer at all if the wait leaf is aware of beer then we would need an extension "
  },
  {
    "startTime": "01:58:23",
    "text": "they have to signal the bit from the leaf to the Rotter which does not exist today notice I have four minutes for my whole presentation but I\u0027m just too right so basically this tract here this RFC 6775 update is how you register this unicast address all the way to the 6lb are which is not the ripple route and that\u0027s yet again a discussion we need to have and all the way back so for the time being we have separated the concept in this draft we have separated the concept of six LVR which is a six Lapine con concept and and what taller is called the six ro the ripple route but in if you read 6lowpan it says the same thing it\u0027s just that six top and did not specify what it would be from the leaf this unaware draft I I had to design the flow between the six lbr under six aha and the ripple root and this is an extra complexity that we may not want so there\u0027s that\u0027s really something that I want you guy to react upon do we consider that the Ripper root is always the sixth year is it by definition the same the same guy if it is then then there are some flows in this draft that we can just avoid now if we want for some reason to keep them separate then the flows that are in the draft are useful okay then so so like I said this this sixty or seventy five that we depend upon is now in DRF CID doc you will get the RFC number like before Christmas so that\u0027s good news because we depend on it so that dependency will be open now there is another draft which comes with it it\u0027s called ap nd it\u0027s the address protection so this thing allows the savvy properties in in sixth open ng meaning that if somebody forms on the dry side vertices it then somebody else cannot steal it cannot come and say I\u0027m him and attract the traffic and so traffic on behalf of the other guy with the savvy properties that a PNG is bringing in we will be able to filter the attacks at the edge of the network so if you have a leaf which is not people aware and that wants to steal the address of somebody else and get it advertised in the ripple Network the six Aloha th can filter that with ap nd it\u0027s a crypto mechanism to avoid that but this mechanism is just varied at the edge so if you really trust your ripple Network we are all set but if you think somebody could sneak in your ripple Network and start advertising addresses on the Alpha the 6ln then this attack would be possible and so my question my second question to the group here is do we want to extend not only RFC 6775 with Ana relief but also ap nd meaning ad mechanisms in ripple that "
  },
  {
    "startTime": "02:01:29",
    "text": "would an attacker to inject an address that is not below it on behalf of 6ln which is somewhere else in the network so do you want to extend the proof of ownership that we do in six level nd in repo my biggest question and after that I can pretty much constant you asked these questions on the mailing list because I think at this moment it will be very difficult to react to you in 30 seconds yeah yeah okay so basically I still question first do we need to first that this repo route is the sixth year or not if they are not the same there is extra cost in signaling when the note gets ill we really want that that craziness I\u0027ve actually shown how it would go would work but I want to get rid of it second thing is do we want to protect repo inside repo against attacks so somebody gets the keys of the real is capable to inject routes in the network do we want to get to use the fact that we have a P and D with the leaf to actually protect the leaves that are registered so that rogue repo router would not be able to inject belief which is not their questions is that logically part of this draft take very much Pascal well we are going okay for one question that is a ticket already open but it will be nice to put that the questions into the menu list okay okay thank you very much to everyone we conclude the meeting thank you [Music] "
  }
]