[
  {
    "startTime": "00:00:06",
    "text": "[Music] go he just deleted upload a new version right folks it\u0027s about that time we\u0027re at the TLS session and IHF 102 um I guess someone start by saying there\u0027s this new person to my right his name is Chris Wood he\u0027s our new co-chair thank you so this is a no well it\u0027s Monday so you might not have seen it take your time basically the gist of it is that you say anything at the microphone you\u0027re gonna be recorded you\u0027re being recorded now um if you have an IPR disclosure you need to disclose it that\u0027s one of the reasons why when we talk about pretty much everything on this agenda it all has a draft so that you have to go through the process of clicking the buttons to make sure you understand the Apgar rules figure out that requests luckily we have already have a minute taker we have a jabber scribe the blue sheets are currently going around please state your name at the mic and let\u0027s keep it professional at the mic as well I\u0027ll just get this right so this is our administrivia for our agenda bashing time we have two sessions today Monday is what we have here um we moved a couple of things around based on an early agenda bash from Victor if you want some extra time else and we have more on Thursday um originally we also had a cryptid ESI to dip or encrypted SMI today but we decided to move it because it\u0027s gonna be a long and lengthy discussion and we thought it would ask the kind of time doubt it at the end there so next the document stats we have two documents in all 48 right now on the TLS 1.3 draft is going through the the process of getting the updates done and hopefully we\u0027ll get that done fairly soon and obviously the ECC for Cyprus sweets for Till\u0027s from which earlier is also going through we have three other documents that have been approved by the ISD and they\u0027re kind of waiting through the cycle another draft that we\u0027ll be talking about later today is the dane record for Dena cycle dedication Jain extension for TLS we have an ITF last call going now for the example handshake traces and exported authenticators we\u0027re also going to talk about today which is gone through working with Les Paul we\u0027re trying to make sure we have all of the outstanding comets addressed and I know that Christian Whitman isn\u0027t here but basically the issues and requirements for SMI encryption and TLS the strap was split so last time there was there was solutions and as well as requirements we decided to split the last time and the actual issues and requirements trap is ready to go the only reason what we haven\u0027t hit the button on that yes "
  },
  {
    "startTime": "00:03:07",
    "text": "because we got all these other things in process and basically we were juggling too much and we have other drafts in play bridge yeah Victor requested that the DNS lock be Medina\u0027s item be moved back to its original slot fYI we can\u0027t we can move it or he wants it back so he said that in the image out okay great so will will we can we can bash that so that essentially we\u0027re gonna do export it authenticators first then we\u0027ll do the dns chain extension stuff and then we\u0027ll talk about to tell us um the press so for those why we\u0027re doing it this way is because these straps are working your blasts call don\u0027t want to make sure your predatory said first to make sure we get to the issues all right so first off rich you\u0027re up okay so in April so this is just you know some some numbers to impress in April we turned on the public beta for TLS one three and we told you know all of our customers if you want to do it you know go to the UI and make these portal changes you know config changes because this was like the first time where our life cycles synced up with the browser\u0027s life cycle in terms of the drafts I did a snapshot every 5 days and by you know under a month later we were seeing 650 million connections a day now the number of people who were enabled this is like it in a roundoff error in terms of percentage of our customers it\u0027s zero the other interesting thing about the chart is the dips or the weekend which means people are using this whether they know we\u0027re not in production for real world real world work it\u0027s been kind of stable so a couple of people have come in and out of the beta and I think Firefox is now drafting compatible with us but in terms of traffic this is like you know 1 or 2 percent but that\u0027s not bad considering that it\u0027s as I said zero percent of our customers can\u0027t give you any more numbers than that sorry the most other interesting thing for us is that nobody reported any incidents and in fact we went back to our support team since it really nobody\u0027s complained it all just works and well nobody\u0027s complained so anyhow I just wanted the show we\u0027re now averaging about 700 million connections that handshakes a day with TLS 130 which is pretty neat part me talk about deployment yeah so if "
  },
  {
    "startTime": "00:06:07",
    "text": "you want to change the protocol to enable man-in-the-middle the cats kind of already out of the back hi this is a Knicks 11 closer I can share some additional numbers from our sides which are relatively similar we deployed TLS 1.3 of various draft versions starting a year and half ago it\u0027s now up to in terms of number of percentage of requests served by CloudFlare 5% so 5% of requests are TOS 1.3 and it\u0027s enabled by default for all customers who didn\u0027t explicitly disable it and so I can\u0027t give you know apples apples number of connections per second but it\u0027s it\u0027s a pretty decent percentage Nick are you um are you 23 and 28 28 only that\u0027s actually no 23 and 28 right now a question on the mic you know what percent of our total traffic is that under 1 percent and we\u0027re 28 only yeah so we should be compatible you now we\u0027re 28 so right so I guess this is our telemetry data these are magnitude estimates um basically you know our client sent back telemetry and you know you have to like filter out or has an outlier problems because if you don\u0027t you get people recording like 8 million connections a day and like they\u0027re like prism we lying so this is a one person sample a lot of our clients and then the phonology is I take I take clients have Bucknam by I pluck it on my client ID and then I treat them is like that because your fraction per client of 1/3 and then you average all that fractions you normalize my client and so anyway this shows a sexually no 1 1 on the presentation in preparation for students presentation not much 100 and we\u0027re you know we\u0027ll in the 3% 1/3 on this is release beta shows more like 5 to 7 percent um don\u0027t know why um I wouldn\u0027t trust a I wouldn\u0027t trust these numbers to within 0.3 so I wouldn\u0027t trust these numbers to within more than a factor of 2 or so um but obviously we\u0027re getting quite a bit I\u0027m a CEO honestly I\u0027m surprised Nicola seems so little um given the Chrome and Firefox are both 1/3 by the fault and surprise you\u0027re not seeing more but we need to break that later and that\u0027s an excellent segue into our next presentation hi so is it time to "
  },
  {
    "startTime": "00:09:24",
    "text": "deprecated TLS 1.0 and 1.1 and we\u0027re trying to get the bottom of that and thank you to everyone for providing statistics on the list and information on problems that you foresee so this is short because we\u0027d like it mostly to be discussion go ahead please all right so oh good it\u0027s right here so we do want meaningful statistics across different applications we\u0027ve gotten some that are non HTTP the Apple ones posted yesterday or today thank you included non-http so that\u0027s helpful examples of systems or applications for which no upgrade path is available is of interest and if they\u0027re showstoppers so are they systems that if a major vulnerability was announced and your configuration possibilities didn\u0027t cover it would there be a big issue or could the system be isolated or even just saying what this is maybe the vendor will step up right so putting it out there and that pretty much covers that next section okay and are there other considerations we should be thinking about so you know I\u0027m thinking statistics showstoppers to help us figure out timelines and of course if it\u0027s adopted right away it doesn\u0027t mean it\u0027s gonna be published right away and then even when it\u0027s published we\u0027ve had several vendors say they\u0027re gonna continue to sport this in their next release like Richard said that for OpenSSL they\u0027re going to be putting out the next version so for the next five years both of these versions will be supported and OpenSSL so you have your bases covered for a bit to help us with this deprecation but the numbers we\u0027ve even seen just with the 1.3 they\u0027re pretty low hi Jeff Hodges PayPal something we noticed in our PCI mandated upgrade here over the last couple of years is that in the case where you where somebody doesn\u0027t operate also operate the client side okay it\u0027s like they\u0027re out there on their own you\u0027re offering service over the net from your server there\u0027s no way to tell when you upgrade what happens other than warn everybody and then have a flag day right for some percentage of your customers and this really sucks yeah I actually had read the page from PayPal and a few other vendors when they did this cut over for PCI and their flag days and that was and just have mini flag days and and try to roll it through your customer base and also you may not catch everybody because they may make changes in in-between the windows where you\u0027re trying to do your testing and such so gee we\u0027d like to put our heads "
  },
  {
    "startTime": "00:12:24",
    "text": "together with various interested parties you know self-nominated and you know brainstorm there\u0027s any something we can do in this context ITF to come up with something to make this easier for when the regulators go oh by the way you\u0027re migrating to 1.3 for example or everybody has to go to 1.2 right now they say 1.1 right we had our customers go and merchants go to 1.2 right and the reason we bundled in 1.1 is because there\u0027s such small numbers or deployment so it just seemed to make sense to just bundle it in there because people should be going to one two as a minimum not one lon if you\u0027re making a move right so anyway at this stage of the game if anyone wants to chat about this feel free to reach out and tug my sleeve I\u0027ll you know we want to talk about it over for the foreseeable future and see if there\u0027s something we can work out and just what\u0027s your name some definition of we Jeff Hodges yes I\u0027m on Thompson I think the the ultimate answer here is going to depend a bit on the deployment context in which we\u0027re talking about for the web at least we\u0027re starting these discussions now we\u0027re seeing as you saw on on-air Co slide there on usage rates we\u0027re now getting pretty close to the point where we can probably start turning off tell us 100 in web browsers at least maybe not straightaway but Layton in eighteen year eighteen months time I think it\u0027s perfectly reasonable to expect that to sort of quietly go away and you\u0027re actually seeing sites now just deploying one too and that\u0027s something that sites can do already and that\u0027s not a big problem for them because browsers tend to be evergreen and they all have tell us one to enable then there\u0027s not really a whole lot of point in trying to talk to someone who\u0027s only got till s1 o because they also probably have a bunch of other problems at the same time and so that\u0027s but the discussion Lisp was pretty clear that there\u0027s a large population of use of TLS 100 in other contexts and it\u0027s going to be a lot more difficult for those contexts to do and so I don\u0027t think it\u0027s a problem for us publishing a document I would be perfectly happy having this document published tomorrow as a statement I think this this organization can make that statement now and that has an effect on the actual rates of use which would be positive I don\u0027t think it needs to be called die die die Croft and we just like to get rid of some tech debt so it\u0027s not really that dramatic right well we just put the die die die because all these drafts that we deprecate have been die die die right so but the media picked it up as a very strong statement and I was surprised by "
  },
  {
    "startTime": "00:15:24",
    "text": "that too it doesn\u0027t need to be that strong but that\u0027s yeah well because so I agree because vendors will continue to support it until their customers are off but this is a way to help get customers off these older versions so you could reduce your footprint of code and we have that too right we where I work at Dell EMC its largest IT company right we still have some customers on 1.0 even though our official stance is that it\u0027s been deprecated I think it\u0027s important for the IDF to send a signal yeah and publishing this now is a pretty effective way of doing that so I\u0027d be sort of on board with doing a little bit more of the groundwork to be talking about but then just publishing this when we\u0027re ready to publish it which hopefully is soon right and just helping with the deprecation curve to speed it up it may not make it see so but over here yeah bingo Franken Bank of America so I guess my point is similar to Martin\u0027s in that I don\u0027t think we need to consider use of statistics at all in this decision because even if it no matter how many users it has our putting our putting out a standard track document entitled die die die does not actually RM all those implementations and make them die die die nothing actually breaks so what the only thing that should make us consider not publishing something like this is if there are some actually architectural sound reasons to keep these protocols around if it\u0027s simply a matter of technical debt sitting around and nobody\u0027s bothered to pay off so for example the but by far the most common problem I find what about why these protocols can\u0027t be to seybolt is simply that I find that a programmer misunderstood the OpenSSL api\u0027s and hard-coded a particular protocol person without meaning to so if we\u0027re just dealing with those sorts of reasons and I think we are mostly just dealing with those sorts of reasons then we should not hesitate to publish this thank you Eric Sprott thanks for publishing this um I think it\u0027s read idea I was gonna get up in the system with Daniel said which is that you know we\u0027re telling people as the IETF no longer thinks easier or safer to calls and we should be and that\u0027s the principle why we did one too so I don\u0027t think it\u0027s a problem to say like we understand you have reasons why it\u0027s our freedom away from them but we advise you to do so it\u0027s positioning so I mean should we add something for some text even for people well that\u0027s not even adopted yet but to explain for enterprise networks and people that might have trouble what it means because I think just I I teepee being overtaxed is probably what we\u0027ll hear most about Bret Jordan thanks for publishing this I "
  },
  {
    "startTime": "00:18:26",
    "text": "think it\u0027s a great idea I agree with accurate and Martin I do think the fundamental problem is not whether or not we published this and we come out with a public stance saying the IETF thinks these two go away because they should have come away a long time ago it\u0027s the fact that most people to implement TLS don\u0027t have a clue as what they\u0027re doing and they go out and they search google and they find something and they just say oh this is what will make it work and they just copy and paste that in and boom it it that\u0027s all that goes so so that\u0027s our fundamental problem with a lot of this but I thanks for publishing it I do think it\u0027s a great idea yeah and that was part you know folding back into my company and then seeing people you know our product teams had to make these decisions and then all the customers would have these four choices soon and that just becomes more complex so reducing the number of choices I felt would be helpful after only me gets up we\u0027re gonna cook the lot this is Dan Gilmore selu so +12 what everyone\u0027s been saying that we can we can afford to publish this without driving all the numbers down to zero first publish this will help us try the numbers down to zero and I also want to observe that there\u0027s there are multiple audiences for documents like this and if we\u0027re careful we can make sure that the document is useful to all of them and when I think about different audiences I\u0027m thinking about both implementers and deployments and if the document actually provides clear advice for implementers such as given the state of the network today you may not be able to remove this entirely but we recommend that you do the following things right so like cipher su prioritization you know version prioritization warnings logs warnings out to the other end party that we can we can provide useful guidance to implementers that will then themselves provide additional Spurs to deployments so we published this now in order to drive adoption we don\u0027t wait for the adoption to drop in order to publish it Erik Nygren Akamai yeah and I think I\u0027m also following on with us I think the be focusing on rather than kind of the dye dye dye which I\u0027m sure will come up at some point but it\u0027s not for now I think a lot of it is really trying to get implemented for example if they\u0027re doing something new to not even think about implementing TLS one wonder if one Owen and new things are building in looking at statistics on this it\u0027s it the any of the numbers of kind like here\u0027s an overall aggregate number are a little bit misleading I was digging into some on someone\u0027s I have access to and we\u0027re seeing that it was that that it ends up being very you have a distribution of different use cases you have some use cases where people have happily turned off everything other than below TLS one two and things just work fine for significant fractions of customer sites then you have other cases at the other end of the spectrum where where you have significant numbers of sites where where 80% of the traffic is still using old versions of TLS often times because they have custom they have custom client software and we\u0027ll just so we\u0027ll just need to be be a little cognizant about not wanting to force everyone just cuts all the plugs off on the pull the rug "
  },
  {
    "startTime": "00:21:26",
    "text": "under some of these custom implementations that where their use cases with 100 might action might be better off than the alternatives if they tried to do something even worse Nene Elkins and enterprise data center operators yeah I actually find myself in in in with the number of things that have been said I think Jeff\u0027s idea of how do we reach out and educate people to do this and also what our friend from the ACLU said about I find myself in a grito Legree surprisingly ISM yeah we need to have guidance for implementers but it\u0027s it\u0027s a tricky problem people really are trying it\u0027s not so easy that\u0027s as I say so so any help and it\u0027s the client software at these hands and so maybe reaching out to those vendors you know I mean I\u0027m just throwing people you know that that there\u0027s a ton of these guys out there and and so that might be it\u0027s just but it\u0027s a somewhat smaller subset so so some kind of reach out and I\u0027d be totally up for up for a you know a word a group that got together and thought about some of these things yeah even if there were blog series and the media picked this up within 12 hours of when it was posted even though I didn\u0027t post it to the tls list so I think when it\u0027s finally published it\u0027ll be highlighted pretty broadly so so Jeff I want to I clip the line just just quick follow-up thanks Jeff Hodges I want to echo what dkg said I support the draft but we TLS working group could do a better job of figuring out how to facilitate deployers in their upgrade efforts alright so um I\u0027m gonna do it can I have a show of hands who\u0027s actually read this draft Wow so fair amount my plan is that we\u0027re probably gonna run a working group adoption later um I should note um I tried to do this five years ago I got my head handed to me by the working group so I\u0027m glad I can put it back on the second thing is we had this working group called Utah in the art area right and they years ago when like 2013 was when this work started and I guess in 2016 or something they finally put out a draft that said hey you should be doing 1.2 so this is not new um this is something that we should just be doing um so that\u0027s it so alright guys great next there we go Nik hi I\u0027m talking about expert authenticators which is draft that I\u0027m currently working on next slide please so background in this is an expert at "
  },
  {
    "startTime": "00:24:30",
    "text": "Authenticator is a method for one peer in a TLS connection to assert ownership of the private key of an additional certificate and this can be either the client or the server and this proof can be sent out of band although it\u0027s bound to the TLS connection that it was originally established with this work was motivated by the HTTP this working groups additional certificates trapped which is a method for enabling post handshake client authentication at the HTTP layer as well as additional server authentication this was adopted last year and the latest update to the draft was earlier this week last I 80 F there was a formal proof of security presented and a paper published by Jonathan appointment all right so between the last IETF and now this went through a last call and there were several comments the main request or the made change that was requested during the last call was the idea of an empty Authenticator as the draft was written before every exported Authenticator was tied to a certificate in a certificate chain and there was a need for a server to do a explicit refusal for a given Authenticator request and so this was added to the draft in response to these comments next slide please alright so in any case that\u0027s that\u0027s sort of where we stand right now there has been a lot of traffic on the the mailing list about this but there has been some discussion and I propose some next steps would be a new boss call for this draft does anybody have any other outstanding comments against the strap that we need to consider because otherwise we\u0027re going to do exactly what Nick is asking for Jonathan Highland if we can do another last call it\u0027d be really nice if in these spontaneous certificates we added a requirement that they be unique the certificate request context can be arbitrary at the moment making it be unique which make life easier for me this would be easier for the the analysis yeah it just it makes the analysis easier because if it\u0027s arbitrary then it could be all kinds of strange things and this is unique from one pair to another or you text in the context of the connection because it can\u0027t it can\u0027t be unique globally because this typical request context is set to empty in various cases right is there not a problem with two authenticators that could be generated at the same time being sent sent across a parity bit would solve that it doesn\u0027t "
  },
  {
    "startTime": "00:27:32",
    "text": "matter if they\u0027re sent by opposite parties it\u0027s whether server sent well a service sending the saint\u0027s two different certificates with the same CLC certificates or sorry to EAS okay same CLC because at the moment that\u0027s allowed and it makes the proof complicated okay Mike Bishop Akamai and offer on the secondary search draft we already have the requirement that the context be unique within the connection so adding that at the TLS layer would be fine now we do need to be able to generate multiple Authenticator for the same certificate potentially I presume that\u0027s not all it doesn\u0027t matter if you use the same certificate multiple times although it does get a bit complicated if you do if you generate spontaneous difficut and send the exact same certificate again later then in response to requests no no not as if you were to send a spontaneous one not in response to requests so for some reason you sent in the a and then you recreated and sent the exact same ei later in the connection that\u0027s complicated to prove I mean you can prove it but it\u0027s just so requiring it to be unique in the context concept con would make it easier but high level requiring that the context be unique in this in the context of the connection that\u0027s fine sounds reasonable Jonathan ants get back to the text about the if you didn\u0027t guess what I think am I crazy is there a not missing in that sentence if the endpoint does happen appropriate certificate does not yep you caught the typo does not have an appropriate certificate or does not want to return them yeah it\u0027s a except denial not a proof of non-existence cool so um will you be able to spin another version of that to include the the guy thinking Jonathan just asked for yes great and the quicker you do that then the quicker we can hit the button okay thank you next now we\u0027re doing the DNS now we\u0027re doing the DNS section extension draft [Music] okay sure okay go next like so this is a summary of what\u0027s happened in like a hundred email messages on the list so just to quickly summarize for people who skipped all that there\u0027s a dainty last record that tells you what public key to use what certificate to use or what CA to use you can put it in DNS can be protected by DNS SEC and it\u0027s either in the DNS or not so if you publish this in a DNS then it\u0027s live and if it\u0027s if your key in the server does not match it TLS that\u0027s like a permanent error okay next "
  },
  {
    "startTime": "00:30:34",
    "text": "slide so there are some obstacles using TLS a records and browsers they\u0027ll add the added latency for additional round trips the network part not being always clean and things being stripped or manipulated so there was a need to put this inside the TLS handshake so next slide so there\u0027s basically this is a TLS a stapling so you get a record from DNS you staple into the TLS handshake and then everybody is happy to be able to get that information to you stain to varalu to verify the certificate so just to be clear there\u0027s no pinning of DNS data involved it is basically a live snapshot of the DNS data so the TLS surf is expected to regenerate this blob that it\u0027s sending in the extension whatever 15 minutes every one hour so this is not like HP keep a next so what is the problem if the extension is not paint you cannot detect whether or not you\u0027re under attack or whether you\u0027re just hitting a server that doesn\u0027t support the extension or whether the administrator turned off the extension so the problem is if you really want to do Dane and you want to increase the deployment of it in the various protocols then you need to have a way of pinning the extension so so when this was found out were various suggestions of changing the scope of the document which we believe is the wrong approach I think that we should actually cover this disused days so can we get you to hold your comments to the in Richard so we can just get through the slides real quick and you can get back up sorry so next page so basically these are the options that have been discussed in the working group one is do nothing to fix everything in a new TLS extension that obsoletes this one three to zero bytes in this RFC meaning do not do any pinning and in the future we can do pinning of the extension again not pinning of the data but pending of the extension some people thought that I was a bit too ambitious and maybe we need to think about it\u0027s a little bit longer so so we can either do 2 to 0 bytes and define this later or we can add a 2-0 bytes fully expect in scientist RFC that\u0027s okay sure sorry sorry that\u0027s not as fine I\u0027m sorry sugar go with your next slide I\u0027m so explaining all of this so next item so fix everything in your tea last extension obviously has the problems that that new tea last extension done has to make statements about this tea less extension so you get like the new extension will pin the new extension and it will pin the old extension and then at some point you know people are going to say this is the same saying let\u0027s just do one new extension from scratch but then you\u0027re basically deferred throwing all of this document that we\u0027re currently working on a way replacing it with the exact same document except then you add the two bytes or whatever the solution so you come up with so so it\u0027s not a very good solution so a next slide so we can specify two zero bytes now which basically mean don\u0027t ever pin this "
  },
  {
    "startTime": "00:33:35",
    "text": "extension so people can experiment with it they can enable it on a server it doesn\u0027t give any commitment to the future of it being there and later on we can specify what non zero byte means and then both service and clients can implement the non zero versions which we think would be enough to do any kind of extension pinning but not everybody agree to that that would be enough and they were a little bit nervous about it so next slide so this is why do we think the two bytes are going to be enough because the dns already has a TTL and an hour SiC value that specifies lifetimes and protects against replay attacks and so anything less than one hour TTL doesn\u0027t really make any sense because especially if you look at Dee\u0027s records at the parents they\u0027re not gonna expire within the hour so there\u0027s no granularity that you really have within the hour and there\u0027s really no way of of needing more than seven and a half years of extension pinning so two bytes ought to really be enough for every scenario we can come up with so next but as a compromise proposal for those who were too nervous that two bytes were not enough and those who were nervous that we couldn\u0027t really specify the two bytes the proposal from Ben knows to do variable lengths where we put in a reserved field so that they\u0027re committing to fixing the extension pinning in the future but then we have a little more leeway we could do something a little more complicated than selling two bytes next and then Acker came up with another idea of a nigga whole new extension block set to zero first and fill it in later it is sort of the same that\u0027s the same issues as doing a new TLS extension because this is sort of just a sub extension inside this extension so it has the same two things spinning each other kind of complexity so now the next slide so the summary is we really want to have the downgrade protection we really don\u0027t want to reduce the scope to being just DNS or 50 lesser or Greenfield clients we really want to like avoid rewriting lots of drafts if it\u0027s not necessary so next slide he\u0027ll just put up these six solutions again and we can discuss about it so just to confirm that the goals here Paul we agreed that with the current document as specified it works fine with the asserted forms of Dane where you\u0027re asserting a trust anchor yes yes it does great for any of this in the correct if you\u0027re not under attack it confirms that you\u0027re not under attack know when you\u0027re using Dane in that flavor even if you are under attack if you are under attack in that scenario it\u0027s a downgrade attack against TLS as typically you know standard protections against stripping things out of TLS handshake messages apply and they can\u0027t remove the surgeon to get in replace it with a new one like I\u0027m what like the point of this "
  },
  {
    "startTime": "00:36:37",
    "text": "assertive case is that is to authenticate even in the presence of attackers so whether you\u0027re under our attacker or not that authentication provides authentication we did yeah I\u0027m not quite okay yeah I started drunk the Cuban there\u0027s the question of attack as in you as someone is trying to muck around and is in the network and there\u0027s question of the attack you know somebody got a fraudulent PKK\u0027s certificate and you maybe they also can redirect your DNS traffic goes to them so it\u0027s question like what attacker capabilities do you have in terms of just testing with bits on the wire and stripping extensions out or actually your being the real other endpoint that\u0027s the tells the server and self do something different it\u0027s only the authentication of the Dame part is all via the DNS SEC information and nothing of the PQR information so all of that is it\u0027s going to be either there or not there and you\u0027re saying that if it is there and it\u0027s not mangled with then you can use it and yes I agree to that but that\u0027s not the problem case I\u0027m worried about right but but that is a use case that one could use this for is to have authentication that didn\u0027t rely on the PKI and traditional trust anchors that was relying instead on the dns indeed the DNS I correct yes okay so there is a set of use cases this does address as specified yes sir there\u0027s a look there\u0027s this a use case for all of those clients that currently do not support wipe a key I could still go running with that which is currently none right so the use case is really small and if we want to grow this Dane usage and obviously data tooth have to live together for a while right so so your use case is a use case where this is the theoretical use case and it\u0027s not a real life use gates I mean okay fine so just to clarify the concern here is for people who want to use this to add this to use the Dane records to add constraints on the PKI validation and the downgrade there is a downgrade that where you don\u0027t have those constraints and you\u0027re just back to normal PK authentication right is that accurate yes okay okay so Viktor and Niko we see you guys in the queue or you\u0027re after Ben Becker right so you were using the era Chris Corolla no II D hat you\u0027re using the term we there I don\u0027t actually think this consensus that so I didn\u0027t mean we use some work Oh faster than tastic right so during the I mean I\u0027m published repeating myself but uh during the last meeting on this topic was raised mind there was a fair amount of concern about any kind of pinning of this and I appreciate that you and Victor and Nick Nico believe this is the same as H P KP but I remain concerned this is a similar to HP KP and the concerns of the same and and so that I remain concerned that having a two by "
  },
  {
    "startTime": "00:39:39",
    "text": "two extension with only was applied for only time semantics will not be in fact what we need if I\u0027m when we decide to do pinning and so I I guess my rank order of I\u0027m sure we\u0027re gonna wanna I\u0027ve actually close us down so I\u0027ll get it out beginning my rank order is published graphed as is secondarily publisher graft with a extension block which actually has like enough room to do the things we want to do and only after that we\u0027ve published things with we our attention blacks have new semantics whatsoever in the testers never done that successfully okay so I understand of that your view but I\u0027m also a little bit sad that in in four or five months of time you have not come up with anything more concrete and say like it feels like this other pinnings of data and not extension and it feels that I\u0027m a little nervous but I haven\u0027t really managed to substantiate the claims of whites actually problem like I haven\u0027t seen you come up with the use case where it\u0027s actually problem that you do this pinning well yes and I\u0027m a little sad that explain it to repeal Dean you keep saying that so this is dkg I think this draft has value as it is I understand that it doesn\u0027t do all the things that you want to do but I would really like to try to get something like this working because there are potential clients that don\u0027t use the web to PKI that could use it and so by by blocking the conclusion of this on allowing pinning what we\u0027re doing is we\u0027re defeating those clients that could otherwise of this so sorry we as in the opponents of going without modification are not proposing of blocking it effect you have three proposals ago I continue without blocking it I think this draft would would be in last call yeah yeah the ver mistakes made in the process yes okay so the reason why people are seeing this I think as comparable to HP KP is because the the flags that we\u0027re talking about adding here that would permit pinning allow the operator of the web server or of the TLS endpoint to make policy decisions about that endpoint that we are not convinced that the operator of the endpoint knows how to make in general one of the reasons when we see pinning problems the pinning problems that we\u0027re running into our problems where hey it turns out that because I delegated this authority to this you know this what I thought was temporary Authority I let this guy run my web site right now they just made a decision based on bits that they set that have implications for my ability to do policy for my domain entirely now that might or might not be a good thing maybe we shouldn\u0027t be encouraging people to do that kind of stuff but that\u0027s why this looks a lot like HP KP I\u0027m a fan of each HP KP and I\u0027m sad that it went away but I can understand why people who were nervous about HP KP are also nervous about this because it\u0027s not about a foot gun that kills other certificates it\u0027s a foot gun that kills the entire weapon you get okay can we get this draught out the door and then deal with something else later sure but but again just just "
  },
  {
    "startTime": "00:42:39",
    "text": "to clarify we\u0027re asking for one or two bites set to zero that just basically ensures that we will solve this problem in the future and that people are not going to come here next the next IETF and say we will never do any kind of extension whatsoever the drafters did it\u0027s an RFC you don\u0027t go home because that is what I\u0027m afraid of I\u0027m afraid of joints that we think we won\u0027t we that we think we will exercise that we don\u0027t know what they mean and adding extension capabilities into stuff extension capabilities are we know that they that the extra complexity is really hard to get right and I would prefer a simpler draft because I want to see this thing published yes but but but again the dangers that four months from now we\u0027re sitting here with the exact same draft called this with the exactly same explanation to falsify we think the two bytes are enough and all of you saying we haven\u0027t looked into it and we\u0027re sort of concerned that looks like this other thing and we can\u0027t really decide then you cannot move forward so if you can give me some way where we can guarantee to move forward that would make me happier all right then Thank You doc with my ad hat on so I think it\u0027s probably useful to remind ourselves here that sort of the core issue is that we have our existing pica-x trucking trust anchors and we have our DNS trust anchors and you know there\u0027s lots of different ways in which you could use one or the other try to combine them answer the problematic case here which we sort of have to acknowledge as being a significant case is the incremental deployment case where are you currently trusting PKK\u0027s and you want to add on deigned in a sec in some form you\u0027re whether that\u0027s to replace it or supplement it you know just really matter and the key point is that because you have these different trust anchors you cannot rely on the pica-x trust anchor to tell you anything about the status of the DNS trust ink and that sort of the key problem we really don\u0027t know how to solve this and you talk about there\u0027s a downgrade attack and penny will fix it but pinning is what I would say a partial mediation and you know it can be pretty completely partial if you\u0027re talking about your pinning for seven years and you don\u0027t have to worry about it too much of that time but you probably still have to do some stuff in the interviewing time and so this is something of an unsolved problem that we only have a partial medication for and it only appears in some other cases so the question that we have is well what do we do how do we go forward and you know there\u0027s several things that you most of us did I mean we could publish this document as is and replace it entirely in four months with either something that you know supplements the behavior of this extension or it could just wholesale do AB is you\u0027re allocating new code point and I think that\u0027s fine if we do that and then sort "
  },
  {
    "startTime": "00:45:40",
    "text": "of the other option is to leave a hole that we will fill in later and if I take off my ad out I really share dicus G\u0027s concerns that you know if we leave a hole that we think we know how we\u0027re gonna fill like we don\u0027t have anybody just applying this it\u0027s if we look at other pending sorts of schemes you know the experiences we\u0027ve had with HSTs which with HK he h PK p yeah and you know if MTA SES we\u0027ve had be vastly different experiences with this and it\u0027s really presumptuous for us to say that we can predict what\u0027s going to happen given up there\u0027s so many different possibilities so I think the question that we want the working your answer is do we want to leave a hole that we can fill or do we want to say we\u0027re gonna replace this with a new extension when we know how to solve the problem because I don\u0027t think we know how to solve it prom night now I just wanna we went and clip the line or Victor you\u0027re next yeah can you hear me yes we can okay so a couple of things I heard again a talk of there is no certainty it all didn\u0027t quite explain the story is that if you\u0027re a server in a web PKI world and your clients are mostly doing web PKI and you say you know what I\u0027m going to you know not have a web pick a certificate I\u0027m gonna detain you\u0027re not gonna get too many clients you\u0027re gonna fail nobody\u0027s gonna do that the restrictive use case doesn\u0027t work because of stripping and they sort of use case is unreliable so the only applications that work for the draft as originally written are those that mandate the extensions and furthermore as originally written only with servers that have TLS a records and have DNS SEC I must remind you that we after that the draft was pulled we managed to get some consensus around denial of existence which substantially broadens the scope of the draft by allowing servers that implement the extension to deliver the bad news that they don\u0027t have gain or don\u0027t have DNS SEC and thereby the Greenfield clients that mandate the extension can interoperate with not just servers that you know do all three things but can also interoperate with servers that aren\u0027t ready for Dane or DNS SEC yet but can deliver the extension so we now have a much broader scope but we\u0027re still scoped only two servers and clients that mandate the damn thing and we\u0027d like to be able to deploy it incrementally and deploying it incrementally means that there has to be some value from such incremental deployment and the value "
  },
  {
    "startTime": "00:48:41",
    "text": "goes away if the thing is trivially script is trivially strippable as Ben points out you know that the trust anchors from peak expand relied upon could say anything about DNS and so we need to be able to to do this now the other thing I want to mention this the extension itself sorry Allah strike it\u0027s 4:00 a.m. apologies so so dkg rightly concerned about we don\u0027t know how this will play out I did not hear any similar objections for MTA STS lots of people are very excited about MTA fps the draft is getting published it pins a mechanism it doesn\u0027t pin data in fact it pins a little bit more data than this does it pins the MX records needlessly copying them you know arguably needlessly copying them from DNS into the the policy that\u0027s that\u0027s pinned by by MTA SPS here there\u0027s no such need we\u0027re just pinning a capability to deliver the extension no data gets pinned this is simple as an MTA STS it\u0027s simpler than STS for HTTP I know we haven\u0027t had the details of that debate but I can assure you there this is this is STS de minimis and if you support any other kind of STS and didn\u0027t make a fuss about it I see no reason why there would be fuss about this so I just clarified that my concern Victor this is dkg my concern was not about what is being pinned my concern was about who is doing the pinning and him the proposal that we have here the entity doing the pinning is the TLS end point itself in MTA STS the operator doing the pinning is a controller of the zone the DNS zone and the operator of the HTTP endpoint right it\u0027s not that the MTA itself saying I\u0027m gonna pin start TLS that\u0027s why there was more excitement about it okay I think we\u0027re gonna we\u0027re gonna move on to Niko thanks Victor Sam Wyler Sam hold on there Sam we\u0027re gonna go Niko\u0027s next and Wes than you all right I guess you can hear me so I wrote down some things to say first of all to Ben\u0027s point this is a bit too poo-ish yeah I mean there\u0027s no you know there\u0027s no silver bullet for we\u0027re trying to do here we I mean we in a very general sense for example if if we were all trying to move away from the web PKI to the DNS sack over time right you know eventually we\u0027d want to have a permanent pin for everybody but that\u0027s not what we "
  },
  {
    "startTime": "00:51:43",
    "text": "Victor Paul and I are really trying to do we\u0027re not trying to say that everybody must be on the NSX only and that web PKI or anything like that the second thing I wanted to say was that you know again - the thing about pinning this is really just pinning the extension I think this is completely different from all the other pinnings except as Victor just pointed out the fact that the user agent or whatever client would be doing pinning of the extension isn\u0027t very interesting I don\u0027t think right because it\u0027s the same thing in SMTP or or whatever someone has to do the pinning on the client side and it\u0027s just about the extension being present you can start out without DNS SEC you can start out you can add the NS SEC you can then add then you can then remove these things and as long as you have the extension there it just works right it does create a problem if you want to be able to to you know go back to an earlier version of your server that doesn\u0027t implement the extension or whatever but I mean I don\u0027t think that\u0027s a problem it\u0027s a very very simple extension since on the server side all it really does is carry data and most implementations I gather will be getting that data asynchronously in a background process the last thing I want to say about the two bytes is that you know it\u0027s speculative in one sense but it isn\u0027t really speculative we know what we would put there right and we know that we\u0027re going to write that draft and you know unless world you know unless there are people who are opposed to the idea of pinning under any circumstance as opposed to yeah like are you guys opposed to having the pinning at all ever or or what because if you\u0027re not then what\u0027s the problem with these two bytes right like we\u0027re not saying put the pending in there now however if you\u0027re not opposed to pitting why not like why not add the pinning functionality now all we need is the two bytes and the semantics that\u0027s it for me okay thanks guys we\u0027re gonna have to get everybody to be concise err thanks Wes we\u0027ll try thanks Wes heard acharya say a couple of things i mean to me the extension setting is extremely different than data pinning so there\u0027s not a whole lot of correlation between the two but I understand the nervousness of it the thing I worry most about is that when you rush a document through because it should get out the door immediately that you end up with a greater complex situation in the future so specifically you know when I\u0027ll cut out some stuff look the way I think that we have the avoiding complexity right is the worst thing that you could do is create two extensions that have to mitigate how they interact with each other that is much more complex than dealing with one extension field that may or may not ever "
  },
  {
    "startTime": "00:54:43",
    "text": "get used or defining pinning in the future so in terms of optimizing for least operational complexity in the future and implementation complexity in the future it seems to me like putting in an extension that basically says if you see this extension and it\u0027s empty regardless of whether it\u0027s 2 bytes or actual length you don\u0027t do anything right that lets the protocol go forward as is we get to define the the aspect of it later and it leaves a space so that we can put it back without adding the complexity of having multiple version interactions we already have that now otherwise we\u0027re going to end up with this thing die die die as well to get rid of the older extension right now the second option is to fill it in now but I\u0027m not sure based on the consensus that was actually filling it now is my original preference but listening to the room there\u0027s not consensus on that so I would option two to leave it in as a blank field for the moment and I\u0027ll cut it there all right Sam you\u0027re next Sam Wyler could not should could if this working group didn\u0027t persist it at not wanting to do an extension here could we fix this in the DNS could you steal enough bits from somewhere in the DNS to signal the pinning in a DNS record no because the whole idea is that for instance you might get service provided at strips old DNS SEC records so you cannot get anything certified through I thought this was coming from one you got the first one no no but but the data you\u0027re pinning is DNS SEC data that presumably you couldn\u0027t get from your local transport so your own resolver can get to it and so you\u0027re getting it via this TLS extension as a sort of workaround for so it\u0027s just a different transport of the same data so so I mean unless you want to do like ggb type like overlays in DNS with a names or whatever sorry with a records you wouldn\u0027t be able to do any of this I\u0027m not sure I believe that answer okay well we shall talk more ekor yeah so I think there are two questions Ericka Scarlett there are two questions one is painting is good for this and the other is if pitting is good for this should we you know how should we proceed hum my sense this is real concern where the printing is good um you asked for some reasons um first of all as I said paying is food you quite brutal deployment on and even if you don\u0027t think sprawl in deployment we show the problem of takeover and I appreciate that you think that you can stall the taker for problem by publishing your new on publishing your new dialogue assistance records but that tastes a server which pre-decide no capabilities to do DNS SEC or any of these engines at all and force the new mass upgrades source they can publish the record it\u0027s completely unacceptable for any operational perspective the um so um but it may be as possible putting is good study that problem I\u0027m gonna be skeptical I\u0027ve heard a lot of kuving\u0027s skeptical as well um so the question becomes what\u0027s the appropriate way to deal with the potential offending is good number possibilities here one is we "
  },
  {
    "startTime": "00:57:43",
    "text": "could just hold this entire draft until two years all those problem with other ideas we could leave a placeholder in this draft so then the question becomes what kind of placeholder wouldn\u0027t leave now your proposal I believe is you want to get a very small placeholder which only has two bytes and has some unspecified but almost certainly time semantics literal des plaines these kinds of things actually more than those kinds of semantics you talk about for instance maybe having ability to warn when there are problems you can actually go well forgets to pull out and see if you\u0027re causing more problems so to buy suddenly Bruford at the nest proposal you have is to have sort of blank unspecified bytes as I say we actually try this in TLS 1.0 and had blank thing at the end of client awhile and it caused enormous amounts a roll up problems so we spend a lot of time to do both protocols that we can actually grease so they could find out if people have this implemented things go through mark and when your poison do is we bring us back into the situation where you can\u0027t grease so in other words basically like if we\u0027re gonna do something let\u0027s just like it actually defines it or do nothing not like have like a blank field that like somehow we have to fill in later Adam and then Richard and then we\u0027re closing the live Victor sorry so cristinaw Co Carnegie Mellon it\u0027s a to Eric\u0027s point it\u0027s not clear to me that you know if you do zero out the bytes you actually have to solve it like it gives you the time right so if I feel like that\u0027s a false boys we\u0027re you know reserving the bytes now and specifying them as zero like the Dvorkin group can pick that up later and decide that you know what Eric we looked at the problem and you were right we shouldn\u0027t do it we can just leave them zero forever I\u0027m not sure with the downside that that is other than you know someone might feel the urge that boy it\u0027s zero bytes we should use those for something I mean two bytes of protocol and efficiency doesn\u0027t seem like the end of the world to me when we\u0027re moving you know some of these certificates and stuff around right so it\u0027s not clear to me how reserving that assuming we can come up with some kind of useful mechanism that we can define as a problem all right Richard so one clarification one piece of argument so wanted to clarify this incremental deployment issue that Victor raises is not an issue if it were an issue we wouldn\u0027t be able to do this delegated credential stuff which requires switching between one modality of authentication and another modality of authentication depending on what the client supports you can do exactly the same thing with this extension if the client advertises that it can do Dane based authentication you do Dane based classification if it doesn\u0027t advertise that you use your regular old PKI sir so there\u0027s no pinning no that\u0027s not that\u0027s not agree if there\u0027s no pinning what do not you do not have the way of of choosing your PGI system you can only choose the one that we allow or the one that we maybe let you allow when you feel like it that\u0027s not a real choice you can have clients so you admittedly servers do have to do the Dane thing and "
  },
  {
    "startTime": "01:00:45",
    "text": "have a normal have a Dane asserted certificate and a normal piece if they do dangerous they need pinning because otherwise they don\u0027t do Dane certs when you say do Dane suit you can\u0027t say hello verify the Dana Circuit certificate and in that case when the client opts in in that way the server can can present that certificate and use that to authenticate I\u0027m sorry now you want to move things to an EQ or something I don\u0027t understand what you\u0027re doing this extension is advertised on the client hello otherwise the server right and so when I when if server receives a client hello with that extension in it it\u0027s wrecked that that\u0027s the client saying I can verify a certificate the certificate the server can decide not to Center that at any point in time in the future so just nothing you can do with that information unless it\u0027s a guarantee for this is the same assistant this is the same as saying your browser sometimes can decide to disable 500cm Caidic the case that Richard was using as an example is still using the same trusting well no the case I\u0027m talking about is where you are trying to authenticate and you\u0027re not trying to bind yourself to a specific type of authentication so it is the case that dkg mentioned where I want to use a dane asserted certificate to authenticate I don\u0027t care that someone might be able to get a PKI certificate with that name and I\u0027ll use that to authenticate that\u0027s not the thing I\u0027m trying to address with this extension I\u0027m trying to use this to extend the set of authentication options I have not to rule out authentication options I thought you were comparing this to like a not the exported outside canary but yeah the delegated credentials thank you well you\u0027re making a new use case instead of addressing the problem in our use case I am saying there are multiple use cases here as the ukg said this addresses a class of use cases and does not address certain other classes of use cases that you care about rich we clip the line on okay so we have it figured out so that was just my first let me briefly make the point I really want to make here which is the people have made been making these future-looking statements about like what happens if we do nothing here the thing I\u0027ve learned about this is the way this discussion has been helpful to me is to underscore how much we screwed up date in the sense that we conflated two very different use cases we took this assertive use case where you want to do one thing is very different from this restricted use case and the fact that we are really we\u0027re talking past each other illustrative of wise dangerous tricks but that points out to me that we have a good chance of success with a future extension doing this with a second extension of future covering the restrictive use cases the difference in the future because there\u0027s a clear semantics for developers and implementers you say you use the "
  },
  {
    "startTime": "01:03:46",
    "text": "extension we\u0027re talking about today if you want to do the assertive thing and I believe me out of the text in the document to say okay this is the assertive thing okay in the future essentially so basically you\u0027re suggesting to change the title of this document of something like how to use DNS over TLS so it is a certificate it is not actually a Dane based method I like you speak can you at least let me finish my sentences and dentox thank you I\u0027m saying that you are not actually addressing the Dane use case and if you\u0027re removing it from a scope you should remove that from the document title from the document abstract and you should say this is only for these specific payloads that don\u0027t that are not bothered by download by downgrade attack this phrase your unit using Dane use case is not a thing there is not a Dane use case there are at least and then if you\u0027re not suffering all of the Dane use cases you should specify that specifically in the document I believe I\u0027m looking back to my co-authors here I think we added the text to the draft in the last after when this was discussed four months ago I think we added the text of the draft to down scope it to only the assertive case they\u0027ll be totally comfortable with that restriction and clarified as well obviously some people are not including me well but we were talking earlier about things we were disappointed it hadn\u0027t happened in the last five months you could have written a short draft that took the syntax here added the pinning stuff and did a great job of addressing specifically the restrictive semantics that you care about we did that as in the github and we did provide many like we have four different proposals here come on you can see we didn\u0027t try to help you out and coming to an agreement here we did all the work we sent to 80 hundred emails that everybody complained about to TLS this I did not see anyone incorporating to get our use case working what I\u0027m saying here is we have two use cases this addresses one there\u0027s a different use case that can be handled in different documents that can borrow a lot from this one we shouldn\u0027t block progress on one set of use cases because it doesn\u0027t do the other yeah so you really just want enso for Teela\u0027s all right I mean unfortunately we\u0027re kind of back where we were before um do either of you have any grant suggestions for it would be nice if we did something um potentially decide whether or not to just put this right back in the artsy\u0027s header DQ to let it move forward and then do as Richard suggests just address the different UK\u0027s in a different draft or you know potentially something else so I don\u0027t know if we want to have our own source to do that particular thing take that particular course of action that\u0027s interpreted every single to me is "
  },
  {
    "startTime": "01:06:53",
    "text": "everybody following along what\u0027s going on here have you all read the draft I see lots of heads nodding okay that\u0027s good so we\u0027re not like having you how many people have read to draft Oh fair amount a lot more than I thought the last time um all right so let\u0027s just do this all right I know here comes more people um yeah we did kind of close the line multiple times oh it\u0027s a separate thing okay not a new topic this is a process suggested fair enough for something that has worked in other groups and since you have another meeting the chairs could convene a small design discussion with a small group of people to see if you can come to at least an understanding of where exactly the tensions are so we kind of tried to do that we did it on github it kind of devolved it suck face-to-face same room and wait for our the suggestion so we\u0027re in this like painful situation where we\u0027re having a deadlock essentially and I am not entirely sure what to do that progress is moving forward Ben any chance you could lend some ideas here for us I mean so I agree we\u0027re kind of stuck as is given the information that we have right now I am not comfortable publishing you know the document that\u0027s currently in the is editor and RFC editor queue like I don\u0027t think we can publish that as it is whether we you add some additional text to it and say you know try to describe what the issues are and what use cases we think is a good solution for and what uses we think it\u0027s not a good solution for I think there\u0027s some potential for that to be your way forward and get something published bowl I mean I think there are other options open for the working group if you people want to leave an extensible hole that we can think we can use but like I don\u0027t have a great sense for like I was in the front of room I couldn\u0027t see but heads were shaking or nodding as people are talking it\u0027s my fine I don\u0027t know if you have a good sense or not know so I what I think I\u0027ve heard is that we\u0027re gonna yank it out of the our theaters queue and then I mean life late if you also make a major change working group last called Reese Bennett that\u0027s what I would do and when we have two strong camps there "
  },
  {
    "startTime": "01:09:53",
    "text": "like one wants to do one thing and one wants to do another we don\u0027t do well and this unfortunately yeah this is that made part ways from Richard here but I I don\u0027t think this document husband it says at this point um I don\u0027t think it\u0027s gonna have consensus with the you know with with reposed denial citizens changes either um so I don\u0027t see I mean I think obviously we can\u0027t publish that as it is but I also don\u0027t think we plausibly I mean there\u0027s the parts the PR everybody agrees on and I think we can merge this perfectly well but I don\u0027t think like God I would be uncomfortable personally have this document published knowing how strongly Nico and Paul and and your feel about it like I don\u0027t think that\u0027s an acceptable outcome either be honest unless we have very strong consensus in the meeting that like it\u0027s everybody but they have managed I\u0027m not sure I\u0027m hearing so right and I think it\u0027s pretty clear that if we don\u0027t have a working group consensus to publish the document and the document just has to die it is not gonna be a product of the working group there are potentially other venues for publication so I may be reaching too far back in history here but we had a home at the last night CF about this and there was pretty strong consensus on the side of doing nothing or the very narrow down scoping I believe was the contestants at that point and we want to confirm it on the list and that exploded into a big discussion but I think none of that netted a broader body of support for making a change it was just a lot of discussion and people indulging the same proponents on that so I mean I I would be glad to have another if you wanted to refresh that here to have another hunt that can engage the temperature of the room but I\u0027m not sure yeah we we did that once we\u0027ve gone there were strong consensus in the room and I\u0027m not convinced that the the mailing was discussion the voluminous actually demonstrated any additional support which the change position okay I would like to briefly respond to that Victor and I had actually given a number of issues that we wanted authors to talk about to the authors and he did not actually present those points when they\u0027re presenting their draft and so we were only you know part of the audience coming up with some items that by we didn\u0027t agree on things and then there was a you know a hum made I don\u0027t think that was a fair like we like and that\u0027s why I actually wanted to present here to make sure that the room actually knows what we\u0027re talking about that we were not just doing some crazy guy to mike saying like you know weird stuff and so that time from last from last TLS was the most misleading ham i\u0027ve seen in a long time Paul Hoffman acting mostly as a tourist here but interested in this so I\u0027m not gonna make this easier for you but I do want to point something out is that is very different than what Richard just said I believe that the large discussion on the mailing list caused people to think more and possibly change that like just looking at what some people said here and then four days later and such I saw people changing their views and I\u0027m not saying which way or is there consensus or not but I believe that the old hum followed by the mailing list "
  },
  {
    "startTime": "01:12:53",
    "text": "actually has caused a number of people to maybe switch or to at least have an opinion so if that helps you on what to do great but it\u0027s not like we\u0027re in the same place we were before but just louder all right so we\u0027re gonna postpone this discussion and come back to figure out something on Thursday I think at this point it\u0027s pretty clear that we\u0027re probably in it maybe being out of the our sitter is key but we\u0027ll revisit this on Thursday hopefully everyone will have a chance to meet and greet and talk and maybe see if there\u0027s any way out of this hole Thanks next I believe is you are next [Music] [Music] Wow Wow normally it\u0027s like really swallow it this is actually a proposal to add a bunch of unspecified bits to the details one three header no confidence monitor seriously a cast pretty grim okay I really need to see my own slides I really need to see my own slides his yeah I\u0027m like get down the floor like like I\u0027m fucking you know or something okay great now we have no slides but if that was awesome okay so so and and I still remember back in IETF 101 um you know we had this long long discussion about whether or not we should explicitly or implicitly mark the CID and I think people were kind of like in on it but we\u0027ve only decided we\u0027re gonna split we mark it on the idea was to mark that\u0027s there not to mark the length um if you want to mark the length well then it\u0027s you can like make a self describing CIA over the first byte is the length so like really we don\u0027t discuss it by that that says there\u0027s a huge amount of like you know quick style screwing around because like trying to pack the length of the first three bytes and like have like you know like only values between 1 and 16 or something so um we also agreed that the DQ less one free work might not be quite as picture as we were hoping partly because they were actually quick and so we split the "
  },
  {
    "startTime": "01:15:54",
    "text": "work into a what though the kinda shiny draft would be a one two draft but come first we take all the CID work and move it all the way into the one three draft as well as just having like separate craft um so um but they both use the condition ID extension and we ended up putting that into one two drafts but the way they did we can get against that now we could just moist it in by reference next slide so when I got one to first and then apply out 1/3 on so um the the big question for 1/2 was basically how do you encode that the CID is present and the two things were float at the time was a bit in the length field or having shadow content types that meant you know unlike a application did the message but CCC ideas present and um we were concerned about like whether or not having the length field you know some of these a that light the fight the packets for you know were sixty sixty five thousand not chest long was gonna like make no boss is sad so we decided not to do that and so we came up with this content type pack um turned out that washes work hard defining for new continent types and minimum you need three maybe don\u0027t like heartbeat but it still is three and that started to make like actually a fun reflection or make people sad starting the Martin Thompson so good so I can lighten up this next slide so Martin on lists just did we basically suck in the TLS one three framing where basically you do is a stroke italic a one extra code point which is just like this is like the detail at TLS one three style encrypted content type plus a CID and then then this real contact would be inside the ad wrapper and of course you get padding for free which is nice and there\u0027s no need Alec ever allocating like more code points cuz you\u0027re not trained up any broker points basis all internal and the reason why we\u0027re being stingy VAT code points here is because of the this problem in muxing with SR Keehan other things so the co points are pretty scarce um so that was more in design which i think is actually not bad yeah thomson one thing i wanted to point out here is that we have seven left and you\u0027re taking fourth no no III think i persuaded me that we shouldn\u0027t take it we shouldn\u0027t take them all now we get this heart because like our PETA service a well loved uh-hum so um right so and the good news is right is that if you do this then all the remaining code points become very available to you so so you\u0027re you\u0027re chewing up one code point that basically says listen I\u0027ve got like I got no more code points yeah I got plenty more room so that\u0027s nice um so after reading this which I thought was a pretty cool so proposal I was like well maybe like is this too much for people swallow so maybe there\u0027s another way to do it it is like less hard to swallow and so my alternate alternate design on their site is basically to do the same thing with a "
  },
  {
    "startTime": "01:18:57",
    "text": "marker content type that means to see ideas present but then have later outside the encryption boundary have a true content type that field which is just the gashel content type and so this is basically like this is conceptually hortons idea but doesn\u0027t involve encrypting it so like obvious that\u0027s except your inferior from a security perspective but it\u0027s like easier to implement and so like you can have to decide like you know am I like am I trying to make one to better or am I just like one to kind of sucks and I\u0027m gonna like have all the good stuff in one three so I think like I this is viable I don\u0027t feel strongly about it I don\u0027t think part in full storming about it but we have to have one of the other end so I don\u0027t know like we just like let\u0027s just decide this real quick and like a halt scribble on the draft and we don\u0027t with that piece I guess I think I personally prefer Martin\u0027s proposal I think it\u0027s like like why not do the right thing when we\u0027re in the game but if anybody thinks morals like too much work and like you know this is available too Thomas I might have an alternate alternate alternate design here and I might have a third opinion okay which is we go back to the original problem which is the fact that the wave the 1.3 header is laid out at the moment implicit ereserves two to the fifth good points that\u0027s why we end up with 38 minus 30 32 problem marking is saying so if we instead pin one of these bits of the reserved bits say bit 7 or equivalently we instead of doing 0 1 1 we do 0 1 1 0 we right shift to cnel beats and we reserved two bits then we get back to to the 4 right so yeah we get back 16 good point which is which is we solves the problem I think it\u0027s because 16 back is plenty sure the problem is the problem is now we\u0027re actually running quite up against the limits of length field another sorry on the on the other other packet number life field so howlin spec another life now Martin is it 13 we have 0 0 1 and then we have two bits ahead of that so we have only 10 bits in that shorter sequence number space right so like I\u0027m not really one to have any more yes it is 10 is pretty bad already I mean it\u0027s it it\u0027s probably good for a large number of use cases but it\u0027s not it\u0027s gonna people are gonna be forced into the Lancome no we only have one left no we will do to fight thing as two dozen is it - is it 20 is it I thought it was 16 we\u0027re just we\u0027re losing them you\u0027re really gonna flag that we\u0027re not losing as you can you can us go forward we have on the slides oq guy so we have the diagram that one yeah okay sorry so have four we have 14 bits of um we have "
  },
  {
    "startTime": "01:21:57",
    "text": "14 deaths so you\u0027re gonna take only one over one of our flight bets right that\u0027s reversal I want to take say seventh in the first body won\u0027t take away this axis right so like I want to make T less 1.3 better and I don\u0027t really care much that tells from point 2 so the fact that you have to like pay one point a less 1.2 to have connection ID because you don\u0027t have moved 1 3 like elitism with me like this is like a piece of recession points we like we have why should we place we give it up just for this for one tail this is Thomas we can\u0027t use we can\u0027t use this fight because this is the 1 2 3 header we are like the the problem is for 1 or 2 these other format crabs beasts that are conflicting with the maximum so I\u0027m with a kadai are not if it\u0027s not as ideal for 1.2 I think that\u0027s acceptable because of you know like him with the whole effort of moving forward 203 anyway so like shaving off the last bit there and we had proposals to always inject like an extra bite just we can have this like bit set here so like I don\u0027t really think that\u0027s like so one thing I think between the two proposals that you Martines and yours I think I prefer Martins because because yours grab one bite more now these are the same they\u0027re the same as I say the same is veteran size yet so I think we\u0027re better but I figure so the difference is here difference here is fundamentally where that bike goes whether it goes under encryption at the end which is what we have for the tell us once where you record lamb or whether it goes outside of encryption before the ID so it\u0027s a wash right dkg do you wanna I\u0027m surprised you\u0027re not saying you want to encrypt it I mean trying it out trying to close the clothes issues so if you think it should be encrypted like ready John care yes I think we should be encrypted thank you I get to pretend to be you I get a bigger beard so I\u0027m gonna I\u0027m gonna write this is like the way more inch puzzle if people are not unhappy or not incredibly unhappy that one yeah there\u0027s nobody like screaming no he\u0027ll go away okay so next lie okay so Newton "
  },
  {
    "startTime": "01:24:57",
    "text": "I\u0027m now a new person speaking for different good for authors this is TTLs one three so this actually has like almost the same topics as previously next slide so as I said you know despite my previous principles um we\u0027re gonna put some extra flag bits in here because we just like need it to fly it needed some flag this already and now we have some spares um that would not be more ordinary preference so we discussed this unified packet format that basically is sort of vaguely prick inspired but not entirely um that um gives it give us one well enough sequence number also doesn\u0027t interface interfere with any other code points um and um and also gives us room for these two to flag bits that tell you whether or not the connection is present so like the way to read this first word is things that say zero zero one actually or zero zero one the Z says a connection ideas present the else has a length fill is present and the exes are reserve reserve bits which might be something in the future and I can\u0027t remember we wrote but we should write is if you receive these bits and there\u0027s something else that you didn\u0027t expect other than like zero and there\u0027s no Ascension telling you that you should joke unless this David things we should grease them which might be a possibility you think you should grease them should we grease the bits okay grease right yes I\u0027m not insulting the approach proof decided to take in quick is that you set them to random values okay ago she ate so meaningless Alyssa negotiated in there greased okay that seems right on and so the next 16 bits or the epic and the 14 bit sequence number and then the connection a and length and those are only there if they\u0027re present um so um next slide um or did you yes I realized that I missed this when I was reviewing this and I\u0027m sorry for that but the having reserved bits there is a little awkward okay because you have to worry about this question of greasing and if you look at this look at this layout you can potentially only have one bit free puck in the very very short hitter if you if you understand that that\u0027s only gonna be used once the connection is yeah is up yep and that gives you potentially the three fixed bits the three bits that you have there would be the connection idea bit the long bit or and the epoch bit and then you have ten bits of sequence number which is a lot for a bunch of use cases if you were just saying this dismal it\u0027s too small for some use case rights but but we had plenty of evidence in quick that eights plenty for a large number right I guess my take on this way if we\u0027re gonna have one size if that are big enough for everything and that\u0027s like at the 14 big enough for everything is that is that be a session can I think think if trouble seeing how you get more CCTV or "
  },
  {
    "startTime": "01:27:58",
    "text": "more than more than like you more than have any packets outstanding yeah it\u0027s it\u0027s a large amount of storage I mean there\u0027s all sister Beth yeah it\u0027s nice having the one format I agree but that\u0027s kind of where I came down yeah um if you feel strongly about him happy too yeah well we\u0027ve sorted I mean like we spent Norden about time in these formats in quick and I\u0027m not sure like that problem this very much I\u0027m sure um I\u0027m just nervous about having having unused things there that we then have to worry about safeguarding yeah I\u0027m sure that too but um and we didn\u0027t break up can we use them free Paul can have a 16-bit sequences and you have like you may have one free bit or just pin it 2-0 just make the three-day epoch we could do that that\u0027s possible D um I don\u0027t feel real strongly about a lot there right I mean I only made this exact this will reserve pixels like though there [Music] yeah okay I think morning are going take this offline and we\u0027ll come back with the mailing list of proposal and like since nobody else seems to be standing up I can\u0027t imagine anybody really cares it\u0027s not going to change by the end of the packages yeah okay um just here\u0027s a picture of what these things actually look like and practice next slide so there\u0027s um unlike one to where we\u0027re not gonna have any way to refresh the connection IDs one three doesn\u0027t refresh second Hades which is like you said a new condition any message that\u0027s missed of underscores in it I think I you just screwed up with tech um there\u0027s also a request Kadesh I need messages says I\u0027d like some more connection IDs has exactly semantics do you think it does which is send me a new cache ID this is her board I think let\u0027s it\u0027s getting increasingly hard to tell which ideas start up for some TTL so much open correct to be honest comment some of the same people so anyway we have this thing so you don\u0027t need to renegotiate um next slide so like all this grip these really great to have a connection IDs but if like you\u0027ve been increasing sequence number then like basically the whole thing was kind of pointless so this is definitely a quick idea home so the idea is to steal the quick style packet number encryption and for all the GTL s1p safer to fix packets and I want emphasize with or without the connection ID like we\u0027re always gonna have this here um and um so it\u0027s exactly the same function as in quick more successfully which is you take some sample sum of the ciphertext and use that as the input to a pseudo-random potion which you XOR with the which is an extra with the micro sequence number you can emulate this with counter mode those like not really counter mode but whatever there\u0027s like a draft redraft PR at this location here and that\u0027s what there is so I think this is like kind of a small improvement to DTLS in the sense that I mean I said that encrypted sequence numbers are a "
  },
  {
    "startTime": "01:30:58",
    "text": "nice thing so we must we\u0027ll have them the whole time program help at all I don\u0027t promise the PR is good hence the term crafty draft yeah so I\u0027ve I haven\u0027t seen the PR until just now but there\u0027s a fixed is here should we be doing the same thing as quick here should be I think I think I just missed it when one hearts out and are we planning to in cipher the epoch because that changes I think my answer is now a look my answer is to only encrypt the 14 low order bits because then you can read the back off the packet just like a phase bit that makes my suggestion to move the epoch into the first first bite a little more interesting because they need a support about masking this is true though I do fact you feel comfortable mask guys you feel comfortable like like ending with you know ending with not without one one um yeah okay next slide so anything else anyone else to raised about details one three um like we\u0027re kind of getting down to the wire here so we have to implement we have no point this header yet but we\u0027re going to really soon so so quick is having a bunch of discussions about new commission IDs how you manage connection IDs have a get rid of them and all of that they\u0027re on a plea of horror that comes with that we should probably not make any serious moves until that sells down over there I\u0027d like to see that designs be relative a great congruent and this this notion of a request connection I\u0027d a thing is not something that appears in quick right and there\u0027s a bunch of just quick at it some sort of like I want you I want to make sure and available or something right we this is part of the huge set of discussions working a bit be having on this one okay well I\u0027m happy to hold the hold it I mean I agree that there\u0027s no reason why they shouldn\u0027t the same design hum but um yeah that\u0027s a you know we are like details one three is closer to being done than quickest um and so that\u0027s the problem yeah so I\u0027d like I\u0027d like to resolve these issues in quick sort of like we can have the same thing and we get this other door we should be we should be talking about this this okay we\u0027re in the quick working group is that discussion happening there\u0027s some building no no I mean as I check the mailing list before working on on the PR and things are it\u0027s sometimes hard to find is it is it on mailing list is it in some github repository where where\u0027s the discussion so quick has the has adopted a policy of having substantive discussions on github and there are a number of issues that track this particular class of problems unfortunately the discussion is split across a number of different issues because there are a number of interrelated issues that were discussing and so I\u0027m happy to give anyone a bit of a set of pointers if that\u0027s necessary or since I makes it listed just worry deserts are I know what annoying but big "
  },
  {
    "startTime": "01:34:01",
    "text": "time yes also that the risk that things are bounce back and forth between the two groups with like there\u0027s still some differences in quick after all so yeah we don\u0027t necessarily do other groups of service with respect to the the work that\u0027s going on because of the way that the discussion is fractured but that\u0027s just a not effective well want to work going on so now different github issues after on yeah if you needed help with that all right there\u0027s a discussion how about we have the discussion be quick and we\u0027ll see how what turns up there and and hopefully there\u0027ll be something that you can use and capture that\u0027s a little less yeah Martin do you think you could email the tls list with issues and quick so people could choose now mom\u0027s like oh oh yeah thanks commenting about encrypting face I don\u0027t think that\u0027s necessary for DTS because the data is yes the plan is only to encrypt once you\u0027re going to save the text mode okay thank you yeah the plain text is out there\u0027s an old details cruddy header I am back delegated credentials next slide please so delegated credentials is a draft that was adopted last year it hasn\u0027t had a lot of action or change not a lot of work has been done at the loss ITF but in recent weeks we would looked at it a little more closely the motivation for this is to reduce the exposure of private certificate private keys to compromise of one way or another of the web server in which that\u0027s serving TLS so you have a server that\u0027s serving TLS and commonly right now the long term secret key the long term private key of the certificate is held in the memory space of that application that\u0027s connected directly to the Internet there\u0027s been a history of compromises that a lot of these web servers are written in memory unsafe languages Hark lead is the most most famous of which so the idea for this is to reduce the exposure of long-term private keys to this type of vulnerability so the latest subject was mainly editorial the action it is a TLS extension that is sent from the client to the server and if the server accepts it it\u0027s we have a lot of discussions about how this is constructed but the server will send back this structure called a delegated credential which contains a public key a "
  },
  {
    "startTime": "01:37:03",
    "text": "date and a signature algorithm and in the TLS response and the point of this delegated credential is that it\u0027s short-lived but this key is used as the key for the certificate verify message so rather than using the certificates key you\u0027re using this short-lived key to finish the TLS connection so the client will validate that this delegated credential was correctly signed by the end entity certificate and that the data is in the valid range and it\u0027s only useful or only to be used with certificates that have a specific object ID that identifies that it is the person owning the certificate is willing to do delegated credentials next slide please so here\u0027s just an overview of the structure and the design it\u0027s a delegated credential is not meant to be a replacement for an x.509 certificate it\u0027s meant to be a very limited scope object that allows you to simply swap the public key reduce the time complete time validity of the credential and so it has some nice properties and that it\u0027s actually bound to the certificate that is signing it and it has this very sort of simple credential structure that has the signature scheme that it\u0027s signed with the signature the valid time the public key next slide please so in terms of implementation this is the the major progress that\u0027s happened is we\u0027ve built some several people have worked on implementations of the current draft specifically there\u0027s an implementation and boring us a cell that\u0027s nearly complete a version in go-tos tris which is if work of goes crypto standard crypto library and we\u0027ve achieved interoperability between these these as well I know there\u0027s also a implementation picot TLS that we haven\u0027t intervene tested with the latest draft but we expect to have more comprehensive testing done soon and if this is on the path to being adopted and and secure then CloudFlare has a plan of serving these for certain certificates starting in fall of this year especially this before but eva CA he\u0027s willing to give you the code point it\u0027s it\u0027s pending on the it\u0027s coming up it\u0027s waiting on us no this is this is pending the ability to issue certificates that have this already okay and there there\u0027s the next slide well we\u0027ll talk oh I\u0027m sorry my question yeah so oh this is the this is an old version of this I updated this um so there\u0027s basically a question and three proposals should be 0:01 or oh "
  },
  {
    "startTime": "01:40:07",
    "text": "- so in the draft right now there\u0027s an object ID proposal that\u0027s basically blank we have been using in interoperability tests one that\u0027s defined under under cloud source object space so the question number one I want to raise here is whether or not we should move to an object ID that is more fit for purpose for this something that\u0027s defined for IETF security or maybe we should even consider changing this from an object ID to an extended key usage in the peek exert if Achatz so this is this is an open question right now um so annoyed isn\u0027t always a no wait it doesn\u0027t matter what a market comes out of if we decide to use annoyed I don\u0027t care that it comes from CloudFlare or start a calm or my Arc like it\u0027s just annoyed so the real question is whether he wants dignity Kay you are not right yes that\u0027s right David Benjamin so I could be misremembering but I want to say ek use are the one where like in practice a lot of the implementations do this inheriting thing so that you cannot have the child certificate a certain EKU that the parents didn\u0027t assert and that tends to cause problems whenever you add new aks I could also be completely making this up but I think it was yeah rich know your memories accurate and the values in EKU or an OID anyway so it\u0027s annoyed here or in a complicated structure that has interesting inherent semantics okay that sounds like we should stick with what it is right now which is just an annoyed more picket next next slide please so proposal number two this was brought up as a way to ensure that these certificates that are used for delegation are not used for TLS so there\u0027s this TLS feature extension that\u0027s used for OCSP must staple it allows you to have an array of enumerations where if a client sees one of these certificates and the feature is not used by the server then it can disconnect so the question is here can we should we add an optional TLS feature value for requiring the use of a delegated credential the advantages of this are that you separate the the use of the private key for this certificate to not be used in TLS so it should not be used in TLS and would only be used for issuing these short-lived delegated credentials the complications here are that if you are going to serve a website and use delegated credentials and have clients that are "
  },
  {
    "startTime": "01:43:09",
    "text": "but supporting and not supporting then you need to have two certificates and be able to switch between the two and a lot of client software is unable to really do that efficiently or do that in practical sense of switching dynamically choosing a certificate so this would be an option for servers that do to have that capability proposal number three this is was raised by Christopher patent currently a delegated credential is really a public key so it can be used for any signature scheme that that public key can be used for so in the case of RSA there\u0027s a whole list of these PSS cipher suites with different hash algorithms that you can use the proposal is to pick one ahead of time when you\u0027re issuing when you\u0027re basically creating a delegated credential bind it to the only one signature algorithm that you can use for that delegated credential it it makes the it makes the analysis slightly simpler it requires you to if you want to support clients that do all sorts of different signature schemes or want different signature schemes it requires you to manufacture more than one delegated credential for a given certificate but it it does have a nice property that you have a lot more explicit control over how that the delegated credential is used this seems like a good idea but I have a nitpicky tech question yep which extension would control which algorithm was sinister algorithms in childhood sir it would be certificate algorithms yeah and all certificate algorithms cert sorry senior onwards signature algorithms sorry signature algorithm is not signature algorithm so as what I suspected yes yeah so this would be the signature algorithms extension you know mom Thompson further did that the the EE sir not the delegated credentials with the e so that actually ends up signing the delegated credential would be governed by signature algorithms cert is that right actively part of the chain now no no no okay currently some of them would be signature most of them would be signature algorithm signature algorithm cert would represent the signatures in the chain above the intensity certificates so the expectation is that the delegated credential is effectively consumed by the TLS spec not by the certificate process absolute logic writes all in the gillis that\u0027s the insight that\u0027s not the PKI and it is a little bit confusing there\u0027s going to be two signature algorithms in the delegated credential one of which algorithm that DC was signed by and which one they can signed if they\u0027re both governed by signature algorithms that\u0027s what I spent it as well perfect "
  },
  {
    "startTime": "01:46:11",
    "text": "to add this well we also discussed having the delegated credential signing algorithm in the DC structure as well to aid for debug ability of errors when certain validation fails downstream yep that\u0027s a good point the pull request as written does not include the signature of them in the explicit delegated credential just in the signature trim the value that\u0027s signed by the signature but having it explicitly in the delegated credential will make debugging easier if you have a failed signature on a DC you\u0027ll you\u0027ll be able to figure it out much more more quickly a potentially stupid question is this difficult verify with a different label or is it gonna have the same label as in string it should be identical sorry Jonathan Hoyland and so you\u0027re gonna use potentially two different keys with the same label and this happens for if your switch using a different certificate for two I mean if you have to using a different certificate sorry you\u0027re using the same certificate verify structure for a slightly different purpose which means you could potential the shuffling around or cause problems or the purpose is the same it\u0027s the key that\u0027s different okay thank you okay next one this is a proposal that came up through discussions right now the draft supports TLS 1.2 and TLS 1.3 this proposal is to just drop TLS 1.2 from the proposal together considering this requires a new change in the client software it\u0027s natural to assume that all new TLS stacks will support TLS 1.3 and supporting delegated credentials with TLS 1.2 doesn\u0027t really serve too much of a purpose in this case I mean and going forward like so you know we have a working group basically tried to concentrate on 1.3 and not kind of fixing 1.2 stuff so I think it\u0027s kind of in keeping with the other changes and things we\u0027ve done in this working group the last like four years so some of them Thompson the the question then would be what\u0027s the cost to doing this in 1.2 because if it\u0027s if it\u0027s more expensive for us to say you can\u0027t do it in 1.2 then I\u0027d be sort of well just let it drive but I suspect what you\u0027ve got here is an extension you you currently in tell us 1/3 would put the delegated credentials as an extension on a certificate message which is something that doesn\u0027t happen in 1.2 I think we simplify the the draft considerably right so that\u0027s that\u0027s the case for this which is this makes the draft hell of a lot simcha we can delete a lot of text with this right and text that\u0027s not "
  },
  {
    "startTime": "01:49:12",
    "text": "necessarily useful and I\u0027m happy with that okay so this is this is something that we\u0027ve been doing for a lot of these dresses is let\u0027s get some actual assurances with cryptographic tools that this is actually a solid thing to do cryptographically and so we don\u0027t have a formal validation of this protocol as currently designed so this is this is sort of an open call if someone wants to talk to me to take this on as a project or talk to people at the working group this would be a really nice to have if before we do a last call is to have some some type of formal validation I can\u0027t commit with certainty but we have someone I think can take a look at it so all fucking do that for you and get back to the list okay thanks Daniel hurry I think I\u0027m late to this conversation so forgive me if this was answered a year ago but am I missing something or is this not useful until it has universal adoption if a client doesn\u0027t support this what\u0027s the service fallback behavior so I in the draft we described the service fallback is to use a remote key type of mechanism which has has a pretty stiff latency penalty so hold your key in another location that\u0027s not on the on the actual machine that\u0027s using to terminate TLS okay that\u0027s it anything any other comments or questions okay thanks okay I\u0027m Jonathan talk about layering sports authenticators next slide please so one of the things I did the formal analysis sort of explores to authentic ages and one of the things it says it doesn\u0027t do is provide joint authentication of multiple certificates applies in multiple EA\u0027s I can prove that I control them individually but not together and so what it actually means is joint authentication would mean that all the A\u0027s were generated by the same actor next slide please I think Ben do you want to interrupt oh please yeah I was just gonna ask you is there a formal definition of what you mean by gently odd or authoritative which I don\u0027t see in the draft I haven\u0027t included it hereby it\u0027s the I joined authentication means that you can prove that all of the certificates sorry all "
  },
  {
    "startTime": "01:52:13",
    "text": "of the EAS were created by the same entity for each side obviously the client ones aren\u0027t created by the Sun or anything next slide please okay so generally you would expect this not to be able to happen because only one person can write to this other side of the TLS channel or whatever however there\u0027s actually a bunch of different scenarios where multiple people could be right into the channel if you have a static RSA key exchange then it could be some middle box an attacker who\u0027s compromised difficut CDN coalescing multiple keyless SSL Certificates together or if you and this was just me last night if you have a server a resumption then you can the resumption whilst the secret might be passed around within a data center and so that multiple different places could accept the resumption other than just the original server next slide please so I propose an extension the previous difficult quest context is now not necessary because it\u0027s guaranteed to be unique but basically you just put the previous finished in the difficult quest and if it\u0027s echoed back it means the server or sorry means the sender believes that all of the previous certificates are valid so this is a not quite the same thing as joint authentication because it includes the client and the server certificates are all valid so it means the server has so if a server sent this it would mean it has accepted the client certificates as well but it also only applies to this difficut scre interchange it changed once the certificate together it says all previous ones are valid doesn\u0027t say anything about future certificates next slide please so one use case could be updating pins difficut I can prove that I control the old certificate and the new ticket I can prove that I\u0027ve accepted a certificate and you can provide authentication even if you are being middle boxed another use case that suggests to me last night was again you could chain or thent occations from resumption so at the moment if you sends in the a and then do a resumption you\u0027d have to resend that ei and now you could make it so that you wouldn\u0027t have to resend it you could just prove that you controls it just to clarify does that in does that also imply that every request and Authenticator now becomes ordered within the connection it\u0027s you would make a chain of them and therefore they would have to be in order in the chain not everything has to be in the chain and if and the chain can diverge and that\u0027s still fine you can have a forest of "
  },
  {
    "startTime": "01:55:14",
    "text": "authentication if you so choose the only case where that would be an issue really is if you have certificates cross mid-flight and then one side or the other has to do an extra sign if you I\u0027m entertained so in the forest\u0027 case are the different branches it\u0027s still joint across everything it\u0027s only joins on your branch so if I have two separate branches they can have two completely different authentication properties but it doesn\u0027t break the authentication it\u0027s just you can end up with some ridiculously complicated authentication mechanism yeah I wouldn\u0027t suggest as a you should do this that that\u0027s more of it it doesn\u0027t break so on at the HTTP layer we do multiple requests and you don\u0027t necessarily have to respond to every request and there\u0027s no particular ordering among the requests so at least in terms of how you respond to them I would have to think about what implications this has for the secondary search to achieve um I wouldn\u0027t expect it to make a difference because as long as the safety the server sending them as long as the server knows what order it\u0027s sending them back in it all works can you scroll back again to the actual thing you\u0027re doing right so the previous finished is the previous finished that I sent not the research that our guy said right it\u0027s the previous if I\u0027m linking 1e8 or previously a it\u0027s the finished message at that ei whether it was sent by the client or the server is irrelevant so okay I guess I\u0027m not sorry so hmm that\u0027s a very odd design Hausa typically we don\u0027t ask people to attest to random crap the third guy sent across the wire didn\u0027t also people soon feel to test a random stuff their guy sent across the wire so there\u0027s an immediate problem I see with this wishes that beam visit a very easy way to implement this that is completely screwed up isn\u0027t doesn\u0027t the request contain the contain the requested certificate is that correct the the requests the request would usually just contain a request context uh-huh and then some extensions right so how am I supposed to know which one is supposed to be linking to so so this is an extension that goes in my request I put "
  },
  {
    "startTime": "01:58:14",
    "text": "this extension of my request send link to certificate 3 or alright that\u0027s what I thought okay good and then I and I send in my response right yeah so what makes me check it so I mean the draw says you have to check yeah and what you would do is you\u0027d say if you include this extension in your response that means you checked if you don\u0027t want to check just drop it out your response yeah I\u0027m just saying it\u0027s a very easy way to implement this which is not the check on so I have a suggestion to try to make this much harder which is only sent the prefix of - in the request and then it needs to prove that it knows the hash yes I mean or any other trans any transformation is non-trivial right yeah I mean you could also grease this like I saw test if this other\u0027s doing that by sending a nonsense finished she won\u0027t build ones that live that right and and also more importantly if if it requires user intervention to generate the signatures then you can\u0027t possibly grease it right because then you just created easier if a user who\u0027s a little failure you just create the Creator to use their visible failure right mmm so um yeah I don\u0027t know so more thoughts required since we\u0027re we have like one minute remaining I guess I want to ask um who\u0027s read this draft oh I\u0027m actually a pretty good fair number yeah um I think maybe it\u0027s a little early to ask for working group adoption but I think that uh I I just wanted to get people to pay attention to yeah fair enough so uh go ahead we got time we have an obsession and I think that\u0027s it for today folks thanks for your time and those people that are Live Love DNS section extension please get together and try to solve our problem thank you [Music] "
  },
  {
    "startTime": "02:01:18",
    "text": "[Music] [Music] "
  }
]