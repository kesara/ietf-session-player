[
  {
    "startTime": "00:12:52",
    "text": "to get this list and then they were show that this module is up augmented by the IETF IP and IETF letter in instance. Next one, please We can reduce grades amounts of times by avoiding the get-all schemas because according to the Cisco XR published, YAM modules it has more than 1,000 modules and download that's for each, for parsing each YAM module will cost great amount of time Next slide, please and that's the information of thought. Thanks. Thank you. Thank you very much So next presentation is sustainability insights and after that possible attempt to use Schoam Pro. So first sustainability insights Yeah, you can use the mic"
  },
  {
    "startTime": "00:14:01",
    "text": "Yeah, it's, all right, set a timer three minutes All right, set the time with three minutes Hmm. Cool on. Okay, skip this I can't manage it. Right, there you go sorry But yesterday, you have to follow the microphone. Now you've tuned the levels, okay, sorry about that. Try to be a good citizen Next slide, please. I can run in myself So we're doing the do I have to focus I don't know what's going It's we have current deck We have a network problem maybe Normally we are connected to here So I'll just have to wait out the whiteboard. Oh, here. Okay so we're doing um sustainability insights getting sustainable metrics from the network, so the operation of the network to do life cycle analysis to be able to get the carbon footprint of the operation So that is not taking into account concrete that built the actual data center, but the operation levels of power draw, for instance So you can imagine that you want to have equal playing field then so you can compare different numbers and know what's in the numbers So if someone asks, like, is the cooling included in the power draw? you can then confidently say yes, it's included or not And then to compare different equipment in the network on on the metrics So the end goal then is,"
  },
  {
    "startTime": "00:16:01",
    "text": "to decrease energy consumption and then increase the awareness of the power climate impact So to do this, you can correlate the power draw with energy mix where it's coming from As you can see here this hackathon is using this sustainability in a box open source project what we did now is to replace this SSH collector that logs into some device and does show config to get the metric to do a yang push collector instead So what we did instead of having hardware to do this, we created a simulator device that published the model, the powerf model by a Yang Push, and we hacked NC Client NetConv Library to be able to get Yang Push and then added a Yang Push collector to this pipeline That was basically it The interesting drafts are in the box on your right, and the projects are published on GitHub. If this is interesting, please come by the green buff on Wednesday in region C slash D at 1.5 o'clock. Thank you you Thank you. Thank you. Thank you. So Okay, the next presenter is a possible attempt to use Schoompro Is that in the room? Remote Hello? Okay, thank you And the speaker of that is ILNP I know this in the room. Okay, there you go Yeah, please go ahead everyone, today I will be present"
  },
  {
    "startTime": "00:18:01",
    "text": "our work on using screenproof or RTC RTC Next. Yep. Yeah Learning this is a critical factor in RTC. High Lentense can decry the user experience in applications such as reduce conferencing and online gaming The primary issues contributing to Lentency include bandwidth jitter and slow detection of bandwise In many cases, detection of bandwice changes too slow, without a long lengthening To mitigate these problems, feedback possible, is needed. This pathway helps in reduce detection time and latency, thereby improve the overall quality of service in RTC applications. Next ScrumPro stands for security communication of network properties ScrumPro is addressing a use case when the network element does intentional throttling. Our attempt to network properties. Scumpro is addressing a use case when the network element does intentional throttling. Our attempt with Scone Pro focus on three main aspects First, identifying feedback information required for optimal performance Second, developing a flow control strategy for the sender based on this feedback and last evaluating the effect of this strategy on latency reduction. Next Our plan you involves testing the latency of Scrum Pro in RTCF applications, as software we use childquick a quick portable stack along with dog Docker and Linux TC to simulate network environment, and we have made our test report and the repo code were unrelated soon. Next The implementation of SCoomproRTC involved setting up a Docker bridge network with fixed latency and dynamically change bandwidth Also, we use ScrumPro feedback"
  },
  {
    "startTime": "00:20:01",
    "text": "pathway to feedback information. This setup allowed us to test the impact of Scrum Pro on RTC and the virus network conditions Next the feedback in Scrum Pro involve 2K metrics capacity, the bandwidth capacity of accessible points, QLEN, the QLens of the AP Based on this, we can calculate the send rate of the sender and the bit rate of the encoder And T is a predefined empty time Next, thank you Our result is also a significant reduction in length the encoder, and T is a predefined empty time. Next, thank you. Our with also a significant reduction in Lentanycy when using RTC with Scoon Pro Compacted to Kopa, we can see the grid line of Lentanycy in two figures. The following table summarized frame lentasy metrics. Next our team members for this project are Jaxing Zhang, Qing Hua Wu, and Jainui Li. Thank you Thank you very much There you are, the next presenter is here and after that we have to presentation on post-contum IoT Shields for PQ No, it doesn't work for some time Who? can use the so this is some work we've been doing across the last three hackathons putting a kernel together with modifications for ILMP. IMP is documented in RFC 6740 to 6748, and there's an ongoing"
  },
  {
    "startTime": "00:22:01",
    "text": "project at my institution university of san an Andrews in Scotland. So over the last two hackathons, we've just been debugging this kernel, a free BSD kernel and making sure things work properly And at this hackathon, we've managed to get it working and we managed to get some good results between here and Scotland and what we were doing was testing hosts multi-homing dynamically all controlled just by the hosts using pure end-to-end signaling using ICMP ILMP addressing is different to IP version 6 it treats the two parts of the IP version 6 address the upper 64 bits and the lower 64 bits as complete separate. The upper 64 bits are effectively an IPV6 prefix a locator. And if you attach to multiple networks, you can bind a node identifier to multiple locators and effectively you are multi- And so that's what we were testing in the BSD kernel Once you've changed your binding locally, if you're in communication, with a remote host you have to signal to that remote host that your bindings for locators, your network prefix have changed, and that uses an ICMP message And so one of the things we really wanted to see was if that ICMP message would be able to make it across from here to Scotland and it did So the experiments we were running yesterday and this morning were to take IPRF run some tests with that. We're both TCP and UDP, and I've got a graph later just to show you what happens with TCP. A TCP flow is started, and then at the network level there is dynamic multi-homing so interfaces are brought up and down new prefixes are discovered using IP version 6 router advertisements"
  },
  {
    "startTime": "00:24:01",
    "text": "and they are just added to the end host and so the TCP flow just works over the top of these. So TCP hasn't really been modified at all to understand that it's worth over multiple parts in this case, and it's just a set of interfaces going up and down. There's a sequence. We start off with one in interface, then go to two, then go to three, then four, then drop back down just to see that the signal works. So we weren't after performance at all in this particular hackathon testing we just want to see that signaling work. And this is what the result look like not very easy to read i'm sorry the um graphs, the four at the top show the throughput on each of the four interfaces So as I said, one interface was being used throughout Then we switched on the second one, then the third one then the fourth one then we turn the fourth one off turn the third one off, turn the second one off, and at the bottom is shown the aggregate throughput If you're interested in any of this, I'm around all week and we'll be at the hack demo happy hour with the other people who've been working on this. And if you're particularly interested in the BS kernel modifications, Gregor, who's not here, will be giving a presentation at Eurobe in Dublin in September. Thanks for me much Okay so yeah, you're next And the next speaker after here is exploring implementation process for the Merkel tree letter Every time it doesn't work Another attempt"
  },
  {
    "startTime": "00:26:01",
    "text": "You have three minutes No. Thank you. Thank you Okay, hello everyone. My name is Elias. So today I'm going to talk about IOT and how we can use post-quantum algorithms that we have Okay, so the problem is that we always say that in the industry that is in IOT stands for security, because there's not been done really much in securing the IOT devices And now we're dealing with even a bigger problem and that's how we can secure it against the quantum computer So there's been lots of research going on about like new algorithm that we can use for key encapsulations, but there's not being much done to how to implement it in IoT devices So here's, sorry, just keep skipping so here we try to develop a draft like a repository so developers can use it into IoT devices. So we can encrypt it draft like a repository, so developers can use it into IOT devices, so we can encrypt the data that is passing through IOT by default there's been much lots of drafts, for example, by NIST that we have for the cryptography for post-quantum and all some that are already discussed in I IETF. So here our repository. Please check it later and control to that if you're interested so to develop it together and make it more efficient So there are two proposals here the first one you can see that we can have like a mesh like design. So the devices that have be have end-to-end communication and you encrypted, for example, by a AES and then have the encapsulation by Khyber as we have developed in our repository"
  },
  {
    "startTime": "00:28:01",
    "text": "The second one is that we actually are developing like a hub that is a we're building that on top of the Raspberry Pi So all devices connected to the Raspberry Pi and then we encrypt the all the information that they're passing through this to outside network or within the local network. So it can look like something like this that you can configure it and you can kind of make sure that always the data is encrypted So we also need more lightweight approaches. There are some Lorescope going on. We actually work, but we have developed a cipher called the gnome cipher. We'll push it after this IETF conference, and hopefully we can help have your help to test it because this is something that can speed up the process by benchmark by 10 times and hopefully by your hope we can make it event better uh because this is something that can speed up the process by benchmark by 10 times and hopefully by your hope we can make it even better. So there's been lots of lesson here I am the first timer here. I appreciate the opportunity So the takeaway here is that IOT still needs lots of focus and hopefully together we can focus more on how to make it more efficient and secure Yeah, thank you very much for your time Okay, thank you. Next presentation in the Merkel tree ladder mode and after that is the responsible DNS integration Thank you Thank you. I will be able that Yeah. Can I take your left? Okay First slide here So our plan was the familiar uh"
  },
  {
    "startTime": "00:30:01",
    "text": "hackathon participants with the draft we came up with. Stateless has face signatures for Merkel Tree Ladder Mode and start talking to implementers about how this might work kind of get the practical feedback into evolving the draft because these will it is a mode of operation that would impact properly resolvers authoritative name servers and us signers to fully take advantage of MTL mode. We have our two drafts listed there. So we want to get that feedback and explore the implementation approaches So what we did to solve the process we wanted to walk through how the signatures are created. And we wanted to show what it looks like. We have a examples of how to do digs against a zone to spin been signed with the Merkel tree ladder mode And then we had discussions with software providers So participants were able to do the dig and see what the signatures actually look like from a live zone file from an authoritative name server We talked them through getting an understanding of how Merkel tree ladder mode operates so they can understand that this is a mode of operation that minimize the size impact of underlying PQC signature schemes And then we could talk about these implementation approach and start to explore alternatives And in particular, it relates to validates resolvers. So we learned was that there's a lot of aspects to implementing a new mode of operation for DNS SEC and particularly because of a some of the things we put in our draft that really make it work well"
  },
  {
    "startTime": "00:32:01",
    "text": "So we need input from the implementers, the operators, and the other people in the DNS SEC ecosystem And there you'd see an example of what, just what a couple of the digs would give you if you dug against the live instance The team members, from Veracine that were on it were Bert Kaliski and myself, and we had dropped by people that we had the discussions with So with that, we're here all week and we'd love to have more interaction about this. Appreciate it Thank you very much Okay, there's next speakers, excellent And after that we have testing congestion control Just that you can't right as you can yeah. All right this one, okay, thanks All right, so we are here talking one. Thanks. All right, so we are here to talk about DNS integrations and most of you would know that DNS domain names have been used for a variety of use cases over the number of years in going all the way back. FTP Tullet, and then, you know, we've had email and web browsing, right? But as of late, we years. Going all the way back, FTP, Tullet, and then we've had email and web browsing, right? But as of late, we've seen that there's a lot of new use cases for D the way back, FTPTELET, and then, you know, we've had email and web browsing, right? But as of late, we've seen that there's a lot of new use cases for DNS domain names within blockchain and Web3 applications decentralized social media applications to name a few use cases But what we would like to see, so that's encouraging, but what we'd like to see is that these integrations are done in a responsible manner"
  },
  {
    "startTime": "00:34:01",
    "text": "so what we did was we studied, you know, a few of these integrations are listed on this page. Before I go into that, you know, what I would mean by our responsible DNS integration. Well, we want to ensure that any application that's allowing DNS domain names is identifiers give you the same consistent user experience that you expect at the same time that extends the security and reliability of DNS into the application or the protocol and so the studied blue sky ENS and Microsoft GitHub So the first one, EnS, Ethereum names services naming application on the Ethereum blockchain that allows you to import your DNS domain names And so once you do that, you can use that in all the applications that are supported via ENS One of the common use cases is using DNS domain names to identify your digital wall The second one is ENS, I'm sorry, blue sky, or blue sky is the social media application that allows you to use DNS domain names as your handles on the social media platform And then the last one is Microsoft GitHub They have a product called GitHub organizations and so and if you have your organization create a GitHub page and allow, and they allow you your DNS domain name to the organization's GitHub page. So as to build trust with your end users and you also can verify that you control the domain name after which you get a green check mark to show that the domain name has been very"
  },
  {
    "startTime": "00:36:01",
    "text": "as to build trust with your end users and you also can verify that you control the domain name after which you get a green check mark to show that the domain name has been verified and so we did some measurement studies to understand if these integrations are responsible And so you could look at our data if these integrations are responsible. And so you could, you know, look at our diner 2024 measurement study presentations that we have we've done what idea of presentations through the year there's two outcomes one is these are integrations integrate with DNS in variety of ways And second is that there is a gap in understanding of how DNS work. And we can certainly yeah, they could certainly use some guidance from you know, this community. And so what we did was we wrote up a draft uh, that talks about, uh, you know, your guidance for integrating with DNS response responsibly responsibly The draft talks about more motivations for using DNS domain but at the same time there's obviously a lot of challenges and the draft goes into a lot of details about the challenges or considerations Somalia first one is the domain name lifecycle, right? So as we know, the domain names have a life cycle Once you register domain name, it can expire it can get deleted, it can get transferred. And so how do these applications that are integrating into DNS ensure that the states are synced across? and so as to avoid any security vulnerabilities as a result For example, depending on the use case in the context, the consequences might be dire. For example, the cryptocurrencies might get transferred to someone else while you were expecting them to be transferred to you and so as part of this hackathon, we're here to try and get feedback on our draft which we did and thank you very much for"
  },
  {
    "startTime": "00:38:01",
    "text": "all the valuable feedback you've given us and we would definitely incorporate as appropriate into our next world on our draft which we did and thank you very much for all the valuable feedback you've given us and we would definitely incorporate as appropriate into our next version we're here all week and if you see you've given us. And we would definitely incorporate as appropriate into our next version. We're here all week. And if you still have more feedback, we'd be happy to take it. We have our email it addresses and please feel free to reach out after IETF And then these second thing was which working group is the right one for our draft and I think the consensus in terms of folks we've been talking to is DNSOP is the working group. So we'll keep polling for that and yeah in conclusion I think the we most people we talked to agree that there is a need for having standards and best practices for responsible DNS integration so that current and future integrations have a path forward to integrate responsibly Thank you Thank you Hi, so next speaker as you and sorry, I have to announce the next speaker here after is the ultra low lady crypto. I have two copies for some reason. So maybe if I select the wrong one, then just please let me know then okay okay please go ahead Hi, my name is reese enghardt and I'm talking about congestion control test So just to bring everybody along congestion control is a process with which Ascendo works out at water rate to send and if we're doing this well we get better application performance as well as later under load. Now, let's see Our high-level plan is that we have several proposals for congestion control in different groups and testing is important"
  },
  {
    "startTime": "00:40:01",
    "text": "so we want to work on test tooling and test cases, and we could also see people hacking on congestion control implementations at this table. Now, this was our first time having this specific table and we had one test of the careful resume draft which is in TSVWG Oh, okay. So this is an interesting between different quick implementation as clients and NS3 sim simulator which emulates a bottleneck of 600 milliseconds and 10 mbPS, however we only achieved five due to NS3 limitations and so we had this long latency to get a specific bandwidth delay product. And then the sender is a key mbps, however, we only achieved five due to NS3 limitations. And so we had this long latency to get a specific bandwidth delay product. And then the sender is a Kish implementation with careful resume and there is a jump of 400 packets Now here's our results all the different quick implementations as we receivers and Kish is our sender The careful resume jump happens in all cases And then there is a different number of packets being sent in the unvalidated phase, validation happens. And so the final outcome congestion window is different in all of these cases. So that's interesting because careful resume is a center side draft, right? So why would it make a difference to have different receivers we're going to still be digging into that, but the bottom line is interoperability, kind of all class worked. So next we would like to bring this table back and have more people involved and more test cases different congestion control algorithms. And part of that is I want us to work on our elevator pitch of what congestion control is and why it matters. And then also, of course, we're going to reach out to more collaboration such as academics That's it for now. Thank you to Gorey and his remainder team, Anna and Mihal, and I'm Reese. I look forward"
  },
  {
    "startTime": "00:42:01",
    "text": "to seeing people during the week Thank you All right, so After the next presentation, the next speaker will be the digital map hackathon hackathon There you go. Please go in Good afternoon, everyone. I'm yumi sakemi from GMO Cybersecurity by IELI, Japan Today I will talk about our IETF-120 Haksom activities activities At first, I will explain the overview of Alleyon Arrayon is a secure and low latency critical plantations based AS instructions and Arleon can be applied to encryption and hushing For more details, please refer to it based AS instructions and Alleyon can be applied to encryption and hashing. For more details, please refer to our internet draft As the use case of Alleyon, we expected that the use case requires real-time secure communication for example, e-sports, remote surgery, and so on on at this at this Hakka-son, we plan to measure the performance of Arayan compared to the measure used cryptographic free mid-bit In detail,"
  },
  {
    "startTime": "00:44:01",
    "text": "as the comparison target is AES-256 DCM and SHAR-256 This slide shows the measurement conditions as the experimental environment, we used A.E environment and arm environment And as implemented, of comparison algorithm, we used open SSL implementation and the measurement as the measurement precautions, we'd like to note that the measurement range includes initial processes These slides show the experimental results in the case of encryption As shown these tables, the message length is shown when the message length is short, Arrayon is approximately two times faster than ASGCM The next is in the case of hushing when the message length is short, Rayon is approximately three times faster than Shar 256 This slide shows our considerations From the experimental results, we found that Arayan is effective when keys are frequently updated and the message length is short for a month 32 bytes Now we are looking for effective applications of the"
  },
  {
    "startTime": "00:46:01",
    "text": "above features. So we would apply appreciate for your comments or feedback This slide shows next step, especially with need volunteers that developed independent implementations So if you are interested in our activity please contact us That's all. Thank you for your attention Thank you. All right Next presenters, you. Excellent And this is the digital map. And after that is the antagonist Here you go. It's most safe to click Yeah, thanks So I'll present the result of our digital map hackathon. This is the hackathon that we plan to do over multiple IETFs, but this is the first detail Thank you make this bigger? No, if we're No, unfortunately not. Okay, sorry. Sorry you have to speak in the microphone, but it's difficult But I can't see this. So, a hackathon plan is to demonstrate how operators can use ITI topology modules to represent the real IP operator net And we want to demonstrate if R.H 345 is the right approach for modeling topologies. So this is the first iteration, as I mentioned, and we will be working on improving this hackathon in Dublin So these are the drafts that we have and some of them we implemented and another one some all I can"
  },
  {
    "startTime": "00:48:01",
    "text": "So these are the drafts that we have, and some of them we implemented, and another one, some more like informational drafts and concept drafts, etc So you can see the list here on the right side there you can see kind of how we implemented those drafts. We collected things from the operator lab, from the real lab, multi-vendavan using IETF OpenConfigure you can see kind of how we implemented those drafts. We collected things from the operator lab, from the real lab, multi-vendavan, using IETF open config or vendor-specific module via NetConf, and then we modeled it and mapped it to the to the IETF network-wide models So one of the challenges going forward is how to connect those network topology modules with the IETF I size, for example or some device modules which have added configuration and performance attributes Sorry Yeah, it's pretty good slide. Yeah, it would be larger. Yeah, sorry Okay, I think slide three, okay, I can go like this, so it's easy So the first iteration would be focusing on looking at the multi-vander operator lab. Yeah, we use the operator lab for this hackathon and it was Hovay, Sisko, and Juniper devices it started with fun particular problems space, how to use these models to represent a real carrier network based on the ISIS and OSPF as well but focus of the HACATON because of the lab only had ISIS was ISIS and the target is really looking at a simulation and planning, but that is for the next hackathons"
  },
  {
    "startTime": "00:50:01",
    "text": "So we focused on generic topology query first, so we started from the read only with the goal going forward to go into simulation and we also looked at the options and comparing the draft augmentations of RFCA-345 versus some gaps that we identified in our drafts so we implemented multiple options. So we also started to analysis and prototype, how to retrieve performance metrics and configuration attributes defined in RFC 9130, sorry, this is typo, and retrieved via device API So nodebound from the controller, the RFCA 845 API, and its ISIS augmented This is our lab, and this is the multi-vandal lab with 11 devices. At this point, we have a discovery of 10 of those devices for the next hackathon, we'd also have Nokia planned and we also have some simulated other two operator labs and one vendor labs so we've discovered before but this is the lab that we connected in real time during the hackathon So what we achieved, we're currently have discovered layer two eyesized topologies for multi-vender and relation between the layers. We mapped different devices models to the network where topology models, we retrieved them the IETF topology API. These are the draft API so we tested those draft's young modules we implemented two options for comparison whereas I said areas the model is IETF networks and when ISIS area is modeled as attributes, which is really something that has to be done at the moment because of limitations of RFCA-345 And we started working on how to connect IPF L3, ISIS, topology"
  },
  {
    "startTime": "00:52:01",
    "text": "to IETF ISIS module. And first attempt is by adding augmenting the topology with some subtrees, but that's not the right approach really as a target, so we need a better approach in the next hackathon code is here but we have to go through it a little bit before making it public The lessons we demonstrate to the TIPS the suitable standard for a presentation the multi-layer topology We also kind of determined that operators may have one ISIS area in the domain or multiplyize isis areas in the domain. Therefore, we have to provide flexible modeling for this In the case of multiple areas, there are limitations in our domain or multiple ISIS areas in the domain. Therefore, we have to provide flexible modeling for this. In the case of multiple areas, there are limitations in RFCA 345, we implemented two options for comparison, and we need a new RFCA-345 augmentation for the purpose of connecting topology modules to our modules with young parts defining the young parts that are connecting them and also the challenge is how to map find the right instances and keys in another module because the keys are different and we want to avoid duplication of the properties at that network layer These are the two APIs The left one is the one with the areas as net network. The other one is the yeah, the other one is the one with without area, the network, and below you can have some kind of pros and cons of each approach And what next? For the next hackathon, we are going to add VGP SIPv6. We will separately, three topology from ICE topology. We will add more peritola Labs. We will add more vendors. And we want to implement more advanced option for connecting"
  },
  {
    "startTime": "00:54:01",
    "text": "topology to other properties in other young modules and solution must be generic to support any other augmentation and we also want to start working on other use cases and current candidates are simulation or regulation so this is the team oscar myself Benoit, and Sherry, Pierre, and Weber. Thank you very much much So the next antagonist, excellent excellent speaker after is the young push model young push publisher There we go It's a little bit small, but that's pretty small. Can I prefer this? Yeah, thanks. Hi, everybody So if you are operating networks and you have plenty of network anomalies, I wanted to reassure you today because your network can anomalies now have a new antagonist, which is the name of the project, and it stands for anomaly tagging on historical data. Now, this is the third time antagonist comes to the IETF hackathon, and it started actually because we needed to have somehow a running code validating this two drafts, which we are presenting on Friday at the NMB working group these two drafts of course are about network anomaly detection detection Okay, so why do we need on antagonists overall? So first of all, let me say that antagonists is a label store for network anomalies detectors. The whole point of network anomaly detection is basically to enable operators discover when something is not working as expected in their network as soon as possible. And these"
  },
  {
    "startTime": "00:56:01",
    "text": "is an iterative process. So we understood that there's no way you're going to get it right the first time. You have to learn over time and you have to keep integrating knowledge in the process. And for this reason, we actually defined a semantic for exchange data for different from between different actors different operators different teams and different tools as well. And a life cycle, which is actually the moments in time where these exchange happen And it turns out that it's really, really important to have a standardized format for this and these projects is actually trying to validate this standardized format so there are a few use cases that antagonist can currently support. The first one is the exchange of anomaly detection labels between different operators or between different teams. And of course, as we talk about it, anomaly detection, we always talk about machine learning and AI. So we want to make sure that these models can actually be both human readable and machine readable and actually feed machine learning models in different ways so we're validating the ability of machine learning models to persist labels in antagonist and to actually retrieve labels from antagonists for the retraining with a validation step in the middle between where human beings can actually validate network engineers can actually validate if those network anomalies are real or are false positives The Hackathon Plan, which is also what we actually managed to achieve today and yesterday, is basically we wanted to validate our project with real operational data. In this case, it's from cloud domain we we wanted to validate the interaction with machine learning models. We actually had a pre-trained small neural network which we use today for the validation here"
  },
  {
    "startTime": "00:58:01",
    "text": "And then we wanted to also validate the support for retraining of the machine learning models and added partial support for the metadata filtering and service of the labels and to fix some deploy or integration issues we are encountering So this is the kind of architectural, these are the architectural models we currently have, so everything is deployable through Docker We are here we're basically modeling the three steps of the lifecycle which are detection validation and refinement, and we've done that by a mean of a couple of Python notebooks, which is the classical way machine learning engineers or data scientists operate with with machine learning models when they do when they play with training and retraining and stuff. And then there's a validation which is provided by a GUI that we build and there's a rest API which substantially supports the young model format in the drafts that I was mentioning before And all of this is persisted in a SQL database Just a quick example of one of the functionalities that we managed to add in this iteration, which is about the automatic generation of dashboards just to make it easier for users to review the results provided by anomaly detection systems And in terms of next steps, this is still very much a POC so we're trying to make it a bit more stable for the next time and we want to improve the scale scalability as well And the very important step also is to make sure that we can validate it a bit more stable for the next time and we want to improve the scalability as well. And the very important step also is to make sure that we can validate and integrate with real network operational data And I wanted to thank the team for the support and help help Thank you very much All right, next slide are"
  },
  {
    "startTime": "01:00:04",
    "text": "Yep, and off presentation will be the threat, low power There you go. Okay, save is to click. Okay, perfect. Thank you I'll give official one minute. Sure, okay Hi, everybody So our project is validate configured subscription young push publisher implementations and the scope The scope of the project was to validate different young push publishers again Young Push Receiver and also in context of message broker integration. We have a repository with the packet captures and also the outcomes of the test automation and the young push notification messages and also a testing script which we are used these are the draft documents the rfc documents involved in the implementations and on the right hand side you see the integration into the message broker And I marked the red area where we were actually doing the verifications Here one example so from this iOS XR the young push notifications we have the push notifications, we have the push change update notifications the subscription started and subscription terminated according to RFC 86 Yang push notifications. We have to push change update notifications. The subscription started and subscription terminated according to RFC 8641. Here an example from six wind uh from the subscription started messages with the different enhancements which an enabling the data mesh, the message broker integrated Here from Huawei, a subscription started message"
  },
  {
    "startTime": "01:02:01",
    "text": "message And here a push update message, so you see basically the subscribed content and also the observation time stamping and from which note this information was being exposed and push change update messages and also like with the state changes in the observation time stamping Here the comparison where we are today, so we started with at IETF 119 with the first implementations now we are at 120 and you will see in the upcoming IETFs how this is progressed progressing to many people who were involved some people remotely some people here locally. Thanks All right, after thread presentation, next time is addition, addition into young library Okay, thanks Click that button. Yeah, this doesn't work I want to start by thanking Beno and Barry and Charles for making this possible and providing this venue and it brought together eight people, eight strangers who didn't know each other, never worked together before and we learned a bunch of stuff I think for most of us, we lot of the people had never heard of thread before"
  },
  {
    "startTime": "01:04:01",
    "text": "Most of us had never done any development for embedded systems before So we had a lot of learning to do And I'm sure you saw on the hand hackathon page, we had a bunch of interesting projects to work on. I'm just going to talk about one of them today For people who don't know, thread is it's a lot You can think of it a lot like Zigby or like Bluetooth in terms of cost, power, range, performance. The big difference is thread embraces IP and that's why we love it because you can take any IP application that runs over TCP or quick or anything else If it runs on Ethernet, if it runs on Wi-Fi, it'll probably run on thread and these these radias are so low power that they can last for years on a single AA battery So thread is really exciting and typically these boards have a US port that you plug into your computer for flashing firmware on them and doing that development And when I first saw a dev of thread years ago, now one of the vendors, from Silicon Labs or Nordic or NXP, I forget who they showed this demo and they had this board plugged into the USB port of their lab from Silicon Labs or Nordic or NXP I forget who they showed this demo and they had this board plugged into the USB port of their laptop and they're using a serial program to type commands to the command line interface and they were showing me I can type this command and I can tell it to join a mesh and I can do a ping six, and look, wireless networking and I went that's not wireless I can see the wire it's plugged in the USB port show show it to be wirelessly if it's supposed to be wireless and so this has always been something on my mind. And today, this weekend, we achieved it. We have a TCP listener running on the Thread of the Open Thread development environment running on the little board, barely bigger than a postage stamp. We hooked that up to the command line interpreters input and output"
  },
  {
    "startTime": "01:06:01",
    "text": "instead of using the serial ports and we add advertised it using DNS service discovery aka bonjour. And then in the terminal program on the Mac, I added a new browser for Open Thread, and you click on Open Thread and then you click on whichever one you've discovered on the list you want to use and you click connect and now you're connected and you can type all the same commands you would have typed over the USB cable, except now without the wire. So thank you Thank you All right Thank you speaker is the addition into a young library set remote maybe? All right don't hear anything so the other one the next the next well I would like to invite the L for people to give a presentation Excellent And I will ask again for the other presentation Great, thank you All right, greg white and Cable House This is the fifth time that L4 This is the fifth time that the L4S Group has held an inter-op event co-located with the hackathon And as in previous IETS, when we've done this, we typically start out during a hackathon event itself and then for the rest of the week we continue testing in the code lounge or some other space that the IETF provides. So same things have happening this time. We've got the network set up and I've done quite a bit of testing yesterday and today"
  },
  {
    "startTime": "01:08:01",
    "text": "And at the end of the day today, it will be moving to another location the We'll be moving to the Brighton room, which is on the fourth floor Invite anyone who's interested to stop by and participate there for the rest of the week So what have we been working on? So the key components to this are the L4S congestion control architecture, which is includes a congestion control implementation on the center It includes a congestion signaling by the network in the ECN field, and it involves the receiver sending feedback back to the sender in terms of the congestion marks that were applied by the network. This is all defined in the RFCs in the box on the lower right, 9330 9331 and 9332. And then for TCP, the feedback mechanism is being standardized in the accurate ECN draft as listed there. Our setup this week includes a GPON network emulator with L4S support, very configurable We can set up all sorts of different paths with different characteristics. Also, a couple of Wi-Fi access points that support L4S which can be used for testing as well And then the congestion control implementations So Netflix is testing their simple rate control There's a new open source congestion control algorithm called UDP PROP implementations. So Netflix is testing their simple rate control. There's a new open source congestion control algorithm called UDP Prague that's been tested this week We have implementations the Apple Quick Prog, as well as the Linux TCP prod For Linux TCP Prague, there are now kernel patches for Linux kernel V6, which is new as of this event What have we gotten done so far?"
  },
  {
    "startTime": "01:10:01",
    "text": "And again, we're just kind of getting started this week So hopefully we'll be doing quite a bit more. And actually, I'll give a recap of the whole week's activities at the TSV Working Group meeting on Friday So if you're interested in seeing more of what got done, please join us on Friday So far, we have produced, or one of the participants, produced a new set of kernel patches for ARM for Colonel V6 Linux. We'll link to that in the slide that includes all the components Accra DCN, TCP, Prague, and of the dual pi-squared congestion, or act Q management mechanism. And second piece is integration and testing of this new open source UDP Prague So that was just published today So a link is also on the slide there. This is a congestion control module that can be used really with any application So running on top of UDP gives the application the application the ability to get this fine fine-grained congestion feedback for the network and get very high through and ultra low latency. So any application that has an interest in high throughput and low latency could pick up this implementation and integrate it into their application And so if anyone's interested in finding out more about that and getting in leg up on getting that implementation any of matthew quick Developers media over Quick or WebRTC that sort of thing, I invite you to come and talk to the folks at the all four us table either here the rest of the day today or up in the Brighton room the rest of the week. Also, this week, that module has gone integrated into IPRF2"
  },
  {
    "startTime": "01:12:01",
    "text": "So anyone who wants to do network testing, testing L4S implementations can get the latest builds of IPRF2 and run testing with that congestion control module Last two items there were support added this week on okay, almost done support for examining the state of the ECN and state of congestion control in the TCPA black box logging feature within previous and Netflix was working on validating improvements in their implementation of L4S congestion control as well So thanks to all the team members who participated so forth this weekend and we'll be continuing this week. Thanks Thank you very much Okay so yeah so please come along is there also the addition into Young presentation I announced just? it's from the Benoit class group, so someone, okay it was double okay thanks thanks I see, yeah, you're right Apologies Then, yeah, up is you. And after this presentation is the DIN stuff. There you go Thank you. Thank you Save the Click on the house. Okay, alright Yeah, this one. Okay. Sounds good"
  },
  {
    "startTime": "01:14:01",
    "text": "safe to click on the mouse. Okay, all right. Hello, everybody. I'm Osama from T.U Dresden All right. Hello, everybody. I'm Osama from T.U Dresden and thanks to my sponsor, Confidential Computing Consortium, which is where attestation is really the enabler for confidential computing and that's why they are funding me for this Basically the idea of oops of Oh, it's lagging in the, okay so the plan of the hackathon was basically that we have three different ways in which attestation can be incorporated in the tier protocol. And the problem with TNS protocol itself or the standard itself is that it only provides the guarantees when the network when we assume that the endpoints are safe or secure. So basically that the keys are always protected. Under this assumption TLS works very well But if this assumption is not correct, meaning that if the endpoint is compromised, there are no guarantees whatsoever So that's under that. So we have explored like three different options which are shown here on this slide pre-handshake at attestation that the attestation part, which is the signing of this, oh, you don't see also the mouse. Signing of evidence happens before the TLS even starts so the time scale is from the left to the right. And in the second option, intra-hand attestation signing of the evidence that is the claims basically happens within the TLS handshake And in the third option, the post handshake, which is where TLS handshake has TLS handshake has now finished and after the finish of the TLS handshake the signing of the evidence will happen all of the three different options have their own security pros and cons and their own security properties and the involved internet draft here is by Hannes and all who are working towards standardizing the attestation, the TLS and DTLS And the goals for this hacker"
  },
  {
    "startTime": "01:16:01",
    "text": "were specifically that how do we actually spell? and by specification I mean formal specification of the case for confidential computing and then the second step is after specification how do we verify that these claims are caught So formal verification Okay, now I hope I click only once okay and the insights, insightful discussions, thanks to all of them who contributed to this And what we came out with was that the overall direction of the research that we are doing is correct that we have not only the for not only the developed of the research that we are doing is correct, that we have not only the development and along with that we also have the formal verification for them and the insights that we obtain that were not yet in the formal model is not only at a station we have to define really what exactly is being attested so that something that's not really in the form model yet. And we have a side meeting where we will summarize all the learnings that we have until now from the perspective of confidential computing specifically and I really hope that will be interesting for the RETS working group to think more about the confidential computing side and for the TLS working group that's where basically it's and rats can be considered as one extension of the TLS And then the WIMS, we are, that's working group is not specifically focused on the on the confidential workloads but this will be an interesting insight for them as well and the lake working group also has a draft which is extension of attestation in the ad hoc protocol. They can exactly follow the same things that the draft attested TLS is following and the UFMRG of course from the former verification site that will be interesting for them and I have added some links that will be interesting for you if you want to explore further and finally"
  },
  {
    "startTime": "01:18:01",
    "text": "cc attestation sick the last link in there is the special interest in special I forgot what it's answer. So it's the group which is working on the on the attestation perspective and it will be interesting for a few folks from rats also to join there Okay, so this is the internet draft which is focusing on that so I will be here next week as well, so I look forward to the discussions specifically I couldn't meet or I couldn't see many of the TLS working group people here around So I hope that we can have some discussion around that And thank you very much. I look forward to it Thank you. Next is the DNS presentation. So it's a combined one of two, three presentations or projects. Two Excellent. So you get double time Dinner stuff, as usual they put too many things in the DNS and uh presentation afterwards is the peak interoperability I have two versions I take the way list It's best to click on the error. Okay so it's so nice to start IT week with meeting on my DNS friends at the hackathon and meeting all the best of you as well, actually There's a bunch of them on this first slide slide so we had a hackathon general dns stuff table I did the first thing, which is SVCB processing by OR alias mode processing by the unbound results Currently, the DELAC will processing by, or alias mode processing by the unbound resolver. Currently, the DELAC working group is still in requirements mode"
  },
  {
    "startTime": "01:20:01",
    "text": "but there are already two protocol proposals that built about SVCB. So they may benefit from this if they go anywhere so shane kerr did implemented zone version EDNS option in NS1 It means that you sent an EDED option and the authoritative name server reports from which zone the answer came and which version of the zone This just came out of working group last call and is now submitted to IESG Jockels finalized the DNS error reporting that we've been working on for a few hackathons already, I guess Shimon implemented the latest protocol enhanced in the compact denial of existence with the new assigned annex name code point or art R-R-type, and Ilius implemented ID key a successor of Dieness key in Dinesack that deals with the issue that key trap And now I hand over the mic to Yoan Thank you, sir So what? did we do at the other table then? Well, we will have this draft since a couple of years back about so-called generalized DNS notification And that together with another draft that builds on the same foundation, which is the decent RRC essentially presents two different mechanisms for completely automated synchronization of the delegation information between a child and parent But for this to really be useful or"
  },
  {
    "startTime": "01:22:01",
    "text": "even understandable, we obviously need running code so we have a name server an open source name server written in Go, and as you can see, it says it done in many of the squares there because we are really nearing completion of full support of both the notify based automatic synchronism and the update-based automatic synchronization There are a couple of corners left, as you can see, but most of the work is done And then we also have various CLI tools to play with this and then test stuff, etc in Python and in Go. So it's coming along nicely And for those of you who are not entirely into why this is important or why we spend effort on it, this is a way of looking at it that you have all these zones out there and the zone maintainer make some sort of change And in some cases, this change affects the actual delegation information. You change your name server or you change the glue from a name server or something like that and then you forget about it and you don't really update the parent. And the result is that you may think that you have four name servers but in reality you don't because you didn't really get it updated in the parent or something. But with the change, suddenly the child nameservor itself will be able to detect the change and do something about it And on his own behalf, synchronize with the parents and then everyone just heads off for the bar and happiness ensues. So that's the plan. Thank you you Thank you very much So the next one is the PQ interoperability And after that"
  },
  {
    "startTime": "01:24:01",
    "text": "it's the stateless open PCB signature verification Okay. It's best to okay Okay, hello everyone, so I'm going to present on the pq and x 509 uh so this is actually our sixth hackathon. So we started back yeah, almost two years ago. Basically, the idea was to get together, test a bunch of these new PQ algorithms that are coming and basically it's just continued to grow from there Also, the NIST NCOC NCCOE Interoperability Project has actually been, actually I don't know why it's kind of messed up on there, but anyway, it's looking at they collaborate with us or they work, anyway, we kind of fit in their projects, so they often look at us when we're, um, doing testing. So that's quite exciting to be part of that and so part of our product goals, obviously I kind of mentioned them already I want them gain experience with PQ algorithms, provide feedback to see standards groups, obviously test interoperables There's a bunch of drafts there so there's lots of new drafts coming with all this PQ stuff so we kind of give feedback and some of us are implemented some of these drafts as well using PQ algorithms so that's all fun and exciting So the important part of what you're interested in is what we got done We actually got a lot done at this hackathon. Thanks to it lot of members so the first item there one of the new exciting things is so we have a GitHub repository that contains artifacts people can post them. So now there's a new GitHub action that will actually, when you post your new artifacts, so say you have a new implement of a PQ algorithm with X5 and 9 certs It will actually run a GitHub action and then automatically run it against Live OQS, which is, you know, a new implementation of a PQ algorithm with x5 and 9 certs, it will actually run a GitHub action and then automatically run it against Lib OQS, which is a standard library. A lot of people use and give you an immediate"
  },
  {
    "startTime": "01:26:01",
    "text": "feedback and we also have tooling that will then create a compatibility matrix. I'll show you a picture of that later And we'll automatically update that as well and we will probably update that in the future as well to add other open source libraries like bouncy castle and that so that's an exciting innovation that this hackathon There's also automation scripts for building Ken recipient info artifacts that were done We had a person join us. He wasn't here at this one. We actually have monthly meetings as well But a lot of these new algorithms, they don't have official optics IDs yet. So a person wanted to make that more crypto agile. So he made an adjacent artifact for lot of these new algorithms, they don't have official object IDs yet. So a person wanted to make that more crypto agile, so he made an adjacent artifact format, basically adjacent format so that you can import that, make use of that, and obviously make your testing more crypto agile so we have that, so that's happened in between because we keep meeting as well And yeah, we have our first implementation of composite chem as well so that is thanks to Carl there's still a few things to need to be done, but this is really great So that's one of the new drafts that's being worked on And there was some discussion about either doing some interrupt testing or some work with TLS with some of these like composite keys and things like that So some work started there but there's more work to do there Yeah, and we had a lot of new people to join So one of them is the major telecom of Taiwan, which is exciting. So I just got introduced to this group a couple days ago, and they joined they created their own provider, they've submitted artifacts they've tested against every other provider. I think there's 12 or 13 of them now, so different implementations. So yeah they're really gung-ho. It's exciting to have them on board as well as part of the team. Joseph also, he joined us this time. He actually looked at the NIST ACVP tests, so those are the standard ones NIST are doing and generated artifacts that, or put"
  },
  {
    "startTime": "01:28:01",
    "text": "them into a form that we can use as possible so that those are the standard ones NIST are doing and generated artifacts that will put them into a form that we can use as part of the project. So now everyone can test against the NIST implementation as well, which is exciting And we had some other new members, Lucas and Conn and Sean and Nick, and they're getting more familiar. There's test against, you know, the NIST implementation as well, which is exciting. And we had some other new members, Lucas and Connor and Sean and Nick, and they're getting more familiar with it and we'll be submitting artifacts in the future as well so those are the major things this is just we still maintain the interoperability OA mapping table there's lots of algorithms there but if you want to do peak interoperability testing and you need oids come use our table, then you'll be interoperable with other people There's quite a lot of them. We have composites as well and all the standard list algorithms this is a sample of our compatibility matrix It's actually being updated, probably being worked on as I speak by members. We have quite a few people that were remote as well. As you can see, we've had a lot of teams members. This is our sixth one. So a lot of new first timers this time. There's just a snapshot I took. We're at Table G on the gathered you can see there's a lot of people involved so yeah, so that's exciting. Our next, we have monthly meetings. Our next meeting is August the 6th. So if you want to join us, you're welcome to come. We've had interim hackathon as well. Sometimes we take a Saturday and work on that. So maybe we'll have one in September And yeah, the NIST algorithms are coming and we have a GitHub repository and yeah, join us. So thank you Thank you. It's nice to see your continued effort working on this Right you're here after dkg we have scrappy the Scrappy presentation there you go Thanks is a very short presentation Just wanted to give a heads up that if you ever used over"
  },
  {
    "startTime": "01:30:01",
    "text": "PGP, you're probably run into some challenges with some of the comments interfaces for dealing with it. This is just a little bit of implementation work towards making it easier to use open PGP, in particular to verify Open PGP signatures which you're likely to do if you're doing something like installing for your software operating system I have to click this button Look at me button clicking. So there's a drag here that it specifies a standardized interface for interacting with OpenP PGP, which lets you do things like this SOP is just the state list open PGP interface And you can do generate keys, extract certs, sign, verify, all very simple straightforward command line options. We have multiple implement of this so you don't need to use fancy, weird obscure commands, like the way that the user bin PGP used to be There is a subset of this which is just verification only It's useful specifically for things like installers And the only sub commands it has are version verified and inline verify. And the semantics are it's succeeds if at least one signature is valid which is the semantics that you want in almost every time And so you may know the GPGV implementation, which does OpenPGP verification. It is not as straightforward. It doesn't match the expected semantics It has some weird quirks about how it deals with the file system. And so a little bit of work that I got done during the hackathon was to publish a wrapper that transforms GPGV into SOPV. So you can have a simple standards compliant variable mechanism. And so still to do is pushing that out into the broader ecosystem so we can replace GPGV implementations with a standardized interface And I think that is my last slide. If folks are interested in this kind of work, please come let me know this SOP implementation"
  },
  {
    "startTime": "01:32:01",
    "text": "is the basis for the OpenPGV working groups Interoperability Test Suite. That's the Sequoia project is done with a great detail view about what kinds of things are functional in it interoperable in about over half a dozen implementation So come check it out Thank you Up next, Scrappy and I think after that is the VECON Let's see Yeah, the other one is next here I think after that is the VECON, let's see, yeah, the other one is next hereafter is the VECF, 120 Yes, both. Just one. Okay Thank you. Okay thank you. Okay. Hi, my name is Thomas I'm here to talk about the hack we did during his hackathon called Scrappy Vcons So basically what we tried to do here, was two things. This is the what are we doing and why are we doing it slide The why are we doing it is humans have the right to know how their data was processed, especially when there are robots involved. And the other is, what do we mean? So this is a quick, quick diagram of two people in a commercial setting, having recorded conversation, then using a VCON to manage the personal information in its lifecycle, the consent, and the complaint But we also added on on top of that, the work this being done by the SCIT team, which is the supply chain integrity, transparency, and trust, so they can provide an indelible record of how that conversation is processed for the regulators and auditors and for the benefit of the customer customer So this is the basic idea. B-Con is that the group that I work with mostly as a virtual conversation container Skit is the supply chain guys across the street, and Scrappy is what we decided to implement"
  },
  {
    "startTime": "01:34:01",
    "text": "which is the SCIT-REST API And so the question we're going to ask is, do they go well together? We're both sort of new standards. Can we work? Is it peanut butter and jelly, wasabi and soy, or is it peanuts and gum? So we just decided to implement that protocol and audit every V-Con transformation in place it onto the ledger so that we can implement a self- and write to no service okay so here this in picture form. So we have a conserver which is a for open framework to manage becons they pass them back and forth. Every time it's passed, it's a transparency service. We use Scrappy to update that ledger. So at the end of the day for that VCon, you can point to that list on the right and say this is exactly what happened to you data authoritatively The what is, and the far end is a schema of how we manage that that log What was, what happened, who did it and was to be verification that it actually happened so what we ended up doing though is a little bit more Big Brotherish. We took a scale link, a skit container, he ran all of our beacon links inside of it so that we didn't have to trust what that link was doing inside. So instead of having to rely on the vendors to tell us what they were doing with the information, we actually knew it because we hadn't surrounded And it was very easy to implement. So that worked up pretty well too. OK, so something that we learned, like what's in a hash so one of the things we learned is you might not want to put a beacon on the ledger because once it's there, it ain't going away which is almost always the wrong thing Never say never, but it's pretty close But also, we also understood that as Vcons get turned it's there, it ain't going away, which is almost always the wrong thing. Never say never, but it's pretty close. But also, we also understood that as Vcons get transferred and processed in the network the shah, the hash of the payload, ends up being a very nice version-ish thing a la Git And so there are times and places where you don't have the same version as someone else does"
  },
  {
    "startTime": "01:36:01",
    "text": "But if you start keeping the operation and the hashes, before and after, you can find out if you have an out-a-date beacon and ask for the next one back. That worked out very, very well So, so the final one was we also implemented the right to know right to erase portal that we do. So if you have a bunch of becons, and you want to know if your stuff is in it you can go get it and ask for it to be corrected or erased, as is your right and so as we implemented this which is the last thing we did in Australia, we added on to the the access history that was read directly off the skit log Of course, that's a subject is a fake ID. You wouldn't give the real ID And so there's a bunch of stuff we have to get to, but by and large, we learned that it was actually very awesome. It's very native to our approach. The identifiers work very well One of the things that actually slowed us down was how well it worked together so it wasn't clear how we should put them together because there's so many different options of how to do it. But that was really, I think, a statement towards the wideness of the use cases we could apply them to so after we really figured out how we don't want to do it, it went like a lightning bolt And the whole idea that we had a V-Con redaction should hold up really nicely because, you know, one of the things that we thought about in the VCon spec, was how my V-Con came to be from someone else before us, but we didn't track how many times that V-C was redacted for other reasons. When you add skit, you can have both sides and track everywhere you do need to go. So finally, I want to thank a bunch of first timers this time. So we've been talking about this hack for about three months and really trying to understand it together has been a great experience for our team. So Sergey Gordon and Pabond and I did this all in real time in the last 24 hours, which was fun It felt like very young. And Josh and Benji, two new friends who helped us as well. So thank you for much for your help. And then the retreads, the people who"
  },
  {
    "startTime": "01:38:02",
    "text": "have been here before, have been here a lot, myself jon geater, steve lasker, and corey bonnell, thank you for all your help too you. Thank you very much All right, so next up is let's see, uh, It's good Oh, VECON, yeah, I do have slides, but it's very basic So what's I only have this version version This, so it's a template not real slides try yeah yeah Okay, um I would like to invite Skid. Yeah, there you go Thank you And now confirm double check. Yeah, that looks good I have many slides. It's fine. Five minutes Well, I'm lenient, yeah, five minutes. Great Okay So, great tea up from, from Thomas there. For, uh, we're doing. So, um, you don't know who skit are, come along on Thursday at 1 o'clock or come to the hack demo happy hour for details But we were trying to do lots and lots of things We're trying to get our architecture in shape. We've been super close to publishing for ages, and we want to get those last nits out wanted to make sure that the scrappy actually implements the architecture that we are planning But most of all, we wanted to prove it. So"
  },
  {
    "startTime": "01:40:01",
    "text": "you've seen the great Vcons present already, which is very gratifying. And we wanted to make sure that all these clever things we've come up with actually work in practice with real code, with people who don't spend all of them lives thinking about this stuff So, here's the team. We always like to have a visual team slide. This isn't everybody, of course, AJ's at home, but her been contributing. I think we're missing Hank from this. Yeah, Hank, somebody else. But as always, a great set of people, including Corey on this slide and Thomas and his team implementing stuff. So what we got done, 20 25-ish, it turned out to be 22, PRs end-to-end client code for skid issuance, use case application engineering that I'll go through, and the very exciting VECON's thing that also got done. And what we learned, we also learned lots from doing lots. We have one huge outstanding question on Scrappy which I think has become very clear so again, come along on Thursday if you want to know the details but how we connect low-level cryptographic principles to lots and lots of broad use cases need some small but clever glue and we did did some good things there roles and definitions jared mauch clearer. We did have one thing where we had bugs for bug compatibility on incorrectly encoding codes so that's an interesting thing But well, how it works. And ultimately, what we found is it is absolutely possible for regular ordinary people who write regular, ordinary code to use skit for their sort of software supply chain, data supply chain, and provisioning. So 22 PRs this is already out of date is that actually 15 now approved so that's that's And you can go to GitHub to see those scrappy issues all basically came down to the same thing, which is if I've got some data in my hand, how do I verify it? So instead of doing a big review of the document, I just wrote"
  },
  {
    "startTime": "01:42:01",
    "text": "a bunch of code and have demonstrated that you can do all of these things this is a standard skit picture of I take an artifact, I turn it into a stage just wrote a bunch of code and have demonstrated that you can do all of these things. This is a standard skip picture of I take an artifact, I turn it into a statement, I sign that statement, I get it stamped by transparency service and then I have a receipt so everybody can globally verify it forever. That's not interesting. That's old. What is it? interesting is that we're able to do this in a GitHub action so it fits regular production workflows We've got interoperability in time between Picosian go GoCozy and in different implementations between the two. So you can have local signing, you can have remote sign with DigiCert, or you can have regular PGP, don't PGP cell OpenSSL and everything works. Use case application is very cool so everybody's aware of what happened on July 19 the hackers particularly are and are trying to exploit this by sending people bad updates for their crowd strike and Windows machines So basic question is, if I'm getting it up update to fix my Windows machine, how do I know this thing on this USB stick is the right thing? And you can do that with Skip. That's the kind of thing that we aim to do and already kind of proven it Go back here. He doesn't claim to have actually proven it but he's kind of proven it that the structures we have and the way that you use skit and skit Scrappy, very similar to the VECON's example, could solve this problem, could make it much clearer and less stressful for people to manage their software supply chain in an emergency situation. So there you go. Tons of stuff done. Always love the hackathon. We always make a lot of programs And yeah, again, come along tomorrow for the demo. Happy hour Thank you very much much thank you very much much"
  },
  {
    "startTime": "01:44:01",
    "text": "So I have another presentation well, it's in me takeout, I think we already had the implementation on implementation augmented by addition into yang, I guess, so just the third copy I have um apologies for this uh next one is quick for deep space. And then thereafter I have interface into network function so then thereafter, I have interface into network functions. So, okay, there you go Thank you Okay Space? No, it doesn't put it Yeah, its focus is lost somewhere. Okay Deep space has very large and very variable art Okay. Deep space has very large and very variable RTT, Earth to Mars up to 40 minutes We have been looking at using Quick with proper transport configuration We did it with Quinn, matthew quick Stack Quinn The good thing about Quinn was that it exposes all the necessary transport power engines we needed for our simulations and, you know, seems to be working pretty well However, not a really quick stack expose the these transport the config parameters in their EPI. So the goal of the Akaton was simple to modify matthew quick stack some quick stacks, depending on the participants knowledge of languages and stuff to expose those parameters and then do interrupt testing between them So we were able to modify"
  },
  {
    "startTime": "01:46:01",
    "text": "Nico and IAO Quick, Nico is in Rust I.O.Q. is in Python. We started Cloudflare but we haven't finished yet We did actually some interrupt testing as at the time of writing, it was the slide deck. It was not done, but we actually successfully interrupt testing with IOC Quick and Quinn And thanks for the participants Yatagai Sam, Robin Miller, Mueller, Laurent Tutin, and myself And we have a few interested more in that generic time of deep space IP, we have a sidemate meeting on Wednesday morning, 8 at Tennyson thank you Thank you very much much so excellent thank you Yes. This one? Yeah. Is your presentation? Next, okay Hello, this is John Paul John. Today I will sort of introduce our Hekassen project, Interface to Innetwork Functions, I2i I2-I-N-F project. This is my graduate student collaboration work So this is the point for this project Basically, the goal of this project is to demonstrate the feasibility of the framework and its interface interfaces It is called the I-2-NF, I-2-NF stand interface to in-net functions like CoinRG they developed the"
  },
  {
    "startTime": "01:48:01",
    "text": "in-net computing device like people switch and NFV-PELA detector Also, we can unconsider a buyer security solutions So this work is based on this ops a draft So I will present this officer session this work is based on this officer that draft. So I will present this option this time. So basically you can see software defined a vehicle is nowadays very popular. Now there is Autosa and the eclipse SDV and Sopi, many, yeah, the car vendors are working for the automotive cars. So this project is we take advantage of their standardization work, so we try to enable Intel intelligent management for mobile objects like software-defined the vehicle So this time we demonstrate like the it is called is an administrator so right-hand site. So it gives some intent like the upside we have something is the other meter later so right-hand site so it gives some intent like the upside we have a subdivide vehicle one and two so they reported a their monitoring data like the mobile information including speed and that that intent to translate in the specific network policy and the application policy depending on so that the policy is a for the 5G core network like a the nettox licensing something like that and the application on the policy delivered to the SDB and then they are report their speed information to SDB bottom side. We have cloud analyzer. So cloud analyte collected that monitoring data and the analyzed using machine learning. Diagonal"
  },
  {
    "startTime": "01:50:01",
    "text": "system, the car status so this our framework so in the past, so we work for I2NSF for Interpace to NetExCutroph functions. We take advantage for that experience, try to generalize to innate Intendables net talking for mobile object So this architecture you can report to this bottom size, the draft, describe it detail. So what we learn are we implemented I2, INF framework for software to define the vehicle So we're using just emulation but so in future we try to use a robot car using a robot OS loss version 2 and we can demonstrate maybe a next haphason. So also we demonstrated intent-based networking, the simple translation for computation and monitoring for SDV So this is the snapshot for our I2-NF framework So we shared the open source, you can access this project. Also, we uploaded video clip. You can, okay, you can see open source. You can access this project. Also, we upload the video clip. You can see the video demonstration. So next time so IETF 12 so we will design and develop intent to translate for this framework for Intender-based networking IBM, also we can design a young data model for our work So this is our team. So the professors and the student, we collaborated for this weekend. Thank you Thank you very much So now we come to the last presentation last presentation of econ so we update it See if I can find it now"
  },
  {
    "startTime": "01:52:01",
    "text": "Yeah, I have an next review I think this one is correct Content? I have content, yeah OK, please go ahead Thanks. My name is DMP daniel petrie. And this is our seventh hackthon for recon. It's kind of cool So actually, just a quick overview you know, for anybody who may not know what V-Con is B-Con is a container, standard container for your conversational data and you know your cover conversation may be an email thread, SMS exchange phone call, video conference, or any combination thereof right these are conversations and there's metadata you know, what, when, where, why, how, etc cetera, that is part of the conversation in addition to ancillary documents like a slide deck or a presentation or an NDA or a contract or something it's relevant to the conversation. And then we take that a little bit further and include, and can slide deck or a presentation or an NDA or a contract or something. It's relevant to the conversation. And then we take that a little bit further and can also include post-conversational and analysis, so a transcript, a translation summary, notes, sent to analysis, action items you know, anything you might want to harvest out of, you know, some machine learning or AI analysis of the conversation data. And the reason we're doing this, is to ease integration You know, we've got contact centers where you've got the deal with all these different modes of conversation of that are that are that are occurring you want to be able to capture those in an abstract way that you can look at this across the board and do analysis in is be able to capture those in an abstract way that you can, you know, look at this, you know, across the board and do analysis in, on the, on your conversations that are happening with your customers or other"
  },
  {
    "startTime": "01:54:01",
    "text": "contexts as well. But so at this hackathon, we focus on a couple things here we uh um in in the last draft i added uh a cdd well. But so at this hackathon, we focused on a couple things here. wen lin the last draft, I added a CDDL schema spec to generalize from JSON format to Jason and being able to support Seabor And so I wanted to explore that in code and then the other thing, another portion of the V-Kind that I haven't explored a lot in their prior implementation efforts is the redaction object And so we wanted to explore that a little bit more and test it out to see that you know you know you know theory and actually give it a try try So here's what we get done We got actually, yeah we were able to generate seabor V-Con for the first time, I don't know anybody else who's got a seabor version of the V-Con And as well as Jason, which we've been doing in the past and able to convert back and forth between seabor and and the Vcon, and as well as Jason, which we've been doing in the past, and able to convert back and forth between Seabor and Jason Vcons We was able to do some tweaking of the CDDL but I'll come back to the CDL in a minute In exploring the redaction object, it it kind of discovered that it made an interesting thing to also consider as part of the VCon effort is to maybe define a media type for redaction labeling So taking the transcription, you know, you know"
  },
  {
    "startTime": "01:56:01",
    "text": "part of that transcription that you want to redact for various reasons and such as personal identifiable information and things like that and but they have a you know a media type to be able to identify what's going to be redacted is interesting because you have many different parts of the economy you may need to redact and so having that labeling makes it easier you know you think if you got audio video and text, you need to be able to redact all those parts or whatever. And then we're able to do a little validation of the redaction object, but we didn't quite finish with more work to do there What we learned, CD tools out there are immature. We had some problems actually trying to use their CDDL CDDL, you know, pieces of it a time we could, you know, use and value but yet to be able to be able to constructs and so even with some simplification of the CDDL, I still having difficulty. We have a few things that we have to sort out on the becon side with seabor tag 21 and t-date, nothing wrong with the seabor side of things it's or the cddl with the respect those two, it's more we have some sorting and thinking to do on that And the as I mentioned earlier the redaction labeling, there may be an interesting media type for us to consider to standardize it And we'll just hear who on it and some links to our code Of course, the hackathon stuff's not"
  },
  {
    "startTime": "01:58:01",
    "text": "there yet. They'll be there soon. Okay, thank you very much. Thank you So thank you all all Just to check, did everyone present their results? everyone that uploaded the presentation? Yeah, I didn't miss someone. Okay, excellent. So first of all, I would like to thank you all with a great hackathon evening And in particular, I would like to thank the presenters to keep very nice in time make my life easy, so I don't have to interrupt someone I would also like to point out that right Monday tomorrow we have the Hackdom Happy Hour So you can present your results to the broader IETF community It's between 6.30, 7.30 in the residency hallway over there. You can resist for the hacker sorry hack demo happy hour on the hack on the wiki, the hackathon wiki So you can find it somewhere in the menu you can click and there you can register that you want to have a table and one present your results So everybody's invited, it's fun to present your work, have discussions with other people maybe other people here in the room, but certainly also the people that didn't were able to attend the hackathon And there's also nice social interaction. So tomorrow Before I close there's the code lounge well this now a shared workspace so just for information, you can register, you will be there working on your project through the week. That's the Brighton Constable Room. And finally, before I close, I want to thank our"
  },
  {
    "startTime": "02:00:01",
    "text": "running code sponsors. This Erickson our gold sponsor, and the bronze sponsors, C and Nick and Ican. They made the weekend available possible. They provided food, drinks so a big thanks for our sponsors Thank you. See you this week around. I think the Datatracker pilot was quite successful. I'm not sure Barry has a headache of managing everything But if you find some improvements for the workflow, please drop an email to the hackathon chair how we can improve the Datatracker flow and see you around this week bye bye I don't know you Thank you Thank you Thank you"
  },
  {
    "startTime": "02:02:01",
    "text": "Thank you Thank you Thank you. I'm going to be able to get it Thank you Thank you Thank you See what I've gone to know"
  }
]
