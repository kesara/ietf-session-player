[
  {
    "startTime": "00:00:35",
    "text": "all right was there a complaint about the slides from the gallery the acronym for the working group or the short name has abyss event the name of the working group is officially the HTTP working group and that\u0027s because after we finished this I asked the area director at the time he was also the Curan area director but yeah this if we could change the name he said no it\u0027s too much trouble so we changed the name but not the acronym hello welcome to Monday session one of HTTP or the HP working group if you prefer we have a pretty full agenda today mostly made of both talking about our active and adopted drafts including a couple that are new on our plate since the last time we met okay and we\u0027re just about ready to go we\u0027re also going to talk about prioritization a little later on so we\u0027ll have a chance to agenda fashion you and mark puts up the agenda salon and the blue sheets have been started to be passed around already which is great we\u0027ve also established the scribes and minute takers so thank you for your volunteerism to the IETF up on the screen now is the note well the note well governs your contributions to the IETF and the intellectual property they\u0027re on if you have questions about the note well come chat with us or even better our ad next slide like I say more huh oh it\u0027s a check check and check thank you again everyone and here is our agenda and you can see the list of active extensive drafts on the official agenda would anyone like to make changes thereupon going once going twice sold all right so we\u0027ll kick it off the first draft we\u0027re going to talk about it has been actually adopted since the last time we met together and I think believe Lucas is going to do the update and presentation on it thanks Lucas hello so this patrick said this was recently adopted thank you everyone for your implicit support what is this thing this is called resource digests but it\u0027s about refreshing at nigh on twenty-year-old RFC which is 30 to 30 so we\u0027ve gone to the next slide as you see this is 2002 done by Mogul and it tried to fix a problem at the time and the draft goes into a lot of discussive texts about what that problem was it was even update in 2010 by that RFC to just add algorithm so on the next slide or two I\u0027ll explain this but not going there yet it had this this terminology around instances and entities I don\u0027t want to get into that if you care go and read it or read the update because it "
  },
  {
    "startTime": "00:03:36",
    "text": "makes it a lot clearer because it doesn\u0027t actually need to define it because in the meantime HP beers has updated things to clarify and the problem is that now those terms have inconsistencies with text that people are more familiar with using and a building upon today to build new capabilities and functionality and so when they come to maybe try to use this digest header it can be confusing and problematic and so Roberto Polly and I have been trying to basically cut away the chaff get down to the core of what this thing is because in practice it\u0027s actually quite simple and this few edge cases that jump out so we try to improve upon them in simple terms the dye dress is just a hash over a representation all payload body so you\u0027ve gone to the next slide as an example you\u0027d make a request for a thing get a response back and in this case it\u0027s HelloWorld we have a sha-256 hash of that body so that I just had a is had a field is composed of the algorithm that you\u0027re using to calculate the hash and then the hash itself the format of that hash can vary could be basics t4 or some other thing that definition is basically tied to the algorithm name and title and so the list of algorithms held in Ayana is what\u0027s listed on the right hand side there and I\u0027ve gone to the next slide I\u0027ll come on to that in a second but what this what\u0027s the new digest thing it\u0027s it\u0027s minimum as I said trying to tease the same semantics as RFC 7230 terminology rather than entity and this width and we use representation rather than instance we selected representation data I don\u0027t really want to get into that what those things mean but maybe if people need clarifying horrifying at the end we can do that but those edge cases I mentioned around when you\u0027re doing different range requests or content encodings now if I returns something hash is the hash over the identity encoding or is it these broccoli that I\u0027ve used for that transfer some of the things that have happened in the meantime in the 20 years of security considerations for things around signatures so digest is you quite often to protect the payload of a response and signature head is easy to protect the metadata and the digest these are the metadata included in it and so you can create a better value proposition by doing those things but there\u0027s those considerations so we\u0027ve come to the next word algorithms the security landscapes changed in the last 20 years so things that were defined in that header like char one an md5 a now not recommended and "
  },
  {
    "startTime": "00:06:36",
    "text": "like who said we we added these things called identity or content encoding independent algorithms so it can be a bit confusing sometimes if you get a digest back to understand exactly which content encoding was used to create it and the draft goes into more detail about those again it\u0027s quite simple yes next slide please there\u0027s a bunch of open issues that need input if anyone cares to add anything they are presented here in order of kind of divisive nurse they\u0027re not urgent but some of them are harder to debate than others and you can see if look at the bottom you know do we need a threat model maybe one for citing char is difficult to say but really it was got mentioned chopped down used with a few signatures do we want to get into how to use this thing personally I\u0027d like to focus on making a message clearer for what this header is and that any guidance on how to use it should probably live elsewhere but I\u0027d really like opinion on that how to use this thing with patch requests for instance filling weird gaps that exist in the current document in the right way so if anyone cares please go on to to get up I don\u0027t think we need to go through them one by one now just for times sake that\u0027s like this is roberto\u0027s so yeah he wants to call us the Akshay vers thanks Roberta yeah thanks you time thanks for doctoring this document and I hope that it\u0027s something that it\u0027s straightforward to get done and that can improve the ecosystem and we do have time to do I enjoy a couple of those issues from the floor people have particular things they want to bring up that\u0027s fine or gentleman Thompson I like this I like the fact that someone\u0027s finally doing this few minor comments I\u0027ll probably raises issues we already have a hash functions registry elsewhere in Ayana and I\u0027d rather not make another one do you talk a little bit about how this interacts with content coatings have you resolved that one more or less I think the question might be is the new identity digests algorithm value of use to people I suspect it is yeah anyway so it\u0027s a one comment has been how much does this ad that\u0027s new and my response would be it doesn\u0027t add anything new new algorithms help purify the usage of this header yes so the other thing to think about here is the relationship with s RI and getting that clarified would be kind of interesting I don\u0027t know whether it\u0027s our responsibility or someone else\u0027s but it\u0027s worth thinking about I don\u0027t know what whether you want me to open the "
  },
  {
    "startTime": "00:09:36",
    "text": "issue on that one or not yeah I don\u0027t know of I\u0027m not aware of any existing problem statement so that so if there is one or you have one you can build own appreciate the question that I would ask there it is if I have an S are I on the link and I follow that link and I also had a digest header field on that response would I expect the Charter 56 value to be the same on the s RI and the the day just had a field and if you can say yes that would be really nice and you could say as much that would be even nicer good to keep recognized Roberto because I have a feeling he wants to respond to that so not sorry not this I know okay well we\u0027ll figure that out Roberto in the room Roberto pay own good to have another uh Verito around by the way hello question um we talked about binary or structured headers in the past and this intersects here because the header name and how it is encoded are the same if we are talking about actual having binary representations where you don\u0027t have to worry about an encoding of the hash itself it would make a lot of sense to make sure that the hash name there is well known I\u0027m sure you can call it binary or something like that but it\u0027s interesting to think about the case where there is no encoding because it\u0027s just the raw bits okay thank you I was going to suggest that the essence sorry this is Jeffrey askin I was going to suggest that the ESRI question should probably live in the w3c as a way of using the header that is defined here and Roberto you might just have to be channeled through brother Jabbar from Roy fielding on jabber plus one to draft IETF HTTP this digest header zero zero but it might be nice to have a little more discussion in the draft well why the authors think these fields will be useful in the future what fields exactly the that I just had to field it\u0027s helpful is really asking for use cases all folks Martin to let Roy respond in time I look at this we have Roy in line so how about we do the line thing and then I\u0027ll open a "
  },
  {
    "startTime": "00:12:37",
    "text": "new topic can someone in Debra tell me to go that a red button is broken and we\u0027re sad oh no shall I continue then someone has already done that the the media code gods have been summoned one of one of the questions that I had and this relates to a similar sort of discussion we had about content coding a little while ago is what are the principles that we use to drive the process of defining new digest schemes obviously there\u0027s a couple in here some of them quite simple we have some schemes that are increasingly complex and some of them are parameterised in interesting ways and it\u0027s not clear from the current system how we\u0027re supposed to encode that sort of information so for instance if you look at the proposal that Jeffrey and I have been working on for sort of a progressive digest system it\u0027s the my struct there are parameters that dictate the size of the blocks that are used and those parameters dictate the how the value is calculated so therefore you need to know them when you calculate the value and so there\u0027s a really interesting relationship between the content coding which at the moment also includes those values and the digests themselves and there\u0027s a discussion on one of the issues that I thought might be worth discussing yeah mm-hmm doesn\u0027t anyone have opinions on that one my opinion would be a single block of octet for the value of any single digest but that\u0027s that\u0027s my initial put your what you were saying makes me think that we need to think about that more carefully because it\u0027s not only content and coding you know you have identity ones for example but also we have things like partial content versus full content and other dimensions and and how is that going to stack up so that\u0027s slightly different what I was talking about and yes I agree we need to talk about that one as well if you\u0027re talking about your progressive yeah this is talking about the progress mano and to provide context there the there\u0027s a block size at the start of the stream that then determines where the progressive hashes appear the interleaved into the end of the stream and you need to know that block size in order to render the content and I think it was Roberto who mentioned that and not this Roberto the other Roberto who mentioned that when you remove that content coding and just save the file to a disc you might still want to be able "
  },
  {
    "startTime": "00:15:37",
    "text": "to go back and take that hash and prove that it still applies but you just lost the emitter information that was encoded into that strings in alternative representation even processed that information possibly be replicated in in the hash value or put alongside it and we need to decide how to do that I mean the digest header allows parameters to be expressed it\u0027s just done in such a way that they it\u0027s not an obvious yeah like that\u0027s that\u0027s kind of the gap there and I Roberto ponder that out to me that you have some of this capability already but it\u0027s it\u0027s pretty badly expressed and I think that in a lot of cases we will have implementations that build these strings with the assumption that it is just a single sequence of bits and when they do need to get parameterised you will find that it\u0027s a problem because you can\u0027t get the extra meta information there\u0027s nobody built it that way all right we\u0027re gonna have to move on what are we gonna give Roberto as cause here one more chance to see if the button works yes Roberto you are on the air hi yes I want to because now to become champion because while solving this issue g4 they digest rather we could provide so migraines and majority for both mice and other specification that builds on digest that\u0027s it thank you so much and thank you to both of you for taking on this contribution and working to make up Chris thanks for listening see you bye oh well if your question I\u0027m here to reply sure and for making a crisp issues list that really helps you know thank you yep alright next fuck um it\u0027s gonna be about another draft that\u0027s pretty new for us since I believe we adapt to that "
  },
  {
    "startTime": "00:18:37",
    "text": "since we met in Prague using just 1.3 with H to David Benjamin\u0027s been doing that work David yeah there is come on come on up front so everyone can see you okay so apparently I missed the memo they were supposed to talk about this but yeah there\u0027s a draft there\u0027s a slight that there\u0027s like one ambiguity with telus one three HTTP - and like key update versus renegotiation verse handshakes certs there\u0027s like one important sentence in this draft plus a bunch of filler text I think it\u0027s hopefully fairly straightforward so that has actually been the feedback during adoption and I\u0027m I think what we wanted to use this meeting time for or see if there were any other issues that need to be opened here because I think this is great and if you know if there aren\u0027t maybe we should talk about working group last call Martin are you gonna ruin that dream Martin Thompson working group last call please I don\u0027t want this to last any longer than the three seconds that David just please sit down so barring further further feedback I think you\u0027ll see it work all open you know at the end of this week thanks thank you David yeah that might be set in a record but don\u0027t count him before they\u0027re published more practice Dallas next one hey my name is Jude Sakura I\u0027m going to talk about the proxy status header that marketing and I myself put together and present it at the last ATF that\u0027s right as a quick reminder proxy status is a header that contains detailed information about why particular requests fight or succeeded in a journey through various intermediaries Citians reverse proxies and whatnot this is not a new concept it\u0027s in dawn many times we just trying to standardize it so what changed since last night EF first of all that there are four sub those that by the working group so thank you for that we\u0027ve also made some editorial changes and aligned no identifiers with the cash Draft there are two open issues we have time so so I can go through them quickly first of the issues is about adding detailed status types for HTTP requests errors so right now we have about dozen of types for response errors but we have only one for request errors it\u0027s called HTTP request error and we piggyback on the status codes to convey the information about why the particular request failed and this is kind of "
  },
  {
    "startTime": "00:21:38",
    "text": "unfortunate because a the header is not self contained so recipe need to look at both the proxy status type and the HTTP response code to figure out why the request failed it must also means that we are kind of constrained by existing HTTP status codes in you know the errors we can represent and it\u0027s much harder to extend this in the future the internal feedback I got because of those issues is that you would basically put the details in free forum details parameter but since it\u0027s freeform we wouldn\u0027t really be standardizing anything so that\u0027s kind of unfortunate the only downside of this issue this suggestion is that we would basically be duplicating information and some of the common status errors for existing status codes but I don\u0027t think that\u0027s too much of a big deal I kind of do we\u0027ve been talking back a huge source of disagreement between information from the working group I think would help alessandro godina CloudFlare I don\u0027t really have information just a question does this mean that any new status codes would need to define a new proxy status no absolutely actually the opposite so if we keep the current design and you have a status field on it it just or sorry in the curt design a new status code doesn\u0027t require any changes to this it just means that you know so if it\u0027s a 411 length required all that the presence of the proxy status field means is that this was generated by a proxy not by the ordered server behind them and as a reminder in this draft we use proxy somewhat generously to mean forward proxy or reverse proxy Gateway you know any kind of intermediary node right but like there you have the the length required explanation and then the proxy status right which kind of the pins in the second proposal where we have a specific proxy status type for each a kind of Clyde error you know if we had a new error status code defined yeah we would have to define one of these yeah um yeah so I kind of prefer the first one but I\u0027m fine either way yeah or the contrary like if we want to add new status type we would also need to make a draft that adds new status code right whereas this is easier if we can extend it or we have to come up with a way to either refine the semantics of an existing one or define a new proxy status and lump it onto an existing status code yeah yeah so like 400 or 500 probably is that the generic ones yeah any more opinions okay next the second "
  },
  {
    "startTime": "00:24:46",
    "text": "issue is about handling of forwarded responses is actually mistake on the slides it should be forwarded not done ever so right now all the status types we have are generated by the proxy itself the only exception when that\u0027s not true is the HTTP response status which basically means that the response was for that that for from the next hop as is without any modifications marketing\u0027s it\u0027s kind of confusing and the suggestion here was to add new informational proxy info header that would carry the information about each node so we would still retain the ability to do HTTP try sorting and stuff like that and keep proxy status only for the response is generated by the intermediaries and so the idea here is is that when you see a proxy status header field on a response you know that the status code that the actual response was generated by an intermediary if we have this split where as proxy info would be information to added incrementally to the response you know whatever information you know opportunistic information about the connection that we might use for debugging or whatever without having that response generated on the actual proxy node Chris Cummins from Comcast so under the previous proposal it was possible for if I understood correctly for multiple proxies in the chain to have generated responses right and there could theoretically be you know one of the proxies could be returning a cached error and then another proxy could be saying well I got an error from upstream and so I generated dis response codes it was that actually impossible because it was possible to express I don\u0027t think you\u0027d see it practically speaking now okay except for that the well except for this HTTP response status one that\u0027s the other now yeah there\u0027s a lot but I think you could still see it for in case of different configurations like if you get to be response from one or the other unlike one of the low proxies closer to downstream but I think all the currentindex we have none of them would be taken from cache from question from it was very possible but I\u0027m not sure if it was practical yeah been a little bit since I\u0027ve read the draft but could you wind up with a situation where somebody marked something as stale and so you have a sinking of that\u0027s that\u0027s a different header different draft distinct deposits yes and so yeah then "
  },
  {
    "startTime": "00:27:47",
    "text": "this is you know a larger discussion of we\u0027re decomposing these different mechanisms and making sure that they\u0027re well aligned you know this is about really just intermediary nodes and their behaviors whereas that draft is about caches which can be intermediaries but they can also be in other places my fielding okay can you hear me now yep okay the just in general I know their people are very fond of these very long names in in header fields I hate them particularly when they\u0027re repeating something that\u0027s a 3-2 degree code and the HTTP response already so how about in the key in the cases where the proxy status is just indicating that the proxy is sending this code just use the three-digit code instead of HTTP correspond table so I think the proxy if we do this split so that\u0027s that\u0027s a different issue really but if we do this split then the proxy status header field will only occur in error responses which are relatively rare so while I generally agree with your sense there it\u0027s not like and it\u0027s gonna be in every message having said that I\u0027m happy to have a discussion or an issue and talk about making these these things a little bit smaller where it\u0027s appropriate yeah part of it was that I I think that at this point the scales are more meaningful than the things that are written out in English keeping in mind that you know not everyone\u0027s in English reader so HTTP response status is an unusual one and I think we\u0027re discussing how it\u0027s unusual right now the other ones are more descriptive if you can make me do that previous slide I think it was a good example hey the second thing and so basically the main target of this header is responses from the origins right and right now basically the only solution we have in HTTP what is 502 but gateway or five or top four gateway timeout right we here have defined at least twenty or more status types that describe in more detail why this happened right and this is something that other companies not all but like a lot of companies especially CD ends within the paths of the risk really need for that I don\u0027t believe that existing response codes who made this information and in particular they\u0027re sometimes pressure to admin status codes or people you know grab their own status codes to tariff on these semantics and so this is really kind of refining the semantics in a header and trying to standardize that "
  },
  {
    "startTime": "00:30:47",
    "text": "find call Verizon media so we do this in patchy traffic server we have something like this but we do it via do it via header and in there we encode every host and then we basically have all the status codes of you know what happened if it\u0027s Ram cache yet if it was disk cache yet we\u0027d have all the you know when we encode all that stuff is like error codes and everything and one thing about bad is having them for each hop is you know you have this hostname and you have all of the status codes for each one of them instead of this you\u0027re gonna have to like parse it out and buy multiple headers and figure out exactly what the status codes for each one of those are so so it seems like you would want couldn\u0027t you add this to like four did or something like that and then you have all of the protocol information and you have all of the for did is a request 10 ago yes yeah but he\u0027s using the via in the response right yeah so that\u0027s a much larger discussion which we\u0027ve got the cash header would you have intended to have the cash state yeah proxy info is basically the intermediary state yes and this is proxy status if we accept this proposal is just for a proxy generated error page effectively yep so that\u0027s that\u0027s the current breakdown so if I understand correctly you have more of the first example here right so what you currently use something that\u0027s more similar to the current draft which gives details about each hop crank the details body talk I\u0027ve used that scheme and perhaps because it was undocumented for so long I found it difficult quit it actually actually works pretty well except for decoding that stream yes that we have actually a special program that takes the 20 you can have an extended version of it it was just like 24 characters and then yes you translate it I agree that\u0027s kind of difficult for end-users I mean for experts and stuff like that it\u0027s not as a gil end-users and it may be very difficult but I think something that\u0027s shows you your hops gives you status in each one might be easier to do than to have it\u0027s broken up into multiple headers right yes that\u0027s my opinion we\u0027re gonna have to cut the line after our job right suppose Roy fielding from Jabbar I agree when it\u0027s new information and not an existing code sorry I need a little more context this is but go back about this basically so not to avoid duplication of the same status code so just stick to existing solutions I think yeah so Martin Thompson I\u0027m looking at this proposal here I just skim through the the discussion can you explain to me the relationship between this and buyer and CDN loop and "
  },
  {
    "startTime": "00:33:48",
    "text": "we\u0027re starting to accrue a couple of these things yeah that would be really helpful sure so via is effectively I think in a lot of people\u0027s minds unusable for anything useful and so cash loop starts EDM loop effectively abandoned that for some purposes and probe down to a very specific purpose CD and loop is a request header and it\u0027s targeted just at certain kinds of notes so it\u0027s very separable from this cash is for caches and so a cache would generate it on a response sorry cache what we\u0027re gonna go on down staff yes yes cash status yeah dick that PR this is for intermediaries and as I explained before the breakdown that\u0027s being proposed is to break that between just general intermediary context and intermediary generated errors which are different things because from a CDN standpoint for example you often have to add a little bit of extra context to responses for debugging and that\u0027s a very typical thing to do but an error page often people will write scripts depending upon that you need those scripts to be robust and so separating that information out makes it a little more obvious that this is yes a CDN or reverse proxy or proxy generated error page and treat that as a special case right thanks that makes me think that the second direction that you\u0027re proposing is for at least a proxy status header field a reasonable course to take but I\u0027m a little concerned about sort of submarining in whole new proxy information fields that\u0027s somewhat like via but not not entirely so somewhat what it\u0027s someone like via but not right entirely it\u0027s a sort of well that one didn\u0027t work out so we\u0027re just gonna make another one it\u0027s effectively if I we just make it in here yeah that\u0027s why it has no semantics and no structure it is just a blob sure that\u0027s what you\u0027ve just done here isn\u0027t it no oh that\u0027s the structured header I\u0027m gonna find sources announcing yeah and the Hewitt\u0027s parameters like the forward protocol for example so how we connected to other Piron to next hop and stuff like that so it can be extended other than just the node name so I guess what I\u0027m suggesting is my wheels we do need to move on but as Tommy says it\u0027s only the illusion of progress because we\u0027re gonna move on to the cache we should be response at her she probably continue this discussion three seconds I\u0027m suggesting that you move that concept into a separate document and progress that separately because otherwise this is you mean is a proxy in for separated from proxy scepters I think so I think we let\u0027s talk about it if there becomes a blocker I\u0027m willing to split it off I don\u0027t think it\u0027s going to but one of the reasons to sort of separate header is is "
  },
  {
    "startTime": "00:36:48",
    "text": "that the semantics are a little bit different but very rich on both sides and smashing it all together is gonna make it a really complex header so this place thank you okay next up is the cache header hello computer so this document and we have two open issues I think one very slight one which we refer to briefly before the name of the header I think the proposal is to call it the cache status theater so I don\u0027t care the other issue was a little more interesting Alex Russo cough who if folks don\u0027t know him is from the old squid days said unlist a while back when this first came out if we\u0027re gonna standardize this then you know it\u0027s reasonable to ask whether we want to just effectively pave the cow paths that you know the cash X cash which is why we call it a cash originally because you just take the X off uh started off as in squid and maybe even back in harvest I forget might be something you can answer that and it was created over time in in what arguably is in really non optimal way and so you know the question is do we want to replicate that because everybody\u0027s very comfortable and understands what those things mean including not only implementers but also people who are consuming these things or do we want to refactor it and and start from scratch effectively and make it a little cleaner and a little more obvious but some of the combinations of these things or the corner cases caused a lot of confusion and so personally I am pretty neutral about it I am very comfortable with X cache and I understand it well sorry I think I understand it there are some quarters in there that are probably pretty hairy I took a strawman approach to you know how would we break this thing up into different facets and I put that into the issue and so if people want to take a look at that I want to hear people\u0027s impressions of which way they want to go on this especially from implementers because this thing has to get implemented and if it\u0027s the difference between oh yeah it\u0027s just like X cache therefore I can Street use that code and I don\u0027t yeah I can it support this thing versus here\u0027s a whole new thing and I can\u0027t be bothered implementing these new things that\u0027s important to know and from consumers I want to hear if if which which way you\u0027d want to consume this information on the topic of your first thing from Roy I\u0027d really really really prefer this to be cache status most people seem to agree "
  },
  {
    "startTime": "00:39:48",
    "text": "with Roy yeah I think we\u0027re getting to change that Colin from Congress um so the one comment I was gonna add to the previous discussion as well to this one we currently emit these as part of our server timing headers that we emit because it\u0027s picked up available in JavaScript land and so the semantics are now duplicating and it\u0027s helis context of having a normalized structured data but also having it represented there so one consideration lucky day to see how we can merge some of these or have anacs-- bridge into the HTML spec so we can have access to some of these headers for beaconing purposes so that\u0027s the purpose we use them for is to collect statistical data from the client-side on performance etc sure so we can probably have that conversation maybe with a fetch box for sure the second is do you have a notion of opting in for these additional headers for debug mode flag tisha I think for the time for the scope of this we haven\u0027t discussed this explicitly but my assumption has been that currently it\u0027s it\u0027s a case-by-case basis different CD ends have different approaches to turning on debug mode and they have different threat models for exposing that information likewise different proxy is going to be configured in different ways and so if we try to come up with some sort of negotiation or triggering mechanism for this I think we\u0027d probably raise the chances that this is gonna fail so right now we\u0027re just gonna focus on defining the semantics and the syntax and then if we can later down the road gets agreement about how does one turn on debugging for CD and Celeste reverse proxies hey that\u0027s great but but we don\u0027t have to couple it to defining these Semitic since in taxes my thinking mat stock limelight networks yeah I mean it in regards to implementation I think that unless somebody was really driving us to actually go and refactor this it would be hard to a hard sell to actually go and do it so as much as I like the idea of refactoring making it clean I think in practice it would be tricky to do that actually brings to mind Mike one of my concerns about keeping the current approach is that from what I\u0027ve observed different reverse proxies and forward proxies and CD ends use all the squid ex quit tags but they all mean slightly different things and there\u0027s gonna be a great temptation for everybody just to say okay let\u0027s just take that code and put a new header name on it and you know it\u0027ll diddle the syntax and we\u0027re done and they won\u0027t be done because now we won\u0027t have good interrupts so I\u0027m a little worried about that Chris I\u0027m speaking for myself yeah I was gonna bring up exactly the point that you you just made the the different caches and intermediaries have slightly different "
  },
  {
    "startTime": "00:42:50",
    "text": "interpretations of some of these these words and to me some of the value is defining the words very specifically and concretely with all capital letters and then interrupts then any system that wants to produce these header fields can produce the will read the definitions and produce that and I\u0027m a little bit concerned that if we if we make it look very very close to what is already out there then we\u0027re not going to get good Interop so my current inclination after listening to this is that you know if we\u0027re able to write down a new thing accurately which is maybe a big if or precisely enough that it\u0027s it\u0027s can be held to truly we might get something out there that is it gets more interrupt but gets there more slowly that that it\u0027ll take more effort for implemented to help them better yeah but better yeah and so I\u0027d be inclined to do this actually based on this little discussion do any cash implementers one - of any sort in any device in HTTP what say anything about how likely or unlikely they would be to implement that alessandro godina CloudFlare um so the more complicated one can in the end be implemented by just taking the previous status and then sort of converting it into different splitting it up in different values so I think it\u0027s it\u0027s not it wouldn\u0027t be that hard to implement maybe not directly in say the the web server but they may be in something more high-level that customizes the responses so I think that would be fine they\u0027re only kind of problem I would that is at least for us this information is mostly intended to be consumed by humans so like you do the response you do the request and then you get the header and then you immediately see it\u0027s a hit or a mess so with like a bunch more fields it might be harder for people to interpret the result but other than that it\u0027s I mean I\u0027m fine with the right so maybe try and work out some examples and see how human readable there and tweak based on that I can see that yeah so so I see Brian getting in line don\u0027t nobody\u0027s gonna say but I was gonna say from the Apache traffic server community I think it\u0027s pretty likely "
  },
  {
    "startTime": "00:45:51",
    "text": "somebody will and somebody will implement that I can think of some folks on my teams that have a have a desire for this kind of information repair to pay own so the browser has also had a cache and probing that cache and or requesting things from that cache has been either non-existent or problematic from the point of view of the application for instance there\u0027s this push thing and we have no way of knowing that we got it because of push let\u0027s say that\u0027s a separate issue potentially but maybe not and I think there\u0027s a separate question we should be asking about this is how we should be using HTTP probing the local cache as opposed to a remote cache Brian call patchy traffic server so we looking at all the different status codes you have for cache the only one that we went ahead and expanded on from the squid codes was the refresh Ram so we actually specify if it\u0027s actually from Ram cache which is helpful for us and that would be the only thing that I would add one there okay thanks well Tommy accommodate that in some little extension or detail field or something yeah so expanding on that particular idea from Thomas Peterson is there not room for allowing freeform values here for implementations that can\u0027t fit in any of these fields and speaking for myself I had a very similar question especially around the the RAM and a few other pieces we need a good extensibility story and then we want to drive people towards common values because that\u0027s the whole point but yeah there\u0027s needs to be an escape valve and then that\u0027s the discussion we need to have definitely but I wanted to get the general tie level shape for it together first thanks thanks for the discussion and Mark what do you think the next step is I\u0027m gonna go ahead and refactor it and put a draft out and let\u0027s see if people can you know I\u0027m sure we\u0027ll have discussions about individuals semantics that\u0027s where I think we need to really focus next so on our agenda that takes us to sort of the newest additions to our set of adopted drafts and let\u0027s see if we can keep that energy going into the the folks that have been with us in our little H Vitas family a little longer so we\u0027ll move on to variants yeah variants extra variance is a little more venerable definitely we haven\u0027t made much progress on this because we put a pin in it to wait for implementation experience and I have assurances from my one generous and unnamed potential implementer in the immediate future that he might be able to gets to something soon he or she might be able get something soon but in this and it is also being used by the exchanges proposal for a little bit different "
  },
  {
    "startTime": "00:48:53",
    "text": "purposes but but there\u0027s still an interesting use case there and and what\u0027s nice there\u0027s an also kind of validates that is a framework and so it\u0027s working pretty well because they\u0027re exercising it more than then we are theoretically it struck me the other day that we might make some progress on this draft by generating a little interest in it and by that one of the open issues is to describe how variants might work with cookies and I\u0027ve been holding off on that because I wanted to get the basics right first but if you\u0027re able to make this thing work with cookies it actually opens up a lot of incredibly interesting use cases so my thinking at this particular point is that I might want to couldn\u0027t sketch that I put a new draft out to see if that beats the bushes of people who might want to go and play with it a bit more beyond that I don\u0027t really have anything to report I think in a month or so ago I went through and addressed some of the open issues especially that Jeffrey asked and it opened against it I think there\u0027s still a couple but it\u0027s just iterative stuff it\u0027s not you know stuff that when you discuss here any comments any other thoughts about that and anybody disagree with keeping working on this draft or not working out or anything come on I\u0027m just I\u0027m in favor of it I have actually a working copy working implementation internally for our sir get exchanges so none externally focused but surrogate variants and it did it works quite well for a lot of purposes a lot of use cases we should talk more thank you that\u0027s great information it\u0027s a good day one god we think that took that little side trip as long as we\u0027re doing memory lane we can talk about BC P 56 this you know which I I had thought was just blocked on the completion of core so maybe we\u0027re going to learn that core will be done like a in of Thursday\u0027s session but Marco will let us know okay so BC P 56 this we had said we were blocked on core as time has progressed that we\u0027ve done other things I\u0027ve left a few notes in the issues list of things that we might can\u0027t we won\u0027t want to discuss before we ship it so I haven\u0027t talked to the other chairs about this at all as to whether this is in scope or not but there\u0027s the issue of using the word header field but that\u0027s a core issue not an issue for this I think what was this is Ben Carrick when he was doing a last call review of 50 70 to fight this one of the things that came up was do we need more advice about when and how to use Bowen on your eyes that\u0027s something potentially we could address here in another context don\u0027t I frankly forget where that was some people are talking about when do you use your eye components versus meeting new headers some advice about that might be good to "
  },
  {
    "startTime": "00:51:53",
    "text": "put in there or at least examples to understand the trade-offs when you make that choice when you\u0027re designing a protocol and yeah some some advice about when you and this is compactly in a couple of different working groups using HTTP recently the idea that a response has this inherent value of being either fresh or stale and what that means in relation to your application when it consumes that response is something that applications probably need to at least be aware of if not talked about when you define a specification so those are just kind of little notes that we could potentially incorporate into the spec if we as organ that were willing to add a little more text to the spec so we have a generic question here of whether or not we feel this document is essentially you know just done and pending on you know the normative reference decor and the resolution around header field given what core defines or whether we want to continue sort of updating it while it\u0027s in this in this interim state and so folks have comments on that the chairs would be interested in hearing from Roy those all sound like a core issues to me I disagree especially regarding 840 and probably about 787 they\u0027re very specifically about how you use the HT oh you talk about how you use HTTP when you write a specification and 77040 I thank you speaking for myself yeah I often discover that in users of things completely forget that stale exists they are always surprised when something gets returned stale and so having more visibility into that is absolutely going to be I\u0027m going to increase the quality of implementations from Roy shrug you know I can see him struggling right now so my inclination is that if people want to provide text we can essentially treat this while it\u0027s in this sort of interim state as a living document if you will if we have the energy to make these kinds of make these kinds of updates before it\u0027s ready to technically go through less call but that wouldn\u0027t be driven by the presence of you know texts are not coming along and so mark says he\u0027ll write it and there\u0027ll be text there you go secondary certificates is up and I hope we can make some partners in this one today I don\u0027t know let\u0027s talk about it Mike\u0027s gonna come talk about it excellent "
  },
  {
    "startTime": "00:54:57",
    "text": "you wanted slides by Friday I was moving into a new house on Friday there was no way that was going to happen so no slides so basically last time around we added the required domain extension to try and limit the possible attack from a compromised cert being used by an attacker that helps with some of the situation\u0027s the lingering angst that has been relayed to me is around DNS check and I think the path forward there may just be to try and make that not being a separate issue from this document and just say if you would do a DNS check otherwise you do it here if you would not do a DNS check otherwise you don\u0027t need to do it here that is not part of secondary search either way so we don\u0027t currently have an issue for that because we thought we had result that with the extension but we can certainly open an issue to clarify that text and if anybody wants to come up to the mic and suggest text I\u0027d prefer PR but if we want discussion around it that\u0027s good too other than that the two open issues coming this week were editorial had a PR I\u0027m rich the PR we now have no open issues so I would say the main thing between us and last call is some actual implementations I\u0027ve heard that there\u0027s the beginning of one but I\u0027d like to see more than one ideally and if the person who told me that they have that partial implementation wants to come up to the mic and publicly admit it caelum Eckert\u0027s we have a beginning implementation with the with the intention million intention of using this for client certificates I don\u0027t want to say this is more than it is it\u0027s very much seen to be gains and if there\u0027s nothing else I\u0027m check out what that means for the working group for next step does that mean we feel that we are at a state where last call would be appropriate is anyone have any comments this has been contentious in the past more specifically do we need to see implementation or interrupt before we ship it Mountain Thomson I would very much not want to ship this as an RFC before there are interoperable implementations preferably deployments of those but I\u0027m not sure that I need to hold the light on that one unless anyone thinks then an RC number to start moving on this one I would suggest that there\u0027s enough complexity "
  },
  {
    "startTime": "00:57:57",
    "text": "in here that having implementations would make me a lot more confident and that\u0027s as an author and Nick Sullivan closer I\u0027d just like to note that we have a server implementation and so looking for clients to interrupt is that something that\u0027s deployed or is that I like to call me it\u0027s a call me that\u0027s great we can move on to structured headers I guess so we\u0027ve had a bit of a burst of activity on structured headers recently if I go down to the changes can you see that in the back and you read that or Eliza what up oh there how\u0027s that great Thanks so the important ones in since draft ten are towards the end 781 we closed we allow empty dictionaries and lists now so in the data model those structures allow are allowed to be empty whereas they weren\u0027t before they\u0027re serialized as the header not appearing on the wire is how it\u0027s currently spelled if the header appears in the wire and it has an empty value that will also successfully parse for serialization the the normal form is at work is to not see realize that 797 I was not important for discussion 816 allow inner lists but in both dictionaries and lists and to remove that effectively obviates lists of Lists as a separate top-level data structure so now you have this in most places where you had a member in those structures you neither have a single thing or you can have a list of things and after a long and enjoyable fruitful discussion of syntax we ended up on using parentheses and whitespace to delimit those lists and it looks it looks okay and finally 839 was even more interesting we subsume parameterize lists into lists which means that basically lists now can have optional parameters list items and the winning argument for that seemed to be that when you define a structured header it may be that in the future you want to add parameters to it and if it\u0027s defined as a list well that\u0027s awkward it\u0027s not backwards compatible whereas if it\u0027s all parameter all list members could potentially have parameters then you can retroactively lis add parameters to an existing header field and it\u0027s backwards compatible because the semantics of parameters and so that the downside of that one was that potentially how you represent structured headers in programming languages in various you know mappings to date structures or objects became potentially a little more complex but the trade-off was felt to be worth it I still have to "
  },
  {
    "startTime": "01:00:59",
    "text": "do a lot of work on the test suite and on the sample implementation that I have in Athens to validate all these changes make sure the algorithms are absolutely correct but we\u0027ve had multiple eyeballs on it we\u0027ve got some fairly detailed feedback from pH K on the algorithms and I feel like they\u0027re in pretty good shape we might have a couple of bugs in there but hopefully when I get a chance to sit down we\u0027ll be able to really make sure that they\u0027re just beating the test suite is still representative and when it passes and then the other implementations last update as well so that\u0027s the recent changes the open issues it is freaking cold in here I want to briefly run through these if we have a little bit of time okay so pH K brought this one up in his review of the latest draft pointing out that that floats the current definition is surprisingly hard to serialize correctly and he of course hurts in sample code and then what he suggests is that if we define that SH flood can have a maximum of six digits after the decimal point things become quite a bit easier and so you know we in it and all the decisions in structured headers we\u0027ve made this kind of trade-off of you know how can we have maximal correctness and maximal interrupt and cover the 80% plus use case knowing that we\u0027re gonna drop some use cases and so personally to me this feels like the right decision if we you know the people who need that kind of precision can put something into binary or put something in a string those use cases in HTTP headers are relatively uncommon and if they are if somebody does want to use that kind of precision and it\u0027s not interoperable or easy to implement it\u0027s much more likely that we\u0027ll be adding to the problem there problems not helping them but that\u0027s my personal feeling I\u0027m very happy to be convinced otherwise so Mum Thomson can we confirm that this is not just a particular C library implementation that we\u0027re hitting and it\u0027s in the C language specification and the similar functions in other languages and not different so you\u0027re asking for research and data yeah if you\u0027re gonna make this sort of change yet sure otherwise I\u0027d be tempted to say well what I just rolled your own string a fire for the float it\u0027s not a huge amount of code you\u0027re right we do need to do more more digging here a little bit my assumption which wasn\u0027t terribly well thought out was that you know most you know look at Python and Ruby and so forth they\u0027re all going to be based on the C libraries yeah what about Russ but what about all these other ones yeah sure but the point is interrupts we have to interview these let me just talk with each other so related from Roy fielding do we have anyone who needs a float other van int / 1000 right and then actually I think in our private discussion when Patrick can "
  },
  {
    "startTime": "01:03:59",
    "text": "we\u0027re talking about this one of the things that I flooded was maybe somebody uses in sand like if you\u0027re mapping from Q values then you say well this is the mapping for Q values into this different structure well the only thing you really lose is the ability to essentially take an existing header that uses floats and pars it as a structured header without changing its identity but that may be a reasonable trade-off as well one of the big reasons to use floats is so you can get a lot of things past that decimal point and while this trade-off may be a perfectly fine one let\u0027s make sure that the name actually reflects the fact that it has a really huge trade-off in its precision so that in the future maybe when somebody act because of the presence of something that can serialize the float in the format that\u0027s not so expensive it would be nice to actually be able to represent it so I think we have a chicken and egg problem and I\u0027m just trying to like I\u0027m worried about that so you\u0027re saying if we do ship something like what suggested here that we\u0027ve changed the name yeah and I\u0027m also suggesting that there\u0027s a chicken and egg problem by not having a good float we will certainly prevent it from happening anyway sorry I\u0027m not quite it\u0027s been expensive to serialize floats yeah more expensive than other things because you have a string the string is fairly long right so because of that we don\u0027t put it in patters doesn\u0027t make a lot of so I see right right you\u0027re saying that we may not have evidence a lot of floats because it\u0027s it\u0027s been expensive so if we\u0027re gonna make it cheap we should make the right thing cheap sure do you have a suggestion for name the the current suggestion because I don\u0027t want to argue this too much because I\u0027m not really participating in this too much is please just change the name so that if somebody does the full float that it has the right name okay just naming things is hard that\u0027s all yeah I was going to observe that the if you have a fixed number of elements after the point fixed point is is a name I see nodding heads or decimal decimal decimal decimal decimal is what it is and if you limit the number of digits after the decimal place you can store them in an integer just exactly what boy was suggesting so um my inclination after hearing this if I\u0027m hearing correctly is to go ahead and do what HK is suggesting here but to change the name to decimal workable anyone with heartburn I don\u0027t remember do we have if there are bounds changing the storage is going to change our expected maximum balance rather significantly yes and so people may have expectations around that I think I think well this came about because we were you know relying on "
  },
  {
    "startTime": "01:07:01",
    "text": "shared concept of float that wasn\u0027t well spelled out in the spec and now it sounds like we\u0027re spelling it out to the degree of precision that we spelled out in twith so it\u0027s worth we\u0027d have to do for that process for this scene in general I think speaking for Roy fielding plus one six point okay now it\u0027s a now it\u0027s a naming race no name race fun month onsen we have 15 ten digits on integers what oh yeah yeah so just take six of those and put them on the right-hand side and leave the rest on them on the left-hand side and there\u0027s your limits right there I think that\u0027s concretely that\u0027s a serious proposal and six seems like a convenient number I don\u0027t know someone must have picked five or seven then we can argue about that one but that\u0027s seems Rican for myself that sounds fantastic okay Martin could you could you write that down in the issue so I don\u0027t forget it\u0027s 848 thank you okay that\u0027s editorial star in parameter names so it was notice I think when when pH can I were talking he asked if there was any use for star and I rely in parameter names and I realized that star is used by RC 50 97 or as Julian corrected me 81 87 this is the internationalization coding for parameters in normal HTTP headers and so the question is right now that is disallowed in forever names in what we call keys I think in the current a B and F so if you wanted to map one of these headers into structured headers you\u0027d need another way to denote that this is the internationalized version of that parameter because for those that may not have mmediately paged it in as soon as I said 81 87 the model of that is that there are a pair of parameters one that is plain ASCII and one that is internationalized so that you can fall back to the ascii if you need to and that\u0027s the the convention for those things for in things like content-disposition and the internationalized version is denoted by I believe a trailing star if I remember correctly so it would be a non-trivial mapping and so one thing we could do is allow stars in these parameter names one further thing we could do if we so felt inclined would be to just reserve that star for that very particularly use case and not for anything else doesn\u0027t have any thoughts about that I see there\u0027s a fair amount of discussion recently if you allow it the size of every key will be larger because you will not be able to encode it as efficiently on the wire when we encode "
  },
  {
    "startTime": "01:10:06",
    "text": "the keys right you can imagine in other protocols revisions that we encode the keys via a specific table Huffman table for instance right adding another character that is not used as often will slightly expand that it\u0027s not a huge deal but I\u0027m just pointing out that adding a character to the acceptable input set those actually have an impact on the size of the things that we said in the case where we\u0027re not using it right so if this is very rarely happening it would be nice to disallow in structured headers and say if you want to use structured headers well you could ask you sorry but and if you want to do some mapping you\u0027d do it in another header it\u0027s not even you can ask it\u0027s just you can\u0027t use this convention in 81 87 correctly or you can\u0027t easily use it you have to dismiss on your own mapping to it yes yeah from Roy fielding +1 to just sending utf-8 for structured headers that that\u0027s not this issue but yes noted 842 Dictionary of a dictionary Kazuko raised this and I think in discussion we came to the understanding that this was basically now that we\u0027ve allowed list members to have parameters can we do the same for dictionary members is that correct because you know yes so I think it\u0027s I\u0027m pointing about an inconsistency and fixing this simple and also provides one sensibility so I think we should do this I\u0027m fine with that I just wanted to check that that\u0027s the other few people\u0027s help what is the encoding of a dictionary containing an empty dictionary that\u0027s not what\u0027s being asked here it doesn\u0027t it\u0027s not Kenna dictionary contain a dictionary it\u0027s can a dictionary member have parameters no it\u0027s not speaking for Roy fielding it is that issue and this would resolve it he\u0027s right that was Julian oh okay I don\u0027t hear any pushback on adding parameters to dictionaries members so that\u0027s good add a subsection on limitations Roy "
  },
  {
    "startTime": "01:13:08",
    "text": "asked that we add us some some text about limitations I looked at this and then I looked at the spec and I feel like it\u0027s pretty specific about what the spec is trying to do and what it\u0027s not trying to do so I don\u0027t know what you\u0027re asking for here Roy so if you could give me some more information or give me some proposed texts that would be great because I don\u0027t know how to actually this request there okay so what I think this this is talking a little bit time so I don\u0027t mind if you close this issue because it\u0027s really there are a lot of things that I found out only by reading the a PMF and that there\u0027s no mention of it in the text particularly having to do with how many if you can have empty lists or empty header values but if you\u0027ve already corrected that in the text then this is no longer applies okay um if you find any of those please do open issues about those specific things we should definitely make sure that it\u0027s unambiguous Roberto and I just wanted to say mark is right it\u0027s not a problem okay that\u0027s what I love to hear more of that one more okay so I think we have ways forward on all of these which is great the last one is one that\u0027s been with us for a while we\u0027ve tried to come to consensus on in quite a few ways which is defunding a yarn reference type and I understand that folks this seems like a natural thing to do for the spec my push back or my concern has been that you know structured headers is all about presenting type data to applications in ways that they can easily consume in a highly interoperable fashion and that interoperability in your eyes unfortunately the story isn\u0027t that great if this thing is going to be implemented by browsers it\u0027s highly highly likely that they\u0027re gonna use the fetch your restaurants are the what working group you\u0027re aspect to offer that URI and that has a different API surface than what we would explain different parsing and processing the new weeks we would likely expose in the ITF in some very fine details and so I\u0027m reluctant to expose a foot gun if we can come to some agreement that you know offers the structure because they eat your eyes themselves are structured that offers the structure of your eyes in an in our horrible fashion that\u0027s actually likely to get implemented by browsers I\u0027m all for it but I don\u0027t see that as achievable in the timeframe that we have in this working group for this document and I really want to ship this document because it\u0027s starting to get a lot of things depending upon it that\u0027s where I\u0027m at with this cuz I hold them lastly my weak preference goes to not having this because we don\u0027t have date for example as well sorry so for not "
  },
  {
    "startTime": "01:16:10",
    "text": "incorporating okay thank you so as editor my inclination is close this with no action just to make that if that\u0027s not crystal clear I\u0027m Thompson I\u0027m inclined to agree simply because it\u0027s it\u0027s gonna be very difficult to specify this correctly even if you sort of wave your hands rapidly about all the various interoperability issues that we have with your eyes do you allow relative your eyes do you allow all these sorts of questions start coming up and and what would they be relative to it\u0027s tricky so that\u0027s not even getting into character encoding problems from Roy actually Roy this time so we can\u0027t have a URI type because nonstic nonstick sorg has an opinion about which spec to reference sad face it\u0027s not about the standards or gets about the implementations I agree with the sad face part I do agree with the sad face speaking for myself so people are gonna need to do this they\u0027re just gonna put it in a string type and get it wrong sure yeah if we don\u0027t have a fundamental type like that because of you know II too ambitious we might want some non normative textures and they just technology that that we didn\u0027t think the spec to support that it\u0027s not be an obvious question from from Julian the inter up argument actually makes me think we should add this because it would actually help the consumers Julian how we can\u0027t force the browser\u0027s to do anything the browsers might voluntarily do things if you decided they were a good idea and we agree I mean we\u0027re in the room and yeah Donovan kissed her and just woke up and said what wrote rolled over eNOS yep Julian says because we would define how it works yeah we could define how it works that\u0027s what this was specifically brought up and the feedback we got was that if they have a 8 P API and parsing code for Euro I was already in the browser they are very strongly disinclined to use anything else right Roy fielding says I don\u0027t care what the recipient does with the string I just want the sender to tell me it\u0027s a reference to a URI so actually to that specific point you know the the specification defining "
  },
  {
    "startTime": "01:19:12",
    "text": "structure to head the structured headers always defines its semantics and it can certainly say this string is a URI just like you can say this string is somebody\u0027s name Julian says +12 what Roy said that\u0027s back line like so yeah I think that this this kind of runs counter to the whole there\u0027s already existing implementations and we\u0027re just going to do a cut and paste of what\u0027s there and unlike what we were talking about with floating-point we can\u0027t play any like realistic scoping reductions to make the problem simpler so yeah Ryan\u0027s levy Google works on Chrome and sadly one of the folks maintained the URL side I support what Mark was proposing air which is punting this issue and and the unfortunate part of it is that one of the challenges that would be with implementing this and what benefits the structured headers is that you get that error processing model right you understand what is a valid or invalid model and the whole reason why we have that joint dubbed 3c just be clear there is an sto behind it you know what WG fetch spec is that challenge which is a lot of the URI processing model was in terms of error handling correctly and so there\u0027s issues that exist out there on the web that don\u0027t conform and we deal with that messed up yeah so the challenge of trying to like do this now for structure headers is trying to define that err processing model and that is a yak shave it\u0027s been going on for nearly a decade and it\u0027s slightly more hairless which is great but it\u0027s not there yet I might be alone here but I it seems like there are two advantages to structured headers one of which we are talking about right now and the lack of that one we\u0027re excluding the other to be specific there is how we encode things on the wire which could potentially be more efficient and then there is how we represent it to the user which in this particular case we\u0027re suggesting we\u0027re probably gonna end up having B text if we can get some advantages by having a shorter encoding because we know it\u0027s a URI and we know who we\u0027re talking to that might be worthwhile even if we just serialize it to text so it may be that it\u0027s useful on the wire so I think we should be talking about these things separately how we present versus how we serialize or store I think part of my concern is it\u0027s almost an attractive nuisance that if you define it as a URI some implementations are gonna present it with an API on top of that and then that\u0027s gonna cause interoperability problems I mean really this specification is a big game of chicken that you know where we\u0027re defining this as precisely as we can to try and "
  },
  {
    "startTime": "01:22:12",
    "text": "encourage a high level of in a row but it\u0027s always up to the implementers to actually show that line and if we have one major implementation that decides it\u0027s gonna go off and go cowboy it\u0027s it\u0027s kind of all over you know so Roy says then why hat even have any strong typing what your eyes are nothing the lack of a specification does not prevent somebody from going cowboy if we held our hum how many people would participate curious keeping in mind that this is effectively what\u0027s keeping this speck open okay so we\u0027re gonna have three options first option is we don\u0027t define anything for the URI and we leave the text as is second option is we decided it\u0027s critical to define something for the URI and that needs to be proposed and then the third option is you don\u0027t know enough yet and you want to leave this document in limbo and make the author sad mutton on the second point there just a clarification we\u0027re making that would be making the statement that we have to define the processing rules for the the URI in detail tequilas shave the AK strong definition yeah okay thank you right okay so please hum now if you believe that we should leave out a definition of URI and leave the document as is okay please hum now if you believe we should add a strong definition of a URI to this document and please some now if you don\u0027t know and you think we should continue discussing this alright seems pretty clear that we are going to leave your eye out thank you everyone okay well that\u0027s "
  },
  {
    "startTime": "01:25:15",
    "text": "great yeah that\u0027s progress so we\u0027ll take it next draft in the agenda we were down to two of our adopted drafts client hints and yobs coming up and Ilya is in the house this is great hey hi your vice Google let\u0027s talk about client hints there were no major draft changes since Prague other than a few PRS that are currently in the air but I wanted to discuss the issues there are yeah various open issues that are worth discussing the first is a sec - eh - prefix we had various people that are interested in adding namespace for client hints similar to for example there is the sack - fetch namespace for a various fetch related request headers and otherwise the sack - prefix is something that is pretty important from course perspective and from a perspective of making sure that these headers are something that only the browser can set and cannot be set by user and JavaScript at the same times Julien had objections to - CH prefix as if I try to channel him that can create conflicting namespaces that we don\u0027t have any plan of uncon Flik thing so for example if we\u0027ll have multiple of those namespaces collect like a request that falls into two namespaces how do we represent that so I\u0027m wondering if anyone else has objection like if anyone has objections to the sack - prefix because this one I think is critical for the fetch processing model and then I will I\u0027m wondering if anyone here has strong opinions regarding the - see like the CH - addition to that as the namespace for general request headers so yeah just try and clarify SEC - turns off client access in fetch access to the headers yes and personally I think pragmatically that\u0027s probably a good thing to be doing here what does CH in the prefix give us does it change any software\u0027s behavior no okay it\u0027s a convention so it seems a little unnecessary than to add that like "
  },
  {
    "startTime": "01:28:15",
    "text": "you could say it\u0027s a convention saying if you want to flag this as you know just to humans as hey this is a client in fine but but you know by saying it\u0027s a prefix that kind of implies some sort of automated handling and that\u0027s maybe causing the confusion here um I don\u0027t think there\u0027s confusion but I am willing to accept that yeah we need to yeah it so you\u0027re saying if I am their senator saying you\u0027re saying that features that use the client and infrastructure are of Liberty to add that prefix if they so wish but but if I define a client hint and I fail to call it CH - something it\u0027s still a client and for all intents and purposes okay nothing special would happen yeah yeah because it\u0027s just the when you start inferring things based upon proof when you get into a bit of a mess if there are multiple facets to the prefix because you know if we define five more prefixes and then you have an ordering problem yeah yeah you know so yeah and I remember we had this whole discussion when SEK came out and my objection was well what happens when we define the second and third prefixes and lo and behold here we are okay so okay so we\u0027re dropping the CH piece first like I\u0027m not telling you what to do but personally for me okay I would just say you know for security reasons I think there\u0027s a whole nother discussion to be had about whether sec - is always required on the request header or whether it\u0027s for just it\u0027s a case-by-case thing I think there\u0027s there could be an argument that some client hints are okay to expose to JavaScript but that\u0027s you know case by case and so I I personally would be like okay every client who needs to evaluate whether it needs this prefix and if you want to be friendly put CH in the front just so that people that that\u0027s personally how am i we\u0027re doing okay speaking for myself Chris lemons the if there\u0027s a convention even if it\u0027s not mandatory if for example even all of the examples have CH in front of them somebody\u0027s gonna write some software assuming that they\u0027re gonna enumerate all of the headers that have CH in them right and that may be but it won\u0027t actually break like the browsing use case which is the main target here yeah so nan Thomson I think the key thing that we\u0027re looking for here is defining the set of rules that we\u0027re setting out for people defining new client hits and that the key property that we\u0027re looking for I think is that they all have second front of them they\u0027re right that is correct requiring this maybe that was what I was just bringing up right and and so so Marx suggested that maybe that\u0027s not a strong requirement then may be the case i I thought about this in "
  },
  {
    "startTime": "01:31:18",
    "text": "the past oh whatever the conclusion was I think we should stick um I I like that framing of the thing at marquette so cool so from my perspective and from a fetch processing perspective I think it will be significantly simpler and easier if all of them had a set prefix and we wouldn\u0027t muck around with multiple options there okay um so moving on to the next issue moved to structure and headers any objections to that okay cool ship it third issue is active versus passive fingerprinting at the last in Prague we had a lively discussion around whether client hints are passive fingerprinting vector or an active one earlier today we had a like we had a discussion with the Mozilla folks and I think we have reached some some form of understanding regarding the actual the actual concerns there Martin do you want to speak to that yeah Thompson again there has been I think I think we\u0027ve got a bit of mutual understanding of where things are we haven\u0027t fully investigated the propagation of client hints into third party browsing contexts which requires a little bit more thought on our part and we\u0027ll find someone to look into that in a bit more detail someone who\u0027s more familiar with with what what our policies are regarding third party browsing at third party context the question about whether this constitutes a new surface area for passive fingerprinting and various other passive use of information I think we\u0027re getting closer on this on this point the key concerns seems to be right around the properties of the individual client hints that we\u0027re talking about and some of them you can imagine being quite easy so if we imagine that we had except language turned into a client hint which I think we want to do that\u0027s essentially static and very rarely changes in DPR and though some of these things are very static in thing and so when you release when when a site says I would like access to that we can "
  },
  {
    "startTime": "01:34:18",
    "text": "look at that one access and treat that as a single point of access and then we don\u0027t have to worry so much about the the information being relayed to the site thereafter because it\u0027s always going to be the same viewport is a little more interesting because it does change over time and there\u0027s a couple of things that do change over time and then at the extreme end we have something like geolocation which has constant changing properties but it may be the case that what we\u0027re concerned about there is that this is also a property that is behind a permission gate or some other thing like that and has additional policies around its use and so we need to understand how that interacts with with with that as well so what we\u0027ve suggested is that we start being very crisp about what it what it is that we\u0027re using to decide whether something\u0027s ok to use in this context and be very clear about what our principles drive that and allow for different browser implementations to make different decisions about what they may or may not want to use in this context so it might be that if we\u0027ve got a property that\u0027s available to script passively that doesn\u0027t change very often everyone\u0027s happy with that one there may be some other ones that the information is only available if there\u0027s an engagement gesture and so we that might be completely unsuitable for use in this context because we\u0027ve only we want to be able to directly correlate that action with the property being released to the site and so there\u0027s a little bit more work to do on this one but I think the the core of the realization here that we\u0027ve reached is that we need to allow for different policies to be enacted by different browsers and protect potentially even different user preferences and whatnot because we each have a different posture with respect to this sort of information and so what the problem I think we were struggling with is that we were trying to encode policy in these documents and I think by having that realization we may find ourselves in there in its slightly better position thank you yeah so yeah the I believe that the way forward here is to try to formulate some set of these policies and then potentially add them to the security and privacy considerations section and and then we can move forward on that front so so with that this may be the most fully formed and well-thought-out privacy considerations section in any RFC ever so thank you for doing that I know this has been hard but I think we\u0027re getting pretty close to to this being big a good thing and I do want to "
  },
  {
    "startTime": "01:37:18",
    "text": "start using this for things like user agents so people this is fair warning user agent is now on death row so so do I hear you correctly the saying that this actually is making you think think about implementing for some for some not all but for some clients good that that\u0027s actually really great news thank you okay yeah thank you and the last issue is ice it was a long title so I summed it up as exposure to CD ends I don\u0027t believe Peter Schneider is here today but yeah in his absence we\u0027ll discuss this basically if I try to sum up there the claims in the issue is that client hints because they are structured and readable automatically readable they expose those exposed values that servers have opted into to other parties on the wire which are typically because this is restricted to HTTPS are either CDNs or MIT M proxies and the claim is that this will enable those parties to log that sensitive information and I believe the question sums up to our CD ends part of the threat like the privacy threat model because they can like if you have if your mi tanning TLS or like if you\u0027re terminating TLS you can already inject JavaScript and do all kinds of bad things if you so wish and I don\u0027t think that logging that potential finger printable information is on the top of those bad things and so the CDN is the origin from the perspective of the of the other browser so what the CDN wants to do with this information is the business of the origin server and the CDN they consult that adults themselves I don\u0027t think that represents any special privacy problem and I don\u0027t think it\u0027s worth docume that and if we\u0027re gonna start talking about interception props and proxies we\u0027re into all sorts of problems and I\u0027m not signing on for that and I don\u0027t expect anyone else to have to so Reynes levy Google and as much like it could "
  },
  {
    "startTime": "01:40:18",
    "text": "rehash something that will mark thought we close to happy there\u0027s a lot of discussion when we were developing the browser web crypto API in terms of why are some folks gonna use this well in the common cases for sort of client-side encryption even though sir Brian could you just get a little closer I\u0027m sorry yeah um one of the discussions with why why would you do browsers client-side encryption for things was an example to prevent information from from being accidentally logged right there\u0027s been multiple security breaches of say then there\u0027s accidentally logging passwords then causing issues so in that argument in which it says that this is not a threat from an adversarial threat model it is a threat from an incidental or accidental operational failure rienne and this is the part that makes mark unhappy is the reintroduction of a prefix to indicate for intermediaries you perhaps should not love hug SEC CH anything in that prefix on the basis that if we assume that client heads as Martin was talking about may contain some identifying information or may themselves be fingerprinting the ability to have that structure allows for filtration on the server side to prevent the incidental logging of that information the same way that one might say should filter out cookie or other headers in you know a structured header this might be a single field so you might not need the CH prefix so it sorry we\u0027re talking exclusively about the previous issue effectively i we\u0027re suggesting that the CD ends are not the adversarial threatened model they\u0027re they\u0027re inseparable so yeah reintroducing a sure my immediate question would be is there any difference between you know the headers that need a sec is a prefix and the headers that need a different flag for district model that is an excellent question it is very much a general problem right yeah our absolute so Martin Thompson on that point though it is a good one and I think rockins onto onto something that we need to think about more generally when we start talking about adding header fields I tend to think that these are very much designed for consumption by CD ends and so accidental logging aside these are this is something that Citians probably want to log because it\u0027s going to be changing their behavior and so if we think about it in that context maybe we\u0027ll find that going to that going to those extra effort putting the extra effort in to make them distinguishable so that they can\u0027t be logged isn\u0027t really a much use when they\u0027re going to end up in the logs anyway so it sounds like maybe there\u0027s a little interest in saying please in your operational practices realize that this is sensitive information potentially whether it\u0027s in a CDN whether it\u0027s on an Origin server in a database or is that "
  },
  {
    "startTime": "01:43:24",
    "text": "and I think that that is the right balance to strike here is recognizing that this could be identifiable information particularly once we said start to get to the point where there\u0027s enough entropy in here to narrow things down quite a lot and so recognizing that and just just putting it in there saying that when someone handles this information they treat it with respect motherhood and apple pie but do it anyway yes okay extending the lis care that the sec prefix implies through the rest of the ecosystem no does that give me the information yeah that that makes total sense ok ok and then new and exciting developments HTTP SVC enables us to solve one of the long-standing issues related to adoption people wanted to use cryin hints as a way to come to perform adaptation on the navigation response so typically on the HTML itself and that has always been a thorny point we added except CH lifetime in order to address it in future H HTML related negotiations but it didn\u0027t address the very first request and pushing that except CH signal to DNS will enable us to solve that problem I wrote a PR that adds an alt service extension to client hints it\u0027s not clear that this David Benjamin have commented on that basically saying that it has a few different characteristics from other things that are currently in service so maybe all service is not the right answer here but I would love to find a path forward to push the opt-in to DNS as well on top of just being a header I think we\u0027re gonna treat that as an FYI because we\u0027re gonna talk about HP service on Thursday and it might come up after that or or not and we\u0027re running low on time okay another substantial discussion I have yes and yeah the last question is can we move forward or what like it seems like we have a path forward for all the open issues it seems like the next thing to do is to incorporate those finish those discussions get a new draft out and it sounds like last call is looming to me I think you know please didn\u0027t on the horizon perhaps yeah it feels like we have like a path forward as you say so let\u0027s see the text see if we get "
  },
  {
    "startTime": "01:46:24",
    "text": "consensus around the text but you know I think that\u0027s definitely worth changing okay thank you so much thank you for for the engagement yeah you ever anything to say on the cookies draft okay so we are going to skip the cookies draft and move on to the priority conversation so ian has a presentation for us it\u0027s all a bit of a tease here to get things going yep should be challenging my name is Ian sweat I\u0027m from Google I\u0027m talking about HP three priorities and to some extent HP two priorities I talked about this briefly at the Quicken Durham in London and here\u0027s kind of an overview of where we\u0027re at today and what are some ideas of the HP 3 workgroup members excellent so it all began with the coin flip I was not there I know some of you were and I know there are two competing proposals and the tree-based proposal next slide one so HP two priority tree is essentially you know it\u0027s what you have here there are weights and you know notes gonna have parents streams can depend on streams or they can depend on this implicit route so there\u0027s been a fair amount of discussion historically on the list to vote the challenges of streams depending on streams in certain circumstances there\u0027s also this concept of placeholders which I\u0027ll talk about briefly later but which is basically like a stream that doesn\u0027t really exist it just exists so you can have something that you can reference for a very long period of time and Firefox actually uses a session see you later so RFC 7540 has a much nicer description so given my time I\u0027m gonna keep moving for it yeah so one way of thinking about them and the way I usually think about them is that strict prioritization is implicit and encoded in the tree structure and the weights allow you to share bandwidth between nodes where the nodes my either be streams themselves or like trees of have streams so next slide so how do browsers use H to party next slide so chrome uses a linked list essentially so just puts everything in one big long list and that gives it strict ordering so it knows exactly which thing is higher priority than the other thing this is very straightforward and maps relatively well to its five party levels that it has internally in the in the browser next slide Firefox creates this placeholder model where it uses a six plate or sorry five placeholders and separates things into buckets based on whether or not their render blocking resources or background so on and so forth and uses weights to "
  },
  {
    "startTime": "01:49:26",
    "text": "end dependencies to kind of trade off between them but it uses weights a little bit more than than chrome DES next slide Safari does use weights and you know kind of just puts render blocking resources at higher weights then than other things I didn\u0027t actually put edge in here it was originally in here but the last time I checked now in edge iam I believe it\u0027s just as what chrome does prior to that it just didn\u0027t send anything at all and use the default which is pure round-robin with no waiting whatsoever next slide so let me give you a quick overview of a few of the other both where we\u0027re at for h3 right now as well as some alternative proposal proposed on the list first by Patric meanin and then subsequently discuss prior ID about their working group member isn\u0027t including Lucas and Kazuo next next next okay sorry I was gonna need to save my time so conceptually HQ priority tree that we discussed previously it\u0027s really clean like you have two concepts you have a you know basically who you\u0027re a parent of and a weight and it provides you a huge amount of power and a lot of flexibility but it has some challenges and it provides a lot of functionality that in reality browsers like really are not using and do not need and some of that complexity embodies itself in the implementations as well so next slide h3 priorities actually are you can they argue this but most people think they\u0027re slightly more complex as they are currently specified than 82 priorities they add explicit placeholders instead of having implicit ones so whether this is more or less complex than in Pleasant ones maybe use a point of contention but in order to ensure consistency all priority frames are now sent on the control stream so you can\u0027t send priority as part of the request itself because you may have issues with you know does this priority apply for storage is this one to apply first and you just you basically get tree and consistency because you\u0027re trying to maintain distributed state at a distance and you have no idea why blocking so the only way to really fix that is to put them on the control stream so you\u0027ve actually reintroduced head-of-line blocking into a protocol but we would like not to have a head of wire blocking in however we solve this by adding this orphan placeholder concept so the idea is really we probably want the default to be FIFO not round-robin and so in order to achieve that we\u0027ve created something that\u0027s basically like if you\u0027re not really sure how to prairies prioritize this thing you put it at the root and you service it after everything else is one way of thinking about it so it\u0027s also been proposed as a zero weight option I think "
  },
  {
    "startTime": "01:52:29",
    "text": "functionally they\u0027re quite similar but but the goal here is to achieve FIFO by default especially when the priority information is lost because now it\u0027s on a different stream and it\u0027s not embody embedded in the request header next slide so patrick mean on the list around january or february of this year proposed something that\u0027s largely a speedy style in numerical priority originally had two bits for concurrency now we simplified it to one so this is basically saying you know everything has kind of a strict prioritization you know higher priority service before lower priorities and then either you want a request sequentially so you want the entire response all or you\u0027d like it round-robin too with other requests there are the few more details that are in the write-up but this is based on his experience on the quorum loading team as well as assume experience at CloudFlare next slide and actually I should go back one sorry for people who haven\u0027t read it that the blog post that\u0027s linked to is quite a nice write-up of priorities and it\u0027s it\u0027s well worth reading if it\u0027s only for educational purposes so excellent so what do we actually need here actually so based on what I can I can observe separate research efforts both Patrick Menon and Robin Marx and others have kind of come to around the same conclusion of what we want at least for standard web page loading so the optimal ordering occurring to Patrick is serialized the CSS and blocking JavaScript I will just let you read it it\u0027s probably next slide sorry hmm this is for a web HS this is not for video and other things no one\u0027s actually done video like research on video which is always kind of curious I did ask Robin for follow up on that but I assume yet he\u0027s not going to run into it yeah so this is kazoos comment which is a much maybe a more visual representation of largely the same text that was in Patrick\u0027s comment and so there\u0027s a few ways of representing this but I think we have a much better idea at least for webpage loading like what what we\u0027re trying to achieve so one more slide and from Robin Marx paper itself some observations and he compared I think eight or nine different schemes against one another more sequential schemes generally outperform more round robin like schemes so if in doubt do FIFO and it\u0027s perfectly possible to switch from us to a simplified prioritization framework while still fully supporting the web browser use "
  },
  {
    "startTime": "01:55:29",
    "text": "case without losing perform so next slide yeah so what do you really need most things we want to be FIFO some things ideally should be round-robin so we want to try to make FIFO easier and that\u0027s why we did the orphan placeholder proposal in the existing h3 model next slide so h2 priorities can achieve optimal loading but so why do we want to change this so there\u0027s some pretty substantial issues some of them technical and some of them known next slide so I think we\u0027d really like wide adoption it depends on your view of adoption and http2 priorities but full adoption is something in the range of 25 percent according to one study you know I think partial adoption is is certainly a bit better but it\u0027s certainly not ubiquitous on either the client or the server side and most the clients that you saw at the beginning they started using priorities on the day that some web developer decided he\u0027d like had some good ideas and then like he did a test and maybe he was better in some circumstance and then it hasn\u0027t been touched in like four years great like I mean this is not being actively worked on and improved from what I can observe so I mean I don\u0027t think we\u0027re seeing an increase in the h2 variety adoption at this stage or dramatically changing usage patterns for what I can establish so I have two minutes that\u0027s awesome next slide as Patrick Meighan pointed out in his blog post very nicely it would be awesome to allow server input sometimes the server simply does no more than the browser and the existing tree model is extremely difficult to achieve this so as we already discussed you have to put everything in this certain order and you have to put everything on the header stream otherwise you have the possibility of what losing synchronization if you try to achieve that with a back-end and a client at the same time it\u0027s essentially an intractable problem it\u0027s impossible to know like really what the tree should look like next slide Firefox needs placeholders right now they\u0027re not actually required that\u0027s sort of a bummer for them next slide next slide next slide or if it doesn\u0027t work next slide okay let me stop here so next slide sorry and next next there we go so my original thought is it seems like we\u0027re basically narrowing down on some proposal that some amount of like number of buckets and a bit for concurrency as being like perfectly sufficient for the web browsing use case and providing optimal performance and we have some better ideas on how to use it my original suggestion was that we try "
  },
  {
    "startTime": "01:58:29",
    "text": "to move forward with that and try to move forward with that but for both hp2 and for HTTP 3 subsequently others have suggested like they really don\u0027t want to go that way at this stage in the game and that the optimal option is to remove priorities from the draft entirely I am happy with that option martin thompson has prepared a PR for that option from a procedural perspective i think that\u0027s a more expedient way forward because it does not block the standard is a standardization of HTTP 3 on figuring out optimal priorities which are really - I would say orthogonal issues I mean I don\u0027t think there\u0027s a requirement that they be one be blocked on the other and as we\u0027ve already shown through the issues that I\u0027ve posted here there are substantial issues with just kind of kind of fixing each two priorities and moving them on to h3 that are already creating substantial challenges so all right so I\u0027m gonna miraculously transform you now see before you a quick working group change from from that perspective what we\u0027re looking for is input from this community about how htv-3 should address priorities one of the big concerns in that work is is that the more Delta we have from HTTP to semantics in HB 3 the more friction it could create for adoption of the new protocol and so if you know HTTP this working group owns semantics to this protocol and so that\u0027s why we\u0027re here is to have this discussion so right we are we have one minute and so the there\u0027s a meeting at 8:30 on Wednesday and Van Horn that\u0027s where we\u0027d like to see this continue and I think we can dedicate some time on Thursday to summarize what happens there is that the plan yes so with the rest of the minute go for it repair to pay on I\u0027m trying go as fast as possible so I want to say that it doesn\u0027t really matter what spec what matters is what implementations do and from that perspective h2 priorities as cool as it seemed at the time seems like it\u0027s a failure right so let\u0027s figure out what the next thing is and move on so I would also warn people however a lack of priorities is really bad we know that from what we did in speedy initially in the in the very initial things we have to have some priorities we can\u0027t do it without it and server priorities I agree is going to be more interesting than client in the end thank you and that\u0027s really the conundrum right so really quick guys lastly even though we have a fully compliant proud and its implementation for both h2 and h3 we think I I think that we should move this Mike Bishop Akamai I want to point out that we ship server push without cache digests we understand what happens when we ship half of a working feature multiplexing without priorities is half our key future and with their own "
  },
  {
    "startTime": "02:01:30",
    "text": "priorities too non-working features from Java Robin mark says we have insight for video streaming but not as detailed as but exploding Martin less word for today but then there\u0027s Thursday for everyone we need prioritization but we don\u0027t need signaling for prioritization all right we\u0027re adjourned until Thursday or the side meeting on Wednesday morning right nervous "
  }
]