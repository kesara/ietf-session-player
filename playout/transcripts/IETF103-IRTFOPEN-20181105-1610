[
  {
    "startTime": "00:00:05",
    "text": "[Music] [Music] [Music] [Music] [Applause] [Music] [Applause] [Music] [Music] [Music] I don\u0027t know there we go alright hi we\u0027re about to get started can someone towards the back of the room close the doors that\u0027s the plan have blue sheets been started yes yes y\u0027all right hand now okay good eye does somebody want to take minutes can we get a volunteer to take minutes thank you all right yes that was Matt perfect um you may have noticed that neither of us is Alison she is yes yeah she\u0027s I had to stay home to deal with the family situation so we\u0027re sitting in for her so your your indulgence consider it begged for okay if you uh if you\u0027ve been here before you recognize this if you haven\u0027t you might "
  },
  {
    "startTime": "00:03:05",
    "text": "not this is essentially the IP our policy we\u0027re under substantially the same IPR regime as IATA IETF but there are some minor differences so note well a more policy on there\u0027s going to be a lot of photography here today because we\u0027ve got our ARP winner no map no no photographs okay skip that um ignore that um so yes so no photographs right and for research group chairs I who are meeting later this week please don\u0027t forget to include the note well in New York and your slide sets for those who aren\u0027t familiar with the IRT F on the mission is to focus on longer term research issues related to the internet in parallel with the IETF they focus on engineering and standards making we focus on research or organized into topical research groups which are parallel to in some cases but different from work working groups IETF working groups the instead of having an ie SV were and we have an Internet research steering group it\u0027s mostly the research shares in a small number of at-large members including Spencer right so we do not produce standards at all period we do produce documents some of which may be published as RFC s and those will be experimental or informational okay these are our research groups these are all probably familiar there are a couple of changes from the last time we met one is that den RG is now a full research group we\u0027ve been promoted and there are two new groups meeting for the first time as proposed research groups one is privacy privacy enhancement and assessment and the other is the quantum internet research group everybody\u0027s meaning except ICC IG this week today\u0027s excuse me today\u0027s agenda um as I mentioned earlier unfortunately Allison is not with us a couple of things are coming up and our p for 2019 nominations are due November 11th so I get those in we\u0027re only going to have one a and our presentation today due to last-minute visa issue but there\u0027ll be news on that the talk that we\u0027re going to have today you\u0027ve probably heard about it and fill us in other working groups today Johanna Aman is going to be talking about excuse me CPS deployment metrics after you know after diginotar so it\u0027s not a vision of the twenty imc 2017 paper with new data hats Allison Scott yes okay okay "
  },
  {
    "startTime": "00:06:05",
    "text": "sometimes people confuse nrw and a and RP so see Allison provided slide disambiguate just ambig√∫ writing that and our things the applied networking with search prize on it\u0027s an annual call for nominees based on papers that were have already been published elsewhere the applied networking was workshop of course is a workshop it was an annual call for papers both already published and not and then presentations are given in a day-long workshop co-located with the summer IETF this year it\u0027s going to be in July in Montreal I should say in 2019 okay so we\u0027re done and if there are no questions on let\u0027s see if we can get out of this we escaped doesn\u0027t get us out of this but yeah Johanna yeah as soon as we can figure out how to switch the slides yeah okay yeah all right and then you see okay it\u0027s the Sun yes hello everyone I\u0027m happy to be here as thank you for the introduction so my name is Johanna I am a researcher at the international computer science institute which is a research institute that affiliated with UC Berkeley and as you can already see by the slashes I wear several hats I am simultaneously also an engineer at a startup called colloid and I am affiliated with the cyber security department at the Lawrence Berkeley National Laboratory and today I am going to give a talk that is basically that is called mission accomplished HTTP security after did you know tell that is a paper that was presented at an Internet measurement conference last year and later I am also going to talk a little bit about additional work that was done later that kind of ties into this research too and it\u0027s also about TLS one thing um this work was done together with a few other people at the Technical University of Munich and the University of Sydney and one thing before I start so this set up is a little bit different than what "
  },
  {
    "startTime": "00:09:06",
    "text": "they typically have because typically I can see the next slide to this presentation is a little bit long and if I am confused a little bit look I\u0027ve confused a little bit sometimes it might be because I actually am because I have no idea what\u0027s coming up next because I have a lot of slides okay um let\u0027s start a little bit so what does this paper about so basically what we did in our paper is we said after that did you note our incident what did change and more specifically we took a look at the TLS and https security extensions that mostly came up after digital and I have you were interested and how deployment actually looks like in practice and we picked a few extensions that we thought the most important ones what specifically we looked at certificate transparency HTTP strict Transport Security HTV public key pinning the TLS 4x signalling cipher suite value certificate authority authorization and they in TLS a and how did we look at this B it did active measurement and passive scans so active measurements means that it basically did domain based measurements of the internet Concord for for three from two continents for this we amassed at that point largest domain list that was known to us and scanned for more than 192 million domains I think even scanned a few times not just once and we also did a passive measurement on three continents so we had three sites which we got access to the Internet uplink of universities and very looked at the outgoing TLS connections and looked how certificate transparency was used and the one thing that was quite a few scientifically interesting about this work is that we had an active a shared pipeline between the active and passive scans because until s in academia a lot of scans have been done before both active and passive but they typically even when they were done athenaeus e for the same paper did not it was completely different software that is the active further than the passive card and in our case what we did is basically for the active scans we took a network ties of the entire traffic that was exchanged by the machine that was doing the scanning and shaft that ties for a passive measurement pipeline later where it was possible and then used the data from the path of measurement pipeline so we had the exact same source code running for both the active scans and the passive measurements later okay I hope I\u0027m not boring too many people of you here because at first I\u0027m going to give a short introduction of certificate transparency for those people that do "
  },
  {
    "startTime": "00:12:06",
    "text": "not know what it is so the big idea between behind certificate transparency is that but what we need to have basically an authoritative list of all the certificates that are being used and trusted on the internet and the way that certificate transparency uses to make this list available is that you have seen my test log service and those see my trusted lock service basically give out inclusion pools when a certificate is added to them and such inclusion pools can be presented to the browser and the browser can verify that a certificate has been added to a log server and the end game of all of this is that you only accept certificates as valid if they are included in certificate as currency which combs that to enforce I think in April this year back on the paper was open this was not yet being enforced so and basically we have three big entities interested here which are the certificate authorities the certificate lock and the browser and as you might also know there are several ways in which certificate transparency can be used and which those inclusion dogs can be transferred to the client the first potentially easiest to explain method is that you as a user request a certificate and get the certificate from the CA and if you want to give out a certificate a lot an including proof of certificate transparency what you can do is you can send that certificate to a certificate as parent see certificate transparency will send you back a signed certificate timestamp so the inclusion proof and when a vet but also connects to you that support certificate transparency you can send that poof in a TLS extension the second way that you can do things is that the CA basically sends the information to a certificate transparency in this case the CA sends a pre certificate to a certificate transparency lock server and a pre certificate basically it\u0027s just a certificate with an additional extension that says that it\u0027s not valid so it has a poisson extension the certificate transparency log I\u0027m science this and since the signature back to the CA the CA Daleks the science certificate time stamps includes it into an extension puts it into the certificate and since the certificate with the pre certificate a city to the web server and the web server doesn\u0027t have to do anything besides sending that certificate to the browser and the powers about that support certificate transparency basically does the reverse process it gets the SED out of this removes the extension and then checks if the city ready dates against the certificate about the extent and there was a third way of transferring the proof that\u0027s a "
  },
  {
    "startTime": "00:15:07",
    "text": "little bit esoteric which is that the CA key is final certificate and since the certificate both to the web server and to the city log the CA gets back a city and the back server supports OCSP stapling in this case and the back server gets an OC SP airplane and the awesome and OCSP state was every few hours or days from the CA and then the browser requests the certificate and signals the supports both certificate transparency and OCSP the city is send in the stapled or CSP response that the web browser can then use to validate the status again so we basically measured how much we see certificate transparency being used in practice and so these numbers from 2017 so these are a year old panel and back then you could see that approximately let me cheat a little bit and look they\u0027re approximately 10% of the males and 7% of certificates were part of certificate transparency we did a follow up paper this year which will be presented tomorrow at Network measurement these are cool I think and today after home started enforcing certificate transparency things look a little bit different in that measurement about 68% of certificates actually had an embedded a city so the ecosystem has changed a little bit however what\u0027s a little bit interesting is when you look at the health of measurement site because when you look at passive measurements this is again the results of a year ago a year ago we had about 30 percent of connections already contained and a city what you can see here is that most of these contained a city in the certificate though there is also a significant amount of cases a sativa sent by a TLS extension or CSP is a little bit he said the what\u0027s interesting is who chooses to send the city in a tie let\u0027s examine at least last year this was mostly Google and I think there might have been another big site that does that we assume that whoever chooses to do this because if you send the scientific a time stamp as a tail as extension you can basically choose if you send it or if you don\u0027t send it so if you have a mobile client connecting to your site and the mobile client does not send the I support sends a CT "
  },
  {
    "startTime": "00:18:07",
    "text": "extension and the connection you can just skip sending the few hundred bytes of data and they are not contained in the certificate either which might make your hand shake a little bit faster on the other hand if you\u0027re flying the process you can take it on the into the handshake and just send the data and you don\u0027t really lose anything we redid this measurement tool um a few months ago and what\u0027s kind of interesting is that this actually hasn\u0027t changed all that much it\u0027s about 32% of connections now all that contain an SCT but it\u0027s still not massively more we expect this to change rather quickly because our measurement was done basically when the comb changes started to go into effect but they don\u0027t go into effect for all certificates only for new ones so the certificates have to first time our for us to see big changes in any case um how does this look like in practice so if you using go back home and go into a development mode you can see the certificate transparency it pulls that transferred here on the right so in this case we have a certificate that has a bunch of valid polls both in the certificate and sent via the TLS extension this is another case that we found for a paper in which two cities were sent in the TLS extension and both of them were invalid and why we did our measurement again in 2017 we found one five certificates for which this exact case happened that because an invalid Wolf\u0027s and where the tls extension and ninety one of them from issued by let\u0027s encrypt and why we don\u0027t exactly know why this happens we have a suspicion and our suspicion is that back then let\u0027s encrypt wasn\u0027t quite that while used as today and we assume that this is earlier that at the post that are actually interested in security and back then let\u0027s encrypt did not automatically submit the certificates to certificate transparency those people who wanted to tie certificate transparency so what you do is that you said it up yourself you send your certificate to a certificate transparency lock so I get back the signature and put that into you about server configuration so that it sends the SCT back to the browser and then after three months you have to change out your certificate and at that point it\u0027s easy to forget to update the configuration of your web server and you send outdated post we also found one certificate back then that embedded an invalid signature in the certificate by bypass we contacted them back then and I\u0027m blanking on by what exactly happened it was one of "
  },
  {
    "startTime": "00:21:08",
    "text": "their yes what they did in that case is that they issued a certificate for if age I know and for some reason something went wrong during the issuance process and they didn\u0027t actually give the certificate to the web to the people and then they issued a second certificate and included the pool for the first certificate that they generated so the time stamps or something like that but different between the pre certificate and the final certificate via redid this measurement for our for the paper that\u0027s going to be talked about tomorrow and this year found sixteen more certificates their invalid signatures were embedded into the certificates by four different CAS I think it\u0027s kind of interesting writers happen in each cases because in each case it was a different reason but they all kind of a similar so one of the CAS was two years in error they in this their case it was a inter it was a test certificate on one of their test servers and that they had set up and was happened is that like a year ago they created a certificate transparency test certificate before they started doing giving those to customers and then after a year they renewed the certificate and when they renew the certificate they did not remove the old SAT extension before they submitted the certificate to the lock server and the log server created a signature that also included the old sct\u0027d which obviously you don\u0027t have when validating the new certificate Global sign had a few certificates in their case it was if you included IPS and as an eye.the ordering between pre certificate and final certificate was different and it wouldn\u0027t be validated details had till as extended ordering differences between betwee certificate and Trenor certificate and net lock Hungarian CA actually had a few random fears being different but that being said at this point there were basically millions and millions and setteth of certificates that were issued that did all of this correctly and all of these were kind of extraordinary cases that they did not see very often so from our point of view the deployment actually worked very good and they were just a few handful of special cases we contacted the CAS and they replaced all of the affected certificates so and our people you also took a look at log operators both active and passive this again is the data set of a year ago especially both the active and the passive side look a little bit different now like the Simon tech log and passive traffic it\u0027s I think it\u0027s like 50% and the Google Docs are also a little bit low and it\u0027s more distributed because there are more different walks now one thing that the AUSA found last year "
  },
  {
    "startTime": "00:24:09",
    "text": "that was kind of interesting was this kind of certificate that was back then issued to transponders on amazon.com I don\u0027t think that exists anymore what they did is that Simon tech I think had an interesting idea so one of the problems of certificate transparency in some people\u0027s eyes is that it makes the certificate public that means that all the host names that the certificates are valid for the public and they are apparently a few people that back then wanted to hide those host names from public and Samantha came up with a way of basically putting him instead of putting the full house name into the previous certificate they put I think a question mark into the pre certificate and put out a document that basically said that you should expand that and just accept any domain which I don\u0027t think any pearls recognized and be found a actually number of those certificates during our scans and if you try it accessing them back then in chrome you got this nice certificate transparency required um our message because home already enforced certificate transparency for Simon tech back then he also found another really interesting thing so and this is one certificate that being counted during our passive measurement on the right and but you can see it down here is when you pass this certificate of OpenSSL it says CTP certificate ICT and then it says a random string goes here so the first thing that I thought when I add this is okay it\u0027s among didn\u0027t implement this in open SSL so let\u0027s look at the actual data and actual data is all the extensions I think how ordered as mock testing and if you decode that Octus thing manually you see that actually that the certificate really contains an utf-8 string that\u0027s just States states random string goes here so for comparison this is how it is supposed to look like so the interesting question is why so this took a little bit of digging and we actually never found out the entire reason but basically the certificate claims to be a certificate is valid for cloud hunt but net we found a similar ones for Twitter dotnet twitter.com I think we found like three hundred something for platform and like sixty four Twitter and those were not valid certificate so this certificate was not actually signed by Symantec it was just a exact clone of a real certificate that was issued to cloud phone so someone copied the serial number issue a subject and all the exemptions besides the pre certificate the certificate transparency extensions which they apparently couldn\u0027t handle and just what release to do anything about and I assume this was two sites the firewalls and network monitoring devices because if you don\u0027t perform "
  },
  {
    "startTime": "00:27:10",
    "text": "certificate validation and this looks exactly like a cloud phone certificate and connections also didn\u0027t go to cloud from the connections went to some servers in cloud hostess in Africa I remember at quality so I think someone really wanted to hide for reasons that we were not able to determine so we also looked at other things besides certificate transparency we looked at age HSTs an HP KP back then we found that HSTs was used by Apollo the earth switch three point five percent of domains and most people that used it used it correctly there were a few misspellings HP KP was used by not that many people just over six thousand five forty one misconfigurations as CSV so the for awake as psycho suite which is automatically deployed when your software supports it was used by more than 96 and more than 96 percent of connections and there isn\u0027t that it was only 96 percent is that IAS doesn\u0027t support it what didn\u0027t back then so one of the interesting things we did in our papers that we basically looked at all of these different security mechanisms and we analyzed them King at the effort it takes for the end-user to deploy a mechanism and availability us and one of the things that we noticed is that unsurprisingly things the low effort or no effort in best case deployed kind of quickly and kind of commonly and the other thing that we noticed is that things that have higher risk also tend to be deployed less often than things that have lower lives and as you can see it so things like the SES we have basically no effort analyst certificate concurrency via ex-59 also has no effort on the user side that as certificate authorities have to do something and no availability us and those are deployed quite widely HSTs also has a relatively low effort and relatively low risk can be still see kind of a big deployment the thing and gets interesting is for example HP KP which has high effort and relatively high availability and relatively shortly after our paper was published actually comb an ounce of common nouns that they intend to duplicate in a move public key pinning support which I think they\u0027re going to switch off in chrome 72 which at the moment is in the canary build and will be released in a few months so this basically supports our thesis that we aired in the paper that if you want to design a hotel call us something "
  },
  {
    "startTime": "00:30:10",
    "text": "that someone should actually use and the end it\u0027s kind of neat if you make it a low effort and if possible also lowers but if you can\u0027t have a low effort at least tie to keep the risk of using it a relatively low if you want it to see being deployed we also had a bunch of community contributions in our paper so one of the fun things that we did is as I mentioned at the moment at the beginning we had a shared pipeline between active scans and passive scans and we actually put the peak apps online so if you\u0027re interested in a PK of span of 193 million domains you can go to the UL that is on the slide and download it it\u0027s a little bit big we also published active scan Lisa as we publish the database terms of certificate transparency that we use and we publish the analysis scripts that we used for the paper and also the software that was used to do this okay and now I\u0027m going to talk a little bit about our follow up work that was done later so this is a new paper that was published at the internet measurement conference 2018 so just a few days ago and that will be talked about again tomorrow I am actually not going to talk very much about it I\u0027m just going to talk about things that have a tiny bit to do with what I talked about already one of the fun things that we did in that paper is we created a honeypot for certificate transparency what that means is we were interested if you put a certificate into the certificate transparency with again a host name that could no one could ever guess how long do you think it takes till someone connects to the domain the answer is between 33 seconds and 3 minutes so people are watching this and to try to connect to you afterwards and you get requests from kind of a lot of people and another fun result that you got is that now that you have a list of all the main names you can look how many people try to fish the mayor common domains like for example epic for which she found like 63,000 fishing domains and if you\u0027re interested in to more the size of that paper go to the session tomorrow another thing that I wanted to talk about a little bit is the xes notary so one of the reasons I have been doing a lot of SSL research over the last few years that and one of the reasons that this paper was possible is that back in 2011 we started a project we were interested in how SSL is actually being used on the Internet and what we did back then is that we started a measurement effort with several universities mostly in North America that give us information about their outgoing SSL session so basically all of these people are using a network monitoring software that is actually "
  },
  {
    "startTime": "00:33:11",
    "text": "just changed name and there\u0027s now called seek like then it was called bro and we give them a little script that generates information about every single assertion that\u0027s outgoing from the network and they send that to us for stored data evaluations and to talk a little bit about network monitoring soft if you have not heard about it Sikh is an open source network monitoring software that basically looks at network traffic converts healthcare protocol analyzer converts the network traffic into events that are completely policy neutral and then you have scripts that you can write it into a domain-specific scripting language and it also ships with a standard library and you can do stuff like intrusion detection but not the ability management final analysis for and our case traffic minute measurement for research and this has been a research project from the very beginning so this was started in 1995 Kevin Paxton at the Lawrence Berkeley National Laboratory and a number of academic publications came out of it and it has been financed by a lot of NSF grants over the years and the way in which views that if you have like this l handshake here is that bro gives you events about all of the different as messages that you get and you basically attach to those events and harvest information and then I would put one log line for each connection that we see and hoe nowadays hand is a whole bunch of the different TLS exemptions that we actually see being used in practice so back to the notary this has been running since the end of 2011 and at the beginning of 2012 when he started look at the measurement data he noticed that there were some packs in the software and that we were doing things wrong so we threw away everything inside the measurement again in February of 2012 and it has been going on since then and that we are collecting are things like the cipher suites that are sent by the client the cipher suites that are selected if the connection is is successfully established extensions that both server and client support and the exact content of some of the extensions and the certificates if you are speaking TLS smaller monthly and so on so we collect basically a whole bit of a bunch of information that we think is interesting on the other hand we try to make this retire to respect people\u0027s privacy so we are not really interested where a specific person is surfing to and because of that we don\u0027t keep playing IP addresses we keep hashes that assorted that allow us to tell them the same client is connecting to the same server that so that we can see how effective sessional assumption is but we cannot see when the same client connects "
  },
  {
    "startTime": "00:36:14",
    "text": "to the transfer of us over time so this is a graph that shows the amount of connections that we get so basically we get a few million connections per hour by our different sites at the moment we are at a little bit of 300 billion total connections that we have observed we have more than 45 million certificates now those jumps that you see in the graph mostly people at one of our contributing institutions that do an active scan of the Internet which then also shows up in our data and also in the last few months the amount of new certificates that we see generally seems to have increased so know that I\u0027ve told you about the node really let me tell you a little bit more about another research project that was also presented at I and C this year that basically uses this data set and takes a look at how tail has changed over the last five years and I\u0027m not really going to go into too much depth about this but if you interested um then look at the paper and this was done together with people at India Stony Brook University the oil Holloway University of London and what we did for this paper is basically the big idea was that have been a lot of asses el ataque since 2011 and we were interested that the publication of these attacks actually caused changes in the ecosystem so after an attack became public or was published in academia the Internet traffic actually change in any significant way and one of the fun things that we looked at is how do they negotiate it as virgins change over time and this graph just flow and plots the tilith versions that we see by finally being negotiated from SSL version 2 to TLS version 1 2 over time and what you might notice here is that we when we began our measurement TLS version till as Fangio already was the most commonly used TLS version however what you might be aware of is that our measurement only started in 2012 and back then till as one two already had been standardized for five years so TLS one to were standardized in 2008 and he has one bond had been standardized for seven years or so so tillis on one-off standardized in 2006 until has one to only managed to cross this threshold of being used more than till as one zero in mid-2014 I think well towards the end of 2014 and why we see a small spike of till as one one it was never really an used much all that much on was unused for a short period of time one reason for that is that I think "
  },
  {
    "startTime": "00:39:14",
    "text": "a lot of software especially open SSL jump from supporting 1 0 to supporting everything up to 1 2 without the intermediate step so there was I think no version that supported upon one and not don\u0027t - another interesting thing and they changed a little bit over time is the amount of export anonymous and null serve cipher connections that over time so back in 2012 a lot of people were advertising especially export ciphers and export ciphers were not really necessary anymore since the middle 90s if I remember it correctly and I assume that a lot of people did that because of the default of their software and didn\u0027t actually really want to advertise export servers and clients to be able to choose export ciphers and this has become better but as you can can see the progress was kind of very incremental and it took a vile mal servers are also kind of interesting though in our case for the networks that we are monitoring their actual kind of use for uses for not ciphers and one of the reasons why we see this isn\u0027t used a little bit is that they additionally I used for the WP connections because the FTP connections are big data transfers of scientific data where the scientific data is not really private but you want to authenticate yourself to the Eleonora you are sending data to it so you use authenticated TLS with a null cipher another one that I really really liked is this one so this is negotiated static as a versus forward secret connection types diffie-hellman and if a melody fisherman and FMLA he seed the fireman and what you kind of can see is that there\u0027s this one line in 2013 from which it seems like people stopped using static key as a bad match oh that was a slow but significant decline over time till 2016 and what happened then was that Edward Snowden came out with his revelations so we are just observing what is happening and we obviously cannot say that that caused this change but it\u0027s at least kind of peculiar timing and in the paper we did a whole bunch more studies where we looked at exactly which life has changed how like for example rc4 or how authenticated encryption is use how much authenticated ecolution is used and if you interest it read the paper and I was about to give a little bit of information about teal as once we use so I don\u0027t actually have or too much about that but you basically started implemented support for teal as monthly relatively early on and I have a few "
  },
  {
    "startTime": "00:42:15",
    "text": "statistics that are kind of current on how it\u0027s being used at the moment so the first one is connections where we basically see the client supporting it in this case measured by the client sending the supported versions extension I have not actually looked into the extension for this measurement we have that data but it\u0027s a little bit hard to access at the moment because of the way our databases are organized but basically what you can see is that the moment that home pushed out there update that enable TLS one free for everyone which was in March I think is monthly for everyone you get up to 35 percent of outgoing connections that we see that signal support for it on the server side things are a tiny bit different but it also see something between four and five percent of connections that send this extension on the server side which probably means that they negotiated TLS one three at the end okay and with that I\u0027m actually kind of at the end so to give a summary mostly about the paper we found out that deployment status correlates with configuration effort with the risk of deploying something and that if you make something that default its deployed it\u0027s commonly deployed most vilely one of the things that I actually forgot to mention earlier is we did all of our measurements from several sites so we had active scans from two sides and passive scans from three sides and in this case that actually didn\u0027t help as much because we basically found out afterwards that there are tiny differences but nothing significant and if you want to dig in what exactly is different you typically come to the point in the end where there\u0027s a CDN or something if some reason it served up slightly different results for that one of mine meanwhile you were scanning and so in our case doing distributed measurements from several sites made the effort like three times as high as it would have been just doing it from one side and did not really get us any more results besides being able to say yes it looks the same from every and with that I think I\u0027m open for questions hey my name is Otto Singh so my question is did you also have two questions actually one is is this reflective of only North America or across geographies do you think there will be a difference and the second question is did you also look into the certificate types and the key sizes whether EC certs are picking up and if RSA is still the you know is still more popular than what are the key sizes if you have some comparisons so this is mostly North America v we have some "
  },
  {
    "startTime": "00:45:19",
    "text": "people contributing from outside North America but I am not at liberty to say from there because the size the contribute data to us want to stay private but nearly all of our data\u0027s from North America so I cannot say how if it would be significantly different if you get it like in Asia and to the certificate sizes um we could look that up I admittedly have not looked in recent memory like when I looked a year ago nearly everything was as I said my name is Elizabeth of - you presented three ways of basically showing your SCT proof yes as I understand they are not mutually exclusive any data on how many do several ways always so ah actually yes we have the problem is that I don\u0027t quite remember the numbers and I will have you look in the papers so from what I remember there is it\u0027s kind of unusual that sides to both simultaneously this is was in 2017 and if they do it simultaneously it\u0027s typically via the TLS extension and via the certificate there were like two cases in which OCSP was used simultaneously if something is wesford occur it is a fantastic work you know this is this is great to see my immediate reaction is okay well how can we translate this into you know helping deployment and you\u0027ve answered some of that as well did you look at so now switching to the question side did you look at other usages of TLS besides web you know did you look for certificates in other places so the answer is yes we do so our measurement so basically how the network monitoring system works is that we attach ourselves a few ports like four four three that are very known to speak to us in addition to that you basically have a regular expression that we match to the beginning of every connection that should be able to catch or TLS connections and then that a regular expression matches the beginning of a connection that basically tries like does this look like a client hello or a there was something else that you can send at the beginning of a connection issue really want to then it just shoves it to the TLS analyzer and the teal as unless authorized depositing either says yes the CLS of Avery and we actually have written papers about him as on other parts there was one paper and users I think two years ago where we looked at TLS for communication protocols like email XMPP and so on back then it was deployment was worse there and for HTTP okay you may want to talk to the victor to Kevin II from to Sigma "
  },
  {
    "startTime": "00:48:20",
    "text": "who does a a Dane survey for for mail in particular and has a large quantity if he\u0027s controlled large parts of the internet looking for TLS on the email site and he has a large number of hosts that you may want to query and pull down their certificates for I can put you in touch with him later if you want he and I actually joined the publish web site stats DNS SEC - tools org that actually lists Dane usage and shows the upper graphs of that and I suspect that you can pull in a lot more data by talking to him Christian Rita ma hey I like these measurements and I like the idea that you can measure government from traffic yes do you don\u0027t you have a small point with here as 1.3 again please I just didn\u0027t quite get I am a lot of the data that you analyze well sent in clear text in the Sigma in the cell flight in theorist 1.2 and below and are encrypted interiors one point wins because it makes my work for doing these measurements but I understand why this is being done and I basically take this as an opportunity because we see the on-ramp of a new version of the protocol and we also get to see all the stragglers over time and who doesn\u0027t update so it\u0027s kind of interesting stead okay and speaking about that I don\u0027t think that I forgot they\u0027re actually already looking at the data of the beginning like until s1 3 was experimental is kind of fun because you have that supported versions extension and from my point of view it\u0027s kind of interesting but everyone sticks in there because why there are the obvious graphed values like I support Hill as one fleet of 28 or something like that Google had their own values that they used I think they started with Vaughn II and they used it for stuff that was kind of teal as monthly but not really and I suspect Facebook also had some because we saw a bunch of them started FB I didn\u0027t actually look if the collections terminated with Facebook but that\u0027s always a good guess so you see interesting things hi I\u0027m Jill Malhotra and my question is it\u0027s maybe just I just missed something in the presentation but what does the risk factors here and the deployments that I might not have explained it more clearly enough so the risk factors mean for example if you let me go back to that if you have something like HTTP public key pinning if you miss configure that too or you lose access to the key "
  },
  {
    "startTime": "00:51:21",
    "text": "that you specify you might lock yourself out of your own domain so basically web browsers might refuse to connect to your domain because the key of the certificate that you are serving doesn\u0027t match anymore and you don\u0027t have access to that anymore and that by oles us in theory you can set something like cache this information for a year and have a certificate on there and it works for a bit and then you lose the key and don\u0027t have access to it anymore and get a new certificate and people that have your old pin save very refuse to connect to your site until that years up so that\u0027s high risk factor in that case which is HSTs you can it gets much more lower because the only thing is that you need a valid certificate that\u0027s easy to get yeah you have near a former website where we standardized HP KP and the thing is once browsers record that your your key should be this once it\u0027s different they\u0027re blocked and they\u0027re blocked for months yeah and there\u0027s no way you can remedy that\u0027s other than push not be to Chrome in the via browser so that never caught on because of this yeah this is more of a comment I feel spk p and CTL the certificate transparency list they\u0027re sort of competing programs so Google decided to pick one eventually and that\u0027s why CTL picked up and they decided to decommission as pkp that says I know so I\u0027m saying of the two I think that they picked up CTS okay well up one more question Matt Ford I was kind of surprised by your final point that you didn\u0027t you didn\u0027t expect that having more diverse measurement points or vantage points would lead to a greater insight or more divergence I wonder if that tells us something about the way the network is being used so it might solve what\u0027s generally kind of interesting is when you compare passive measurements to active measurements because then you see a huge difference because active measurement basically you see everything that exists on the internet more or less on passive measurements you see what is being used and one thing that you might have noticed is that we have like 45 million certificates in our active data set and our passive data said no but you might be aware of is that when you do a really full scan of the Internet just once at this moment you already get more certificates and like for the first few years when we didn\u0027t have anyone actively scanning we were like at two or three million certificates so the amount of sites that people actually do surf to or to access is much much much lower than what\u0027s actually available so if you "
  },
  {
    "startTime": "00:54:21",
    "text": "just want access can you get a hugely skewed picture of what\u0027s going on in the Internet and what is also really interesting is like when you do an active scan of the Internet you at least in the past you found a lot of servers with not so good configurations or choosing sizes weeds that are not really that great and if you look at the passive data again tons and tons and tons of people go to Facebook Google and the big CD ends and like 80 90 percent of your connections use from now at today\u0027s point of view perfect security yeah and then you have a lot of weird stragglers that you partially really bf when you start digging into things you find things that you find like one connection in your data set that used a specific random type that you have never seen before but I think you get a little it\u0027s from a vantage point we\u0027ve not really seen a big difference but if you compare pest measurements with active measurements you get a completely different point different view from what is going on in the ecosystem at the moment okay well thank you very much [Applause] okay yeah thank you all right blue sheets we\u0027ve got heads does anybody need them and does anybody have the other one okay um is there any other business oh I think we\u0027re done thank you thank you [Music] [Music] "
  }
]