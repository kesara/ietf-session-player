[
  {
    "startTime": "00:00:06",
    "text": "Thank you well, uh reserve that for the 80 So I wasn't in. I wasn't in so this is my first time with Gunter as our AD Everybody knows Gunter, I assume, from other, you know, route working groups and over the years. Put your hand up in case in Good money, everyone Welcome to the LSR session. So now it's 9.30 and let's get started Our agenda is relatively light this time, so that will allow us some discussion time during the process Without overdue let's guess started. So I will do the status report first So note well it's Friday, so by now hope you all see If not, please read it And we have one RFC public since last IETF, the OSPF, V3 extended LRIC advertisement, Young Model So this one will remove a lot of debate"
  },
  {
    "startTime": "00:02:00",
    "text": "dependencies we have for the other models because they will be augmenting this one and so we'll be able to progress several of them them and we have two new drafts that move to RFC Editor Q during this period And we have the area proxy that's still there. So we have the two flooding reduction draft that moved to editor Q and we have one draft that submitted to IESC for publication and it's going to be on the territory on August 8th Thanks for, thanks to Tony Lee for writing this and we make sure the process is recorded on paper and the chairs did accept the challenge raised by some people and we did it And we have to jobs adopted First one is, of course, already not only adopted more to IES for publication So the second one was adopted after last IETF and we have three working groups last call The admin text, Bruno sent us some very good comments and the authors are call. The admin text, Bruno, sent us some very good comments, and the authors already have published a new version this week after the window is open after the Datatracker is open"
  },
  {
    "startTime": "00:04:00",
    "text": "so we want to make sure all the issues are addressed and then this will be submitted for publication The multi-TLV, we still have a pending response from there IPR response from the outsource, so we can now close the last call yet. So we'll do that when all authors respond to the last call And the flexor the last one, they are still pending comments to be addressed by the author This week there's an email thread on that so I expect it next week, Pete. Yeah, still wait, we are waiting for them to get all the open issues read out before we move to the next step So they also, um, I think this has been going on for a while so if the authors can just resolve the opens without the open. Yeah, they responded just, yeah, so it should be be And so we have these two jobs in the last call, ready state, so in the queue for a while because this one, the OSPF with SR model. It also includes OSPF with 3, so that has dependency on the extended LSA Now we can progress both of them And this one is also in the last call queue So if you want to give a review, this is the time to do it And we have some other existing Young Model documents There will just be"
  },
  {
    "startTime": "00:06:00",
    "text": "further refined and then in the queue for a lot call. No hurry for them yet. Probably the SR6, the tool for SR6 will go first So for other existing working group documents um at this review one will be on the agenda Tony P will do an update the optimal distributed flow will be on the agenda. Tony P will do an update the optimal distributed flooding for dense topologies And so all others will let them cook Yeah so that's pretty much the of them are actually newly adopted They haven't changed much since the adoption So hopefully the authors will continue to work on the job, refine them solicitate feedbacks, progress them. And then, so we have two jobs, well, not two so the peaks actually right now include three documents We added one more module for the layer two member attribute rfc a six six seven forgot the number, but anyway, so the we'll do an adoption call for the PIX Young model first, and then the authors of the Flexiago with link loss also requested adoption call That's it That's how I have. Any comments? If not, we'll go to the first presentation That's you, Tony"
  },
  {
    "startTime": "00:08:39",
    "text": "All right, so this is basically an update on this top of flat stuff which has been adopted, has been around for a while Larges update Let's run through it So what's new? We have basically fully list of co-authors now. Lots of further discussion, you know with service provider, other customers And what came out from discussions with other various and customers is that we integrated the new requirement into the draft. So let's roll back. So the previous version of the draft was basically the algorithm without any signaling. Like, you know, switch the new network Stuff will work It doesn't need anything centralized as though you don't have any kind of blast radius beyond the you know single node that you installed the network, maybe re-computation of the tree in most extreme case kind of blast radius beyond a single node that you installed the network, maybe a recomputation of the tree in most, you know, extreme case. Did it need any configuration? And you can put it into the network node by node right? So migrate into the network. And implicitly, there were already two algorithms in the network right? Because the standard ISIS does all the flood with reduction, namely none, right? Because it floods on all the ring"
  },
  {
    "startTime": "00:10:01",
    "text": "So the new requirement that came out was that people think that it would make sense to have more than one algorithm at the same time on the next network. Don't ask about my opinion And the scenario would be let's say you deploy the stuff and the stuff is a buck. So you need to roll another algorithm. You have two vendors right? And consequently, what it dragged in was a the signaling, because now you have to indicate which algorithm and node runs That stuff doesn't work No, doesn't doesn't Well, now it started Okay So, it helps to understand what's going on If we introduce a simple concept for we introduce a simple concept first, which is a well-known graph theory thing. Nothing I invented right? And this thing is called an edge-connected dominating set, or CDS, for short So what this thing basically is, is a set of edges that touch all the note on the network, okay? And any pair of the nodes on the network can have a path right? And if you see the topology below, it's actually there's multiple of such things that exist So the red ones and the blue ones are pretty much you know, largely disjoint, but they all of them have a set of links to touch all the nodes and all the notes are connected And that's basically what the fluttered up reduction algorithm, no matter what it is builds okay um these CDS does not have to be loop free, right? I was here making for a very nice picture There is a loop-free variant, but we don't need it Right. Now, why is that in"
  },
  {
    "startTime": "00:12:01",
    "text": "interesting? Because if we start to talk now about mixing algorithm, each algorithm that is introduced no matter what it is, will be of the CTS in a former of fashion, because otherwise flooding will be broken, okay? So if we are signaling, which algorithm runs on the network we can actually figure out a component which are all the nodes over which you can build the CDS. So the thing is like the nodes that are close enough running an algorithm that you can actually run flood reduction over them. So we call over such an algorithm. So this component are basically the nodes that run the algorithm. I know there will be a picture later, but bear with me So like I said, each algorithm builds a CDS We call it a star, don't worry too much about that And the default ISIS is actually a special case without signaling and which implies that the flood reduction, the CDS, is basically all the links just to give a framework when you start to talk about the stuff later. Okay So we introduce something we would call it prune which is like any algorithm that does flood reduction And what we say is that obviously it forms the CDS but we put another restriction on it, wherever it touches a component with another algorithm, it has to flood over this link all right Like I said, this is graph theory 100 years These people are 100 years dead if you want to complain about the stuff. So a pony for a picture which will become much clearer, right? So what you say? here is these components. So the Z we used to denote standardizeize And you see that the same algorithm can build multiple components So the A, those two components are disjoint. But I call them not components and not partition"
  },
  {
    "startTime": "00:14:01",
    "text": "because partition implies that it's not connected to the rest of the graph So those are components. That's a correct term So you have this A prime and the A double prime and you have three standard islands right? And you have this B algorithm And now what you see that within each component, they will build a the, you know, CDS, which, how they do it is irrelevant. And the pruner restriction means that all the black link have to flood. Now, what does that mean? It basically means that we're building a CDS of all the CDSs And that proves that the whole graph will be covered by flooding okay, in a fully distributed fashion. We can talk about you know at the end I'll talk a little bit about what could be done but I don't want to do it and I don't think it's a good idea. Okay. So and the rest is almost trivial. So there is a TLD with algorithm number and now notes can obviously change the algorithm and join another component. And the biggest impact you will see is that you will have two components we compute the cds join another component. And the biggest impact you will see is that you will have two components we compute the CDS, which is like, I think it is necessary and sufficient. You cannot do it more efficient okay and because the Z, so the standard ISIs is a very well-known behavior, a pruno is also allowed to play tricks with the fact that it actually join adjoined to a Z And I give you an example, look at the A and the B, A double prime and the b and the z triple prime and you see this triangle so a and b could figure out i know that the z triple prime will always flop through the two links. So I actually don't have to flood on the links from a to b so those tricks are allowed right so in the sense it's relaxed. You can play tricks with the fact that you know how the normal ISI"
  },
  {
    "startTime": "00:16:00",
    "text": "works. But this implies by the dark link that you're not doing that. No, I just say it's allowed, but the way the pruner is defined is you touch a component with another argument you flat over it. That's the, that's, you know, the normal requirement. But we've seen cases where you can be small Do we recommend to be smart? Well if it works And that's pretty much all. So now the last trick question is you go if you look at this stuff, it's recursive. So you say, funny enough, the black links the fat links are also CDS. So now we could also prune it. Yes, we could right? If you look at that precisely But the problem is that then we within a component, you would have to synchronize the edges right imagine the a goes look the whole thing is a circle if i for to B, the thing will come all the way around it would but now the one edge of A has to talk to the other edge of A and they must run some kind of election saying, no, you flood and I don't And that will become very heavy and it can build Hamiltonian cycles So in clear terrors, all of a sudden you may end up flooding all, you know, three ways around the diameter before you actually get the flooding done. So that's why it's not a good idea before anybody asks. And that's pretty much older is to it. So we introduce signaling I introduce the concept of a pruner right? So anybody can implement the stuff, there's registrate, just the usual, you know, machinations But it's about it. So that allowed to migrate algorithms and change the you know, the algorithms at any given point in time in and out of the network without any flagged ace or, you know, configuration or centralizing sense or anything like that. Yeah I'm good"
  },
  {
    "startTime": "00:18:03",
    "text": "Sorry, yeah, exactly I was looking for, sorry, I'm sniffling Thank you. les ginsberg. I have two major comments The first one is you've, so you have two parts to the latest version of the draft. One of them is defining a flooding algorithm a stop flood as it been called And the second is defining a new control mechanism to determine how these flooding algorithms are enabled. These are logically independent. I would really like to see this presented in two separate drafts I see zero value in that at this point in time so if I have generating more red tape delay value in that at this point in time. So if I have... Is there any reason that dist up flood couldn't be enabled by a different control mechanism? and you know the there's nothing preventing draft saying, use this algorithm with this control mechanism and reference this draft okay I'm just saying architecturally, to me, good software design et cetera, et cetera, is these things are logically independent I should be able to enable any flooding algorithm with any control mechanism and any control mechanisms should support any of the flooding algorithms So to me, this should be presented separately My practical customers have zero interest in that They want an RFC with a distributive plan because of the requirements that I mentioned that we met Otherwise, there wouldn't be even disrupt, correct? And they're perfectly happy with the default algorithm because they don't have to chase seven drafts. And at the end, end up with seven vendors having 12 different algorithms that they can actually interoper at all because it's already actually clean"
  },
  {
    "startTime": "00:20:01",
    "text": "well frankly i see no value well i don't think we know where the marketplace is going to go in terms of a control algorithm. But anyway, you understand my comment my second comment has to do with the new control algorithm, which, you know, as you've indicated potentially allow multiple optimized algorithms to be enabled in the network at the same time Speaking as someone who, like yourself, I'm sure, has had to debug flood problems in a live network It's difficult enough with the one algorithm that we have today We've already made it more difficult by allowing one optimized flooding algorithms to be run in the presence of legacy nodes that are still going to use the standard flooding algorithm I do not want to deal with a network that has more than one optimized flooding algorithm. It'll be a nightmare to debug. And I'm fully there with you. And so this is the last thing I advise, but having talked through the stuff with customers, you will end up in this scenario if you find that you deployed some I advise, but having talked through the stuff with customers, you will end up in this scenario. If you find that you deployed something that has a problem and you have to migrate to a new to a algorithm. You'll be in exactly this picture, whether you wanted or not So, you know, I don't recommend them like run for different you know different algorithms and debug them because it's hell, no discussion, yeah, it's bad They basically tell them, look, here's the default algorithm, that's how the stuff works It gives you the option in case the stuff doesn't work on somebody comes with some dramatic five x improvement to roll another algorithm on the network. Well, with extreme likelihood never happen and that's also although the architectural thing is exercising red tape for me at this point in time well okay so just in summary um i have no problem with the flooding algorithm itself I've supported that in the past I continue to support it I find it difficult to support the new control algorithm"
  },
  {
    "startTime": "00:22:00",
    "text": "Which is partially based on your comment that the stuff sucks because it doesn't have it. So, you know, it's confusing Anyway, so no technical comments as far as I see the stuff is working, okay? That's what we're rolling. And so far you know, I have all the customer requirements fulfill fulfilled It's a difficult technology no matter what. So it's the last thing I recommend before the even least recommended, you know, fast flooding So normally, you know, architecting network properly and looking what's actually going on and configuring properly even at very large scale there is not really a justification. But the algorithm that is suggested in the draft has a nice property that it connects actually look at the graph of a customer and see by deploying a few nodes how we could actually reduce the fan out on flooding very significantly in hotspots So that's roughly where the discussions are going Build the tooling to analyze the topology unless it's a fabric, clear, right? But on large networks, you basically go and look for hotspots and you throw a couple of those nodes that basically start to reduce the very hot spots And it normally takes very few nodes. So it's not like you have to roll the whole network onto this stuff. So that's the status of this thing Thanks you. Yeah. Any other comments? So tough you two are not really talking to the point I think Lise meant, you know, the working group document since it's already a working group document and the framework, the control framework, your idea is not within the origin"
  },
  {
    "startTime": "00:24:00",
    "text": "scope and that could be a separate job where did you do this scope? I didn't see in the adoption call a scope It's completely new context, concept to me, and if you look at about a hundred drafts that had a huge creep on what you call scope I don't understand how this thing makes any sense or how these procedures are being invented on the fly now So where was the scope? on the adoption call? Because I totally missed it. Don't even know the concept. I'm still solving the same problem and I got the new requirement. So what are we playing here? Procedural games? Hey, let's bring the heat down on this a little bit Tony. Right I'm keeping down already I think people have a valid concern. The working group adopted the docking and there is significant change to it so it's worth talking about. Good, so point me to the concept of a scope and that you cannot add a new requirement to a draft. And I bring you about 50 drafts and pick up new requirements and other things. Well, are you saying that you should be able to add anything to a draft? at all and no one can question it? No Because, okay, then that's what's going on. No this thing took a new requirement, and it fulfills a requirement. And we can talk about other drafts We're doing this stuff extensively Just look at something like fast flooding. Okay i'm saying people are asking for ISIS. People are asking a question and that's valid you're saying it's not it's not valid to ask it very dismissive of it. So let's at least talk it through right let's talk it through good so i don't see any value except more rat tape and possible content I mean, while the stuff will be deploying. OK, let's make sure the work group agrees with you, since it's a working group document That's all. Sure"
  },
  {
    "startTime": "00:26:00",
    "text": "the stuff will be deploying. Okay, so let's make sure the working group agrees with you, since it's a working group document. That's all. Let's get it sure the working group agrees with you since it's a working group document. That's all. les ginsberg again. So I think there's a legitimate process question, but that's not what I'm raising I think the working group has an interest in that, and that should be resolved. My objective is technical. Technical? yeah I don't make a single technical argument that you claim the stuff does not work? No that's a technical argument so the control algorithm should be able to support any optimized flooding and any optimized flooding should be able to run under any control algorithm And you may have a preference to put these two things together no for the deployment cases that you're thinking about but from my point of view these are logically independent. If I was writing code, I would not embed the control algorithm in the control mechanism in the flooding algorithm and vice versa. Yes, you wouldn't and so. But you know, that you think is draft. And if the object is technical that you cannot take another control mechanism and reference this algorithm this is absolutely possible You just reference this document, says, use this algorithm. That's my registry that's my number and if you want into this frame, we inject new algorithms, you just publish an algorithm document and you take a point in the registry And that will work perfectly fine I would buy your argument if you say you prevent me from adding algorithms or you prevent me from using this algorithm somewhere else. This is not the case Done will you back in Canada Is it possible, maybe to write what you have in mind in the list? because I have a hard time to follow the problem that you're trying? It's already there in the list? Okay So maybe we can take it from there"
  },
  {
    "startTime": "00:28:12",
    "text": "Yes, Gunther speaking here as with my routing AD hat on I just realized I'm sitting at the wrong spot. I'm too far away from the microphone here. So, you know, beginner routes AD, you know, mistake. So I just want to reiterate again what Chris was saying. So actually we are dealing with the working group document. That actually means that you know, the document is, you know, part of to reiterate again what Chris was saying. So actually, we are dealing with the working group document. That actually means that, you know, the document is, you know, we form consensus through the working group. It's not true really fully in the hands of, you know, the editor of this document Fully agree. Yep. So, you know, yeah so so yeah so that is where I think we should be going so we should form consensus and and yep. So, you know, yeah. So, so, yeah. So that is where I think we should be going. So we should form consensus and keep it like that and stay, you know, on the friendly note with everybody all right but my point is that I've never seen a draft or fulfilling a new requirement led to new consensus call And I would be hard to pressed to find an RFC with procedures that actually talks about this kind of stuff. Hey, Tony, it hasn't happened a lot in our... Sorry for breaking the queue. It hasn't happened a lot in our working group but if you followed IDR, there's been a lot of forced breakup of drafts for different requirements between non-agre parties. I mean, we haven't done it a lot So perhaps we should have because this has been brought up, perhaps we should just do a consensus call on not the new requirement but leaving them coupled. I mean, not, and I agree, they're not, they're not necessarily coupled the control make there are two separate things I don't but I, my personal opinion speaking as a working group member, is this is much ado about nothing, but"
  },
  {
    "startTime": "00:30:00",
    "text": "yeah, couldn't agree more Same thing else happened in the PIM working group with like PIM light you know having you know being its own document at this point in time Tony Lee Juniper MPLS co-chair In our working group, if there is a change to the document, we go back to the working group Even if it's an editorial change, we go back to the working group every time Yeah, I think the point is there is no problem with the draft taking on new requirements, but if somebody asks we should take a consensus call on that, I think. Yeah. Somebody asked them to split up that's what i'm saying exactly that that's all i was getting at was it felt like, Tony, like you were resistant to even questioning the validity of adding new things I mean we just have to, the chairs are going to have to make a consensus call on whether the working group is okay with it. That's all But let's not reject it right out of hand Let's do a show of hands to think of control framework should be in a separate draft? Thank you Yeah, if you have a log into if you haven't logged into the meeting session, please scan the QR code over there"
  },
  {
    "startTime": "00:32:00",
    "text": "so you can do the answer to the show of hands Tumall seconds Okay Go ahead. Yeah yeah. Please go ahead, yeah understand that Danvoi, Canada, I understand the working group fields as I watched the poll towards separate draft But just be mindful every time we split things in different draft is becoming hard and harder to follow from the receiving end And I've personally found, it messy. So I don't know unless there is a clear view of that. But again, it's working group I'm following the beat. I just wanted to be the comment to be heard Yeah, and by the way, the show of hands is just giving the chairs a feel for the room, right? This isn't a vote so we'll also take into a account what people's actual point are on the mailing list, and then we make a call after that on rough consensus This doesn't necessarily mean the result that we are necessarily mean the result that we will be taking"
  },
  {
    "startTime": "00:34:00",
    "text": "yeah so have a split down the middle or i think it's sort of in the middle or Oh, wait. I think it's south of you in the middle. Goody A.C. Lindum, I have one off technical, technical question. So for the for the flooding algorithm, I guess, you're using the links of LSPs to find the two hot neighborhoods of everybody Yeah. In ISIS, you advertise the adjacency right away so there's not any any neighborhoods of everybody. In ISIS, you advertise the adjacency right away, so there's not any point of missing anybody, whereas OSPF, you would have to you would have to help you know you don't advertise the guys that are in exchange, but haven't come full yet no you don't but you have a three-way it's not immediate Almost everybody runs three-way, right? So there is a couple things exchange before the adjacency comes up but that's but that's sooner enough so they don't miss stuff Well, you know, we have these PS&P stuff, which seems to work fine. I mean, we implemented the stuff, did a lot of measurements so the PS&P staff doesn't seem to kick in much, okay? But I mean, I'll have experience when the stuff rolls on really, really large net networks, which obviously takes significant time so no we have simulation at large scale and looks like no there is no problem there so you don't need to heal this stuff Any other? question? If no more question will go to the next presentation Still me, right? Okay, so that's a fairly simple idea We have"
  },
  {
    "startTime": "00:36:00",
    "text": "requirements to start to do fragment time stamping And what does it mean? Between me and Colby Colby so we see on large networks especially with traffic engineering, that the time timeliness of information can influence actually the quality of traffic engineer and we also need a lot of operational tools now at very large scale. For example, stuff that becomes more and more important is a flood delay across the diameter. It's a mixed diameter and things like deviation, all right, standard deviation on this kind of stuff The other thing that hits us is that if you have a very large TED database some of these parts of the TED database may actually arrive much slower than other parts And we end up optimizing into parts of the network where the flooding is behind And algorithms that can actually understand where the parts of the TET is flowing much slower in can do much better job, especially when you start to crank back on the congestion It is also a good measure for the stability of the network where you see when was the last time any of the nodes updated some something. Even better measure is to know how many times it up updated it, but that needs more of a tooling. But this that gives a very quick look whether your network is basically someone is flapping stuff very quickly, so reissue And bunch of other things So now, if we want to timestamp the fragments and shaft the stuff around, we need some kind of clock synchronization right? There is no way around that because otherwise things don't mean anything, right? So we don't need to synchronize stratum zero, but we"
  },
  {
    "startTime": "00:38:00",
    "text": "need some kind of a good feeling who has what quality of clock is available on a note that is issuing something like that. So basically, we suggest to carry a funky time feeling who has what quality of clock is available on a note that is issuing something like that so basically we suggest to carry a funky timestamp kind of handcrafted to what I ISIs need, practically needs, plus the precision of the clock that is on the node right? So what is the possible deviation? and yeah now comes pretty much, you know, the whole thing is a timestamp where we send seconds and we sent a fraction of the second which is, you know, we try to be really concise So four beats, which gives you a resolution of 60 million right? It's like one 16 of a second And the precision which basically tells you the same thing in terms of the clock deviations. So the maximum clock deviation is one second we allow or you have something which is all one basically means, yeah, this stuff basically doesn't have a particularly good clock And we use the PTP epoch, which avoids funky things like a leap year seconds, you know, the bloody sound not being very precise, how no earth turns around it but it is rolling over like 20, 30 something. So basically what we took is a PTP epoch and we bit offset it so it starts in 2020 or something. And the reason is that if somebody, has a really bad implementation, something goes really wrong, you want to realize that stuff doesn't make any sense he's sending something which was taking years before and that gives us an overflow in 2070 We're, you know, pretty soon I'll be pushing DASIS. So that puts it out of the scope of my work um that's it there's some discussions with customers and some of them won't better resolution I do not think anything beyond 20 milliseconds resolution does make any sense We do not specify what the timestamp means, right?"
  },
  {
    "startTime": "00:40:00",
    "text": "Is it the time the stuff ended up in the flooding queue? Is it the time? you generated? It is the time it has been scheduled for generation? So that already puts it into you know, a resolution beyond, in my opinion, 50 milliseconds as questionable. Otherwise, we would need LFA, right? But the discussions are ongoing We can add a bunch of bits and so on. But that's kind of, you know the idea I'd like That's all Hi, Tony Lee. Two comments First, I understand what you're doing with the time stand but from an implementation point of view, I'd really love to see something less funky I'm just dropping a Unix timestamp in would make me happier We will need fractions anyway. Seconds are not going to dropping a Unix timestamp then would make me happier. We will need fractions anyway. Seconds are not enough. So we end up in fraction and the Unix timestamp is actually very ill-defined in terms of leap years, lip seconds, stuff like that. That's why P are not enough. So we end up in fraction. And the Unix time stamp is actually very ill defined in terms of leap years, leap seconds, stuff like that. That's why PTP guys went to a different epoch I was suggesting down to nanoseconds. And yes, I really this overkill. But from an implementation point, it's real easy, right? That's my point Second point, I realize you're doing this for debugging. I get that It scares me because I'm not sure that there's enough text here to prevent people from doing other things with this No, I am. Oh, you mean that it basically makes the network more vulnerable? No, no, no, no, I'm not worried about vulnerability I'm thinking somebody's going to come along and write a feature and says that they have to look at timestamp for their feature I would very, very much appreciate it if you would put another section in here that basically says that doing that would be a re- really, really bad idea. I agree. It will be very ill advice. Yes. So please add more texts saying that Okay, yeah, that's actually a very fair point that the control"
  },
  {
    "startTime": "00:42:00",
    "text": "plan behavior on the routing protocol should not be affected in any way, but by the values of presence of the stuff. That is very fair. Yeah, yeah. Okay, we'll let it that. Thanks, Tony. les ginsberg So, to a full appreciate the usefulness of this, and I can see this is potentially useful you need to clarify that there's a use case directly on the router, because if you're doing this from a controller, the controller is going to have to retrieve the receive times on each router so while it's doing that it could just as easily retrieve the the generation so if you've got to use case on the router itself this makes some sense to me but if it's for a controller to use it does not. Okay so uh i thought you ask for an abstract control plane for it, but fortunately not, but I think you didn't rock it. So, yes, the controller can get that stuff and it's enough the control hooks up to a single node and get the links state database because this is on every fragment on the whole network and the clock is synchronized the the controller can relate to this clock and understands with what precision this times the may deviate from what he has synchronized as time If you don't have synchronized time on the network, in some reasonable resolution none of the stuff will work. No, no, that's a given But I'm saying the input you need to whatever use case you have requires not only the timestamp of when the LSP was generic but the timestamp of when it was received on the various notes. But you have to do a local router You also have a controller? Yes. No, you don't have it on the controller. Why not? You would have, you could you would have to retrieve it. My point is if the control is going to retrieve the receive time, it could just sit easily, as part of that, retrieve the generation time but if you're on the router itself"
  },
  {
    "startTime": "00:44:01",
    "text": "and you're trying to do something, then clearly you need the generation time to be advertised to know what it is so i'm just asking i'm not a opposing this. I'm asking you to clarify the use cases oh yeah so like I we talk about it I went to call me edit it's something clarify the use cases. So, like we talk about it, I went to call me, edit some text, and that's pretty much what it says here. Those are the use cases we have today. So the TED seems very prevalent so did you did you publish a new version or already? Sorry. Did you publish a new version already? No, I don't think I published a new version yet I just said that it, uh, did I? No, I have it in the next number. All right. But if you do, I'll look at it. But it basically says that, right. Colby said tad, more tat. That's what, you know that's where we see especially on crankbacks under heavy load That we basically go and try to reroute for a part of the network with We're so behind on flooding that we basically crankbacking like crazy for nothing um All right, I'll look at the updated text you know i have to i have to push it but it's really just two sentences i mean there's no real there's no real magic there but not there is an interesting discussion that also came up with customers having looked at that A lot of people like to consume BGPLS And how the hell you stick that into BGPLS is beyond Hi, so maybe the, I think reiterate what Les was saying and also I'll echo what Hank said in the chat room If you have a central controller, you can also be getting timestamps with NetConf or, you know, one of those protocols I think that's the point he was saying on if you need this on the router. If you're using it on a router, you don't necessarily have the infrastructure for that router to be going out and doing netcomf right like you would with a controller Um, I'm lost. What does it have to do with net? at all? Except, yeah. If you have a send centralized controller,"
  },
  {
    "startTime": "00:46:00",
    "text": "it's talking to all the routers. It can talk to the in lots of different ways, right? It can get the LSP database with timestamps and all that yeah ways that don't involve the IGP But if you're needing the timestamp, on a router, you don't have that infrastructure So that was, I think, Les's point about controller versus route use the two observations first one net netconv is slow as a peak. I mean, that's a show command right? Glorified. The second one I doubt that we'll do anything you see The second one, lots of people with controllers do not attach to every node They just consume one or two BGPLS streams so that get the link state database of a note or two. And that's it So beats me, I've seen really somebody deploying at scale, a controller that talks to every single node the network. Okay I want to echo Tony's point also I'd be happy with 64 bits and just you know like let's not screw around with weird fractions. Let's just do 64 bits and put nanoseconds in there. If they don't have to actually, it's doesn't actually have to be, you know uh resolved to the nanosecond but it's just easier Well, look, I mean, I tried to be clever and so those bites because you know it bites us all the time goes on every fragment, right? So yeah, I can do, we can do it 64 Take it to the list of discussion a little bit. Like I said, people discuss whether the resolution 60 million or something is good enough millisecond makes no sense I mean you can implement routing protocol at scale that does better than maybe 20 or 30 milliseconds It's also it's a I mean the interesting discussion is when is the fragment stamped? Do we have a clear point of implementation? Because between the database generating the stuff and the stuff making it out the box you know, at scale, there may be second And yeah, yeah, yeah"
  },
  {
    "startTime": "00:48:00",
    "text": "yeah, normal stuff And the other problem, because I was thinking like the really useful stuff would be when is it on the interface and being pushed out the box? But we couldn't do that because each interface floods independently right so we cannot generate different timestamp on each interface, simply not possible so it has to be something before the stuff hits flat flooding, but it's not clear to me what it is So that's the interesting discussion, because people talking millisecond if we don't standardize that is an exercise in futility in my experience. Yeah, all right so input, take it large we can do that cost a couple of bytes and the other one is the resolution, so I'm discussing with the parties Okay. And yeah, what Tony said, do not use that to optimize ISI's behavior. You'll end up on the valley of years. That reminded me right, because I'm constantly having to tell people who want to synchronize their forwarding database, right? to try to eliminate micro loops. That's the obvious one people will immediately go after with this Yeah. Yeah, so, yeah correct, same thing. Yes or do you think you know that is extremely smart to actually synchronize the box from the chip all the way to show commands, yes. And then they surprised how damn slow the convergence becomes, yes So my very quick comment, this is Jeff Oz If you don't like funky formats, we have a nice RFC for that. RFC 8877 It's all in there. And that's exactly what this thing is referring to. Yeah. And that's why I went to PTP epoch, which is recommended and yeah i had to offset because to run over The Unix thing can deliver interest results like I said on leap years and so on, depending on the kernel and so on and so on"
  },
  {
    "startTime": "00:50:01",
    "text": "So all the high precision guys, nobody's using timestamping 8777 8-7-8. 8-78, it is in the draft It's actually a very good document by Eastlake and a bunch of guys. Very, very good document recommending how the hell you time the draft it's actually a very good document by Eastlake and a bunch of guys very very good document recommending how the hell you timestamp right different things clever stuff david lamparter, I guess I also need to read that document. I do need to warn that our implementation will get this wrong and in half of the cases put in the Unix timestamp because we don't have the ability to check if the PTP clock is configured correctly Oh you don't need PTP clock for that now where do you pull the stuff from the kernel is, you know, that does not- yes, but I can't guarantee that I know the offset No, the offset is fixed. The offset says, this is ptp epoch but shifted by that much the document says hey we just take an offset, so it rolls over much, much later There's no magic. Okay. It's just a constant Okay more question, I guess No, it was lively. Yeah. Thank you. Thank you Sometimes it works Yeah Okay just wanted to comment that for especially the first draft, you might want to look in the taking to the what's it called hedge dock because I know I didn't get everybody's comment I know Chris will look in there, but I don't know if the rest of you will Anyway okay, I'm going to give an update on this draft. We had some discussions based on the"
  },
  {
    "startTime": "00:52:00",
    "text": "feedback on the list for the opt- optimized OSPF database exchange Okay, I'm not going to go through the whole packet sequence again, but basically what happens, let's say router C restarts it it has a database, and it's going to start from the first sequence number, so I have the first instance of all itself originated LSAs. So when it goes during database synchronization with B and E B and E is going to have the stale ones that is more recent So they'll they're they're going to request, I mean, see is going to request the more recent ones from them and it will eventually converge. OSBF work as is. I want to point that out Only the problem is uh b and e the way it works today, since they don't need any LSAs from C there are not, C doesn't have any that are more recent, they're going to just go full and advertise the adjacency before C has requested and refreshed or per are more recent, they're going to just go full and advertise the adjacency before C has requested and refreshed or purged the scale LSAs that it had in the previous incantation Well, previously we were discovering the stale LSAs during the database exchange Now, the problem with that see, there could be LSAs that C had in a pre previously, but it doesn't have today, so it won't find these. So the big change that we made is if you look at the conceptual database exchange in OSPA in RFC 2328 there's a portion of it initially when you go into exchange start"
  },
  {
    "startTime": "00:54:00",
    "text": "when you go through your entire database and build up a database summary. At the same time, you can build up a list of the LSA's in your database that were originated by the restarting router So what we do is we build them up at the same time we're building the database summary. So it's really not much more overhead. We're just keeping track of all of these And we're calling this the Stale Database Exchange list and what we're then doing is in the current OSPF, uh, database exchange of state machine as soon as our link state request list is empty, we'd advertise the adjacency because it would be full respect to us But we're not going to do it until not only that list is empty, but this list is empty And there's two to situations under which we will remove LSAs from this list The first is when the link state database of the restarting neighbor if it's his database, uh, database packets have an instance of the LSA that is the same or more recent then you remove it, because that means it's not, it's not stale and that that'll work and the other is if you did have a stale version and then it would go through the whole self-originated LSA where the restarting router will request in a link state request path will request that LSA the routers, the restarting router's neighbors will send that LSA to that route and it will either advance the sequence number and update it or it'll purge it. And in this manner,"
  },
  {
    "startTime": "00:56:00",
    "text": "none of the stale LSAs are missed And I put in all the places It looks like it changes a lot, but really a lot of it is just the cleanup for a neighbor that goes down something in this state machine. That's repeated all over. It's kind of the phenomenon of, I don't know if you saw Jeff is presentation in IDR This is just that same type of thing where the, if, when the, you know, this is repetition like that he was talking about and different ways you can handle it but we're, uh, so it, so it looks like a lot more This is just on a smaller scale than the BGP state machine And, well, anyway we start talking about this, well, you know, you really don't need to do this for every neighbor So a couple optimizations we talked about The first one was keep track of neighbors that you previously had somehow, or keep track of whether or not, well, one way if you've never had it before, then the list will be empty on the start of it so that that wouldn't matter because if it wasn't if it weren't active before, you wouldn't have any LSAs in your data then the list will be empty on the start of it. So that wouldn't matter because if it wasn't, if it weren't active before, you wouldn't have any LSAs in your database. So this one is, is some interesting, but I think this other one, actually this one's mine, so I'm going to I think it's a much more, it'll save you a lot more This second optimization is where you don't have to keep track of all the restarting may routers still LSAs. You really only have to keep track of the router and network LSAs that have a link to you. So I well, actually, the router LSAs in the network house you might as well keep track of those. And those are really the only ones you have to make sure that get refreshed or purged"
  },
  {
    "startTime": "00:58:01",
    "text": "prior to advertising that neighbor Because those are the ones that are in your database and you'll be able to advertising that neighbor because those are the ones that are in your that are in your database and you'll be able to, using them there's a two-way check in OSPF, SPF, so both sides So as long as you don't advertise the adjacent, prior to those, that router LSA, that was the one in the original definition of the problem and any network LSAs where the restarting rodent was previously the DR and had a link to you You really have to only do those those Let's see here. Okay, there was a, there was a, concern on the list that okay you're you're doing this you're doing this the restarting, I mean, the neighbors the rest restarting router are doing this, there could be some this, you're doing this, the restarting, I mean, the neighbors of the restarting router are doing this, there could be somewhere in the domain, there could be stale eligibility are being used. Now, I really don't think this makes, this is a problem as long as you do this because you think about this. In order for this to be a problem a neighbor the restarting router has to advertise the adjacency prematurely So he doesn't do that until or that router doesn't do that until those LSA, stale LAS have been refreshed or purged so that's on the same flooding path. So it would be really unlikely that there'd be stale LSAs on the same flooding path as the router that's going to advertise the adjacency to the restarting router The only way this could happen is if you had LSA's, I mean, LSA package some LSP packets being dropped and other"
  },
  {
    "startTime": "01:00:00",
    "text": "getting through. Now how would you handle that? Would you make an arbitrary long delay? In that case, the medicine of not converging for this long time or waiting for reach retransmission intervals will be much worse. I mean, the medicine be much more worse than the cure. That's what I'm thinking And finally we also talked about this data plane update Now my contention is that you know, the synchronization of the state, get rid of the stale LSAs and advertise them before advertising, the adjacency of the restarting router before those are purged That's a problem of the router that's advertising the adjacency prematurely The fact that the restarting router hasn't updated the data plane, that's a problem of the restarting router. So I think rather than trying to signal other guys not to advertise their adjacencies, that route can just suppress the advertisement of its adjacency to its neighbors until it's installed the routes to the neighbors. Now, one thing Les pointed out less pointed out or, or was that, uh, you're going to have to be clever about this because the spf needs the LSP or I mean the LSA in order to calculate those routes So you're really going to have to do something to either to put them in your LSA and not advertise it or do something or or mark them as such that they won't be advertised or have you know there's many ways you can do it implement dependent and i covered all the comments that were on the list That's it"
  },
  {
    "startTime": "01:02:00",
    "text": "Yeah, go ahead Thank you. from Palo Alto Networks. So, I have not really followed this work, but this just reminds me of the issue we had to deal with when did the PGP press for restart because the remember the we, when the BGP speaker restarts, we basically are in the receiving mode right if you have more than one that are restarting, you have a possibility of dialogue. We are waiting for the EU URs. Aga is also waiting for UR So we have to introduce a bit, say, I'm restarting so that the other guy can exclude you and just wait for you from all the other names neighbors and stuff from you, right? So here because there could be something similar. I just want to make sure it is is this kind of issue is taken care of don't need you're taking care of you don't need the signaling I mean you know I always feel if you want to get something done, do it yourself. Because here it seems to me this something similar in this holding pattern initially. Say, OK, I want to wait Yeah, we shouldn't be relegated to the inefficiencies of other protocols. Yeah, yeah. Just make sure just just just just make sure this is taking care of okay it works Yeah. All right. Okay Anyway, I, we could discuss this on the list. I know that BGP has the end of race i'm we've been talking about we've been having to debate on that in another draft I'm in, which some of you are well familiar the BGPSP. So there are two things, right? One is basically whether this rod is restarting or not, the other is the end of rip right? These two things, they work together"
  },
  {
    "startTime": "01:04:00",
    "text": "yeah, in PGPGR You are that next Okay, this is the end from China Mobile Thank you for Peace Day for Peace Day is Leanne from China Mobile. Thank you for considering the questions to have discussed on the list and will be like to speech And I go to two improvements from your slides So I'll say type and the folding plane problem In response to this tool, I would like to consult some questions The first one, could you please turn to the page? 5 or 6? about the opportunity vision? Yeah yeah, yeah. I just want to confirm the first one I'm not very clear about that Do you mean that this? solution does not need to be deployed on all the needs about that. Do you mean that this solution does not need to be deployed on all the neighbors of the restarting router? Yeah, if you weren't, if you weren't previous previously adjacent to it, you can't have any stale links even if the, even if the, even if the router I just was adjacent with other other other other routers oh I mean yeah okay I got it but uh i think in this situation, we must maintain the neighbor list of the previously"
  },
  {
    "startTime": "01:06:00",
    "text": "achieved the full state. So I think in this solution, we have two lists One is the neighbor list and the other is the But this is, this is optional anyway I in thinking about it more I don't think I would do this if I were to implement oh yeah yeah i just confirm it and i think it will be better but uh i also, I still think it's a little complex, but also I will live the diet to other experts to evaluate the complex city And the next question about the next page next page about the LSA type about the reason to the reason to this implies that the still IOSA updates approach have been flooded by the restarting loiter prior to the router LSA or network RISA continue a link to the restarting router. I think this is a normal situation and I have just thought about one new scenario for example, the still else will say, is the max age, you know at the max age state and just as the 23 and 28"
  },
  {
    "startTime": "01:08:00",
    "text": "are described this hour as we will now be ID to the database description packet and it will be added to the retransmit list directly So I think in this situation, the route are I will continue a link to the neighbor router will arrive I think a long time prior to the type 5 I will I'm not sure I quit keep following it, but it did remind follow that, but it did remind me of one thing I failed to say when I was talking about it. Okay if you handle the, the you handle getting rid of the stale LSAs that are in the domain with these links, links, you will not, the restarting router is going to either update or purge. It's router LSA and its network LSA is if it becomes DR again, it'll purge the, it'll purge the it'll purge or update the old ones now it won't advertise any adjacencies with any if it becomes DR again, it'll purge or update the old ones. Now it won't advertise any adjacencies with anybody else until it has updated or purged all the LSAs that were previously in that guy's database That's what I'm saying. You really only have to worry about those stale I just want to mention that this is the normal flow and it's not related to the DR or some more complexes situation is just for the P2P this will happen and it has described in section 10.3 10.3 in R the P2P, this will happen. And it has described in section 10.3, 10.3 in RFC 23 and 28 Maybe you can refer to it and think about this situation. What I want to say"
  },
  {
    "startTime": "01:10:00",
    "text": "Yeah, can you put that scenario in the list where there'd be a problem? with this? No problem, no problem I will put this situation in the list Okay. No problem. And what I want to do we need to, Leon, can we move through the queue? We're running out of time We're out of time Okay, thank you. I have another question sorry, because I'm focusing on this topic, so I have a lot of work curious tool consider I have the other second one question about the page 7 You have mentioned about the forwarding plan. I think to realize they we must also control the neighborhood machine of the restarting rotor. Am I right? No From the I can see that so I hope this will be clarified on the list or on the draft OSBF requires both LSA's to have bidirectional connectivity So as long as you're not using the stale one the router that's updating its the restarting router, as long as it can as long as it delays updating an adjacency unless until it's installed the routes associated with that adjacency, everything's fun yeah yeah um think you have mr samuel some special consideration I will send it to the list Yes, can you?"
  },
  {
    "startTime": "01:12:00",
    "text": "please send your questions to the list? So by now we have already used that all our discussion time. We have 48 minutes of presentation to go Great new management. Please go ahead Yeah, please go ahead. No, okay Let's Very quickly, if you could go back to slide five So I think this first optimization in AC, I think you're pretty much talked yourself out of it already but I don't think it applies because the scenarios you're trying to address are not restricted to those cases where the neighbors still haven't time out their adjacency. Your LSA I think, you know SBF by default lasts for an hour So it's quite likely that the you know, the adjacency has gone down. You don't have any memory of it but you still want to use these procedures. So I just don't think this is you don't need this Yeah, I tend to agree Okay So please continue the discussion on the list and we'll do the next presentation Okay, thank you This is the end coming from China Mobile I'm doing the plan detention on behalf of all the courses. Can you speak a little?"
  },
  {
    "startTime": "01:14:00",
    "text": "bit louder? Oh, okay, okay, okay Is it okay now? now It's another solution to solve the same problem as the previous document Oh this draft so I will now to detail the problem again, and I just quickly go through the solution about our draft, the key point of the solution is Router B, just as the picture shows the Uter B surprise, advertising the line B to A or the agency's agency state of B to A until the Lutter B with Stephen the re-originated IOSA from LUTRB of B to A until the Router B is giving the re-originated IOSA from Router A. And I think the main point of the two drafts, had the similar So I will focus on the P-point difference that can distinguish this proposal from the previous one The first one is that we yielding our signal, we call it the SA indicator to ensure that the suppression is controlled by the restart router And the second one, we introduce a time to control the surprise duration, which"
  },
  {
    "startTime": "01:16:00",
    "text": "can reduce the complexity of the solution before to illustrate the key difference, I would like to introduce a new use case of the solution This has been updated in the latest version of the draft draft We do not initially resolve this situation that we found that our solution is more friendly to this situation situation And generally speaking is the startup procedure I think the solution can be used to it not only the restart procedure, I think this can prevent traffic from being directed to the start router too early, just as the picture shows during the initial startup, R1 does not want to our to direct any traffic to it using this signal mechanism it will be achieved very easily And this is a little similar to the graceful stat in ISIS But as we all know that in OSPF, we just have the graceful restart not included the stat initial status, so we added this use case to the draft"
  },
  {
    "startTime": "01:18:00",
    "text": "And this lies shows some key point about our solution and also have sent it to the meaning list and here we just discuss it further further As we all know that the ideal solution is to find the precise surprise duration. But because of the answer uncertainty of the flooding and the other reasons, I think the precise time cannot be achieved easily because it must miss the meeting the two conditions. One is it should be received received Still, I'll say refreshing should be received by not only the direct neighbor, but also the remote neighbor So it's very, very good difficult, and I think it's impossible to guide the exact or precise timing for the complete of the old LSC refraction So we need to find a compromise solution to balance the effectiveness and the cost of the solution We introduce a timer here to resolve this problem and also, I think this is inspired by some other features such as the Stabrouter timer LDP sync timer or some other VDP St TAMR, so, so it has several benefits we have analyzed"
  },
  {
    "startTime": "01:20:00",
    "text": "it. The first one is effective for both direct and remote neighbors And the second one is facilities for folding plane programming And I think the important thing is to this new feature maybe we'll cause some neighborhood machine dialogue if we change the neighbor machine So I think this is more friendly And the first one, I think the timer is valid for the whole restart route or OS pair of precise And the last one just we have discussed it's no need to distinguish the IOC type of the ILC ILC Because due to the time limitations, I think I cannot explain it in detail if you can refer to the slides slides And the key point two, we use the acidity The fundamental purpose of this point is to ensure that the control end is in the rest route, not the neighbor router It also based on the following actors The first one is meeting consistency with other futures. And the second one, it can distinguish interest interest actors, the first one is meeting consistency with other futures. And the second one, it can distinguish inter-face restart and the rotor restat And the third one, I think this one is very, very important since the unexpected response can be happened at any time. So this feature should be enabled by default It will be easily"
  },
  {
    "startTime": "01:22:00",
    "text": "realized on the restart water but the neighbor router cannot achieve this. And the first one we have thought about the multi-neigh versus net narrow. We just need to deploy it in the restart route return With down the previous discussion, I just like to summarize the concerns to decide where to control this action. With that, we turn our neighborhood router router And I strongly suggest that we first determine which side and then consider the cost and effective of the solution Maybe after that we can clearly evaluate the prongs and points of the then consider the cost and the effectiveness of the solution. Maybe after that we can clearly evaluate the prongs and points of each solution solution Also, because the time limitation, I will not explain it further But yeah further. Are there people, is anyone want to comment before we cut the presentation? We can give you two more minutes if nobody wants to comment. Okay, okay, I can finish to right, very fast and the next step, we will update the draft according to the comments. Some from the Eastern step, we will update the draft according to comments, some from the EC and some other experts. Thank you all very much And we have requests Dr.10 doctrine for one's time"
  },
  {
    "startTime": "01:24:00",
    "text": "so maybe if no other questions we can request again I just have a quick question other question we can request again. I just have a quick one. I mean, it would put this is that OSP just have a quick one. I mean it it with this is that that OSPF flooding is determined And if it's broken, you know, you know, broken, we wouldn't want the neighbor to come on up. You know, you're talking about you could have a deadlock. I don't think you'd do it think if you had a deadlock, it would employ a bug. So that's the only thing I would. We can discuss this more on the list though Yes, I think it depends on the developing experience but as we all know that the OSPF, is all very, very complex protocol The RFC has defends and introduced all kinds of mechanism to resolve this all situation to make sure the neighbor state machine can run normally I think any change maybe will cause that that It's a, I think, it's a high risk to modify it. And the a high risk to modify it and also it's just a some experience and I will also leave this to other experts to evaluate Tony, you want to say something? IDBX staff, so let's get realistic Conceptually, what is in the drawing has been implemented, not necessarily enough way it's described in the draft, has been deployed 10 years at scale, whenever so deadlocks or any farther transient"
  },
  {
    "startTime": "01:26:00",
    "text": "Hank is common as set is valid for ISIS. That's why we have to hacks like over a long time out, you can say but because OSPF has database synchronization and you have at end of RIP implicit, their concern does not apply Okay, thanks. Let's go to the next presentation Thank you. Thanks Okay hello everyone, I'm Lantern lancheng qin from Zhongkwonen Lab. I'm going to introduce an IDP-based intradomation solution. This document is also being discussed in the cell networking group. This is the first time I present this document in ALSR working group, so I will introduce more about the background and introduce only the highlights of the design Okay subnetworking group has adopted two drafts about intradominate source address validation. The first one is intradomain problem statements. This document summarizes the problems of existing intradomine cell solutions and the other document is the Intradomine Samnet architecture. It proposes the architecture, which focuses on CF on customer-facing routers host phasing routers, and AS border routers And it requires routers to generate self-rules by using self-speaker information exchanged among intradamations"
  },
  {
    "startTime": "01:28:00",
    "text": "routers. And another, drafts called source prefix advertisement proposes a protocol independent sub-solution under this architecture so following the above three documents, this document proposes an IGP-based method for interest cellnet. It allows routers to communicate self-specific mission documents, this document proposes an IGP-based method for intra-domen cellnet. It allows routers to communicate self-specific information through IGP And we define photo types of interfaces on which source address readdiction can be deployed. The first is singlehood interface. It is the interface of Android address rendition can be deployed. The first is single-home interface. It is the interface of an edge rocker that faces to a single-home subnet, such as Interface 3 in this field And the second is complete multi-home interface. It means if all routers facing a multi-homed subnet are in the local AS, the interfaces face this subnet are complete multi-home interface such as interface 1 and 2. The third is incomplete multi-home interface. If some routers fit multi-home interfaces, such as interface 1 and 2. The third is incomplete multi-home interface. If some routers facing the multi-home subnet are in other ASCs, the interfaces facing this summit are incomplete multi-home interfaces And the internet interfaces is the interface of an AS border router that faces to another AS And the goal of Israel domain CellvNet is to automatically generate prefix a loudlist or blocklist on the four types of interface. Specifically for single homing interface, it aims to generate a prefix allow list containing all sorts prefixes of the phasing single-home subnet and only allow data packets from that subject using source addresses in"
  },
  {
    "startTime": "01:30:00",
    "text": "this alarm one one quick question are those subnets are they they are they they're an as well right? The bottom subnets are in the bottom are part of AS1? right? The subnet in this figure is a host network or custom network of AS1 and for complete multi-home interface similarly, it also aims to generate an allow list containing all source prefixes of the facing multi-home subnet But for incomplete, multi-home interface, it aims to generate a prefix block list containing source prefixes of intra-domen single- subnet and intradoment subnet. It's because multi-homed subnet. It's because in this case, the adrobatter may not identify all source prefixes of the cursor corresponding subnet without communication between other ASCs And for internet interface it aims to generate the same prefix block list as on the incomplete multi-homing interfaces So to achieve this goal this method has three main steps. They are self-specific information generation, self-specific information communication, and several generations In the first step, edge rafters will generate self-specific information containing four main types of information. Their source prefix, interface type, subnet tag, and only source flag. The source prefix should connect the source prefix learned through its look at the source prefix They are source prefix, interface type, subnet tag, and only source flag. The source prefix should contain the source prefix learned through its local rules to the facing subnet And interface type should be one after single homing, complete multi-huming, or incompletement homing. And the subnet tag,"
  },
  {
    "startTime": "01:32:00",
    "text": "is a unique tag value that I'd identifies the subnet that owns the source prefix. And only source flat is used to indicate whether the source prefix is only used by that subnet. By default, the flag is said, but in some special cases such as for multi-source prefixes, the flow should be unsaid And the interface time and subtext tag value can be configured when the subnet first connect to the adroctors. After that, the adrovetter can automatically match the interface type and the subnet tag to source prefixes of the corresponding subnet And as we can see, different from ACL-based CF, this solution doesn't need manual configuration when source prefix changes, and only interface type may need to the other applicate After that, the adrovetters will provide is self-specific information to other routers while IG when it distributes IP prefix information of its subnet while IGP, it can carry the other cell self-specific information with the IP prefix information And we have two approaches to self-specific information communication. The first one is using existing administrative tech sub-tLA and the second approach is to define a new 7-net tech sub-tLA And if we use the first approach, which can there is a limitation because the administrative tax subterway is not designed for SAP self. So using this tax up tailway may conflict with other routing policies"
  },
  {
    "startTime": "01:34:00",
    "text": "So to avoid possible conflicts, additional operations are needed And if we choose the second approach, they should defy a new subnet tech subter for ISIs and OSPF but it can help avoid conflicts and facilitate the operation And in the following, we will briefly introduce the several generations For single-home interface, it will general prefix allow list by using its own self-specific information And for completed by the home interface the routers will generate the allow list by using those its own self-specific information and self-specific information from other routers using the same subnet And for incomplete, multi-home interface and internet, interface, the routers can generate a block list by the subspeat information it received from other routers So in the next step, we'd love to improve the preliminary design of this method So your comments and the suggestions are welcome. Thank you Okay, I put two minutes on the clock for comments No, you can, Tony, you can go There's two minutes minutes minutes You are not kidding. A.C. I'll be interested. A.C. Linda Malavin. I just wanted to say, are you going to advertise? the colors for the interfaces? I know you're you're going to advertise a tag on the prefixes, but it's you also going to color the interfaces with the same tag? I know we got a color in the to advertise a tag on the prefixes, but are you also going to color the interfaces with the same tag? I know we got a color in, like in ISIS and OSP prefix"
  },
  {
    "startTime": "01:36:00",
    "text": "extended, I mean, link extended attributes It's not called the tag. It's not called the tag for the interface. It's called the color. That's what I'm saying. That's why I said color Yeah, thank you. I will crack this I think last year in the queue queue Right, can be done. What I'm seeing here, is that if you have now BGP and IGP, sloshing all this stuff in information into the domain, you'll need some kind of a type tie-breaking, right? And talk about how this thing possibly ends up in BGP how it's being consumed, because without that, it's just a mechanism, and I don't see how to practically use it that with my observation when I when I look what's going on in stuff Southnet, right? Somehow, it's like route type breaking route types right you need some type 5 7et or something like this because otherwise none of this stuff makes a lot of sense, because everything will start to install stuff independently and step on top of each other And you face an interest problem because the software information is actually not particularly precise especially the farther you get away, right, from the source that something like BGP can actually try to install something in Southnet, which are actually suppressed the subnet on which you're running and basically bring it just distance it down. So some it will be interesting for a framework between preference. What gives you the information? and actually not ended up being, you know, subnetting yourself out of existence while you're consuming it Thank you for your comments"
  },
  {
    "startTime": "01:38:00",
    "text": "les ginsberg. There are many things to discuss about sabnet. I don't want to do that here Just a very pointed comment. There is no reason to invent a new tag sub-TLV We have 32 bits of tags They're meant to be used for multiple purposes. We don't want to invent it new sub-tLV for every use case of tags. Please don't do that Okay. Okay, thanks. Alburo, I'm sorry I'd lock the queue. We're way out of time time we need to go to the next presentation Yeah. Tony's comment was the picture of the prefix that was coming both in the, I'll just clarify, both via the other AS and via the IG interface. So Tony was saying that there could be common complicated that was that one picture the incomplete multi- one. That's what he was commenting on We can do this quick right ginsberg on behalf of my co-authors So Flex Algo supports a variety of metric types. Some of them are based on dynamic measurement and in such cases you can have asymmetry, meaning that the cost in one direction can be different than the cost in the other direction. When you use this for multicast, this means if you don't take this into account, that the receivers of a multicast stream may send join in a different direction than the actual stream is going to flow So here's a quick picture If you look at the metric, that would be used in a standard IGPSPF,"
  },
  {
    "startTime": "01:40:00",
    "text": "the shortest path would be on the normal northbound, but when the multi-gas stream actually gets delivered it's going to follow the reverse metrics and it's going to flow on the southbound interface So you're going to have a discrepancy between the two and your RPF checks are going to fail So what have we proposed? We've proposed a new SPF algorithm to be registered in the registry, which is to use the reverse metric This will be advertised in the association FAD, and I've just highlighted that the calculation type is where this field goes Notice we decided to do this as a new SBF not a new metric type, because this can be applied to a variety of different metric types How does this actually get? used? As you've seen, the FAD includes the new calculation The key points are the last two both this actually get used? As you've seen, the FAD includes the new calculation. The key points are the last two bullets that the reverse SPF fags in whatever you're in internal implementation is get installed in a multicast rib, and they're used both for RPF and for PIMS signaling. There's a key assumption here that the multicast source as well as the receivers are working on a common data plane, which in this instance really means using a common set of addresses You get that naturally with flex out If you're doing SRV6, we've got algorithm-specific locators If you're doing IPv4, the easiest way to do this is with ID Algo and that's it Any questions? david lamparter. I believe you're exaggerating a bit on the requirements here and you don't actually need a continuous data plan for the source and destination to"
  },
  {
    "startTime": "01:42:00",
    "text": "support this all the way. It will just work I disagree If you're using an IP address, that's not part of the flex album disagree. If you're using an IP address, that's not part of the Flex algorithm calculation. You're going to come up with a different path And Sandy Zhang ETE, just I have no comments for the extension itself for now, but I'd like to say we must discuss more details on how to use it for pain or other multicars technologies. Yeah, and I noticed I know you you have a draft in PIM yeah for PIM or other multicaster technologies. Yeah, and I noticed, I know you have a draft in PIM, which I think is related and I think that there's some interaction here yeah we can we can discuss more about the two jobs yeah agree thanks you have a draft in PIM, which I think is related and I think that there's some interaction here. Yeah, yeah, we can discuss more about the two drafts. Yeah, agreed. You want next? Oh, yeah had a quick, A.C. Linden Lab, I just had a quick question that I know you're doing this, you're signaling this with the Cal type. I mean, it seems to make sense. The only thing is, wouldn't you want this for every prefix in the domain as opposed to doing it for? specific prefixes and signaling them all with flex algorithms? Like wouldn't you need like a multicast topology? Wouldn't that be? a more common deployment rather than specific prefixes? So I think there's are use cases in which what you say make sense and then I think in that case what we've thought about, this is early brains brainstorming, is that we would invent a, what I would call a new data plane, and then all of the addresses could participate in that data plane But then you wouldn't need to, you wouldn't need to signal a flexal algorithm for every prefix um addresses could participate in that data plane. But then you wouldn't need to signal a flex algorithm for every prefix. But you need a way to do the calculation"
  },
  {
    "startTime": "01:44:00",
    "text": "Thanks, Les Thank you, Les. Yeah. Thank you for save us a few minutes I'll go to the next one one Thank you. This is Leah again. Okay, please go ahead. I'm talking about you ADV extension for optimized the SRA is Lillian again. Okay, please go ahead. Yeah, yeah. I'm talking about the ADV extension for optimized the SRV6th and state advertisement I will go through this slide very, very quickly quickly Okay is the motivation of this draft as the number of links in the flex ego algorithms increases the amount of required else disease will increase its proper seemingly proportionally. When the LSD data scale extends, it can all overwhelm the system and affect the normal flooding of ISDB, leading to the potential malfunction of the ITP protocol So the purpose of this motion is very very simple is to reduce the number of the bias to come by to see the advertising We conducted the analyzed for simple scenario mainly to clarify the effectiveness of the solution just as the picture shows when there is 100 link and 100 black Algo deployed, the USP member will reach about 400 480 And in actual network, many features of life and"
  },
  {
    "startTime": "01:46:00",
    "text": "various factors affect the flooding So in the network's goal group of life and various factors affect the flooding. So in the network scope, maybe there will maybe we assume that there is 100 routers and the LSP number will reach about 48 48,000, sorry, there is one extra zero zero The main idea is shown as the pictures We use the bulk alock method The main idea is that different IFA adopted the same function field And the seeds of other AFIs can be obtained by combining the seed published by FAA Bureau with their own FAA locator So what we need to do is just to either hide the exact position of the function field in Locator So this point needs to IDP extension A no sub-stop child is idied in the car current locator TLV, which is yours third to declare the position of the function field, which can be high-rate advantage is idied in the current locator TLV, which is used to declare the position of the function field, which can be high-rated by other algorithms, which contains 16 oaks state marks This function field can be obtained by performing bitwise end option with the seed This is the demonstration of the"
  },
  {
    "startTime": "01:48:00",
    "text": "results after deployed this day solution. The lifetime is the color after deployed this solution. The left is the current advertisement and the right is the optimal advertisement. And the right for indicates the points of difference between the two. Also, the USP number comparison is as the following which can be reduced from 48 students to about six 600 From the comparison, you can see that before the optimization, the number of ISP is a multiple relationship with link and flex elbow. And after the optimization, the proportion of LSP, is increased by the flex algal has decreased significantly If a single FAA, advertises multiple states, they find flex algal, has decreased significantly. If a single FAA advertises multiple states, the effect will be more significant significant The new feature can be controlled by a local configuration for net The new feature can be controlled by a local configuration for network devices that support this feature and this feature and when the network pressure caused by the FDA deployment will cause a high network pressure, this wage can be tuned on and otherwise the switch should be turned off This is a use case to help to understand it. First, we obtain the function value by performing a bitwise and the operation between the SSW6 and for Flex Algo Bureau and the ADGS the mask. And then, obtained the SIVIL6 and XC by computer"
  },
  {
    "startTime": "01:50:00",
    "text": "the locator value and the function value. The newly idea is sub-tlva in locator TLV combining the locator value and the function value. The newly idea is sub tlva in locator tlva replaced the space NX set for each flex elbow What I want to see here is that the solution is not a purpose one, it requires a certain level of deployment planning We must assure that the function field of different FAA to be the same That is a symbol and easy way to be deployment, to be deployed So I think it's just a balance of the complaint and the effectiveness So, any comments? I guess I'm up I'll be first. I heard some place I can't remember where that operators were afraid of complexity Wouldn't this? uh wouldn't this be complex and prone to error Also, the compatibility mode if it's just a switch, it seems like you'd almost need a capability that you advertised around the domain so you could tell it some people didn't support it Thank you About the complex city, I think it's a common relatively simple method that we have fun And about the capability, I think think, like other new features, maybe, we can add some capability in negotiation mechanism that I think is not very necessary"
  },
  {
    "startTime": "01:52:00",
    "text": "not so special for that Peter, please go ahead It's Peter Shannock, Sisko So I would really like to see a real use case for this because the fact that you can advertise hundreds of indexes for hundreds of links doesn't mean you want to do it and I see absolutely no real life example where one would want to do it index seats for hundreds of links doesn't mean you want to do it. And I see absolutely no real life example where one would want to do this because index seats are used for a very special purposes like protection and, you know, traffic engineering and typically on a box where you have hundreds of adjacencies you don't want to do any of this so before we start to solve the problem I would really like to see a real use case but this becomes useful thank you Yeah, yes, thank you for your question Yeah, we have a elaborated the use case in the draft. Maybe you can refer to if anything, any comments we can improve it And it's just one scenario. The use case in the draft is not specified. What you have in a draft? is not sufficient to convince me that there is a need to solve it Okay, okay, I will check it I thought that we have updated this to the draft. If not, we will update In the interest of time, please continue the decision on the list, and we'll go to the E last presentation Hi, this is changwang lin from new to H3C. It's about an IDP IPKal-Ward shortcut So background, this draft aim to add color to IDP looters and enable the select"
  },
  {
    "startTime": "01:54:00",
    "text": "of SR policy based on color during IGP shortcut calculation Al First, the use case is about SRI policy page IPCA-A-A-A-A-A-Ward routine For control place, BGP, advertised route between E1 and E2 will next hop as E2 and color as color one one Really, it's three Osprey areas at P. Shortcut calculation are performed and delighted traffic to the corresponding as our policy based on the color In Osprey area on devised E1 performed the ICP shortcard calculation. And other calculations elect the outgoing interface of the looter with destination address of E2, and color 1, to the sarpolis 1 with the color color one BP service loot are relied through IDP ISP-car-aware loot based on color and the nest hall Analys use case is about the SRV6 locator based on IDP color router in Ospre area 1 on the device E1 performed the IDP shortcut calculation and alter the calculation directing the outgoing or interface of the locator E2 and the color one to the sr polish one with the color one the BP so service route are related to the SRV6 locator loiter For the folding place,"
  },
  {
    "startTime": "01:56:00",
    "text": "the traffic in each area follows the corresponding colors SRIPOLIS and thus releasing the E2 device The proposed solution outlined in this document is to utilize the colored IHP prefix and still the color prefix or color matched panel for This is about how to advertise the color for ISP prefix The first approach is by using existing administrator tag. Another approach is defining a new color subterway from the perspective or simplified protocol, tag could be used for magic colors. However, it requires the tag to color mapping configuration to be consistent across the entire network We up update the SPF computation of IGP SOTC as described in RFC-396 at the following step when calculating Nest Hopper for prefix advertised by a node If a prefix is kind of step, when calculating next hopper for a prefix advertised by a node. If a prefix is colored, we look up the first hopper information of the advertised node for T-Tan, with the same color If they are illisible T-tunnel, we compare the cost of pass over those tetanels and use next hop of tetanels with the low list path cost. If there is no eligible tetanels"
  },
  {
    "startTime": "01:58:00",
    "text": "we use native agency nest hop If a perfect has no color, we use the nest hop with a lower list of past cost Out of last item meeting, we updated by using tag for color mapping And we also add use case for S.MPS and SRIPv6 v6 Let's all, thank you Any questions come? I welcome Peter, please go ahead So Peter Shinnak from francisco arias don't see anything that needs to be standardized here. This is about a tunnel head behavior picking up the tunnel based on some local configuration or based on the attacks which is associated with the prefix there are implementations that are doing this for many years already. There is absolutely nothing to be standardizing here Thank you. We need to update up, say, 396 to handle to map mapping card of to the tetanos during IDP shortcut calculation. I don't agree but let's keep it to the working group Yeah, thanks thanks Actually, I was going to say what Peter said that the shortcut behavior is purely low based on the local coloring of the tunnel endpoint there. But that Peter said this same thing thing We need, we have the real use case in SR6, like this use case VA, you want to say something quick?"
  },
  {
    "startTime": "02:00:00",
    "text": "Yeah, I guess the want to express that whatever the solution, the current RFC cannot meet the scenario. So I think this is a new scenario and we should without it And also, just like Peter's side, we also hope to hear the appeal scenario and we should without it. And also, just like future side, we also hope to hear the opinions of the working group on whether the existing document needs to be updated or controlled through local configuration But which one, what I choose, whatever we chose, I think that we need one solution to resolve this problem problem Thank you. With that, I think we are running out of time. Please continue the discussion on the list Thank you to everyone for attending this session and the good discussions. We'll see you in Dublin Dublin At the Templar Bar. Apparently we need to leave more than 30 minutes of free time Yeah, we had 30 minutes and we use them for good discussions Yeah. Thanks, everybody Thank you just go back up once? Go up one slide I just want to all right. I mean, I think Thank you very much"
  }
]
