[
  {
    "startTime": "00:00:04",
    "text": "yes hello hello welcome to the perigee session thank you for coming everyone get right into it there\u0027s no well I\u0027m sure you\u0027ve already seen this from the morning session if you haven\u0027t please familiarize yourself with this keep in mind going forward for the session a couple of Ministry of notes before we get started blue sheets are somewhere up here did you pass and run we will pass the blue sheets around please fill them out we need to jabber scribe we do okay great as well as a minute taker oh great excellent [Music] this is the agenda pretty sure for we\u0027re gonna couple presentations from sort of researchers in the area and then some individual draft presentations does anyone have any comments or adjustments they\u0027d like to make before we get started so I think so Joe offered to do a quick update for one of the adopted jobs that we have either maybe come up so Joff censorship is an adopted RG draft and Joe offered to like give a quick overview and update yeah so this is a draft that\u0027s been alive for a very long time I\u0027ve made absolutely no progress since the last IETF because I changed jobs and my job now is been uh difficult so to speak but anyway I have a list of issues I think I just threw in the chat I may not have hit return Christian if you want to hit return on my computer they\u0027ll post but I\u0027m hoping to get through those in "
  },
  {
    "startTime": "00:03:05",
    "text": "December and that\u0027s I guess the update thanks already thanks Joe when the update comes you going to take a look provide some feedback on the list and that would be helpful going forward with that we can get into the presentations of the presenter for the first talk could please come up this professor Shoukri here do we have professor Liu do you want to go first perfect and from scripts and you thank you for imitation and today I will share our research on privacy preserving my home oh home amorphic encryption and my talk was divided into two paths first ever introduced some Merrick back ones of homo encryption and then I reintroduce the main applications of homework encryption and now let\u0027s begin with the first part okay that\u0027s simple definition what is homophily encryption and both of these tours are variations for example encryption is the process of encoding of a message and a meaningful message into randomness like message for example we can use the side Caesar cipher I used which was invented about 2,000 years ago and in this encoding the message welcome to NTU can be transformed to a meaningless message the key is dusta to shift every "
  },
  {
    "startTime": "00:06:06",
    "text": "character three positions and what is homomorphism home of ism is a structure preserving map and that\u0027s it will preserve the Arabic breaker structures and combined it together we\u0027ll get the whole mafia encryption so that\u0027s the definition of homogeneous and if we can preserve the arabika structure then we get the home of encryption that means if we have the mass encryption of the message one to message N and also a function f we can just simply computed the unencrypted data and the get the encryption of F F M like this so now we have the definition of how much encryption it\u0027s a special kinds of encryption algorithm that supports subtext the computation and there are mainly two types of hama encryptions and the first type is a partial homomorphic encryption and the second type I is fully Houma in Houma encryption and for the first the type it\u0027s only support single operations such as addition or multiplication and it was used the in data aggregation or some construction of MPC protocols and it is very easy to design such a kind of algorithm and but for the second type of form of encryption the follicle mark encryption we required to support unlimited numbers of operations and it can both supports a multiplication and addition and a little surprise it is very difficult to design such kinds of encryption algorithms it was named at the holy grail of the cryptography area and remains at the open problem of about 30 years and it does result of our entry in 2009 and between these two types of form of encryption there are many method helps of algorithms for example the humorous some words home of encryption it\u0027s a keen supporter limited the numbers of operations and it is also widely used in the area of privacy protecting okay said this is a brief history of home of encryption I taste nearly as old as the public encryption itself it was first proposed "
  },
  {
    "startTime": "00:09:08",
    "text": "in 1978 and after 30 years development the First Folio movie encryption occurred and after that\u0027s about ten years we have the folio moving here they were developed a very quick light and then now we have many public implementations which we can get from the github oh and and elsewhere and the standardization process is already underway and for the standardization for the partial home of encryption we already have a standard that was published by ISO this year it includes two algorithms which is the exponent show alchemist encryption and the pad encryption algorithm and for the case of fully homomorphic encryption and the researchers and the government have already organized for workshops processing and okay this is a list of the mainly current open source libraries for home of encryption and and for integer or finished field operations we have Cu an HD lab and on the hand rhythm and for the bullying gates operation we have tfhe in the effort aw and this our alpha baker in the internet we can get so freely now to use the Hamoui encryption in real applications the most factor we care about is the performance and that there are mainly three kinds of operations the integer arithmetic and the proxy proxy the arithmetic and the bull engage and for arithmetic operations currently we have very fast computations are integers or fixed point numbers for limited atoms of operations if we want to achieve unlimited time approaches then I took was not that efficient because of the slope the scraping technique currently and for bullying circles the bootstrapping is seems very fast for example we need 13 milliseconds for one operation of the n kind of gates but since any real application if we constructed by using the boolean gate gates and it may take many gaze operations so the real applications may "
  },
  {
    "startTime": "00:12:08",
    "text": "be less efficient now let\u0027s see some tests the results of the different kinds of libraries if we want to do the integer addition or multiplication for example we want to do the integer addition then we can use the exponential argument or pallium or just simple lettuce based encryption and the performance is very good of example we only need to one microsecond for the exponential argument and the women need eight microseconds for the Palio and less than one microseconds for the lettuce based encryption but this three kinds of libraries cannot support the operation of a multiplication and if we want to support some multiplication then it will be less efficient for example the seal library King completes the interior edition in six micro second and also for one millisecond for the operation of multiplication and if we want to do unlimited operations of addition and multiplication then we can use the AG lab it may takes five milliseconds for the addition and about 200 milliseconds for multiplication it is much slower and if we want to do the interior addition by using the basic boolean gates then it takes about one second to complete the addition operation and about 20 seconds for multiplication so it\u0027s much slower with the bullen\u0027s also the boolean circuit is Matsuura but we can construct any kinds of operation by using the blowing gates for example we can design the the circular for integer addition and the flows number addition and subtraction and a multiplication or even the square root operation or the sine function or the exponential function that we can construct any kinds of functions by using the bull engage and it is much slower for example the exponential function may takes about 100 and some save for our seconds okay and now let\u0027s begin the second parts how to use homomorphic encryption to provide the privacy protecting generally speaking we can solve the piracy problem by using home of folly for Morgan who very simply the frame worker is firstly in the first step we just encrypt our data\u0027s and then we do any kinds of operations on the "
  },
  {
    "startTime": "00:15:09",
    "text": "cipher text and finally our the user does that to decribe to the surf text and get the results of the computation so it is very simple but this kind of realization it\u0027s always not very efficient of our real applications and so we need to design different kinds of protocols are specific protocols for different kinds of applications for example in the data collection data retrieval is a sharing and a determining we may need to design the protocol of data aggregation private information retrieval and private set intersection and the privacy preserving computation protocols to design these kinds of protocols we may use many kinds of or primitives and for example the differential privacy technique the searchable encryption function encryption on even the oblivious Ram and the searching secret of sharing and oblivious transfer or garbled circuit today we are mainly focused on the common morphic encryption now let\u0027s begin with the very simple application that\u0027s in occurs in the data collection and the left a the famous feature published the banister it shows that the power usage gets from the smart meters may leak the information of the users what you are doing your home for example from this video when we get the information that the user may be get up in the morning before AIDS and prepare his breakfast and then washing and then about went to eat his lunch and went to get to sleep so in this scenario we need to aggregate the data the power usage of each hot work each user and get a summarizations and send this summarization to the control center and this is mainly the most simple and the most mature application of home encryption in this case the online needs additive homem of encryption for example we can just add the usage of each harm together and according to the tables previous we can see that addition is very efficient and in case of data retrieval for example the user want to get some public database access some public database although the data itself is public but the access pattern will leak the privacy of the users for "
  },
  {
    "startTime": "00:18:10",
    "text": "example if we are access patented database then the server may know what kind of product this company will be playing that you two took to construct and theoretically we made it seem that we may add only way it is to get download all the details in the database because even if one item is not touched that then the server may know that the user is not interest on these kinds of data and so this is very efficient previously we can solve this problem by using multi servers and we need to assume that these servers I will not concluded together to recover the privacy of the users but this kind of assumption is not reasonable for most of the real applications so let\u0027s see how to protect the privacy by using homomorphic encryption that the user only need to encrypt every index by a separate text and for the item he want to get he does the encrypt one for example that the eyes index and for all other index he just encrypt 0 and then the server will multiply each data to the ciphertext and we know that for for the index I the X I will be encrypt this position will get in quick encrypt of XII for our other positions will be the encrypt of Bureau then this server summarize all the staff tags together and only to send one ciphertext to the user and then the user can be grabbed it and it gets what he wants so in this simple protocol and the server that the communication pen wise that the server sent back to the user is only one ciphertext but the users do need to send many subtext to the server we can optimize this protocol are very simply for example we can divide the potatoes in the server into one hundred blocks and in this case the user only need to send one hundred the ciphertext and the server all like I need to send over one hundred suffer texts the back so instead of sending about to us to a ten thousand subtext in this case we all I need to send 200 a server text is a balance between the truth passes and we can make if we use "
  },
  {
    "startTime": "00:21:11",
    "text": "the most of the more powerful form of encryption we can make this project still simpler in this case the user only need to encrypted enix I want only one self text and this server for each index he doesn\u0027t finish the compare operation and if i equal to j then it will be encrypt of one and for all other positions it will be in subtext of zero so and he still summarize all the subtext the NS and the results back so in this protocol we only need two to ciphertext and communication bandwidth is very efficient but we have already seen that fall aha moment inclusion may be not that efficient so we can improve this protocol by our very careful design of macedon coding methods we can encode the message instead of encrypted the message directly we just encrypted it to a polynomial for time limits I will not have enough time to describe the technical details so I would like at this equation and in this case we only need the additive hormone encryption and to complete the Equality test and achieve the bandwidth efficiency and the computation physician together this a more complete scenario maybe the user want to outsource his data to the server in this case all the data\u0027s X is also the encrypt a safer text and in the last scenario it is a plain text so in this case we may need to to do much more about the design of the protocol and the encoding to avoid the usage of multiplication and only use the computation for additional home of encryption and makes the protocol and more efficient and in this case besides the operation of a read operation the user may be want to update his data\u0027s stored on the server then the writes operation may also leak his privacy so to protect this kind of privacy we mainly the more complex oblivious Ram techniques and I will not describe that this thing here ok that\u0027s the case of a data retrieval not let\u0027s say that they are the case of for data sharing in this case Alice and Bob both have to "
  },
  {
    "startTime": "00:24:11",
    "text": "parrots at it assess and they want to computer the intersection it is a very simple as Nauru obviously we can solve this problem by using the hash function for example Alice just said that each of his value the hash value of each of his data to Bob and Bob send back each value the hash value to Alice and then each of them every of them can just compare the hash values and to find out their intersects but this protocol is notice cure forgiven boy if the the space of Alice and Bob\u0027s in the setter is not big enough then we can search all the possible inputs and find that data\u0027s and we can also we can resolve this problem by using a very different exchange like protocol and this is secure but as in Bob also needed to many to do many kinds of module exponential computations which is very time-consuming and with himavan homomorphic encryption we can intend only a few more minutes okay okay ah that\u0027s the finish so we can we can design a particle based hormone-free encryption and to the Equality test and LSD dances and the encryption which is data and the Bob does this - every of his data and the multiplayer random number if X is equal to ID and Alice will gets the encryption of Bureau and if X is not equal to Y and Alice will get a random number so he\u0027ll find out their intersections okay with the quality tests that we designed in the data retrieval protocol we can design our more efficient protocol to come to resolve this kind of for applications and finally is the privacy preserving in this money the two phases in neural networks and the training phase and the prediction phase and the remaining folks on the prediction phase because the training phase is self in the plain text is still very time-consuming and but the prediction is in plain text it\u0027s efficient now and the the first step we need to analyze what kinds of competitions we\u0027ll need in application of neural networks for example the commercial convolution there\u0027s is a simply the computation of matrix multiply a vector and the loot layer ok is we need to comparison in this direction and in the for connection they "
  },
  {
    "startTime": "00:27:12",
    "text": "are we also need computation of matrix multiply vector and so we can design a very simple protocol to complete the computations based on the bullying bullying gates although we can see that it is very inefficient and we can achieve the operation of the linear operation by using additive homo be inclusion but in this case we cannot compute the active layer or the signal or the redo function by using the additive home encryption this is what we are still research now and ok friendly it were concluding with komova encryption firstly we can achieve the bull and circular gates at the X or in the end and the arithmetic addition and multiplication and with these rhythms we can achieve many any kinds of algorithm or bullying circuit and then we can so any kind of generic or some problem with a generic resolution and we also can design as basic approach calls for each kinds of applications and we can get efficient solutions okay thank you all right yeah unless anyone has a very very quick question or comment perhaps we can move on to the presentation thank you very much for coming can the presenter for the first presentation come up yes thank you alright ah hello everyone and you need to stay in the thinker\u0027s oh here alright ok it\u0027s for the benefit of the remote people my name is Reza I\u0027m an assistant professor at NUS I run the data privacy and transporting machine learning lab and today I\u0027m going to talk about the privacy risks of machine learning but I need to start with how does this ok perfect so I need to start with a very important concept of inference attacks if you have some data about individuals it\u0027s possible to combine it with some other information and use advanced statistical methods or machine learning algorithms to infer further information about those individuals this has been shown many "
  },
  {
    "startTime": "00:30:12",
    "text": "times in the research community and on different types of Delta for example on Facebook Likes you can infer information about personal data and also it could help to identify whose data is in the data set for example for location data you just give me five random locations from their trajectories you are almost unique in the world alright so this is a this is basically the main risk of sharing the data itself either it can infer some sensitive information further than what is already in the data or identify the individuals in the data set so there has been a lot of efforts on how to protect data privacy data sanitization through removing sensitive information or removing identities has been one idea but and there\u0027s a huge business on this by anonymizing data but what is missing there is you know what is the definition of privacy because the bad news is that by removing identities or sensitive information from the data you don\u0027t make the data privacy preserve okay anonymous data or anonymized data isn\u0027t but there is not anonymized which means that the attacker can link the anonymize data to the true identities of the entities in the data set or is not data anymore which means that you have to destroy it so much to break the link between identities and the data basically what happens is that an attacker has some background information that links it with the data that you release to infer information about the data which is not in the release information right and this can go for like different types of data and recently we have also shown that machine learning algorithms can extract patterns from the data even it has been obfuscated a lot so if you see this kind faces in the that are used for anonymizing data it\u0027s not anonymous anymore so machine learning models can can reconstruct the identity of individuals so in general this is what I call inference avalanche there is some piece of information that is released there is some information that the attacker has combined together can lead to more inference about the individuals whose data was used for a computation and doesn\u0027t matter what type of computation I\u0027m going to give you some information about at an oil statistics and machine learning and for example for for statistics you have some data you want to release many statistics about the data records in your data set the attacker can run an inference attacker to identify which data sets could have produced these statistics and as you increase the number of statistics that "
  },
  {
    "startTime": "00:33:13",
    "text": "you about your data set the plausible later said that could have produced these data 6 reduces and some of them have higher probability of being the true original data set and it has been shown that the attacker can actually reconstruct the via the full data set with negligible error as the number of statistics increases even if the statistics are noisy a little bit all right or it can be used to identify whose data was using the in the data set for example NIH is to release the statistical information about the DNA of individuals who are in their data sets so the allele frequencies if you\u0027re familiar with the DNA data and from that researchers managed to find out whose data isn\u0027t that data set that resulted in this summary statistics which are very harmless right so just I\u0027m just releasing the average value of each attribute but but if there are so many of those statistics the attacker can actually identify whose data is in the data set and this had consequences a lot of data holders now stop releasing their data stop releasing the statistics about their data and so on and so forth now I just want to move to what is the topic of this talk that I want to briefly talk about and that is the information leakage through machine learning models right so you would say well if I\u0027m anonymizing data yeah there are a lot of attributes which are in the data set I understand how the attacker can join this data set with some other it is to reconstruct the identities if you really as a statistics maybe I can tell why this can lead to the inference attacks but machine learning models even those who design machine learning model don\u0027t know why the machine learning models work right so then how can an attacker exploit the information which is embedded in a machine learning model to infer the data set that was used for training of it so in a setting that we have is that we have some data set and that we use using some training algorithms to construct a model that does for example a classification for us at the time of inference or the test what you do is that you send some data points and the model tells you what is the probability of each class associated to the data that you have shared all right very simple very useful there are a lot of services out there machine learning as services provided by cloud service providers today that you don\u0027t even need to understand how machinery works you just upload your data they train a model for you and then you have this very simple API through which you can access it all "
  },
  {
    "startTime": "00:36:13",
    "text": "right and also you know we know that machine learning is eating the world so everyone is now using machine learning for everything any data that they have so it\u0027s very important to ask whether the predictions that I get from the model actually leak any information about the data that was used to train the model but note that at the time that you get the predictions the data is gone right so at first phase one we train the model now in Phase two we just interact with the model you send the query you get a prediction right so how can this leak information about the training data I mean before that I need to clarify what leakage means because when you interact with a model you learn information from the model right you didn\u0027t know that this patient is susceptible to cancer now you know you didn\u0027t know whether you need to invest in this plan or invest in the other plan but now you know which one is more important right you didn\u0027t know these things before interacting with the model so not any information that you learn from the model is privacy violating so what is leakage here if I can learn something about you by interacting with the model that I could have not learned if you were not in the data set means that the model is leaking information about you right because if I get some model and then I interact with the model and I learned that you know half of the population or male half of the population or female it doesn\u0027t matter if your data was there or not right so this is just generic patterns about the data but if I learned that the chance that an individual particular individual has cancer but I couldn\u0027t tell that while just looking at the general patterns of the population means that the model is leaking information about that individual right so this is what we call leakage and one more particular way of measuring leakage is to tell whether by interacting with the model I can tell whether your data was used in the training set of the model or not okay and this is what we investigated as I said there is machine learning as a service Google Amazon markers of others provide this data sorry this service and you have no idea what models they trained and the attacker has no idea to tell what models they trained but it can access the model through this API so what we went and we designed an attack that can tell with a very high accuracy so for this data that was some customers purchase data that was used to train a model online on Google and Amazon platforms with close to 90% accuracy you could tell whether your record was part "
  },
  {
    "startTime": "00:39:13",
    "text": "of the training set or not and the only access window of access to the model is just a prediction I send a query get a prediction and from that I want to tell whether some particular data was part of the training set or not so these are award-winning set of algorithms tell us that there is a huge risk of using sensitive data while we\u0027re training machine learning models so so that because we don\u0027t know how the model is trained therefore there is no way to extract information about the model some very simple statistics that I want to show to you is that basically the models are more confident on the data that they have seen compared to the data that they haven\u0027t seen and this piece of information could be exploited by the attacker right so the behavior of the models with respect to the data that they have seen during the training is quite different from the behavior the models with respect to the data that they see for the first time right and this is statistical difference could be exploited by the attacker and this is exactly what we explored if the model is released for various reasons now you hear about transparency in machine learning so the yes okay on what model do you use for certain decision-making you might have even access to the model parameters this is what we call the white box access in the model you know how the model come up with with a decision and you know if you look at these different types of machine learning tasks they extract all sorts of simple to very complex features about the data that help you then later on classify the data and what we ask is whether the parameters of the model each information for those of you who want be interested in the techniques basically there is a training algorithm there\u0027s an optimization problem that we solve for coming up with with a model and that optimization problem the way that we go through different values of the parameters until we solve the the optimization problem and we find out the final model totally depends on the data that was used for training them all so the footprint of the data can be seen and extracted from the model parameters and this is exactly what we looked at and again some other statistics that can show that the behavior of the model parameters with respect to training of test data is different and what we did was that we looked at where you will generalize models out there the best machine learning algorithms that are out there for some benchmark data set and what shows is that the ones that are even the best in terms of accuracy that generalize the best leak the most they "
  },
  {
    "startTime": "00:42:16",
    "text": "have huge capacity these machine learning models have so many parameters to embed the function that they want to learn and they use some of this capacity to learn the task the rest is used to memorize information and that\u0027s a footprint right so we went through all these different values of parameters by looking at the data and later on the attacker can can exploit this and in fear whose data was in the training set and even reconstruct the data that was used during the training so today I\u0027m asking this question if you look at different privacy regulations it says that the personal data or any information which are directly or indirectly related to an identified around at fybel natural person so basically the information that can help you to single out an individual and say okay this is this this information is related to this particular individual and now I\u0027m saying okay that the models enable us to single out individuals from any data and until ok this data was using the training set now can we let me just simply release models or use models in the cases where some attacker can can have access to it or on trusted entity have access to it it\u0027s it\u0027s a it\u0027s a big question is model personal data should we treat models similar to the way that we treat raw data because what the attacks show is that you can infer a whole lot of information about the models from the models about the training data right so it\u0027s a big question here so I want to just say a few words about what to do right so as privacy experts the first thing that that we do is to just identify why you need to use the data in what process and what is your trust model do you trust the machine on which you do the computation to trust the entity that is going to see the the end result of the computation what is a trust model and based on the trans model based on why you want to use the data we can design privacy-preserving computations that protect against these kind of inference attacks whether you\u0027re outsourcing the data whether it\u0027s a collaborative type of computation whether you want to do data analytics or you want to enable data release for acceleration and visualization all of these need different types of tailored defense mechanisms so for privacy tourism and computation in order to "
  },
  {
    "startTime": "00:45:16",
    "text": "protect against the attacks that I mentioned what do we do do we need to make a choice and one choice that we make is to just say what I am I\u0027m fine if general patterns about the data set are shared but I want to protect the information about individuals right we need to allow some information to be shared otherwise the data is useless right the computation is useless so what computations what kind of information do I allow to to be to be communicated the general patterns the ones that are not dependent on individual records and at the same time I want to protect information leakage about individuals I don\u0027t want one data point to significantly change the result of the computation so that the attacker can exploit in other words if you want to go and collect data or convince the customers or the data holders to provide data for you for your computation you want to tell them that well whether you participate or you don\u0027t participate right the information that someone can learn about you by observing the results of the competition is the same or more or less the same right because you helped us to learn the general patterns but your specific patterns are not leaked a few other techniques that I refer to them as sharing without sharing you have huge data set you want to release this data set or you want to learn something from the data set instead of sharing the data why not constructing another data set which is very similar but not the same as the original data this is through the process of data synthesis and the data synthesis itself should be done in a privacy-preserving manner so that the results the data set that is release cannot be linked back to the original data set right and we\u0027re designing techniques that can probably using mathematical rigor show that there is no way to link back the release data from the original data and nevertheless you can infer you know you can construct models on the synthetic data you can run statistics on the on the synthetic data and then use it for whatever purpose that you another one is collaborative learning and the idea is that and this is this is very important because in many cases we have many entities that have data but but they don\u0027t trust each other to share the data with each other right but they have the same task multiple banks multiple hospitals multiple financial even different departments in one organization and the the platform that that you\u0027re designing "
  },
  {
    "startTime": "00:48:18",
    "text": "allows these different entities to learn the same machine learning model together without sharing the data with each other but sharing some hints about how they are constructing their models but in a privacy-preserving manner so that those hints also don\u0027t leak information about the individual records in their citizens these are just two examples of how we can construct mechanism that can enable privacy preserving computation I\u0027ll stop here and be happy to take questions but if you want you can also look at our website to find out more about our research results thanks all right Thank You Reza are there any questions like once going twice ah that\u0027s away from dkg hi Daniel Kahn Gilmore ACLU thanks for presenting this year I think it\u0027s useful information and background for folks to have at the IETF especially as we move towards things like software-defined networking and other kinds of mechanisms that might incorporate machine learning in ways that I I\u0027m personally kind of terrified of I was curious about your point about personal data whether you know if there\u0027s any attempt to classify so one of the things that gdpr and other similar privacy regulations require or want to encourage is the ability to have your data removed from the data set and I\u0027m wondering if you think of models machine learned models as potentially containing personal data if anyone has attempted to categorize different machine learning models as models that you could remove your data from that is not only can your information be added to the model to make the model more accurate but that at some later date you could take an existing model and and knowledge about a person\u0027s information and effectively remove them from the data set is there any attempt to break that kind of does the question make sense yeah so basically there are two ways to look at this problem right one is by construction right when when I include your data in the training set can I minimize is the influence of your data to the model so that somehow approximately everybody\u0027s data is removed already right so I learned the general patterns but the information about it in the individual or the influence of each individual on the model is bounded right so somehow "
  },
  {
    "startTime": "00:51:18",
    "text": "everybody\u0027s data is remove except that like there is this small epsilon information about each individual which which which influences the model so it is one way to to look at it and the second way is well if I want to totally remove all the bits of information that you contributed to the model can we provide the provable guarantee that now your data is removed for certain types of models is much easier for complex models I don\u0027t know such as deep learning there does not exist a provable technique yet but but people are working on it so this is a problem that that researchers are working on it on how to I shouldn\u0027t prove that all the information about your data is removed from the model because otherwise you can just now retrain the whole model but you don\u0027t want to do that right so how can i with minimal effort remove all the information and prove the guarantee proof yeah you can only retrain it if you\u0027ve actually kept all of your training data around right in which case you may that that requires you to store even more personal data in order to retrain with a smaller so you don\u0027t want to retrain right so what I\u0027m saying is that overall you want to have minimal effort but provable guarantee that the data is completely removed if you train it with differential privacy as this is what we are we are doing now then the the influence is already minimum okay so how much more guarantee can you provide then then that\u0027s an open question right for complex models your chrysocolla trying to put together this talk in the last talk I know there\u0027s been a fair amount of work on on trying to build and there\u0027s been a fair amount work on trying to build learning models that don\u0027t involve the central server ever having access to your specific data using things like homework for encryption dollars and more techniques does that have any substantial impact on this on this problem ie fuses techniques you don\u0027t have to worry about release of the models or is that not solve the problem yes so these are two different trust models right so who the adversary is right is the adversary the one who is doing the computation or is the adversary the one who is observing the result of the computation right so what I was talking about mostly is about the adversary\u0027s observe the result of the conversation all right so let\u0027s say for example if you have a central server that blindly trains the model for you later on you use the model for certain applications then the inference attack is against the one who can observe the mulcher yeah no I understand but I guess my question I\u0027m getting at is that many situations in which the adversary is the is is is the "
  },
  {
    "startTime": "00:54:21",
    "text": "people doing them is the site which is doing the training itself right which is the machine learning site and that\u0027s why you want these privacy-preserving training systems and so I guess the question I\u0027m interested in is is that a stronger model in the sense that if you were in the formal sense of strong namely that if you were protecting as that model do you also protect against this kind of attack no no no no okay so these are two different types of attacks basically one one is the attacker who observes the other one is the one that infers later on with whatever is or catch you later yeah so you have n numbers you want to compute the average somebody computes the average for you without seeing the numbers right somebody observes the average value right these are two attackers you don\u0027t you want to hide the averaging but also you want to hide the fact that my data was used as one of these n data records Thanks all right thank you as a [Music] presenter for the next hour come up please Sandeep hello can you owe me hello guys so this is a talk about how we can improve privacy preservation by using a method of personal tagging it at the source so let me start with some basics what is log data so obviously so we all understand log data is nothing but a record of information activity of a user system or an application so the lot of devices application services do log the information about the activity of the user so log data is always useful to many actors in the systems whether it\u0027s a developer who can use it for debugging troubleshooting purposes also it could be operationally useful to monitor system performance measurements Layton sees and not and of course now nowadays for marketing to do analysis on the systems who understand what is the user behavior what is the user usage of a system of a service resource usage metrics and things like that and a very important obviously the use of log is security monitoring so we all already have a lot of tools which can consume a lot of blocks and be able to determine "
  },
  {
    "startTime": "00:57:23",
    "text": "what happened to an event if there\u0027s a security breach if there is a anti abuse or a fraud so logs are very useful source of information to go back track and figure out what happened to the system and what went wrong in the system so this is a basic life cycle of a log if you look at right from this generation of the log to its preservation it starts right from the source where a user activity gets triggered and it could be any intermediary in the path looking at the user flow as its forwarding it or processing it so every system in the path does contribute some information about what is happening to the user and what system itself is doing with the user and user activity typically we have many devices in the system so that kind of generate these locks and at the end of the cycle comes the log preservation so now the question is what you do with some of the log data that you have collected so there could be many organizations do invest on tools that have some kind of protection to the locks that are generated because we see a lot of locks now being shared with third party services for either monitoring or marketing purposes as we saw so there is always an activity to reform the log redact it in terms of the data that the log already has and then eventually give it to a third party or outsource it to different vendors to process the logs and then come up with some interesting information so if you look at the logs logs have been that for many decades right so we have seen right from the Network Devices to applications generating the logs so what has fundamentally changed from the log semantics so obviously there is more personalization of the log itself so there is more applications that are trying to pin the user information into a log so obviously and another trend that we are seeing is locks are no longer just owned by an organization or owned by a department in the organization so it\u0027s more shared either within the organization or across boundaries or of course geographies as well so largely for kind of purposes that we already saw and and also the log itself is no longer analyzed in in silos so it\u0027s basically combined with other events of the user or the system so there\u0027s tools that can do indexing and then come out with a common understanding of what the user or a system or a service is trying to do so it\u0027s no longer just in silos there is also cases where the log itself can be vulnerable especially when when you\u0027re sharing with the third party services the log data can be vulnerable "
  },
  {
    "startTime": "01:00:24",
    "text": "which can result in sensitive data leakage so obviously also app also has a lot of regulations in terms of how you handle your log data and how do you share it with different parties so and also a very important shift in terms of the log usage is the monetization of the log so just going from from monitoring and management ability management to monetization so what about privacy and log so it\u0027s there are already organizations that define log data as part of their privacy policies they basically address what which log data is being collected how they\u0027re using the log data and with whom they are sharing a lot of vendors do provide that user policy log usage policy but again the shift is now towards more regulation of the loss especially from a privacy the privacy working groups are more focusing and regulating the log itself the log data itself so how so when we look at log so we see a lot of challenges in terms of how do you identify something that is sensitive in a log how do you protect the log so obviously is a lot of ways in which we can process the logs but at the same time it\u0027s very subjective in terms of what a log what is sensitive data for in a log so it\u0027s something that the application knows very well so this whether additional IP addresses is something sensitive or personal again it depends on how the log is used and how it\u0027s collaborated with other events in the system but at the same time we are seeing a lot of vendors providing various tools like machine learning data set dictionary based methods to actually go into the log read the log and find out what is very critical about the log and try to provide a way to mask it or hide it so I think if you look at what is happening in terms of the privacy preservation or data preservation in in locks so it it requires some kind of a framework that we see here like right from this generation to the point of preservation of privacy preservation so it starts with log generation so this is a kind of a framework that we can envision in terms of the whole privacy even you apply privacy to the log it starts from the generation where potentially you can tag the log with some kind of a metadata so some kind of an accession token or whatever right then there are various ways to do that so imagine if we can at the source point to a system that this data that I\u0027m going to put it in a log is going to be very sensitive or it\u0027s has some degree of sensitivity to it right and that in turn can go into a detection system so where we don\u0027t have "
  },
  {
    "startTime": "01:03:24",
    "text": "to do any specific hard coding of course you can complement this with other existing methods and then be able to detect what is private data or personal data in the system and the log and then be able to additionally define what you want to do with the data whether you want to remove the field from the log or you just want to anonymize mask it or do anything any actions specific to the log so and also you can have different actions defined to different fields in the logs potentially so that\u0027s where we saw it could be differential reduction actions that you can enforce in the law so based on that idea so the proposal here is to look at a way in which the source can define some kind of metadata so as I said like which can potentially indicate the interesting fields or sensitivity fields within the log that is being generated so most of us have standard long formats that most applications use so imagine if you can add another framework or another data to it saying that while you\u0027re defining this log also look at what is going to be sensitive in the log so if you if the source can assert that within the at the time of generation so it could be more useful or more deterministic in the way the data could be preserved or policy enforced so this is a an approach that we investigated where you can add something like a PII data within a log so it could be at the field level saying that every field you can tag it with a private true or false kind of indicator or it could be at a log level where you can enumerate all the variables or all the identifiers in the log saying that this the private feeds so this is not something new that is happening with a lot of precedence in terms of how or the the whole method of identifying data so I hear some vendors that are already doing one way or the other so the so each one has of course its own way in syntax or a CLI that they define to pretty much define what private data is in a what constitutes a private data and in a log so this is of course a proposal that has been submitted so we\u0027ll be welcome to get feedback on what you think in terms of this problem statement so here is some hackathon results we just try to put it together and try to compare it but one of the reg X based approaches so obviously the results is that that an explicit marking you have of course has more deterministic results with heuristics or maybe a data set based approach you can get into wrong classifications or Miska or something else which is not private better getting "
  },
  {
    "startTime": "01:06:24",
    "text": "mangled so that\u0027s it\u0027s a very short talk and so you would be very interested to hear your feedback and what you think would be the next steps and can we do from a working group point of view thank you hi Daniel Congo Morgan thanks for this I the your your point about the way that logs are shifting globally is I think very well taken and something I I don\u0027t know how traditionally the IETF has not bothered too much with what happens outside of the network protocol and the this is now is starting to sort of starting to look at what gets into what\u0027s what\u0027s stored as a result I think that\u0027s useful but I can imagine there might be some people who are scared about seeing mission creep or something around it but I do think that we that we should be addressing it I\u0027m wondering whether you\u0027ve whether you\u0027ve looked also at systems for like deterministic or format preserving encryption for logs yeah it seems like it sort of fits into this general framework I know that there was some discussion with Indy Prive about IP address within deep breath the I don\u0027t remember there was other discussion here the IDF about about that kind of work and it might be worth trying to fold in these questions about you know key rotation and things like that like what you can do with these when you have fields that you want to to scrub my one other piece of feedback for this is that this seems to take for granted the idea that the way that you identify PII as you say this field this PII and this field is not and well I think that\u0027s tempting from an engineering standpoint I think it is very unrealistic in terms of what actually personally identifiable data is that I did is identifiable in combination and not as specific fields and so you could I mean my name is not personally identifiable because there\u0027s somebody else who has my same name but that in combination with my with say the state that I live in is and so maybe the name is not be iin the state\u0027s not PII but the two together are P and so this is this is a problem with the Const PII itself but I think we need to be careful about enshrining that in in our data representations yeah that\u0027s a good feedback thank you yes so just I\u0027ll just respond as to your last point EKG also I think we were definitely I see as your draft thing that we\u0027re just saying that PA equals true I think definitely agree that that\u0027s not you know that\u0027s not sufficient I think one thing you were looking at was sensitivity level so you "
  },
  {
    "startTime": "01:09:24",
    "text": "could maybe classify certain fields as belonging to a certain set of feel you like in terms of how sensitive they could be in combination with others and then you could have a policy where if you know there\u0027s too many of these then you say that Oh redact all of them that\u0027s something we did think about this is interesting we have actually been trying to address this at the basic level because it\u0027s sexual a problem you have whenever you have an application that generates logs today in Europe at least you have to defend and perfected that personal information even just the IP addresses that are in the logs so we have been experimenting with for example and clipping the IP addresses in place and in a way that they can be light of the cripton if necessary but with proper procedures in case of monitoring law enforcement in this kind of stuff so maybe it would make sense to have some kind of best practices across the industry on how to do this in a consistent way even if each application even for the same kind of service has different log formats maybe but maybe some discussion on general principles could be useful so that we get to a good way of doing this was heard Karzai two comments one actually did tkg\u0027s point the ATF has a lot of protocols that actually shipped logs around in various formats including you know everything from and actually shipped straight in DNS they\u0027re shipped in syslog they\u0027re shipped in syslog-ng they\u0027re shipped in net comp they\u0027re shipped and you know there\u0027s actually a lot of places where log information is sent an SNMP that so I like your approach a lot there\u0027s only one question that I had with it which is you specifically said no hard-coded rules and I don\u0027t understand the motivation for that of why you wouldn\u0027t do both hard-coded rules and machine learning because her rule hard-coded rules are pretty much a guaranteed ground truth always will match because I\u0027m removing you know a user name field that I know about whereas if you just let the machine learning component take over it just make it a 80% chance of removing now sometimes can you just debate it because I think you the question was about no hard coding was it that so go back a couple of slides that one this one yeah so you said detect personal data and you had no heard coding okay and so I would think that you would want a combination of a you know of an automatic you know machine learning best approach and you know expert knowledge where you know it\u0027s always right yeah yeah that that\u0027s a good point so obviously it\u0027s going to be like a compliment to what mesh methods are already there so just that it could be another input for a machine learning model to see okay this is the indication from the source that the degree of sensitivity could be there so that way it could be used well specifically I would think I would use the log "
  },
  {
    "startTime": "01:12:25",
    "text": "detection mechanism and with that augmented with you know expert knowledge at the end so that the redaction took both you know the the fixed hard set of rules and the machine learning component and then did either or of them you would remove this channeling Chris lemons from Comcast from Java I think this was in response to de cádiz comment which is what happens off the network is often a consequence of what happens on the network it\u0027s easily in the scope in my opinion what happens of the network what happens off the network is often a consequence of what happens on the network and it\u0027s easily in the scope in Ben Schwartz if you\u0027re looking for a place at the IETF to do this kind of work I would suggest narrowing scope here or narrowing generality and trying to look very specifically at a specific existing systems that generate logs one that comes to mind is HTTP request logging which is of course almost universal that\u0027s a case where the IETF has substantial authority and if we for example identified different kinds of different specific header fields that that should be logged differently in different circumstances that\u0027s something that we could reasonably make a recommendation about I also know that there are there are people out there who believe that servers will log their HTTP requests in different ways and have encoded assumptions about that into how their clients behave so for example I\u0027ve seen I\u0027ve seen assumptions in systems related to doe that requests of the form get will have their full query path log but requests that are formed as a post will not have the post body logged right baby and that is in fact a popular that is consistent with implementation but it\u0027s not something that\u0027s ever been it\u0027s documented and standardized maybe it should be yeah I think that\u0027s agreed that generalization is it a part part yeah because some of the vendors that we are seeing there again focused on a very specific type of log that they want to provide the redaction so the very specific for instance they only look at HTTP packet or they only look at maybe SF CFL kind of a formatted log so but I think you\u0027re pretty right in terms of saying that we have to narrow the scope one reason to keep it general was to like have a deliberate decision to keep it like a research document trying to see explore the space essentially but I agree like if subsequent jobs try to make it more narrow that would be it\u0027ll belong in the IETF Thank You Allison "
  },
  {
    "startTime": "01:15:28",
    "text": "Menken Salesforce thank you for the great presentation I support adopting this as an IEEE RTF document just to back to something that Ben just said I think you don\u0027t really have the option of being very prescriptive but you can actually provide of you can but it will won\u0027t be standard but you can provide questions and guidance that can later be valid valuable into the standards process a thing that struck me about that was I mean there\u0027s a there\u0027s a saying that the best logs for privacy are the ones you don\u0027t retain and you you gave this great statement that you know people have more and more reasons why they\u0027re retaining and using logs perhaps this document could also talk about kind of a time limit like at a certain point you really have made a tremendous loss of privacy by keeping it beyond that point and give some of the reasoning for that and that might help to advise people to to improve their policies I know if you have a comment on that okay so I think it also depends on the policy privacy policy itself right I think there are a lot of organizations the regulations that define what is the timeline I think it\u0027s a good input but we\u0027ll have to look at it from the privacy policy point of view and see if we can put those guidelines but you are right in terms of identifying a specific time limit as you said right it should be useful at some point of time it may be we have to be more pragmatic about that agree thank you it\u0027s Chris lemons of Comcast in the Jabra chart again consider the audience who will read this document people who write drafts that standardized or generate logs might be a good set of members for that audience I didn\u0027t quite get it can you repeat it again yes I\u0027ll repeat that consider the audience who will read this document people who write drafts that standardized or generate logs might be a good set of members for that audience thank you all right so there seems to be some interest in this document and there\u0027s some overlap with work that\u0027s going on in the IETF can I get a quick show of hands from people in the room who have read this so a couple hands go up how about a show of hands of people who are interested in this particular topic a lot more hands noted okay so I guess based on that I I\u0027m gonna do a home for adoption right now so the question is pretty simple if you support adoption of this particular document into the research group please home now and if you do not support adoption "
  },
  {
    "startTime": "01:18:31",
    "text": "please home now all right so there seem to be stronger support for adoption of course we\u0027ll confirm on the list and go from there and if you have any comments on the document in the meantime please you know reach out to the authors or something on the list as well that\u0027d be helpful thank you thank you alright hello everyone names Chris Wood this should hopefully be very quick because we talked about this last meeting in Montreal or there was a talk similar today in our W paper that was presented and we presented some results that were similar to it so this is just going to go over the document that we have sort of describing the network based website being a pending problem and ask you some questions so some background for people who were not there in Montreal and don\u0027t really know what I\u0027m talking about website fingerprinting very vaguely or broadly is this class of attacks that basically try to use metadata of some sort to figure out some sensitive application data so a common example this is looking at Ben from TOS connections like the sizes of records or the timing of records that are sent over a particular connection in trying to infer what application data is sent equally could be looking at the IP addresses of you know a particular connection in trying to infer what the service or domain a particular connection corresponds to we\u0027re not being super specific with this particular definition it\u0027s just generally about using metadata to identify a particular website or service and so this document sort of was born out of discussions with Ian Goldberg and Tawang who are heavily involved in the Tor community basically asking whether or not all the attacks that have been done on tour or sort of relevant to or applicable to you know things that we would do on the ITF and moreover to what extent are these attacks applicable in practice and do they scale well to you know the internet so in trying to you know get our heads around this we basically went and looked at a bunch of research papers that were published on this topic and summarized them both for our own knowledge and hopefully for the benefit of others who potentially read this here\u0027s the outline of the document if you have not looked at it so it basically it goes and describes the general problem describes the known attacks that are that are in these papers describe certain defenses that are also been experimenting with and "
  },
  {
    "startTime": "01:21:31",
    "text": "have been deployed in practice to some extent particularly in the Tor space and then ask some open questions for how these might be relevant for you know existing ITF protocols or ITF protocols going forward so pretty straightforward very similar to Joe\u0027s draft on censorship tech in the sense that we were just serving existing stuff so a question to people here are first is this useful to anyone besides me because I in writing this down I had to read a lot of papers and that was useful so I\u0027m learned something from it maybe it\u0027s useful to the IETF or I or TF who knows and if it is useful should this happened here in perigee or elsewhere who knows does the scope need to change if we take things out remove things whatever and similar to Joe\u0027s draft this is sort of problematic because the nature of this document is whenever new paper is published I go in and summarize it and put it in and that sort of implies that you know publishing it something that\u0027s sort of stable is not perhaps the best way forward so I will defer to the mic that was a lot of questions all right I mean yeah go I mean yes this is absolutely useful um you know we you know there\u0027s like a long list of mechanisms that allow you know that allow passive or active observers to determine what your you know what browsing behavior is and you know once we finish like removing all the ones that like just like steak flat out what pressing behavior is you know eventually this will come like the easiest way to do it and so getting a handle on how to fix that it seems like super critical I think PRG seems like the right place for this it\u0027s hard to see where else it\u0027s gonna sit I don\u0027t think HTTP really is gonna like know what to do with this um I think you know that the output of this work you know or recommendations for a shippi should do to like actually pretty figure pretty harder would be something you could feed into HTTP um um I I agree like probably having an RFC doesn\u0027t seem like super like how fol cuz it\u0027s kind of static um um you know I don\u0027t know maybe the IDF application process is lightweight enough that you could like crank out new RC every year or something but the existence of this document seems like super helpful um so I would encourage you to keep at it and I guess I don\u0027t know the RTI process well enough but you know a dump things working group items at the signal this is like something that we think is important sometimes viable yeah it may be with respect to the how frequently update the document may be the approach is just make it a github page or something and then I just update it there and point people to it from the purging thing I don\u0027t know yeah I\u0027m gonna I see Cullen\u0027s bike way behind us so he has an opinion and how does that work but this is a good work and you "
  },
  {
    "startTime": "01:24:31",
    "text": "should keep that Thanks yeah I totally agree I think it\u0027s useful for our chef and I think ietf I think folks you\u0027re gonna get wider readership from folks who just like with the censorship graph people walk up to me and they\u0027re like wow this is really helpful for a number of reasons and they\u0027ve never you know touched protocols I think the scope is right I do wonder if there\u0027s gonna be a way to capture things that maybe don\u0027t make it necessarily into the academic literature I know that\u0027s where you sort of started from and maybe that\u0027s something to think about like what what level does it reach to make it in there and I guess in terms of being living I don\u0027t know there\u0027s nothing wrong with having an ID that gets updated occasionally and and peeled off if we need something to point to as canonical but yeah I don\u0027t know if I have anything useful to say there but yeah thanks all right this is Joe from I suck that just to clarify the criteria for the criteria for putting something in this document was very low I had to do something with what\u0027s I figure bridging and it had to show up in my Google Scholar Alert so that\u0027s pretty much it this is general Khan Gilmore so thanks for this seconding previous to commenters we definitely need this work the the framing of web site fingerprinting I think is maybe a little bit confusing given the way that we\u0027re talking about HTTP as transport these days and so it might be worth trying to think about what we want to talk about there right yeah I\u0027m a bit unhappy with the term website fingerprinting it\u0027s just what\u0027s used traditionally in the literature typically because like it started off in tour in that particular way and they\u0027ve just carried it forward so yeah if there\u0027s a better term the more accurately capture what we\u0027re trying to actually do today I will happily use it not sure what it would be so so what\u0027s interesting is that it used to be that you\u0027d say website fingerprinting because you were distinguishing between that and other forms of network traffic fingerprinting but now that most network traffic wants to be HTTP traffic in the first place all of a sudden we\u0027re back to kind of network traffic fingerprinting point yeah so so I\u0027m not sure what balances as far as the live document or whatever please keep working on it let\u0027s have revisions for it if it turns out that it\u0027s useful to say here\u0027s what we think network traffic fingerprinting looks like in 2020 that\u0027s a that\u0027s a perfectly legitimate document to produce as long as we continue to revise that you know the the baseline draft that produces that so that maybe we want another one at four twenty twenty five but that but but yeah I do I do think we need a place to collect this information and we need a place to point people to when they start designing new protocols as they inevitably will that make these same mistakes again thank you just like given up on the mic stand here gotta go "
  },
  {
    "startTime": "01:27:38",
    "text": "back to first principles here miss Richard Barnes I\u0027m just gonna +1 all the comments about this being valuable work and caging mostly cover what I was thinking about you know extending to non web applications because like everybody uses HTTP now and concerns for fingerprinting what apps are on your phone is very similar to consume a fingerprinting what websites you\u0027re visiting as far as stability like I wouldn\u0027t be it doesn\u0027t seem like we would fail here if we produced a snapshot at the time and revisited at the time a one thing that could be done to give this a bit more longevity is to think about whether there\u0027s some you know abstractions one could make over the techniques in the literature and to discuss general classes of attacks I mean kind of call those out as guidance for things people to consider in in designing protocols we did this there\u0027s something similar a few years ago a few IAB folks and I did a draft about censorship techniques on ways you could do blocking where we talked about generic classes of approach to that that problem so to speak and in ways that in the you know the advantages that the the ways they could be deployed and the things they break and so I think a similar approach could could work here I haven\u0027t I admit dived into the document real detail but that would give that this document a bit more longevity yeah good suggestion we haven\u0027t taken the time to sort of try to generalize anything it\u0027s really been just a brain dump of what we\u0027ve discovered in the literature but that\u0027s a very good suggestion yeah thank you hi Colin Perkins we\u0027ll see if this microphone falls down before I finish talking see ya I think this work is useful I think this research group is as good a place as any to do the work and I don\u0027t have any objections to that in terms of the the living document type thing if you\u0027ve only ever published RFC\u0027s via the IETF side I think you\u0027ll find the process is perhaps lighter weight in the IRT F yeah I mean XML fee-free but you know means you can add pretty pictures no but I mean seriously I think you\u0027re keeping this sort of finger life as an internet draft and occasionally pushing out snapshots as an RFC and makes a lot of sense you that this is the state of the world as of 2020 or whatever it is and then just keep keep it ticking over and then in a couple years time well we\u0027ll publish another one okay yeah that seems you deal with me yeah we got plenty of RFC numbers right yeah I\u0027d might as well is it even opposed to us asking for adoption right now please step up to the mic right now okay so all those in favor of adoption of this document by Paigey please hum now all those not in favor of "
  },
  {
    "startTime": "01:30:39",
    "text": "adoption please have now perfect same we\u0027ll take you to the list also and yeah take it from there thanks Chris yeah Thank You Bernie [Music] afternoon my name is Bernie niacin I am having a short presentation to frame the discussion of the next document is presented by Eric Ries so there is an activity going on called meetup missing elements for decentralized usable privacy and just following background so we are working on solutions that are decentralized end-to-end peer-to-peer for reasons of mitigating the adverse effects of process monitoring because it\u0027s an attack to privacy and has been documented in RC and centralized elements are usually more prone to attacks because if you have two centralized delavane you have everything and if it\u0027s centralized the effect is limited usable because message encryption has law for most Internet users I mean who of you has already tried to set up PGP not so many who of you managed to do that in less than one hour the first time okay a bit less anyway but whoever would consider that people who are not attending the idea throwing something completely different are able to set out the PGP kind okay zero and that\u0027s actually where it comes from we need folks fixed is usability challenged by automation because people are simply not able to do it on their own if they are not getting enough help and that\u0027s where it\u0027s coming from is usable and privacy we consider privacy is a human right so this medical tech TV team show I can\u0027t go into all details but basically it\u0027s about enhancements to application protocols for decentralized usable privacy it\u0027s based on opportunistic security and the whole thing emerged "
  },
  {
    "startTime": "01:33:40",
    "text": "from the initiative of pepper pretty easy privacy it\u0027s a foundation that piece doing implementations in this area but it\u0027s not limited to that it\u0027s also like other people working in the field for example autocorrect are invited to participate directly actively contribute to meet up and the goal is to define the missing pieces like key management private key synchronizations message formats trust well change etc I can\u0027t go into details of this we meet in so-called non working group sessions during IDF meetings with the exception of this one you\u0027re not having these kind of sessions otherwise he had it last free IDF meetings I think we have a mailing list set up made up at ITF talk and you can subscribe there if you\u0027re interested in the field and at some point in time we are aiming for both to be an ideal working group and work on this a bit more in the proto sense so what\u0027s there so far all these boxes for representing internet craft I don\u0027t know how much time we have that I can go into details of all the boxes or should I just summarize okay yeah right okay so basically then I talk about the four corners like the pink corner is more or less what has to do with handshake and Trust then there is the application corner which the brown corner for example use it in email but also instant messaging and we are even using it for banking transaction for example Swift Network is using the same technology then we have the private key synchronization area like that you have different devices and generate the key with one the ability to encrypt your email and read the email on the other devices usually don\u0027t work unless we share the keys and we have a solution for that it\u0027s already implemented and the green area is like the core area with requirements the cost of end what you hear as next is basis for that green area it\u0027s the fret analyzes that out of the fret analyzes that is discussed in this next presentation requirements are coming or part of requirements are coming so now we know where this next presentation is fit to and I would end or to in raqqa stem okay I might need the speaker maybe not like that so hello everyone thank you "
  },
  {
    "startTime": "01:36:41",
    "text": "for Pierre G and ITF for inviting me and for this long-standing contribution I want to break this presentation actually it\u0027s a call for stimulate discussions and to call for contributions under the keywords a break down the title of this presentation on this four points a systematic analysis of security and privacy threats for private messaging and what I\u0027m talking about private messaging I\u0027m talking about emailing and instant messaging okay are miracles many ways I\u0027m a postdoc to give ambassador of Luxembourg and this is a joint work with pet with Bernie Hansen and Nanak Carol character so very quickly is still a relevant problem private messaging in mail and it\u0027s a message II so does quickly in the numbers I\u0027m not gonna sting - Matt\u0027s 3.7 billion users email with a future predictions even more we see a little bit dropping on the private use but still like 75 billion users approximately females here just to say on these numbers and the statistics that these prominent these two are messaging applications actually are belong to a single application provider and we see this distribution roughly I would say the percent of the world is under a single service provider so do have a systematic way of analyzing the threats and the requirements what is usually been done in the RFC and the first f70 P 821 back in 1982 we build it I did with a very nice system SMTP but initially without security into consideration so we found out a bunch of threads for instance two least one monthly middle attacks then we started designing systems that you have that ahead like client-server decryption like start TLS and you had all these nice analytics of Gmail showing is to our browser like all your flight is at that time you should consider going because there is a traffic or not surprisingly in 2013 we got the spring project which is not the revelation that they showed us oh by the way this information is not going only to you but is going to some Secret Service analytics systems so we shouldn\u0027t consider trusted the servers of email servers and be some basic servers that they only keep the information only to ourselves so we start building "
  },
  {
    "startTime": "01:39:41",
    "text": "end-to-end encryption as mine we thought that centralized systems they might even not be that robust and privacy security privacy preserving because they might send different public keys we have open PGP and this summer we had this proofing of certificate poisoning which I\u0027m not going to go into technical details but essentially they break up open GP because they made it very buggy and large start shining sorry signing certificates they make very large and buggy certificate certificate and then when you download it sexually was breaking of new GP ok we found out ways to have internal encryption with great security protocols but then now what there is a harder problem with metadata and this great person the general for NSA director said that well by the way we might don\u0027t know to what you are saying but we kill people based on metadata and even there are like academic work very good academic work or like projects successful but still there is no application so where are we now there is a lot of academic work but usually the approach is like we think that these threats are really relevant but what we if we do it the other way around we start mapping the list of threats and we start like instead of running after the attacks we start designing systems by very beginning so EF first started to on this direction try to evaluate and try to make a list of design security features but this specific is a website but this is limited categories is obsolete right now and it evaluates only existing apps so the aim of this internet document is about to assess to have a security and privacy threat modeling requirements are a holistic systematic approach and for assessing existing systems or this when designing a new system systems you can use it for as a guideline and this takes into consideration technical threats security and privacy but also the user threads there is keep on discussion on intelligent service about backdoors and this is not a technical vulnerability this is an issue of opening a backdoor in their system and this is a user threat so we think that as a basis for "
  },
  {
    "startTime": "01:42:42",
    "text": "private messaging maybe it\u0027s a good fit for later and for ITF and ERG PR to consider adopting is as a working item okay what is in the internet draft what we have what is our contribution until now so as we will we\u0027ll show you a little bit later on we have a system model we define the system model meaning what exactly the entities and the functionalities which are the adversaries what the adversaries can do the class of threads the class of requirements and later on in a later phase in this document or in a later on we will have the risk approach because now we consider the threads uniformly but maybe you want to evaluate the threads and then which are the crypto protocols we have all the crypto primitives for instance OTR so if I am to say the system model in a halt it could be the Italian Bob wants to communicates and want to exchange messages or it wants to exchange emails or instant messaging using instant messaging systems and here we have the networking nodes and we have splitted the trust establishment which is essentially to have identity key and contact management and third parties and what we can do is we can start playing with the threads with adversarial models and when we say adversary model we are talking about whether advisor is a passive we say owners but curious it tries to not break the system but it tries to extract as much information as possible it can be active adversary and can be internal or external and here is the list that we start have started compiling and this first list the first two columns is about security threats and and security requirements and this is extracting this is a methodologies being used by Microsoft with a straight framework so essentially we try to find out all the possible threats in these classes of attacks classes of threat and the corresponding requirements so the same seeing as a methodology we did it with privacy but I ever see uses we used an academic were called Linton which we adopted it for our needs and I want to highlight three specific points so for confidentiality information disclosure there is this is a threat to security and privacy however for non-repudiation "
  },
  {
    "startTime": "01:45:47",
    "text": "it might be a requirement as a security but an issue to privacy in the for a privacy can be an issue and it\u0027s actually how are the arts been built that has plausible deniability so having a map of threats and requirements we can very beginning at the very early States point what we need to do another thing is the privacy interdependence think about the case where you\u0027re installing an what\u0027s up or a signal and all your contacts go into the clouds and that is a matching who has this application so essentially what you do you send your whole social network to the cloud provider of what\u0027s up to do the matching and notify your home has the same contact who has the same person stole the same application so in signal there was a lot of discussion how you can do it privacy preserving word so we might have had recall the previous slide it\u0027s not only metadata about who communicating but also like with whom we have exchanged information we have our contacts shared so just a case study just to show you what we can do with that what we can do with this internet document and what we have done if we start discussing about okay if you start placing at the other siren model that could be for instance the mail servers we can have protocols as start TLS which can preserve confidentiality NDT and data fornication but we consider what about if we start consider in mail service as passive adversaries or as materials that will constantly try to read our information to read our email and instant messages then we start playing with for instance s/mime we thought that okay what about I don\u0027t know okay here\u0027s great so what about if public keys that are my shirt are spoofed for instance I\u0027m using a public key that\u0027s supposed to be for my friend Bob but this actually is not we have this issue of certificate flooding as I said which in specific a third party we can frame it after party and external adversary is aiming to break to do a denial of service attack and in this particular case Bob is considered as adversary an OTR has been "
  },
  {
    "startTime": "01:48:47",
    "text": "designed considering this this very much this very principles of confidentiality entity and data education forward secrecy and deniability so we can start called peeking threats that we need to design a system for and we have specific countermeasures and having the whole map of adversarial models we can say exactly what we need to do instead of going the other way around saying I believe which can be as an expert you can have a very good overview of what is needed but we think that as a systematic systematically it\u0027s even more important to do it as we can see the whole map of threats future directions well there\u0027s a lot of work that needs to be done so usability issues on top of EDP and bgp has been discussed in the previously and there are three Kaka demic papers from 99 16 and 0 6 so we have a key management issues and still the problem remains about how we can use it how we can make it more usable so that can be another issue and the requirement that we need to design our system but we need to consider our system design so that not only designed in an engineering way but also like to make it practical so there is a lot of push from intelligent services with different arguments about back during and this is like very recent news about us and UK and a stress in Australia to just start back during and we think Australia already passed a low but I think that it\u0027s not active they say they\u0027d have inactivated and us there is a human rights and law of the private privacy of correspondents of females you cannot offer males we cannot open the mail in a non war times the same should apply as a reasoning the same should apply in the deed in the digital world and finally there is a lot of discussion about post quantum crypto and there is a call by professors and academics and experts in the field that we need to start considering moving towards that because the time that will pass so companies to adapt for new plot to design new protocols it takes time information that we are storing in our system needs to keep it for 10 to 50 years so we already need to start designing new systems that would consider post quantum security instead of running afterwards we need to be "
  },
  {
    "startTime": "01:51:48",
    "text": "proactive so that\u0027s all for my site if you have any questions it\u0027s very welcome thank you then Schwartz thank you for forgiving the deep thought to the important topic I I definitely support this work in this area and and this draft seems very well written but I had a few comments about this I think that this is a fairly opinionated draft it doesn\u0027t seem like a neutral summary of the field it seems more like a coherent framework that you\u0027re presenting I was just giving it a name essentially presenting it as a new named framework I would also suggest thinking about it as a framework instead of describing it as an analysis or especially using the word requirements which occurs a few times in the draft certainly if the IETF requirements refers pretty specifically to setting yourself up to do specific protocol based work at it doesn\u0027t seem like that\u0027s the real purpose here I would clarify the scope some some of the research I\u0027ve seen here suggests that at least for ordinary users if you ask them what kinds of security threats they\u0027re worried about in in private messaging context the things that you listed here are not at the top of their list the things you listed the things that they tend to list our insider threats things like people peering over their shoulders or their boss checking their phone while they have it in a in a locker those are really important security threats and it\u0027s fine to say to make them out of scope but we should clarify scope and I would suggest thinking about this in terms of communication not just messaging both because I think the the technology itself doesn\u0027t matter and because video because that what we\u0027re really thinking about here is communication between people whatever form that takes in particular video chat and related stuff I think it has important privacy concerns that we should be thinking about thank you very much I would suggest to take you to a flying and go point by point later on you tell me exactly and very much up in exchange I just want to be sure that I understand what\u0027s the objective of the work you\u0027re opposing because I mean are you trying to write a set of requirements to then design yet another instant messaging protocol that this time will be private and secure and so because I think that it was already pointed out first of all in the scenario an email and instant messaging is pretty different because an instant messaging you only have walled gardens and when you have walled gardens there\u0027s no way you can exclude it whoever lost the server of the service you\u0027re using so that\u0027s already I mean a basic problem from any care for any kind of privacy "
  },
  {
    "startTime": "01:54:49",
    "text": "security you want to to grant with email it\u0027s different because you could choose your server but still you you have lot lots of other things to address but also I mean having spent some time time to me in the real world convinced some big email operators to just adopt existing technologies like Dane and DNS SEC for example to make it efficient more secure I agree that that the problem is this problem is not very high in request of their users or of the people that runs the service so some if you really want to advance the discussion maybe there\u0027s non-technical things that we should discuss if you want to put this only at the technical level then I would like to understand what the objectives are what what you want to achieve in practice so the objective of this internet document is to do it in a way of mapping the threads in the technical aspect from a very beginning instead of pointing later on we have this thread let\u0027s try to patch it let\u0027s try to figure figure how we\u0027re gonna design a system so this is like for evaluating existing systems and protocols and all you want to design a new and I\u0027ve you are a security engineer or a privacy engineer that you will be able to see which are the threats what you need to do what what are the existing systems crypto primitives protocols one point that you said I don\u0027t know if I\u0027ve covered your with my answer we can also take it offline one thing that you said is system messaging and emailing is different yes but one is low latency the other is high latency well nowadays both systems and in the in the messaging aspect they both have common points with both if we just remove the XMPP if we just remove the SMTP like the transport how we transport on the format if we see it like us what we need to safeguard so we send text who set attachments and we have our archiving or searching we have I agree that technically I mean we are working on chat or IMAP so I mean that\u0027s not what I was pointing out is that they are very different in that architecture of the market and the service that people actually use so it\u0027s a non-technical difference okay okay thank you very much Paris koala I mean this is an interesting space I guess I\u0027m a little less sanguine about this document particular document that Ben is the as Victoria was saying like trying to like span email and instant messaging in video straight me just really difficult you know like the MLS work here house "
  },
  {
    "startTime": "01:57:49",
    "text": "like a fairly well-defined threat model in the organizer document that rise like map output the threat model is but a lot of it\u0027s actually fairly specific like the MLS setting and so and and the if we try to like expand that to email I think it wouldn\u0027t work very well and I think actually part of like like as an example of that on the slides you have about like how awful PGP is interface is like basically don\u0027t apply any instant messaging systems it actually have extremely streamlined um you know you know key discovery and set up if I call just other problems but they don\u0027t but they don\u0027t have these problems about like key discovery they\u0027re complicated um so I think trying to like you know have some document that like is a master document like for all message like model for all messaging like ends up with you like rating like a quarter feet export and like you know and describing dole of yeah which is like not super helpful so um so I like I would encourage you I\u0027m given that like that we have existing work um in the IETF on in it is like designing secured your first measuring right now to like um if you want to work in there\u0027s a meshing problem to engage there and if you want to write like an email for analysis like this might be an okay place for this but then this document needs some provision to like actually be that understood correctly the question I don\u0027t know I don\u0027t want to say open PGP or PGP is awful okay no I know that\u0027s not my point what I said is we have some facts and some analysis of whether it\u0027s working until to which extent or which issues we have to be considered like based on the academic world that exists so time check one minute yes be mine so this is more like here in this room and in ITF as Badar there is a lot of expertise and that has be done a lot of work so it\u0027s more like a call for discussion instead of doing things like I do believe or like with us maybe you were set up like we start doing as a systematic way of threads and identify the whole spectrum by bringing the expertise everyone has and then have an internet document that will help and guide others that will like to design engineers that would like to design right is it like did I answer why again what\u0027s the question I guess what I\u0027m saying is that like this document would not be helpful for designing MLS it would not advance the state of the art it might be useful um some other versions dog in the beasts for analyzing email but if you want to contribute to the design of the protocols we\u0027re actually doing here then I don\u0027t think a document census tract is gonna be very helpful very quickly Richard Richard Barnes yeah similar page to echo at all I think you know I I agree that this is an important problem with the state of messaging security especially for email is really terrible but I don\u0027t think it\u0027s because we don\u0027t understand the problem sufficiently in contrast to dr. Woods document about a "
  },
  {
    "startTime": "02:00:49",
    "text": "fingerprinting where there is like open uncertainty you know active research about what the threats are I think we actually understand the problem pretty well and even in the MLS case we\u0027re writing a document to document the threats were addressing in the architecture for addressing those threats that\u0027s more about kind of consolidating on a view and making sure that everyone\u0027s in the same page because everyone already had fairly detailed internal models all of the vendors who are coming to the table for MLS and so that was more of a consolidation effort than research really so I think this is probably not appropriate work for a research group here this is dkg so I think I agree with Eckert and Richard that this document might be too broad to be particularly useful in contrast to what Ben was saying Ben I\u0027m suggesting maybe we could abstract it even further I mean the way you had split up your architecture it looks a lot like you could use it to discuss IPSec in that you have trust you know Association context and then you have the actual messaging security and you have to transport all of these things right you could actually evaluate IPSec with the same framework that you have but at some point it becomes vague enough that it\u0027s hard to know what\u0027s actionable where with regards to whether this is actually useful for research Richard I think that the that the work on a fail in the last year shows that we actually still don\u0027t understand scope of attacks against email against and and protected email and and I actually do think that it would be useful to try to document this for a specific application domain like email because I I believe that there actually is more I mean we\u0027ve done such a bad job of defending against the attacks that we do know about for email that no one feels like it\u0027s worth showing that it\u0027s even more broken than it is but that doesn\u0027t mean that it isn\u0027t actually also more broken and so I do think that there\u0027s actually room given the evidence for like the low-hanging fruit that we saw from a fail there\u0027s room to identify more problems there and so I don\u0027t I don\u0027t think this is going to be fallow ground for for research even but but I do think that it needs to be more scopes to be useful or entitle more tightly scopes to hi I\u0027m Mallory noddle from our 19 it was a question I\u0027m I didn\u0027t understand what you were trying to document was it that how the actual threat is compromised or is it the threats themselves because I think what you\u0027re trying to do is look at threats from a like bring user level threats into the conversation which would be very useful but now after do these comments I\u0027m not so sure that\u0027s what you\u0027re doing user threads it\u0027s mainly these documents about technical threats which threats can be the classes of threats and what actually does it mean and private communication private messaging system in a future consideration we need to think about just we with we think that we should "
  },
  {
    "startTime": "02:03:49",
    "text": "also consider other user threats in terms of but this is can be in another document not in this one it does this one I try to capture all the directions that we think of that should be but it\u0027s not in this document so for I\u0027m sorry um we\u0027re way over time can you take this offline thank you thank you everyone you "
  }
]