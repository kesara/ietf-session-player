[
  {
    "startTime": "00:00:08",
    "text": "no no um is yeah okay it's 9 30 here in London well time to start the ippm session first session of the week so um welcome everyone um if you're not here for the ippm session then um please check which room you want to be in um Tommy is here as well he's joining us from California it must be a nice time of the day there it's a dark and rainy so we are celebrating traditional winter England weather here so this is an ietf session so you should familiar familiarize yourself with this note well slide you will be probably be seeing it quite a lot during the week but basically everything you say here is a contribution to the ietf when that comes with a consideration so if you're aware of patents and things like this you should you should familiarize yourself with the guidelines and rules around that uh it's also important to"
  },
  {
    "startTime": "00:02:01",
    "text": "note that things here will be recorded and can be publicly be made publicly available online so so you're aware of this um and please uh kind of maintain a respectful tone to each other when having discussions and disagreements and there are a lot of documents you can read if you want to further familiarize yourself with any of these matters right also for people who are on site remember that we have a masking policy here so you need to wear masks in all meeting rooms and it's also recommended that you do that in in the common areas but not required um you may briefly remove your masks if you're eating and drinking um but that cannot be an excuse for leaving them off for longer periods so please try to kind of respect these rules it's for all of our safety um of course if you're actively speaking meaning that you are up by the microphone presenting it is okay to take off your mask while you are presenting but that's pretty much the only exception um there are no exemptions for mask wearing no medical or otherwise so please be aware of that and also be aware that the masks that are required should be equivalent to n95 or ffp2 or better and there are free masks all around here so please if you don't have masks go go fetch some right um a bit of meeting management we have uh we're running this through meet Echo we have the link here um queuing for everyone including on site is based on meet Echo so if you are here please uh please join uh the meet Echo session using the using your mobile device and then use the queuing system of me Deco to put yourself in queue um slides are pre-loaded into meet Echo so it's possible for anyone presenting to share the slides uh there is there is"
  },
  {
    "startTime": "00:04:02",
    "text": "a button in the mid Echo to to that allows you to share pre-loaded slides it is possible to share your screen as well if needed but ideally that's not needed and it's not recommended um and we have a link here for the notes and we would like to see if anyone wants to volunteer as a note taker we would also need a JavaScript that basically is somebody who can relay comments from the from the chat into into the microphone when needed anyone wants to do that as well that would be helpful uh so I I'm happy as I mentioned on chat to do the notes uh so I can cover that I would ask that if people are up at the mic uh please do clearly uh state your name to I know you'll also be queuing but if there's conversation back and forth we'll make sure that the remote people can tell who's talking that's excellent we have a note taker there's a lot of Tommy okay these are the administrative pieces so let's go on a little bit of document status right now we have the ioam conf state and IPv6 options drafts in iesg review and we have just done a second working group last call for the explicit flow measurements document and I don't think we got any pushback on the second on this second last call so it looks like this one will likely make progress"
  },
  {
    "startTime": "00:06:05",
    "text": "okay we have a pretty packed agenda today um it's divided into kind of three sections we have we're going to talk about uh adopted or working group documents um and we we have a set of documents here we will start with a newly adopted one which is uh which are these performance measurements on on on on link aggregation um then we move on to uh to the capacity protocol encrypted PDM responsiveness uh we will not be doing the connectivity monitoring here a slight updated agenda and then move on with data Integrity Yang and stamp on srpm Then Greg will be doing a presentation on uh on Pam and after that we move into to the section which we call the lightning talks so here we have a bunch of documents um a bunch of presentations uh they should all be uh done as a one slider pretty much similar similar but shorter than a hot RFC but pretty much just just present your concept on High level and see if people are interested to to collaborate with you further offline so um with that said I think we can get started and we have pm on lag first can you hear me louder would you like to share the slides yourself or uh could you please share it for me absolutely thank you very much"
  },
  {
    "startTime": "00:08:00",
    "text": "yeah I can see okay hello everyone I'm kieranjo from Huawei and I will introduce the programs of Performance Management on lag these two drafts are adopted just after ief0114 and next the page um let's firstly recap the motivation the lag provides an aggregation for of medical links we want to measure the performance of each link however however existing active PM methods run a single test session over the aggregation without the knowledge of each member link this will make it impossible to measure the performance of even physical member link so we followed the similar idea of RFC 31 uh 71 30 the BFD and next to measure the performance metrics of every member link of lag multiple sessions need to be established between the two end points and are connected that are connected by the lag these sessions are called micro sessions when the macro sessions need to associate with the corresponding member links for example when the reflector receives a test package it needs to know from which membrane the packet is received and correlated with micro session so we execute we extend a new commands type to indicate the set of micro sessions of lag and we use identifier to correlate the test packet to a particular micro session and carry the member link"
  },
  {
    "startTime": "00:10:02",
    "text": "information for validity check next this shows the web and the t-wamp extensions including control message and the test packet we add two new control messages the request the o1 micro sessions and the request T1 micro sessions and in the test packet we add sender micro session ID and the reflector micro session ID both IDs are locally assigned next and this shows how the sender a micro session ID and the reflector micro session ID are located in the authenticated mode the next page a stem do not have a control plan so only need to extend the extra package and your stamp tlv mechanism extend a stamp test packet with one or more optional trvs so we propose a micro session ID tlv here next page there are some discussions during the adoption core it's about the interop issue because uh web light and example are different on the format uh Cuban per flight sender with a stamp reflector or a stamp sender with a T1 polite reflector may as usual so our conclusions are firstly there is no requirement for such deployment this only happens when micro when misconfiguration"
  },
  {
    "startTime": "00:12:01",
    "text": "and so if there is misconfiguration existing mechanism described in this draft can detect then the operator can correct it at last a operator can choose not to not to use pm on lag and the micro session but to use independent session for each link so and we will then discuss how we will then describe this as operational considerations in our next revision next page and as as suggested By Request among authors next next step we will add a status process for a stamp extension because standard support both stateful and Status mode and stateless reflector May simply copy the received micro session ID in the reflector session ID and here we would like to hear more comments thank you thank you do we have any comments yeah Frank please go ahead yeah I have one high level question and sorry for maybe my misunderstanding of what you're trying to achieve but how would it work if you run stand between two notes and in between there are multiple X segments sequenced one after the other uh it does not work but but we have magazines to to fund this scenario so the the scope of the work is only a scenario where you only have two uh node adjacent notes okay all right"
  },
  {
    "startTime": "00:14:03",
    "text": "I think that would be helpful to go and clarify right at the very beginning okay thank you um I thought we had Greg in the queue but maybe yeah I was too quick to jump in the queue while the friend continuan already resolved um just a note um so the use case and scope of this work is uh analogous to be of the over lag work which is exactly as Frank noted is only for um single link between [Music] um aggregation points and it it works only for lag it doesn't work for MC lag Frank you're still in the queue is it that you forgot to or do you have okay great okay thank you um if we have no more comments on this one we can move on to the next point in the agenda which should be uh capacity measurement ow Al do you want to drive the slides yourself or do you want me to share it uh we need your audio Al we can't hear you I'm gonna get rid of the video now just because that's uh you can't really see me anyway it's too dark here and I'll try to um share my screen"
  },
  {
    "startTime": "00:16:03",
    "text": "okay all right yes I do select the window foreign all right so can you see the first slide yes great all right so um uh this is the uh the talk on the test protocol for um one-way IP capacity measurement and you know it turns out we can do a lot more than capacity measuring with this protocol so I encourage you to think about that um but we're what we're responding to this time is the security directorate um early review response which is now uh pretty much fully implemented in the draft and um with an exchange with uh Roman Daniel of uh you know the the SEC area A.D uh we want to have a little encrypted mode discussion so um anyway moving right along here so I sent this list uh to the ipbm list uh that describes the extensive changes in the protocol um the you know the big changes are for newly defined modes of uh Security operation um and uh I'm gonna go into uh one two and three here uh more extensively in the next picture but things you can't see in the pictures are the new key management and firewall configuration uh the new uh subsection outlines which basically align with each step of host processing for this protocol so that should make it pretty easy for people to read and understand as we work our way through"
  },
  {
    "startTime": "00:18:00",
    "text": "we've got new security considerations where we discussed the attacks um going back to ipf114 and a really expanded Ayanna section where we've got the new registry group several registry groups to uh support the expansion of the protocol so we're on slide three now um basically what I want to say here is that we have um you know for background in the control phase which is the top half of the slide we're using um two kinds of packet exchanges zero setup Exchange and a test activation Exchange and um for a uh for the newly required authentication mode for the control phase we've added the uh authentication die test and processing on all the requests from the client to the server and all the replies from the server to the client in both tests testing that's set up test activation so that's a that's a very complete authentication mode now um we've also got a a um an optional authentication mode which takes care of one of the messages of the data phase so now going down below the control phase line into the data phase we typically have our load pdus we send in really high rates we can go up to 40 gigabits per second now in our running code and we expect to get feedback pdus back from the uh from the server for example so um now the key information we're trying to authenticate here is the measurements that we conduct at 50 millisecond intervals and share back in"
  },
  {
    "startTime": "00:20:01",
    "text": "the feedback or depending upon the role and that's an important uh piece of information too so we can authenticate this it's an optional mode it might affect some of the round trip measurements we make here and that's why it's optional uh you know no no big uh no big shakes there um the the thing that the feedback we got which we uh which we talked about uh at itf-114 and then continued to decide not to do is to add authentication digest and processing to the load pdus you know we're sending lots and lots of packets there very often they're at the rate that uh the CPE can barely handle without doing anything extra you know like authentication and certainly not encryption so um these are you know when these are the lightweight CPE we can really get in trouble there and we decided you know there's really not that much information here to protect so um uh we're not going to add the load um the uh the authentication digest and processing in the low pdus that's our uh that's our choice for now we've also got the completely unknown authenticated mode so that's uh available as well for folks who want to do this so moving on to uh to slide four uh Brian Weiss Who provided the um they very kindly provided the the early sectarian review suggested that we might use dtls during the test setup and activation however the um it was kind of like I I've said before here the information we're exchanging there's a very limited"
  },
  {
    "startTime": "00:22:00",
    "text": "value uh test is starting we got configuration of the test you know you could easily think or pin print this uh and reveal that it's a measurement there's no results there in the control phase uh when we talked you know back and forth from Roman it's really the measurement results the the send rate structure that's that's the critical information that's exposed so uh dtls doesn't help with that we can only use it during the control phase um the re-transmissions that it has ordered delivery they're not really helpful in the control phase I'm sorry data phase so um uh the most valuable information is communicative or dtls can't help us so we're not going to do this that's our that's our choice right now so um Roman uh the security ad Estes SMS series a very pointed questions trying to lead us to the truth uh which was very kind to him and I replied back to that on the list uh the key information we're exposing is during the data phase the exposed measurements and rate control messages they seem to have been require some form of encryption so a simple solution here is to encrypt all the things to operate the protocol within an encrypted tunnel excuse me however we've got this uh you know that when you have encryption like this um it's a bilateral agreement the tests are point to point so the users can choose their own encrypted tunnel and their keys and and set it up uh you know as they desire there's there's plenty of support for independent tunnel implementations in Linux hosts there's even Hardware support in smart Nixon you know data center equipment and so forth"
  },
  {
    "startTime": "00:24:01",
    "text": "so um you know we strongly take the position here there's no need to modify the protocol to use an encrypted tunnel we'll simply say here's a mode where you use the the protocol and you set up your own encrypted tunnel so you know that turns out to be an advantage some users may want to characterize uh their own measurements in the tunnel technology they chose so let's leave the choice to the users um a emphasis in ippm is accuracy so you know we'd even recommend that that some people who are going to use a tunnel run some tests unauthenticated first uh to see if the tunnel has negative impact and you can purposely characterize the tunnel encryption uh this way you know very likely it's going to be that the capacity you see with an encrypted tunnel is less than the unauthenticated mode or even the um uh the recommendation the recommended uh authenticated mode that people can use that's still an option so um let's see there we go oh yeah and then the you know in the running code we've got the MTU set at a fairly uh conservative value um so our our our case is that the uh uh you know if we wanted if we if people want to use encryption uh they can set it up themselves between consenting adults and um you know that's what we would describe in the draft we don't see a need to modify the protocol to do this it'll work uh just as well so that's what we'll do in the draft and this is the kind of thing I I just wanted to talk about for a few minutes if if folks have comments on this"
  },
  {
    "startTime": "00:26:04",
    "text": "all right so I'll let people think about that while we go on to the uh the final slide Mark Martin indicator sorry oh okay client like resets all the time and I can't get in the queue um okay I'm sorry I don't know if maybe I missed the explanation but why can't you use dtls to exchange the sensitive information oh um it it it uh it performs re-transmissions and ordered delivery so we make measurements on uh the feedback packets and you know obviously the test stream so we don't want we don't want the feedback packets retransmitted we measure round trip time on those and we don't want them reordered so basically the dtls features which are really nice that you know that might make sense in the control phase they don't help us at all when we're making our re-transmission I'm sorry our our feedback measurements for Round Trip time on the uh the you know the feedback pdus does that make sense um yes uh I mean uh I guess the reason I'm hemming and hawing up here is that I mean it seems like this is a little scope creep on what this traffic and what this design is doing right you're trying to measure capacity and and we have other tools to measure delay um I mean certainly nice but um it's hey Martin it's definitely not scope creep then let me take that on we measure we measure loss and delay variation and we use that information directly in our load adjustment or search algorithm when we're trying to search for the maximum capacity"
  },
  {
    "startTime": "00:28:04",
    "text": "all right um all right thanks sure thing so here's the here's the wrap up I've still got a couple of minutes here um I think we'll have some more uh SEC area uh maybe SEC directorate uh interactions um we'd like to agree to uh on a proposal for a fully encrypted mode but um you know uh we'd like to implement a working group agreed proposal and uh for us the bottom line is you know as far as we can tell even when we even when we put in encryption in our protocols it's not widely activated um in the measurement protocols that are used to scale you might see it going on between consenting parties and that's fine but um you know oh lamp had encrypted mode t-whip had encrypted mode uh we have 600 000 T wamp instantiations we don't use encryption in any of them so look if we if we have um have some agreement on this uh you know we could spend another draft and maybe get a working group class call early to 2023 you know maybe sooner if the encryption solution is simple it's really just about wording and describing it and um uh you know I wanted to note finally here that uh lots of measurements with um RFC 99d7 the capacity metric uh and uh round-trip time under working load uh those are the kinds of things we've been sharing on the list uh very recently and it points to the fact that uh you know this protocol can be used for other things work and load assessment capacity under working load and so forth we've got a lot of capability here so let's uh it said you know I don't really see this is scope creep I see it as you know"
  },
  {
    "startTime": "00:30:01",
    "text": "using a tool that's really well endowed to make all the measurements we can so thanks for your time everybody any further questions I'll be glad to take them foreign I went back and checked because I thought I was why is like dtls doesn't have re-transmission except for the handshake messages right I mean I thought it was re-transmission for for all the messages it protects and when I said this last time around I saw Tommy nodding maybe Tommy can help us out here Tom Tommy um I I think that it should just mainly be the the handshake messages that have the re-transmission um yeah I mean it's it's meant to go over UDP so I mean like you would use less if you could about a liability yeah so there's a retrans mechanism for the handshake which is a different thing um I think it's similar I mean aside from security I think like the transport guarantees are similar to UDP so I'm not sure that this the premise of this is correct okay now I miss I'm I mean my understanding was that you know when I read about it it was definitely talking about re-transmissions and um handshake has to be has to have that so it does create like a little like a mini TCP for the handshake but after that no it doesn't have those guarantees okay okay all right so so dtls would be would be applicable then but you know I'd make the same case that that um you know the the if you if you really want if well if"
  },
  {
    "startTime": "00:32:02",
    "text": "you really want to encrypt everything then The Simple Solution is to put it in a tunnel yes if you certainly if the probe traffic you want to encrypt you would need to do that um but obviously as you as you are well aware that seems that potentially can influence the throughput you can generate um which may or may not be a problem yeah I I I mean it seems a little weird to say um I'll be brief sorry I know I'm out of time um it seems a little weird to say well like you can try you can do the test without encryption and into these tests with encryption to verify that like it's not messing up your measurement and do the test with encryption because then like the data is then passing unencrypted right um well I mean if you did that once or twice before you started your your tunnel then you'd have the you know that I mean those are the kinds of things that that uh you know it's a really simply die it's a really simple comparison uh there's not that much information that's going to be um you know exposed and you're doing it quickly potentially you know in a on a port that uh people would have trouble finding so you know I think there's value in in having that comparison but the bottom line is you want to know whether the tunnel is is affecting your your accuracy or not and with that little data point you can know okay so if if the premise is that you're using some like other link that is not you know you're putting on like a local host or whatever so like you're running it through the encryption without actually putting it out online I think that's fine anyway I'm I'll take enough time so thanks bye yeah thanks Martin thanks for the clarification go ahead Tommy hello so I wanted to clarify for the the next steps here around"
  },
  {
    "startTime": "00:34:01",
    "text": "encryption um since it seems like from this you're proposing you know just you know put it in an encrypted tunnel if you want and I guess the other thing on the table is you know if dtls does work you could just say you know slap slap in details optionally are those the things that are on the table for this like is the fully encrypted mode just going to come down to put it in a specific in any tunnel you want or is it going to be a specific protocol change what are you thinking um yeah a good good question I I'm trying to avoid protocol changes at this point right and I think it's I think it's really simple that people could you know choose their own tunnel they're likely to do that anyway they're even likely to have the encrypted tunnel up and running anyway between consenting adults so so the so the answer is really simple if you if you want to make these measurements run it inside a tunnel and and there's lots of different tunnel choices you know why why should we you know get into those details okay so this would be essentially an additional uh subsection that's like one paragraph long that says hey here's how you can run this in a tunnel and the impacts it may have in your measurements and how to think about it yeah that's exactly right perfect so it'll be it'd be real interesting to find out how the security area reacts to that and you know whether uh whether we can do this okay well thanks very much everybody I appreciate the uh the corrections and the feedback today thanks a lot L and then we move onwards"
  },
  {
    "startTime": "00:36:02",
    "text": "to encrypted PDM uh let me see see if it works otherwise no I pressed this one right okay okay next slide please okay this is kind of the yeah this kind of agenda um let's go through that next please okay so in terms of implementation um we're changing to using abpf we used to have um uh patches to the kernel and abpf runs in user mode and we can use it on uh more platforms so that's that's where we're trying to do just for the implementation we can always support Windows um and uh we have it done for PDM V1 and have been testing it and now we're working on doing the PDM uh V2 in ebpf okay next please you can come talk to us at the hack demo and see the PDM V1 stuff um our proposal for PDM V2 was also accepted into the IAB Workshop very interesting workshop on managing encrypted networks um and we think this might be a very good way because um uh certainly this is a big problem our thought is ideally once we have a"
  },
  {
    "startTime": "00:38:00",
    "text": "stable implementation to co-locate PDM V2 at various points uh potentially with some of the CDN providers next please so uh the bigger question for all this is like it's all well and good to Define um extension headers but if extension headers don't work on the internet it is an exercise in futility so next please um we have two drafts that we're working in V6 Ops and we have also done an iepg presentation uh the bottom line uh nolini's opinion is that probably each H's work depending on the topology that you use we will have a side meeting to discuss this on Thursday um we are use we have done some testing using cdns and Cloud providers and one cloud provider and one CDN is working very closely with us to try to fix the problems because there are problems such as within a CDN you'll get to the edge in IPv6 but internal to the CDN Network you are traveling in ipv4 and so uh suffice it to say that if you're traveling in ipv4 you're not likely to be supporting extension headers so let us fix that problem first so that is our big effort right now um we hope you agree that IPv6 should be"
  },
  {
    "startTime": "00:40:00",
    "text": "supported in cdns so next please so uh as far as PDM V2 itself there are three parts to the communication there's the secondary to secondary which is what this particular draft defines but um and that is an independent uh protocol in itself it is the PDM V2 encryption but somehow you have to get the keys you need a control protocol or what we call a registration uh protocol to create a common context and so on that is what we are calling primary to secondary and primary to primary the the reason for for this protocol is to make it a scalable because otherwise you get essentially combinatorial explosion with too many secondaries what we are proposing is that we leave this line clean which is secondary to secondary and start a second draft for the primary to secondary and primary to primary because it is quite it's quite a bit and so that is that is what we would like to do is have have two drafts next please that's it so yeah any comments thoughts um if we split the drafts as we would like then um just our opinion is is possibly we're ready for last call so I would like to get some thoughts no comments has anybody read it no I'm teasing you I'm teasing you go ahead tell me yeah yeah so"
  },
  {
    "startTime": "00:42:00",
    "text": "just about the plan for the documents um if you were splitting this um you know we would need to do some kind of like an adoption call at least or your consensus call within the group to say we want to have more different documents for this I'd also be curious to know how much of the current document is would be kind of generic between the different modes um like How Deeply entangled would these two documents be um how much are we buying by separating them out yeah that's a really good question um I actually think that we should take out because we have in in the secondary to secondary uh what we have is some of the security requirements for the primary the secondary and primary primary flow I would suggest that we take all of that out as I say keep it clean um and then start the second document so I would say that the the the amount of repetition uh should be uh relatively minimal the reason I say this is that um the reason for the split really is that um well I guess I myself get really tired of reading 60 page rfcs it it it's hard to keep your head straight you know and um um so maybe but but I totally get your question maybe what we should do um I don't know what everybody thinks is maybe just go ahead and create like a a draft for what the primary and secondary"
  },
  {
    "startTime": "00:44:02",
    "text": "and primary primary would contain you know so you guys can kind of see and leave a bunch of sections like like this needs to be considered this needs to be considered this needs to be considered as TBD that makes sense to you Tommy yeah that does I think having you know we don't want to create too much busy work but if you are sufficiently motivated and you want to kind of share it with the list hey here's how we think this split would be here's our first cuts of those two documents um yeah then you can get agreement within the group because something like that does need group consensus sure sure no no totally totally get that and and you know so so why don't we go at least at least an outline of what sections there should be and how the two documents would look split apart and then and then people can say no you should just really have them be one document um the the other the other um consideration too is that really if scalability is not an issue for an implementer you can just go ahead and separately implement the secondary to secondary it really if you just do secondary to secondary probably if you get behind a hand you know if you increase to more than a handful of clients and servers uh you would you will probably be doing a bunch of you know shooting yourself in the foot by doing that but having said that if you do want to do it for a very small environment that's certainly possible that was another part of our thinking okay great great so we'll go ahead and"
  },
  {
    "startTime": "00:46:00",
    "text": "and uh give you guys um a prototype thank you perfect Thanks that'll be very helpful so the next presentation is on responsiveness and it will be Stuart it didn't work it seems so um foreign my name is Stuart Cheshire I am presenting on behalf of Christoph parsh who's the primary author on this document he's not able to be here in person this week and it's 2 A.M in California so he asked me to step in for him uh these are his slides uh let's go on uh the response from this draft is a working group draft uh we uh Kristoff is working on a couple of updates uh which I'll describe in more detail uh one is we discovered a floor in the algorithm that it can terminate too early and underestimate the buffer blades and the second issue is a suggestion for a well-known URI so if we move to the next slide I can describe this so the goal to remind everybody of the responsiveness test is to measure the round trip delay when the network is actually being used most of the time right now when we run a ping command on the command line we're testing the network when it's idle which is not very interesting because I want to know how the network operates when I'm actually using it not when it's idle so we do this by generating traffic that's representative of any normal upload and download let's move on"
  },
  {
    "startTime": "00:48:02",
    "text": "and in this example that Kristoff made Let's assume the bandwidth delay product is 32 megabytes and each TCP connection has a received window of four megabytes and that's why it takes multiple connections to fill up the pipeline so the test starts with four connections and they each grow to their four megabyte received window we have 16 megabytes in flight but that's still not filling the pipe so in the next slide we add for more connections and we observe that the aggregate throughput goes up so that's great uh now we can tell from this graph that we've hit the limit but of course the test doesn't know that so the test adds four more connections and at this point we don't get any more throughput because we have hit the capacity of our bottleneck link and at this point the extra traffic we introduce into the network is sitting in a queue on Entry to that bottleneck Network and that's what we want to measure we want to observe what is the depth of the buffer bloat in this network how much is it willing to delay our packets and make them late with the current test this is where it terminates because it sees that the latest round of adding connections did not increase the throughput significantly so it concludes I've now filled the full capacity of the pipe my measurements are done you can see from this graph that it may have filled the full capacity of the link but it has not yet filled the buffers and in Real World operation it's very likely you would fill the buffers until they overflow so this risks uh underestimating the true buffer blow to the network and if we move on um the solution to this very simple uh it is uh described in the issue tracker"
  },
  {
    "startTime": "00:50:00",
    "text": "in GitHub all of this attracting GitHub so we welcome any suggestions from other people who noticed mistakes or have ideas for improvements the solution is very simple instead of terminating the test when the throughput stops going up we monitor both throughput and delay and terminate the test when both of those are stabilized so uh simple fix there that's going in the next version of the draft the next suggestion next slide sorry I've used the clicker if it was working um uh this is another suggestion we had because this responsiveness test is basically built on HTTP gets and puts any web server is a suitable platform for running this test so there's a suggestion that we have a well-known URI of a configuration file in Json format so any web server and maybe in the future this would be built into standard web servers that they all support doing responsiveness measurements and the way you find this out is by querying the well-known URI and see if you get back a configuration object next one uh we have a couple more issues tracked on GitHub that are in the pipeline uh one is that I described earlier that you keep adding connections until the results stabilize sometimes they don't stabilize um and it can be hard to tell if the little fluctuations are significant so because we don't want the test to run forever sometimes we have to terminate before we're totally confident the other issue we've been talking to uh home Gateway vendors uh companies that make Nat gateways and Wi-Fi access points and one of the really important"
  },
  {
    "startTime": "00:52:02",
    "text": "things for Diagnostics here is to narrow down where the buffer bloat is so anybody in this room can pull out their iPhone you can run the Apple responsiveness test or you can run the Ookla speed test app which now it also includes a similar uh working responsiveness measurement so now you know you have horrible buffer blades but but where is it uh do you blame the ISP is it your Wi-Fi access point The Next Step you want to do is diagnose that we've had interest from uh equipment vendors to uh host a test endpoint on the home Gateway so you can run a test from your iPhone to the home Gateway and tell if maybe your Wi-Fi access point is where the buffer bloat is occurring uh or the home Gateway contest Upstream uh you could imagine if there's a cable modem or a DSL mode um you can divide and conquer and try to narrow down where the buffer bloat is happening a lot of these home gateways for cost reasons are not built with more powerful CPUs than they really need to get the job done and we've had strong feedback from them that doing TLS at a gigabit per second is is beyond the capabilities of their Hardware I know my iPhone can do it and my Mac can do it but but a little fifty dollar home Gateway box can't so those requests as a request to support unencrypted capacity measurements as well um that's uh that's something we're going to work out how to put into the draft it's not totally obvious how to do it for the same reason that HTTP and https don't run on the same port so there isn't a good in-band negotiation way to say are we using encryption or not but we will sort that out and I think that's our last slide"
  },
  {
    "startTime": "00:54:03",
    "text": "so yes um I will answer any questions if people have any uh of course file issues on GitHub and Kristoff will be available via email to answer any questions too all right we have l in the cube thank you uh Stuart for the uh for stepping in for Kristoff I know I pretty appreciate it um I'm wondering if you're familiar with any of the measurements we've shared on the uh ippm mailing list recently they tend to point to um you know the underestimate of capacity and therefore uh working latency uh that you guys are talking about and um well we're what we saw basically was that the RFC 1997 um IP air capacity measurements uh produced um there's higher latency because we have a you know we sort of have a stronger uh method of producing uh you know the working load and expanding the buffer blow in the channel That We're measuring uh so we saw I mean to be uh to be clear about the numbers we saw um you know like on a one gigabit downlink we saw um you know the full the full gigabit measured with the ipuar capacity Tool uh we saw about 900 megabits with uh responsiveness and the capacity of report it reports and um when we tried the Go responsiveness version uh the capacity was very much lower than that on the order of about a 120 megabits per second when it should have been you know downlink capacity of one you know uh 940 megabits so um you know we're we definitely saw the kind of problem that uh you guys are saying you're going to attack this time around"
  },
  {
    "startTime": "00:56:00",
    "text": "um you know the latency is is uh you know a good thing to monitor but um you know it may be that there's faster ways to get there and to uh you know to measure the working latency than you know adding one connection at a time so I just encourage you to think about that and and also you know consider the measurements that have been shared thanks let me understand what you're saying I'll are you are you saying that the the algorithm I was described in the draft is flawed or are you saying the current implementation written in go is not as efficient as it could be uh well both those things because you guys are saying that the that the the algorithm based on throughput is flawed and you want to change it um I uh I wouldn't have stated quite that strongly we that this software is still in development and this draft is draft zero one so it's a fairly young draft the existing code would uh it would look for the throughput to stop increasing as it signed that it had filled the link and actually it was me who pointed out the issue I was thinking about this and I said just because the throughput hasn't uh now just because the throughput is no longer increasing doesn't mean you filled the buffers because the round trip delay might be still going up so that's not a particularly profound observation that was just something I realized that we should wait until both of both of these measures have stabilized um uh so I don't think that's some fundamental flaw in the way it's measuring capacity it's just a a slightly different condition in the in the while loop about when to stop uh as to your comments about um it was only reporting 900 and something megabits on a gigabit link do"
  },
  {
    "startTime": "00:58:01",
    "text": "you have any uh can you explain uh do you have a quick summary about what you think was causing it to not get the full gigabit well in general TCP with multiple connections um you know has some instabilities about uh the throughput that it measures and um without without a lot of averaging that uh you know some of the companies use you tend to get um you know variations from measurement to measurement and and also some um you know just some uh interaction problems that uh I think mad Mathis can explain to you very well so um uh the you know the the issues here are are uh in some sense uh you know choices and um you know that the fact you're adding additional information to the algorithm now that may be that may work out very well but the um you know right now the capacity estimate is uh is quite low and that's resulting in a working latency which is low as well uh that's at least according to our measurements so you know I'm just trying to share uh some experience that uh you know non-developers have had and it's been shared on the list so um you know I hope that you guys will take that for what it's worth thank you it sounds like your feedback is that it's uh your observation is that uh you disagree with using TCP with cubic congestion control and it should be something else that's some other transport protocol that's filling the network is that TCP is the wrong protocol I'm not sure what you're saying DC DCP had when you had a lot of TCP connections together there's an instability that results and Matt like I said man Mathis can explain that to you very well in fact it's it he explained it very well in uh"
  },
  {
    "startTime": "01:00:02",
    "text": "um in RFC that we wrote here in ippm uh some years back on model based methods for measuring um that capacity so so you're saying tsp is the wrong tool what is the right tool well if we want to measure IP layer capacity it's RFC 9097 and we've got a you know an RFC for that okay thank you thanks Adam Martin Google um maybe this is a dumb question but uh you mentioned the use case of measuring buffer Bullet to the Wi-Fi access point but isn't that like a single hop where's the buffer blood in that case uh the the buffer bloat is in the Wi-Fi chipset in the access point that is a big black hole that sits on packets for half a second so when when data comes in over your cable modem and of your gigabit Ethernet into the access points for most people unless you're sitting right on top of the access point your Wi-Fi rate is less than a gigabit so uh if you're downloading data a software update an app you're watching Netflix video your Wi-Fi access point is the slowest hop and that's where the queue builds up and depending on who makes that access point in the chipset inside it you might have half a second of queuing two seconds five seconds I have been doing some tests on I won't say which vendor but one particular access point that has five seconds of buffering so you can measure packet comes in sits in Ram trips for five seconds and then gets delivered to the Wi-Fi client so Wi-Fi access points right now seem like they're the biggest source of delay on an end-to-end internet power so by directly connecting to the Wi-Fi point then just like it's if it's generating data coming back at"
  },
  {
    "startTime": "01:02:01",
    "text": "you in this test then you would then obviously fill up a buffer for that access point um or are you connected to something beyond the access point to uh both of those are envisaged so uh most customers have an integrated box they have a cable modem that's cable modem and that Gateway and the HTTP server and Wi-Fi and an ethernet switch all in one box uh there are other people probably some of the people in this room who have more of a component system with a ubiquity unify Wi-Fi access point that's just a Wi-Fi access point and some other box that's being the NAT Gateway and so forth so each of these bits of hardware could run a little web server serving the right URLs for doing the responsiveness test and that would give the client on your device multiple Vantage points in the network to hit kind of reaching further into the network to narrow down where the buffer bloat is happening thank you I mean to give one example um it doesn't help the customer to call their ISP to complain about buffer bloat if the buffer bloat is actually on the Wi-Fi access point they bought themselves so um but we have also measured cases where the cable modem CS cmts equipment at the ISP is configured depending on what data rate you're paying for 50 meg 100 right 200 Meg they configure the queues through two seconds of buffering at whatever rate you're paying for so again under load um every packet you receive sits in RAM chips at the ISP for two seconds while it it sits and twiddles its thumbs and then it comes out so you've got a gigabit in two seconds of going nowhere gigabit coming out the other side so you could have two seconds of lag in the ISP you could have five seconds of lag in the Wi-Fi access point and knowing which you is afflicting you is that really"
  },
  {
    "startTime": "01:04:01",
    "text": "important to know what to do about it thanks Tommy all right thank you um so first there's not the reason I got in queue but just to uh call back to the conversation with Al um I I would encourage you and Chris nothing the others to look at the stuff that Al wrote to the list because that does have a lot of details and you know even I certainly think there's room for different methodologies and the point of this is not to measure capacity but uh at least understanding the comparisons and the difference in the measurement results will be good um so uh I came in just about the kind of the unencrypted mode looking at the Json because I assume that you're well known URI will contain the Json that's currently defined in the document it does seem that that you know includes the URLs of the different tests um yes you're also would we imagine that the client could fetch the well-known URL at https such that this the test server does support TLs but then points you to unencrypted URLs for the specific download files yes thank you Tommy that's a really good observation um we were [Music] um I think we were thinking too much in binary All or Nothing black and white that it's either clear text or it's TLS and and your point is is really good which is the problem is not that these devices can't support TLS they can't support TLS at a very high rate so yes"
  },
  {
    "startTime": "01:06:01",
    "text": "the um the configuration blob will always be fetched over TLs but the actual High rate test traffic can be optionally unencrypted thank you Tommy yeah and just one more comment off of that of just something that we'll need to change uh currently your test is always done explicitly over http 2. of course when you're unencrypted that will not be an option so we'll have to go to http one which will have different flavors of performance as well so that's going to need to be a consideration uh okay let's let's think about this a little bit more um I know uh the intention of HTTP 2 is that security is not optional and for traffic on the public web that makes perfect sense for this kind of benchmarking traffic uh my understanding is that there's nothing about HTTP 2 that says you can't run it directly over TCP you're not supposed to because it's supposed to be tied to TLs but right I I guess I mean you can um but I don't know if we want to be encouraging implementations to kind of for this reason build the unencrypted HTTP 2 mechanism that it's something that is not normally supported and so you need more exotic implementations or more knobs that some of the languages we may have may not support today yes um let's think more about the right way to do that it's not as simple as just saying we'll use HTTP one because part of the way the test works is it's fetching large chunks over the H2 connection and then in the middle of"
  },
  {
    "startTime": "01:08:01",
    "text": "that it inserts a get request for little one byte object and that's how we're measuring on a working busy connection how quickly can it deliver some other piece of data on demand and um that uh that that ability to interleave multiple requests uh is is not there on HTTP one one you can do pipelining um yeah so yeah let's we'll need to think about the right way to do that yeah all right that sounds good it and sorry one final there's just a curiosity question because I as we were talking about this in HTTP 2 versus HTTP one in general the document and this presentation we're talking about having multiple TCP connections here how are you inducing the HTTP Stacks to create multiple TCP connections when with when they're doing HTTP 2 because generally it will try to use one uh that's a good question I don't know the specifics of um I'm I'm I'll give you my uh best understanding of this that on the tools on Mac OS and iOS um I think it's using the the URL session apis and by making but most applications make one URL session and use it for everything I think this code is explicitly making multiple URL session objects and the connection pooling is per object uh as to what the go responsiveness test does I have not looked at the source code of that about how it is steering the underlying code to open parallel connections yeah okay it may be worth a note again to implementers to you know"
  },
  {
    "startTime": "01:10:01",
    "text": "be careful about you know you make sure that whatever API you're using in whatever language you're using is letting you have that control yes yeah that's a good point uh a client could make four different calls to an API to get a URL and not realize that under the covers those are all being coalesced into one connection okay okay thank you great um we have a little bit time so I just want to insert myself and ask one more question um I was wondering if you have considered uh these tests in in certain mobile scenarios so imagine that you you're running this from your from your device on a mobile network and you're you're on a high-speed train say um so you start your capacity measurement or your responsiveness measurements while you're in one cell and then you might hand over to a different cell with completely different properties for instance going from 140 cell to a 5G cell maybe in the first cell you you sort of your algorithm thinks that you found the capacity and you start measuring the delay but then you hand over to some to some cell with much higher capacity and then that would probably lead in the delay dropping is this something your algorithm is currently considering but I mean if you see you start to see a delay build up but then the delay drops and would you then kind of try to add more more throughput into the I think the simple answer to your question is we have not considered those kind of changing environments okay uh one of the things we have considered just for usability reasons is that our goal is for the test to complete in about 10 seconds this is this is the kind of test where you pull out your phone you run the test you wait you see the answer uh it's not something that takes five minutes to run so by keeping it short I think that reduces these kind of opportunities for conditions to change uh I don't I can't imagine a fully General solution to the kind of situation you describe which is however"
  },
  {
    "startTime": "01:12:00",
    "text": "long the test runs just as it thinks it's done suddenly the whole environment changes the same could go if you're sharing capacity with some other client and they finish that download and suddenly there's twice as much share available for you um I think it's always possible to conduct not construct scenarios where those changes happen at just the wrong time and and uh and you don't notice the change has happened uh I think the answer there is um at the human level if you run the test two or three times hopefully you get consistent results um the the other thing to remember for this test in particular is the focus of this test is not how many megabits per second are you getting because there are many many tests that already do that everybody runs iperf and and many other ways of testing capacity uh the focus of this test is to work out how deep are those dark buffers and our belief is that the depth of buffering actually is not something that varies with time of day it's not something that varies with traffic it tends to be a configuration option of the network hardware and as such it's relatively stable now if you if you roam from one wife from one mobile cell to another one then you might inherit a completely different configuration just like if you were to roam from one Wi-Fi access point to another um you you could end up in a dramatically different network environment I mean to give a silly example right you could have one Wi-Fi access point plugged into a one megabit DSL modem and you walk next door and you roam to an AP that's plugged into gigabit fiber um and a lot of the time that roaming is completely transparent to the application uh if your IP address hasn't changed"
  },
  {
    "startTime": "01:14:00",
    "text": "um and the SSID network name hasn't changed the application doesn't even know it's just suddenly the configuration is different okay thanks a lot thank you so we move on to data Integrity iom data integrity don't seem to get this one too right hi good morning um so this one is going to be pretty fast actually we have no change since my last ETF um the reason is simple we were waiting for the implementers to have a feedback on the implementation as we agreed so I think we're gonna wait a little bit more uh so I think also that it doesn't change anything about the working group less code so we're gonna postpone it to maybe I hope by next ietf we will have some feedback on that and regarding the email we received from Ayanna so I just wanted to advice on that should we just annotate the code points with the suggested mention or should we just ask for the allocation so this is a question for you Marcus or Tommy foreign"
  },
  {
    "startTime": "01:16:00",
    "text": "Justin would you mind expanding a little bit on why the delay happened I think that would be helpful for everybody to understand well actually um there was a student for that and it turned out that it it was quite unreliable so you know things happens and um now we have another student which is a master uh uh in the University of liege and so this is is Master thesis so I for sure hope that it's gonna be okay this time all right thank you then yeah thanks a lot and we have iom yang do you want me to share yeah yeah could you please share it for me okay thank you very much uh hello everyone um again I'm tianjo from Huawei and I will report the progress of the iom young data model um we received a comments from the working Google last call and thanks Tom and Greg for the very useful discussions there are some minor issues we will update the new revision and there is a major issue raised by Tom to add uh some examples we are going to accept but still we can discuss later whether"
  },
  {
    "startTime": "01:18:02",
    "text": "it is necessary and next next stage and there are many discussions raised by Greg most of them related to the scope of iom like whether iom DX is an integral part of iom or not I'm going to reduce the scope of a scope of this document to align with the RFC 9197 that means i1 ex and i1 flags are excluded from this year model and then the first question whether to include the presentation of iom data my suggestion is Young model only focus on the configuration um DCR mode only okay only focus on the configuration because the exports may not use your model for example ipfix could be used on the other hand the export should be uh should be iom independent that means there are other measurements could generate the same Matrix like a delay loss and so on known the last question should should the configuration of iom or IPv6 or an asset should be part of this document uh I would say yes and I do not think we need to augment the PCL model here the filter defined in this defined in this draft is only used to uh identify the target flow which does not have the which does not have an ion header we matched the packet well enter the iom"
  },
  {
    "startTime": "01:20:02",
    "text": "process we can use the protocol entry in this draft in the young model to find the irony instruction in addition Jan just provide enough information from the configuration interface a device may have different implementations yeah and that's all thank you oh we have Frank can you what yeah maybe yeah I'm gonna go and ask the same questions again that the other one already asked um so um there is in many cases people supplying examples for young models we can go and create a full example as part of the document feasible doable but we also have to recognize and acknowledge that there is no implementation yet so it would be really a made-up example that we can go and put into the document and I'm just wondering how useful that is so we can even go and consider moving the overall document to experimental and set a standards track and then just that way saying well yeah we can go and have a mock-up example of a young model if we look at other management documents that we've done just recently like comp state uh there is no examples in there at all right so I'm just wondering whether people have a a feeling for or some guidance on whether we want to put a full example in whether it's useful or whether we should just go and leave it for now recognizing that this is like early"
  },
  {
    "startTime": "01:22:01",
    "text": "stages and we're waiting for reference implementation and then the second thing um that John already mentioned is um I would be very much in favor of following the suggestions that um Cameron had I.E we focused the scope on the the core iom documents so 9197 and that way avoid like forward references on other documents that are still in flight and and making that a little like nebulous on on what the scope of this document would be so if we can go and scope this document also to 9197 then a lot of the problems that were brought up and working group last call would naturally resolve itself Greg let's go ahead um well I I understand that uh desire to move forward and progress this document but I see that IEM Dax is important and uh very much needed mode of I am especially in environment uh with their constraints so that because it allows for um export of operational State and Telemetry information uh out of band or for the management plane for example so I concerned that if there is no effort to drive this work and I don't see any draft individual draft or any draft of any maturity that addresses it so a narrowing scope of this draft at this point uh seems like a risk of uh IM Dax Yang model would never be done in time"
  },
  {
    "startTime": "01:24:01",
    "text": "because I can point to work and discussion we have for example on mpos architecture enhancements using the network actions where I am Dex is very attractive and especially for example in a deterministic networking within the OS data plane uh where their resources allocated for that net flows are explicitly reserved so that even their operational State and Telemetry information are important exporting them is not critical to delivering that net service services so and that's imtex is very valuable mode of IAM especially for these environments yes then there will be several Choice one is yeah one is just that I suggested exclude this uh ion text or on the other hand maybe we need to um ah to have a consensus on how to operate the i1 text where to detect the ACL in the at the transit node I think this is still not clear right now okay if you want to respond quickly to this one great I'm going to move forward um yes I agree I think that having this discussion before we make a decision on how to progress this work it will be very useful and helpful not only to the"
  },
  {
    "startTime": "01:26:01",
    "text": "group but to the large community that is looking to use an app Apple IAM technology in their use cases networks thank you thank you so let's move onwards we have Rakesh with stamp on srpm uh good good morning everyone my name is Rakesh Gandhi and presenting the simple the stamp extension for Sr networks on behalf of the authors listed next slide please so the agenda is uh the updates that we have made in revision zero six uh will uh briefly have a look uh highlight the stamp based work that's being done in other working groups and the next steps where we are and what we should do next next slide please so in the latest revision zero six we have addressed various review comments many thanks to Rick and Greg for providing the comments so comments from Rick uh conspirant regarding the wecheck flag for the state does reflector specifically for the counters for the direct measurement tlv so we have added the text for that we have also addressed various review comments from Greg many thanks Greg with clarification tags for the V flag destination address tlv and written path tlv so we have also done the iron early code point allocations to Fascinate the"
  },
  {
    "startTime": "01:28:00",
    "text": "implementations that's going on and we have added that in the draft as well a few minor editorial changes and we had no open issues right now and next slide please so there is a ongoing work to extend the stamp that's a great protocol work done in ippm and we are using that in Spring cavity a few drafts there as well as this one for mpls as well so please uh review this draft as well as and provide review comments and next slide please so for this draft currently we have no open issues um and uh we believe uh the draft is ready for the working of last call so we'd like to request our kingdom last call thank you that is definitely something we've consider then yeah so that's all I had many thanks thanks for cash any comments foreign yeah thank you all right thanks then we move onwards in the agenda uh we will have uh Greg to talk about Pam it's one of the benefits to being presenter yes we can go to the next slide please okay so let's recapture uh what we're trying to um address here service level objectives are components of service level agreement and um they reflect on uh key uh performance"
  },
  {
    "startTime": "01:30:00",
    "text": "metrics uh that are critical to user experience with a particular service so in some use cases the whole history of each SLO is not needed and what is important and critical is capturing uh when their SLO are violated or um not being delivered and that's sufficient uh to draw the conclusion of Wellness of uh their um service being delivered so basically how much it um in regard to SLA um and the second observation so you can see here on a drawing that what will matter what matters here is that when a particular SLO is outside of the range and there could be a different interpretation so it could be that for example operator is interested in early warning about their Dynamics or degradation of the particular performance metric and will request that the system the Pam will inform about the violation of uh optimal threshold whereas the operator and customer I will certainly will be interested in knowing uh with the degradation crosses um uh critical level so for that uh we allow in our approach in the discussion in this document that uh there are two types of thresholds might be associated with their any given SLO next slide please so what have they"
  },
  {
    "startTime": "01:32:02",
    "text": "um we received uh excellent comments uh from Adrian and he agreed to join us and collaborate together welcome edrin thank you and uh we work together in addressing uh his comments and other comments we received in the meantime between minutes next so uh what we wanted to emphasize is that uh one of the use cases for uh bam and SLO is ITF transport slices and um if we look at the draft that being worked in the TS working group so the definitions uh clearly state that SLA is composed of slos and uh service level expectations and service level expectations unlike um service level objectives they are can they can be expressed but they're more challenging to measure so thus uh slas are outside the scope of this work next slide um usefulness of metrics uh in in the foundation of this approach is that uh for each given SLO uh there are associated performance metric is measured uh over uh predefined interval and that is um the same interval being applied to us all slos that um are part of the same SLA but at the same time because their decision of transition between availability in unavailability state is done based on the number of consecutive intervals uh that uh can hide on their notion of number of uh translations violations uh"
  },
  {
    "startTime": "01:34:01",
    "text": "is lost so that's why um the ratio metric uh seems to be a useful metric so and the ratio can be applied equally to violated intervals so when there are optimal thresholds uh being crossed uh and severely violated where their critical thresholds can be lost of course if um only one threshold critical is defined then the metric for the violated intervals will be identical to the severe violated next slide please if you have any questions let me know I don't see their queue so okay so let's continue um in discussion of ITF Network slicing what's important is that a network slice can be uh um constructed using a set of connectivity constructs and these constructs uh are could be a point to point to point to multi-point um and uh more about it in more details you can look at um MBI a norbound interface yank model for Network slides so the uh an SLO can be provide applied in or assigned to all the construct that are included in the composite service or subsets of constructs can be assigned at different sets of slos so thus it allows to monitor individually this subset of constructs and draw a conclusion and learn about their availability and availability"
  },
  {
    "startTime": "01:36:00",
    "text": "State and uh in turn so that the composing service will be a composition of this uh subservice Pam indicators and Metric any questions about that and why it seemed to be important okay let's continue so uh we still have some um questions uh that we want to discuss and we are discussing with offers and we invite uh your comments suggestions and contributions uh one of them it's uh individual packet metrics whether it's important or uh might be too burden it might be an optional and so we as originally we indicated so that uh future work in this direction will include Yang data model ipfix extensions uh support statistical slos and more defining the policies that guide monitoring service level objectives okay so next as I said we always welcome comments and questions and contributions so we would like to better understand uh their state of the working group adoption poll and resolve um questions that being raised during adoption Pro we have a working version that includes updates uh applied resulting from the comments but I believe that we still have um one discussion that needs to get some closure or at least we would like to understand what the"
  },
  {
    "startTime": "01:38:00",
    "text": "status of the working group adoption poll thank you thank you Greg yeah thank you um just regarding that adoption call foreign we did uh in general you know we had decent feedback you know to point out you know a number of the support was coming from co-authors and so you know we don't count that quite as much of course um so you know we definitely had uh decent support there wasn't a lot of detailed feedback in that um and then the one main piece of detail and feedback was from Benoit and that uh unfortunately hasn't gotten more response so I think uh when the chair is discussed we would like to see some resolution or more discussion there or alternatively more in depth uh comments or reviews from other people so um I don't know if then was you know in the room we're watching this discussion I don't see him but um you could also try to help reach out or if others in this room if they are interested in this work please feel free to chime in on that call for adoption thread uh and add support because at this point it we're kind of 50 50. I'd say as far as um getting consensus here yeah I understand um so um offers and contributors man I'll just refer to offers so we discussed you know"
  },
  {
    "startTime": "01:40:01",
    "text": "uh questions and comments and responded to him um during their uh two-week period of adoption poll but for some reason we heard nothing back uh from him uh whether um our responses uh what we believe um is straightforward uh updates uh that been already Incorporated in a based on his comments uh Incorporated in a working version that is not uploaded yet uh because we felt that um yes I agree that it's beneficial to have a conclusion but at the same time um it's not clear that uh his comments uh are really that critical that basically cannot be resolved in the course of the discussions as the document progresses but that's probably our offers View right that's fair um I mean one option certainly would be to if you have this working copy and you have other changes upload a new version we do a new call on that version and if we don't you know if we get consensus and we don't get objections then we can move forward okay um that's a good plan I agree I will follow through thank you sounds good thank you thank you okay now we're moving into the the lightning talks uh uh section here so we'll have a bunch of presentations and they will be rather quick so um please really try to to make your presentation short and crisp so we will"
  },
  {
    "startTime": "01:42:00",
    "text": "start with the enhanced alternate marking yeah this is just a one slide presentation so to present to introduce this draft and I'm going to yeah introduce why what is the rationale and the background to for this new draft why we want to augment um alternate marking so maybe you know that um NFC 8321bs and AFC 88 89bs are in the RFC editor queue so the work is quite completed I also want to thank keep the occasion to thank Martin for great help on this but however there are some pending points that we want to explore for example in some protocols there are no additional bits that can be used and also some deployment experience give new requirements for example the entropy of the pseudo random flow identification can can be increased in some cases to to to extend the number of flows that can be monitored and there is also another point that we want to take into consideration that is the implementation of the world framework included the multi-point measurements so that's why um the draft aims to consider all these aspects and generalize the alternate marking data fields for all the transport protocols so in order to introduce new metadata new flow monitoring for flow identification extension and new Flags so the the extended data fields can be used for several application to have a shortest"
  },
  {
    "startTime": "01:44:00",
    "text": "marketing period uh have more dense delay measurement increase the enthalpy of the flow more monitoring identifier and automatically set up the backward Direction so this is the the scope of the draft so please read and share your feedback on the list so I think where's that okay thank you and okay next up we should have distributed flow measurements yeah yep yes thank you yeah hello hello everyone I'm hot here from China mobile and on behalf of other courses to share two drafts with the topic of inbounder flow environmental in IPv6 Network the first draft is about distributor flow measurement next slide supply place uh so as we all know embed the network environment to utilize the controllers to look like the data and calculate the packet loss and delay on the other hand in your multiple domain scenario domain controllers collect Merit data of each shade well it is a domain controllers across calculated the undertone the results their interaction is required the controller interaction induces the complexity and categories in the native measurement which is basically to guarantee the high as well requirements"
  },
  {
    "startTime": "01:46:02",
    "text": "of customers such as bands and finances so we would like to propose a distributed flow flow of performance measurements method without the participation of the control environmental results could be used by the router to select the forwarding pass that's the high as a requirements more details can be found in the draft next Slide the place the second draft is also about uh flowmenting Happy base physics Network next next slide please automarking options to provide enhance the capabilities and all those advanced stuff and function and abilities in this is helpful to application and deployments and pass flow measurement that is also called the inbounder network in a network Telemetry it's researching and deploying in China mobile from the test results in our life it is better to um either is better it is better for flexible deployments on condition light on node ID and a stable measurement period can be you know enabled in this Innovative plan so to factor flexibility Deploy on pass flow performance environment based on auto marking method in ipv system with the Pacific participation of a"
  },
  {
    "startTime": "01:48:01",
    "text": "controller another ID and the steerable measurement period is is auditory demand demanded multiples can be found in the draft next slide please uh also in the next step uh we will continue to improve the draft and any comments and the feedbacks are welcome thank you great thanks a lot uh next up we have the devices measurements hello everyone I'm Fabio carella from Telecom Italia today we want to introduce this new draft [Music] this is the user device explicit monitoring and next slide please in this draft we want to propose to to put the explicit flow measurement props directly on the user devices for example smartphone tablets or personal computer this new idea has some advantages the first one is the scalability because on the user device there are a few connections to Monitor and it does not need so much resources to monitor all of them um using the probe inside the user device give the possibility to obtain more precise measurements for example if we consider the client the the delay we can remove the client application Delay from the measurement so we can measure only the the delay that is on the internet path obviously another Advantage is that the monitoring of both direction is guaranteed and and another big Advantage is that we"
  },
  {
    "startTime": "01:50:01",
    "text": "can save on network monitoring equipment because there could be a sort of user device and network props coordination so for example is possible to set alarm thresholds on a user device that signal to network props which session has to be monitored and networking in network monitor equipment can concentrate only on those sessions and we have also the possibility to improve some Metric because for example uh the the qubit that is not end to end uh can um can become end-to-end if the if the prop is placed in the user device handle bit measures are not affected by losses so are more reliable obviously this proposals um does some assumptions some privacy related assumptions so the device owner decides whether to traffic is smart is traffic or not so there should be some sort of uh decision that the device owner can do in his device and the device owner can also decides if share his performance data with only with these internet service provider or for example also with national uh authorities for for starts or other evaluation on the performance so if you want to collaborate you can contact us okay just a very quick question yeah yeah Martin do Google um okay assumption's an odd word for like what the device owner decides and has the power to decide to do and um I mean I think you're right to consider the privacy considerations here but I'm concerned that this become become a mandatory requirement on some networks and thus you know not really be"
  },
  {
    "startTime": "01:52:02",
    "text": "uh an optional uh forfeiture of privacy but rather a mandatory one thanks yes it's Monday yes I think so great thanks a lot next up we have mpls stamp great thank you foreign next slide so uh this is a just to bring to your information the work uh started and mpls working group uh to um extend um LSP thing uh with ability uh to bootstrap stamp um session uh with this some state Associated at session reflector so uh um those familiar with the OSP thing will um notice that it's a similar with how um lspping is used to bootstrap point to point BFD session uh there are proposals of extending lspping to bootstrap point to multi-point build this session so uh this follows uh this similar Paradigm of using an extension to LSP pin to bootstrap stamp session whether it's a point to point a point or multi-point and more extensive discussion will be this week at mpls working group session any questions I encourage you to come to an Infamous working group thank you thanks a lot Greg and then next up we have a path consistency over srv6"
  },
  {
    "startTime": "01:54:05",
    "text": "hello can you hear me yes I ever reported this draft about the past consistency over 76 next please remember with exposes through stamp or QR blood is important to ensure that test packet under black packs are transmitted on the next animal that is to ensure that the passes are consistent if task consistency cannot be guaranted there will be some issues for example the delay method is in occurrent for the time step carry the inner reply packets don't belong to the passage of the test packet is not enough for the packet loss even it may be not a com confirmative effect as you interact to figure but when the transmission passes of latest pocket and the reply packed are consistent may be discussed because they are from worded through IP dropped away processes of process or method to keep the past consistent and when measures as our passes process through stamp or to apply we use the path segment to associate the transmission parts of the test or pockets under the pocket by this way we can solve those about issues less of"
  },
  {
    "startTime": "01:56:00",
    "text": "a request you foreign so there is a draft in Spring that talks about using the path segment as well for the SR part uh First Step so please have a look at the draft and let us know if there is anything missing thanks um Sasha if you're in the queue by mistake you can remove yourself from the queue or do you have a question okay then we'll move on to the last presentation here thank you oh Mark yeah thank you foreign can you hear me yes okay thank you I'm Juanita from turnover Bell and on behalf of other authors I will present this uh Yamoto for the alternate marketing method so I want to First explain uh the alternate marketing use cases in China mobile so for the diversity of the service type and the SLA depreciations in the 5D period it brings great challenges to the performance monitoring of their background networks so in China mobile we have the 5G background background Network which is deployed for 400 000 MTN devices MTN is defined in idot g.s"
  },
  {
    "startTime": "01:58:05",
    "text": "Ray 10 and uses an alternate marketing to do the service flow level performance measurement and accurate for locations so and we also plan to use the alternate marking to provide the accurate performance monitoring for the dedicated line service in the very near future so why we need a young model for the alternate marking so uh as you know it's a large scale for the background and the Metro networks in China mobile and we need a consistent young model to manage the performance monitoring across a different domain or different vendors so we propose a model for the alternate Market and we have uh three objects here and the global object and head node and the endone so in global object we have some label and also some fir mode um for the global uh configuration and in head node we can configure the flow ID as a key parameter and also the alternate status period hot by Hub series mic IP uh and the interface name as um uh and there are some other parameters and I didn't list here and for the end node also can pick the flow ID VPN period and hope I hope status and the if names um so uh this is my our proposal thank you uh we are welcomed any discussions and comments thank you"
  },
  {
    "startTime": "02:00:01",
    "text": "thank you very much that was our last presentation right on time yeah okay so thanks everyone for joining and have a great rest of your idea foreign"
  }
]
