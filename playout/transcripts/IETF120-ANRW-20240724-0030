[
  {
    "startTime": "00:00:00",
    "text": "or after my, I ever complete, or sad A, Adversion B, or Saving with Aborism C algorithms, stop signing with it You re-sign with it and you stop signing it That's what you do with an algorithm. There's no such concept of roll over signing that's what you do over there's no such concept of roll-up yeah I thought like maybe it's another room if you had no I don't know Where is he roll in? you're rolling out? a set of keys using the same algorithm? There's no divider going for RIS RSA Char 256 or do anything else. None of them is a, there's no defined Rob Whereas in the protocol that is rules the migration from one key to another key using the same market and you can do that increment Thank you Very well, welcome back everybody We have now the lightning session So we thought further ado James will be presenting towards measuring content locality the room is yours okay thank you very much thank you for still being here everyone those who are left So yeah, I'll be talking about our work towards measuring content locality hopefully Okay"
  },
  {
    "startTime": "00:02:00",
    "text": "Oh, there we go. Okay. So yeah, we'll start with the definition of what local traffic is in this context Quite simply, it is traffic that moves from user to a website, and it remains in the country of origin And conversely, external traffic is traffic that I don't think this is well, okay is traffic that goes via an international network between user and endpoint So now we've got our definitions out the way We will look at CDN deployment and we're aware that there is a lot of previous work looking at this are look at CDN deployment, and we're aware that there is a lot of previous work looking at this. Our methodology is slightly different in that we use much more fine fine-grained measurements. And in terms of geolocation, which I'll talk about later, we are not proposed a new method of geolocation. Instead, we are just utilizing current methods in order to put together our database So why are we looking at content locality? Well, we've got the three P's of motivation policy, performance, and persistence. In terms of policy, we can use content locality measurements to check how traffic currently conforms to standards such as those that exist in South Africa and the EU. We can also use content locality measurements to shape future policy such as what's being done to towards the Internet Society's 50-50 vision And in terms of performance, local traffic is faster simply because if traffic travels a short distance, it will take less time at the same speed I don't know why I've specifically chosen live streaming here but as well as that, it can also lead to a benefit for the user, because transiting international links is expensive, and so if content remains low,"
  },
  {
    "startTime": "00:04:01",
    "text": "it can be cheaper, it trickles down to the end users. In terms of availability local traffic provides a greater resilience against faults for example earlier this year in West Africa there was a cable fault that meant that multiple countries could not access local websites. And they couldn't do things like paying their utility bills, which clearly is a problem, especially when everything is local bar where the traffic is going I should also point out that local content isn't necessary always better. We are aware that it could be used to increase censorship and also manipulation. However, we're just focused on how much content is local, not why or what it means at a wider scale yet So how's our methodology work? Well, we have a four-step process. We take the list of the top 1,000 domains per country We then remove any censored websites We determine where the website is hosted And finally, we geolocate either the content provider or the domain itself. And the reason that step two is important here is because in step four, we use residential proxies And for those who don't know, residential proxies use devices in the country we're testing and we don't want the people who run those devices to be sending a lot of traffic to censored websites just in case that gets the into trouble. So I'm just going to dig into the methodology a bit more. Steps one and two are quite straightforward. We just poll from online databases and I'll talk about step three and four in a bit more detail So to determine where our websites are hosted, we initially do a who is and C name lookup. We try and pass out any CDNs that we find in there And if there's a tie, we can then do a tie break lookup of the headers and again we then just do a matching process and if there are no matches we'll take the who is first so it's a top"
  },
  {
    "startTime": "00:06:01",
    "text": "top-down approach. And I should say that generally there is a there is not a tie and the who is in C name agree with each other other Now to geolocate the domains for those without a CDA it's very straightforward we take the domain we put it through, we do three DNS lookups to get an IP address, we then put that IP address through three geolocation databases to get a locality, which we then add to our results For geolocating CDNs, it's a bit more involved So we take a CDN and an ASN in the country and we put that into a residential proxy with a search string. We then extract the headers in the body, we put it through a reg X to extract geo-hints, which we then convert into locality and then results and i'll just give a quick example. So let's say we're looking at bunny CDN for AS 200 in the Netherlands So we put in our CDN and AL- We use a search string we've determined to access the bunny CDN We extract the headers in this case. We put it through our reg X to extract geo-hints, and then in this case we put it through an airport code lookup in order to say that for AS-200, Bunny CDN is local in the Netherlands In order to combine our results we would say that if there are two ASNs, each with a 50% market, share, we would then put the domain count through the locality percentage so in this case we have five local domains from bunny CDN, one local domain that's natively hosted and we then say that the country has a 40% locality There are some limitations to this method To start with, we don't consider website complexity, so we are just doing a lookup on the domain itself we don't consider embedded"
  },
  {
    "startTime": "00:08:01",
    "text": "content yet We're also limited by where the proxy probes are There are not proxy probes everywhere. And the amount of probes we have does affect the validity of our results. And finally, we've got what we're calling the fog of cloud which basically just means when we get to that content provider and this is a bit due to the website complex we don't know whether all the content is loaded or whether it's all cached at the end point we reach or whether it's brought from elsewhere Again, we don't know yet, but that is something we'll look at in future So now on to a couple of results. So we have done locality for each region. And this is quite a broad, broad graph here but we've also been doing our measurements per country and again this is affected by where the probes are. However, we can look at the global locality per country and currently we're running these measurements every week so that we can start building up a pattern between how content locality changes with for example global events that are going on We can also look at which CDNs are the most local and this is just something else we can look at with our results. We can also check where websites are hosted, as well as which CDNs are most popular, which in this case Cloudflare was well above the rest And then something we're starting to look at is categorization So this was just a random sample of 100 web websites from the USA's top 1,000 which is why it doesn't include streamers and things like that And this is still early work We will hopefully build the results out a bit more from here So in future, we are going to look at recursive searching, and this should hope work, we will hopefully build the results out a bit more from here. So in future, we are going to look at recursive searching, and this should hopefully address the website complexity issue we're also going to include trace route and latency measurements in order to hopefully dodge some of that fog of cloud stuff I mentioned earlier"
  },
  {
    "startTime": "00:10:01",
    "text": "so once we get to our endpoints we can see whether it likely that our data is loaded from the endpoint we reach or from further away We will also start looking at the reasons for locality, which is arguably more interesting, but without the results we can't start explaining why we think they might be that way We're going to include greater visualization and finally increase our categorization that we've done So just a quick summary local traffic is often beneficial We are conducting global locality measurements and we're collecting weekly and we're still expanding the methodology So yes, feel free to check out our paper or learn a bit more about the Internet Society of 50-50 Vision. And thank you for listening I'll now take any questions Thank you very much. I can see David in the cube Please go ahead just a quick question about the definition How do non-terrestrial networks play into your definition of locality? That's a great question. They don't currently So that is some, that is again future work, but yeah, good point. Thank you you And if there are no other questions, let's thank the speaker Thank you very much And the next speaker is Nirmala Shenoy. Are you the Hello, Nirmala Is anyone from this paper present in Miteko?"
  },
  {
    "startTime": "00:12:03",
    "text": "All right I'll just to play to you, okay Can you, sir, your video? There should be some buttons at the bottom of the screen with a video and an audio Oh okay. Okay, there you are Okay, Nirmala, the remission be presenting investigating data center network protocols. Okay Hello, good evening, everybody. Sorry I was just stuck with, I didn't know how to start the audio here I have just a few slides here Is it full screen ignition? or do I have to do something? Have you transferred there? Yes, you should be able to control the slides from your side. OK okay. So, Peter Belize is my PhD student and he has been working with me on Data Center Network Product So it's more like a research project. So what I'm going to be presenting today is how we use the February test bed to actually test data center network protocols And we were primarily focusing on the more popular protocols"
  },
  {
    "startTime": "00:14:01",
    "text": "that are used in folded clause topology Working along with us is in PAN and BILS Stackpole from the Department of Security in our same college Okay, so why are wen lin? interested in investigating data center networks? and data center network protocols is because, you know, this has been my research project for the last three four years. So we noticed that an even in some of the talks earlier today, there was this talk about the advent of AI data center networks are going to grow in demand and in size. And even now, believe it or not, there are so many data centers that are submerged in the ocean to cut down on their cooling costs and things like that Now, while on one side, we are trying to reduce the energy consumption cooling costs, etc., on the other side, we notice that the demands and the complexity on the data center networks keeps increasing And with the advent of AI, it is still going to get worse. Okay. So and if we look at all the data center network protocols, I'm not looking at the server part of it just if we look at the protocol site you'll see that there are so many protocols which have been investigated and variations of these protocols have been used. But most of these protocols are just off-the-shelf protocols So we wanted to see, can we investigate? something that is just not based on protocols which are currently existing out there and that can address major concerns which are faced in our networks today energy and carbon footprint concerns, security concerns the configuration needs and we all know how many, how human energy crops into the configurations when you're"
  },
  {
    "startTime": "00:16:01",
    "text": "have to set up huge networks, which also happen with data center networks that are operating with BGP currently So again, like I said, you'll see that there are quite a lot of new architecture and topologies that have been investigated But when you look at the protocols that are being used in these architectures and topologies, they are variations of current routing protocols like VGP, OSPF, and so on. Okay, I'm looking only from a routed perspective. So when we started in investigating these protocols for data center networks, we've said, okay, can we come up with a simple? protocol and so on? So we decided to go with a candidate topology the most popular topology that's used in data center networks, which is the folded clause topology And the more popular routing protocol that are used in these folded class topology which is BGP, I don't know, can I, are you able to see my current? cursor? No. No, you're not So how do I point a cursor on the screen? can I or can I not I don't think you can, I'm afraid. Okay so I'll just try to explain with whatever is there on the screen. So you see two colorful blocks there on the left side is the current these router protocol stack that's being used in folded clause topologies. And they use BTP for routing. Okay that's the most popular protocol that's being deployed in folded clause topologies and they have ECMP they use ECMP because Folded Clause Topologies has got multiple paths and you want to equally load these different paths"
  },
  {
    "startTime": "00:18:01",
    "text": "So BGP along with ECMP is used and to run BGP you need TCP because BGP has to run on TCP. And then to speed up the failure recovery which is very very important in data center networks, because we should have very low down times. They use BFD which is bidirectional forwarding detection and then bfd requires udp and then all these protocols are running on internet products And what we came up with is a simple single protocol which we call as MRMTP it's the multirut mesh tree protocol okay and this protocol performs all the essential functions that for which purpose we sort of retrofitted all these protocols to do it does routing it does load balancing, it has a very quick failure recovery it does not need tcp it does not need you and we sort of did away with internet protocol because we wanted to have a non- solution which is not constrained by all the requirements that you need to run any protocol on the internet protocol like BGP OSP if they are odd decisions to work on the internet protocol We wanted to be free of that, and that's where we came up with this. And this paper is more about investing this protocol and of course we are trying to use a fabric test bed which is what you see here and i in notice that one presenter earlier on also used this fabric test bed It is a widely deployed test bed in the US. It's got, you can reserve resources set up topology, so that simple folder class topology that you see on the right side that is the one we deployed on the test bed, the fabric test bed"
  },
  {
    "startTime": "00:20:01",
    "text": "and we coded our protocol the multi right side that is the one we deployed on the test bed the fabric test bed and we coded our protocol the multi-route meshry protocol we coded it in C due to the limited time. I'm not going to go into the details of how this protocol works but you can have a look at these papers which were published in SICCOMFERR FIRA, 2022, and 2023, the 2026 paper is better because it's got more details 22 was more concepts. And we also made a presentation in Nanog, 91 I actually provided a YouTube link, Nanog91 recorded the whole presentation and it is available in YouTube. So I think because they converted this into a PDF some of my figures are sort of overlapping and I'm sure you lost the link to it but you can look up Nanog 91 YouTube presentations and you should be able to pull out this presentation which gives you all the details on how this very simple protocol is able to set up routes and do the forwarding to to cut short everything all that we do is, you know, all these are the TORs, L11, L12, L2, L21 L2, they are the TORs. And from the TORs, as root, we construct mesh trees that reach all the top tier spines without forming any loops, okay? So one of the major challenges we face in our routing protocols is loop avoidance And this is actually a very simple scheme and that's where I would request you to have a look at the presentation that sets up all this route It's got animations on how the route set up is done okay now and my PhD student Peter Willis he's great with setting up all these automations tools and fabric. So there's a whole"
  },
  {
    "startTime": "00:22:01",
    "text": "bundle of tools. Again, I have given you a GitHub link here where you can set up topologies to test BGP. We downloaded BGP from the FRR routing all the protocols required for comparison. We downloaded it from the FRR routing site and we use his very nice automation script that you see here, that can be used on the fabric test, but you can use it for any other purpose also you can tailor make it he has built it in such a way and so the test cases that i'm going to be presenting to you are we do fail at all those test points. T.C TC2, TC3, TC4 and we send traffic from the compute node 11 to a computer node which is sitting in Pod 4 and we tried the only result that I presented in the paper because it was a two-page paper was the packet loss. So for all the four different failure points how much packet loss do you face? and that is what you see here you can see we are comparing it for a two portopolis and a four-part topology and if i do not the y-axis is a log scale That is because the loss of packets without if I do not, the y-axis is a log scale. That is because the loss of packets, if I use just BGP, ECMP was pretty high for some of the test cases So the blue one is test case one or orange is test case two, and so on So you will notice that we were losing more than 4,000 packets. I was just sending a stream of packets between those servers, and that is a loss of packet. And the last one to the extreme right, we introduced B a stream of packets between those servers, and that is a loss of packet. And the last one, to the extreme right, they introduced BFD into BGP and you know of packet. And the last one, to the extreme right, we introduced BFD into BGP, and you notice how much it cuts down on the packet loss"
  },
  {
    "startTime": "00:24:01",
    "text": "fabric is a very good tool to test it out and you can just imagine if I scaled this network to multiple parts, what will be the benefit? of looking into simple product like MRMTP and like I said you can test these protocols using the fabric test bed. Looks like I'm running out of time so I'm just going to end it with this and the takeaway for me is and this is predominant my research area. Do we need to read? routing protocols at all in networks today? You have beautifully structured networks very definitive architectures, we don't throw routers and switches around. And using those structures, you can auto assign addresses on auto auto-establish paths that can do all the routing for you it will cut down on your configuration needs, errors, auto-address assignment It's a non-IP-based solution, but it backward compatible with IPv4 IPV6. It can be used with limited domain which are currently struggling with the IP addresses Any special addressing you can use with this types of protocols. This is just a beginning. They can be extended for intra-AS routing as well. Okay, so this is one solution that we are looking at and coming back, if a router, I replace FISA as well. Okay. So this is one solution that we are looking at. And coming back, if a router, I replace five, six protocols with a simple protocol. Look at the cut down on the energy cause equipment cause maintenance cause that's all a great study to be done no bgp no TCP, no IP. All the same security threats that we faced against these protocols can't be avoided. That is one of the studies which we are currently doing. So I think I'm going to stop it here because I seem to have run out of time I have added some more slides from my other work. You know, like I said, I was"
  },
  {
    "startTime": "00:26:01",
    "text": "not able to add much on the... Thank you very much but there is only one minute left, so probably better to leave for the questions. I see Thomas and Lars in the queue Okay. Yeah, hello um question um to my understanding many data centers run STN, have you? evaluated how this interacts with NDN? sorry, SDN controllers? and networks? I don't think there is a need for SDN in this case because, you know, this is a very simple protocol, it is able to establish path I don't need any sort of a central controller to control all those path establishment or decide on the paths to be used And adding SDN, you know, adds another level of complexity and there have been severe security issues against SDN-based DCN topology that I've used SDNs So I'm trying to keep away from that Any other extra feature? if they need to be added, they can be added in this protocol because look at it like this, this protocol was designed and developed by us. You want any other feature to be included, we will add it Long second, very briefly, how do you do congestion control? if you don't have a TCP layer? Because it doesn't look like your routing protocol does that tcp congestion control if you don't have a TCP layer? Because it doesn't look like your routing protocol does that. TCP in the routers are not there for congestion control. They are there because BGP requires TCP. So you're running TCP? on top of your routing protocol then, end to end. No, no no, no. TCP is running still on the servers this solution is only for the DCN routers all right thank you very much. Let's thank the speaker"
  },
  {
    "startTime": "00:28:00",
    "text": "And we have our next speaker online presenting quick pro, integrating deep, reinforced and large learning to defend against quick handsake flooding attacks The floor is yours Hi, everyone. This is why you're the i'm from concordy University, Montreal, and I'm going to present a quick pro integrating deep reinforcement learning to defend against quick handshake flooding attacks This works with my supervisor my PhD supervisor Carol Fang as well I'm going to cover introduction of Quick Pro, quick overview previous research works, motivation, problem statements QuickPro framework details, plan implementation details expected outcome and benefits, and finally, conclusion and future works introduction of QuickPro, it utilizes deep reinforce learning with proximal policy optimization algorithm for dynamic security optimization against handcheck flooding attacks. Quick Pro employs real time rate limiting connection prioritization and uh traffic shaping. And it also implements the isolation forest and for the anomaly detection and support vector machine for the pattern recognition. And quick pro features a feedback loop for ongoing improved of security policies so quick pro is for quick protocol so quick is a udb based multiplex and secure transport protocol. It provides flow control streams for structured and efficient communication It keeps low latency connection establishment and quick supports network path migration and also offer zero RTTN connection migration feature And finally, quick enhances security with measures for confidentiality, integrity, and availability our previous works in 2022, we published a survey on the security issues of week, where we figured out multiple security issues"
  },
  {
    "startTime": "00:30:01",
    "text": "And in 2023, we published our specific wing handshake related issues titled as an empirical approach of evaluate the resilience of quick protocol against handshake blood attacks and on the same year we come up with a detection mechanism called quick QuickSheld. It is a statistical mechanism, a rapid detection mechanism against quick flooding attacks And earlier this year, we published a machine learning base approach that is called Quick One, a machine learning optimization-based hybrid defense approach against quick flooding attacks, where we use vision optimization for that. And now is will come up with quick pro integrating deep reinforcement learning to defend against quick hand-check flooding attacks Motivation of our works, quick handshake process is vulnerable to flooding attacks with 4.6 times CPU amplification factor traditional TCP scene flooding detection mechanisms are ineffective due to quick distance handshake design. Quick shield a prior defense solution, has a higher false position rate and potentially blocking the legitimate traffic quick want lacks adaptability to to rapidly evolving the network condition and sophisticated attacks Problem statements. Malicious attackers targets quick's handshake mechanism leading to network disruption and resource exhaustion and current defense for matthew quick handshake flooding attacks like Quick Shields have high false positive rates and damage and resource exhaustion. And the current differences for matthew quick handshake flooding attacks like quick shield have high false positive rates and diminishes detection accuracy in the dynamic and adverse while Quick 1 lacks adaptability Quick Pro framework Quick Pro utilizes deep reinforcement lines while quick one lacks adaptability. Quick Pro framework. Quick Pro utilizes deep reinforcement learning with PPO algorithm to dynamically optimize security measures against hand check flooding attack Functionality, it detects and mitigates quick flooding attacks by continuously monitoring network traffic and adjusts"
  },
  {
    "startTime": "00:32:01",
    "text": "defense mechanism in real time dynamic optimization quick pro leverizes machine learning to adapt detection and mitigation strategies based on current network condition and emerging threats. Improved accuracy it reduces false positives and increased detection accuracy compared to previous matters, such as Quick Shield and Quick want In quick simplified handshaking, there is issue that is unverified response issue in the first round trip And quick handshake flooding attacks can be happened in three scenarios one is a version negotiation without ad address validation and with address validation we proved it in our previous paper called quick one Cool components of quick is deep reinforcement learning agents network traffic monitoring module, and adaptive defense mechanisms Deep reinforcement learning agents use proximal policy optimization to learning and optimizing security policies based on environmental feedback and neural networks with convolution networks for the feature extraction and followed by fully connected layers for decision making traffic network traffic monitoring module continuously monitors incoming traffic to quick servers and uses machine learning algorithms like isolated forest for anomaly detection and support vector machine for the pattern recognition Adaptive defense mechanism use employees dynamic and rate rate limiting, connection prioritization, and traffic shaping techniques and adjusting real time based on the feedback from deep reinforcement learning agents and the traffic monitoring module Planned implementation details of QuickPro involves integrating with existing quick implement like Air Week Weekly"
  },
  {
    "startTime": "00:34:01",
    "text": "for seamless operation and deep reinforcement learning set up with the algorithm and neuralettes uses proximal policy optimization for algorithm and neuralness for CNN for the feature instruction and followed by fully connected layers and decision making and in the case of network traffic monitoring uses continuous monitoring by utilizing isolation forests for animal detection and sbm for the traffic for the pattern recognition Expected outcomes and benefits high quick pro has high detection accuracy, reduce false posit dynamic adaption and enhanced resistance resilience Conclusion and future works, QuickPro has a effective detection and mitigation techniques and it has low false positive rates and with enhanced resilience And in our future works, we will focus on the multiple employees libraries implementation to see that proper results on the variation Now, currently we're using the DARPA dataset as an attack data set by manipulating regarding to our projects. But in future, we will test again as the diverse attacks and as well as the developing a comprehensive quick attack dataset Thank you, everyone Thank you very much Do we have questions? hello so i have one question. So did you try testing this? on real world quick traffic? to see how quick pro is performing? performing? In real world, we didn't do it yet. It is our ongoing projects currently so what we are doing now we take as a we collect matthew quick data and from using wash and as a as a attack data"
  },
  {
    "startTime": "00:36:01",
    "text": "we collect the DARBA data from the TCP DDoS data set so we modified it as seen for CELO and act for C CET for, for the server hello And we see the only using AIQQWIC now but we have a plan to use it in multiple implementation like Quick libraries and after that in the real scenario as well. Thank you Thank you eggert, a quick question. Have you validated that you're using less CPU? time for the training and running of your model than you would use for absorbing the flood? Thank you for your question. We validated in our previous two methods. One is called a quick ship and quick want. One is statistical and one is machine learning base but this one we just uh i mean based on the previous results, we are still working on that All right, very well Let's thank the speaker Thank you you Hello, Tenev, just one second Your slides should be coming up Okay. Am I audible? Yes, we can hear you. Somehow your slides are not coming through. Yep, yep. I'm sharing all right so next we have Danesh Sein Ali, presenting BBRV3 in the public internet, a boon or a bane The room is yours. Okay, hello everyone, I am Donesh, and today I am presenting on behalf of my colleagues and collaborators from Max Planck Institute for Informatics and Foo"
  },
  {
    "startTime": "00:38:01",
    "text": "Amsterdam. This is a work about BBRV3 in public internet Okay, just to refresh your memory, I know everyone is familiar with BBR. The first version of the BBR was introduced in 2016 and it was a big paradigm shift in that date, because all of the CCAs were just reliant on delay or loss to detect the congestion, but they decided to use estimation of bandwidth or delay and also probe and drain to avoid filling the cues And it was in the main line of the key Linux kernel from version 4.9 So BBR was pretty important because in 2019, just three years after the introduction of the first version, a study in here that I'm showing this snapshot of it shows that 22% of the Alex top 20k websites were using BBR and by their estimation, it's more than 40% of the internet traffic in that date date and early after the introduction of the BBR first version, Jeff Pistone evaluated it because of this huge mic migration of the traffic to the BBR, and as you see in the BBR blog post in the Ripe Labs that he's showing the average throughput over time of the cubic flow that is competing with the BBR flow. As you see the QBBR showing the average throughput over time of the of a cubic flow that is competing with the BBR flow. As you see the cubic flow at the beginning, the red one is starting and the BBR flow is joining to it after 20 seconds, and as soon as the BBR flow is joining cubic flow, doesn't have any chance to grab any of the band Also, another step in 2019 shows that even a single BBR version 1 flow can grab most of the bandwidth"
  },
  {
    "startTime": "00:40:01",
    "text": "or 50% of the bandwidth while it is competing with 16 independent cubic flows in the same bottleneck bottleneck So the Google team redesigned or are redesigned and implemented it new version of the BBR. BBR version 2 was introduced in 2019, which the big change was a reaction to loss and also ECNR and also some adjustment to parameters to ensure fairness to the loss-based protocols So again researchers studied this new version and as you see, the second version of the BBR is totally fair to the QB cubic blows Until last year, that the third version of the BBR was introduced and it was a minor evolution of BBR version 2, which was supposed to fix bandwidth convergence with or without loss and or ECM markus amend also some performance to tuning for better performance when it is competing with the plus base protocols. And the promises was that better coexistence with the cubic or Reno also lower transmission rate and reduced latency for different buffer configuration to similar to the previous works we also this decided to see how these promises work in the internet. And we set up a very simple test with a Dumbled topology where we have a bottleneck in the middle, it's 100 megabits per second bottleneck and we used off-the-shelf Linux tools to configure our cues, buffer sizes and also our delays We did a comprehensive evaluation For example, I'm just giving some examples in here, inter a CCA fairness where to BBR flows were competing with each other or art fairness where the RTT of these"
  },
  {
    "startTime": "00:42:01",
    "text": "two BBR flows were different, and also coexistence with L loss-based protocols, which was the classic problem we saw in the previous slides and some real-world network traffic that not only we have mice, elephant flows, long-lived flows like that are called elephant, also we have some short flow that are called mice This work has been published and presented in the PAM 24 if you want to see more details about it please read the paper. But for the interest of time, today I'm just focusing on coexistence with the lost-based CCAs So, Sim, we beginning we started to reproduce the previous results, 1BBRV version 1, competing with 1 cubic flow, and as you see, the flows are starting at the same time, and this plot I'm showing the 2 throughput over time And as we were expecting from the previous work, BBR will be dominating cubic But it was really surprising for us that we saw that BBR has similar behavior or sometimes even worse than the first version of it Also, in the introduction, I said that a single BBR version one can grab more than 50% of the bandwidth when competing with 16 cubic flows. So we decided to have a similar experiment where we have one to five cubic flows I'm showing in the x-axis to decided to have a similar experiment where we have one to five cubic flows I'm showing in the x-axis that are competing to one to five BBR flows in each cell of this i'm showing JFI at the top, Jane's Fairness Index at the top, which is the number and also the big number and also the color of the set the cell. And at the bottom on the right side, I'm showing total cubic flows share and at the left total BBR flow"
  },
  {
    "startTime": "00:44:01",
    "text": "share for example in this specific cell where one BBR flow is competing with five cubic flows, we see that those five cubic flows only have 20% of the link while the single BBR flows grab more, uh, more than eight, about 80% of it If we repeat this experiment with VBR version 2, we see that the fairness is much, much better and also the bandwidth share of the cubic and BBR are reasonable We repeated this with BBR version 3. It's somewhere in between but it's leading towards the BBR version 1. It's the fairness is lower than the BBR version 2 and also you see that cubic flow five cubic flows only have 40 of the link, while single BBR flow has 60% of the link If we, if you look at the top list extreme case of this experiment, you will see that okay the fairness is good in that area. But if you look at the numbers, in the bottom, we will see that cubic flows almost are dead when they are competing with several BBR flows so bbr flows are fairly shared the link among themselves but they are not letting the cubic flow to leave For BBRV2, the case was a bit better. So we can overall say BBRV3 shows unfairness towards multiple cubic flows as seen with the BBRV1 Another big change, from the version 2 of the BBR was ECF and also ECN is going to be deployed more in the internet so we decided to take a look at how it is performed while the ECN is on or off Just a quick recap again for ECN when two or several"
  },
  {
    "startTime": "00:46:01",
    "text": "flows of TCP are competing with each other and the bottleneck router supports ECN after the Q buildup after certain threshold, they are marking the packets with the congestion encounter. These packets go through receiver, receiver reflects them back to the sender, and send their receiver to react to them let's see how bBR was designed in this As we know from previous presentation by the Google team, that the bBR design was dcp inspired DCP-inspired ECN So we took their similar conf- configuration to their configuration where we just scaled the marking threshold. We have just 100 megabits per second in here and the whole RTT of the system was 100 milliseconds Just here I'm showing the result of PBRV versus cubic because in this case the queuing mechanism is different into free previous slides that I showed, queuing mechanism was FIFO, but in this case it's it's codel so still bBRv3 is not fair to the cubic and by enabling the ECN, the result is even worse than the previous one. So we repeated the experiment that we had one to five cubic versus one to five BBR flows. And as you see in the right corner in the right bottom corner cubic flows only have three had 1 to 5 cubic versus 1 to 5 pbr flows and as you see in the right corner in the right bottom corner cubic flows only have 3% of the link by in enabling the ECN even this this percentage decreases to 0.5% Even in the case at the top left as well we see that the share of the cubic is not really that much And the BB flows probably are fair to each other, definitely are fair to each other because the fairness number is high"
  },
  {
    "startTime": "00:48:00",
    "text": "So just in conclusion we did an evaluation of coexistence of BPR with cubic, and we saw that without EC this coexistence was not that well Even enabling ECN did help the case to improve the performance of the fairness of the PBR to the loss-based protocols protocols So just in conclusion, we believe that Google has done a great job implementing a new CCA a new CCA that was a big paradigm ship compared to previous congestion control algorithms and evaluation of a congestion control algorithm is definitely a challenging task and we believe that us as a networking community maybe should consensus on some kind of guidelines how to evaluate CCAs to before deployment in the internet So if you want to read more about our paper, scan this URL, scan this QR code and visit our website. Thank you Thank you, Daneh. Are there questions? I see michael jones the microphone approaching to the microphone Hello, this is not a question, just a small comment because you kept saying there's a big paradigm shift I would like, I think it's good for the community to be aware that the have been some TCPs that the these kinds of things before. It's not that new. I mean, West has always looked at the accurate and used that as a guidance to understand the capacity Okay, thanks. It's just a side command thanks thank you you"
  },
  {
    "startTime": "00:50:00",
    "text": "And I see another, sorry, I started with your name Just a comment about the ECN comparison I don't think it actually makes sense to compare it because BBRV2 and V3 is ECN is DCTP inspired and DCTC DCTC And comparing a DC-CP-inspired ECN response to a classic ECN response will result in in results like this but this is, I wouldn't say this is a flower in the V3. You should compare it to Prague or DCTCP rather than cubic yeah i see your point but but flow in the in the V3. You should compare it to Prague or DCTCP rather than QB. Yeah, I see your point, but in the documents that we saw in the Google's report we didn't see that anywhere they say this is just for the data center. So we thought maybe it's going to be dependent in the internet as well. That's why we did this OK. Thank you i'm michael gibbs back me again speaking about ECN the key thing is is this ECT zero or is it ECT one? Do you know? what it used? uh to be honest i don't recall so if it's ECT1, right, then this is for L4S and it doesn't make sense to compare it in the way you've done. If it's ECT zero, then it would make sense to compare it like you've done i think OK, I will look this up definitely. Thank you And Reese is next. Hi, reese enghardt If I understood you correctly, you said, you wish there were guidelines for evaluating congestion controllers before they got deployed on the internet Well, I have good news for you. We have a draft in the congestion controller working group, 50% of your biz, and I invite you to take a look at it and come back with more evaluation with BBR3. Of course, of course. I'm everyone of that and we are looking for any collaborations or data sets or whatever the community can help us to improve the evaluations. Thank you"
  },
  {
    "startTime": "00:52:01",
    "text": "Great, thanks well let's thank the speaker And is the next presenter in the room? So, you're one percent of the See? We put the time out. Thank you can find anything to the Q&A so you're all all Yeah. I'm Bunel this, mate. Yes, go ahead Hi, I'm Punele Smil. I am PhD student from UC Center Barbara. Today I'll be present my paper that is about the tool. We are working coordinate NetMosaic. This is a joint work with collaboration from ECHSURE, Nixon and my colleagues from UC Center Barbara. So MLM models for networks. So if you look into this space, there are at least 1,000 research papers, multiple products and startups have been created and overall billions of dollars have been invested So given these investments, our expectations are easy to develop ML models for any given problem and target environment and abundance of production ready ML models ready for high-stakes DC in making. But in reality, few, if any of these models have ever been deployed in production settings so for example these are some of the models in the literature Why can't we deploy these in production? So the problem is they suffer from generalizability issues like shortcut learning out of distribution samples and various correlation And hence, most of these ML models fail to generalize meaning they don't perform well on new or unseen data and so are not ready for production"
  },
  {
    "startTime": "00:54:01",
    "text": "deployment. So how do we develop? generalizable ML models for network? So this is a standard ML pipeline let's say we use EIC IDAS data to detect malicious traffic Is this the right data? Next we get unusually high F1 score is the model under specified For example, model might be learning a shortcut instead of truly understanding the traffic. So how do we collect better data? at scale? Answering these questions, is critical for developing generalizable MLRT artifacts for networking. So recently they are has been progress in this for example, PNOT presented here last year can transform your production network for data collection trustee presented in CCS 22 can take in any trained model and give you give easy to interpret the CNP and a trust report that a domain expert can then use to under model specification issues like shortcut learning Next, you can use a tool called NetUnicon to endogenously curate new data can then use to understand model specification issues like short-cut learning. Next, you can use a tool called NetUnicon to endogenously curate new datasets, which don't have these under specification issues like short-cut learning So, but does and you can repeat the cycle continuously eventually getting rid of data-related problems but does Net Unicon truly solve the problem of collective? the right data? So a bit of review on Net Unicon So before Net Unicon, you had a learning problem in that network environment. You had to write separate data collection pipe of review on net unicorn so before net unicorn you had a learning problem and network environment you had to write separate data collection pipelines for each learning problem and uh network environment. What Net Unicon did was provide this thin waste where it decouples the data collection intents for different learning problems from the deployment mechanism. Hence, this abstraction simplifies collecting data for any learning problem and target environment. But net unique has this limitation. So to"
  },
  {
    "startTime": "00:56:01",
    "text": "curate realistic traffic, you have to mimic real-world, you have to mimic application diverse of real world data but writing that application logic is a manual effort and hence it is hard to scale right and and application logic that you write might break over time as well because of updates in application that effect your code so hence you will have to have more manual effort in this so how do you scale data collection for new applications so for uh hence, you will have to have more manual effort in this. So how do you scale data collection for new applications? So for this over idea is to use already available resources in the form of publicly available GitHub repos that can capture diverse application logic And our work has also shown that there are around 70k GitHub wrappers which contains containerized applications that generate diverse network traffic and can easily be deployed using a Docker Composed file. We refer to this as big code So can big code address Net Unicons limitation? So this is our earlier figure of NetUnicon This is where our system net mosaic comes into picture. So it uses big code application diversity and subsume platforms like NetUnicon to deploy it and uh physical and virtual networks. Hence it gives us the ability to curate more data and hence argue about how do you argue about the models in the ability to generalize But does it enable curating a better data? set so for this we consider a learning problem of traffic classification here we identified services based on encrypted packets in a place flow. Over data source was the 16 GitHub repos and we labeled them using IANA port numbers"
  },
  {
    "startTime": "00:58:01",
    "text": "port and service mapping and we curated this data where we got and this data had 1.7 million flows and 54 million packets and apart from that we had 264 unique services that shows the application diversity that this data had over top services include https red services that shows the application diversity that this data had. Over top services include HTTP, Redis, Post, GRE, SQL, Forward MongoDB, and MyS MySQL I think it's stopped working MySQL I think it's stopped working, okay, yeah. So, other than, diversity along with this application diversity, was able to curate far bigger data sets than then of the other available data sets in the community that is used for traffic classification So NetMOSIC is able to carry this better data set which is more diverse and realistic But does it enable create? developing generalizable models? For this, we deployed for this we collected some data and different network conditions introduced in a virtual network We did this by deploying services in a virtual network using Docker component file present in 256 GitHub wrappers And so we collected two source datasets, dataset A and dataset B In Dataset A, we didn't place any limit on the network condition Whereas in Dataset B, we placed limit between links in different containers in our Docker Compos file to introduce some congestion a low congestion. And after that, we curate a target data set which is an unlabeled data set used for assessing the model's generalizability. Here, we introduced high congestion and by congestion I mean high packet loss"
  },
  {
    "startTime": "01:00:01",
    "text": "high latency, lower bandwidth and finally we trained random forward decision tree logistically regression in MLP using Dataset Pay, which is the default setting Dataset B, which is the low congestion setting right? And after this, would tested their performance performance of, so, okay, there more thing, so the model strain, with Dataset A, we call them Model A, and the model strain with data set B we call them model B so here we tested the performance in the form of FN score for model A and model B for source data set and target data set So for model A, the source data set on which source data set is the data set environment on which we train model A. So when we tested it in data set from the same environment we got decent performance with random forest and disease entries Model B also exhibits similar performance when tested on source data set But when we tested it on target data which was that data set with high congestion we see that there's a great performance drop, hence highlighting issues with generalizability But when we tested Model B on the target data, set, we see performance drop, but not that much as it was for Model A, and highlighting some generalizability so this makes us think that you using training data collecting and the more realistic network conditions could improve models generalizability So these are the summary and the next steps So we learned that our system simplifies collecting data for different applications under different network conditions by leveraging big code and platforms like NetUnicon"
  },
  {
    "startTime": "01:02:01",
    "text": "Next, the prototype implementation exists and it demonstrates the ability to create better data sets that we can use to study and improve models generalizability. What's next? So for this as this is still an ongoing effort, we want to develop some closed-loop workflows where we can study which network conditions are an ongoing effort, we want to develop some closed-loop workflows where we can study which network conditions affect the data quality the most and also leverage model explainability tools like trustee to shed light on which part conditions affect the data quality the most, and also leverage model explainability tools like trustee to shed light on which aspects of network conditions and application logic affects the model generally models which effect the model generalizability the most and also for which kind of learning problems and lastly we also want to scale data collection for more Rappers and improve data quality by addressing class embeds and also for which kind of learning problems. And lastly, we also want to scale data collection for more wrappers and improve data quality by addressing class imbalance issues and filter noise samples Thank you. And I can answer any questions or if you have any comments Thank you very much. Questions, comments? see any comments or questions or questions so thank the speaker thank you very much thank you And last, what not? least, we have Jerry who is going to present to large Language Models Dream of Sockets All right. Hello everybody. Thanks for staying. Until the late evening So I will talk about large language models and what they might have to do with protocols And so what is that about? So there's obviously been lots of exercise"
  },
  {
    "startTime": "01:04:01",
    "text": "about large language models recently but mostly in terms of like chatbots and programming assistants and so on. And for me, as a protocol ends, there's obviously been lots of excitement about large language models recently, but mostly in terms of like chatbots and programming assistance and so on. And for me, as a protocol engineer or network engineer that doesn't do that much. So that's not exciting, I think so we started asking whether you could actually have some of these models speak in quotation mark, this protocol language natively. And it seems that that potentially should be possible given that this multi multimodal generative AI tools available for other things, so why not protocols as well? of course this is not totally new we have very AI tools available for other things. So why not protocols as well? Of course, this is not totally new. We have various kinds of things. You take yourself to the nearest chatbot and you can ask it to construct protocol message to some degree of success at least We also had recently people publish a work on building tailored model specifically for the digital world We have had people look at use of large language models for the protocol work, for instance looking at specifications and so on. So there's many related works So what is our vision? Our vision is that you somehow acquire a set of training data that is in the in the form of packet traces for instance And then you feed this to an LLM system as training data and then we make something interesting happen. And what is that interesting? That could be actually several things. Could be done diagnostics explaining what's going on. It could be tested data generation, could be simulation or even quick prototyping And our research approach has been try and understand if the is feasible and to what extent keeping an open mind maybe it works maybe it doesn't what are the issues there's also different ways of doing this. So we try to test those different techniques this is early work that's why this is a lightning paper, so we just basically started"
  },
  {
    "startTime": "01:06:01",
    "text": "We have some results, but not super much yet but we already run into a number of challenges The first challenge is that protocols use usually have like this complex fields length fields check sums encryption and so on and the LLMs they're not very good at dealing with math. And, you know, maybe we shouldn't even ask them to do that sort of thing. And for some of the fun problems like encryption, you principle, shouldn't be able to do it also protocols are not everything even though we protocol designers like to think that's the most important thing in the world, but typically there's like configurations and other stuff in systems that affects the behavior. So if you try to understand the behavior, protocol is not enough Also, we should be very, very worried about letting our large language models or AI systems send messages around the network or access resources. We really need to think about what the security implications of that are. Of course, hallucinations is a problem. We had some discussion about that in the context of the keynote this morning Yeah, you can't get to 100% correctness What, you know, what does that do for your? use case? And then we have many efficiency problems we do have some parcel solutions in our work for this for the complex fields we've sort of combined traditional techniques like message parsers and constructors together with LLMs and sort of both do like their part we of combined traditional techniques like message parsers and constructors together with LLMs and sort of both do like their part. We, if the question is that like we are looking at protocols but we that's not enough, we can of course also look at the other aspects of systems, like look at what the configurations are, what the file system accesses are, and what's happening in other internet security and safety an obvious answer is some kind of limitations or sandboxing at least a partial answer maybe not the final answer. Hallucination that's a big problem. Some of the things that we"
  },
  {
    "startTime": "01:08:01",
    "text": "discussed this morning can help, um, but also I'll ultimately you need to think about what use cases are feasible given the possibility of hallucination. So typically, where the human is ultimately involved and then maybe that's a more reasonable case to use And then for efficiency, I won't go into details of that. You can have like, you can use the LLMs to do a task or you can use the lLMs to generate code to do a task and then the code runs faster than the LLM instead of repeating the same thing a billion times, which might be slightly costly using these tools Okay, so I have two example use cases The first one is diagnostics And the context here is that, you know, basically you would feed expected behavior or normal behavior as training traces to the LLN And then you make a question and you feed a sort of suspect trace or problem trace you know, what's happening here and then the LLM would output what happened and it would, you know, that output would be potentially useful for a huge who's trying to understand what's going on and, you know, having stared many TCP dumps in my life for a long time and not understanding what's going on some tooling here would be super useful. Here's the next example, a simple HTTP trace where the AI is explaining that the method name is wrong and high is get in infinis and that doesn't really work in the protocol. So that's why you get an error. The AI got that. But that sort of anecdotal evidence we also attempted to do a little bit more soon systematic approach where we create an artificial protocol, created a set of messages in that that protocol of training data, we created examples of errors and examples of non-error and then tested the ability of the LLM to identify whether there are problems in this"
  },
  {
    "startTime": "01:10:01",
    "text": "example traces and we did this by having a human that will be the researcher trying to check what the results are the LLM are if they are reasonable or not And we also, because there's many ways of doing these techniques, whether you feed for instance, direct binary input or you feed the results of message parser and so on we varied the techniques that we used and then maybe we were able to compare like how do the different techniques fair compare to each other. And I want going to too many details of these results. There's a little bit more in the paper even though it's short, but basically the bottom line is that the chosen approach does affect so for instance if you can use the message parser, then you get a little bit better results for various reasons And also the other observation is that we can get to sort of reasonable, or in my opinion, at least reasonable level sort of high 90% accuracy of identifying what the problems are but more work is needed so this was just one example We're continuing the work, trying to understand this with more realistic protocols and bigger bigger real-world protocol another use case simulation, and this is kind of like science fiction use case maybe i'm not really sure if this is really feasible. One of the issues here is that because of this hallucination problems, you might not get to 100% accuracy so is that a problem Or is that not a problem? Maybe that's not a problem for simulates If you try to use this as a, you know, final purpose that could be a problem or likely is a problem But it was kind of interesting to see that you can record the behavior of systems and have the LLMs learn that behavior. So one simple example where we did this, we recorded web service behavior and a pass server was installed"
  },
  {
    "startTime": "01:12:01",
    "text": "and then we look at what's happening on the network in the field and then we look at what's happening at the OS interface, basically using the S trace tool and this is training data and based on this training data then the LL figures out that, ah, if I get, you know, this get request and with a file name, then I should open the file name using the open call And, you know, if I get minus one, then that should lead to the result. And, you know, with the relevant result and if I don't get minus one I get actual data then the data should go here in the response and then the length of the data should go goes to another place and so on so it was kind of a fun exercise yeah So conclusions, we've had lots of fun trying to do this experimentation. We found this exciting in general. We think that the protocol and system behavior patterns are a good topic for LLMs. There are some use cases where this seems potential useful, like the diagnostics There's some other use cases where we don't know or, you know, are doubtful, like the simulation or system impact implementation we also realized that it's important to not just apply this LLM technology that I have one tool, and I'm going to apply LLMs for everything and if it doesn't work then I wait for the next version of the LLM That's not how to work in our opinion. Rather it's it's better to understand what are the different tools good for? You can use this tool for this task and then this other tool for other tags. So we chose to use the LLMs in this work to sort of understand the patterns of behavior rather than the detailed bit level tasks or bit level operations yeah and plenty of research remains both on the diagnostics angle and the other angle And that's it. Questions? Thank you very much. Do we have questions?"
  },
  {
    "startTime": "01:14:01",
    "text": "questions? Then maybe a question from my side. I don't know if you have seen that there is some work on foundational models for networking by Nick Finster, Pete Gupta, come to mind I'm sure a few others I'm not sure I've seen that specific work but I've seen many other things. I can look it up Yeah, yeah, it goes in the same direction and some of the problems they encounter among others say at some point they can but I've seen many, many other things. I can look it up. Yeah, yeah, it goes in the same direction and some of the problems they encounter, among others say at some point, like they realized that they would have is a multimodal MLM because the protocols are not necessarily in the same thing, right? Like a large language model predicts the next talking in a sequence and every protocol might be having its own sequence so Yeah, and that's actually, I mean, we've run into that as well and that that's often a feature because you have this situation where you have potentially multiple different things and different sides of the box and they're all different sequences. You need to understand that as well and not just like the single behavior and also like at the very basic level like you do diagnostics it's really nice to get the explanation mike english right That's why it's useful to have the LLM be able to speak English to the user that, hey, your method name is wrong. Let me see a question from christopher janz Hi, christopher inacio. Did you compare different like LLM engines? or so like do you have any insight on on that because you're just fine tuning them, right? Well, our research theme is actually having sort of multiple approaches we're doing fine-tuning, we're doing like building the actual new new models of foundational models This particular exercise that I'm presenting now is basically in context a future of learning But we have compared the different"
  },
  {
    "startTime": "01:16:01",
    "text": "models and the work that we did here is based issues using the CPT4 model and we've used some of the other ones, but gotten in my opinion worse results So that's why we were sort of stuck with GPT4 Thanks I see David Sorry, if you already said it. I was curious, did you do any measurements about? energy efficiency this time or is that future? work? I mean, that's a huge issue with AI technology and LLM in particular. That's one of the reasons why we you know, I had hinted on this code scenario approach that instead of like if we have to do something, let's say for every packet then do you do that with the LLM or do you do that, have the LLM do a task once which produces some code for instance, that's going to do those tasks for every pack? packet and the energy efficiency is a huge problem but also costs are prohibitive if you try to do some things, a billion times with LLMs, for instance very well and looks like there are no more questions, so let's thank Jari And this concludes a very long and fruIETFul day. I hope everybody enjoyed. Thank you to the speakers. Thank you to the TPC Thank you to the audience. Thank you to the barista. Thank you to Michael Church Thank you to everybody. And I hope everybody has a good And thank you to you for organizing Thank you"
  }
]
