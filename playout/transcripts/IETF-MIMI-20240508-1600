[
  {
    "startTime": "00:00:58",
    "text": "all right hello everybody um I'm just wrangling slides over here while we wait for more people to trickle in uh we will get started with today's interim shortly um ahead of the official start as usual we need a note taker so volunteers are appreciated e"
  },
  {
    "startTime": "00:02:28",
    "text": "e e Tim did you get my slides I did uh and I uploaded them and they should be yeah we're loaded up so we still don't have a lot of people in the room so I want to wait a little longer just so that we get something more like a quum [Music] today"
  },
  {
    "startTime": "00:04:28",
    "text": "e e e okay it's 5 past the hour so I think we can at least get started with uh some of the admin stuff and then get into today's discussions so welcome everybody to the second or third inter that we've"
  },
  {
    "startTime": "00:06:00",
    "text": "had since last ITF Clary um today we'll be Focus back more on protocol and architecture matters so first off please note well the know well please make yourself aware of itf's uh code of conduct and intellectual uh intellectual property policies and the like as usual we need a we need a notaker uh I haven't changed this slide since last time but in any case since brendon's presenting um I don't think it's appropriate for them to take notes so we need a volunteer as usual I can take some notes thank you Richard okay with that settled Let's uh all right so the agenda on the agenda today um chair slides which we're um hashing out right now uh then uh Brendan's going to lead us through a discussion on privacy preserving delivery service continuing from some discussion on the list as well as sort of a pseudo draft posted up as a as a gist on GitHub um then Rowan has some updates on Mimi content format in particular focusing on dissecting TLS presentation syntax versus seore and then with any remaining time we're just going to go through open issues on the uh I suppose there should be three documents there the three adopted uh architecture protocol and content format documents um does anybody want to suggest changes to the agenda before we move [Music] on okay sounds like everybody's happy so I'm going to switch over to here we go the syncing over from data tracker didn't work but you can now upload slides PDF slides directly into meet echo which is a really nice way to last minut it gets a get a deck in um"
  },
  {
    "startTime": "00:08:02",
    "text": "okay so Brendan I'm happy to drive the slides for you um otherwise take it away is it possible for you to pass to me or do you want to drive okay uh which button is it there we go that and then I click that cool uh yeah so like T said this is a document that I shared towards the last of the the end towards the end of the last ETF uh because there was an adoption call for M protocol and M architecture and I had some feedback in particular I was concerned about uh the the Privacy aspects of the protocol document as it was shared um but if you kind of start from the top of what does a Mimi delivery service actually need to do um there's a couple of things the most important I would say is probably access control so when you create a group um you want to be able to control who is able to send and read the messages in that group I mean they are all encrypted um but it's still better if you can make sure that people that aren't in the group um can't read messages or send a bunch of junk messages and make it really hard to to participate in the group um and sort of as a step down from that spam and abuse filtering so to the extent that that spam messages get through Access Control you still want to um be able to detect and remove those so whenever someone is just sending like a bunch of junk messages uh you want the delivery service to be able to remove those so that users don't have to receive them and process them and also so the provider doesn't have to store them for a long time in like waste dis space and there's a lot of other things that the delivery service do but just sort of starting with those as like the the Top Line um the current approach in the the Mimi protocol document is that it does this with commit inspection so"
  },
  {
    "startTime": "00:10:00",
    "text": "whenever a commit is sent to a group the delivery service is supposed to look through all of the proposals in the commit and see how thatx group membership um and so it does that to always keep tabs on um which which users are actually supposed to be in the group um and also I think sometimes it will send proposals and it will enforce that the next commit to the group has to include that proposal so that it can uh enforce changes to the group State as well um the reason that's not gr the reason that's not great is is first of all you can have invalid commits so the provider is not actually in a position to verify that commits are valid um but what it's doing in the current Mei protocol is that it's trying to enforce that certain commits get accepted so uh you have the kind of obvious issue that I as a malicious client can send an invalid commit um the provider will see that it will look valid to the provider because the provider can't actually verify it and then it will try to force everyone else to accept my commit and everyone else is going to get blocked on trying to process this commit which is not actually um processible you also have issues with uh no membership privacy like I said so it requires um if if the DS is going to inspect every commit message it requires that all of the handshake messages be public and so the DS always knows everyone who is in the group even if those users are not um members of the the provid own service um so I can see you know if if I'm like a little service provider federating with like Facebook I can get personal information from all of the Facebook users that ever uh interact with my service and that seems wrong um and so we we talked briefly about pseudonyms I think in the last ietf notf the last interim um and I mean that's kind of a solution it does have a lot of implementation baggage in terms of who can be added to a group and who can add"
  },
  {
    "startTime": "00:12:01",
    "text": "someone to a group because you need um um you need to have a connection with the user to be able to add them to a group and it actually has the same issue with invalid commits as well because it doesn't address that issue um yeah yeah um so in in terms of the uh you know you mentioned this issue of being able to see what is um all the user you're you're provider being able to see all the users on the Facebook side but with pseudonyms this is definitely more of a hiding in plain site in that direction but it's actually more of a concern in the other direction where there are relatively small number of users on a less well-known provider uh then then the likelihood that it's you know a handful of specific individuals becomes much higher yeah that's a good point I actually didn't think about that until you sent your message to the list that your provider is kind of an anonymity set I mean especially with pseudonyms yeah Rich yeah um I just wanted to clarify a little bit um whether the to what degree the concern here is about the Hub provider versus other providers that might be participating in the concern for membership privacy or for invalid commits um I guess either way more so than membership privacy I guess because I it seems like clearly for the access control Point um The Hub needs to know the the the membership in the room unless unless you have some magic solution for that but maybe we could deny that information to other people I mean in the current in the current protocol document I don't believe that you have membership"
  },
  {
    "startTime": "00:14:01",
    "text": "privacy from any of the participating uh service providers because every all the Comm message is public and everyone can see the the commit messages so every provider can see all of the members of the group yeah yeah that's correct I was just trying to get an idea of what you were trying to solve for with this um so what I would like the property that I'm going to talk about sort of towards the end of the presentation is that I would like um like ran said your service provider to kind of be an anonymity set where if I'm a hub Prov if I'm a hub provider and I add a user from Facebook um I would ideally not see which user of Facebook my own users are talking to uh I would just see that we're talking to someone from Facebook so the point would be to make sure that the social graphs of different providers are not shared between different providers the social graph that you have stays local to your service provider and then you can Branch out to different service providers and like rely on their social network but you can't learn about their social network okay thanks I'll look look forward to rest um so uh the question that I got when we were talking about this in terms of the adoption call was how would I actually solve this problem so that is the next slide um so if you think about like what an idealized MLS group looks like it tends to be drawn sort of in a single line where you have uh a single Epoch and sort of the dashes in this line here denote application messages and then the circles at the end of each line denote a commit so you send a bunch of application messages someone sends a commit um and then that immediately starts uh a new Epoch and you kind of keep going like that so each Epoch has a single commit um which starts immediately a new Epoch of application messages until someone's in the commit and you've got one commit per Epoch and"
  },
  {
    "startTime": "00:16:01",
    "text": "it's always um very nice and clean and if you're sort of naively implementing a delivery service this is probably how you would be inclined to um try to implement it at first um but kind of like I talked about on the first slide in reality Forks are inevitable because multi multiple commits can always be sent they can be sent um by accident because there was like a race condition or there was um a bug in a client where it accidentally sent a a commit which was not valid um but it could also be sent maliciously by somebody so this is um actually a point where Mimi specifically really does need to be robust to this because if you're building mls in like a close source code base you can have a lot of confidence in exactly what code is interacting with your server um but if you have an open source code base or MIM a Federated codebase or a Federated environment um the the minimum quality of code that's interacting with your Mimi server is going to be very low and so you're going to have a bunch of junk and you have to um be very robust to people sending junk to your server and so when there are forks and there are multiple commits and you as the delivery service are not in a position to decide which one is right you have to be able to to handle Forks um so the way that we do that once uh so the way that we do that is essentially that we put each Epoch in its own little box and inside of this box all of the messages are ordered linearly so you have a complete linear order of messages that are sent within the epoch but then each Epoch sort of gets put in its own little box and they're all separate and there is um not a strong connection between the boxes so"
  },
  {
    "startTime": "00:18:00",
    "text": "kind of like I drew here we have multiple commits in one of the epochs in this box in the middle and then we have multiple subsequent EO that come after that and there's kind of an implicit connection um that you know one commit was added to this box and then it created this next box um and so it's kind of like a directed aycc graph instead of just a line like we have um in the the ideal MLS case and so to actually make this usable what we do is we give the boxes each IDs and the ID is what clients so either um actual users or remote service providers will use when they interact with the Mimi service they'll refer to boxes um and they use that ID to identify which box they either want to send their message to or um which box they want to read messages from so if you're starting here in in box a then you can say I want to read all the messages in box a and then once you get to the end and like you want to send a message you can tell the tell the service provider I want to send a message to box a and it gets added to box a and it's sort of separated from all of the other boxes it's it's contained to this one um little area and so if you think about how does reading messages like across several epochs actually work with this sort of system um if I'm a client and I'm starting in box a then I'll read all of the I'll read all of the application messages in box a then I'll get to this commit and I will I will accept it because it's a valid commit um which is why I circled it in in green um and then once I process that commit I know that the next box IDE is box B um so then I go to box b i download that I download that from the service provider and I read all of the application messages in there there are some commits which are xed out because my client doesn't like them for whatever reason maybe they are their m forms or there's some sort of"
  },
  {
    "startTime": "00:20:00",
    "text": "change happening in the commit that I don't think should be allowed like um adding someone to the group that shouldn't be allowed to be added to the group and so basically I just skip over those invalid commits the same way that I would skip over any invalid application message that was maybe signed wrong um and then I get to this last commit which is in green so I like it so I process that commit and then I move on to the next Epoch um so it's this kind of jumping from box to box um where after you process a commit you learn the next box ID and then you jump to that box and then you read all the messages in there and then you jump to the next one um and so in that way you're kind of um following a single path through the the graph of boxes yes ran yeah I I I don't know if you were planning to go into this in the next slide but the the problem with if if uh the client reading you know reading this in box B decides that this commit that it received is invalid and somebody else in the group thinks it is valid um dealing you know dealing with that particularly if it's a malicious client or a bug um that that's a hard that's a you know sort of a classic hard problem um without a quorum and you know without or without some kind of central resource to to to be an arbiter well so the central resource that's an Arbiter in this case is um the code base so everybody needs to have the same policy for which commits are acceptable and which aren't and that's actually true for vanilla MLS as well is anytime you're run MLS everyone needs a policy to uh determine which commits are acceptable and which aren't um and everybody needs to agree on that policy or else you have uh the problem you you just said which is that people will fork and that's a bug"
  },
  {
    "startTime": "00:22:00",
    "text": "well I mean it's either it's either a bug or it's a malicious client well no so if you have a malicious client that one malicious client will send their their invalid commit and then they can go off on their own box but the the service provider will see that everyone else ignores it and goes somewhere else so that that malicious client will um kind of fail and causing any disruption to the group because everybody else jumps over their commit and goes to the next valid one whereas if you had a delivery service which tried to you know say this is the correct Fork without having any kind of Quorum then um there's the potential that the delivery service could decide that one of the the malicious and valid Forks is the one that's going to force everyone to accept and then that breaks everyone so the fact that we allow forking allows the Quorum mechanism that you were talking about to happen in the background sort of as like a garbage control where we can see all this Fork was created and nobody ever used it that's probably trash I can delete it but it's not something that happens for actively where I say um I'm going to actually block messages being sent on everybody telling me which Fork is correct okay so in your opinion does the does the the the reaction of the of the Hub or you know of one of the providers depend on there being more uh more correct implementations than buggy implementations or more honest implementation than malicious implementations I mean it's really hard because I mean like I said the delivery service is not in a position to decide which commit is valid or not um so yeah it kind of does rely on there being more honest not bugy implementations than there being uh malicious implementations it's like a civil problem I guess is what it would be Eric"
  },
  {
    "startTime": "00:24:01",
    "text": "yeah I guess I'm still trying to follow exactly what happens here so as I understand it what you're saying is if there is an invalid commit which is accepted by some set of people but not by others then effectively you get a partition and you have some set of people are in box D and some set of people are in box C for instance yeah exactly you could have partitioned where everyone sort of branches off in different direction and they continue on their own okay and you you not have a specified mechanism for cleaning that PR up I mean the specified mechanism is that the service provider sees um you're echoing my own voice which is making it hard to talk thank you um the the specified mechanism is that if there is a fork where um half of the group goes up in One Direction half the group goes up in the other direction they there really isn't a proactive thing that you can do in that case to say who is right so what this would allow you to do is allow those two forks to kind of continue on their own happily um and the service provider can look into that later and see oh there was this weird group that forked like can I find anything common between the clients that went off in this fork and the clients that went off in this Fork like maybe all of the clients that took box D instead of box C like my own clients all took box c um so I know that box C is the correct box because my client is is perfect and then like everyone from Face from Facebook took Buck D um that's that's a bug that I could report to Facebook and say hey you're not validating commits properly so that's that's the mechanism is that somebody a person somebody notices um and figures out what's in common between the clients who took one fork versus the other and try to resolve it in a in a human way I would call it fairly underspecified that's not operationalizable yeah okay well um uh"
  },
  {
    "startTime": "00:26:03",
    "text": "so uh I guess I'd like if before before we move further down this chain I'd like to be persuaded it's not possible for a attacker to induce a situation where some set of people that are victims are part are part of one partition other people part of another partition because the current design is not allow that and what you're suggesting is allowing that so so it's fine if the attacker can so it's it's fine if the attacker can only partition themselves into into some partition but if the attacker can say that you and I are in one partition and that and that the attacker and Rowan are a different partition that is very bad I agree that that is very bad the only mechanism in MLS that actually would allow that to be possible is um if when you send a commit you do the thing where like half of the update path is uh invalid and then half of it is or basically up the update path as it goes up the ratchet tree um one half is different than the other half so people that are in a certain sub tree wouldn't be able to verify the commit and they would reject it and then everyone who is outside of that sub tree uh would accept it and so that's the only mechanism where you could U sort of separate people out in in a malicious way um but I I think that you need a different mechanism essentially to deal with commit messages that are invalid like that hey um I was mostly commenting on on ecker's comment um just saying that you know there with the current mechanism there are already things where the clients can say uh you know I I can come I it's challenging but you can the clients can come up with with commits where they can"
  },
  {
    "startTime": "00:28:00",
    "text": "where they could fool the the provider where they could fool The Hub U but the thing is that there is recourse if somebody detects that wait a minute like the Hub just said that that this commit which I think is is invalid is wrong which is through the external the external commit mechanism that it can basically rejoin the group and kick out you know kick out somebody that it thinks is um is misbehaving um but there's there's exactly one point of control for that so the the number of sort of code paths that that you have to follow you know you're you you have one remedy it's kind of like going to a judge and saying hey we just the two of us disagree right um so I you know I I think what what Brendan is proposing there's a kernel of of you know something potentially you know valuable interesting useful there um but I am also concerned with the with the general problem of having um you know sort of an explosion of different combinations of things that could happen and like not a single recourse to get everybody back on the same track that um particularly in the case of of a bug um right that's a good point I mean the branching is concerning um but in terms of actually like operationalizing this or like I guess the question is what you do when there is a bug uh and the current Mimi specification says that you know half of the group group get stuck and broken and the other half can"
  },
  {
    "startTime": "00:30:01",
    "text": "continue um versus more so with this is which is the two can kind of keep operating they would just get separated from each other and then someone in the background could go and figure out um what what the bug was but yeah I think we've we've talked about this so we understand how reading messages works so basically you jump from box to box to box as you kind of um read the messages in each one um so to to dig a little bit deeper on how access control works um I said last time that the the ID of each box is used to read and write messages to that specific box and you sort of combine that with the second point which is that the Box ID is going to be a sort of big random secret which is derived from the MLS key schedule and so only people who are actually members of the group in that specific eoch are going to be able to derive the Box ID so they're going to be the only ones that know this big random secret to be able to send requests to the server to ask about that specific group and so that's the uh the general principle about how only group members are allowed to participate in a specific keyock and this Al this is also nice because it um ACC kind of an access control mechanism and also a Spam control mechanism where if you're a spammer and you just want to send a bunch of random messages once you get removed from the group you don't actually know the next um box idid to send messages to so so you can maybe keep sending messages somewhere but the point is that nobody is going to to read them because they're all reading messages from a different box already and so actually we've kind of already um digested this a lot in a couple slides ago with the the read messages um but the way this helps with invalid commits is that if there are invalid commits that a client sends the shouldn't have sent uh that creates Forks those Forks are allowed to exist"
  },
  {
    "startTime": "00:32:02",
    "text": "but um honest correctly implemented clients will uh never actually pursue those Forks so they don't have to they don't have to process those messages they don't have to get stuck on um the the delivery service trying to force them to accept a commit which is invalid um so they can kind of keep continuing on and then the buggy clients go off in their own Fork um and the buggy clients will you know eventually figure out that something was wrong and deal with that themselves um to to E's point that this is not really operational operationalizable um I would argue that there's not really a way to make it operationalizable like if someone has a bug in their client uh the best that you can do is kind of allow that bug to happen gracefully and the the client fail out on its own um without without blocking and getting everyone else stuck but that's what helps withal commits is that you can allow Forks um and then in terms of spam deletion um whenever you have either a malicious client or a bugy client which is creating forks and he commits um they're going to create new boxes and those boxes are going to have messages um and that is something that the service provider is going to have to store and also something that the service provider is um not um going to know to delete because it's not going to see everyone read the messages and so it's kind of going to be holding on to it um waiting to see if people read these messages or not um but I guess in time sort of in the background you can say oh well this was a fork of this group nobody ever pursued that fork except like this one buggy client so I can just delete that fork um that's how it works is basically just uh tree Trine essentially when you have Forks of a group which are um which have have no one interested in reading them"
  },
  {
    "startTime": "00:34:01",
    "text": "and then uh to to get back to Rich's questions about how does this help with membership privacy so this picture is a diagram of essentially what a hub provider would see when it's running a group so on the left side we have all of the hub's own users interacting with the group and so the Hub can see which of its own users are interested in the group and it can see um which messages they're wanting to read and all of that but um when group membership or when handshake messages are encrypted in MLS the consequences that the Hub provider has no visibility into the service providers users so on the right side of the graph all the Hub sees is that you know um remote service provider one and two um seem to keep knowing the next um box ID to get messages from so that implies that they have users which are in this group um feel free to to tell me this is coming but I'm wondering how like I see kind of what you're thinking with the boxes once the group is running but when you're talking about pregroup stuff like fetching key packages and consent um that's all less clear how you hide things that uh so in this presentation actually didn't include any of the key package stuff um in terms of how a user would fetch a key package privately um but essentially the the core ID the core idea that I had was uh if I'm user a at my Hub provider um and I know that user one is at remote service provider one then what I would do is I would send uh an oblivious HTTP request through my Hub provider to rsp1 to get user one's key package uh and the purpose of of using oblivious HTTP is that um The Hub provider would not be able to see what I"
  },
  {
    "startTime": "00:36:00",
    "text": "requested from rsp1 and rsp1 would not be able to to find out who from Hub who from The Hub provider is requesting um the specific key package um except if they have like a a bearer token which is used to authenticate with within some kind of anonymity set okay than uh but yeah this is this is the core idea core idea if you think about what the Hub sees um it sees which of its own users are interested in a group and it sees which remote service providers are interested in a group um and also what this means is that certain tasks are kind of delegated to the the service provider which is local to a given user um so there was an example on the mailing list recently which is like if a user gets compromised I want to be able to remove them from all of the the groups that so that that compromised key Stop's being used um so if I'm the Hub provider I know which of my own users are in a group and so I can send a message to that group saying hey please remove user a because their key is compromised um but I would not necessarily be able to see anything about user one or user two from the remote service providers so when the the remote service provider finds out that someone is compromised they have to send that message on behalf of their user to the hub there's no way for the Hub to know sort of um which of the remote service providers users are in in the group or not which is intentional but it's just a consequence which is um that only the service provider which is local to a user knows which of their own users are in a group um and it's also worth pointing out that this is not required to use handshake message encryption um it's just an option like you can still use un encrypted handshake messages if that's something which you need for other reasons um but it's not required for the"
  },
  {
    "startTime": "00:38:01",
    "text": "core delivery service functionality which is what I was trying to achieve um Alissa can you talk a little bit about um whether or how you could sustain Alissa your audio is super faint okay I'll put it in the chat I don't know why that is so I'll wait for Melissa to to write her question but to to go to the next Point um there was some concern in this proposal because you are kind of following a directed graph that there's a lot of hops that you have to read all of box a before you can go to box B and then read all of box B before you can go to box c um and if you have little epochs or frequent epochs that can be a lot of round trips and it can make it really inefficient to to synchronize with the group so if a service provider is reasonably confident that a series of epochs will all be requested together because every other client has requested all of these epochs in the same order and so we have kind of that Quorum that you know it's that the we have the Quorum that the proper series of epochs in the group is box a then box B then box c um what you can do is you can provide them all together you can provide all the boxes together um which you could call a pallet if you will a series of boxes um but basically what happen is that uh someone would come to the the service provider they would say I would like to read the messages in box a and the service provider provides back box a um but it also provides back um boxes B and C because it's pretty sure those are next um which just the one caveat that you hash the the Box ID to prevent leaking the Box ID if uh the the user was removed in one of these EPO and we weren't able to see"
  },
  {
    "startTime": "00:40:05",
    "text": "that so I was wondering how this interacts with inner provider user blocking or any other user reputation based actions providers might need or want to take that is an issue um where um I can't see who is in this group as the Hub provider um so my visibility into the group is not you know user one from from rsp1 is being malicious I can only see I'm getting malicious traffic from rsp1 um this person is creating a bunch of forks they're sending a bunch of dumb messages nobody reads they're trying to waste my storage I don't like that um so the this is actually yes this is the point that I was talking about before where certain things get delegated down to a user's local service provider so if there is malicious action there's spam or something um the way I Envision that working is that the H provider initially reports that to the remote service provider and it says hey someone in this group is being malicious I can't see who it is but you can so you need to to figure it out and stop it so there would be this initial mechanism of uh basically sending reports to the remote service provider saying that a certain user I don't know which one is being malicious can you please fix this um and if there is sort of a pattern of you know every time I had someone from rsp1 to a group then I have a bunch of of like malicious wasteful traffic so I'm just going to stop federating with rsp1 I'm going to stop talking to rsp1 altogether um because um all of the traffic from them seems to be malicious and they don't have control over um the the abuse of their users so that's um how I would picture that working but yeah that's all I have that's on my slides are there any more questions"
  },
  {
    "startTime": "00:42:07",
    "text": "I I had some implications I wanted to bring up [Music] um uh and I'm uh you know I'm I'm quite pleased that you wrote this that you wrote this up right this is this is good um this is fertile ground for the kind of discussion so even if I you know disagree on the on on what we should do at the moment I I think that this is going to that this may cause us to have a kind of a breakthrough on on some of the Privacy requirements but um the three implications that uh I was typing up in the zul up here so of course you mentioned the the frequent epics where the the client needs to stop decrypting send a request wait for a wait for a network response uh get more information decrypt um you know you've partially addressed that but I don't know that you can I don't know that you can the Hub can can predict easily whether it's you know hasb hasb Prime hasb double Prime you know that there could be like quite a proliferation of those uh the uh the second thing is that um The Hub can't remove deleted users not even with an external proposal because they don't know the leaf index of their users if they're not privy to the commits and so then they don't know what the structure of the leaf uh you know which which Leaf nodes correspond to which even pseudonyms um and then the last thing is the um is external commits like under"
  },
  {
    "startTime": "00:44:02",
    "text": "all of the systems that the people in the design team were um were associated with there is the Hub has the group info and the um on a client that wants to to join it can it can ask the hub for help to do an external join um if that wasn't the case the Joiner could still send an ex proposal or it could go fetch a group info from uh from an existing member and do an external commit it's just that in a small group this means that uh a user that wants to join or rejoin that they can't take any action until another member um until another member helps them out okay those are good points um to to go through them so the first one you were talking about is that when there are sort of large proliferation of forks that this um approach of um trying to proactively provide the next Epoch doesn't really work because you don't know which sort of fork is actually the next one in the epoch um and that's true but also I would say that producing a lot of forks is more so a sign of abuse so um you know if there are a bunch of for then you would not be able to proactively provide the next box because you don't know which one is next um but the user would be able to request which box they want next and that would um sort of allow you to Traverse the the tree a little bit more efficiently so you're saying that if the if there's if there's only one um if only one commit is received for a particular Epic than the um then you consider that to be"
  },
  {
    "startTime": "00:46:02",
    "text": "uh you know business as usual and the server just sends stuff but like if I have two two commits that both arrive approximately the same time or if I have a large group and I have you know a handful like five of them that all kind of you know were sent you know were sent in like several were in Flight as um as another was um arrived at the Hub those don't rep represent an error state they're that's just sort of a normal busy network uh yeah I would say that's a a normal busy Network okay and also um I would just say that the the way that you think about these sort of ex ra boxes that are provided is a semantic more similar to like an HTTP to push kind of thing where I I am providing this data proactively but it's totally valid for you to never request it so if I provide the wrong box then you just kind of ignore this and you um send another request for what you actually do want um and so you've got the the usual trade-off which you have with things like http2 push which is you have to balance um wasting the client's memory by sending a bunch of things that they're never actually going to want um with the potential of saving this round trip um that's kind of dynamic I think that essentially always you would have just one or two commits um in an Epoch and you would have a really good sense of which box comes next um I think that essentially always you would have a good sense of which box comes next but there is sometimes that you um yeah there are sometimes that you would not and in that case you would not provide the push um and you would just let the user request which comes next"
  },
  {
    "startTime": "00:48:01",
    "text": "instead of try to waste their their memory um sending a bunch of junk um yeah and then for the The Hub deleting The Hub removing deleted users I think that you would actually probably need a new proposal type which says remove user with this credential hash or with this Identity or something that is signed by the the user's own local service provider because like you said you don't know the leaf index so you can't send just a normal external remove um but yeah anything else I mentioned the external commits but I mean you don't necessarily need to comment on all of these right it just is kind of more of like we we need to figure out what the requirements are I think that you can still do external commits with this um you just have the issue that when there is a fork so when the most recent Epoch is a fork um the server doesn't necessarily know which Epoch to let you externally join um but I mean in that case it is actually unclear what to do when there's a fork and there's multiple potential Epoch for you to join you kind of have Dealers Choice you could say the server lets me externally join the the one Epoch that it feels the most confident about or maybe it lets me externally join multiple epochs and like see how things go I don't really know um but external join is something that you can do with this it's not required that yes are we out of time to no we're not really out of time um I mean we do need to eventually uh get their own stuff on content but I think we have time to keep talking about this uh what I want to discuss is yeah like what do we do next with this set of ideas um in particular because like I don't think we have a clear consensus right now and in any case there aren't enough people here in the inter today to like you know formally make decisions as it were so um it sounds Richard do you"
  },
  {
    "startTime": "00:50:04",
    "text": "want to interject or do you want to go go ahead I I I was gonna go after you okay so I think there's two things here right one is um as Rowan was arguing there's like some new implied requirements that the working group probably needs to consider and you know either accept or reject um and then past that there's like solutions to those requirements which Brendan has been explaining to us so so what as a working group do we want to do with these things like um at a minimum we got to take all these ideas to like a wider audience for consideration uh but so with the requirements would those manifest say as changes to the architecture document or the protocol document I guess I guess we could open the que to thoughts on that like how to how to proceed with digesting these requirements yeah I mean ultimately these things like if we end up moving more in this direction we would make changes to the architecture and the protocol call document um but I I think we've got some rounds of discussion to do before we get there um I think you're spot on that you know we we've got some we we're getting some clearer thinking on some requirements that had been a little latent uh before um and getting those out and as as we were just discussing some some limitations that come along with this so like flushing out the tradeoffs uh that are involved with this proposal so yeah I think the what seems to me like the next step is for uh Brendon maybe with some some help from Rowan to kind of put together a concise description of the tradeoffs um and you as as a guide to kind of the working group in in figuring out which way we want to go with us I guess it's it would be good like taking the good proposal as it is and understanding it trade-offs better but it maybe there's some you know that that could be a guide to also how we might adapt this um if we were going to say um take some parts of it um and and use those and leave other parts"
  },
  {
    "startTime": "00:52:01",
    "text": "side yeah um I was going to say um I think that the the Privacy uh the P like getting privacy threat models um outlined and some of these additional requirements documented I think that that that's a good a good way to get us moving um toward you know like it it may be we come up with okay like well you know this isn't really great over here and this isn't great over there but you know we think that this one is better based on the requirements that we need to satisfy and it may also be that in some cases that we have one we may end up with you know one Hub chooses a particular tradeoff over a different Hub provider and that we have more than one way of do of doing things but the clients have exactly one way to do things and know what they need to do at all times I think that would also be an acceptable solution just pausing to let anybody else jump into the queue who wants to um okay so it sounds like the path forward here is for uh Brendan and or Rowan to continue to flesh out the ideas on the list with an eye towards uh converging towards a proposal for like either excuse me a new draft um discussing these things or figuring out like how to incorporate it into existing drafts manifesting that perhaps as a set of uh PLL requests which we can then discuss in the working group and uh at Future interms Richard anything to add yeah yeah I think maybe an issue on the on the architecture repo would be a good place to kind of memorialize this or or on the mailing list um do we have we have a couple seconds more for some some discussion on the proposal Tim yes"
  },
  {
    "startTime": "00:54:01",
    "text": "absolutely okay yeah so so Brendon I just had like a really prosaic question um I kind of get how in a pure poll model where the clients are asking for like give me this box how this works um is there any notion of fan out here like proactively pushing stuff down to interested clients and I guess if we're aiming for that um I'm not does not clear to me how that works although I guess pushing to clients isn't really what this this working group is about but um I guess server to server service provider to service provider is is even still interesting because like how does the how does the Hub say keep track of which service providers are involved in a given in a given box um so the Hub knows which service providers need to know when there's new messages box um so in terms of which service providers and which users are interested in a given box I think that you would have a kind of Mimi level concept of subscribing to a given box where um if you know the Box ID then you can I guess subscribe to push requests about new messages to that given box um so that's how you would do push as you would say I know this box ID um please proactively send me new messages to this box as they get sent um and as they get sequenced by The Hub um and then once you send to commit and their subsequent Epoch um you would instead have to switch to the um the the http2 push kind of idea that I have on the current slide which is where I am providing you proactively what I think the next Epoch is going to be um just with uh like the box that he hashed in case you are not actually in this group then I I'm not leaking the Box ID so you can't send messages to to aox that you're not in the group"
  },
  {
    "startTime": "00:56:03",
    "text": "um justes that make sense so it sounds like at at one level you're just kind of indirecting the pull model the Subscribe model through the the service provider um is that kind of the idea that a a client connected to a service provider and say hey I'm interested in this box and service proor and say dear Hub please tell me about this box tripping okay yeah it would be good to kind of get some of these I think you might have muted prematurely Richard your thought got cut off oh sorry about that dude um just just thinking as we flush this out like understanding some of this kind of basic physics um would be good good thing um Brendan in in your mind if we've got the sort of the normal case where we've got three clients that all send a commit uh you know from their from their perspective a valid commit um and if the other two commits didn't exist everybody else and all the other members would agree that it was a valid commit and so the only thing that would be making one of you know the two of these to be invalid commits is that they arrive later um how do you how do you see communicating that using your model I don't understand how that could happen that you would have a commit which is invalidated by a commit that comes later like the the normal mechanic in MLS as you say the first valid commit is the the canonical one right so nobody knows what the first"
  },
  {
    "startTime": "00:58:02",
    "text": "one is because the first one is you know which the first one that arrives at the Hub right you don't know that when you send it you don't know that if somebody else has already has one in flight to the hub and even if I have two that that are in flight at the same time I don't necessarily know which one of them is going to arrive first I mean that's the the core kind of service that the Hub delivery service is providing is that it's sequencing all of the messages that get sent in a linear order um at least within a specific box so if I tend to commit I generally would not know that it's the commit that gets accepted I would send it and then I would like continue reading from the box and see which commit came first and if it's mine that's lucky but it it might not be okay so in other words the order of the the order of a commit that arrived in the Box tells you that it arrived that that that tells you oh I'm going I need to go in this particular direction I need to roll back the commit that I made and start the new one okay yeah that that's that sounds that sounds reasonable I think that's normal for MLS is that whenever you produce a commit it's kind of provisional and then you send it to the server and see what happens yeah I I agree with that uh it it was just more like the what's the feedback mechanism and the feedback mechanism is that the that the commit arrives that you read the commit from the box okay we're at the end of the first hour um which is fine because we've just been eating into time that was reserved for um scrubbing bugs and PRS on the repository so it's perfectly okay for us to been you know using that time instead for this which is more valuable but I would like to move on to um uh to Rowan's updates on content format stuff just to make sure we have time to get"
  },
  {
    "startTime": "01:00:00",
    "text": "through that um and uh we can return to this topic should we have time after discussing content format business um or yeah so okay Ron are you ready um we can move on to your your deck sure where's your deck I can drive it for you or you can uh request slide thing yeah go ahead um okay so um we had a bunch of a bunch of you know we had a handful of things that we wanted to talk about but the biggest issue from the last ITF was um whether we use seore or TS presentation language as the concrete syntax so we had a roughly 5050 uh split of the group last time uh when we were in Brisbane and then it was like okay I propose to go off and write a new version of the draft that has both concrete syntaxes so right now if you go and look at the 03 version of the draft you'll see that there is um EXA all the uh the the structs in the beginning are in TLS presentation language the examples are in TLS presentation language and then there's an there's an appendix that has the um the cddl um data language format and all of the examples in cabore and then there's also in the GitHub directory there are there's a whole directory full of example messages that were actually you know are in cabore and that validate to the to the cddl that's in the draft um so I'm just really curious first of all um has anybody read the new version of the document"
  },
  {
    "startTime": "01:02:04",
    "text": "skimmed it yes okay uh so uh I I'll sort of give a little bit of a little bit of uh of you know I I will I will provide my framing on this but I think the best way for people to get an idea of this is to look at some of the messages side by side or to like look at look at what the what's in the document at least skim it it's not you know it hasn't changed that much and this the differences between the TLs and the cabore it like it you know it's it's not it's not a tremendous amount of work to go to go and look at this it's not a huge I don't think that it's a huge investment of time for somebody who's already read the document U so we've got um I'm just going to kind of like go over some general some general points here from this slide so in the TLs presentation language this was originally developed for use in TLS um wasn't really intended as a generic tool but it has since been used for MLS um it is not a formal schema or data model language it just specifies the structs and so consequently the extensibility is accomplished largely using um using like a uh a typ or enom which is then um then there is like a select uh statement which says if the you know if this thing which I'm selecting on is has this particular value then the following contents underneath are are Incorporated uh and so it's not like um it's not like we have sort of a formal language with which to to with which to Define things this stuff is done largely"
  },
  {
    "startTime": "01:04:01",
    "text": "manually um likewise there's not a lot of sort of standard tooling for decoding debugging um that said the the the format itself is fairly simple if you want to roll your own you know debugging library that pretty prints uh or annotates a a TS message uh but there's not like a standard debugging format that I know of um all right um now the convenience here is that this is already used for MLS and currently you know notionally we're using uh TLS presentation language for the Mimi protocol because they we wanted to incorporate or borrow uh certain structs that we use in MLS a couple of other little points on TLS um so right now if you have uh vectors um vectors have a variable length so if I've got a vector that's 63 has 63 octets or less I can represent that using a single octet if I've got um if I've got less than um let's see what is it it's um I think 4,95 then um or 16 sorry 16,000 you know 16k minus one then that's represented using two octets and a larger value is represented with four octets um so this requires bit shifting because the upper two bits were were used as the effectively to decide on the length of the length uh and this is not super straightforward in j JavaScript for example but uh Tim said in Brisbane he said that they did an implementation and"
  },
  {
    "startTime": "01:06:01",
    "text": "that this works so um it's possible but it's not necessarily like the the most natural thing for a for for folks um and then um let's see also one other little uh detail is that the lengths of vectors vectors are the lengths of vectors are always given in number of octets and instead of the number of units of the thing that is inside the vector okay uh on the seore side so cabore is a general purpose format for carrying binary data and its historical motivation was for a binary format that is that was Compact and could work well on um on iot devices for example um but since then you know it has has a few other uses uh it's being used in um in kose which is the um uh like ass signing format similar to Jose that you could use to carry for example the the moral equivalent of uh of uh Json web tokens uh called cwts uh there is a formal data definition language called cddl which was designed to be able to use to to be used for both um cabore and Jason um and it it has functionality comparable to what you would get in largely comparable to what you would get in Jason schema for the you know at the sort of 90% um level in terms of tooling it um the initial tooling was largely written by carsten and Ruby um but there are tools available in you"
  },
  {
    "startTime": "01:08:00",
    "text": "know handfuls of Tools around to verify the syntax of a cddl um schema to verify the basic structure of a Cabo document that you don't have a schema for and finally to validate an instance of a Cabo document using a cddl schema um Cort can be converted into a variety of formats to make it easier to read so it can be converted into Json um that's a lossy conversion it can and it can be converted round tripped into uh a sort of um diagnostic notation and extended diagnostic notation and then finally there's also a pretty printed uh hex format which is um which has been adopted by the by the by tools and so if you go to uh the cabore playground se.me when you if you type in a document you will see the corresponding hex values um in this pretty printed format um the I would say that the pretty printed hex format is about as easy to read as the annotated TLS presentation language formats that I did for these examples and the extended diagnostic notation is actually way easier to read uh and let's see finally um there is a deterministic so cabore has a couple of different variations or a couple of different ways that you could convey the same information but if you use deterministic seore or come up with another profile like deterministic seore you can ensure that trivially ensure that there's exactly one representation of every instance document um a canonical way of representing it and let's see there's no bit shifting but small length items are stuffed together with a with a type code so there is uh"
  },
  {
    "startTime": "01:10:02",
    "text": "some bit masking that's necessary or a jump table to implement Cort and then um all of the lengths like instead of having Vector lengths and octets item lengths are in units [Music] um okay next slide please oh actually were there any questions about that overview slide or comments about that overview slide okay moving along okay um so I took the I took the the TLs structs and a cddl uh schema for uh for the content format and I split it up into two halves basically the half that had that that covers the nonbody part of the message and then the part that covers the bodies uh so if you look on the left hand side here the format of a message is there is an optional replaces message there's a topic ID um a value for expires uh an optional uh in uh reply to info a list a vector of uh last scen messages um a uh a vector of extensions and then the body and then in reply to consists of three values down a little bit lower um and then the extensions are basically just defined as this is a I would call this as a poor man's hashmap here now if you look over on the other side we've got same kind kind of content here but uh this is slightly more"
  },
  {
    "startTime": "01:12:00",
    "text": "expressive in terms of the um uh the typing so there are some built-in types so a b string is a binary is a binary string or you know a byes object uh we have um the concept of a null and so you can have a null or something um but this can be written pretty um um this can be written pretty quickly and it's relatively compact um it has the you know no great um nothing great here motivating one thing one one choice over over the other but the um the sort of the language expressiveness is is a little bit greater in cddl right next slide please so before we move on I just wanted to interject you you said the phrase a second ago like a a poor man's hashmap which made me think so we've been using uh T presentation language over in the distributed aggregation protocol and mostly it's been fine but um it is occasionally frustrating it is occasionally a point of friction that you don't have like a nice handy hashmap type thing there but you do you end up having to come up with these sort of bespoke constructions each time which is a bit of a hassle U I wanted to just get that like implementation experience known note on the record yeah okay um so this section here describes a little bit the uh this um this slide shows for the body formats uh the the comparable U the comp comparable struct uh structs and schema um so without uh without going you know into super gory detail I want to point out two aspects here so the extensibility model"
  },
  {
    "startTime": "01:14:02",
    "text": "is that um we have if you go down toward the bottom of the left column here the last struct called nestable part it has um it has a disposition language part index and cardinality and then it has depending on the cardinality it has uh it has different components that are included in the stru um so this um this is not necessarily the most like natural way to go and express this uh by comparison if we look up at the upper rightand uh the the up the right hand column on the the uh the first production there nested part equals a map of uh disposition language part index and then one of null part multi-art external part or multi-art um so it's a little bit clear to a reader what's going on um but the in terms of what actually is allowed um what actually validates in the schema it ends up being something that that is ident you know functionally identical to what is on the left hand side here now the last thing that I wanted to point out here was for the extensibility of things like enom um so in the bottom right hand corner there is I have this thing that says base dispose equals and then there's a list of of enums and this matches the list of enums a little bit over to the left for disposition um and then I have something"
  },
  {
    "startTime": "01:16:01",
    "text": "that says unknown dispose is basically this this value from 9 to 255 then if you go all the way up to the the the top right uh under nested part it says disposition is base dispose or dollar x uh extended or extension dispositions slash unknown dis or unknown dispositions and so there's a sort of a priority here that's um that if you come up with a future extension disposition it takes it takes precedence over an unknown disposition so if I come up with a value 10 later on and I have a def defined that 10 is the Fubar or smell a vision disposition then the then that disposition will be noted in the SCH in the schema and when validating and when doing Diagnostics over the generic this was a you know this is a valid range for a disposition but I don't know what it means but it's an unknown one so that's kind of a nice little feature but either way we can do you know we can express everything that we want in both of these syntaxes all right um hey yeah go ahead hey uh so I wanted to mention there a bit of a sharp edge here with the TLs stuff that I think this illustrates nicely um so um this will not this this uh uh uh um uh production on the left will not act will not correctly parse unknown um is not extensible for unknown um cardinality values because you don't"
  },
  {
    "startTime": "01:18:00",
    "text": "know how to parse that to length of them so so they require so typically the way you deal with that is you put a length field right before the select that tells you how long the thing after it is um because otherwise what happens is if you receive a value you don't recognize then you don't have to skip over it um and and so like it's totally fixable but it's just it's just a sharp edge here which I think I think CW where actually handles better um well um I I agree with you I think in the case of the cardinality the cardinality has an ending value of 255 as well no I think what eer was saying was that if you wanted to have stuff you be able to tell where the end of that nest part thing is and handle unknown cardinality values you need to know how big the stuff in the struct is um so like if you look at the you know the extension struct in MLS or CLS client hello right like each extension has a type which tells you what it is and then a length that tells you how long the data are yeah indeed yeah in in this case the Cardinal like it wasn't intended to for cardinality to be something you would you would uh that you would ever um pass over an unknown cardinality so that's why I didn't do it in this particular case but yeah that that is like Eker said it is a bit of a sharp edge e are you still in q okay um moving on so I I took three examples from the"
  },
  {
    "startTime": "01:20:03",
    "text": "document all of the examples are in the document and also in the GitHub in the GitHub in Standalone files and you're welcome to play along play around with the um with validating and doing stuff like that for the cabore ones if you're not familiar with it um so in TLS presentation language uh on the left side we have the original message example uh and so you know you're just sort of like taking the next the next element and just concatenating it boom boom boom boom boom down the down the struct until you get to the the bottom um the only place places where you have lengths are for the the length of the content type and the length of the content in this particular example um on the cabore side it's uh this is the extended diagnostic format and so if it looks like Jason that's because that's uh that was the idea that it looked a little bit like Jason except that you've got uh single qued literals that are binary that become binary strings um and so here we have um a message which is pretty easy to read um things separated with slashes are comments and they're also End of Line uh hash uh terminated uh or hash um hash till the end of the line U comments as well I think that if a develop saw a you know a debug of the thing on the right I think it's going to be a little bit easier for them"
  },
  {
    "startTime": "01:22:00",
    "text": "to see what's going on um whether that's more important than than you know reusing a library that we also potentially use with uh with Mimi protocol or not that's that that is I think a very interesting debate in question um next slide please okay this is a more complicated example so this is the edit message so in this one we have the you're editing a message which was itself a reply so um the so we're replacing a message so we need to have an ID in the top line on the right hand side here for the message being replaced um topic ID and expires are zero and then we're replying to the original message so we have that message ID um and then I specifically wanted to have two last scene uh messages so that we would have a merge and so here we've got two um the last scen messages are the reaction message and the mention message and then we have the straightforward body type here where we're just correcting the previous error and then this the the um edn format on the right hand side there this shows the end of line uh comment type just same encoding and content format and protocol yeah noted maybe we will maybe we won't okay next uh next slide okay I think this is the last slide I've got here yeah so this is an an example"
  },
  {
    "startTime": "01:24:00",
    "text": "showing um uh some external content so this is somebody uploads a big file and then basically provides a pointer to this and um as intended on the previous on the previous uh draft draft uh 02 um there is now a hash of the of the content um that is available in the uh external uh external content format here okay any comments or reactions on this does anyone feel differently about which syntax we should use uh go ahead Tim W you thanks so I guess both of these I I think will work just fine in a vacuum I almost I think I might lean a bit towards seore in that like the tooling the tooling is better and it might be a little less surprising and less alienating to people trying to debug stuff in this environment but to me one of the main concerns here is consistency in which encoding is used at like different you know layers of the stack so for instance Richard in the chat was bringing up um uh the possibility of using cabore in M protocol for the provider to provider interactions and that makes sense but like the precedent that seems to matter here is that we're already I was going to say we're stuck with but that's not true we enjoy the opportunity to use MLS which already is committed to using TLS presentation language and that to me is like a pretty strong reason to use the same encoding in um uh for Content format and orbb protocol um okay so besides that statement a question which maybe is during the pot does anyone Recall why um MLS doesn't use"
  },
  {
    "startTime": "01:26:03",
    "text": "cabore um I think part of it was because we were B leaning on the experience from TLS and TLS uses TLS presentation language um the other thing is that the TLs presentation language is very focused on unique representation so if you encode the same thing with TLS presentation language there is no variability you always get the same thing which when you're dealing with inputs to cry cryptographic stuff matters a lot and I I think I seem to recall that cabore has some flexibility how you express things which is undesirable you're making a rry protocol but doesn't matter when you're talking about things like application yeah I'm just going to point out that deterministic cabore is the is is a trivial way to get a single canonical representation of of cabor and so that's what you would do and that's what that's what K does for for uh cryptographic purposes yeah um so I I was actually in in Q to say like I'm this seems like it's making a pretty good case for just using C throughout um I agree that using um the same encodings up and down the stack makes sense but I think that there's a pretty clean DeMark between the MLS layer and the mimer which makes that a sensible place to change um right if you think about how in practice this is going to get built like people are going to have an MLs library and they're going to have like a TLS encoder linked into that but probably not visible externally like maybe it is as a Sher library or something but um you know like with the MOs libraries I I've used like the MLS en the TLs encoding is not visible outside the library um so like there's not necessarily much savings to to reusing that encoding elsewhere in the stack and so given the kind of developer"
  },
  {
    "startTime": "01:28:02",
    "text": "experience benefits that that Rowan is pointing out here like it seems sensible to use seor for the stuff that um is less sensitive to some of the the strict crypto requirements that MLS has so I I think I'm still like leaning probably more towards Tim in terms of consistency um I guess I'm not like super persuaded by um this tooling argument um my experience has been I mean the toing does help but my experience has been you actually write spe custom tooling to like handle the MLS Cas cases anyway if you really wanted to do debugging um like certainly if you like look at like you know what like things like TCP D stuff like that people write write or or or you know I guess wire Shar these days people write things like actually do a good job of this and like this thing on the right like is kind of like I I agree much better than I left but it's still pretty impenetrable um and so um so I I think you know I'm not going to like uh you know if we're humming I'm going to vote hum for TLs but if we're like you know I'm not GNA I'm not going to say much more about it if we hum and it goes to sew War so um oh I forgot to mention the um analogy that came to mind which is like HT TPS is like HTTP on top of TLS HTTP is encoding is like totally different than tls's encoding even the binary ones in the more recent versions in fact if you're doing H3 like you have quick encoding TLS encoding and https binary encoding so three different things in one St I think we can do better here but there's some precent for Chang this stuff up yeah I'm I'm just going to give my you know so I uh I was like you know 55% for cabore 45% for TLS presentation language at Brisbane before I went and did this exercise and now I'm probably"
  },
  {
    "startTime": "01:30:02",
    "text": "more like 65% for cabore but um you know I'm also not going to you know I I think the most important thing is for us to make um for us to make a a reasonable decision given what we've got in front of us uh I'm you know I'm going to implement it either way right uh I I do like the tooling um and I do see I do see the arguments on both sides yeah okay so putting on my chair hat I guess so first the most important thing is that I don't think we can make a decision here there's not enough people in this particular meeting so we'll have to pursue this like on the list and then I think we'll be to consider um when how we arrive at a decision here like whether we can sort of do this in the contestant call the list or we we would want to do it at a plenary um otherwise I don't know I'm reading here like a slightly in favor of seore and it doesn't sound like it's a deal breaker even for the the TLs presentation language likers um so my guess is that's how we would go um okay so what are we G to do next I think the chairs are going to discuss how we want sorry it's not like we need a decision here um I think but chairs are going to discuss like what Forum we want to make make this decision in um either that'll either be a consensus call on the list soon or worst case it'll wait until Vancouver I mean is anything R would you say anything is blocked on this decision you're muted just if people wanted to start implementing you know having a having a single concrete syntax would would be useful but uh there's there's nothing uh yeah there there's we're not blocked"
  },
  {
    "startTime": "01:32:01",
    "text": "other okay so then I think the end the action is on me to talk to Alyssa about how we want to handle this and then I once we come to a figure that out R we'll probably come and talk to you about it okay um and then um if it's okay I would like to spend five minutes looking at uh one issue on the on the GitHub for C yep sounds good bug scrub is what we were going to do next anyway um do you want to share screen um if you don't yeah I do not hang on so one sec just finding the window this one is ISS is on content Mimi content it's Issue Number 15 do we need a stronger hash for in reply to you external content hash and the message ID so basically you know I was kind of going over the so cnsa 2 2.0 has the algorithms that the US government is recom amending for uh you know in going forward and Shaw 256 is no longer on that list um if they've come to this conclusion there may be other people who have come to a similar conclusion and so even if it's not being used in a you know sort of a strong cryptographic way um do we uh we we already we can we can make the def so we've got three places where we're using a hash right so both in reply to and exter for external"
  },
  {
    "startTime": "01:34:02",
    "text": "content the hash of the external content and the hash of the replied to message um there is a there's a field that says which hash algorithm are you using and then there's the hash that according to that particular length um so we could make the we could leave the default shot to 56 or we could make the default be shaw 384 um so that's one question and then and I you know I can't imagine that we would want to do that differently for those two for in reply to an external content then the second issue is the message ID So currently the message IDs we wanted to have uh be the you know a hash of the cipher text of the encrypted message um and we really wanted to have a fix length field so that all the messages all the message links are the same and so if somebody replies to a message later you know even if the hash changes that the the length is the same so uh we've got a couple of different choices we could do you know keep it Shaw 256 we could use 384 but shw 384 but we could make it still 32 octets long we could make it the entire Shaw 384 hash or we could make it a variable length which I I really don't want to do that last one so I was just curious if anybody had any any feelings on this so I mean this is the first I'd heard that that NSA recommended not using shot 256 for anything um like the world runs on shot 256 so like that's a little concerning um at least from a compatibility perspective um uh I don't think we should truncate uh I don't know what the rationale is but unless the rationale is they have an analytic weakness in top 256 that I don't think"
  },
  {
    "startTime": "01:36:02",
    "text": "we should just truncate shot 384 because it seems like that puts you back where you started um um so um I guess I understand what the rale was why people think that 256 bit hash is not strong enough for these kinds of purposes um and if it's some kind of Grover's algorithm thing then that's one thing if it's like um uh uh Anyway Richard it seems like you're on line yeah just note that cnsa 2.0 does not deprecate shot 256 in in fact it recommends it for some of the hash based signature stuff um so it's not like that's going away and like I think that it was this would matter here if like we were relying on the full entropy of the hash like I don't think if there's like what's the consequence of a hash the risk with the quantum computer right the reason you double the symetric key lights is like it makes finding collisions harder um which was what Grover's algorith about um it doesn't seem like there's a security failure here um at best at worst there's a little bit of confusion um and like the the Grover's algorithm speed up as quadratic so we be reducing to like a 128bit probability of collision so like this is not seeming super fatal to me so I would probably go with keep it CH 56 here eer are you still in Q okay Richard just went um okay I'm inclined to agree with the two previous speakers or rather to like defer to their Superior expertise but on top of that uh I'm concerned about the performance cost of going to shot three and so if we did do this I think we'd want to consider one of the reduced round things like I think turbo Shake is the the one to consider but um that's only if we did decide to go shot three by default I just want to be clear that shot 384 is not shot oh I'm sorry 34 that's just shot"
  },
  {
    "startTime": "01:38:02",
    "text": "two 384 right um I think unless I'm like really tired e you're right I'm I got mixed up okay ignore me that was a nonse um is there somebody else that we is there another uh ATF working group or or irtf research group that we should this question to or do we feel like we can just say Let's ignore this for now I would say Let's ignore it until one of the um there's there's a few PQ wise messaging folks hanging around so I would say Let's ignore it until they they come around okay um I'm not hearing any anybody saying we shouldn't ignore this that so uh yeah I will leave this leave this hibernating dormant for now thank you very much uh I I yield to the next presentation um well sorry one last thing Ro do you want to make an make a note in this issue about what we just discussed if only so that's somebody who's you know watching this repository can get F into answering yes I am doing that as we speak great thank you okay um so next thing on the agenda with the remaining 20 minutes that we have is to do more like more scrubbing of open uh items on GitHub um and I've got some tabs queued up here to that end uh so I think possibly we could get through one or two things uh before that just want to check was did anybody want to return to anything to say on the Privacy preserving DS topic okay guess not so um we have here R I think this one will be probably for you uh this is the"
  },
  {
    "startTime": "01:40:00",
    "text": "sole open pole request on Mimi content um somebody would uh wanted to add a read me sometime last summer you have thoughts on what to do with this um I um so I if I convert to if I convert from M Mark to Crown then I will use Martin Tom U Martin Thompson's uh uh read me that has the links to the GitHub pages I may still get around to making GitHub Pages work for M Mark in which case if I do that then I'll update the readme um but I I didn't really I didn't really want to have sort of static readme content around that would become stale I think I agree I mean this just seems to repeat the abstract from the document and there's no point to keeping it up to date in two places um so in that case the action here seems to me to be to explain like know what you just explained about your plans to clean up the read me and then presumably close this PR without merging it that sound right yeah I can do that yeah and and uh you know I don't think the the other issues on the the other issues on content are really worth discussing compared to probably what's on uh the protocol or architecture documents at this point all right sounds good let me just tag this as reviewed and then we'll move on to there we go and we'll move on to protocol um sorry let me just double check first off for architecture there's nothing that we haven't reviewed there just yeah it's about metadata leakage which we talked about last time I apologize for jumping between tabs so much um all right so we've got this open poll request on Mimi protocol uh Rowan you're the author though I notice it is a draft um anything you want to say about this I I think that we want to get the"
  },
  {
    "startTime": "01:42:03",
    "text": "you know sort of the core functionality um that this was more so people would could see that that this was one of this was one of the functionalities that um is included as something that would be required for dma that's something that's used by a lot of instant messaging systems it's something that does need to to cross go across provider boundaries and so I just wanted there to be an existence proof that this was possible but it's not like there is a you know there is no burning reason to go and incorporate this um into the uh into the document unless other people are you know other people are asking for it so is there a is there a requirement that needs to be discussed or explored here I think there is a requirement but I think that coming up with the coming up with in general the Privacy requirements um you know the Privacy threat model um and some of these other requirements that are that are more systemwide I think that that is going to be very valuable for us to have those first because it may motivate slight changes in the approach that you would take for dealing with for example um downloaded messages or attachments like this okay well well in that case it sounds like it's useful to keep this around as a draft because as you say it illustrates something potentially useful and you know adds Nuance to other ongoing discussions about requirements Richard I mean this does seem like functionality we will want in the protocol um so I mean let me ask the reverse question like there a reason to hold this and not merge it as a you know an initial take at it to have it in the document I mean I mind uh I think it's I think it's pretty pretty simple I just don't want to spend a lot of time you know if somebody wants to argue about"
  },
  {
    "startTime": "01:44:01",
    "text": "some particular point of this that it wouldn't be my highest priority in in Mimi well the Richard's point I have side concern about you know keeping PRS open or um keeping poll requests open indefinitely because they'll inevitably go stale um or fail to merge so if this is like our best understanding if if this is something that we know Mimi wants and this is our best current understanding of how to do it um then perhaps we should take the change just in in the for the sake of moving forward acknowledging that we can always revisit it and change it later so I guess the thing here perhaps is for the document reviewers to review the change and discuss it okay I think that's all we got on that issue so let's move on to uh this is yeah open issues on the protocol document that we have not previously reviewed um so let's see if we can clear out some Deadwood in the last 50 minutes here uh all right so this one is about preparing a document for i18 which whether we like it or not ef18 already happened um is any of this still relevant Rowan I hate to put you on the spot I guess you would Richard are here to speak as like authors or editors of the document even though we don't have Conrad or Travis today yeah I think this is all sale all right so in that case whoops I can't"
  },
  {
    "startTime": "01:46:01",
    "text": "do type all right so I'm going to close this and uh it can always be reopened should there turn out that there was something important here good we're making progress I'm helping so this one was written up by Conrad maybe we should skip it since Conor's not here to speak to it unless or should Rowan do have thoughts on this seems to be fixed by a PR that's been merged oh yeah this one this one can be closed this is done good stuff okay tracking arbitrary state uh which I suppose can mean room name and the like do we want to support this asks is that Matthew or is that Travis that's Travis right um okay I think maybe we should skip this one and we could review it at some point when Travis is in the room I'm scanning for stuff that's"
  },
  {
    "startTime": "01:48:02",
    "text": "been there we go okay hn8 asks do we need xmpp compatibility yeah we can definitely we can definitely discuss this in detail in the next 12 minutes and close it down fair enough I mean my answer is no so that's short yeah there's a lot here I think 's right we don't have time to dissect this today um okay [Music] is versioning too Saucy for us to get into today that seems like something where I mean if people have ideas and it seems like we've got some recent you know experience of this Acme versioning and uh things like that um I know Tim you and your colleagues at isrg have done a lot of interaction with with AC and versioning there like any experiences that you've heard about there or or from the D the DAP DPP Evolution so initially in Dap in particular we did do sort of explicit we I think we thought about doing explicit inband versioning of the protocol uh and we were we were talked out of it uh yeah on the premise that the version negotiation is is too complicated and risky and they rather if you're just changing the version then you should just sort of expose the the API from two different places we did end up do entangling protocol version into um into"
  },
  {
    "startTime": "01:50:02",
    "text": "aads for hpk encryption um which ends up being useful because um it ends up being an implicit check that like yeah you're running the same version you know your server is running the same version as a client um you'll fail to decrypt because you're using a different label in an aad if you're not um so I like that but I don't love the idea of requiring implementation of a server to support multiple different drafts at the same time Eric yeah I mean this this seems like a much more complicated problem frankly than um uh than Acme or anything else I've heard um in that with have potential situation where we have multiple entities and we have so we have a real diversity of versions and so for in I think it might be useful to discuss like do we for instance think that it h it should be the case that if we have a if we The Hub is a and then we have B and C that B and C have to speak the same version of The Hub um um uh at least for at least for a given conversation and um and what happens you know um and what H and uh you know what happens if you if if the Hub wants to migrate um you know etc etc etc right um for instance do convers do all the conversations have to go at the same time or because you have like some conversations that are one on one to the other I don't know any any of questions but those seem like much more difficult questions and these are much more long running so it seems like trying to put together some kind of um you know theory about that is probably helpful um I'm definitely talking my way into believing that we're never going to have a version rev at this moment um but it's probably we're thinking about what we think want it be possible"
  },
  {
    "startTime": "01:52:02",
    "text": "well I guess we close that topic yeah yeah I guess no one else has anything to add to that um go ahead I mean agree about the the problem of do all the Hub do do all the hubs sorry do all the providers that are participating in a room need to all support exactly the same version right so that's that's a that's a good requirements you know that's a good requirements question the other thing I was that Eric's comments made me reminded me of was that um if you look at say Matrix I think they actually have two layers of versioning um one on the kind of exchange protocol and one on the the room itself um which you know clearly there's there's kind of different Notions of support there um you can Envision you know having one everyone have to support the room version but maybe you support different transport versions underneath that um might be a useful concept to import"
  },
  {
    "startTime": "01:54:00",
    "text": "okay seems like that's all we got on that issue um I think well let's see if we can knock out one more um this is a placeholder to fix like you know to fix way later it's it's kind of like this is like before working group last call go do this it's not there's no okay as in sync up the artwork with like whatever wherever these um messages and interactions end up converging toward yeah yeah it's just a bunch of make work uh but there's no substan of change Co thanks [Music] thank you um okay Richard here's one of yours so I think yes so this is a discussion seems to be still ongoing my only observation here immediately is that I think we have exactly the same issue on the architecture doent like do we need both yeah I think we can probably close this one in favor of the uh the architecture one I think I just threw that as in a quick sub to make sure that we track that but if we fix the architecture one then we'll flow it through the protocol in more precise ways"
  },
  {
    "startTime": "01:56:04",
    "text": "thanks um okay we have just a few minutes left and I think just at a glance everything else in here seems like big questions or primarily stuff um that it'd be nice to have Travis in the room to speak to so I'm inclined to give everybody four minutes back or you know open the floor one last time if there's anything else anybody wants to quickly chat about all right go ahead Richard no I was just gonna say let's close all right then the last thing I will note is so thanks everybody for participating today um let's see the few actions came out of today's discussion uh will the chairs will c will um provide an update about like what we want to do about cabore versus TLS presentation language um I think we're going to expect to hear more from Brendan and Rowan about um the Privacy preserving delivery service discussion and otherwise we'll see everybody in two weeks on May whatever that works out to um for another interim we're going to be back on Discovery go ahead Ron 23rd thank you on May 23rd we'll be check data tracker for accurate and up-to-date information on when the next interim is and we'll uh see you all then thanks everybody thanks everybody"
  }
]
