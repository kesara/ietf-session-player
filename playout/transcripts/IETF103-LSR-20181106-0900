[
  {
    "startTime": "00:00:04",
    "text": "Paige I added a link to it as well so the main LS are working a page has a has a separate link to the status the highlights at least you you all might think this is a rather parochial view of this of the highlights but I think it\u0027s because I\u0027ve worked on in some capacity I\u0027ve worked or been the document shepherd for these documents I think one thing is we\u0027ve had the yang models we\u0027re gonna go forward with them both were pretty close on OSPF actually I\u0027m just I realized we needed one more IPR call and we\u0027re I\u0027m just rounding up all the contributors the officers are all readily we\u0027ve been just doing the design meetings and is is coming shortly we got some yang doctor comments and we had admission on Oh Stefan\u0027s working on those the mpls data plane s our documents are pretty much all working group last called and you know though or on or waiting on Alvaro so weird some other those are multi-year documents that as Shepherd up to them I\u0027m glad to see those go by the other documents that I think are really interesting we have presentations so I\u0027m not gonna waste any time on those let\u0027s see and I know we have some a lot of different flooding proposals we may have an interim on this I\u0027m kind of I don\u0027t really think it\u0027s a good idea to try and do it at the end of the routing working group because who knows you know exactly when it is and we\u0027ll probably lose people so we might have an interim to talk about the drafts that have a lot of overlap and that\u0027s it okay so we go with the first presentation you want to say yeah the UN say so yeah less less has to to get some push forward on a couple things we he\u0027s like what\u0027s going on with this much in it so the teehee this draft is submitted the is Uma here there were I think his he that hold up on the segment routing extensions no no what is the hold up on that eight office I told I told me to get down your life okay right me I\u0027m never mind it\u0027s that just reduce the engineer on the office yeah but I mean so so it\u0027s like have you done the is J submission or do we have to resolve the author issue first yours all first-rate I mean it should be it\u0027ll go to Alvaro and he\u0027ll probably have the same Tommy so yeah yeah I mean we\u0027ll take care of that I use do first I\u0027m just saying you "
  },
  {
    "startTime": "00:03:05",
    "text": "know might take us a few days to you know see who gets the short straw or whatever so so that is the only thing that\u0027s you had a few of them oh one thing in my in my hurry do you all know about the note well that if you know about any IP are you\u0027re obligated to disclose it as early as possible seems to work and I\u0027m sure if you\u0027ve attended any other what your maintenance oh did we did we didn\u0027t do and we didn\u0027t do that note well yeah yeah one that one second that\u0027s right here you wanna here\u0027s the routing here\u0027s the routing working that\u0027s the same thing so no well noted sorry what the okay okay unless Ginsburg this is a joint presentation on the patootie attribute drafts one for is is one for OSPF these are changes since IETF 101 we added the TE metric somehow we had overlooked that we added that as sub TLV that was supported in the per application encoding we also allowed that the per application TLV or sub TLV could be associated with the l2 link bundle TLV in Esaias and we moved the registry that\u0027s defining the application pit identifiers because it\u0027s being shared by ISS and OSPF and we moved it to the to the IGP parameters registry and no SPF v3 support was added this was actually presented in Montreal but just included it in the list we feel these drafts are mature there\u0027s been a lot of discussion about this these have been three years in the evolution there are some implementations so we feel like both drafts are ready for last call I will mention there\u0027s one minor editorial change to the OSPF draft that\u0027s coming which is just to make sure that the length of the application good identifiers is is a multiple of four bytes which is consistent with the way OSPF does encoding but other than that we\u0027d like to see these go to last call "
  },
  {
    "startTime": "00:06:09",
    "text": "does anybody have any any objections to this call we\u0027re gonna make we\u0027ll make on lists I guess I\u0027m a co-author of one of these drafts but and like although they\u0027re not I don\u0027t think I don\u0027t think we have any implementations there at least but at least there\u0027s been a test of people actually coding to it and testing with it already with with this with these encodings so I\u0027m glad I did that before christened into the room I sees in the back okay so hahaha so we\u0027ll take it to the list the working group last call oh just keep speeding yeah do you need a new presentation oh yeah you seemed to me more Dexter I don\u0027t know and then me I missed oh no yeah you did why doesn\u0027t it do square though maybe this I had so much fun with that Wow okay this is the an update on the restart signaling missed draft for sis here\u0027s the history we first introduced this in March and presented it in London there was an update the update was basically to include an appendix that had the summary of the changes from RFC 53 and we presented that in Montreal this was adopted as a working group document in October they\u0027re really in the eight months here since we first presented this there really hasn\u0027t been any significant comments other than to summarize the changes so this is a really a modest extension to the existing restart protocol for for restruck functionality for ISS and in the absence of any concerns that have been expressed we\u0027d like to move forward to the last call I should also mention this functionality is equivalent to what\u0027s been in OSPF for many many years okay does is there any objection in the room to taking this to a working group last call does anybody think this is not ready for that for the who\u0027s taking our minutes oh yeah all right okay there\u0027s nobody nobody thinks that nobody objects "
  },
  {
    "startTime": "00:09:20",
    "text": "okay this is an update on the spine leaf extensions for is is we\u0027ve presented this multiple times in the past so I\u0027m not going to spend a lot of time going through the details just a quick overview this is a fairly modest extension to is is it\u0027s we believe that it addresses a number of issues in the data center topologies it particularly addresses the flooding problem to the leaf nodes in most cases there\u0027s no flooding done to the leaf nodes but we do have extensions to allow us to recover when there\u0027s incomplete connectivity between some of the spine nodes and the leaf nodes so that we don\u0027t block all traffic well then we can advertise essentially the routes that are that need to be exceptions from the default route that you would otherwise use from from the leaf nodes so if if there are link failures we do address that and avoid the black hole we are compatible with a number of other extensions the dynamic flooding extensions can be used in conjunction with the extensions defined here there also are some mechanisms that we introduced in support of Russ White\u0027s open fabric draft particularly some of the auto provisioning portions we made a few modest changes since the last ITF based on comments we had received largely from Tony P thanks very much to him we had support for the horizontal links between the leaf nodes and we had a flag that would indicate that the leaf node could be used as an alternate default route the feedback that we got was this was adding unnecessary complexity so we have removed that and essentially we\u0027re just not making use of the horizontal links between leaf nodes and if they exist we also clarified that in these cases where some of the spine notes don\u0027t have full connectivity to the leaf nodes that you might have multiple link down events and therefore you might have to exchange some of the protocol extensions to multiple spine notes not just between one leaf node and one spine note this is not a change it\u0027s just a clarification and we also added text that suggested "
  },
  {
    "startTime": "00:12:20",
    "text": "that although the extensions we defined are intended to be really primarily targeted targeted for the the tr0 between the leaf nodes and the next layer of spy notes that in theory you could use these extensions for additional layers so again this draft has been presented I think this is going to be at least the fourth time I didn\u0027t go back and count exactly but but I know we\u0027ve presented it multiple times we have made changes based on the comments we\u0027ve received and so we\u0027re back here not for the first time but we\u0027d like to ask for working group adoption so I guess I have a few comments the dynamic flooding compatibility with Tony Tony leaves and at how is that just using the the advertisement of the distributed algorithm the fact that it\u0027s using explain this this algorithm well no so with the spine leaf extensions essentially the the leaf nodes the LSPs and the leaf nodes are not part of the flooding so it\u0027s big we\u0027ve you know yeah so they\u0027re just not part so you you use the Denny flooding extensions for the upper tiers and now Isis pine leaf extensions basically to to come almost completely eliminate the flooding to the leaves so in it I mean sort of it\u0027s kind of like overloaded LSP operation for the Leafs I guess but right they were advertising their own LSP with no flooding to them no so when you said the horizontal I just read the reread the draft I don\u0027t remember that being talked about obviously he said it was removed you talk about not flooding over those horizontal links between leaves no no so the previous versions of the draft we allowed that there was a B bit that essentially a leaf node could say I\u0027m a potentially a backup path for the default route instead of going to the spine if your spine is compromised just by neighbors compromised you could come to me we the feedback that we got was this is just an unnecessary complexity okay but but so you still when a leaf comes up in floods to all its links the horizontal and to the spine so the the yeah so the the leaf zones are nominally going to flood to their spine neighbors okay the idea that you is that you don\u0027t that "
  },
  {
    "startTime": "00:15:21",
    "text": "the leaf nodes do not have to have the full LSP database they just need to know hey what spine is gonna use for the default route and if there are some compromised connectivity then they need to get some advertisements from the spine notes to say well for this set of prefixes you know you can\u0027t use me well I understand that I\u0027m saying what I didn\u0027t see anything in the draft that talked about the horizontal links you\u0027re saying they can\u0027t be there but what happens when they are does it flood the Leafs flood do the Leafs flood there I know they\u0027re only doing their own LSP right and they\u0027re not gonna hold on down the other but are they flooding their own else pieces to their leaf in that case or it I guess I\u0027m just asking for that to be covered because it\u0027s not gonna do the are you know I can do the are well exchange it\u0027ll be like ll right correct and what happens and I you know that song saying is I didn\u0027t see that was they mean do you remember I\u0027m drawing a boy yeah I naming ssin with Cisco Systems yeah I think we before we were saying we have a bit bit if if we can\u0027t go through this to reach the other one now if we\u0027re really in this particular case I think a farm flooding point of view from you can leave we don\u0027t do anything special they just flooded over but but we don\u0027t flood our neighbors LSP back over there right I think we probably need to put on statement chain we it puts hi metric between those two or something like that yeah I mean it\u0027s not particularly useful because right it\u0027s not we don\u0027t have the topology connectivity right yeah as a working group member speaking is working remember a cylinder Cisco Systems I think this has little overlap with the other proposals so I think and it\u0027s like it\u0027s a moderate a very modest proposal if there\u0027s any overlap in functionality it\u0027s an overlap it does a small subset of what RIF does you know but it but it\u0027s you know so I don\u0027t I don\u0027t think it has overlap with the remainder so I think we could safely working group working group adopt shouldn\u0027t call this one without worrying about overlap well I was having this I I haven\u0027t "
  },
  {
    "startTime": "00:18:24",
    "text": "decided yet on whether I I think you\u0027re I think we\u0027re closed on it I don\u0027t think that the the work is I mean other than that what I just mentioned right I think the work is kind of done right I don\u0027t think it\u0027s just a question of do we push it forward right as we\u0027re about to sort of collapse well I think we\u0027re going to be collapsing a bunch of other flooding stuff you know do we do we do this one kind of ships on the night with those or do we know I don\u0027t want to stall the work either because I said yeah these are the this this is definitely a complimentary proposal yeah it just handles that bottom tier right I mean it\u0027s not yeah yeah I mean we\u0027ve allowed for the fact you could use this on the upper tiers but that\u0027s not our primary target Tony P troublemakers incorporated and I think a key discussion on this draft so like independent all the other stuff will go to there what is it 7356 or will keep the stuff on the hellos and frankly I think we should push for the 7356 because then it has potential then you can grow lots of other stuff yeah I think that for the uninitiated 7366 isn\u0027t scoped LSPs yeah so right now the draft allows you could put this in hellos or you could put this in the link scope tell us beasts and well I think clearly both and they contradict the link scope Delos bees are a better solution so I hope you know personally I\u0027ll consult with my co-authors yeah okay yeah I I have no objection yeah okay so that\u0027s comment from me in depend of the adoption everything else so is this I guess my question to you as the chairs is because we\u0027ve been here before and basically the answer at before was wait so what\u0027s the answer now in terms of our can we ask the working group you know we can we can do that I mean I just have my own opinion I\u0027m not saying as a chair I don\u0027t think we\u0027re ready to ask that I I really wish we could do that in term you know if we\u0027re gonna do an interim on the flooding stuff yeah yeah and we disagree on this point you know I think this is it doesn\u0027t have overlap so the fewer things we\u0027re trying to call s in the interim the better and this just is we might as we can do this as a you know Roma hansmann the other thing that\u0027s interesting about this work we have implementations going so I hate to delay it what we\u0027re waiting on the these separate this these all these graphs that are related to subsets or separate flooding topologies from the total routing domain topology well like I said "
  },
  {
    "startTime": "00:21:25",
    "text": "I don\u0027t object as a chair so we can ask the list but does anyone else object in the room to this being working group laughs called it no adopted working group of doctors let\u0027s go okay Tony P again so if I would be running this group that I would probably you know try to get into 7356 format I mean this hellos are an accident waiting to happen so and I think the flooding is not really a problem it\u0027s so nobody\u0027s not the chair anymore but you\u0027re still a member so you\u0027re objecting no so no I\u0027m suggesting that you do be like you know so that I think that all you\u0027re suggesting and yeah I support this is we\u0027ve got two mechanisms to give these exchanges you\u0027re suggesting get rid of the whole mechanism yeah a result and right yeah and and the other one I I think the flooding is an optional optimization so if this is really the stumbling stone you can just shelve it for the moment elegantly right the draft works nevertheless it\u0027s an optimization and that when things comes to free you figure out what you do with that stuff fooling recruit you from reusing anything yeah just motivations I don\u0027t think there\u0027s any changes that would be required to this draft no flooding optimization right flooding optimizations might have to take into account the signaling from this draft correct yeah but that is independent I mean whoever comes up with any solution I mean this will you have to signalling and they like you say they have to properly deal with it that this the Leafs cannot flop through right I mean I\u0027m not objecting but I\u0027m suggesting to ask for resolution of the mechanism this is the time before the hex propagate okay sure yeah okay yeah I mean soon get yeah I agree with the lesson a Tony and we can move to this link local signaling but the original intention I saw the way exist to use the holo is let\u0027s say we only have here zero in the tier 1 and above tier 1 there is a rich connections for example there\u0027s a ring among other spines right so in this particular case the only thing you need to do for this draft is signal I do not want the flooding back that\u0027s all so for this simple purpose if there\u0027s any link breakage or something there is a possible to reroute in the upper layer "
  },
  {
    "startTime": "00:24:25",
    "text": "so in that kind of condition I was thinking you know you only need a probably 100 lines of code to support this so that\u0027s the idea but yeah if we are going to adoption or something we certainly listen to whatever yeah group opening yeah that did it caught me a little by surprise I guess we\u0027ll take that to the list what the working last call no Dobson adoption more coffee fast tracking it is yep yep that\u0027s it does that mean yep this is it you stuck this sovaldi covers both homes PF and I sighs no no no that\u0027s what I didn\u0027t think that was right okay I must have put him in the wrong we need to don\u0027t dense yeah it is I think I missed it it\u0027s up to you can I\u0027m gonna try okay sorry this is when Michigan Jay frog comes out I don\u0027t know how I got 717 proposal soon I mean I mean mmm yes I try and see why it\u0027s not there "
  },
  {
    "startTime": "00:28:00",
    "text": "do we know why it\u0027s not working buddy yeah they\u0027re gonna be there soon sorry oh here it is it\u0027s your dynamic flooding update why is it not alright we\u0027re it\u0027s different about this one it\u0027s together yeah I\u0027m gonna see why it why it doesn\u0027t it\u0027s it should be there maybe it\u0027s the wrong order I don\u0027t know this is the okay that\u0027s a different page do you have it on your laptop do you have HDMI okay do you want to move to a different presentation well I I can transfer it sure let\u0027s photo what we\u0027ll just switch to the next presentation and then I\u0027ll get ears up okay you want to put oh yes you know it\u0027s it\u0027s on the meeting material that\u0027s just not on the agenda I understand that Oh yeah yeah I\u0027ll actually start gender right oh yeah [Music] here "
  },
  {
    "startTime": "00:31:05",
    "text": "here it is it\u0027s uh it\u0027s right there so good morning ma\u0027am my name is Sara turn from Arista networks so I work about updates on dynamic flooding on dense graphs first a quick review um the basic idea of dynamic flooding is to tekapo up relatively sparse flooding topology from the physical topology and this draft has focused on extending the existing link state protocols to support dynamic of flooding imposed centralized and distributed mode without any restriction on the physical topology and this draft doesn\u0027t intend to define the arizim for computing the flooding topology these are the theories that have been introduced and to support dynamic flooding where the ISS and OSPF it covers the air leader selection and flooding topology encoding since last meeting and there many editorial changes and also two important changes are made to this draft we introduced new protocol elements for both eyes eyes and OSPF and I will also discuss the treatment of topology events in more details in particular we introduced the concept of a temporary flooding the basic idea is to allow the node to flood on the link that does not belong to the following topology I will talk more about it later now I cannot go through the new protocol elements we introduced in this update first are the ice ice theories we introduced the a dynamic flooding sub TOB so you\u0027ve a note suppose dynamic flooding it can insert this sub heavy - it\u0027s a router capability TLV and the knowledge of which notes support dynamic flooding can help optimize the flooding topology in sub trv the Noda can tell which evidence its support for for flooding calculation and that this knowledge can help the air leader to select the algorithm in a distributed mode we also introduced a new following request govt and this govt is used for requesting temporary flooding from the neighbor node this is the format for the new iodized dynamic flooding sub govt it\u0027s pretty straightforward we have the type field lands field and multiple algorithm fields each aerosol filter is a new macro echo identifier in the range of 0 "
  },
  {
    "startTime": "00:34:07",
    "text": "to 255 and it identifies the errors and used to calculating the flooding topology and we can have multiple algorithm fields here and this is the new ice ice flooding request govt and it may be included in the iih in the p2p mode there\u0027s only one type of or hello so but the node needs to tell the neighbor which level it wants the temporary flooding to happen so here we added a circle type field the orbit and the scope field is meant for the notes that support this ifc 7356 our not going to details very similarly we introduced the new OSP ft/lbs the dynamic of flooding sub govt which were being the router information era say for Post v2 and v3 for flooding requests we introduced a way proposed option built in the errors type 1 extended options and fields field so here is the format of OSPF dynamic flooding sub govt all the fields have the same meaning as those in the ice ice okay so as promised I will talk more about the temporary flooding so why do I need a temporary flooding I would go through one example let me go through the first case let\u0027s sing her a new link comes up then the two nodes were formed the adjacency and extinct there are link state database these are all done using the existing protocol mechanism in the normal case both suggest Encinos are connected to the flooding topology and this new link states have update will be flooded on the flooding topology but in some case if the one of the adjacency node is not connecting to the flooding of flooding topology then this guy will not receive any links that updates until a new flood in topology is calculated and there it who becomes part of the new frogging topology so the name to flooding still works but it will slow down the convergence significantly so we propose here that in this case and to use temporary flooding it works like this so when the new link comes up if the node sinks it\u0027s not connecting to any flooding topology then it enabled the flooding locally and then Center our request to flooding front to the neighbor asking for the faladi temporary flooding the neighbor once it receives the flooding request it will start "
  },
  {
    "startTime": "00:37:08",
    "text": "flooding on this new link the temporary flooding will continues until the new threatened to perigee is calculated and the pose adjacency nodes are connected to this new two topology so there\u0027s another case where temporary flooding can be used so if a local link fails and this node has one or only oh no connection to the flagging topology it can also enable temporary flooding one or a small subset of links for fast convergence but here we do not recommend that this know the primary request temporary flooding are oh it\u0027s links because this my overwhelmed the note itself and caused some instability so as you can see that there\u0027s trade off wing during the design of dynamic flooding on one hand if were it\u0027s excessive flooding may cost control plane to overload and lead to networker in stable on the other hand to less flooding may slow down the convergence so there\u0027s no quantitative or main measure of how much flooding is optimal so when we choose the flooding topology and enable temporary flooding which are take into account is trade off and that\u0027s my presentation hi Tony Lee Arista so if there\u0027s no discussion the author\u0027s dens and design team would like to ask for working group adoption at this time yeah I think we just have to resolve one issue but I think it\u0027s ready for that working group adoption call as well the issue I think is that there\u0027s we have another we have another draft out there that is very why motrin Verma horoscope technology I think at least I have to comprehensive almost completed solutions for flocking reduction and then we have or I think it I remember in US IDF we have discussions some more people for poles merge to Jack and also I think one Charles or cabbage indication maybe merged right so I don\u0027t know whether we just one draft move forward just let the "
  },
  {
    "startTime": "00:40:11",
    "text": "other draft and then those people work also working very hard and then I don\u0027t know who is that if so better fair or just the right we need we need to have a more discussions yeah so I knew this was gonna be a little contentious so I went back and I I looked at the timelines right and Tony published his draft of which was about a central controller and distributing a flooding topology in January 7 then the the distributed flooding reduction draft was published in March they both presented at IETF 101 the distributed algorithm was found wanting right there was there was problems that were called at the mic like breakage of a triangle topologies and at the point being that if it wasn\u0027t fully baked right Tony\u0027s kind of was a little bit more baked then we had presentations that during the transition to the next idea we had both work both works adopted sort of the concept from each other Tony brought in the idea of distributed which really was just eliminating the flooding topology and putting an algorithm feel them and you had it in the centralized solution so I and and and you also had a distributed algorithm which would still fit within Tony\u0027s work right he\u0027s not the Tony at how they\u0027re not defining distributed algorithms so I think one way forward here would be for you to work on the distributed algorithm that you\u0027d thought of before right and that that would then not conflict at all right but to have to basically the other thing is that you know I mean this is okay this is my opinion as a member of the working group the the the there\u0027s a Tony\u0027s Draft is really well written and you know also and also the flooding pathology district distribution is very much a kiss solution right it\u0027s very simple and when I went it this is just my opinion as a member of the working group when I look at your solution it seems a lot more complex right and and I\u0027m not sure what the win is there so anyway that\u0027s my opinion as a member and also the history here so I don\u0027t I would hope you know the I think that one way forward would be for you to work on the distributor algorithm that you\u0027d thought of before and then that can advance in parallel and then we have no conflict I don\u0027t know what other people\u0027s opinion I think a cognitive days I think there\u0027s a meeting or as a proposal in some kind of or I think Jeff hosted the meeting "
  },
  {
    "startTime": "00:43:13",
    "text": "regarding the requirement for data center right so you from that point and then people walking on the platter reduction and then today\u0027s first we also presented the Palatinate action on ATF 101 right and then I also remember that some of people think the tribute of why the more practical and that\u0027s the different opinions right and also I think we have a regarding the solution people also have given opinion on this solution is that hard it\u0027s so proven you simpler I think maybe after post draft presented and then we we should have discussions from technical review for whatever point of view and then I don\u0027t know whether we can have discussion which one is better which one is the simpler will maybe combined together maybe can improve one Java or another and have a whole solution is a much better I think for those different approaches or options with me we have should have some discussion right Easter is a centralized one one craft and distributor one another whatever word you together I speaking as a chair I like the way that Tony I mean I mean that Chris said position the drafts so that way we\u0027d have this draft at the top as a pro dynamic flooding and the two flavors centralized and distributed and your graphs would be one distributed algorithm and the one that comfort is going to present would be another one and I think that would I think that would allow all of them to be positioned and go forward so I\u0027m I\u0027m supportive that speaking this chair because I I lived through the monnet three drafts as I\u0027ll borrowed it as well and we don\u0027t want to get we don\u0027t want to adopt multiples and say okay let the best man win it because sometimes they go on you know beef Els was another thing I mean they\u0027re you know where they had to two different signaling solutions and and they both went on and what it did is it diminished the value of both of them and in a Monet what we had to do at the end was they all became experimental and they kind of fell into obscurity and we definitely don\u0027t want to lose this work and I think I\u0027d support Chris\u0027s straumann and maybe we could put that straw man and discuss this from Ian he\u0027s got on the list and why and not rarely because we were gonna run out of time all up I think that\u0027s what we should do yeah I run all the Tonys drop down that old Rafa resolve the same issues right see I think it may be just a different approach and there\u0027s some difference I\u0027m not saying I see it thank you "
  },
  {
    "startTime": "00:46:14",
    "text": "are you finished they say I was just gonna say in terms of splitting the the algorithm work from the mechanistic part of it it seems to be the the piece that makes the most sense so just Chris Martin for Marissa I think that would be the better approaches what make that claim he was not yeah clenches next nu yeah about this so I\u0027m jabber scribe I\u0027m stay I\u0027m sitting here or typing in your name as would be as you\u0027re up here at the mic if you don\u0027t show me your badge people in the room don\u0027t know who you are yes but it\u0027s like make sure your badge is fully visible thank ok so I am here actually to speak about like yet another you know floating reduction technology here it is something that you know comes out of the brain of Hank Smith so you know he wanted to present here but he no he couldn\u0027t actually make it so this is something we started to work upon from since the last you know ITF in Montreal and we were actually thinking like okay you know we have some floating you know reduction algorithm already out there but there might be a way to actually not make it even more simple you know the word simple was already mentioned before we like simple simple are good things and if it can be implemented also on the router you know running already is yes and if the router can be extended with like something you know very simple like no additional SPFs no complex signaling something that just follows the traditional routing I think that would be a simple solution so that\u0027s what I want to be presenting here so what are we gonna be doing here I\u0027m gonna be talking about something which is like fully distributed something which will work across any kind of topology of what you have available and I will just hope it my explanation will justify the simplicity of the work because I tend to think you know I tend to explain things more complicated than they actually are in reality so I\u0027ll do my best so yeah so so in essence what we are going to be doing here is if you have like do boxes in the network and you\u0027re connected with multiple links then what we really would like to have is that you know that we don\u0027t float across the links between between all the links between those two boxes we would like to have like one of the links between two box which is used for floating so that is the the master plan and to actually achieve that we use like the LVS just like in the previous proposal and we also use something you know so one TLV is going to be used to identify a floating anchor so the technology what I\u0027m describing here is based upon creating a floating tree and the tree the root of the tree is going to be our floating anger so that is gonna be basically like a simple "
  },
  {
    "startTime": "00:49:14",
    "text": "TLV I will explain a little bit more about it the till they will be set in the LS look we you know part of the LSP and it will indicate it\u0027s an anchor good there quick question yeah this a cylinder what is that the only thing it reduces is parallel links it reduces ecmp right like you know in a cloning or crew doesn\u0027t it yeah okay okay I\u0027ll explain later I even have pictures pictures are good I don\u0027t only have texted pictures also so I\u0027m like super advanced here so and then the other extension I have is you know if a particular router determines you know what its gonna be is you know best link towards the fleeing anchor so that\u0027s a local decision he actually needs to signal it upstream towards the anchor to tell the other guy that he selected that particular link as the floating link itself so to do that we actually you know use like another TLV in the is H so I\u0027m gonna be skipping this I\u0027m going to be jumping directly to pictures okay because people like pictures so what you see here on the classic floating yes so you see the router in or out of 13 here in the middle sorry router 23 so assume router 23 gets like a new LSP he actually ships you the upstream as the blue arrow it goes to the router on top that\u0027s rather actually you know depending on if it is new or not it will actually send that LSP you know to everywhere and then the everybody will send LSP is back so you have like its ruling storm thing going on now that is not very optimal so that is what we would like to avoid so what we would like you know achieve here with our minimum flooding so is the desired behavior that if router 23 creates like a new LSP that actually you know ships it up 22 in this case I miss okay it doesn\u0027t really matter so we\u0027re out to 22 because like a new LSP it chips it up and that only the blue lines actually are part of our floating topology so it actually you know routed 12 go then just ship it over towards router 11 around to 13 and so on boards so the blue lines is actually a minimal floating topology now the big question is how do we go from the classic thing towards a minimal floating thing and that\u0027s what I\u0027m you know what we actually came up with so how does it work so the first step you know you see the topology here so I again the topology what I\u0027m using is just a random topology by the way I\u0027m not going I\u0027m not going quick enough or I need to go faster because okay I will go faster so it would become more complex so I have like you know I just select one of the routers in my network as being the floating anchor and that actually that guy will settle this deal facing like I\u0027m the floating anchor and that LSP has floated everything back so the first set up happens is for the routers directly attached to the floating anchor and actually they will say okay you know I know who threw the anchor is now which interface points towards a floating anger and that interface here for "
  },
  {
    "startTime": "00:52:14",
    "text": "example here we actually say okay on this interface I would like to do floating and on the other interfaces actually going to be doing footings and all suppression now that is very good if this guy gets another speed and you want to shake it up but of course if there is another speed coming from somewhere else like from here it needs to go down also so the upstream you know the router going up towards the anchor needs to be aware about which is the footing you know the floating link so that is why we use the iih you know TLV extension so that this router is link-local can signal towards that guy I\u0027m going to be using this link as my floating link so the same kind of principle is actually happening you know know consecutively like you know different times and that is what what you see actually in this picture so what you have in this case you create from your very you know very dense diverse kind of topology a topology for floating just for the control plane something like this what you see here and all of the control plane you know and all of the control plane information will actually have to go over the anchor you can actually have one anchor you know but if that actually fails you actually fall back to the traditional floating which is maybe undesired you can actually you know set up a secondary anchor you know for resiliency in your infrastructure so actually works very well so what you actually you know what we are doing here is we actually you know in essence if you look into it the way we actually are distributing our LSPs and control plane traffic for from a routing perspective it is very similar to what you actually do with like a pin sports mode tree towards the round of your point it\u0027s only used for controlling packets not for data forwarding at all you don\u0027t need any additional you know SPFs or anything else complex signaling is you know relatively simple so this is again when I explained for having a more robust you know topology so I also added to like a bit more information about what we would like to add in the tlvs so the first TLV so the anchored TV so this is the TLP used by the anchor to signal everybody else in the infrastructure I am the anchor so the first thing you have to put in there is like a priority it\u0027s a priority field you actually you know if you have multiple anchors you know to actually let the network know which is the most important one or the one which is most desired to become you know the real floating anchor then a second field is like you know to let everybody know how many footing topologies you would like to have then in the is H for the yellows to actually know signal you know link locally between two routers which is going to be the footing link so again a very simple you know TLV you\u0027re gonna put like you know we were thinking about putting three different values in there the first thing would be like you know a floating suppression indicator so this "
  },
  {
    "startTime": "00:55:14",
    "text": "actually would be the adjacent and all the router itself determines which is going to be this the linked pointing towards the anchor and that actually you\u0027re gonna be setting in there okay this is gonna be the link it\u0027s going to be suppressed yes or no another field would be you know in in there too actually give the actual suppression itself the actual suppression on the link which can be used for troubleshooting cannot perspective which would be very handy and then a third you know piece of information which is in there is you know if you wanna have like a bit more advanced you know algorithm or whatever in there like in the number of active floating adjacency so this actually can even be used to optimize your floating topology based upon the degree of connectivity so there is something we can do it\u0027s also fully backward-compatible so you can actually introduce this you know gradually if you desire to do that and in essence you know what it results to is like you know if router doesn\u0027t really support this and it cannot inject the iOS a you know the the hello TLV then there is no flippin suppression and we just fall back to you know classic traditional floating at the node itself anyway so we actually have some you know additional text written up already you know if you actually go floating between trees in essence you know the you will have to make the eternal trade-off a trade-off being and on easy to go for high-speed or you go for stability which actually means you go a little bit slower and that\u0027s a trade-off because you\u0027re going to be making also the going slower will be based upon the degree of connectivity so I think I\u0027m gonna be leaving it over there with this light on the whole thing because I see a sea you know almost kicking me I know out of stage any questions comments and so on writes I have a question is it does this actually just end up computing a minimal spanning tree it computes like a sparse tree but it actually just like around emoticons around the whole point so you create like a tree but you don\u0027t do it based upon like any kind of SPF or whatever you use the information of what you have available you know where the anchor is just select the link which is you know most close to it and that\u0027s say yeah I understood the mechanism I was just wondering this the result was that that loss Ginsburg so in the spirit of Chris\u0027s proposal to take all of the multiple drafts because now we have one more yes one more yep do you do you see or do you see any reason why we could not take whatever ideas are relevant from your draft incorporated into one draft which represents the mechanics of the flooding topology and have other draft or drafts which work on the algorithms do you see this as a reasonable way forward so I see that\u0027s a good one so the reason we come no we created this draft that is because you know it\u0027s "
  },
  {
    "startTime": "00:58:14",
    "text": "actually if you look into it you know because Hank you know is written somewhere I just go back in the past you know we actually you know envision this as being like relatively simple to implement on an existing ideas implementation okay now if you know we want right now the idea is just you know existing is sort of like being created how to move this forward knowing you like multiple drafts you know what I don\u0027t you know I can talk to you afterwards not a problem at all we can figure that one out I Tony Lee arista so I\u0027d like to reiterate some comments that we had in private email but just you know the benefits of the working group my concerns with this are all about the diameter of the result and also the degree the diameter is key because that controls the speed that the flooding is going to give you a graph with a very large diameter your LSP flooding is going to have to take many hops and that\u0027s going to impact convergence the degree if the degree of the node is too high and especially in this case when you\u0027ve got redundant anchors you could get an anchor that gets flooded by an LSP update and that could cause instability at that node so those things are both things I think need to be addressed yes and and again Tony you know that is why you know the well I mentioned lucky the next version we actually have some some text above which was like inspired by your comments you know and that\u0027s why you know we have like some sort you know we actually we have a solution which trades up speed by convergence yes and crisp errors as so I just wanted to point out that I\u0027m very supportive of this it doesn\u0027t really seem to me that it fits into the framework of of Tony\u0027s draft or Tonio dolls draft in that it\u0027s not just a distributed protocol but it\u0027s distributed plus some signaling with these tlvs so it\u0027s not just like a subset of that I believe that would be my my take I mean it would I think it could be made to be one overarching thing but I think there would have to be work to to accomplish that we really have two minutes over sorry Chris Martin I just wanted to say one thing because Chris and Chris gave Todd I gave him my spot back to Tony\u0027s point the the nature of the naiton the notion of a flooding tree is kind of I don\u0027t want to say it\u0027s obvious and good there I don\u0027t mean this in a bad way so we could have I mean obviously that\u0027s the first step you would take I mean it doesn\u0027t seem to be the coverage is not the same I think the resiliency is not there and the diameter issues are there so I just wanted to make that clear I mean we kind of thought a bit right away I don\u0027t know if that\u0027s the best approach "
  },
  {
    "startTime": "01:01:14",
    "text": "this is a different thing yeah when Jeff said don\u0027t don\u0027t do this we\u0027re just gonna have to run with it yeah well why don\u0027t we just go cancel our cool yeah I\u0027m watching from Mojave technology today I\u0027m going to present Mingus state of lot introduction so these coppers or OSPF at the ISS next page okay so in a surger inversion journal so we focus on distribute a mode for fellating reduction so in addition to that we also talk about centralized the mode and the static mode for flattened reduction that\u0027s in the our surgery operation so in our one version we made extensions so in we allow operators to select a mode they can select the trigger mode centralizing mode or static mode so we can also allow customers to select algorithms for computing flattened topology in addition to that it also allow customers to enable for lighting technology for a flooding reduction also route back from flooding reduction to Domo faladi so after version zero one we we deliver a couple of versions which address comments from the list and from the the IETF meetings and then right now we have a zero for version so in the current version we have a piece of stuff one is that we for post centralized diversion and distributed mode we have bike hub pass which can be used to back up a lot in topologies bleed so force centralizing mode we have messages for formatting topologies so include including cup of topology for logging operation coatings and then we have in contains for packet pass and then we have in this draft we have our invitation for all different the IGP is also a version 2003 and is next page "
  },
  {
    "startTime": "01:04:17",
    "text": "so these for Mike Harper for for Latin - what ASA bleed so when we can construct a fraud in topology Normandy will have two objectives one objective is that where will the leg of half for LA t√®ne topology and then which can be used to reduce the flooding greatly so in this case we should have a saline flat Entomology that\u0027s one objective at the same time we also would like to cut off for a bit hibachi which is more is kind of a reliable means tolerance to failures so in this case we need a favor for one property which is it\u0027s very fat so this is a contradictory right so you know is very hard so you want to get around this we propose a backup task using backup at pass to back up flooding a topic split so in this way we can have a first lien top flight in topology at the same time we can also achieve for the tolerance so for example for critical node on the flooded homology if we can compute a backup of us when this critic knows is done and then we can flood link state using the backup pass or that node at the same time the remaining homology so we can quickly flood link state to every life node so using this way we can also achieve for the tolerance for manual failures so for example you may have a multi finish though the failures or link failures so in this case we can use back a purpose for this failure know so link and then same time that remaining topologies so we can flood at unique state using remaining flag property and then the packet pass so in this way link state can quickly distribute to every life load in the topology so next page so this is the message\u0027 for flood the flood entomologist for centralized mode so we know for flood in topology which can be represented by the links under flood in topology so those links we can very easily encode it so we can start for each node we know there\u0027s a links attached to that a node so we can just encode the data node we call the local node and then the remote node which is connected by that flattening so for each node we encode a local node and then the remote node so we just user and know the index in addition to that we also keep "
  },
  {
    "startTime": "01:07:20",
    "text": "the size of data note index so in this way we can achieve a very efficient efficient encoding of the links for here we\u0027ll give an example for example for we consider know the local node with short for ln1 so we have three links under flooding for G which is the green link so to remote what one remember to remove the three so three links in this case we have to encoding for local node Ln 1 and then we encoded the remote node which is the three node node one Ramona LuAnn Ramona to reminisce 3 so Suri links so local now the index and then plus the lamp of nodes and then this 3 Note edge index and then we also keep the side indicates on both sides of the index so in this way we we have a very simple and efficient that know the link encodings so next page so for each node portal links connect to the node and a flag entomology we encode of the links and then all those links we can put in a TLB well record a finale topology and ink PRV yeah almost done and then this TV can put it in the flat into our the obokata says and then cricket flat that\u0027s the flat in topology encoding next page so this one is a improvement for party for my property encoding so we can just encode in code the hope for a party or hopefully in topology in one data structure in this way we can have a more efficient encoding next page so this is a encoding about a backup of path so we have a encoding for backup has 4 loaded for note and then this is the first image just we have for encoding for the past by load index right and then for you to node we may have a number 4 PI K pathway we may have multiple paths backup path and then for each of our postulants and then the least of lausanne the past so for this backup backup path we can put it in the POV and then this govt can be put it in the open LJ\u0027s so similarly we can do that for the 4-pack hopper for the link so so this is only for user for centralized mode so right so we can see that we have a backup path for flooding to participate "
  },
  {
    "startTime": "01:10:21",
    "text": "so in this way we can chief the objective reduce the flood topology flooding severe flooding significantly at same time we achieve the photo tolerance and also we have a the encoding for the Flavian topology that will give us couple ways options and then I think this one is also first single and inefficient I think also so regarding the the one we have a solution for centralized one mode and also distribute mode I think this one is also comprehensive solutions so regarding this one I like also asked with options because but I idea some people propose emerge I also I think it\u0027s a good way to merge because same problem and then maybe people are solutions and then come for different ways and then maybe ok ok I don\u0027t think we are I don\u0027t think we have time for too many comments I guess we\u0027re gonna have some discussions on the strawman and how these drafts relate Dave can you do for 10 minutes instead of 15 ok another working group to write no we tried to get it on a couple of other agendas but didn\u0027t quite often anyway this is a problem space that I found really really interesting and there was stuff from something I\u0027d done in a past life that I thought was applicable so I thought I\u0027d throw my hat in the ring or shark tank or whatever you want to characterize this exercise as something that I have a distributed algorithm for the constraints letting abide GP advertisements and it kind of no not that one I don\u0027t even know what half of those acronyms are known encoding an addressed either what happened was it was even my time there there\u0027s other there\u0027s our tabs open that\u0027s the problem okay and it went to the next yeah I hate anyway well they\u0027re solving mapped just close those tabs okay yeah and we don\u0027t want the agenda we what the materials what happened to manage yeah that\u0027s what I\u0027m saying I don\u0027t know I\u0027ve no idea what no "
  },
  {
    "startTime": "01:13:30",
    "text": "I had stirred into my plot but I think I would lose myself along the way so yeah I\u0027m starting to think this this like preset up laptop thing is not that useful I mean really like it just worked better when we used our own look at know what what did it do there okay I had it here okay next okay okay so Tony brought forward this of a general problem on how to produce a constrained flooding topology for dense graphs something that would be immune to single failures and would reduce the number of copies of an LSA that that would be continually interrupting a control plane what this draft discusses is a distributed algorithm for computing the flooding topologies with desirable properties I have only really looked at it for bipartite style graphs which actually could be so it\u0027s with multiple hierarchies and the modified ones with intra tier links it may be applicable to other topologies but that would be for further study my understanding this was kind of the problem space at the moment so that\u0027s what I focused on what the approach is is to do use two diversely routed spanning trees such that each node in the dense graph is by connected to the flooding topologies these spanning trees are computed by each node or that each node figures out what its role is in the spanning tree by computing it from the basis of information that\u0027s in the IGP the flooding topology itself is the sum of the spanning trees so for example the first copy of an LSA received by a node it doesn\u0027t care which spanning tree had got it from it that\u0027s the one that propagates and of course the next one is considered to be redundant and thrown away because the key thing here is is I\u0027m trying to achieve resiliency with nothing being able to think so in essence it\u0027s a one plus one arrangement for flooding and everybody gets two copies of everything the actual flooding itself is split horizon between upstream and downstream for LSAs received from an upstream interface and that\u0027s one of the ways we explicitly constrain flooding and like I said the net result is in a fault tree topology all nodes participating in the flooding topology will receive two copies and even under single failure so scenarios and many multiple failure scenarios they will receive at least one what makes it work is the tiebreaking algorithm from 802 1aq which is also documented in RFC 63 29 for those of you who want to see the IETF version of it and when we worked on the algorithms fredo 2.1 AQ i guess "
  },
  {
    "startTime": "01:16:30",
    "text": "twelve years ago now one of the things we did was we had tools for visualizing the networks that we built and one of the things that was embodied in this was the idea - if I wanted to do load spreading and this was for originally for Ethernet we had this notion of an algorithm mask that would be involved in the tiebreaking algorithm and therefore we could do different variations of tiebreaking and when we use the bookends of the tiebreaking algorithm then we got you know in most networks very or completely diverse trees out of the deals now the actual time braking itself is is you take the algorithm mask you XOR it with the lexicographically sorted list of node IDs in the path you rank those and select the either the lowest to the highest depending on what you\u0027re doing and that is your tie breaking the interesting property of this is is that any component of the shortest path is also the shortest path and what that means is as you\u0027re traversing a graph you can ditch an awful lot of options so this thing is n log n in complexity but not all n log n czar would be my observation and this one is really really quite frugal of resources to give you a visual representation this is what the the flooding topology would look like it\u0027s based on one spanning tree rooted at 0 which is the red one and it\u0027s constructed using the low tie breaker so you\u0027ll notice all the transit nodes yet at any given distance from that route is the low node ID and the other one is reader down 55 and it is using the high ID so all the transit nodes for the green tree end up transiting the high ID of any given set of nodes it\u0027s equidistant from it the net result is is that everybody is bi connected to the flooding topology hence they will receive two copies now the flooding rules themselves are really quite simple if an LSA is received from an upstream adjacency and it\u0027s the first copy you\u0027ve received flood on all downstream member adjacencies and if you are also connected to nodes that are not participating in the flooding topology you use normal flooding rules for those particular adjacencies those are described as non-participant adjacencies in the draft if i\u0027m received from a downstream adjacency and it\u0027s a new LSA flood on all the non-participating adjacencies and all member adjacencies except the adjacency of arrival and so this is all those examples are illustrated at the bottom here and the key idea is is that although I\u0027ve Illustrated them as the red and the green spanning trees in essence we\u0027re dealing with the some of them so there is no protocol changes to the actual LS a flooding itself to make this work now the required protocol changes I "
  },
  {
    "startTime": "01:19:32",
    "text": "need the ability of a node to advertise that it wants to participate in the flooding topology in the IGP this would be some form of capability TLV and I would need knowledge of the roots ideally that would be advertised in the IGP or there would have to be sufficient information to allow some form of distributed route election I don\u0027t actually solve that problem I simply provide a lot of stuff on what is required in terms of but what any means of route selection would need to achieve now that probably the key limitation to this is is I do not bound the number of copies that a node needs to generate I bound the number of copies and node will receive but for example if I look at node 55 it will generate what is it 8 16 24 copy you still have to produce to send it\u0027s only ever going to receive two copies but it has to send and and that is a function of the physical topology that\u0027s not something that\u0027s artificially constrained intuitively the only way I can constrain that is by extending the flooding diameter and I considered that to be undesirable so the draft contains a discussion of the problem space provides the algorithms the flooding rules a discussion on the requirements for route selection how to interact with non participants in the flooding topology has some discussion about abri optimization right now the whole idea is is I\u0027m trying to maintain a fully redundant structure at all times which means when failures are occur at some point I\u0027m gonna have to go and clean it up afterwards and proceed to restore a full full one plus one failure tolerance it also suggests some strategies for dealing with catastrophic multiple failures where for example the extreme worse case would be losing both routes simultaneously the draft doesn\u0027t define the protocol elements at this particular point in time it simply discusses what is needed and like I said it doesn\u0027t define selection procedures it only provides what the requirements are for the routes relative to each other so distant very quickly summarize the characteristics of the solution the structure of the flooding topology is interconnected one plus one multi-point to multi-point trees the protocol changes requirement are an advertisement of the two routes an advertisement of the desire and the capability to participate in the flooding topology the computation that each node has to do is order two times n log n but like I said that\u0027s a relatively frugal n log n in a spectrum of n log ends that are out there the maximum diameter of the flooding topology is twice the distances Leafs to spine in a fault free network and in a single failure worst-case it\u0027s twice the "
  },
  {
    "startTime": "01:22:32",
    "text": "distance from the leaf to the spine plus the distance between the roots minus one because the worst case is when it\u0027s a inter root link that goes down or a node on the interview path which means things need to fully loop back around such that every node in the network sees a copy of every LSA that needs to be flooded and the typical and maximum number of LSAs and node will receive will be two so next steps is a bit and I\u0027ve done a bit more thinking about the route selection I want to document that and otherwise I\u0027m just interested in collecting feedback and figuring up where we go from here and it looks like that\u0027s going to be a fun exercise so Tony Tony P goober right discussion open so I didn\u0027t look into all the super gritty nitty-gritty detail of the algorithm and I wasn\u0027t actually worried this work has been done until I saw you draft circulating so I basically went after the thing in a more by gut feeling what the properties of this thing will be and one thing I\u0027m confused about so will that produce the lowest diameter tree or will that stabilize on an unnecessarily lowest diameter because I saw this tiebreaking but I didn\u0027t understand what at each like the spanning read the tiebreaks of the point he has an optimal solution where there\u0027s some stability point it\u0027s on the shortest paths and seeing as we\u0027re discussing tree networks I believe the diameter would correspond to the minimum physical diameter okay which is not the shortest tree or the shortest path okay no fair enough answer the other question is did anybody do any work choosing a route for originator that Yuri flopped I don\u0027t we did look at that when we looked at multicast some time ago back in name dot 1aq work I did consider it in this case it\u0027s just that I ended up going at the two spanning trees because I could still produce failure cases with a route per originator that I did not think the the resiliency would cover I can\u0027t remember why I ended up thinking that I would be very interesting discussion because right now I mean you don\u0027t have any final control right degree control on the node whereas where we go in this direction you could possibly address this problem and otherwise you know yeah I\u0027ll look into work and okay thank you so so we\u0027ll go to the next one obviously we\u0027re not going to do all standardize all these different distributed algorithms but one criteria I think ones that are implemented have implementation results would be preferred over ones that don\u0027t I question for you not for a day or you go ahead sorry no I was just gonna say I "
  },
  {
    "startTime": "01:25:33",
    "text": "mean I I think that it\u0027s not just the implementation rate but it\u0027s also differentiation yes like like the sparse links and the spanning tree look very similar like I mean they\u0027re not exactly the same right but right except this one is on binary shaking and ones done by computational right so earth on a row each is the question for you guys and what\u0027s gonna happen next so there\u0027s this straw man on separating the algorithms from the rest of the work there are several proposals you said that maybe there\u0027s gonna be an intro you also said that you\u0027re going to discuss the proposal on the list is that going to happen first and then the interim we\u0027re gonna discuss everything on the interim that decision of we only you\u0027re gonna choose one is that part of the proposal just sure that everyone knows what\u0027s going to happen so I I think there\u0027s two things to discuss as long as we can agree to separate the two things then we can have it in I think you have to agree on that first and then we have an interim based on the results of what you know right what that is we\u0027ve already agreed to split out the spine leaf optimization on its own essays is a small incremental one level flooding optimization now we\u0027re gonna put the straw man for distributing the centralized and distributed algorithms frameworks and then may I think we should at least have an interim so everybody can talk I mean I think the interim is most useful about the algorithms yeah I mean okay I I think we just need to settle this two drafts covering the same exact technology right I mean that\u0027s we don\u0027t need to two drafts did yes so we sell that and then then it\u0027s a discussion of the algorithms whether its centralized or distributed all right les I actually think we\u0027re not as far behind as a clock no and we could mean that depends on how if you want we can shorten the break but I don\u0027t any people yell at us yeah you can I read this draft you should both cisors that ian no possible okay no this is a bit of is is 101 but it seems that there\u0027s some reasons why this this draft was written because of some real-world events no screens apparently we need to do PDF from now on we\u0027re gonna use this dumb thing okay so what were the motivations for this draft there there was some discussion that it\u0027s hard to find an explicit statement about what to do when there\u0027s a TLD that\u0027s not supposed to be in a "
  },
  {
    "startTime": "01:28:34",
    "text": "particular PDU there have been some interoperability issues actually seen in the field things such as LSP is being rejected because they were unsupported tlvs or sub TVs in a particular LSB or a TLD was malformed the purge handling has gotten has several modes because of past work and there\u0027s been some confusion around that and the this is this leads to some significant operational problems because you can end up with inconsistent LSP TBS and different notes on the network and then clearly your routing is broken do this okay so what do we have we have a TLV code points registry that looks kind of like this I only used one example TLV gives you the value in the name and what PDUs the TLV is allowed in yes and a column means is this TLD is allowed in this particular PT you type a no means it\u0027s disallowed the question then is how to handle the case where TLV is in a PD you that it\u0027s disallowed next so if we go back to the base spec 10 5 89 there\u0027s a statement in there that says any codes and received PT you that are not recognized shall be ignored well unsupported and equals disallowed because maybe my implementation supports TLV but your implementation does not and I cannot expect you if I\u0027m going to be able to roll out new tlvs hitless ly I can\u0027t make decisions on the assumption that every node of the network understands what this TLD is like so if I get a TLV and a PD you and it\u0027s not supposed to be there then need to ignore it as per the base specification and that\u0027s what this little table showing let\u0027s go to the next slide so it\u0027s critical to remember that the units of update for Isis is an LSP it\u0027s a PDU it\u0027s not a TLV when we say we accept the the flooding update we\u0027re not saying we accept every TLV or we understand their retail v inside the LSP we\u0027re saying that the LSP itself has passed the validation checks what are the validation checks there\u0027s a checksum there\u0027s authentication which optionally may be used and then of course there\u0027s a rules as defining is this LSP newer than what I have in the database if it\u0027s not then I need to descend the newer copy if if what I have is older than I need to accept it keypoint TLV content is not relevant but in terms of accepting the LSB the validation checks are on the PDU "
  },
  {
    "startTime": "01:31:34",
    "text": "level not on the TLV level next slide so what interoperability issues have we seen you have a case here where you start out and no day has sent an LSP with sequence number 99 everybody\u0027s happy then it generates a new copy puts a TLV in there that is in some way bad doesn\u0027t follow the the specification in some way what happens B follows the rules he looks at the LSB and says well the checksum is fine the authentication is fine I will accept this then he sends it to C and C go see this TLV is not not to my liking I\u0027m not going to accept the LSB so what do we end up with we end up with note a and B that have version 100 of the LSP and note C and D that have version 99 this is clearly non-functional next slide purges get to be a little more complex because we start out with the base specification 10 5 89 which suggested that well if I go to purge and LSP there\u0027s no point in keeping the content the TLDs that are in the LSB but it didn\u0027t actually require that the tlvs be removed just suggested that that was a good policy so if I get a purge based on ten 589 rolls and it has some TVs in it I can still accept it if it has no TVs in it I can still accept it when we moved to cryptographic authentication that was no longer possible because it meant that an attacker could simply disrupt the network by setting the remaining lifetime to zero not changing the content in the the LSP at all and the authentication hash would still pass this was clearly broken so 5304 stated okay if you\u0027re using cryptographic authentication the only TLV that you can have is the authentication TLV and 53 oh 10 53:10 followed suit when the purge origination TLV was introduced we now had an additional case because we needed to allow a new TLV in purchase but if we followed 5304 rules strictly then anybody that\u0027s following that was saying oh this has a TLB besides authentication I cannot accept this so this was not backwards compatible so implementations that support P oh I have to have some way of allowing the operator to enable or disable the use of the P oh I TLV when cryptographic authentication is in use note that if you\u0027re not using cryptographic authentication you can go back to the base 10 589 rules say well okay anybody should be accepting a purge "
  },
  {
    "startTime": "01:34:37",
    "text": "regardless of the TLV content next slide so what are the POA implementation issues again not everybody in the network may support p oh I so you need some control to enable the use of py when you\u0027re using cryptographic authentication if what what we then did as part of the this.p oh I support we added the possibility of other tlvs perhaps being allowed in purchase in the future and in fact that has happened we now have 40 of these that are allowed in purchase and that\u0027s why there\u0027s a column in the code points registry that I showed on the first slide and which says hey this TLV is allowed in aperture it\u0027s not allowed in the purge again in order to be extensible if I add a new TLV that\u0027s allowed in a purge but you somebody else out there has an older implementation and they don\u0027t understand what that TLV is I could have an interoperability problem so if I implement Bo I support I have to do it in such a way that I can say okay there\u0027s tlvs that I know about and there\u0027s still these that were not defined when I wrote my implementation and I don\u0027t know about though the ones that I know about I can say based upon the state of the registry when I wrote my implementation this is allowed in a in a purge or it\u0027s not a lot in a purge to tell these that get defined later my implementation doesn\u0027t understand them I cannot predict whether they\u0027re allowed or not I have to ignore them when I receive a perch and next slide is an example of the interoperability problems that happen with purchase I think maybe in the interest of time will not go through the steps again this is this draft is written for clarification there are no protocol changes introduced by any of what the draft talks about this is just trying to make things clearer and especially so because we have had interoperability issues in the field and we were just trying to make sure that it\u0027s less likely to happen 20p juniper is the last thanks for doing the dirty laundry again we shall be not in need of those drafts it\u0027s the second one you\u0027re bringing right highly encouraged absolutely for adoption if you need any help call toship we\u0027re here thanks that\u0027s that\u0027s on my mind Tony in fact just interrupts truck great work very much needed and hopefully foundation for really security framework that could be a formal reference any time you write new draft here and our friend from security asked what happens when I\u0027ve got four more references this tells us "
  },
  {
    "startTime": "01:37:39",
    "text": "what happens when the great stuff and looking forward to OSPF as well okay thank you one of the but one of the reason one of the reasons for writing this was so that new drafts would not have to repeat this content over and over and over just references Michael Abramson having been bitten by this kind of interest ten years ago without v6 enablement where it would drop the entire you know a package just because it\u0027s so and I could be sixty le and there yeah please I would like that not to happen again I had to spin up a second I GP to do my fifty six in a row lot for two years okay looks like we have a lot of plus ones and this being great uh from juniper so I have a question on the allowing unknown T always in the purge so are you suggesting that an implementation that does not understand a TLV in the purge it sure if it\u0027s authenticated you should accept it or are you suggesting any other T and we should also be accepted I\u0027m saying when you write you have version n of your implementation at that point in time you understand some set of tlvs a new TLV can be introduced after your implementation was written clearly you don\u0027t know whether that TLV is allowed in the purge or not because you just don\u0027t understand it so you have to accept it what if TLV that I understand has now is being allowed in there\u0027s a new draft that allows that TLV in the purge for some reason okay then I think that\u0027s another we\u0027re introducing a new backwards compatibility problem and we would have to if we wrote such a graphic you cannot see on agreed I may even do faster okay then it\u0027s allowed yes it\u0027s a lot okay so this thing actually you know is uh I don\u0027t want to go there okay I don\u0027t want to go that so this idea actually you know is something you know what I believe is relatively simple and I know if you look into it it\u0027s kind of surprising it never popped up before because you know we see like a lot of proposals to you know improve all of the floating things to improve our convergence time but there is like another component you know with a cheapy routing which can really really speed up convergence significantly and if you look into how the fluting actually is operated in the way our IGP is actually do the pudding so they actually you know "
  },
  {
    "startTime": "01:40:40",
    "text": "take care of the packet pacing it take care of reliability retransmission and so onwards you know and it actually has been unchanged since you know the original you know the technology itself now the way technology progressed you know we now have TCP and it sort of made us wonder like okay you know why do we actually first want to you know improve our floating topologies but not really look into like you know how route it is do the floating of control information between the routers themselves so we said okay maybe that\u0027s not look into TCP and actually you know external use an outsource all of the floating stuff into TCP let ECB take care of the retransmission and the packet pacing and then reliability and all those kind of things so that\u0027s what we\u0027re doing it so you know so the proposal what we have here is FRA as yes you know I\u0027m pretty sure we can do the same thing for SPF but you know at this point in time you know we believe at least you know let\u0027s look at ICS first so in essence what it is about here is indeed you know between two rappers to exchange LSPs and to use TCP as a communication channel for that now to actually do that the two routers need to agree between each other that they actually support you know exchanging you know all of the you know floating information over the TCP session itself so we actually we define like a new TLD for that in the IOH now at the same time because we also believe BGP is like ultra cool and it also uses TCP and and it\u0027s a TCP byte stream we also in BGP is using some sort of like I can see in our synchronization market header you know in the TCP we actually said like you know if we go down the road of using TCP for our control information we should do the same thing as what we have in BGP so we\u0027re gonna be defining also like a small marker to have synchronization in the byte stream very similar to the way beach is using it so if you look into the different scaling factors of is a yes yeah so the first thing we have is like a cave you know each router that\u0027s like a number of adjacency like neighboring routers we cannot really do that much about it to reduce it the second thing we can look at you know to improve scalability is you know how do we deal with flooding so if we improve that then we actually we improve you know our scaling you know capabilities here so one way is to actually you know work upon new flutings apologies in other ways actually you know we look into how flooding itself is done and then the third thing what we can actually look at it\u0027s like you know in is how SPF is done right now we have the extra text rise you know quite okay it\u0027s not too complex and it\u0027s probably the best we can do without creating too much additional complexity so if you look into the middle point here so what are the different scaling limitations here so looking into it from a historical perspective yeah so something what we have is our packet pacing and the true put itself so initially when iOS was created between two control plane packets there must be like about "
  },
  {
    "startTime": "01:43:40",
    "text": "like 30 milliseconds and the reason is is because you know in the older implementations if you could send too much packets at once it may actually overload your neighbor and he actually may lose packets and you know all bad things kind of happen now with those 13 milliseconds it also means that if you have like a really big network let\u0027s say about like a thousand notes yeah that actually has like quite an impact because a thousand notes will result in approximately you know for a full sink going from zero to everything in about like thirty seconds because we have this 30 milliseconds packets between the LSPs that\u0027s a lot of time we can do much faster than that because why do we have those 30 milliseconds it\u0027s because of the older implementations of iOS in the way it was done so the other element here is like the reliable floating on point-to-point interfaces so each you know LSP needs to be act on a point-to-point so that actually comes with like you know acting the packet itself and some associated timers you know with it and then the third element here it\u0027s like a Kady and the reliability of the complete sequence number of packets so if your point to point interface and you come up you know with the two routers the ease exchange you know the link state databases using CNN piece in each years and a B we actually we can stuff in like about like 91 you know different you know LSP descriptors if you would lose one it actually automatically you know multiplies itself by you know 91 LSP is being exchanged between each other that\u0027s quite significant so in that\u0027s actually why we say okay you know why not do this exchange instead of like let\u0027s just take care of it you know set up a TCP session and actually you know push all of the LS piece into that one now of course if you want to set up a TCP session you need to know the IP addresses to be used v4 v6 and you need to know the port numbers on which each of the routers actually is you know listening so that is something you can actually signal between each other by you know by you know creating or adding like a new TLV in the is H in which actually have like different and old TVs subdial vid itself for the port number before addresses address or addresses and if he seeks address or addresses and right now at this point in time we think that is sufficient at this inner artist at this moment and again also becomes TCP uses a byte stream and cause we like BGP you know we gonna put like a market in there you know which we have preset in our draft so the new hatreds the new behavior itself is to actually establish the floating so in essence you know when the link actually comes up they actually exchanged is ages and each router will sort of like look for this new TLV to figure out the IP addresses you know what is used it to also figure out that it\u0027s a B port number the router with the lowest router ID will actually initiate TCP session and set it up so from the moment TCP session is set up you actually will exchange only one time the NIH over the TCP session itself to make "
  },
  {
    "startTime": "01:46:41",
    "text": "sure that no the guy you see on the other side is actually the guy you\u0027re thinking yes so you can authenticate and make sure about that so only one time you will send you know the ionisation bar it the for the rest on the normal you know on the normal link between the two routers in October TCP so the neighbors ship and our establishment is still being done by exchanging iOS age messages on the link itself so nothing really you know changes from that perspective so it all stays the same which is very good because if you have like a control plane failover or one of the ends you don\u0027t want that the TCP session itself creates additional you know dynamics and in our neighbor ship complexity you know from from where we are that is all you know described pretty well you know in in our draft so the nice thing is you know when you do this now what will you win so in essence what you win is what you see it on the bottom and it\u0027s like no more retransmissions of LSPs or verifications you know using sequence number of packets because everything now is in the hands of TCP and that is really nice you don\u0027t have those 30 milliseconds anymore you can actually send us quickly as possible as fast as your neighbor it actually can accept and TCP will take care of the windowing and about you know everything else and then of course you know your you know we also have like you know new behavior like you know during you know the you know during the footing itself so a few small things actually change but in essence nothing really you know super dramatic so if you receive an LSP you know I need the same version the rather really doesn\u0027t do anything at all if you actually receive an older version of an LSP then basically what you do is it like this Center out in Mississippi itself and you return like a new aerial speed towards appear if you receive like a new recipe then you actually you know usually you floated to you know to do everywhere else yes this was for the end of presentation from the Java room so yeah we got two more presentations of you in the end minute yeah let\u0027s take this to the discussion of this okay okay yeah kind of finished kind of like so you know some some additional plans and considerations so better the interest of time I\u0027m gonna I\u0027m gonna skip them the only thing what I want is I think the drafts right now is in a reasonable shape and it would be nice to see you know if it can be actually you know adopted to the working group yes or no it just came out I know I know but why don\u0027t you why don\u0027t you start a discussion on the mailing list if you have you know we\u0027re gonna take the next slide how many people are in it at the time there\u0027s one thing that I have to say I\u0027m gonna check into it more there is a Cisco provisional patent that has TCP flooding of the iGPS as a component of it I\u0027m not sure I\u0027m gonna check with "
  },
  {
    "startTime": "01:49:41",
    "text": "are illegal to see if it\u0027s applicable or not doesn\u0027t go to it doesn\u0027t go into this level of detail but I\u0027ll check on that can we get the presentation up you want to see a grope for presentation I\u0027ll leave it to you okay yeah I think two minutes should be in Tacoma curses so this draft has been out there and presented a number of times it\u0027s more or less stable at this point and just a couple of changes which were added in the recent update for more clarification one of it was clarifying that is our algorithm TLB which was there in the ISS extensions for asada and pls are also applicable here is our v6 and there were some function behavior points and dot DX and d t6 which were included in the draft but there was no use case documentation for what for what they are used for and so we have removed that in this version so really that\u0027s the only change the next step you know there are implementations of this draft already out there and we would like to ask for working group adoption this one how many you read it should we start a discussion if it\u0027s ready for adoption I think we could just do the adoption and people can object right thanks thanks great every time it jerks like that back to burrow yeah apologize for this but I figured out is we were using the agenda and not meeting materials and then anything that wasn\u0027t in PDF format wasn\u0027t on the agenda so we had to go to meeting materials to get all the PowerPoint presentations yeah yes I Ching Wu was supposed to give this presentation but due to net mod clash I\u0027m standing in for him in the interest of time I\u0027ll try to make this as quickly as possible next slide please technology okay good so this is San ID to basically provide discovery of secure pcs capable of supporting things like TCP AO TLS TCP md5 so that the path computation clients PCC can send and "
  },
  {
    "startTime": "01:52:42",
    "text": "receive information related to path computations securely it\u0027s a very simple document essentially we have one sub TLV with three options there they are specifically advertising what type of security the PC will support so essentially this is just a sub TLB for the IGP and we would like the working group to look at the document it\u0027s a relatively recent document I think we published it probably about six weeks ago I think ACS already made a comment that if we use TCP ao we will have to provide some shared secret information that\u0027s not currently in the document there are some your potential security risks with that that we need to discuss or at least identify and disclose in the document and yeah I think that\u0027s it really I think what we talked about was just using like an essay ID there\u0027s we\u0027re not talking about putting the keys in there you know this is coming from you know PCE uses a uses that I GPS as a tool this has qualify as is and OSPF and they are coming and saying that this is a good thing to do I can\u0027t see any reason why we wouldn\u0027t have topped it speaking as chair yeah I mean this important so there\u0027s some precedence here as well because there are sort of numerous PC capabilities that are advertised through the IGP okay back when the PCE working group first established they came first OSPF and then i Esaias and we have the drafts that are referenced in this document ah refer to that and they\u0027re just extending more bits and then we\u0027ll have this key ID for TCP ILO as well so okay well I was just gonna say if there\u0027s no more comments on this there were two people that wanted to talk about TCP oh yeah yeah so we do have five minutes you guys want to bring your comments about the TCP Tony Lee still at Arista so I would like to say that I support this work I think it\u0027s very good and I think we should consider using quick instead of TCP this is because slow start actually is going to be a factor and I apologize because I jumped on your comment taking it to the list so I already sent it that\u0027s the list okay that\u0027s good because did you have something from jabber I\u0027m the TCP okay through dick toriel eat it we finished on time and we\u0027re gonna be back here at 28 the stuff start promptly at 20 after "
  },
  {
    "startTime": "01:55:44",
    "text": "yeah on the dot 11:20 I think I think looking at the presentations I don\u0027t think we should be as rushed as we were during the first two hours okay see you back here yeah "
  }
]