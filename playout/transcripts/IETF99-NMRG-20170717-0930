[
  {
    "startTime": "00:03:15",
    "text": "okay good morning and we are organizing this workshop here on measurement based for ready the six so we started originally with looking only at NetFlow wall or maybe six space and we sill for two year four to the upper two years we extended it to general measurement base so this is a we call it a rug shop so we have six speakers giving insight in the current work on using networking right few measurements for network management and of course this is not a conference yet so we hope that there will be a lot of interaction we have asks its because to give enough time for some questions and for discussions first of all I want to show you this knot slide here which you probably already know but oh I got some one I got from the annuity chairs from the energy okay for our agenda is yeah come to be a black home speak with our speech would be I mean this two and half hours are not so but we plan to have a me will have sweet presentations before the break then we make a break raishin we choose ourselves and after that three other presentations and something I pop up tell you so this workshop is organized by me today and energy okay you know all the quests I I want one more thing there is lava energy meeting on Thursday on different topic so if you are interested of this joint "
  },
  {
    "startTime": "00:06:16",
    "text": "though so I would I would suggest that we start this course people who is deeply from penalty for sin so in that long trip so good morning everyone I\u0027m Orchestra Kelly from says neither Brunel University of Technology and the PhD student and I\u0027m here to speak about our attempt to accelerate IDs systems for high-speed networks as I as I already mentioned I\u0027m from chestnut more specifically so as I already mention up from sasnett Czech national religion Education Network most Bisset more specifically I work for my broader group and our main goal is to monitor the perimeter of our network and to guarded perimeter from external or internal attacks that we can detect from monitoring these these lines so we have vast tool set to do so from Network probes so the data acquisition from metro grinds through collection detection storage visualization and remote configuration of the whole in this presentation I want to speak about network probes and how we collect date on how we analyze the packets so the standard approach to monitoring probes is you have a network interface card that provide packet capture and on those capture packets you do some software processing on a CPU of a host server this is the standard approach we have an accelerated approach when the probe itself has a accelerator in FPGA and each accelerator can somehow eight the processing of the packet so the software performs only very specific or very advanced processing tasks and the card can accelerate the total throughput of the system we call this concepts of 35 "
  },
  {
    "startTime": "00:09:16",
    "text": "monitoring the concept is here on the right you have your processing applications your flow exporter that that exports NetFlow data in IP fix or net four formats it receives data from the card and in the card the card received packets from the line and don\u0027t send only whole packets to the software applications but the software applications can instruct the card to do some processing it can either parse the packets and send only headers instead of whole packets or we have flow cash in the hardware so some kind of net flow records or aggregated records for flow can be also sent to the software instead of whole packets and as I said this is all controlled by the application so it\u0027s flexible depending on application you can have different requirements how this data should be pre-processed so we measured the achievable speed ups on various network monitoring tasks and we proved to first under a net flow we have like 5 times beta for application layer processing mainly HTTP processing we have speed up to like 3 times compared to the standard monitoring probe but when the software need to process every packet we already publish those results at infocomm conference and in our three fully transactions own computers journal so now the question is can we use this system this software-defined monitoring system to accelerate also IDs so not only network monitoring but IDs so our assumptions are that a current IDs systems are not fast enough for current high speed networks also that before discarding method that they use basically blind discarding when you have an input buffer and if the ideas is not fast enough these buffers start to blindly lose packets is not good for the detections of IDs and informed discarding can be better and perform better so another assumption is that usually the attacks or the threats are present in the initial packets so usually you don\u0027t find a threat insider in the middle of a let\u0027s say long video stream but somewhere in the beginning of each network connection so in the last assumption is the heavy tail character of flow sizes of network connection sizes when you have a very few heavy flows that carry mate majority of all the network traffic so by dropping only the middle packets of these few heavy flows you can get a pretty decent reduction of total network traffic that is processed by the CPU so these are the assumptions using SDM basically to "
  },
  {
    "startTime": "00:12:18",
    "text": "accelerate IDs we use as as a pre-filter so we don\u0027t need a flow kitchen hardware our application is IDs but the system stays the same basically so it\u0027s only a different use case so we don\u0027t need to modify the SDM concept we just use it for new use case so our test setup was we have two servers sorry we have a traffic generator with a large pickup files on an SSD drive which we replayed but using TCP reply over a standard network interface card these were these are pickups collected from our network so that it\u0027s a real traffic it\u0027s not synthetic it\u0027s real traffic so the reply traffic was then delivered to our acceleration card in that card we have an SDM firmware so the hardware acceleration part that\u0027s for valid packets - IDs software and the software instructed the SDM to do the pre filtering we tested to idea systems su ricotta and snort the testing server just the quick stats we\u0027ve got to physical Intel processor V with total of 16 16 cores at 2.6 gigahertz a lot of RAM and of course our acceleration card with Sdn firmware as I already mentioned so with the acceleration with the accelerator on the FPGA on the cart so for some results first of all it\u0027s snort over a standard bleep backup interface now to describe the graphs on the x-axis of both we have a speed of the input link so here it\u0027s from few few hundred megabyte bits per second to do gigabit per second and on the higher graph we\u0027ve got buffer overflow percentage so percentage of lost blindly lost packets on the input of the ideas system due to its lack of performance on even speed and on the lower graph we have number of detected events on that speed the recap was the same so the number of detective events should be same if the detection is hundred percent correct but due to we can see from the graph that due to blind lost of decades the detection the number of detective events is decreasing also so if we take a look the Green Line is the ideas snort without our acceleration so pretty quickly even at the two hundred and fifty megabits per second the drop rate starts to rise and therefore the detection rate drops using our accelerator the drop is around zero up till three times larger speed so up till "
  },
  {
    "startTime": "00:15:18",
    "text": "750 megabits per second and then start to slowly rising as well so the detection rate is better then without SDM so this is what we want to achieve better detection rate so the ideas need to process only packets that are interesting and therefore can detect more threads another similar graphs but this time for suricate are already picked up we can see the same trend basically without SDM the drop rate starts very quickly with SDM the drop rate is not not so significant and also the detected number of detected thread is not declining so rapidly so we can we can use this ideas on even higher speeds with more precise detection rates now the leap back up has a problem with performance that is known so we try to use our our own driver instead of lip backup which bypass the kernel do zero memory copy and so on so basically the car delivers packets directly to the to the application to the in this in this case to the sericata ids and the results are better the performance is now in a in terms of gigabits per second and again we can see without the acceleration the drop rates start to increase very quickly and the detection rate starts to drop according and with SDM sorry with SDM we\u0027ve got better results we\u0027ve got more detective threats more detective events even at higher speeds and the last graph is basically just a surrogate are the same IDs but with smaller rule rule set for the previous test we use all the rules that are available for the Sarika tights like 13,000 rules but for this test we reduce it only to know their detection so the number of rules was only 1,000 or something like that and the performance is even better even more than 10 gigabit per second up to 20 and we can see basically the same trend as the drop rate is increasing the detection rate is decreasing and again with SDM we\u0027ve got better better performance better detection right so to summarize ideas can be accelerated using our SDM system with reduction of packet loss we increase the accuracy of detection so from the other side the SDM is applicable not only to network monitoring but also to network security specifically IDs acceleration and we are preparing in another infocomm paper about this duration so this was just a parallel preliminary results for this paper so thank you for your attention so "
  },
  {
    "startTime": "00:18:22",
    "text": "any questions please go to the microphone and present yourself and your association no this is from Ethernet and I signed us look you drop the middle packets yes so tell how many packets do you need and is it very we have a variable threshold on which packet which we start to drop and it\u0027s usually around like first 20 packets are analyzed and then we start to drop or 30 or 10 but usually it\u0027s between 20 and 30 okay the decobray around with this parameter and that\u0027s it if we play around basically after 20 or 30 the number of drop packets is basically the declining but the number of detective events is staying the same okay okay so but it does download with a bunch of files yes and the second file is maybe with malware then yeah maybe but but as I said we try to play with the parameters and look at the graph or look at the data okay the results and we kind of wasn\u0027t able to see that kind of behavior in our later okay so it\u0027s okay no tell is it another detection is it more like web traffic wave detective or is it mostly large large downloads where this effect is most of the traffic on our network is HTTP or HTTPS so it\u0027s usually read traffic websites and good morning thanks for the presentation our chunk of a check of speaking for purity what you\u0027ve just mentioned that a lot of traffic network is HTTP what does the resolution has to do with encrypted patterns I don\u0027t actually know the insides of the both tested IDs so I don\u0027t know if they do some or what kind of analysis they do we just you know take take those ideas and as per snort it doesn\u0027t support going to the TLS session but I believe they\u0027re amateurs and ciphers I think that some some threats can be detected also under the parameters of this traffic mistaken okay okay see Thanks I have a question from from remote he "
  },
  {
    "startTime": "00:21:22",
    "text": "was asking how easy it is to program programs offering API or well I mentioned the Snowden\u0027s ricotta snort has a limited limited support of some extensions that\u0027s why we only tested it so far with withstand a really backup interface but for sericata you can implement your own plugins basically input plugins or some different kind of plugins that can take the data for you and do some reprocessing with them so using the plugins using the API that is already in there we was able to extend the system with SDM acceleration let\u0027s say you are you are a few own ideas how hard would it be to adapt it well our SDM system has its own API so basically you just have to call a function to connect to SDM and then call a function like I don\u0027t like this flow drop it for me for each flow that you don\u0027t want and that\u0027s all any other question okay thank you again [Applause] then I would like to ask the next speaker to come it\u0027s abacavir Foreman here you mean why\u0027d I go to one of you take care of the jabber rule and see whether there are questions coming up from remote participants everybody you left I I find it with my Windows PC but it\u0027s hopeless [Music] [Music] the work is about topological analysis and visualization of networking data where we use the when we have a case study which was the dark netra "
  },
  {
    "startTime": "00:24:27",
    "text": "presentation first ever-present motivation of the work second divide reasons and background and related work the methodology that we applied in this work some experimental results regarding the scanning activity and did those DVDs darknet and the finally conclusion future worked so the the context of the work is where we are focusing the network monitoring data which is usually used for security forensics and anomaly detection the goal is to notify malicious activities regarding traffic patterns behind that and the alerts have triggered this Masha\u0027s activity we focus on specific but this modality which it ibf that work background radiation basically data could have this data is coming from networking scopes like net usually it\u0027s noisy traffic but important source of forensics data we have many information that we collect thorough list at work disk up Santa and magnets the data is will consider a volume and wide range of services and sources the extraction of structure and compose of this data is difficult because it\u0027s noisy and then complete information we have all the packets we are with not closed because it\u0027s passive so we just receive packets from the internet so they usually the GAO learn to study this kind of traffic to predict and model internet malicious activities basically large-scale scallop order or the dose the I don\u0027t see the night observe ourselves so to show an example of like net so usually it\u0027s a perfect sound and you IP addresses we haven\u0027t serves behind it just that idea that net so there is no productive traffic knowledge made traffic we are in our lab we will stink like net so we select on and coming back pockets without to play from there we show this example use of that\u0027s so the Otakon will control the bikinis we start sending some packets and an IP address connector to connect all the packets and then we are able to visualize them and so the our goal is to which is usually nosy but contains some useful information regarding large-scale scanning or that\u0027s a unite of self "
  },
  {
    "startTime": "00:27:31",
    "text": "the problem that we addressed in this work was - what are the compounds of the patterns of the darknet traffic and how to filter this traffic to extract types formation with basically to attract did those activities and to obstruct the scanning get me some work was done before many more that didn\u0027t under guarding this issue mainly to characterize internet background traffic the first work was done by paying the oil for where the character is a ideal traffic become basically the composition of the observed protocols and ports in this traffic another work was done by more efforts in 2006 where they studied the probability to observe it was attacks within military scope and withdraw and co-authored in 2010 made another world to characterize internet background traffic over multiple darknets extract environment features and level of pollution of the station of the addresses this is the first bug report regarding military characterizations idea more works where they focus upon BACnet the data basically the world to first first care about identity and other work regarding DNS queries in 2015 by absolute the same authors regarding facilitation was that basically the way we find some tools regarding mainly in a twist which was like net data from 3d scatter plots or some 3d visualization tools to monitor and visualize historic network is little bit different because we applied new technique this technique is based on topological topological data analysis its TBA or today it\u0027s a branch of mathematics where the goal is to study high dimensional and complex data by extracting invariably emetics feature from this data to discover relationships and patterns so the goal is to study large-scale data multi-dimensional look stacked ovarian agility and money the PDA has some fundamental properties very interesting which are coordinate which coordinate invites some tennis that does not depend on coordinate system analyze which our case interesting because we can analyze data connected from different platforms it is the formation of ice so we so it is less and insensitive to noisy even the data is noisy there is no problem with this beta we can apply to DA and it is able to handle approximate data and "
  },
  {
    "startTime": "00:30:32",
    "text": "the third form that we obtained using PDA the compressive version of the day press the presentation so basically will it take so here our example is not related to that working but we take CD shape which is Rabbitohs first alpha and here we have as input data a 3d point cloud which with many many number of points in this case we used the photonic function which is example X and recipe so this function will allow us to add another dimension to the data and this dimension will filter the data its filtering function they will explain later switcher and the output will be in at work paragraph 18 edges that represents drop so this is the polished beautiful representation of this 3d chain and the colors represents the filtering parts we filter in here and the colors of the filtering function applied to the points so this new part but the other part this is the last part of the object but about the top of the ears of the Yap so this is the main idea so here we have 3d shape and we want to apply the same technique for the network packets that we collected from exactly so they to apply to be a our use case so we extracted some noisy traffic monitoring data from the darknet that used our lap and we apply the one technique from the DDA which is the Moffatt algorithm the algorithm as explained before will allow us to obtain this particular graph this graph represents the data instead of linear many points so the the processing step so we have the darknet where we extract some features related to the packets basically the issues the address destination of the address the ports and TV stuff compute the distance between the packet filter function same as the eccentricity for example but we can use another one split this function so we "
  },
  {
    "startTime": "00:33:33",
    "text": "speed the values of friction using many intervals car history technique like the beasts can Lester each data which are combined this graph which represents representation so this is the details of the mapper algorithm so the input is the feature vector it\u0027s contained the feature of the packets from the back yet basically in this case we used that the timestamp the source destination IP address and the parts of the protocol TCP parameters of the algorithm are the ones that we used to split the values for the filter fraction percentage over this afterwards because we can define can you define a overlap between the other ones which represent something like azuma when we walk to zoom the the graph they will obtain later using this underneath in this case little function which is the identity so from but the technique is really flexible so can use and other types of reflection the data our data from the trench and the package for future packets this OVA deployed over the intervals that we define on the filtering function and then last but each using the bisque and clustering technically we can use another one but in this case we used the bisque and what each vertex is a pastor of a be the cluster the containers using to the discard and LG represents a non-empty intersection between clusters so good bye when we apply this technique we obtain the graph where each vertex is a cluster obtained from the discard and the link between them means that there is no ambition no update per section this technique using the Nabisco so each each hunter viola a function of its points projected on this interval we applied the be scan which requires two parameter no but I need you to discover just any technique many lips alone in the same cluster number of neighbors that the point you have to be considered as Augusta and the distance function that we use on this world is the difference for time stamps for the time stamp which we take the difference and IP destination the "
  },
  {
    "startTime": "00:36:36",
    "text": "difference and for the parts and the protocols use the quality which means equal or not we apply that this technique over 6 for example 1000 like it\u0027s this is the parameter and we extracted some patterns for example this that we expected result scanning activities but we check if this money and we found that business can get and the success active access some sparse cuts and some randomized and those discounts but then we applied the Technic in some day some scanning activities probably like that and we applied also Sirica tap on the same data and we observe that we are able more than sericata only five so first can I get DVD but for scanning activities using this list the parameters are estimated using an error method so we have tried when we find something interesting and but when we find them it remains them so we can apply them more data sets and we find the another example of activity that detective is regarding Windows so we apply this some would it be the UDP packets DNS you use these parameters epsilon some others because to extract them directly from the dock game and what\u0027s the destination and the approach so we for example for one thanks yes than one second to analyze depth using the map Berger agrees to analyze three millions of packets that we received for one day requires eleven eleven minutes so which is reasonable so we can analyze whole day one specific attacker sent today "
  },
  {
    "startTime": "00:39:44",
    "text": "it\u0027s two minutes so we can know exactly what the specific article sound throughout the darknet and on that idea is in short type but we need to increase some this performance because here we are using a single machine so we can use more computing power and also paralyze the tool enhance the performance of the analysis so as a conclusion and future work so in this work we presented this new technique that we are using to extract potatoes from a darknet traffic basically this technique used to function the first one is this filter function who represent one or more one or more dimension dimensions to filter this data and apply the number of intervals and the never an overlap from our recent advance and also a partial clustering using the Biskind technique the goal is to extract some activities basically scanning activities or DDoS activities and as a future role we want to include more packet targets and applied this to net flow for example not only in the packets like that and extract more activities and action and I signed up to have him so why didn\u0027t you use statistical feature extraction like principal component analysis our singular value decomposition instead of the day usually question the first point that we want to validate this thing this is the this work and we know that TBI was applied different data and 3d shapes and the goal was to apply this technique very day how to apply decent qualitative is technical different types of data basically data from networking and we want to know more on this variety how basically it\u0027s cluster data but it is "
  },
  {
    "startTime": "00:42:44",
    "text": "more because we clustering in each interval it\u0027s not the global clustering so also this one for the reason that we want to validate and obtain the good results but I agree that we need to compare this to other peoples my accessibility techniques what as we have even can use or just discard this is one what one of the reason why we applied the DBA to know the validity another question is are the datasets available datasets is most of them I collect from our deck depth area to access the data we have to sign but so it is a possibility but thanks Jochen Sabini technically universe between Justin oh so dark in this case is used by dark space is that is used in literature correctly and if you search about dark space and you will find that Qaeda is a class a network is doing tasks talks this research there\u0027s a lot a lot of work yes just one point yeah the direct net is not the the GAO voice this is why we have the term darks yes yes yes so it\u0027s mainly pills thank you my uncle is on it so you look at the and address space the top space what do you think if you use other address space and apply the technique to it like services and lines I think we can this is one of the future work that we want to do is to apply the same technique for I mean protective networks the packets or even that flows of looks track some some patterns that will be abstract some services but we need to find the good parameters for the ability or extract as some scanning activities target replies the network so the technique is opening we can apply this I could just imagine that you you find traffic patterns in production traffic which are closed the things you discover now which is occupied or which is asked by many "
  },
  {
    "startTime": "00:45:44",
    "text": "clients then you have something that he does scenario so it could be you may end up in more false positives I guess yes but then this in this case for this specific world we haven\u0027t we haven\u0027t in average about we check it manually that this is for the doors scanning activities but if you apply this to real traffic liability item and then we I can check if this force protection but here we received this now exactly what kind so yes this case the validation photographer got space it\u0027s quite simple the validation because there will be no katachi and isolated events and if you have traffic it\u0027s maybe a small much more complicated and complex to isolate but the check yeah the comment is faster this is this is an ongoing work we\u0027re working on this yes goodbye any other questions no okay thank you very much for the break Michelle Oh Santos right and if I wanna security form stimulus provide but one question is the blue shade is still circulating everybody writes in the name okay okay morning my name is Michele Santos I am a professor in Brazil and the objective of this presentation is talking about some as the end placement challenges so probably everybody here everybody heard about at the end the "
  },
  {
    "startTime": "00:48:46",
    "text": "objective is not it a class about a.cian but he a briefing reveal about us and it\u0027s important to have in mind that we have a separation of the photo plane in the data plane in stage we have any cheat codes as in controller and it\u0027s a centralized Inglot in a nutshell Sdn is a paradigm that the cop of the photo plane from the data plane so we have this famous figure in a summary we have three layers the network elements the data plane the Kanto Plain Jane controller means software\u0027s like parts not good light of the life and so on and some Sdn applications that will run over the controller so we need to have a different view about how to treat scenarios of optimization when we take when we think about Sdn we have now a single point of failure ease and we needed to think about dependability and knowledge in a different way we will have overhead mainly in the SDN controller and we need to think in a different way about planning and provision and we have some problems like the flows at a time flows at a time and we need to think about well place the s can control it in the best way because probably probably most of the people here know that but when you have a switch and a new flow arrived in the switch if you don\u0027t have that specific girl to this new flow we need to consult the Assam control and it took some time some additional time so we have a lot research question related to this scenario for example what is the best placement position for each Sdn controller what is the curse of each controller what should it be the capacity of each controller what should it be the capacity of its controller how to manage the rules and the network policies in a centralized way how to deploy virtual light as in so how to categorize this problem in each way we propose in this presentation and probably draft three men placement problems about Sdn as in controller placement problem has been ruled placement problem has been hypervisor placement problem I was trash-talk talking about Sen controller placement problem it\u0027s a famous problem problem and in summary a "
  },
  {
    "startTime": "00:51:46",
    "text": "steam controller and placement problem all CPP deals if the allocation of a theme in trollese in a network it seems easy question but it\u0027s not when we think about this problem we need to decide how many controllers are required to support a network where to place each Sdn controller and what is the controller demand in other words in this trigger in the right side we can see the controller 1 and we have a lot of switches switches assigning it to this controller and it\u0027s Adam and so when we think about optimization and the objective function it\u0027s not polynomial problem it\u0027s an np-hard problem and we have several papers about this problem like if we quick search for Ashley and control placement problem in scholar Google we can find hundreds of papers about this problem one of them like in the first result has more than four hundred citations and it\u0027s not a new problem like this paper is from 2012 so the second problem is as the SDN roll placement problem it seems similar to the last problem but it\u0027s not when we have applications running over the controller and when I talk that it\u0027s not one application but several occasions we needed to run the conflicts we needed to to the science the best path and it seems ok old problem but you think about that with a simple with same controller with at the end paradigm we can think about how to do the load balance at the same time save image turn off some links and aggregating some flows and a specific link and everything in our we have time it\u0027s not a user problem that you\u0027re solving a real time when you have a huge network and several nodes so we have different types of rules like access control world policies track shaping thirteen-year load balancing and we need to do everything in a real-time and have the conflicts and policies so what do you think about this problem like optimization problem and use some techniques like integer linear program of some areas so "
  },
  {
    "startTime": "00:54:47",
    "text": "the last problem is Sdn hypervisor placement problem in summary hypervisor placement solutions deals is how men hypervisor instance are needed and deposition it\u0027s very similar to the SDN controller placement problem the first problem that I talked to two minutes ago so here is an example with a visor or I can talk about slow-mo we have a hypervisor and the hypervisor will create abstraction for each controller in the infrastructure like you we can have Knox and open the light and like you walk in parallel oh and it\u0027s similar to the controller placement problem but the placement of the hypervisor demands detailed investigation because some question will arise like wire to the fly the Sdn hypervisor we need to think about hypervisor reliability and fault tolerance because we will have another layer of software and the Skibo hypervisor design and you okay I talk to you about some problem in there and I tried to define some problems about relatedly to at the end but the question is how to solve these problems what is the best technique to solve these problems and the answer is its there is not a best technique because it will be its depend of the objective and the complexity of the network how many nodes do you have and what how many model so in summary we have two categories two categories exactly resolution methods that give as optimal solutions and we have a time consume well a high time McCracken some examples technically is Brenton about dynamic program and linear and entry program we have here a trade-off because we have exact methods to solve these problems but to retake time on the other hand we have a rich fish with quads ultimate solution reasonable competition times like some techniques like Jeanette Jeanette Jeanette algorithms simulated annealing and ant colony optimization so one normal question that arrives from this presentation is okay I have a iesson placement problem what is the best techniques to solve this problem that\u0027s not the best here is the "
  },
  {
    "startTime": "00:57:48",
    "text": "example we have a paper published in the pupil I communication error and it\u0027s paid this paper is from 2012 and to use a linear program to solve this problem we have a model and here we have another paper and this paper dynamics controller provision and software-defined networks and they\u0027re all of autos proposed the risk is Bayes it simulated annealing for the same problem but in this case we have dynamic placement so we need to have quick solution we need generate a quick solution most in real time because it\u0027s a dynamic I analyzed the load in the network and decides where to put my to create Sdn controller dynamic so the proposes creates an informational information of their FG didn\u0027t find at the emplacement problems challenge and solution directions and that is thank you okay so this was a presentation quite different from the Odyssey also represented solutions while you are presenting a problem so maybe the really good idea to from question offer more for what do you think is anything missing we do the efforts on some feedback to give some hints where to how to start and so on using anything how how the problem has been looked at what what what you see is is it a good idea to look to look at the problem with the three placement placement of the control of his from I ask the audience this is a good idea is there to handle the problem often you know where it\u0027s from it\u0027s really quite interesting because actually yes this is a this is a Florida Sdn lesson but this is the sole program we find in in other topics related to network management for instance in my company we work in optimizing you know that\u0027s a monitoring infrastructure based on containers which is also you have to "
  },
  {
    "startTime": "01:00:49",
    "text": "do quite the same thing you have to optimize the way you locate resources and in place them and this is also problem for I guess you know indebted centers with VM so there is a lot of problems with the same background optimization issue so it\u0027s great interesting to tackle such an issue in in an emerging I think yes so I\u0027m just relaying a question from Carter Schmidt um is asking how cannot work measurements help in solving problems you raised in this presentation and where the measurements should come from yep so how can network measurements help on solving the problems you raised in your presentation and where shall do you measure those it\u0027s depend help to treat the problem we can treat the problem just in an analytic way the measurement of the network can be an input in the problem and how to measure that after the solution is generated it\u0027s the end of the problem it\u0027s problem we need different treatment thanks okay more remarks or questions okay thank you we will have now a short break off around 20 minutes so we will continue 5:00 to 11:00 so you see we have a very precise time plan and then we will continue with some screen X presentations you will notice that the X representations are from from industry from from companies and institutions why the first three were from universities so let\u0027s see what will come up interesting thank you see you in 30 minutes "
  },
  {
    "startTime": "01:10:04",
    "text": "yeah "
  },
  {
    "startTime": "01:18:46",
    "text": "[Music] "
  },
  {
    "startTime": "01:26:29",
    "text": "so I come back to second half of the author workshop thanks again to Giovanni who is taking care of the Jaguar so let\u0027s start our next speaker our necks because marco de Witts from SI DN and he\u0027s gone everyone everyone in the back to okay okay better like this okay hi everyone everyone seated hey my name is Martha Fitch and I work for Italian labs and we are the R\u0026D team of the Dutch registry the country code top-level domain and I may be representing the industry as Roman said so nicely but we are enough profit organization yesterday make things clear and today I would like to talk briefly with you about our spin projects the spin project stands for a security and privacy in the Internet of Things it\u0027s a project we started recently at Pasadena labs and it\u0027s about the intent of things now I could argue with you about what the definition is of the Internet of Things we have been struggling with that internally quite a while there is a great definition of the I Triple E organization it is only 86 pages long so you can have a look at that if you like but I like the approach of rc7 452 but whatever the definition is of the internal things we all agree that there will be plenty of it there is a lot of IOT coming towards us both in our homes as well in the enterprises there are many research activities trying to estimate the growth here is one made by garden the figures may differ but everyone agrees is going to be a lot of IOT and and with that we will also see quite a number of problems because all these devices entering our networks all many of them has their limitations like for example they are cheap manufactured cheap at for security they have standard passwords hard-coded fess or it\u0027s telnet ports being open sometimes you can bypass security but just going to a direct link so in general there is this is this agreement that it\u0027s it\u0027s a bit of a mess and also a security nightmare and we have also seen evidence of this this is the famous mirai botnet that you may have heard of last year targeted against time we were particularly worried about this because Dyne is a DNS provider and we also run a DNS "
  },
  {
    "startTime": "01:29:30",
    "text": "infrastructure for Cottonelle and this attack brought many important services down such as PayPal for the finest let Romania and since we also run this DNS a DNS infrastructure for Darnell this particularly triggered us so we came together we had this little brainstorm session and we thought like what could be the solution to this problem shoot manufacturers deliver better products or should we have legislation or international policies or maybe even certification programs for devices or should we make the user more aware through the security become a feature that sells that people that there is a market demand for for security or should be empower the users give to give the user tools to to be aware of the things that are happening in this home network and give him control of what he can do within the home network so yeah we came to the conclusion that there is no silver bullets actually you have to do all of these things to solve this problem but for this spin project we decided to focus on the empowerment of home users we particularly targeted home users because we believe that in the enterprise world there\u0027s already already a lot of things happening with intrusion detection systems and stuff like that but if you look at the home using his router all ACP device or a home browser basically has is a simple manner of finding some firewalls so that\u0027s how the spin project was born spin is a research project from our lab steam and it attempts to research the user empowerment part and that means that with our spin box or spin system or spin device we hope to detect anomalies and however just to give you an example it\u0027s not normal if you refrigerator starts sending our millions of emails all over the world that\u0027s not typical behavior for a refrigerator and it\u0027s also not normal if your IP camera starts scanning for 22 or less that\u0027s unusual then what we would also like it once these anomalies are detected that they are automatically blocked so suspicious of the traffic from empty Intel things devices we hope to automatically block them and we also want to inform an average user about them I mean not every user is spec setting like you are many users who have very limited knowledge about how these things work is that we want to conform them and also give them the ability to define some sort of security preferences for network so these are the research goals for this project our main motivation for starting this "
  },
  {
    "startTime": "01:32:31",
    "text": "project because it\u0027s a little bit out of our league perhaps is because we want to protect the infrastructure of operators or DNS operators and other operators in particular of course our own infrastructure United direct benefits if if this problem gets tackled in one way or another we also have this booth of the Internet\u0027s mentality so we would also like to give users more control over their in-home Internet of Things network and by doing these things we hope to preserve the trust in the Internet and that\u0027s more or less a indirect goal and will benefit us all and also know ourselves we decided to choose for what we call a user centric approach that means we would like to allow users to easily deploy a solution and I\u0027ll get back to that later we want to protect the users privacy by keeping things local as much as possible what I mean by that is we do not want to connect to any cloud servers for to transfer all the behavior that\u0027s going on within the network because we believe that is a privacy in Figment so we want to do as much as processing on the box itself as possible and again as I said earlier we would like to allow the users and average enough affects everyone\u0027s to configure a system at 40 to certain security preferences and what we are also thinking about is to initiate some sort of collaborative initiative to work together with a group of maybe security related people to define perhaps certain security profiles think of a security profile that matches a smart TV for example a smart TV has a certain behavior and it would be art it was smart in view to sending out these emails so maybe we can define templates that a music and load into the spinning device for specific devices maybe I can important in a way maybe in a manual way but the collaborative event is also part of this project here is a brief overview of the spin concept it\u0027s hard to see I suppose but what this figure represents is partner defines that you install in your home network it has in common trafficking as outcome of traffic and it has a number of modules the three main components of this thing is are the three modules on the Left a module to visualize threatening to let the user to make it user aware of what\u0027s happening in network and also there is a control panel that it allows the user to configure certain settings there is a module that is supposed to monitor devices for our behavior and there is a "
  },
  {
    "startTime": "01:35:33",
    "text": "module to control traffic basically viola what this figure also shows is this group of people on the left and the right these are the communities feeding the system with knowledge about certain devices like for example your refrigerator all your television what happened and again as I said the processing is done locally so the device is not sending behavior of the user to a cloud service of any kind it\u0027s processed locally and hopefully we will manage to make this largely automated first this is I mean this is a provocative thing I\u0027m aware of that is tricky to have a device have things blocking automatically but maybe if the profiles are mature enough you can achieve this goal as well yeah at the moment that the spirit project is both it is both a concept and running coat we decided to write start writing running code from the start so we have at the moment of prototype running it\u0027s based on open wrt and it is also currently bundled with our belly box device that is an earlier project of a setting and labs it is this piece of hardware on the left it\u0027s a GL I net small cheap kind of home looser device and with the family box project we implemented a validating resolver on that thing with trust anchor management etc and we took that project to an able spin on it so we have announced the value box after it\u0027s been functionality and one of our architectural principles is to focus on IOT devices with a what we call a predictable behavior so we clearly distinguish between a home computer a PC or a laptop for example tablet because the behavior of such a device is pretty unpredictable I mean my behavior at my laptop is totally different from the one of my wife for example I do weird stuff she just visits a nice web sites but there is also a privacy issue info there because if I would be the manager of the spin device in my home I wouldn\u0027t even want to know what my life is due so we left that out of the equation we are focusing on IOT devices because IOT devices a regular IOT device at least the ones as we envision them they have a predictable behavior like for example the refrigerator again it\u0027s it may visit the manufacturers site maybe for a firmware update of something but it may also visit the grocery store to order something if you could notice that you\u0027re out of milk I don\u0027t know but that\u0027s about it it\u0027s not going to scan the entire internet and for 22 or do all kinds of other stuff so we envision that "
  },
  {
    "startTime": "01:38:33",
    "text": "we can define templates for these particular devices that\u0027s why we focus on on them so as you can see the computer traffic is directly forwarded to the Internet and you can have your internet things network or internet things devices let their traffic pass through the spinning box here is a picture of an early prototype of the visualizer it\u0027s a bit simple but what it does is in the center is the IOT device in this case it\u0027s a Samsung Smart TV of one of my colleagues and as you can see it already makes a lot of connections if you turn it on to the Internet and in the very first prototype these where IP addresses so it showed the IP addresses it was connecting to of course that\u0027s not very useful for the efforts user so we build a kernel module in the spin box that monitors DNS queries and when it can correlate a DNS query to one of the IP addresses it connects to and it shows the name rather than the IP address and we notice for example that this Smart TV was connecting to Facebook now mycolic has nothing against Facebook but he didn\u0027t configure a Facebook account on that smart even so he was surprised to see but his smart miss Marchant he was connecting to Facebook the next thing you can do is you can click on the balloon of showing Facebook and you can tell the spin device to block traffic to Facebook that\u0027s also currently working in the current program now we have this little IOT lap within SIEM we\u0027re testing various devices smart speakers and most Amazon echo for example and we have noticed that a few starts walking to empty and to adjust a key then of course at some point in time the device will stop working so it\u0027s that\u0027s why we are thinking of building up this community effort of you know templates that you can load that belong to certain devices you can load safely and let the device do clever things without breaking things but anyway this is the current situation speaking of current status as I said we have this running prototype on our money box open wot platform we started with a focus on privacy we hope to extend that to security related things likely we are hoping to scan devices within the network for example to see if they have open ports or whatever our philosophy was to design a vertical slice that\u0027s kind of narrow kind of functionality that works top to bottom and once you extend that functionality it becomes broader so we have more modulus as time progresses we have this visualization module we\u0027ll have this blocking module but again it\u0027s still on many will and we are now working on more automation being able to "
  },
  {
    "startTime": "01:41:37",
    "text": "detect malicious traffic within the network anomalies etc the software is free so you can have a look at how we progress a target upside if you happen to have the same hardware that we use then also install firmware images straight from the valley box websites so feel free to have a look at that but remember it\u0027s all been through research so don\u0027t expect the vision for the further future is it would be great if we would get the spin concept and maybe even spin software deployed into regular home devices we are aware of some similar initiatives apparently the industry has picked this up as well but this is all proprietary stuff and it is cloud based mostly and we hope to come up with some kind of an open standard that vendors might ultimately implement in their home Reuters for example we have it running on the torus which is a big thing that bill colleagues awfully Suzette and our spin software is running on that route we foresee also some standardization work in regard to this we foresee that for example there should be interoperability amongst into the things devices I can imagine that if you plug in an Internet of Things device in your network its identifies itself in a secure manner to maybe do router so that the roots are can download certain templates belonging to that device so we foresee a standardization work in that area concerning protocols data formats and for the near future we are working on refinements and improvements of the spinning software we also have one huge research question and that is how to protect the protector how to make the spin device safe itself so challenging again we have to initiate this elaborate collaboration effort it best form for sharing device information in a standardized way that\u0027s interesting I came across a draft that seems to touch this matter it\u0027s the draft ITF pops aw nut that more or less resembles the things we\u0027re thinking of so that\u0027s interesting that there is already some ongoing work happening in that area as well and hopefully ultimately I can tell my TV to only go to Netflix and not nowhere else to Facebook in my case if you are interested in celebration please feel free contact me I\u0027m here all week we have also written a tech paper about this there\u0027s a lot more elaborate than what I can share in 15 minutes you can find it find it on this URL so I will have a read if you want to know more if you want to discuss this with me you know and that\u0027s it questions just a "
  },
  {
    "startTime": "01:44:48",
    "text": "remark as the slides would be soon online where he was the white person to URL for example Dharam ashkani unaffiliated you mentioned the standardization and I just wanted to point to me maybe you are familiar already but there is a working group called second mission and continuous monitoring they truly does something like that eating in architecture and the data model for profiling security pattern or normal behavior of your network and kind of holding out as exceptions so that could be something that you would like to work at least it was talking for me absolutely excellent feedback thank you I will look into it Tim carreo yeah I will say that you know this is actually great stuff because you know search organizations like we brought in forum we actually were developing a new protocol you talked about you know there\u0027s in translation going on it\u0027s a new protocol called Universal Services Platform which actually has a Patrol or an agent it\u0027s focused in the home area network and so you know your ear affect your your device is actually would be a controller there they\u0027ve got the discovery of vocational and stuff are taken care of the other thing was is that an L map right you know if you look at the diagnostic piece within these devices whether it\u0027s an IOT device rather the router that that\u0027s also a possibility because really looking at a diagnostic test this is this is actually great work because we\u0027re we are very interested thickly I was brought to inform how we how do we troubleshoot diagnose and react towards the events that happen at home so we\u0027re looking we\u0027re thinking along those things up a line so you know I\u0027ll be interested talk to me oh that\u0027s for to maybe see what we did is this is great great great confirmation that we are on the right checking one way or another thank you oh are you question my life away maybe I would remember later okay thank you again those were interesting oh by the way it\u0027s there is there anybody here working maybe for manufacture before manufacture of some such devices nobody here has a week great to hear a feedback on on this idea okay "
  },
  {
    "startTime": "01:47:55",
    "text": "so our next speaker is young cougar from is from Ethernet okay and the bottom line sorry so we have two tickets okay so this is actually from in distillery industry we are from SONET and this is about indirect as it measurement of the three sticks in the Ottoman project I will give the introduction how this route is linked and Sebastian talk about the indirect measurement paths where we have this passive sample measurement that\u0027s which is currently broken progress send it and maybe you get some and here or if you can tell us some pointers or feedback on it will present some first results and any confusion and so briefly Ottoman project the project goal is automated performance monitoring so bringing more automation in the whole performance measurement and monitoring things it\u0027s funded by the German government and it\u0027s a program for small and medium enterprises we are one of those timeframe is 2016 until 2019 so we are at the beginning and you can visit the website if you like now to get a better impression of the project it\u0027s maybe makes sense to tell you or the partners we have some application partners which are directly interested in the results we have and they provide problem statements use cases scenarios they have unless we can get the network data these are legible in IBM and we have research partners which university and to enterprises so Japan so it\u0027s a service provider for the German railway and autoblog logistics so everything which is connected to the Japan and then there\u0027s IBM and it\u0027s IBM Network one services they provide connectivity and services to Airlines of enterprises formerly belonged to the transit systems now it\u0027s basically if they use the platform and solid wire IBM and they\u0027re not part of IBM then there\u0027s a column then for small medium enterprises it\u0027s acid ice on it we have a network monitoring solution called ISO flow many Lopez but we do all things like loves kale and the rice network measurement and monitoring and we also have a second department which does the "
  },
  {
    "startTime": "01:50:58",
    "text": "very very knowledge based company in Munich and we have our customers in Germany there\u0027s not a small company it\u0027s sensitive medium is from preschool and they have something which is for data exploration that just expire and get it for Tyra in entire country go to the news content management system so they\u0027re really use of century and UI based so it\u0027s 24 weeks in the consortium to have either two companies here or for research completes for application they try to put together and I guess ok so what is the idea of project why we think we need more to make today\u0027s challenges in a circulatory is that network infrastructure is business critical part it becomes more and more business critical that we in enterprise networks so if there\u0027s something program and production stops yeah or whatever units you can do with your bank transfers whatever and at the same time you have fewer and fewer people operating increasingly large networks so men power is declining but you still have to be able operate large networks and additionally you have high dynamics in networks to to authorization like Sdn and all of automation things so the network becomes more and more moving part so this makes the automation of network monitoring mandatory because the network rules and is automated and so as the network monitoring 2ps well of course there\u0027s always the discussion thus is it only monitoring so that we\u0027ve stopped at monitoring always also the configuration of the network that\u0027s also discussion with our Asian partners and with our customers in terms of liability and what if the automation breaks the network because your monitoring system sets we want to have to change Network who is liable for that trust something which is in discussion um the vision of Ottoman is basically well you have some users in a data center in between you have wide area network and there might be interfering traffic and you want to detect this happens quite often in network operations and what you do to name is you have basically the monitoring system which collects the data metering and export by our IP fix or other mechanisms and then you have a med monitoring system here and that you have to configure initially you configure the router then you have to manually interactively to the problem analysis you to the drill down to through several charts and entire crimes and in the end you have an analyst report compilation compilation but this is typically done manual by the operations people then you link it with other ticket from the ticket data and in the end you have the management reposes your management tells you well this application broke down what\u0027s the reason "
  },
  {
    "startTime": "01:53:58",
    "text": "for it you have to to lots of these things manually today in order to end up with the solution and the report and the autumn on in autumn on we want to automate the whole process so we want to start a configuration of the network infrastructure and the network monitoring system we do the problem analysis mostly automatically and we can then do adaptive adjustments in case we need more fine-grained data from the system or from from routers we are aiming towards the traceability in visualization so that you already get the result presented that you would otherwise to manually by by drilldowns linking with other data if you get some insights there as basically expert in the loop the user which can feedback to this one and in the end we have the automatic generation of the management report so this is the vision of the complete broad project and we have now one specific case where we get a little bit more down-to-earth and the problem of unobserved parts so this problem just came up in a meeting we discussed some approach and this is for example the used to the scenario deutsche bahn you have a van which is monitored you have active measurements there like see so at core IP SLA to all locations you continuously know what\u0027s going on there but then you have the access network out there and you don\u0027t know what\u0027s going on there and if an application breaks or is slow and the issue is somewhere over there you may not know so you have an observed path and you even don\u0027t know at any time which client is over there and this could be for example hi queuing delays exist network issues hi processing delay in the routers because they are mostly software based here or there can be any error that you cannot imagine yeah so this is why we measure we measure because we want to see the performance of the network and that\u0027s why we think it\u0027s important to look into this and observed path and the idea we got is we could sample packets in here and we can do some times them analysis from the traffic this goes into this direction and this came up when we discussed the paper on school based sibling detection based on TCP time stems from Technical University Munich so this is basically the TCP and flow time stamp analysis that we are currently looking at of course and it\u0027s not possible it\u0027s a coarse-grained approach so it\u0027s not possible to get really the cheeto take it by packet but generally we are interested in bursty Network conditions so if in general a network conditions become worse and then they impact the interactive business applications for example these are some charts from round trip times where round trip time suddenly increases from 300 to 400 or we have a piece of "
  },
  {
    "startTime": "01:57:00",
    "text": "even 700 millisecond round-trip time so these are effects observed an enterprise network and you want to know if there are such effects that can take your application so it\u0027s just we just want to know is the network becoming worse because then we can say well it\u0027s in the better condition then we trigger further automated investigation by our ottoman mechanisms and if it\u0027s in a good condition and application users complained and you know nothing changed and you\u0027re still safe and this network is still the same as before due to measurement and now the research question is how well can we passively message it off and delay increases in those large scale delay variations and that\u0027s our current work and I will hand over to Sebastian to explain it thank you ok so in the following I\u0027m going to present our technical approach to a little bit more in detail and in particular how do we do this passages passive monitoring in principle well as you often indicated before we rely on time stamp information now what time stamps are typically available to us as you can see here in this simplified area we assume that we have hosts which communicate with some servers and we have some TCP communication including the TCP segment with time stamp option set which is usual for most current Linux host implementations and also of most current Windows operating systems so this is the first timing information we get the time of the host system or the server the second time information which we collect is the time at which we do packet sampling on the router so what we do is we take every hundred thousand packets and we take a snapshot of its payload including the time stand option we also know what time was it from the perspective of the router when we took the sample and then we try to establish a relation between these two times times and based on this equation which I\u0027m going to show you on the next slide we are attempting to detect delay variations of course with this approach there are some challenges in particular how accurate are clocks in the router and in hosts how much TCP traffic with TCP timestamps option is actually available in the network and how many samples do we need in order to get some valid measurements but our basic assumption is like this the first step will assume that clocks they don\u0027t jump they don\u0027t drift so we live in a perfect world and we can establish a linear relation between the timestamps of the host and the timestamp of the router so we assume that we can take the TCP timestamp of our measurement sample related to the packet timestamp sample in the router and do this for several samples and we will end up with some sort of a linear equation like times "
  },
  {
    "startTime": "02:00:01",
    "text": "them of TCP equals some slope M multiplied with the packet sampling times them plus some option now of course there are two unknown variables in here the slope and the offset and I\u0027m going to show you in the following how we try to gain some insight into the correct values of these for the slope we get a very simple approach we did appliance analysis so we collected packet samples of our TCP flows and in a after in second step we analyzed how much is the Delta of the TCP x times compared to the Delta of the packet sampling timestamps and we did this for each consecutive packet sample which we got now of course we are aware that there is probably a lot of noise on the packet sampling times then because we will measure the delay jitter processing delay in that but still our results showed there are distinct peaks for different values of M and we got two insights first of all well even with this noise there is a way to the guessed the most slow at least if your sample size is large enough and second of all there are two typical Peaks for Windows host this peak is at 0.25 and for Linux host is 1 but in the end this means that we have to do this slope information estimation I\u0027m sorry for every flow which we observe now with this knowledge we still missed the second variable the offset beam and we try to estimate the value for it like this first of all we start with our initial packet sample we now know the slope M and we know the observed packet sampling time stamp and the tcp times them and we just calculate an initial value for B or the offset and for every constitutive sample we use this B value and try to calculate what time would we expect to at what time we expect to observe a particular TCP time step now if we should be wrong with our estimation for instance we see that the measured times them for particular TCP is x then actually arrived much sooner than predicted this means that the sample which we currently process probably expected less processing or queuing delay or whatever and this means that our current estimation for B was wrong and we have to adjust it take the new minimum maximum and by iterating over all samples of a TCP flow we will eventually get the offset which reflects the minimum processing and packet delay so now we have suitable values for the "
  },
  {
    "startTime": "02:03:03",
    "text": "slope and the offset and we can start to actually calculate the delay variation and I\u0027m going to show you in the two last slides some preliminary results as I said before we did offline processing but we did it with real traffic in our intranet so we have local area network as well as wide area network in this however we don\u0027t have any well known as traffic we don\u0027t have any one on delay or jitter and but still we see some interesting results even if we don\u0027t have any one let\u0027s say lab setup conditions in the first picture you see a flow which has a duration of about 2 or 3 minutes and as we can see here the calculated delay variation is typically around 1 to 5 milliseconds and the first glance there are no outliers at all and so we assume that this was local area network traffic that our measurement accuracy is probably around somewhere between 1 and 5 milliseconds so in the worst case 5 milliseconds so not too too bad the last result slide this is a flow which was measured for a IP address destination in the internet so this is wide area network traffic and it was quite a long flow we see here that this is going on for 12 hours and we see here an interesting sawtooth pattern we don\u0027t see this sawtooth pattern for every flow which we observed in our measurements but only for sound and hence we assume that this is probably an issue with the clock on the host which drifts and eventually it\u0027s corrected again I don\u0027t know maybe MTP or something like that but which means in the end that for our approach we will have to consider clock drift and other clock effects in the future now how does this fit into the big picture what does delay variation mean does this boil down to a most valued no can you make any statements about voice quality with just as well you know again it\u0027s useful for us as a first indicator for anomalies in the network so if we see that the delay variation is typically around 5 milliseconds and then at some point we see some weird Peaks which can be done with this passive approach this is an input for Ottoman control loop to trigger additional and more fine-grained monitoring as we intend to do in the Ottoman project ok so it jumped to the last slide so as we have seen the positive the passive monitoring of the day variations using TCP timestamps seems feasible at least for the scenarios which we look at and we assume that the assumption that the clock drift is like little didn\u0027t old however the timestamp accuracy of routers has improved a lot so actually now it\u0027s feasible to do measurement in the order of magnitude of small number of milliseconds our future "
  },
  {
    "startTime": "02:06:06",
    "text": "work includes that we set up a task lab where we have delay jitter and everything under control so that we can have a further look at how accurate we actually can measure and second of all that we do more measurements in the network of our application partner in particular document systems the stuff at least we also want to redesign our approach so that we can migrate from offline twats online processing and also taking into account the clock drift okay this concludes our talk thank you for attention and we are happy to take your questions you\u0027ll cancel bidding well at the moment our router is capable of ipv4 and ipv6 for the measurements we did so far we relied on the ipv4 okay just because for conveying timestamps many people have similar problems and there\u0027s now and the draft in the idea editors queue it\u0027s about IP version 6 performance and time Gnostic metrics destination offices so they have a destination destination of extension header field in IP version 6 where they exactly put these times them sequence numbers and so on nan the track or for conveying this is quite interesting because at the moment we are limited to TCP traffic and only TCP traffic with the times the option set and this is some fraction of the the overall traffic and with IP public all this would be much more interesting because the visibility would increase of this for ipv6 search so you can go wait thanks for your call Westfair to Curry University of Southern California um a fantastic work so things for bringing is interesting to look at the data have you looked at if you considered the effects of mobile devices as they change between say different access points and things like that which were distance from the access language might cause the saw tooth pattern or other stream gene artifacts this little Bismarck work though I don\u0027t necessarily mean cell phone network even we should see some mobile devices in original because well of course everybody fastest in smartphone but indeed I didn\u0027t have a look at the mobile so far so the results which we have a look at word just business okay so these these effects complete what interesting but we didn\u0027t have yes and I think also I don\u0027t know "
  },
  {
    "startTime": "02:09:10",
    "text": "yeah well we have I think we\u0027re past typically though though a wireless love device in the price daily from separate subnets I think yeah I\u0027d love to see a graph oh that\u0027s that\u0027s what drilled my curiosity a second real quick question is have you looked into turning any of these data sets into sort of notifications no issues with too many false positives and things like that with trying to actually detect real problems using the data to come up with on you you come up with a whole bunch of interesting data sets they have talked about how to turn them into something useful right at the beginning so no we keep going right relay in on the question here so the car Schmidt moly his ask any field plan via plan and standard drafts are even on artsy on this work and if so which working both integers we have not thought about it yet but if we maybe have your picture of the provenance loser space ability I don\u0027t know maybe it\u0027s people publish measurement but let\u0027s see what it will be about thank you God Jesse okay well speak up just over my dog to our remote participants as you can see you can ask questions you can even buy all you also this new feature I don\u0027t know words otherwise just write your question down to Jabba we are following you and on the chat Giovanni is doing that okay hi everybody my name is Thomas green and I started my PhD a few months ago with orange and telecom PI tech my talk today is different from what you\u0027ve seen before but out you\u0027ll find it into interesting so my thesis is on entitlement routing and security so let\u0027s dive into it so a bit of context first so BGP has been there for a few decades now so I guess most of you know how it works to summarize it provides kind of a back end complex environment for example you can have limited visibility of the topology you have limited portion of information to you - "
  },
  {
    "startTime": "02:12:10",
    "text": "the best path selection and of course you have questions of legitimacy and integrity this means that you have a lot of steal a lot of incidents and attacks ongoing and that\u0027s why in 12 2015 7 10 years Theo PhD thesis including mine on subject so the main idea behind this work come from the fact that AAS relationships I made by business agreements which one negotiated few times a year and this also inferred the idea that the inter domain structure must be stable at least on a large or large part about the methodology so a bit of overview of the definitions and synoptic of the process of BGP dynamics and Rises so first definition of primary path we basically want to feel referential of a stable structure of BGP so the internet and so we build a referential of what we call primary path which is the most useful for each router perfect spare and from this we want to interpret the flow of incoming updates messages into primary vas and availability so to compare it to the primary bus referential that revealed since the Soto event is a primary pass in availability period so is quick overview on the synoptic of BGP damning analyzes so this is where we take place and at an extent we want to after that be able allows these VP dynamic analyzes to extract and detect events and be able to mitigate them eventually a bit sorry a bit more precision on what is episode of event so basically as I said we\u0027re transforming the the stream of updates into a stream of set of events which basically groups updates together messages together following a primary pass for so yeah you can expect from that to see two types of total events so so they weren\u0027t that are the what we call transient which translate into events that go back the lose the primary pass and then after some past expression phenomenon go back on to the primary but again we expect to see those kind of events fight often and with with a lot of with short duration sorry "
  },
  {
    "startTime": "02:15:10",
    "text": "also you expect to see from those kind of events to see structural so that ends with basically our survey events where you switch from your primary paths that you have in referential to a new primary path which can be due to a change in policy business policies for example also yeah this is the two types of event that we will see and we want to take a look at the term Poland artistics of those events to analyze BGP dynamics so let\u0027s take a look look at the first result so for this work we took data from one monitor from the right right price project on the three months very good so that is that is pretty really relevant because you had several vantage points but for free to work we intend to extend those monitoring forms so first what we\u0027re going to look at is the first thing we look at is the turnover of primary path so basically it\u0027s entering the question of stable our primary path over long period of times so to do that we computed primary path calculated on April 2 a 16 and compared them to the primary path that we would find on different months following this one so you can see that primary paths are pretty stable over time so after one year you almost have still 50% of primary path still the primary path that you sign one year later but it does definitely it is definitely a decreasing over time so you need to identify the structural changes and to incorporate them into your referential and be able to update this referential periodically to have a meaningful view of the stability second thing we look at is the prevalence of primary path so do they exist and how are they stable okay so we have DCF figure on so the complementary CDF of the primary path Sujit for all pairs at the data set on the three-month period so you can see that first ipv6 is a bit more stable than ipv4 so basically you have a large part of set of primary paths that I used for long period of time almost all the three-month period but you have also some that are really unstable and not used so far police exists even more up here yeah so second thing we\u0027ll look at is take a closer look on primary on pseudo evidence so this "
  },
  {
    "startTime": "02:18:15",
    "text": "confirms our first assumption so you can see that you have almost observe the events that we find our event that come back to the primary pass that we calculated from the referential and you have a few of structure of today that we wonder on the top x-axis you can find more friendlier human friendly units than seconds right you can see that for transient to the events they basically have short durations most of them so under a minute for about 50 of ip4 only 12.9% are longer than one hour and for ipv6 it\u0027s almost a new trend about the structure of the events you can see that they on the contrary have way longer duration so only one 11.5% less than one week for ipv4 so yeah this again disconfirm was at our assumptions of expected properties of the observer and so so how do we benefit from those of the events and how do they help us to analyze bgp dynamics so you can see that first you gain with those new two events objects you gain a factor in term of volume again about almost one order of magnitude for ipv4 and ipv6 which mainly comes from the fact that remember the soul events include all upset during the past expression following a from a past fall you come from the fact that you group up there together and you can see that for a lot of transients 11 at least you have only one path that you switch on the past expression before you go back again onto the primary path and about most of them are at maximum sight but from the bass exploration in the trends of my p4 and ipv6 the Subang benefit that we are from this is that it is semantically rich so to do that so the tables are beeping to get it to understand it first so I\u0027m gonna explain them so we compared a BGP mounted net which is a public service that we do I Jack sand any kind of event detection on BGP so we wanted to compare our methodology and apply it on a use case to detect outages in Ajax compared to the BGP man so you can find the reports on BGP stream but coming down there public website so first on the outages type of events so out of all observable event that we could see no data set meaning that we have at least a one update related to the prefix and that they say is impacted by the T "
  },
  {
    "startTime": "02:21:18",
    "text": "outage we can for most of them they take them at the same time so basically what we look at is do we have a super event corresponding to a starting time announced by BGP money that translates into observe even domain so the answer is yes for most of them and even for a non-negligible part about fifty percent we can detect in the eleven domain we detect them before than they do so we said there is observing that translated primary person availability before them and actually out of those 236 early detected events there is a significant detection phase about one hour before what they announce or about 90 percent have done nothing and only for about one per nine percent of the events we didn\u0027t find any event related to this outage another type of events that the report is our Ajax or just which most by Jack\u0027s multiple origin si Jax so you just want to look at the origin yes I don\u0027t think yeah see I Jack so out of the observable event we can say so the table may be a bit confusing at first because we appears to be missing a large part but actually when we manually inspected the results it seemed that there was only due to one prefix which was illegitimate less specific graphics which was in Egypt similarly announced which triggered a lot of hijack events because of all more specific announcements so explicitly this might mean that we found in the when we compared to the in the so driven domain and the primary pass referential when we compared that we saw that there was a primary bus for this specific event and that for us the I Jack was not a hijack because the original yes was the one we had in calculated in the primary bus referential and for those events inclusive legitimate means that for is perfect less legitimate the less specific yes sorry good find events yeah implicit illegitimate means that we could find an event due to a less specific prefix so for us we didn\u0027t find any primary well CSV we didn\u0027t find any primary pass for this those events which means that we cannot say that you see the I Jack because we don\u0027t have any primary pass to this value right so to "
  },
  {
    "startTime": "02:24:18",
    "text": "conclude on this those first results we can safely say or confirm that the entitlement are is pretty stable for the most part and that settlements are useful and compact objects EPP dynamics we have excellent work of course in progress for now with more data as I said before so more monitoring points more meaningful view of the Internet and we also going to include new results for example to better analyze the structural events are they what are their properties really and also to be able to remove all the bgp noise so the recurrent there so the events that receive for example the transient so the events to be able to remove all that noise so and if you have any suggestions on new interesting result like any good you know I guess that will conclude my talk thank you for your attention and if you have any questions or remarks you know yeah nice presentation I just have a question uh Giovanni Italian by the way there some people use IP anycast which just allows you to announce the same perfects from multiple equations across the globe yes and some people use the same eternal system some people use different autonomous system so how that would play out in your methodology he was different on on system numbers this is true so actually we want to refine a bit of a methodology to take into account such specific cases because you can have a lot of cases we\u0027re really looking at primary path from a router and a Naas so I wrote her below me Rheneas - a prefix so indeed it those kind of network practice and in fact and we gonna look into that to make sure you know when you see the primary tabs on the theory that he had in the beginning and the kind of a 50% remain stable over one year yeah yeah it\u0027s very interesting but it could you elaborate what a little bit cuz I\u0027m also curious about that little thing were the reasons for that and why 50 percent change yeah yeah yeah so yeah so basically for us mean that you have other business equipments that change providers for example so you can add a different as pass you have also some "
  },
  {
    "startTime": "02:27:21",
    "text": "engineering practices that can impact as well because we look really the primary path is the entire path that we look at not so you if you have one new AAS or one less a yes so as fast you can add a mismatch of course so we want to refine this methodology to include such specifications and our more precise and defined definition of the yes if people do prepending like adding the same internal system number does it count as a change in the primary yes for now yes the because we think it\u0027s legitimate us all right thank you also questions okay well thank you guys thank you again for coming so we are planning to do this workshop next year again provided we get big enough time slot it\u0027s meeting I please consider joining Selma humouring list again remind us that s in northern what you need you not polite to this one on Thursday evening and a gentle will be published soon by Alessandro okay and is not a meeting of the energy yes yes yes Friday Thursday at 6 o clock or something okay thanks if you have not yet with and and for the speakers who have not yet sent me your slide set please send it to me Otto Lisandro or Ricardo yeah it was "
  }
]