[
  {
    "startTime": "00:00:18",
    "text": "okay it\u0027s 1:30 so we should be starting for those near to the dog these doors yeah this is the cold working group I\u0027m a custom one this is I\u0027m a few minutes and yeah there was a mailing list and there is a jabber room and this is a Monday so just refresh their minds we assume that everybody has met the drafts and we are here to advance difficult issues and all this is that you can reach information so let\u0027s sum up the agenda today today we will focus on documents that already have passed and today we will focus on drafts that already have passed by noob last call and I\u0027ve various years of going through the iesg and two sets of drafts that we really want to work in glass call after this meeting so this is things Jason Oscar\u0027s animal resource directory and said and tomorrow we will have cocoa because there will be a transport area of person coming in that\u0027s why this is tomorrow we will there you and I have managed to put this into other slides yet and then we will go through documents that are a little bit less advanced and you can see there\u0027s a lot of documents and so this will be little bit of a gong show tomorrow we have any changes additions to the agenda we need to do okay so let me quickly talk about the working group status we have one RFC published since the last ITF which is the coil over tcp TNS that was a pretty "
  },
  {
    "startTime": "00:03:18",
    "text": "long last fire we had with this draft but we finally got it published on February 15 and and one one of the things that we actually had to do is write another RFC that that was just pitching a minor hole in the circuits environment there\u0027s actually arm without help so I could buy around a beer for everyone each time this working group gets an RFC done that\u0027s alright that\u0027s alright if that motivates you okay so this I\u0027m not going through the milestones right now because it\u0027s three documents to iteration so we will talk about the documents when we talk about the recognition but I have a couple of advertisements at the beginning first of all there will be I think you think we research group meeting on coexistence this afternoon those of you who were the hot FC talks have Laura talked about the problem she\u0027s trying to address so right now we are building cars under the assumption there are no other cars on the highway and that works for a while but at some point we will have to put in Direction indicators and all the other things that allows cars to work in traffic and so coexistence is mostly seen as a fine layer thing but that\u0027s probably not true we have to think about coexistence how does our pet network work in an apartment building together with 200 other networks that\u0027s a problem that we currently don\u0027t quite know how to solve so its research but I think it might be interesting to do this as well second thing there is a draft that is going to be workgroup last called very very soon in the six dish working group and that draft contains a co-op option and that\u0027s I think the way it should be quote is designed for extensibility so other groups should be able to define options it\u0027s an option that we have talked about here the stateless proxy option and I would advise everyone who who cares about things like this to look at the draft and maybe send a message to call and or six dish about any comments that you have and maybe go to the meeting on Wednesday and Viscount who so just to give away what what I\u0027m going to write I "
  },
  {
    "startTime": "00:06:18",
    "text": "think we had a discussion on whether that option could be repeatable or not right now it\u0027s defined as not repeatable and we probably should think about whether that\u0027s the right thing to do on the the third thing is we are going to talk about we saw through three today and we are making resource directory to DNS SD so we\u0027re going to briefly talk about that but actually there will be more discussion about that in the DNS st mark meeting on thursday morning so please go there if you care about resource directory and or DNS system okay and that one message from our sponsors this is really not directly related to to call but it\u0027s interesting to everybody who cares about constraint system so the next right savage will be in September and sediment you you might care about that okay that finishes the first and the next thing is links Jason so this this drop we have been discussing this draft for a wire actually it was started in February 2012 so by the time when 66 ninety what is now 66 najuk became stable we thought well it might be a good idea to have a JC to avoid having the need for another pass I in mid-2015 we added seaboard variant so the whole point is about documents that contained links and it is used for self description of car notes it\u0027s in flesh we\u0027re now instead called and for a long time we have been working on this document with the assumption that the focus should be on round trip abilities with RFC 66 ninety and that\u0027s actually the that being the focus of the draft that passed burden of last fall last year and was submitted to the iesg on April 2nd and then gates and we got lots of feedback and there\u0027s also related work for instance in BMC F spec that we probably shouldn\u0027t ignore so they are not using is they same forward but it\u0027s kind of culturally compatible and we should try to understand what they were trying to do so with all that feedback and all that related work the it didn\u0027t seem "
  },
  {
    "startTime": "00:09:18",
    "text": "reasonable to continue with the direction that work had taken so far focus on round trip ability and so that the proposal is to refocus this a little bit and try not to inherit the limitations that we put in RFC 66 19 for it for it to be easy to implement so the the idea is to have a full web linking environment in the JSON or support variants but of course still cover all of RFC six is ignited because we at least want to make sure that the forward direction works even if the backward direction may not always be possible also communications there so that is the the we focus if you look at the document there\u0027s actually not much change I have submitted event that does most of the changes already so it\u0027s still pretty much the same document there are some details that are now refocused on this and there is one background activity that happened while we were last calling the JSON document an update of RFC 59 88 which is the base level obviously 66 90 happened so the web linking people realized their specification so RFC 66 90 is now based on what is an obsolete version of the web link specification record that\u0027s probably not a big problem because they were careful of not trying to break too many things but again what happens is they have to refocus on it little bit so for instance the the way a B and F was used in 59 88 which creates some of the little problems we are having here that was fixed in 82 88 there is now a clearer approach to the Unicode and language tags issue and most importantly the document actually acknowledges that there will be other civilizations of web linking not just the one in the HTTP link header which this was originally about much for instance obviously 66 90 links Jason and other things that may be coming we haven\u0027t seen a need to actually update 66 92 that Newbern we think a pretty much works well as a cheese so right now the yes yes to rebase links Jason on 8080 to make eh but at the same time stay mostly compatible 266 90 which is "
  },
  {
    "startTime": "00:12:18",
    "text": "based on five names like it so there is a few places where this comes up and I just put in a one here to the slides language tags our c59 8h defines some some special target attributes that have a star an asterisk in their name and what\u0027s special about them is not actually the attribute itself but the way they are represented in an HTTP link header because it should be linked at us may need to be a ski if you will have a link attribute that actually uses the Unicode you have to do something and what they decided to do was provide an encoding of the unit water content and also provide a language tag which is typically useful to actually correctly interpret the Unicode so you know whether some some Chinese characters are in reality Japanese practice so 66 90 has some support in its a B and F for a title star attribute but that uses exactly the weird HTTP link kind of syntax and originally we just copied that over into links Jason and it just doesn\u0027t make sense you shut up cause decoder is this stuff and put it in an extra Unicode and the new thing is it became clear in the discussion that we probably also need to preserve the language I saw what but the real a new piece of technical content here is that a title star attribute in a link head are in 66 90 what we translated into a nominal title actually root of the value of this attribute would be a string qualified by a language text so if you want to have a title then the equal spring and put in your language take it helps to okay so this is the new stuff and we all have to look at it and we this is the right way to do it well that\u0027s that\u0027s a detailer but on a high level is this right form right way forward we they see the document on other places where each wait it has cleaned up things explain how become links placed in touch so make sure the nothing is fully defined in that direction but otherwise 690 using "
  },
  {
    "startTime": "00:15:24",
    "text": "crystals that\u0027s one and another direction that we as very know should be deciding at some point is there and intention of getting rid of in college who actually want to replace when you\u0027re caught by a Jason for more Zeebo form that\u0027s a second thing which does not have a bearing on what we do in the customer but there\u0027s something that the document is very clear this not happening at this point so I think but but we have to think about for instance the simple representation is pretty compact is that something much we have know so is actually armed first three bullet points I think this is completely logical as a way forward so I don\u0027t have any pushback there I not intimately familiar with the ice-t comments around those if this fulfills those requirements so it sounds like Carson\u0027s point of view it does the last one you know I would comment that we have we have media type variations with different civilizations for a reason I don\u0027t see any reason why these can\u0027t coexist but this needs to be made clear right like if I request a see bore version of thought well known slash core I should get that um rather than an implementation just blowing up because what you should get RC six to six ninety why are you asking Rivers for Seaguar alright so I think we need to be able to be future proof also with how we deal was slash download on slash course so this fourth bullet point should we mandate that it is just sixty six ninety know we should mandate that you can optionally support others but you probably have to continue to support this as the default yes so the question was that\u0027s a lot of much about forbidding it\u0027s in win of course will be like that but what is the mandatory to implement ha I don\u0027t think we have I don\u0027t think we there\u0027s a difference between mandatory to implement recommended right I mean you need something that everyone has to support um right now you know the wave flash sizes and and meta devices are increasing at that rate C bar is not an issue right we have more issues with overhead on the wire energy etc so I don\u0027t see C bore as a limitation in these devices but we do have enough stuff out there that\u0027s using 66 90 you "
  },
  {
    "startTime": "00:18:25",
    "text": "know it\u0027s in the wild it would be hard for us to just say now the mandatory C bore and does the device just what fail if it doesn\u0027t understand C bar I don\u0027t think that\u0027s reasonable yeah Michael Koster smart things in Rd I think the approach we took and I Christian can correct me if it\u0027s that\u0027s been changed was that we required RFC 66 90 compatibility and allowed additional media types and if that\u0027s what\u0027s being proposed here I think that makes sense for well-known core also he did the trick of causes if you don\u0027t care about the old link forward is that you just provide a very short link form a document that points to a link SIBO document that has the actual information so then you are compliant to the little okay so you can kind of gradually migrate away without waiting okay I think it that we want to continue this play and so there is a dish out there right now there are few final tweaks that I probably want to make yeah this document is like nine months after I see review so I probably should return it to the working group it also depends how many other changes you think you want to do and for how long so there should be a version of this by the end of the month and that has all the changes in the angles the working group should look right I might be able to short-circuit avoid another IT at last call but this document will need another IG review at minimum because several area directors who balloted on it are just going to step down from IHG so you will lose some bows here it might not have enough positions to bosses which kind of linked to decisions yes so let\u0027s take off line but the idea is finish this quickly if there are the "
  },
  {
    "startTime": "00:21:35",
    "text": "next item is a score hello everyone I\u0027m Yolanda from erikson I\u0027m going to present the next update on our score so we are now in version 11 my co-authors I\u0027d like to go through the issues from from the IC review um here is the status number of implementations we actually appeared one new implementation at the end of the list there which so it\u0027s really being used several in crops up in time but topic of today\u0027s presentation is about the ISD your view we had also have some post last call reviews and if you want to follow the details we are handling the review comments on the wiki and we\u0027re having this new version 11 we think that all but a few specific comments are addressed so there are a few slides on on on review comments I\u0027m not going through all but those that I think are representative port for the type of comments we\u0027ve got and here is a comment saying the document needs to security analysis section and implications and modifications of unconnected fields are are not sufficiently covered so they written was already a security consideration but the IC wanted to have more specifically an analysis of the security that is being used in the protocol and what guarantees are provided so what we propose to do is add and what we already have done is to add an appendix describing security properties of the protocol there are two three sub sections one is looking at the problem statement the assumptions from even videos so that was not really clear to everyone making the review so we think that needs to be highlighted that means the media are supposed to perform certain actions using the available headers but other other message fields are not available to the intermediaries so there are protective headers that are unpredictable and then we will also include two sub as one which is going through the security properties of the protected headers and one which is going through the unprotected fields and the consequences of being operated and there were questions around the nonce construction why is Sandra include nonce and the rationale a is that this the security design is you it\u0027s intended to support both the ordinary request response notifications as well as an interchange of client and server roles and that required a special construction so what we think is needed for for "
  },
  {
    "startTime": "00:24:37",
    "text": "understanding this better is that we have a proof for how quino\u0027s uniqueness is obtained and we put that as fourth subsection in the new context but this design actively works against any involvement of intermediaries that also attack or comment which basically shows that we have not done a good job explaining the problem statement what the intermediates are supposed to do so so we that\u0027s the first of the three sub three subsections of the appendices we\u0027re dealing with the intermediaries and their role and we elaborate on that so we can quicken on it but I think it would be useful to start a document that just explains different situations in which Oscars being used so people understand why that is actually not not true I mean it should not go into this document or to finish it but having a short document that even might go away I don\u0027t know that just says these are different configurations in which we run or score and these are the rationales for why we want to support these configurations I think that would be used for Lynch good it could even be done on top of 77 44 which has already has use cases so you don\u0027t really have to define these use cases in most cases I mean part of this is actually in the requirements stuff co-op intent requirements there are also examples showing showing how it\u0027s used if along with the trust model for prophecies so I don\u0027t extend something that needs the abbot so should should we maybe complete this requirements documents please not with the name requirements but as an informational document that goes with Oscar or that succeeds us because we want to finish Oscar first but it would be useful to turn this into an RFC I think what happened with that happiness and so the the is G is always pushing back a little bit of information about humans but I think in this case because of this kind of question it might actually be useful to do so we just need to find people who want to work on this who would want to work on this I mean there are authors of the document but they are okay others about come to where it\u0027s maybe anybody else would be interested in finishing there well you you will be reviewing it\u0027s like yeah okay let\u0027s take that offline and see if there\u0027s a way to yeah "
  },
  {
    "startTime": "00:27:44",
    "text": "okay then the what a set of high-level comments related to I mean this case is a statement about this that we this draft is not it\u0027s neglecting to address important the difficult part of the problem like key exchange and we disagree with this comment we are addressing I mean the basic the host comment was saying this is a partial solution because there is no key exchange protocol but there are other ways to establish keys besides key exchange and so you could either do it with with the the probe the Oh score profile of the ACE framework or you saw my deployments require PSK so because of their constrained nature so it is a complete solution but on the other hand the key exchange protocol it is also something that\u0027s needed for Osborne that was discussed in the ACE working group this morning so so that\u0027s so we we agree with that you need for a key exchange but it\u0027s not a necessary condition for all school and then there were a bunch of comments of HTTP and they were very good because we hadn\u0027t focused so much so first comment this protocol abuses HTTP by tunneling over it and that it\u0027s actually correct and that was exactly what was intended we had a missing a be an effort and that\u0027s fixed now yo and it was a question about how how does the coop HTTP gateway understand the significance of the new header field so that\u0027s the obvious security header field and insert the medium pipe when translating and that\u0027s exactly what we wanted to intend so we don\u0027t want to necessarily add at the content format for knows a bit corny obviate security protective message so but custom from the floor I\u0027m not sure we are actually abusing HTTP yes we are tunneling through it but we are using it as a request response protocol it\u0027s not like we are just using HTTP do to send messages back and forth so I think there are there are different levels of it abused and I think we are not in the murder range here we are just in the manslaughter thanks for the clarification so another Winston question was do we need a code point for coop for this new media Titan and we had this question before and we said as we said that time previously we said no we actually don\u0027t need it for this draft and then we realized that maybe someone will actually have a use for for this code form so we decided to include that anyway but not not use it in the draftin and explain when you\u0027re not going to use it so that\u0027s a placeholder currently what if "
  },
  {
    "startTime": "00:30:48",
    "text": "the request is redirected by the server that doesn\u0027t understand those core ok so here are two these two questions are actually still things which we would like to have good feedback from the working group shall we support HTTP redirects and the setting is two there are two settings one setting this is one of the settings HTTP redirects you have a coop through an HTTP proxy coop HTTP proxy and you get counter server and the server makes the redirect back to the proxy that would be the ACD no it\u0027s not okay let\u0027s not recognize why is that a thing that should be addressed in a score this is the thing that effects it coop HTTP proxies in general and I think in general they don\u0027t but this is this is this is generic good question I think the reason why I mean this is one of the questions we got from from the ISC review so we assumed that this was reasonable to address in the doc but the answer could be that it\u0027s not something that we are actually in this there is also by the way when you define a new HTTP header you need to answer a number of questions how will will read is be impacted by redirect so I think it from that point of view we should have a good answer to the question so and this question was brought up again by Dave Taylor you want to say something on the first point I don\u0027t think that this is a media type of coop it may be maybe a title of a score but my assumption is all of the is that coop out of that strip so this is just it\u0027s just a question of the content format of value right there\u0027s no there\u0027s no co-operators on us No just I mean it\u0027s just the value for the for so we have a media-type before for for over for the object security for the payload containing the compressed cozy object we have a media-type for that and the question is do we also need a content format a value and we don\u0027t need it for this draft but maybe someone wants to use this compressed cozy object and pass along a media type for it okay I don\u0027t have a better I better answer than that people have been requesting this and we thought it better include it now then you find a good use case later and then how to do it yeah so maybe to answer this question the there is no need to include the content for adoption because the object security option "
  },
  {
    "startTime": "00:33:48",
    "text": "already implies the value of the content for adoption however if this media type is used in some composite media type that has content from it numbers on the specific elements that go into the composite media type then it is useful to have a number for that that\u0027s all that\u0027s the whole reason next ask him sort of a while while thinking about that so yeah so the question actually was then brought got brought up again by Dave Taylor so he said has the working group made a conscious decision here whether we going to support HTTP redirects or not he was not he didn\u0027t really care about the answer but he just wanted the the working group to have take the decision that either no we are not supporting a stirry redirects or yes we will support them and we will make sure that the necessary whatever specification is in place if there there is anything Aleksey I will try to provide nori not very formed and not necessarily correct opinion on this I was talking to Patrick McManus one over HTTP base coach Ayers about another document that decided to prohibit redirects and he said basically you shouldn\u0027t be doing this when you are using HTTP the error direct is a standard feature you should just support it basically I\u0027m not entirely sure whether there are any exceptions to this but that\u0027s the the gist of of the comment I got from him besides I don\u0027t think that actually I need to think a bit more about this but I think you can have HTTP proxies on the path that don\u0027t have to understand or score as long as they in implement HTTP correctly they will work with what you know it\u0027s just another payload for for for them so they can redirect another source and it can go to another server that is HTTP 2 core proxy and and then everything should be fine so my gut feeling I don\u0027t think there is anything inherently wrong with using redirects Franchesca so the problem we are thinking of is that if it doesn\u0027t reach the right server the server won\u0027t like the security material won\u0027t be there if it\u0027s if it reaches a different server it\u0027s not a proxy problem it\u0027s a fluid who is this intended to and do they have the right security material I "
  },
  {
    "startTime": "00:36:49",
    "text": "mean if it goes the wrong place that I don\u0027t really see a huge problem because they will basically just return in it HTTP error and you\u0027re fine I mean it maybe goes to somebody who understands the format but doesn\u0027t have the right key you\u0027re going to interpret much the same situation plus one okay so we will make sure that this support HTTP redirects in some way and you don\u0027t need to specify something we\u0027ll find out what you what it appeared the last point on this slide is the name of the HTTP header field so originally we call it object security and we got some comments that we should probably be more specific that it\u0027s not it\u0027s actually dealing with constrain the restful setting so the proposal was to change to coop object security which is the current text in the drafts and now we got another proposal from Dave Taylor he thinks we should call it core of it security because it\u0027s if he actually didn\u0027t want to narrow this down to coop you think this is the in his view of the end-to-end rest setting so so there are there\u0027s a counterproposal get to change the name to core object security any news well the whole reason you changed a name to Oscar was because it wasn\u0027t a coop specific anymore so putting co-op and there doesn\u0027t make any sense at all it was Dave who proposed to change from Autosports consequential change so what I\u0027ll just call it as cool so that\u0027s a Google Google return which is probably more useful than anything yeah we had the discussion number of times I think that most arguments against that is gone I could you recall the arguments that\u0027s quite alone so would that be changing both the the option and the header field or what would be you have we have a co-op option and we have an HTTP hazard but the option name never occurs on the wire so you don\u0027t get in a situation where you need to google it but the the HTTP header mean that occurs on the wire and if you find a strange baguette where that in it you might want to move it so I think that the Google ability of the header field name is a is an important thing how we actually call the the option we have very wide okay so any "
  },
  {
    "startTime": "00:39:53",
    "text": "other views naming it thinks we can discuss forever as you know so really important stuff so but so I put out the mail on the mailing list and as this is this is the proposal and I also I respond to day\u0027s mail then we move on to that was the last actually so this is not a complete cover II of all other your comments you could look at the wiki and the commits that we have yeah I\u0027m gonna get off essentially but in summary we have tried to clarify the points which were brought up and fix all the editorials and there is a new appendix or reviewing which is going has these four subsections as we discussed yeah but essentially with version 11 are always should essentially or issues are addressed so are all issues addressed there were some minor to do I would say that let\u0027s say yes so will there be a dish 12 I mean so okay so let me what is the to do or is doing the broth in the version 11 this was late night work I can\u0027t reproduce so I would say that we should be able to fix whatever is is in the to do during today or tomorrow that type of complete Francesca so if you take a look at the wiki in the github we\u0027re really tracking all the issues and what we have done and we consider we just have to answer and what we need to just review in general I think we all the all the elements are in the draft we might want to rephrase some things but the content is there in our opinion and yes so we just need to answer the emails we got the emails pointing through the new text and asking if they are happy with resolution okay so the assumption would be there will be a distro in a couple of days from now yeah okay there is a to do so we need to have yeah but but we could we could speak it at respond to the emails sooner because yes basically okay wait thank you sorry "
  },
  {
    "startTime": "00:43:04",
    "text": "okay talking about quick state of something on cinnamon I don\u0027t know you did now yeah works now no sounds like this 11.5 million meters from you okay it\u0027s gonna be interesting no no okay closer yes it\u0027s gonna be able slightly awkward but anyway so update for media tax force in ml okay stages um first of all we\u0027re done from burning crow point of view so sentimental is currently I get last cold yeah that job is scheduled one month from now so there was a since last person Alex I did a thorough review on it and some bunch of editorial or clarifications etc that we fixed there one that you could consider a technical change was the media type registration for exi was changed from plus EXI to minus CX I although yesterday we did discover this may be worth clarifying one small point there on the expert guidance or new values to make it clear when new values are registered in the name long name of the value human readable party to take value to make it clear this has the value semantics are for the new field then for early assignments so this um currently the verse that is submitted has a bunch of DVDs on the IDS course that\u0027s gonna be assigned by iana but since there\u0027s already a lot of use for cinema will be useful to have those IDs assigned as soon as possible so what we\u0027ve been discussing now with reviewers expert reviewers for that registry is that okay it is a good set of ID\u0027s have a one consequent set of ID\u0027s for all that all the numbers except for XML so the reason for those XML IDs being in the two pide range is that XLS anyway quite verbose you\u0027re not saving much or have using the one byte IDs so so length read with the experts on this ante we all seem to be having consensus on this so we\u0027ll be going forward with these assignments unless someone sees any concerns so procedurally this is in early allocation so the the authors of this document will ask the chairs and npad to to earlier location and then and if you approve it tomorrow we don\u0027t have to do that right yeah I\u0027m trying to remember ah I might not have added it to the next to each other it\u0027s probably going to be a nice chair review in April okay so I mean do you really need early allocation on 5th April 5th you know two weeks "
  },
  {
    "startTime": "00:46:04",
    "text": "earlier than that you think we\u0027re gonna have the assignments or well basically you know fingers crossed if it\u0027s approved on a tell a head and then it goes into publication and Ayana does allocation very shortly as soon as it\u0027s submitted or easy editor I cannot promise things outside of my control you already got yes from me so that\u0027s fine um okay so I guess we can see if there\u0027s no discuss is flowing before the telecheck then we probably don\u0027t need to do it then it\u0027s only a couple of weeks thinking if there\u0027s something we need to do Rod\u0027s updates having these ideas usable for other SDOs would be highly useful okay yeah okay let\u0027s see oh let\u0027s see what happens during the Taylor chat week and then remind me if if it\u0027s not done you know the we\u0027ll discuss right then now yeah the way to do it is I add management item to the teller chart and say you know can we prove this okay thanks then there\u0027s another question on early assignments how about extensions to send a mail so since it\u0027s not an RFC yet we don\u0027t have the registry actually but there\u0027s already a request at a new field from again steal from a DM on the object links so what is the general procedure here can we already allocate but it\u0027s not part of this spectacle specification is external so what\u0027s that is there a procedure for this kind of assignments yeah I don\u0027t think there is a procedure for early creation of a registry in a document that wasn\u0027t yet approved I mean the salmon can be done very quickly as soon as the document is approved you know even if it\u0027s not published yet I think that will be okay to actually basically say well Ayana will create it right away in fact they usually typically create you know draft versions of the registries or at least they suggest tell you what the registry is going to contain during last call so they will have information available before they tell each are typically yeah okay good so so much about cinema oh so next up fits and touch media types of course in ml so the background for this one is that um you\u0027ve been seeing what a lot of lot of synonyms earlier but this one part of our use of cinema called the collection use and that is what is used today if I became protocol and also I\u0027m so smart "
  },
  {
    "startTime": "00:49:06",
    "text": "objects so here\u0027s an example of an in to smart object it\u0027s a remote actuator it has actually a cure for light it has that resource filling if lights on and off what is the demon cult deeming value how long it has been on and human readable description of it so use case here is that what about if you want to retrieve or change only two of these resources you could be as of today doing two gets on a specific resources and get the values and that could be okay how about but however if you want to do this in order to save battling only with a single request or maybe you want to be changing the value of a few of those but not touching attitude luckily we do have methods for that in in koa we had the cooperation patch or exactly for addressing a parts resource updating or fetching them however the KOA patch and fetch methods they do need a payload format that is dependent on the resource creepers intention format and current there is no one force nml so that\u0027s exactly what is proposed by this craft the feds form loops last as an example on the bottom of the slide it is modeled after several JSON format axis this is playing sin ml without the values and the idea they recent you can have simple parsing of these type a Log form of course you already have support of sentiment on the device it\u0027s using this format a really simple format just indicate the names and potentially times if you\u0027re using x in their other values of the records you want to fetch and you will be getting the results for those so this would be solving the problem of getting two resources out of the center go back at Susanna mode records in its interval words under the packs format exactly the same however you also give the values you want to be changing there so those of you are familiar with the chase emerge as format assessing a subset of that format applied or for each record so that\u0027s the simple part of the best cuts format but then there\u0027s the optimization base now currently called wildcards and essentially it\u0027s about when you want to be selecting multiple records using a single pitch or Pat\u0027s record again it\u0027s if you have a let\u0027s say a few hundred people records and you don\u0027t want to be naming explicitly hundred different records on your pets or Pat\u0027s request you could be using some kind of a way to select multiple multiple records a use case could be for example ghetto temperature sensor values or be more like 10% so currently the draft is proposing one format a new center field code specs filter it can contain use you can use it like a name instead ml your concatenate with the base name and it can contain "
  },
  {
    "startTime": "00:52:06",
    "text": "wildcard characters that you are then matching many characters up to a a separator and you can see there in the bottles like example that would be matching all resources starting it by a more common use would be for example with wildcard for example in place of 0 on the best field and it will give you all instances of an object so then the considerations are recording this track on the wild cards is the upper half on screen okay something simple it\u0027s needed for addressing this use case and there was quite a lot back up or what what is the right way of doing that the current is such that say early proposal are up for discussion we believe the basic format that were you explicit name the resources it\u0027s been a straightforward but this world or is something bit more complex and maybe need a spark more thinking and although what we were discussing right before the courses in here is that there is need for the pitch packs format relatively early be pretty much end of this year however this wild card format is maybe something we want to consider a bit longer than triangle endpoint of this year so it could be split out of this document because it is quite a bit of complexity and getting it right maybe requires some some time but the basic format seems to be pretty straightforward and something what we could be defining by the end of the year SEC shall be armed um telepathic connection so soon as I stood up you realize what I was gonna say right yeah so I thought yeah we always have to be a little suspicious about need um and it sounds to me like this wild card things nice to have now if you look at how some of these resource structures were designed like in OMA objects right in just referencing into like halfway down the tree will get you the entire object in there so having like a 5/8 star kind of okay you get part of the object but why they\u0027re pretty granular already 5/8 wasn\u0027t really a good example accent I think much more usable would be all instances of an object but you get that if you just reference the root of that object all the instances of an object but the thing about specific resource give good recommendation on proper object design so that might be something you you could do it say like we do not have wildcards in this version of this specification thus here\u0027s some recommendations on how you can structure your resources in such a way that this is useful already not right that might be a temporary make sense and all in all this being able to select multiple things maybe "
  },
  {
    "startTime": "00:55:07",
    "text": "it\u0027s what we need but a habit more thinking think about the use is probably and probably applies beyond 10 ml so cinema is not where we hit it the first time maybe something even think they are cheese called want to think about in a bigger picture and then do later on for example and extends with this but having the basic basic semantics or fetch and patch defined seems pretty straightforward so if we then forget about the world card considerations for a while and yet there\u0027s also question about regular expresses maybe it maybe later preferably not and under the patch operations so currently the semantics is that you can basically create new and you can change existing ones but you cannot for example and a similar so there could be some need for operation codes later but again maybe it\u0027s something want to do as an extension and really see if there\u0027s piece of news case for it and also currently the draft poses new responded permit IDs but as Klaus pointed out there\u0027s no need for it we can actually use the same existing Golan format IDs and justifying the semantics with the patch and pets that are are slightly different from the regular say never use but then the key question since this now zero zero crap Eastern interesting the croup to work on it because there\u0027s little interest external positive so OMA DM has already requirements for something like this and to me I got a bunch of others here it seems very sensible thing to do here a general thing that is used by oma DM instead of comity of specifying it work my personal works for them but then that comes with the kind of timeline stable by the end of the year preferably RFC but if we take the wildcard parts way it sounds feasible it\u0027s a common the operations are also taking out yes and all the Mattias Kovich Siemens so for these wild cards there could be a use case on industrial systems you very often have this right multiple read multiple and so on so I would have interest to to work on what is there that we need I\u0027m not specifically interested in the cinema version but in this generic thing how we could solve this multiple read right sounds good let\u0027s get into it hi Paulo from Nokia my question is liquid all these new additions do we have any impression on the size growth of the code for a constrained device I mean is that something still yeah for supporting all "
  },
  {
    "startTime": "00:58:08",
    "text": "these new features and wildcards we don\u0027t have a good idea yet supporting the simple here\u0027s the name if you already support getting senemo as input the code change should be pretty minimal but you already have all the machinery who understand that and it sends matter of speaking everything with map it doesn\u0027t explicit match so I think that should be pretty straightforward on the wild card of filters and selectors it really depends on the design and what one question for it\u0027s on the wild card was afraid how about more than one wild card well that actually increased the complexity quite a bit but you get the vanity so again maybe that\u0027s something we want to push later but it\u0027s not that I don\u0027t think it\u0027s an urgent thing even if ramadi yes this is des Browne speaking about wild cards one of the things that I was going to say is that wild cards in the middle of the URI are the or the evil part and you said oh that\u0027s exactly what I want so but to echo what Zach was saying so very often with proper structuring of the data you can avoid that if you think ahead to what your use cases are you can avoid it and possibly if your structure is something that you\u0027re set with it\u0027s built in stone but you really want to query their different way there\u0027s nothing wrong with having data appear in different parts different trees different views and so restructure the data over there in a different view which allows you to be properly hierarchical that it at the very least put your wild cards only at the end because wild cards in the middle and we know that\u0027s the search writing the code for that is very difficult especially if you have something that then you open up multiple wild cards in yuku you know so it different levels it gets very complicated wild cards on the end are ok and if you structure your data so that that works that\u0027s ok yeah and I think the wildcards in the center can be okay if you must only upload up to a delimiter so if you have clearly delimited structure however there is complexity different there I write that right no so in case of for example like with in managing Docs in to smart object you would know okay this object ID can be anything so there are some structure where it works but I do what we in general it is thinking right and that\u0027s it I think coming back to you or rather like do another view that\u0027s exact what Cristian was suggesting earlier yes we could be able to do that often gets you away from having to do complex filtering or complex queries where you just I have I had the query for you already because I know you want this and here\u0027s the view that does what you want so yeah something we could be exploring in the wider scope of how we want to handle this Alexander path yes I\u0027m going to echo this this comment and just at a point here that in karma we are using fetch for this couple of operation so whenever you want to do like like basically what we get as an input is that tree selection like a subtree if you want to go and do some operations of trees pretty pretty much everybody who is asking for so maybe you know just if you "
  },
  {
    "startTime": "01:01:10",
    "text": "happen to want a couple of sub trees then in a fetch operation you can get them all of the things that you are wanting I do see the use case where you might want to say okay I don\u0027t know exactly all the identifiers that are here and you know I don\u0027t want to really restructure if some SDO has fixed some some particular you know structure of your eyes then you know I don\u0027t want to redo this but then I mean there I feel that there must be some use case that comes in a circle for this use case when he just needed we need wildcard operation and then to be narrowed down to this use case and that could be useful so would be interesting interested in reviewing future versions of this document 1 2 3 4 5 six so we do have some some interest in this room and I think I\u0027m only going to ask for formal adoption when when cinnamon is actually approved to reduce the number of documents in the backlog but I think we have some interest here let\u0027s go ahead with us okay and we\u0027ll go also ahead with that split of having just the basics in here and then we do that wider filtering hearing part on a separate document sounds good excellent thank you okay you have to speak about 1.5 millimeters from the like okay hello my name is Christine I\u0027m Susie I\u0027m just I will be presenting not only the main resource document which is nearing completion but also two documents that are justly related to it um the SSD document which Carolyn is primarily working on and the personal draft that moves some things that we\u0027ve been discussing in resource directory out of the main out of the main document so as I said the the resource directory as it is is from the office point of view pretty much ready so nothing more will come of it if we stay brooding over it so will we need your input so this can go into a working group last fall we\u0027ve done quite a bit of work in the last few years it is mainly documented in the Isha tract and pull request by the time we released the "
  },
  {
    "startTime": "01:04:12",
    "text": "- 13 draft we were down to one remaining issue which I\u0027ll talk about in just moment in the last days another came up um that is mainly editorial do we want to have this forward reference deal in it or not and I\u0027m hoping for this number to go up a little bit and while we are receiving reviews but I expect that there will be mainly editorial things that we need to clear out um through that time um the issue that I\u0027m looking forward to solving is that we\u0027d like to show the interoperability of the resource directory as we have specified it now in that sense that different people arrive at compatible implementations from the same document so far I have three people that would like to work on this please if you have an implementation of a resource directory drop me a mail and then if I know who else is participating then we can set a date and we can set a context and in which we will have this in detail this will probably be a remote interrupt because it\u0027s because we can so what what changed recently this is basically the the Delta since since I TF 100 there\u0027s been lots of smaller cleanups so you if you want to do this then this is exactly how it is done because the mother document is not completely queue about it if you want to indicate your server version you can you can do that without changing anything of the mechanism we\u0027ve we now allocating a multicast address so the initial step of this finding a resource directory can be targeted towards a resource directory without exactly knowing what it is the there big change since - 12 is related to what Caston talked about before the fine points between RFC 66 90 resource link format and link headers and for the sake of not creating confusion and having things just work we resorted to in recent when when looking for resources to just turning absolute references because this avoids a whole bunch of of ambiguities as long as we\u0027re in at least as long as we\u0027re dealing with a link format representation so when the resource directory mandates that link format is supported by the server but all other kinds of serialization of web links can be used as well and if they don\u0027t suffer from the same ambiguities then in those cases relative references we don\u0027t forbid relative references but um we\u0027re there where we know there\u0027s problems we just just hand out absolute references "
  },
  {
    "startTime": "01:07:12",
    "text": "and the last part of changes was related to resource directories that are not necessarily hosted on the same server so for example if you have two resource directories and want to do lookups across them we added some text in the resource directory document document that says that I do not expect this your I to be a relative reference this can be just just treated as a opaque your I the resource directory will know what it is doing and what exactly the resource directory could do is outlined in in a new draft that is called a resource directory replication which just explores several possibilities of what you could do if you if if you have your research if you have multiple components in your resource directory because you want to scale to large numbers of requests or what\u0027s or not this doesn\u0027t propose a specific way of doing it but shows that it is possible with within what is provided already by the resource directory and this is also compatible with them with an earlier draft of Kaymer that deals with more distributed resource directory so those two are kind of a focal another another document that is closely related to the resource directory is the is the export from resource directory to DNS SD this document is still in active work it has been updated to reflect also changes in resource directory it now has an intro a proper introduction so this this is this is not nearing completion yet but it is in a state where we can be relatively sure that we only reference to the resource directory and don\u0027t need to forward reference from the resource directory to our DNS st everything that DNS st is supposed to do can happen as an extension to the resource directory as we have it now and this is this is the way to go for what we think with this and this is happening but not ready for a working group last call as of today speaking of working group last call what is missing for the resource directory reviews because the last once we\u0027ve received from Jim and another review we\u0027re on - 11 so in order to go from working group last call I\u0027ll ask for for some people to have another look at it so any any volunteers I see at least three um maybe some of the other NGOs OCA or may could also volunteer since they use resource directory and their members in the room of those obviously but I wasn\u0027t talking about you yeah I "
  },
  {
    "startTime": "01:10:14",
    "text": "was mentioning possibly yes okay so for the the minutes Marty right yes any value had the hands up first and then Michael and yeah I think that\u0027s good for this round we we will have a blast having a few reviews before that would be great and as I said if you have an implementation and this again also goes especially to to stos please contact me so that I can arrange for whatever we need to to to run this against each other and see whether we all arrive at the same practical implementation from no specification so the plan is to have a blood test run mid-april depending on the availability of people of course so we have a month to get our implementations up to speed and then the practice itself will not have physical the physical meeting but will be done over the internet questions commands yeah so we have to draft here that there are working of documents and one draft there is completely new and the question is who cares about this ah de replication scenario Christian brought up so do we do we have the energy do we have the interest in this group to look at this is this something we should push to the research group well I am interested because I also work on that some years ago but I wouldn\u0027t mind revisiting it is it something where we think there will be a standard track document or is it something that just is good to explore some more in the latter case I would push it into the research group because let\u0027s maybe do these things research research group sounds good to me because I this this idea I don\u0027t plan on this to be the way how those things work but I like this to document that it that it could work and to explore what we are running into when we are when we are when we\u0027re doing this so probably I should just ask t2 TRG if if there\u0027s interest in picking this up there yeah so maybe you have to find the chair Stewart Cheshire from Apple I think if we move to a world with many many things in the home automated work and to not want a single point of failure so this may not be urgent but I think it is important at some point we\u0027ll want things like this um so since you\u0027re there do you have an opinion on how to distribute it is it dhts or are we "
  },
  {
    "startTime": "01:13:15",
    "text": "thinking something else it\u0027s too soon I don\u0027t have any strong opinions for or against any solution I do feel like we will want some kind of solution we\u0027re not there yet most homes have a single Wi-Fi access point and if it fails it fails so clearly we don\u0027t have a fault-tolerant system but I think we will want something like that in the near future Thank You Otto Kira and without any hats I think it\u0027s a very interesting topic I would like to explore it with the thinking Archie co-chair hat on sounds very much kind of the explorative thing that we should be supposed to be doing in the Archie so we very much in favor of taking this here ok ok so I think we\u0027re done with this point here Michael since we are ahead of schedule we might be pulling the group communication to today so just prepare for that but the next item on the agenda is come on and I have to dig out the slides for a little so start talking and I will try to find the slides and yes and you can have a laser pointer but ok I I love the background here I\u0027m not sure if it\u0027s going to represent connected devices 20 years from now all them talking co-op anyways yeah so ok hello everyone my name is alexander panov and i\u0027m going to present the advancements of the things that we\u0027ve done with kamae in the in the in the past months so there have been several quite exciting things out there and and now the basic message that is the takeaway from you is that we really need your input now and he\u0027ll be asking for all of reviews so the looking at all the people that are here each of you can get a documentary review so that could be good but I really am going to be to be asking for you for this so what we done the last time and what we had so we that there are new releases new versions of all the documents so there are three main documents for three main documents for Africa my so we have the yang to see bore the carmine document in the state document so these are all working group items and the yang to see bore is from the point of view the altars it is ready so we would like to make a working group last call on this one and yes so please do review this one and I can talk on "
  },
  {
    "startTime": "01:16:29",
    "text": "this also okay now I can know what I\u0027m going to talk about okay so this is what I was saying about so we have these three documents that are working with items and they have new versions so we did some minor changes there to the yang to see Boer and it is ready for a working group last call so basically the things that we did there is you have this thing that is called young template and we just needed to make sure it is in rest conf and we just needed to make sure that it works out of the box which with the encoding with a young to savour encoding and as of today it works so basically I don\u0027t see anything that we could add to this document so please do review it then we have the comments so the C bar is the encoding thus it provides you how you encode identifiers and the comma is the protocol itself so here for the set document that provides identifiers the only thing that reminds that that that remains is for us we need to to see if all the things that we added actually that we made sure for the yang to see bor are actually also true for the sit a document and go again through a jana about this and i would like for us to make a working group last call after this and on the comma i draft well here we need to go over a couple of things to make sure that it works out of the box the first thing is the young template then there is this new thing or at least for me it was relatively new the yang attached we need to make sure that it works with nmda and for yang push so we talked to during the weekend with wood Hank so we found out that there is basically it should work out of the box so it\u0027s pretty much okay so this is here actually it\u0027s pretty strong what we are seeing right so we at core we develop this protocol come by and we say okay we take the yang world and bring it here into the IOT world and so the people in the yang world they continued building new stuff that is quite powerful and we are just making sure that how it actually works without changing the thing that we did we did here so I think that\u0027s a pretty powerful thing that we are seeing here and and yes so these are the three drafts here and there is this new draft that it\u0027s not an inn of the receipt it\u0027s in version two so it\u0027s stable since IGF 98 and it is the coming introspection model so basically how do you learn for models that are already there and so here this is a question do we want to do this in in core so I\u0027m going "
  },
  {
    "startTime": "01:19:30",
    "text": "to ask all these questions once again and the end of presentation I just wanted to give you a couple of pointers how you can start using come by today so there are a couple of implementations from that\u0027s from from the last from the last time they were they were existing in go in see and there are some people that tell told us that they had their own implementations we had a virtual interrupt at the last hackathon so we tested it with fetch and so we just the fetch operator without that system and it actually proved to be quite challenging to have such a big a module for for interrupt from the start so that was a lesson learned and on this hackathon what we what we did we scale down a little bit on what we wanted to do we wanted to start an open-source implementation of kamae so we were postponed in this for the next time but what we did do is we joined the semantic interoperability we she hackathon where it you had the things coming from coming from the t2 TRG coming from the w3c though so you have this thing description and what we showed was that you can do the mapping from yang to the thing description and you you have the bindings from comma to expressed in this thing description a lesson learned from there we need at least to have to save the get method but mostly we need to say to keep the methods that we have get post put delete so that we are able to keep this compatibility with the thing description so if you remember the last tight if you are saying okay we would like to simplify the document and remove everything except fetch and patch right now this thing actually seems to point out that it is it\u0027s going to only I mean the whole day the ecosystem as a whole would take a little bit of time to be able to express everything in only fetch and patch so it would seem a little bit too fast to go and say well we don\u0027t need get input it\u0027s already there on the document it there is just an implication that we will not be able to simplify the document by just removing things I\u0027m Matthias Kovac speaking for WC vapor things so in the TD we try to to allow for adaptation so if you have an implementation that uses let\u0027s say weird methods that we can allow for that however they have there was quite some pushback there that like the sensible default should be in place that there is something that people can converge to and something having a get for something that this link to is is kind of one of those if you want to simplify and say hey this is a very constrained environment we really have to cut it down to the minimum you would have to deal with something that you cannot have properties that are something that their state is directly exposed but you have to use actions all the time basically an "
  },
  {
    "startTime": "01:22:31",
    "text": "action to read something an action to write something but that\u0027s what you\u0027re doing if you only have fetch yes so so that\u0027s actually a very good first lesson that that we that we have out of this and it was you know at some point we were super excited that\u0027s okay when all we can do really super simplify the thing have only fetch in patch but it from all this interoperability point of view and from the from semantic interoperability it wouldn\u0027t be reasonable so this actually says that ok we did our work right it\u0027s everything\u0027s there we cannot really simplify it more than it is so so yes and then the last time we didn\u0027t interrupt that was some kind of a private interrupt you know we like you over the internet and people are just setting up things so it showed up that there are actually quite a lot of difficulties doing this one of the difficulties that you know we were using ipv6 and UDP so you tend to have some filtering from time to time with these things and we had these issues so from the last IDF we saw some great people here that work at eff inter up and so their logo is cropped here but they will forgive us about this so I\u0027ve interrupt for those of you who have not heard this is a platform so it\u0027s an open platform the you can go and you can do your interoperability tests on that platform so you have like an environment that is set up for you it is open like it\u0027s a European project like so it\u0027s you know it\u0027s really used for this and you have the way to coordinate the things to just nip the traffic that is so--but when you do your inter up you have a sniffer that is going to write down the all the packets that are exchanged and and you can have even in some cases a verdict that will tell you okay that the interrupt passed or failed so what we did is we actually published our implementation on on this on this side so it is called like a reference implementation which is reference for the eff interrupt so this means that you can go there and you can set up your own interrupt session and you can run it and it will run and you can have come I server setup and akamai client so depending if if you wish to test if you have a comment you can go there and test with Akamai server if you have it from my server you can use the come by client that\u0027s over there and for the moment the methods that are implemented our get fetch put patch I patch and delete so we have not yet implemented the post so just to working to show you a couple of photos that it really works so you go to this Internet address you sign up and then you\u0027ll get good to go and then when you when you sign up the only thing that you need to you know you say okay I want to new tests you need to click here on interoperability and then you see the because you here you have a list of tests and you need just to click OK I want to do come my test shoot and then "
  },
  {
    "startTime": "01:25:32",
    "text": "you know you click Next Next and and so forth and you have like you have all think out because there is a VPN you can connect over VPN and then you have five to v6 and you know that no filtering and so forth so it\u0027s really user friendly and like it\u0027s not us that we\u0027re running it so you have a whole organization dealing with this so really great you can start using Carmi today the test file that were published so we wanted to do something simplified and we mean I Jeff system is you know if you want to make sense of things it\u0027s it could take a little bit of time so there is a very simple tile that it basically has three so it\u0027s a simple model with three leaves so we have a container interface and three leaves IP address name and throughput like it\u0027s almost invented and then we have the seed file that is generated out of this so you have so this is the the identifier that number you have comma int or blah blah blah and this is the SID so for the moment we are using seeds that are from the experimental range and basically if you want to run today your first command request you go to F Interop you create your inter up stuff and then you do a coop get to slash c /r f y and this does get a get on this set file so you\u0027re going to get the IP address of that thing so it\u0027s as simple as that so that was the first point there is implement so there is the implementation you can start running it today the second point is about the registry so now the the registry is so this is the first draft of the registry if you wish it is not yet approved by a Jana but we have started already allocating ID so that we can learn how to use them so you can come here so the name the URI Cisco my dot space come I dot space so you go there fortunately here it is cut but you have a couple of URLs your eyes so he can go and you can say well what are the more models available and so you can see all of them so there are some of the system\u0027s ones are over here so you can see the models and you can click on the yank file and the seed file you know this is only about the sits right Yankees just for consulting that thing and you have tools you can generate the seed file from here you can you can generate the egg file so you can do all the other young file but you can generate the city file and all that stuff so it\u0027s all there just go there and with this I\u0027m going to say ok well we want we need reviews of young to see Boer and I think the best well this is just starter working group last call we have core and the the sit and the comma drafts and here we really need neat reviews so we will check these things and you know by the end of March that\u0027s sir by the end of March us for sure maybe I\u0027m not sure by the end of the week we\u0027ll bind of by the end of March and and yeah then we need we "
  },
  {
    "startTime": "01:28:34",
    "text": "really do need reviews I mean we as authors have done have done so I\u0027m reflecting what Christian said we have done to what everything that we could do here and we can spend lots of thoughts of time just you know trying to say okay improve readability but if we don\u0027t have any input it\u0027s difficult for us to say well you know it\u0027s so who is willing to review the yang to see Boer Hank yeah hi this is listening half-year I can make a exploration endeavor Internet conf and maybe select a specific individual there that helps me in concert to a review on that but that is the only way I would commit to that if I do not find a partner there then I will not but this I will try to okay okay thank you that works pretty well for me yeah the whole situation is pretty complicated because we are doing something here that that goes into a different ecosystem and so the the reason we haven\u0027t last called Yangtze bow yet which which is essentially done and has been saving for a while is that there is a certain risk the more we learn about using it in practice the fewer mistakes there will be in there but one one view would be we can do this now we have played with it for long enough even though we don\u0027t have specific event where we could say oh we just went through an interrupt and and it was great but it has been around for a while people have played with it and when we do the working last call on this this certainly will be in concert with net mod which is doing the yang work the the other draft are slightly more risky because yang is right now going through their second system syndrome and has actually it\u0027s not yang it\u0027s the natural environment that wasn\u0027t precise yang is not a problem that\u0027s why we can just call the first one they have this nimda thing I forget what dimdim means but it essentially means let\u0027s redesign everything and so all the the documents that into H with the Netcom freeing space need huge weeks to make sure that they actually work in the nominal space as well and right now I personally am I\u0027m not feeling very sure about the fact "
  },
  {
    "startTime": "01:31:37",
    "text": "that we have done this but I also don\u0027t have any indications that we don\u0027t have done this so that\u0027s something where we again need input from the network management people and the same thing is true for the yang library I think it\u0027s not yet entirely here that we have to do this at all but it\u0027s it may be a good idea to have our own way of getting this catalog information so it would be really useful to have input from people who want to use comai whether we should be pursuing this or not yeah so I think as a worker we are in a somewhat difficult situation here but on the other hand this stuff has been stable for a while apart from the nimda issue and we should be finishing it so yeah you asked for reviewers for the yangtze bar who would be reviewing the CID and comma documents from this working group nobody nobody in this room do we have a conflict with some net not thing or net conferring so everybody who who would do this is not in the room that that sometimes happens that\u0027s a question is there a way to have last working replace going to working group and consulting and another working so yeah so that there is no formal last call and everyone rules but by just informing then so how about we we say okay there is the last call and wake up and we say to net Mott also and this should make people react because then we can stop the last okay let\u0027s try this out with young people the reason why young people really would benefit from from an early last call is that there are people who want to use yang as a data modeling language way outside of net Conniff just used yang as a data modeling language and and used the CBO representation so the this draft it contains everything that is needed for that so we can can go ahead with those applications okay so commute seems we should be starting the the last call on now should a little bit for for named our verification of the komali things there\u0027s probably not that much that that "
  },
  {
    "startTime": "01:34:37",
    "text": "will happen with CID based on him but I\u0027m not an indirect spurt and then go for last call next month okay thanks and do the interim it\u0027s really cool interface yep one comment not related with this one but with the DNS there we saw rectory DNS SD caroling is pointing out in the jabber that the DNS is the working group in on Thursday will that drop will be presented on that group on Thursday for those interested yeah I said at the beginning Jerry was a reminded because it\u0027s not in the miniature yes thank you okay so I think we are done with this item here and that means we have about half an hour change or 25 minutes gained and we can start doing atoms from tomorrow and I think we should start with the grew from stuff because that also was discussing is too a quickly find the slides for that and it\u0027s usually just allowed to start talking while I\u0027m digging out this ledge okay they\u0027re really allowed to start okay hello mark hello karai six this document got adopted right after Singapore it was resubmitted with minor polishing well this version zero one is an actual major update after that yes most of the updates are actually out of two major reviews we got from ESCO and Peter after Singapore thank you very much for that indeed so based on that on those reviews we essentially euro structure the document organization quite a lot and clarified as many things are possible and here just summarize the the main ones we took care of already started from the terminology we notice that there could be potential for confusion a third work group so we we provided the exact definition we intend to have for that we refer to a security group as a set of n points sharing the same security context and essentially key material and policies and so on so this doesn\u0027t have to be confused with other possible meanings like network group when it comes to possible IP addresses identifying a multicast group for instance or even application group meaning a set of nodes running the same application in the context of a security "
  },
  {
    "startTime": "01:37:38",
    "text": "or network group so here we mean only security group and you you can map that quite flexibly in other kinds of groups as well in the security context especially other comments from Peter I guess we try to clarify as best as possible how the different types of contexts so commands and the recipients are established and arrived later derivations especially occurring around time and obvious requests as well we added a new table highlighting the exact deltas from the contexts we already have in the menos core document and and do the content we\u0027re adding here in this one in section 3 about the the cozy object that was an explicit request from s call so we had the examples on request and response messages before and after compression and we switched to countersignature 0 because we believe it\u0027s quite effective anyway rather than countersignature and we updated the externally ad in order to mention explicit with the signature algorithm used in the group for counter signature and we removed after the the group ID for external a because it was really necessary to have section 6 is a new one to have definitely because considerations on what the group manager is supposed to do in the difference days of the protocol were actually scattered all over the document so we essentially collected all of them now they are list all together in a single section where the last two or three are actually optional features that the group manager can help so now they are all collected in a single spot we had some work also in the appendices actually that they were a little bit restructure rephrase the move appendix a used to be a section with assumptions and security objectives and it was quite distracting where it was and it made also cooler the alignment with the menos core document so we thought just to move that as an appendix we got some feedback in those reviews about the use cases so we just improved their description appendix B well in Appendix C where we already gave an example of how a group identifier that partially changed dynamically can be encoded now it comes also with an actual examples considering again the constructor we already had as prefix and above then in appendix D this is also related to what we presented this morning in India\u0027s meeting we consider also the alignment with new draft a ski group calm because the panic still provides an high level description of the joint process that pointing at the ACE approaches the recommended way and now we have announced that pointing at the new draft those are the main points "
  },
  {
    "startTime": "01:40:43",
    "text": "addressed in the revision now there are a few points open to discussion for which further reviews and feedback are or an welcome there\u0027s a point about the Independence of the security group from IP addresses altogether so far we have mostly thought in terms of a request message especially sent over multicast coops over a multicast IP address but there are some cases were requests especially selectively retransmitted can or should be same even unicast both online the group identifier should be just enough to retrieve the correct security context one needs to process a request right now is the the draft says the context is retrieved considering the pair group ID and IP address of the group so perhaps is just better to force this the coupling altogether and use the group ID alone and the sate another thing we have kind of solved that with a few may exchange with with a school today - we are currently stating that it\u0027s important that the G ID is partial at least in a part of it random and large enough especially to to avoid global collisions with group identifiers of other groups under other group managers we can potentially and neglect at least be less strict when considering randomness and large size of that part of the group ID please beat that I pitiful most okay very obvious question how do you see there how do you want to get a relation between multicast address and gid then handle you think about the resource directory or do you want to do autonomous maintenance main vehicle management okay do you wanna mismanagement of the multicast address with respect to the group ID can be through a source directory or group managers then in case you need to coordinate with one another or both online one can try possible different security contests that can be both retrieved and try them until the right one is found out as a tiebreaker okay do you want to remove it completely from this document and even or any reference to the multicast at the as I said this is a different problem or that I\u0027m not quite sure here it is essentially a separate problem the point is being able to send the request of a multicast API that is still possible anyway okay I don\u0027t believe that this is necessarily restricted to multicast it could be unicast reso thanks a lot "
  },
  {
    "startTime": "01:43:53",
    "text": "oh yes this is about the terminology so right now we have force and stress quite a lot the multicast were so that\u0027s why the terminology multicast there meaning an endpoint sending requests over multicast IP and that\u0027s it but back to the comment before perhaps we could just consider to simply the the same terminology we have in our score and that\u0027s it and and that would in turn simplify also de the enrollment of new nodes in the group cause it just reduces the amount of roles they can have and by the way they are just the same again so you\u0027d have positive side effects too it should be totally doable and finally more on the joint process actually as I mentioned also before the appendix covering the process is still a high-level example but is structure at very high level guideline more discussion on about how to provisioning and handling public keys and I\u0027m pointing at the Essbase approach we we have an SS the recommended way should we keep this line of reasoning and keeping the the way open for a possible alternative approaches that then the one in a soar we should just go for the ice one as the one the ACE one is aligned with the general guideline in the first part of course but just in case other approaches can come up later on so far we are allowing that in principle because I would like it if the interface that you are assuming here is very documented that\u0027s good if you want to put another joint process in there but it\u0027s also good for verifying the east joint process so it\u0027s clearly do you find what security of the property is you you expect from that joint process so I think it is a good thing to to keep a clear boundary okay yes sum up they own the implementation we already have last year in Prague a proof of concept in contiki of course along with it now old version of the drug not with the very last one but I recently came to know about an implementation from other innovation developing see for the anklet a smart board and that\u0027s also centrally aligned with the very same version of the document considered by the kontiki implementation so we were wondering that this is possible possibly good for taking first steps to an early interrupt perhaps already marell can promise that "
  },
  {
    "startTime": "01:46:54",
    "text": "but you can try yeah we\u0027ve already talked about that but it\u0027s essentially a related activity nice describing how the joint process is performed key provisioning including using the ice framework and whatever profile of AAC you need to use to secure communication between the joining endpoint as the client and the group manager as the resource server but you find more details in the ACE draft about that that\u0027s all I have thank you so who is read the most recent version of this document how long has it been out okay so generally who is interested in reviewing this document so we have had a few people who reviewed it okay so there are about five hands up now okay thank you so we still if I left and we could just continue with the agenda which would make re the next guy who is yes but it\u0027s less juggling if we just use them the next item on the agenda so we have a few surprises in store today okay um so too many requests response code for code how to check what is actually on the agenda so the background on this is this common cold case that a client can be bombarding a server so hard that the X becomes overloaded and the question is like how can server tell hey you are doing this too fast please back off I nee to DP there is already find an error code four to nine called tool a requests so it seems quite sensible to also register it is for coop with a four point two nine and the acog specific edition here would be I would use the max-age option to indicate for the client when is it okay to try again so that\u0027s rough the gist of it and this is originally part of the co-op\u0027s a broker so it was decided in the last IDF meaning that it changed this kind of an error code seems have used much more wider scope than just a broker it makes sense to do it as a separate RFC and there\u0027s also a recent ocf interest for the same kind of functionality there\u0027s all one question that came up during the drafting of the details of this specification is that should there be a way for the server to say well don\u0027t do that but here\u0027s a set of things that I might be considering okay for you to do so what the current text says the client shouldn\u0027t sent the same request before the max of max age "
  },
  {
    "startTime": "01:49:56",
    "text": "option has passed so however something may be useful here but maybe again this is something wire and just for this response code could be actually applicable for other response code so maybe this is something we want to consider but keep actually outside of scope of this draft some generic method for some hypermedia controls in the veil or perhaps or some header extends until I hey here yes okay okay actions but that\u0027s the key part of it our previous slide so constant again from the floor this sounds like a really good place to remind people that they can actually send response bodies with error responses and you could explicitly point out that that the array response that comes back might give additional guidance and then people can just register media tribes that they provide that their guidance and we have a nice decoupling from respond fault code itself exactly however maybe that\u0027s not something you want to specify in this draft that has a generic mechanism so I would recommend keeping that I\u0027ll scope for this however would be very useful to progress this draft relatively fast because of its gonna be now a normative dependency for the Bob\u0027s a broker and as it\u0027s also interest in outside of the IEP f-for using this so keeping it simple and being able to progress seems like a sensible way forward however there has been a discussion that well there\u0027s also another and some other response codes that we may want to be defining and shoot this draft then be bundled with some of the other other response code if they are something that we can progress fast and in a non-controversial matter probably it makes sense if it would be delaying publication of this draft I would be bit worried of that but the key question yeah okay working group item since it\u0027s a normally dependency and was agreed on the last IETF that it\u0027s already it was already part of a group document but we just played it apart having work group working on this seems to be a reasonable way forward yeah so it seems to me that we should just do the reproduction call on the mailing list now and then essentially when that time is over do the working class code sounds like a plan to me Peter farmer stock I also had an controversial response code which has been presented already twice I think and I very much would like it to go forward it the same smooth way as is proposed for this response code and I would say that bundling the two response code to "
  },
  {
    "startTime": "01:52:56",
    "text": "have the same smooth treatment would be very welcome indeed you know I have a slide for you you have a slide for me yes no but let\u0027s do this this thing first so anything else we need to discuss about that so you you have a little bit of feedback you can do a dash to zero ITF - the view of the document after the Wagner adoption and then we do with the working class code and if Peter is fast enough to get his stuff in there before the way you bla scroll immunes oh the cheese okay thank you we have fun okay we still have six minutes left enough for Peters I don\u0027t do you want since you\u0027ve already started we have to pick it up again tomorrow but this comment goes between these two presentations that there is a second response code that we defined in observe that is similar to this which one is it it\u0027s basically analogous to the HTTP no content response 204 and HTTP we want to define a similar response code for co-op okay and please to oblige what is the motivation for this draft that the robot of secure transport uses the HTTP response 202 and which means it\u0027s not immediately available but say come back in ten minutes three hours and then you can get the response and this response code can be returned both for and get or on post so just doing an observer on a ket it\u0027s not sufficient because you want also on the post to have this response caused um though we have no such response code for co-op and nevertheless we need we need this the HTTP 202 and it commands the HTTP 202 has been done for memory here I\u0027m not going to read it aloud I mean it tells you look here it can be a request it can be delayed and eventually in the response that can be said where you can monitor it your request well we have three use cases for this kind of response codes first of all there is this is D co-op s then there is the cutoff score perp SERP which has a bit different treatment it doesn\u0027t say you have to wait for the raise for the result but actually it says there is no result yep so you go away and don\u0027t bother me and "
  },
  {
    "startTime": "01:55:56",
    "text": "then there\u0027s of course the too many requirements which we have from we have just about which is also a new response code so the proposal is one RFC which we discusses these three response codes and we go forward smoothly and hope that it will be here a proof by the working group I want to stop here so I could use the the last three minutes to present my slide on this so basically co-op is is a lot like HTTP except where is and we have tried to keep the the color state machine simple so for instance we have decided not to do redirects even though redirects are but by mini HTTP people consider to be a basic part of HTTP that everybody should always do koib doesn\u0027t use them and there are two reasons for this one is redirects are really badly defined in HTTP so that that\u0027s would be hard to do this right but also we just want to keep the state machine Center and the difference between error response codes and success response codes is that error response codes all create the same imprint in the state machine there was an error so the request as done no caching and so on while a success response code actually requires every single client to have code to handle this success case now one one way to handle it of course is to say I don\u0027t understand this so I give up but okay I think that\u0027s that\u0027s really counterproductive so adding a success response code is an expensive operation because kind of it\u0027s the whole ecosystem and now that the question is if there are application-specific state machines that that happened to have something in HTTP that kind of seems to have handled that I mean that the way ESD has appropriated tort words is I\u0027m not going to comment about that but is that a reason for us to emulate that or should we just say there is a rest approach to do these state machines if an application needs a state machine and you transfer representations with the important information to run the state machine so my feeling is just as with redirect where we told ocf oh you can define a media-type that has all the information that that would be an redirect we could do this here and say oh we can defined a "
  },
  {
    "startTime": "01:58:59",
    "text": "media-type that has the content is not yet available now those applications that that need to cope with this of course now have to implement that media type so we have reduced the complexity to zero but other clients that they don\u0027t care about applications like this don\u0027t have to take an impact on on their state machine and I think this is since we have about 40 seconds left this is one thing that that you might want to take home for for the afternoon and we can continue discussing tomorrow morning but I really like to hear what what the view of the working group on this is do we want to open the floodgates here or do we want to be as frugal as we have been in the past with that thank you for coming today tomorrow 9:30 in another room I hope everybody will find other bullshit "
  }
]