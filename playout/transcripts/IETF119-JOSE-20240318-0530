[
  {
    "startTime": "00:00:24",
    "text": "Sure. There's no talk. Is is is already? Of course, I it's not working for me. To unlock button missing. Outs are. Let's try super comes. So So We will go ahead and get started. Government, So this is the Jose Working Group at IITF. 119. Welcome, everyone. As you know, And these are your chairs. All three of us. John and John and me, I think is it not on? It feels"
  },
  {
    "startTime": "00:02:01",
    "text": "loud to me. Can you hear me? How about this? Okay. Excellent. Welcome to the IETF Jose Working Group. And, With that, This is the note. Which day? Just remind people that code in. Apparently, the QR code outside wasn't but that one Okay. So there are reports that the outside QR code is not working. So please share to use the one on the screen in front of you, or just log in through data tracker? Parks as well. With that, this is the note well for the IATF. You will have agreed to this when you register for mating. Any contributions and any discussions in these meetings all fall under the purview of our note well. Along with that, there's also all of our process and, code of conduct, anti harassment, those kinds of things. If you have any questions, about the any of these, please be sure to ask either one of your chairs or our area director who was Roman, and I'm not sure if it's going to transition to Deb or We're transitioning to Deb or to Paul. Okay. Well, we will have a new AD at the end of this week. I'm just not sure who It's air. Is it? Yes. Okay. We'll find out. We don't know. But anyway, as, as you all are probably aware, Roman is Now the general chair, and we will get a new security area director responsible for our work. So I would talk to them. This, few things. The draft minutes will be taken on the online notes tool, please, help contribute I did send an email. Suggesting that we could use any volunteers for, Minutes. I'm not sure if somebody has responded to that email. Is anybody willing to help with minutes?"
  },
  {
    "startTime": "00:04:02",
    "text": "Minutes. Thank you, Ori. I love volunteers. Also, remember a reminder to use the Q tool which, again, will be why you will need the QR code or to log in. Be clear, concise, and respectful, and act according to our code of conduct. Brian, did you wanna say something? No. He just hit the wrong button. Okay. This is our agenda. We have a fairly agenda for today. Is there any agenda bashing? Nope. Okay. With that, the webproof drafts, Mike, you're presenting. Right? Let me A proof specification. Confirm you. When you can advance slides for me, or does that work? It it works. If if you Good afternoon. I'm Mike Jones. Thank you for coming, and we'll talk today first about the JSON Webproofs work, which, we got the In some sense, this working group was rechartered in order to do this and related work. So there's actually been a lot of progress since we last Met our heroes in Prague. There've been substantial normative and editorial updates of 3 of the related specifications. Among other things, there were a bunch of places that the spec used to just kinda define things by examples, and now I tried to do a comprehensive pass to normative statements about what those things that are also still in the examples due."
  },
  {
    "startTime": "00:06:01",
    "text": "Where we define header parameters and algorithms and the such. Now there's, requested Diana registrations for them. The proof representations were updated to be a to contain multiple parts, which simplifies some things for some of the algorithms. It turns out that there's an ambiguity or there was an ambiguity about You couldn't tell the difference between an undisclosed value and a zero length value to be closed. And we fixed that. We define some terminology and put them in sections. There's some moving parts that were dependent upon, including the BBS signatures draft and the BLS key representations draft And the both the references and the examples were updated to use the current versions of those. And there's more and better examples. I did a full proofreading of the thing in December. And filed a bunch of editorial and normative stuff as a result of that. And we've finally made our way through the majority of the issues and PRs that previously had been hanging around. So I'm happy with the amount of progress on the drafts There is a landscape of related specifications. 2 of which I referenced earlier. The BBS signature's draft continues to evolve. It turns out that the signature format hasn't changed, but the proof format. Has changed a couple of times"
  },
  {
    "startTime": "00:08:03",
    "text": "Based on input from real cryptographers. And it turns out that that that may not be done But the, Our drafts use some open source software that does generate or does perform the BBS computations. In alignment with the current BBS drafts. Then, you know, I read the key representations draft for. And discovered that it was inconsistently using the key type parameters. So I fixed that and just messly editorially that Letters, b l s. Are people's initials just like RSA, are people's initials So we determined though those should all be spelled in uppercase. These are the decisions that really matter. Finally, come to Jose tomorrow. Because, Tobias Looker is going to be talking about Whether add a compressed key representation or not. Currently, we just have uncompressed. Turns out that there's a The spoke key representation an underlying draft that's, is it cryptokash or something defined? Anyway, this is not for us, but just saying We have some dependencies on things that are still moving parts. So what do we think we should be doing next? We should continue working through issues. You can file issues. This is where to do it. It's in the slides, and you can get the slides online, continue tracking Changes to the specs were dependent upon."
  },
  {
    "startTime": "00:10:00",
    "text": "We would really like to add representations for another zero knowledge. Proof algorithm other than BBS. That said, in an ideal world, we would like that algorithm to be standards track and have multiple interoperating implementations. Some people have talked to us about CK Snarks, there's been some other possibilities. None of those may all the criteria, but We have a working group to the extent that any of you is interested and defining representations for an additional ZKP. Algorithm, The editors feel like that would give us more confidence that the container format that we're defining is actually general purpose. And not overly specific to the things that we already know. And understand. So if any of you, love a ZKP algorithm come talk to me, put it on the list, and whatnot. Finally, there are several implementations out there Some of the implementers have been filing issues. Which is great. And I think we're coming up on the time that we would learn things from trying to get the different implementations to interoperate and see what works and what breaks and what was commonly understood and what was misunderstood. What we didn't write write. So It's your turn to tell us now what You think about where we are and where we want Ticao."
  },
  {
    "startTime": "00:12:03",
    "text": "The floor is yours. Go ahead, Rory. Alright. Boris Steele. On the the comment about, additional algorithms, just for folks who are groups. I would personally really love to see something lattice based or error code coding base, something that can something that's not based on the elliptic curve discreet log. In terms of the the cryptographic problem, the the signatures improves are based on just because, of all of the debate within CFRG and other organizations on, a post quantum threat model and migration strategy. So if it were possible to find something that fit that category of we think We think this is maybe gonna do well, you know, the when compared against the discreet log, that would be really awesome. I'm not a cryptographer, but it would love it if someone who's excited about lattices and has something that they're aware of that might fit these interfaces could share, that would be great. Yeah. Agreed. And I'll just repeat. It's really gonna take a volunteer who's passionate about this to you. Write some text and work with the working group to add this. Procedurally, everything we're doing now is standards track. And so When we decide we're done, we could take these 2 you know, the various last calls and the RFC editor. The latter stuff if it's not or, you know, ZK Snarks or whatnot. If there's not CFRG"
  },
  {
    "startTime": "00:14:01",
    "text": "RFCs on the way. We could still define this stuff, we might put it in another draft so that it can progress at its own natural rate and not delay completion of this work. Comment on Al Grids, both the cozy and the who see short assess that, should have idea of consensus algorithm. For example, CFRG or I, missed standards shall not implement new algorithms but these are not new either. But I think any Gray zone algorithm should be align with the ADs. So we don't end up in, situation like this elvig elliptic curve drop that that got stopped in IS g, I think sync with the AD, what the what the AD, it it won't. Absolutely. David David, do you still wanna be in the queue? Let me go to Michael and we'll come back to David. Hey, Mike Parrock here. Yeah, thanks for this. And just to follow on Dory. I know plaza would be the one thing I would be tracking from a ZKP standpoint, as far as lettuces go, I don't think that work's gonna resolve to, like, 2026, but there's some good starting places on that. So now might be a good time to get some of that in front of CFRG. I know some of those prior things that that this is built on have been reviewed there. So, I did put a link in the, chat to, one of the more current papers on that. So definitely worth reviewing there. Something. Sure. If that could get its way up to the notes, that would be really helpful. Okay. So David seems offline. Just no more questions on this Draft. Alright. We'll move to the next one."
  },
  {
    "startTime": "00:16:12",
    "text": "And what do you know? I'm still here. This time to talk about work I've been doing with the working group and, Corey Steele as a co editor. On fully specified algorithms for Jose and Jose. Next. Okay. I can do next. I am empowered. So the last two ITS I've talked about why do this and what it would be. I am not gonna do that here. There's links in the deck. Us to the introductions to the draft that says why do this and what we're doing. And you could look at the slides from last time if you are unfamiliar with why we're motivated to do this work. So there's been progress since ITFA 118. At 118, this was an individual draft. There was support in the working group meeting to adopt it. And then we held a successful call for adoption. In January, that there was a lot of feedback. A lot of people said yes. A few people said I wouldn't do this. I would do it differently, or if you're going to do it, these are the things I would try to cover. And, you know, I value that feedback not just the people who said, yeah, do this. Because there's useful information we've mined and tried to use to improve specification since that. So we published a 00 draft that was just the individual draft. Turned into a working group draft in January."
  },
  {
    "startTime": "00:18:01",
    "text": "Then we've published 2 subsequent drafts that are intended to incorporate some of the working group feedback we received. During the adoption call. There was text added on what it means to be fully specified when you're using multiple algorithms. In a computation. Well, when would you do that? Jason Webb encryption Has both an algorithm an an algae parameter to establish the key and an ANC algorithm. To do the block encryption. And we talk about both of those needing to be fully specified, even if independently. For the combination to be fully specified. Likewise, because there's multiple algorithms in different phases of the computation in particular for Jose encrypt, you get the same thing. You have an algorithm to establish the key, and you have an an algorithm to do the ball concryption. Or he's been tracking some of the, post Quantum work, which you'll hear about in Jose tomorrow, but We added text on key establishment methods. What it means for them to be fully specified. And encapsulated keys. And we tweaked the instructions to the designated spreads to make them even more. Precise. There's one set of open questions which was raised in the last IETF and has been discussed on lists since that, which is What to do about Eleptic curve, Diffie Hellman Key agreement, and it friends."
  },
  {
    "startTime": "00:20:01",
    "text": "ECTH takes as a parameter an ephemeral key, which has a key type and An algorithm. Which means that ECDH as it's written down is not fully side And there's been disagreement among well intended parties about whether This draft needs to deal with that Right now, before we Proceed. Or whether we can define the principles do the new algorithms for the low hanging fruit. And leave it up to the working group to decide whether to do another draft that creates replacements that are fully specified. For some of these things, an ECDH being the primary example. So there's a question, and I'm open to either answer from the working group as I believe is Orie. Should we create fully specified algorithm at Denners. Identifiers for ECDH. So for instance, you might have ECTHES using ES256. You might have ECDH Yes. Es 256. For a 128 key wrap. And equivalent things in the cozy space. Some have said on list that we think if we're gonna do any of this, this draft should do the whole job. Others have said it it's okay to do the low hanging fruit, which we feel like we've done and decide later to do more or not. Brian Campbell and, Alari, very usefully, did, at least, you know, a back of the envelope of how many new algorithms would we be defining if we define"
  },
  {
    "startTime": "00:22:02",
    "text": "fully specified variants of elliptic curve curve I wrote that up. Of Diffi Hellman, key agreement. And it would be 10 or 12 or something. So let me pause to have us discuss this point in the room. Go ahead. Mike Parikh. Yeah. I do think we should fully specify them. Because otherwise people will get themselves inevitably in trouble. And that's part of the reason we wanna fully specify this stuff to begin with. I actually am a fan due to the the characteristics of Diffie Hellman stuff. To put that in its own draft because that can give some introductory text as to why given kind of the femoral key parameter nature of things that you would, 1, wanna handle this as its own, kind of thing. And then list those things out cleanly in one place. So, I think doing that as a separate draft versus the low hanging fruit that's already been done is totally fine Thank you. Fill it. Fill it. Fill it. Good day. Thank you. Hi, and good morning, everyone. Question to Brian, I guess I see him in the audience there. The 10 to 12 new algorithms was that product of the Cartesian matrix, or was that something that had to do with the relative strength of the ECDH and then the curve, and then possibly in the key rep, portion also the key wrap. Hi, Philip. It was. It was taking the Cartesian product and trying to whittle it down to those that made sense based on the the, related strengths of the composite algorithms, I don't remember exactly that. What it was, but I think that you all listed, That was the idea anyway, but I it was kinda back of a"
  },
  {
    "startTime": "00:24:00",
    "text": "envelope. Thinking, Right. The the the thing that I worry is, like, the the cartesian itself would be as far as I can say there's, for ECDH algorithms today, There are 5 cards registered for ECBH. If I omit the 2 secp256k1, which is not defined for ECDH. So that gives me 20 already. So that's why I was asking 20 would be around working, I guess. So if if we are only considering the ones that make sense, And I can see that in the slides now. I'm I'm sorry. It's it's 6:6:30 in the morning for me. So I never quite left Praga who lost the ATM. So Thank you, Brian. Brian, did you want him? You're still on the queue. So Yeah. You're on the queue. Part of the thinking in that was trying to enumerate the number of new hogs that would be there and get it down to something made sense. But as I said at the end of that email, Even 1012 feels like a lot and given the current state of I don't know. Support for this stuff. Libraries aren't in the world. That the, not that the polymorphic nature of of of of these algorithms, has not manifested itself as a problem in implementations and deployment at least to the extent that I'm aware of. I don't I am really reluctant to work to make these fully specified sort of for the sake of making them fully specified. It feels like maybe a lot of work and ecosystem interoperability pain without any real benefit. It feels odd to talk. To my telephone. But I, I, I, I'm not sure there's really value in doing it. I'd be really reticent to to take that on, particularly as a maintainer of a library like"
  },
  {
    "startTime": "00:26:00",
    "text": "it would be a bunch of work and support work. That almost feels like make work for a, a upside benefit that's not at all clear. Okay. Chris. We can't hear you, Chris. Did you want to try again? And you're gone. Ory, do you wanna go ahead and go to the mic? And we'll come back to Chris. Alright. No worries, Neil. So I just wanted to say, like, know, with HPKE, the HPKE CAMS, are fully specified. And so I kind of agree with what Brian had said, and I think others have said this on the list. Like, like, to fully specify these algorithms, it doesn't, to me, seem like it's providing tremendous value. In particular, if we look at, like, where HPK is fitting into cozy and cozy today. A lot of the HPKE algorithms, they're, well, they're fully specified, and they're kind of the that I would be moving to if I was doing one of these today. And so, If you're gonna end up implementing HBKE in the future, I think you'd probably be sad as an implementer to do that and then also do this. So just some know, the comment there is, like, hpke you know, And and it's chems and fully specified chems are are gonna be maybe the the better place to see this kind of fully specified algorithm be applied in in Hosie and Cozy. And so I would tend to say, Either do it in a separate document or don't do it at all and just use HPK. That's it. Okay. Any other comments for the queue?"
  },
  {
    "startTime": "00:28:03",
    "text": "I assume you'll do this, but there's a couple of notes in the chat, chat, chat, chat, for you. Alright. Let's see Okay. So I suspect we should call this question on the list as well. I guess I'm willing to do the work to at least write down for people to review what it would look like to do this. Her Orie and my pro rock suggestions, maybe put it in a separate individual draft right now. And then you know, the working group could buy acclimation, say, No. Put it in the main draft or no. Don't. But That's what I hear and what I think might help us make a decision Yeah. Mike Mike Parrock again. I'll add a quick follow on, Mike, because I've I've seen comments both on the list as well said. Some of the prior meetings and then just again in the chat here on some folks who have said, yeah, I got myself into trouble. Doing this. I Oh, sorry. Yeah. I think Ori, made a really good comment about HPKE, etcetera, kind of being the path forward here. Right? So by separating this out, if someone needs to go pick this up because they got themselves of trouble. Cool. We've given a mechanism to do that. We haven't found ourselves to necessarily go commit to all that work unless we know for that it's actually worth Right? Yep. So, finally,"
  },
  {
    "startTime": "00:30:02",
    "text": "I I will ask this question on list. Probably After writing down what I think the new algorithms would be. May not be a draft. It might just be an email message at first. But I think that's the only open question left for the draft. And so after we have a reasonable discussion of that, It seems to me that we could just, a working group last call once that question is decided that's obviously up to the esteemed chairs to my left and our new area director, whoever that shall be. Debt. It is Deb. Okay. Good. With that, I believe I am done. Thank you. Okay. Okay. Up next. Use of HBKE for Jose. There we go. Good afternoon, everyone. I'm through. We presented this draft in the last working group and after that, we had several comments. So we've been working on fixing these comments, and I would like to give an update on what changed from the time we present a return the loan. A quick overview is that we have 2 new modes defined. 1 is the HP Key Direct encryption mode, which is more or less similar to the direct encryption mode. In addition to it encrypts the payload as well. And the the HPK encryption mode, which,"
  },
  {
    "startTime": "00:32:01",
    "text": "encrypts the content encryption key, especially for multiple recipients. Why has been, defined few years back. For basically public encryption of, arbitrary size plain text for a recipient public key. HVAC is used by several, IT specifications, obvious HTTP encrypted client. Hello. And in MLS as well. We have, a similar draft running in KOSA Working Group as well. And the best part is HPE interfaces are friendly to hybrid and we have published a draft discussing how, it can be extended to type encryption where we can use both the PQC and traditional algorithms. Yeah. So we decided to pick the fully, specified algorithm instead of the a la carte approach, which is very similar to what cozy, drafters. So that's basically the HPE the mode is basic or it's gonna be authentication or authentication with asymmetric keys, or it can be authentication with asymmetric keys and PSK or just the PSK mode. And then the key derivation function for, deriving the keys and then the aid algorithm for encrypting the payload or the content encryption key. We are pretty much leveraging all these values from HPE INR registry, so we're not venting anything new there. So After all the discussion that's eventually boils down to 2, modes that have defined 1, 1 for single respain and 1 for multiple respain It works in both the serializations and and the first case, the key that is derived from HP Key is used for encrypting the payload and the other case. Encrypting the content encryption key Yeah. So we are we are leveraging the So APS that are exposed by HBV specification and available in most of the predominant imitations today, which is to"
  },
  {
    "startTime": "00:34:04",
    "text": "use the setup based function to create the HPK context And in case of the direct encryption mode, plain text will be passed to the c function, which will get the content encrypted. Case of, key encryption mode, the plain text will be passed into the save function, which will encrypt the content encryption key And the receiver will basically use setup based receiver where it uses the ephemeral keys of the sender and it's long term shared secret to create the Hb context and it would use open function to decrypt the ciphertext which will be either the plain text or the content encryption key Yeah. This is just some examples to illustrate the new parameters and how it's being used. So the algorithm is direct in case of, h take a direct encryption mode. Have a fully specified hpeki, cipher suite mentioned. And then we have the encapsulated key being sent to the receiver so that it can use it within the decouped operation and then the HP key encryption mode where we have predicted header, which includes the encryption algorithm used for encrypting the payload. And then for each recipient, the algorithm and the encapsulated key, that will be sent the receiver. And I think I don't think I don't recollect any pending comments we have just all the comments received so far, it looks ready for working to pass. Fucking production calls. Any discussion on adoption? I'm not sure how to annotate that, but Mike Jones. While I'm listed author, I'll still say that for, an individual draft. This has gotten a lot of attention. On list, from active contributors. So it seems to me, like, there's"
  },
  {
    "startTime": "00:36:00",
    "text": "evidence that people wanna do this work. Okay. So There's I, I don't hear anybody that's actively opposed to doing a call adoption. So the, chairs will issue on And then Short order. Thanks. Okay. Oops. Oh, The next thing is the cookbook. Without slides. Yeah. Sorry, It If someone could That's this will be super brief. Alright. I'm Ori Steele. I don't have any slides. The reason I don't have any slides is that you basically just saw the examples that are in the cookbook. So, The cookbook, is inspired by, I believe, it's RFC 7520. I'm sure Philip can correct me in chat. You're still awake. And that RFC basically provides a number of examples for that's very extremely helpful to implement hers. You can go through them and you can see the structure of the messages that your implementation should court, there's some text around them that helps you kind of understand, like, what is this AAD property? And, like, how do I use it? And they align with, you know, the the specification, but it's really just a grouping of examples. And, the draft that I'm referring to, which I'm sure is available hopefully, and the agenda, and you can click it. You can look at it has some examples for Posey and Cozy HPKE. And so the reason I'm speaking to you here is that, as Tira mentioned, you know, like,"
  },
  {
    "startTime": "00:38:01",
    "text": "Cozy HP Key is happening. Hosey HPKE might be happening soon, And developers probably would like a kind of consistent understanding of what these examples for direct encryption, and, key encryption. That are, like, really, really simple that can show you when you're using Hosey, It looks like this. When you're using cozy, it looks like this. Here's the key representations. They look similar. Here's examples for the, the 2 modes in Jose and Cozy. They look similar. And I think the main thing that I would like to sort of point out and you, if you come to the cozy, sessions you'll see this, in the cozy HBKE presentation. There's a difference right now in how cozy represents the ephemeral key. And how Jose represents it. So in the examples, that you saw, you could see that EPK, a femoral public key is actually used to transport and, encapsulated key. And that looks really familiar to halsey developers, but you know, is that the right way to handle DHchems and HPke? The cozy working group came to a different set of conclusions around that. That's the kind of alignment that doing this example document helps us really see very quickly. And so, you know, Please read the document. Happy to answer any questions you have on the list, or in person if you have questions now. Yeah. I've implemented Cozy HBK and Cozy HBK, and I the implementations that I've built I used to generate the examples in the document that's that I'm talking about with ounce slides. Philip. Hi, Ori. Hi, everyone again. I'm not I'm not asleep. Yes. It's 75, 7520, for the, Jose cookbook. As a library developer, I'd like to say that the immense value of a document like this is not the example examples need to be included in the set specifications, not"
  },
  {
    "startTime": "00:40:02",
    "text": "the example cookbook, the immense value comes from having through Verified vectors, and maybe even a programmatic representation of them to use in your own development and testing. I agree. Mike, Mike, Mike Jones. I'll just, say that having Matthew Miller do the Cut butt. In parallel with developing the initial Jose specifications that became 7520 was super useful. 2. Make sure that people had those test factors that the latest talking to. And human readable versions of them so that, people had stuff to test their code against. That was great. So I like this kind of work. Okay. Richard. I was confused when you called this cookbook, if you call it a test vector document, Yeah. Custom. Okay. document? Anything else on this No. And I, I didn't, actually didn't even mean to get on the agenda. It just has the word hosey. Front of it. So when I published the draft, it showed up. So I'm not asking, you know, for adoption, I would love comments on it. And, I I think the next step for it is, like, to sort out these remaining differences between the hosing working group and Cozy Working Group. And once those are sorted out, maybe the document with additional, changes and maybe some more machine readable processing capability, maybe then I would come back and ask for adoption in hosey or cozy. So just Yeah. What I'm thinking right now. But if you have different opinions, I'm happy to talk with you on the list or off the list. Thanks. Yeah. Thanks. Joe. Joe. Yep."
  },
  {
    "startTime": "00:42:02",
    "text": "Joe Saloway. Are you in the room? You're on the queue. Oh, okay. It's Brian. I just just wanna I think it was still at 1 in a second, the point that this this this this Cookbook shouldn't be a replacement for the kind of examples that you would see in the core document itself. I get a little concerned that it would be used as the the Vector to sort out those issues. I feel like the document itself should be sufficiently But Yes. Yeah. So, I completely agree with you. Part of the challenge here is you've got 2 working groups, both doing HPK. So I can't, in my hosing working group, tell the cozy working group what to do. I mean, I could, but I don't think that would go over well. So I I wrote a separate document that kinda compares both of their approaches. You can see each of them. And it's not, you know, we're currently not on track to be adopted in anywhere, it's, you know, for me to kind of make the argument clearly in one place. You know, hey, did you notice that they use a header parameter and we use the EPK our existing header parameter to move the encapsulated key. That's like the only remaining difference Could we get rid of that remaining difference? It's it's It's been to support those kinds of conversations on the list, not provide the examples that you should see in the specifications, just to be crystal clear. That makes sense. It could become something more if we wanna make it more machine readable or make it easier for developers, but you know, its original purpose was just to coordinate between hosingcozy individual format. That's a little bit different for me. That makes sense. Thank you. Yeah. Mike Parrock here. Because I think 70 twenties listed as, like, examples of Jose, etcetera, I think is titling or something like that, but the cookbook terminology could be a bit confusing because you're thinking more of patterns I do see as, like, someone who maintains multiple APIs that"
  },
  {
    "startTime": "00:44:04",
    "text": "you know, go in and say, Oh, I want this in seaborne or using Jose or, you know, JC or Jose, depending on what it is, it's very helpful to make these kinds of comparisons, and it's very helpful for my development teams to, for me to be able to point to something like this and say, see this is why this is different. Then to be able to raise issues if we find things with specs under So it is a very helpful, tool. Ahead, mate. So, Mike Jones, I'm gonna disagree slightly with my friend, Brian. Always a good thing. You. What Matt Miller did for us in 7520, was create testable examples for every algorithm. You know, 384521 And different key links and All the key wrap modes. And all the key encryption modes. And I was not about to put that amount of examples. In the doc. The examples in the doc were there in my mind to help people understand what the heck we were talking about. He produced a developer resource. And while they're overlapping, they're different. Just one comment on, like, you know, some of the complexity that still remains even within HPK the AD scenarios that you can run into. And, APU, APV, you know, considerations that, you know, potentially could end up being implemented differently in Cozy and Jose. Like, those are the kinds of edge cases that seeing them addressed in both formats, like would be super nice or seeing them but not addressed in both formats and consistently telling you, don't do this. Also be super Okay. Thank you."
  },
  {
    "startTime": "00:46:02",
    "text": "Next is the hosingcozy Guidance. Oh, Aaron, So I be brief would really Next slide, please. Hannah's presented the the draft, in Prague. There was some interest in the draft. Me and Philip who never sleeps, spoken, joined. We issued a call for adoption on the list We got some positive feedback, but also some feedback saying This is quite thin. What is really the scope of this, document, and it's a good question. We We created a repo. We we met several times. We have a few issues open for the draft, including, rather extensive, review by customs. Thank you, custom. And We do plan to update the draft after shortly after Brucebane, And then once we have, the, the scope clarified, with these issues and with some, some ideas of the various, participants we will come back to the, to the working group. For adoption. Okay. Thank you. Oh, I should have asked this in by any questions. I'm sorry. Yep. Okay. Great. Alright."
  },
  {
    "startTime": "00:48:12",
    "text": "Hello, everyone. This draft was discussed. We got several comments on as well. It's it's purely Picu Cams for Jose and, Jose. Yeah. I mean, I don't want to go spend more time on this word existing traditional symmetric call with them. So we'll be broken with a cryptographic serial element quantum computer. There are several, algorithms that are being standardized by Nest and the top one is MLkem. That's already used by several other protocols. What this draft is chem is basically a very simple mechanism where you have 3 APS basically one for generating the keys. Sending the public key to the server or free, any peer that you want to, encrypt messages and then the end cap would be used to generate shared secret in the ciphertext and the ciphertext would be sent back anti cap would be used to generate this shared secret. So what what we're trying to do here is, a migration path basically from traditional asymmetric crypto to hybrid schemes. Hybrid schemes would be done in Jose and cozy with the HP key scheme, we have published a draft on how that can be extended. And then eventually, there has to be a transition to, PCCAM as as we all may know, CNN is a 2.0 standard requires PQCAM, to be used. And MLCAM has been around for 7 years. And, I believe that once us cryptography development content computers arrive, we will have to get the existing traditional one. But I see some discussions in other working groups that they want to transition directly from traditional to PCCM. I'm not sure about that. The system that I think would be the right way to transition with least risk involved. Of"
  },
  {
    "startTime": "00:50:00",
    "text": "So the what we are trying to do in this draft is use the end cap operation and then do a key derivation function. We are using K MAC for the derivation function. And similarly, for the decap where the same Kmart would be used Now, The simple registration functions is the, PTC algorithm followed by the, KDM function. Which is very similar to what ECDH he has does and, and then we add the key wrapping, a algorithm for, key encryption as well. Yeah. And and the 2 modes direct encryption and, key agreement with pre drafting would be supported with that. And and couple of examples, We had to add a KEM cipher suit because We don't have anything, within unlike a working group where there is the the encapsulated key parameter there. Fortunately, in and, Jose, we have the encapsulated key being sent in ephemeral public key So we we that the working group discussion was not too piggyback on that. So was a discussion that we had to introduce a new parameter for carrying the ciphertext and and very similar operation even for the key wrapping where, the algorithm KEMs, ciphertext will be mentioned in the recipient had us. And, Yeah. This looks pretty straightforward, but we want to hear the working group alum consideration, whether they think it's Ready for the option or Sorry. Hey. Go author for the other, HPKE stuff. Sorry for what I'm about to say. I feel like, you know, this is adding algorithms, just for the sake of adding algorithms to hosie. So, like, cryptographic algorithms aren't Pokemon, we shouldn't try and catch them all the, the HPKE algorithms have us, give us the security baseline and the migration path to"
  },
  {
    "startTime": "00:52:02",
    "text": "hybrid or, pure PQ cans. But they also give us these additional HPQ security based lines, which I feel like are important and the details around how to use this, these constructions in the existing hosey envelopes and potentially these these same structures within the existing cozy envelopes We're gonna end up seeing the the the at potentially a lot of duplicate or equal strength or maybe not perfectly equal strength to duplicates in terms of fully specified encryption suites. And I don't feel that all of those encryption suites are necessarily providing enough value to see all of So, in, in the words of harrow Harold from all dispatch, like, should be only one. Let's, let's see, you know, which one, folks 1. And, like, let's just do that one. Let's not add a whole bunch of new algorithms that are essentially doing very similar things. If we can avoid it. So That's that's my comment. Thanks. Sorry. I mean, I get your comment, right, especially for hybrid scheme, we have to go with HP key. Right? It's pretty much can take both the ones but whether HPE is required when we go to PQM, right, Adam, that I'm not sure why we have to replace HP. Right, which advances here is the author of HPK. So I'm pretty sure we can listen to this. Yeah, John Pressmeitzson, not some Ericsson talking as myself chair hat off. I would like to I think I'd have should adopt all the outlets standardized by needs. Like, just take them all variants stop arguing. I I plan to use hybrid, but I would like to see separate algorithms seems to the least unclear whether you can use hybridmb pathable with CNSA. 2.0.0"
  },
  {
    "startTime": "00:54:01",
    "text": "then it I think it would be bad to have individual outlets and HPEE. Overlapped. Most. So I think that should be avoided. I'm a bit confused about how to divide these PTC jobs between cozy and We'll see. But that's another question. You made the outlets recommended no, I think the right term would be optional. No, it doesn't exist. In in in Hi, Richard Barnes. Yeah. I actually enkewed to ask why there was Kmart in your, site first video I did I'm guessing is to to aligned between the size of the secret that can produce and size in the key you need. Oh, the reason why we used came at was that, we have Jose context and cozy we wanted to add that as one of the slots into the final derivation case. So that was the reason then we also wanted the size, to be the size that we would want to encrypt the payload. So Kmart gives that. So that was one of the reasons for picking Kmart and if my memory serves right next recommends to use K MAC instead of going towards using shake, but K MAC internally uses seasheck, anyway. So I thought it gives all the flexibility that we want to be looking for. You know, that that that actually reinforces The point I ultimately came up to make, which is that Oregon seems to be right I think this working group does best when it convince the least cryptographically. When we are taking things that have broadly the shape we need for Jose and plugging them pretty directly into the, what was it, framing and so I think The work that's been done on the HPK drafts has has done that alignment HBK. Yeah. They've done the alignment. And so we shouldn't do the extra work of redoing all that work here. So I think it was right on in terms of keeping the focus on on HBK. Because that that will cover both the hybrid and the"
  },
  {
    "startTime": "00:56:02",
    "text": "CNSA 2 pure pure PQ, cases. Mike Paroc here, I'm gonna strongly concur with, Richard and, with Ori there. There are bits of this that feel like defining some new crypto And it's hard enough keeping track just on the signature side, with peak quip and everything, you know, all the various groups between land, what we're doing at Lambs, we're doing here, right, and getting all that stuff in line. Right now, HPKE for better or worse is what is seeing traction and solves both use cases. So I think until we kind of finish hashing some of that stuff out that feels like a good starting place. Did you do you have any comments regarding some of the discussion around ML Kim and Kyra and some of the related things from CFRG this morning. Where you at that session? I would No. I was in the Lindsay session. I Yeah. I would, definitely go review some of that materials and maybe do some brain picking. There are areas that might be adjusting here. Right? So I would just be aware I and we've you know, the reason, for instance, with the when we even suggested moving forward with, like, Jose and Jose's side of just the pure signature side was when we knew that parameter sets were close enough to something we could build and test against and still knowing those things we're gonna change. Are bits of this to just really concern me. And if we can do it and one consistent way. Let's do it in one consistent way. Even if this exists. And they and I'm not sure what how much of this we would do in Jose necessarily with mlchem we have right. Yeah. That's that's a very good comment. I mean, in fact, I was talking to the authors of the Lamb's working group when they were using ML command, made sure that our mechanism is similar to that, but I was asking them if they place it in a separate document, right, but, I don't see such a document available yet. So Yeah. Hopefully that happens."
  },
  {
    "startTime": "00:58:05",
    "text": "Okay. I'm not, hearing any any sort of momentum to adopt this draft. So I think it think we're good to wait for someone. Good to wait. Okay. Great. Thank you. Alright, Paul. Thanks. Hey, uncle. I'm presenting on an ECDH Mac based signatures, and I see that I have a copy paste Aaron. And these My headline, so I'll just skip to the Go to the next slide, please. What's the idea behind this? I'm proposing to add a new was a algorithm and a little bit of background story. Yes, it might be controversial In Germany, we have a national ID card. That has a functionality for identification, pseudonymous authentication called extended extended access control, and it enables 2 to share this data in the identification, part by not using, sign data instead it's using ecvh, He agreed in opening up a symmetric. Channel and then sending the data in plain text. I mean, Thanks. Another privacy oriented. Cisions there. And, We are currently in the design phase for I just 2 based, for the calls and especially, I'm in the German architecture team for the German Ida's Wallet."
  },
  {
    "startTime": "01:00:03",
    "text": "And we're having a lot of discussions with, BSI which designed these protocols for the German National ID card back in 2010. And, so Be as I was proposing to use something similar in the very confidential ecosystem or IDS 2.0 To achieve certain privacy targets. Next slide, please. Yeah. So motivation is, from the architecture document on the chairman, Idas Wallet, and besides many other things, we came to analyzing The comparison between issue assigned credentials, which is I would say what The majority or almost everyone in the in the VC face is doing versus, what we believe could be an option, and we call authentic to Chuggle, Prudential's, Next slide, please. And I think the main So VSI is one of the main driver behind this, and would they offer him Push forward as an argument is repudiation or probable It's niability, added, Definition of repudiation or our definition of repudiation here, I think it's no surprise to anyone in this audience. We Mainly 1, 2. Deny afterwards. Just to a third party that a transaction actually happened. And, with ECDH, Tas Mac. That's very easy because We can always argue that"
  },
  {
    "startTime": "01:02:02",
    "text": "The other party that we've shared this information with, for the unsightened pater, Lynn, or the Mac to data, in this case, Could have made up this mic as well because we did a Kia green them beforehand. So they have the key for the MAC that we're using afterwards. As well. And, also interesting, maybe we differentiate between to repudiations, Especially in the BC context, And then one of this is the Authenticity of the Data, I would be likely issue assigned part and then Normal VC Space. And then also the deniability of the user's presentation of this thinking in as the jot terms first one is the SD job, and the second was the KB job. Next slide, please. You can argue a lot on repeat repudiation, and this is probably also what I expect the discussion this draft, to be if this actually makes sense at all or not, The point of BSI is that they think data breaches are just a matter of time, and, Relowing parties will be lazy and they will store the whole presentation of very helpful credentials that you will get. And if either to Pakes up a lot, then we'll have a lot of issue assigned, data floating around, And, They don't, necessarily want this for the PIDs or the the, like, National ID card equivalents, some people are not familiar with the term. They will the level of assurance. Hi."
  },
  {
    "startTime": "01:04:00",
    "text": "Identification, data, issued by the governments. And they don't. Want that This Dater, Well, like, if if there is a data leak at the relying party, They don't want, This data to be issued to be signed by government because it would this data even more valuable in the dark part. For sale. That's, one of the main arguments and, Like, notched, some use cases where 3rd, Where you want To show that you have received this data to a third party, but they say, well, In this cases, you should not use. PIVs or EAS or verifiable credentials, but you should use. Qualified electronic signatures. Next slide. So what's the proposal? It's, A new algorithm that's doing an ECDH key agreement first. Deriving a key and then, using a Mac on top of lists, and, picking up the idea of fully specified algorithms, I see their 3 parameters go into this. First one is the elliptic curve that we're working on we have a key derivational algorithm and a Mac. Algorithm algorithm, Also, this is how an algorithm, could look like using the nistp256curve the Comcast key derivation function that's also being used in ECDH ES and then Hmac, 256. Next slide, please. Michael, you're in the queue. Did you wanna ask now do you wanna ask questions at the end? Paul, do you"
  },
  {
    "startTime": "01:06:00",
    "text": "wanna finish, or do you Oh, old There's, one more question, but, yeah, you can ask, straight away if it's important to you. Okay. Go ahead. L. I just want to so Michael will be UK NCIC. I just wanted to ask isn't the construction I'm familiar with. Is this something that CFRG have specified, approved, discussed, analyzed, or is it something you this hasn't been presented to CFRG on the This is I would say a very basic, combination of things that is also being used in other spaces, like, islandoc. For example, or in the, Jamal National ID card, and very similar. Yeah. pattern I think The the overall overall is is is Not really well described and encapsulated and analyzed as a standalone thing, but this pattern of using ECDH for plus, a Mac is pretty commonly regarded as a designated verifier signature. In particular, the way you have personally have probably used it as an signal protocol. Because that's the only authentication you ever get in signal. Is that you did an ECVH with someone And and got a, the correct encryptions. With key results in chop. You know, it's a widely used pattern. I don't know if it's you know, pulled out and analyzed this discrete thing all that much. Yeah. Yeah. John. Thomas, I'm talking as myself. Think I agree with of the, like, I I this is a very simple and well known contract. I don't think we need to ask see for you what what what what everything. No. Alright, Paul. Your race and X side."
  },
  {
    "startTime": "01:08:02",
    "text": "Yeah. Poland I've I've Run down like a very simple algorithm, that's also present in the Individual draft right now. Well, it's yeah. What I said, we performed an ECVH P agreement, possibly verifying that the key what I call the generating party is signed, for example, by an X Five C, Enter Also, the thing is a little bit It so it behaves like a signature. So I mentioned the 2 parties as a generating party and the verification party because people might argue that it is not a secondary scheme, but it behaves like a signature scheme. So Afterwards, sweet. Do we have a symmetric key by the key derivation algorithm from the shared secret and then we generate a MAC on the symmetric based on the symmetric secret. And then in the verification, it is basically the same and the verifier compares the generated with the one that is he got over the line. And last slide is an example. So A new algorithm in a jot so it's it's adjacent web token example. Sorry, We have the algorithm and the header then we have the kit Which is the PID pointing to the ephemeral key that the Verifying party sent us before"
  },
  {
    "startTime": "01:10:02",
    "text": "And, we have the ephemeral public key EPK Which is the ephemeral See json webp, use body generating party And, optionally, the X Five C header that signs this thing, then we have some claims and In the end, we have the base 64 encoded MAC. This is what it could look like. And Yeah. All these pieces more or less exist in the All this back, we have ECDH, ES, and we have all these max. So it's kind of plugging existing things together, in my opinion, And my actual last slide is the summary. So it's in easy way to offer reputable signatures with established crypto And it brings a similar mechanism at in a kind of similar fashion, let me know, from MDark, to the jogged space we have 2 different you we currently see diff 2 different use cases, how we would want to use this so this could be used for on demand on the fly generation presentation. I've verified credentials, So this is one architecture, how you could use that So you could argue it's Similar to an IDP flow where the while it sits in the middle and the relying party is not known to the issue. Also, you could do that without an issue and maybe you have some trusted logic, secure element thing that is acting as the generating party, and that may Do reputable PC presentations."
  },
  {
    "startTime": "01:12:01",
    "text": "Turaline party. I mean, disadvantage that comes, with this flow is that the relying party usually has to provide an ephemeral public key, especially with the correct curve. Had a presentation. So there's brings some challenges, to the protocol design. And that's it. Alright, Richard. Hey, Richard Burns again. I think it would be useful just in terms of terminology here. I think what really have here, as you've created, designated to verify our signature scheme. I think you're just framing in that term. We'll we'll make it easier to match against the literature. I have in terms of doing this in Jose, Some folks who've been doing some other stuff with me will know that I'm uncomfortable mixing things with different security properties and one syntax. Right. So mixing, you know, standard GWS that has standard signature semantics with JWS that has doesn't mean to verify semantics makes me a little worried. I don't think anything terrible is likely to happen if they get confused. We're not gonna allegnon issues. But we should think carefully about that. And you have do more analysis. Let me just do any of the microphone Last comment is, I don't wanna be the guy. It's like always use HPPE, but it occurs to me that the, you know, hpke with TH cam, at least, has an auth PKU mode. Or an off cam mode. Where you can plug in 2 keys. One one of which would be the signer's key and one of which would be the verifier's key, in this in this case. So it may be useful just to to reuse that. You could reuse all the good stuff been done in terms of verifying the algorithms for that."
  },
  {
    "startTime": "01:14:00",
    "text": "Just, you know, add an auth at the end or something like that. And and off you go. And, you know, if anyone invents, a PQ cam that has has off cam interface, be able to use that too. Anyway, just some suggestions there. For doing the work. Sorry. Alright. I queued to say basically everything Richard said, just you know, one comment is like the off mode stuff, You know, it's not entirely clear how easy it is to do off mode the like, a pure PQ cam with auth mode. And, you know, in the interim, you might consider, you know, pure, pq, cam, as a replacement for this ECD DH component that you're talking about here or a hybrid Cam as a replacement for those components. But then, again, to to say the same thing that Richard said, like, maybe just use HPKE because Otherwise, we're going to be having the same chem conversation we just had Again, for this. In Maybe. Did you you're not. Okay. So next Next steps for this. Further discussion and comment on the List. Doesn't sound I'm not hearing a Groundswell to immediately adopt it. Start with it. Yeah. My Go ahead. I don't wanna, my comments to be interpreted as, like, overly critical. It sounds like this approach is sort of Either being rolled out, you know, regardless of whether it has HBK or not."
  },
  {
    "startTime": "01:16:01",
    "text": "I agree with Richard's comments about the the worry, the concerns around just having a JWT syntax show up that has these specific security properties, but I'm overall, I'm really supportive of the fact that draft was written. It summarizes designated verifier signatures is whatever the right language is around that. Think it's been a helpful document. Love to see it continue to evolve to reflect whatever governments are actually doing. Maintenance. Discuss sage key lately. John Bradley. Paul, I know that you're not doing this in a vacuum. Are there a healer time time deadlines that you that you're facing that we should know about for considering adoption. And or, Are you willing to consider the HBKE alternative, So, I'm not, yeah, too familiar with the HPKE stuff, so I will I will research these, alternatives, But, as you yeah, Are in the Ides projects on both yourself, but you can imagine that a time pressure is, Omni present, The main purpose was to Yeah. To get the ideas out, So Also saying that these ideas are very early and May not reflect the main stream of where people are going with Verified credentials. So it's kind of It's it's it looks odd to many people, I would say. But I think BSI is also an important voice."
  },
  {
    "startTime": "01:18:02",
    "text": "For all these government related projects, and they Have a opinion that should be not, maybe, ignored. And that's something that's very important to them. So Yeah. I don't know how this will evolves but, time pressure is mediocre, I would say. Okay. Brian. We've discuss this a little bit. I wanted to say it in front of here. Terms of time pressure, I'm wondering if or how I don't know. I don't know how does it there's the possibility too that the N normal existing H Mach algorithms, JWS could be used was building the key exchange and KDF on the higher level protocol for that, which Still feels like it might be a a faster, path to actually getting something to work. I think or I bought, I don't know, that's been my perception. I've looked at some of this stuff. And looking at the actual draft itself, tried to express this to. I get really confused, and I'm not sure. It's just me. I think maybe the draft is very confused about whose key is a femoral and whose key would be static and what your proving to whom and how you convey those things. All layered on top of Jose where There's short of an implicit assumption in the things now that they're sort of, like, one key operating on Whatever it is we're doing particularly in JWS. Some of the comparisons to ECDH in JADA VE are little At least for me, it's confusing because the the flow of things that's basically reversed and the keys. Who owns what keys and what you're proving to reverse? So, I don't know if that's very constructive, but instead of going all the way to HBK, maybe none of this is actually needed the key exchange could be built into the whatever he's using, using that, using that, using that, using that, using Alright."
  },
  {
    "startTime": "01:20:00",
    "text": "Obviously, to but that's what a parent, I got. Michael, can you be quick? Yeah. I'll be I'll be nice and quick. I'm like Ori, I I appreciate you doing the work. I would like see some like terminology alignment with the rest of the field and maybe clarity in the draft just so I can understand better before I was like, yes. Let's adopt this as a, a work item, I would also like to make sure that the work item does count for some of the actual problems with store now decrypted that are pretty well understood and discussed cause I'm not seeing that covered in the draft as is. Alright. Thank you. And that for our last agenda item, you are muted. Can you unmute? There you go. Hello, everyone. So go ahead We can hear you. Okay. Hello, everyone. I'm an IT developmental engineer representing China Unicamp It's my first time attending a ATM meeting. So I'm really excited to be here. And looking forward to learning from you all. Let's again look at took Looker at flight, which outlines the to of our discussion. The title of our document is tuition 1, green access. Firstly, let me introduce the significance Next slide, please. Traditional access control method such as role based access control and the attributes based access control. Although protecting data security to some can gradually show the limitation went dealing with"
  },
  {
    "startTime": "01:22:03",
    "text": "complex and a dynamic spatial access requirements. To address this issue, this paperwork process, Jason based fan green access control master that can be applied to various scenarios such as such as work storage, Cloud Computing, and, in internet of things, Next slide, please. In this slide, I would like to briefly introduce the data structure we have established. Jason, Based to fan green access control data format, it's standardized format. Yield to initiate attacks. Requests to access control system. Pieces of Jason object that contains a requested is and there are concrete access conditions. Request ID is identifier of request subject identifier representing the access subject operation indicates the action I of the request for this. Such as update, and so are results indicate the identifier of says results. Today refers to the fan going attributes of the access subject Nice to have slime. Please k. K. That The next slide will break down the proposed impact, implementation process into 7 up, that's that's The first one is the client sent authentication information to the server. And then resale, GWT Talkers So request and by the client include, talker and the payload of of token contains information about the accessing subject accessories"
  },
  {
    "startTime": "01:24:00",
    "text": "and attributes. Resource service that Fangoon access control policies. For different results. Which are represented by an access control tree. The server refi is downward, a literate of children happens the payload information and the extract the access information and, it attributes information. Next slide. Based on the extracted information and the pre defined access control policy. It is determined determined whether there is corresponding policy. If there is the access conditions, check to see if they are met, if the conditions are met, access is granted, Otherwise, the access is not the resource service encrypts the requested source using the suffer tax policy. In correction algorithms. The encryption process incorporates the access control policy. Corresponding to the assessed, to start. Encrypted ciphertext is then sent back to the client. At last a plant, generous, decryption I would based on a set of attributes included in request using the out of way, our grades up. After receiving the encrypted several texts, The client verifies that the attributes in the attributes set can satisfy the access control. Only if the attributes might meet the policy has a plant equipped and access the resource. The file is all the content of the Drafted."
  },
  {
    "startTime": "01:26:02",
    "text": "Thank you for listening to help judged our comments about our track Any questions or comments? Hi. John Bradley is individual. Thanks for doing this work and and sharing it with us, my my observation is that this probably isn't Jose work. So Jason This fits more closely to chasing web tokens, which is actually in the a lost working group. So I suspect that this is probably closer to something that the OAuth working group would pick up or or potentially some other working group. Because this is at the You know, yes, it happens to be signed by Jason Webb signatures, but you know, is, as you said, part of a adjacent web token, and, refinement of that token. So Yeah. Unless unless this directly impacting the crypto envelope of that Probably would be better off someplace else. So, maybe we can help you find, some other place that might be better able to to deal with this work. Okay. Michael Yeah. I think I just put something in the comments very similar to what John said. As in individual. But I, I, this feels very much like an OAuth or an app kind of useful type function, like, Hey, here's this protocol. I need to go request these very specific misses, very great utility. It's a very the concepts, I"
  },
  {
    "startTime": "01:28:04",
    "text": "totally see the use, but I, I think it's probably better suited in something that's more protocol or Okay. So, perhaps the, chairs can work with you all to get it in front of the OAuth working group. Is that okay? Okay. Okay. Thank you for your presentation. And you work. With that, that brings us to the end of our agenda. 2 minutes to spare. I wish I could say we planned it that way, but, you know, If there's no is there any other last minute business? Last time we asked if we wanted to do interims and you all were tent with, working in the github repos and just mating at the next IETF. I assume that is our We're going to continue with that mode of operation. Alright. Seeing nobody in the queue. Everybody, have a good day. Of"
  }
]
