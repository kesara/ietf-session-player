[
  {
    "startTime": "00:00:06",
    "text": "Just a lot. I think about it. Good, but that Hello, welcome to IETF 120 the Grow meeting, which is going to start in about a minute and a half while we finish up our other thing here Seriously, that's the biggest point Yeah Yeah, well, that's, it's a third Vancouver has the largest ports It's a picture of Vancouver. It's a picture of Vancouver So with every growth meeting, we try to make sure that the audience learn at least one thing and that is always on the first slide of the chair slide slide All right, welcome everybody to the global Routing Operations Working Group meeting at IETF 120 A special warm welcome to the remote attendees Next slide, please Please note well, various things Make sure to scan the QR code to indicate your presence in this room We use that information in lawsuits and to plan the size of the room next time We also expect everyone to treat each other with respect. Make sure that if you present arguments, they are related to"
  },
  {
    "startTime": "00:02:01",
    "text": "ideas, not to persons. Next slide please. We have various resources This slide should have been updated, but I copy-pasted it from last time. Next slide Next slide So, we need a minute taker. Do I have? to appoint a volunteer? named Warren? Second it, thank you all right Warren thank you for your volunteer services Our agenda today is packed, so we're going to be quite strict on time This also means that we may need to cut off the microphone line at some point Let's kick it off. We're going to start with Tobias He has a number of presentations Do you prefer to tobias looker Tobias? Or dude? Hair Tobias or Dr. Hare Tobios The esteemed chair of the Grow Working Group I don't care All right. I would like to start with the yellow slide deck, please please Is it combined or something? No, no, I uploaded two And this morning I got like the confirmation of the second one also made it it What is it about? BGP stuff BGP stuff? Yeah, excellent Like the first one is the adopted drop. Like the drop"
  },
  {
    "startTime": "00:04:01",
    "text": "Is the second one in this one? Yep. That's got your name on it. Try that the correct one, okay right. Tobias, the floor is yours. Thank you So this is draft IETF grow, BGP OPSEC update dash 03, together with Nick Hilliard who couldn't make it here. Next slide, please So at IETF 119, we have this really long graph, roughly 50 pages the idea then since then became that the focus should be more and like short enough for policymakers to actually read it generic enough to be resilient against change over time testable, kind of independent of how it's implemented and published quickly enough, so it gets ahead of the wave of current efforts to actually revise certain regulations where we don't want to have things of the current PCPB 194 in. Next slide, please so what the plan was is split out the individual X from the basket keep the core of the document as it is but I move like all the terminology stuff and all the like implementation specifics to other documents And next slide, please First and foremost, be quick. Before seeing become laws. We don't want to have in laws next slide please so what happens in things become laws, we don't want to have in laws. Next slide, please. So what happens since then is that we removed all the text that has no timeless high-level directive policy feature This text has been reserved for further use in two other drafts, which we will be talking about later. We also removed some more. In total, we brought the document down from around about 50 pages to round about five Hold on back, thanks. And we basically focused on the essentials. So basically do not do stupid things or do not expose your BGP speakers unnecessarily make sure you don't import NLRi you shouldn't import and make sure you don't export NLR you shouldn't export. Next slide, please Actually, the current draft kind of fits on the slides So these are the points for BGP session protection. Next slide"
  },
  {
    "startTime": "00:06:01",
    "text": "please. Then BGP speaker management interface protection, so you shouldn't put your management interfaces out there. Next slide, please Then on importing LRI, basically make sure that actually what you import is, like, has the party enough importing LRI, basically make sure that actually what you import is like has the party announcing it to you being authorized to announce it There's a couple of exceptions which you can have and between two consenting ASS you can basically announce whatever you want as long as you make sure it doesn't leak outside. Next slide, please And the same kind of also is valid for like we disputing an LRI Kind of basically boils down to the same thing. Don't do things. You're not so supposed to do. Next slide, please Then there's a general consideration on all altering an MRI. There's also compounding draft in side drops on not not annotating APCI validation state with terms transitive attributes. And you shouldn't do things to attributes you don't know what they are about, like you should just ignore them next slide please so the next steps for this draft would be we have to somehow reach working group consensus We basically need to figure out what still can be taken away because there is actually not really that much left, which can be removed. We have to think about what can be added The metric I'm suggesting here if there is more than two mails or two minutes of discussion on if something should be added, it belongs in another draft And when we are there, that we do kind of feel like there is consensus, we should move to working group last call in our opinion as authors Next slide, please So we can either now discuss this or we can do the presentation of the other two individual drafts, which are currently being submitted. I don't know what the shares prefer We have a little bit of time for discussion"
  },
  {
    "startTime": "00:08:00",
    "text": "so if there's anybody in the audience that has preferences on the future direction of BCP19 that would be... Especially in the context of how can we move forward quickly Okay, well, instead of waiting to be called on, since the air is dead, I'll just start talking So, one nice thing about BCPs is that they are aggregate of multiple RFCs potentially So I think that that speaks strongly in favor of going ahead with the slim document that you have you know, kick out 7454 sub in your document, and then if people want to fill in all the cracks they can add another RFC to the set of RFCs that comprise BCP 194. So in other words, you know, go fast, it's cool ben maddison from Work Online. I'm broadly in favour of the approach. I think that there's a kind of a practical challenge that we're going to face where different documents need to be kind of updated and kept current on different timelines. I'd quite like to have a sense of the kinds of things that you envisage moving into other drafts and calling out before we have that discussion in detail. So I'd suggest maybe we move on and discuss the whole thing after the next couple of presentations That's it? Okay Next. Next slide deck. Yep I updated the order. So yeah, two submitted individual drafts, grow routing OPSEC information"
  },
  {
    "startTime": "00:10:01",
    "text": "and grow routing ops terms basically recycling redundant drafts by currently me and potentially you if you want to join in next slide please. So the starting point is the idea we discussed for the 194 updates at 119 moving these things into individual drafts and next slide, please The idea is to have like two informational drafts, which are more easy to update than a BCP the first one would cover basically most of the implementation related parts of what used to be in the BCP 194 update and the second one would mostly contain what was there as terms. Next slide, please so yeah no no not really slide. Thank you. So for the obsequc informational it basically borrows a structure and content from the draft IETF grow BGP OPSEC update dash 01, which is mostly concrete ways to implement certain things like concrete ways to make sure that you're not announcing an LRI or that you're not importing an LRI which you shouldn't import Sadly, there's often multiple ways to accomplish the same thing and the idea for the informational document would be to note, like, the various options you have to accomplish something without being prescripted So instead of being like to do why, which is, well we want to do to do Y, which is an option to accomplish X you need to do instead of saying like you need to do X Next slide, please It might be also an option to add an explicit detail into the document basically a best before, because sometimes no document or do not use this document anymore is better than having a stale document which is still considered current, which is kind of the situation we do have with certain parts of BCP 194 at the moment Next slide, please"
  },
  {
    "startTime": "00:12:01",
    "text": "it should well by being informational it can also be a bit more best effort, so we don't have to have absolute complete which is also a challenge given that, for example, Asper at the moment is still a draft So like, do you mention it? Do you not mention? it if you mention it in the BCP it's kind of more difficult etc. It's not an issue of some of the techniques proposed actually accomplish the same thing You don't have to do any judgment of methods Just because something is mentioned does not mean people should or must use it. It's just an option And that makes it ideally easier to find out form of rough consensus whether what is in there is actually okay. Next slide please The status of this thing is basically where the draft IETF grow VGP obsec dash over the additions was before it got severely shortened There's lots of editing to do. There's a lot of room still for editions because now being just a technique to accomplish something suffices And the big question is, is this something we would want to work on in this working group? And would it be possible to have a call for adoption that basically concludes the first of the two drafts. Next slide, please bring us to the terms next slide please Interjecting we have noted your request for a call for working group adoption. Thank you So for the second document which is basically terms, if you think about things listing terms, you think usually dictionaries For dictionaries, there's two ways you can do this. You can have like a pre- prescriptive dictionary which says like this is how you should speak and which words you may use. Next slide, please Or you can have a descriptive one, which is like a couple of people do this, couple of people do that, pick something or make it into this dictionary with something new. I'm a dictionary not a cop Next slide, please Obviously, we want to have the letter because otherwise we run into the same"
  },
  {
    "startTime": "00:14:01",
    "text": "issue of having it very, very difficult to reach consensus on what to put in there, and we basically end up with a draft that remains a draft forever and never really gets anywhere Next slide, please So the idea is to have this document as a collection of terms. So think about the peering with a peer that it appears different from the peer with a peer that is a downstream which is like a perfectly valid statement especially in the terminology of current BCP 194 and new IDs tend to bring in like new terms and actually tried to make this more defined and in general better still having it all in one place including potentially his historic uses of terms and how and when they used to be used might be really beneficial for the general understanding of these documents. Next slide, please So at the moment, the document is just the terms and definition section from the route IETF grow BGP OPSEC, update, 01 Probably need somewhat of an open survey, like tell us about all the funny terms you've been using in the context of global routing operations and what they mean it generally needs more input on what should and should not go in there And we would have to come clear about what structure we need So if it should have like a historic part and the current part, or if it should just be alphabetically and many options, basically In general, the same question as before is this something we would like to work on? and what you would like to contribute to do you think this is useful? And if so I would also like to ask for adoption for this draft No, does Any questions or comments from the audio? audience? Staying quiet intentionally okay Oh, I meant too long"
  },
  {
    "startTime": "00:16:06",
    "text": "ben maddison again. I think there's another option for organizing the dictionary work I would, I think I would do it thematic because one of the problems that we have when we're speaking about this stuff is we have a bunch of very similar terms that mean a bunch of very similar things and the degree to which, or the nature of the nuance between them varies when you from person to person and I think that that's going to be its primary value. I mean, I think your example is a perfect one, of like expressing what we mean when we say peer peer I think that your general ideas for how to lay out this as a series is probably a good one My primary concern is how we go about trying to stay on top of the revision cycle. I don't know It's not at all obvious to me that the stuff that talks about the specific operation considerations it's not all clear to me that that should be an RFC or a series of RFCs or whatever Yeah, I mean, yes living documents. We, you know, I mean, I don't know, I mean, maybe Warren wants to talk about whether the think we should try and reopen that kind of worms. I mean, it's just it's just so obviously the right solution to this problem We can, I mean, maybe we can kind of approximate that by just having an ID that's like refreshed every six months forever and never goes past working group last call I mean, I don't know but I feel I feel quite strongly that that's the kind of thing that we need because like sticking a TTL in an RFC and saying, if it's 2027, don't read this because it's probably garbage garbage It's, I think that's the problem here. I think that, you know, this group of people can arrive at good content to put in there"
  },
  {
    "startTime": "00:18:01",
    "text": "if we have a means to keep it good. I think we should err on the side of not doing it at all, to be honest, if we don't have that means in advance, personally I think we should keep it super hand wavy and like kill 195 and move on on 94. So general points, A, I really appreciate that you want to join in on that I like your idea with the rearrangement. We can just A, I really appreciate that you want to join in on that. I like your idea with the rearrangement. We can discuss get access later And besides that, we currently do have the problem that we do have this stale document. So whatever pass forward we take we have to get rid of that one stale document being around that part I'm in 100 agreement. And if we replace it with something that says like the IETF is a bad place to write this document, it is all obsolete, then if that's the best we can do, we should still do that thing Gee, thanks, Ben, living documents We, I mean, ideally, yes, this would be something like a living document, but that seems to have been really hard to get people to buy into. So maybe what we could just do is something to what DNSOP is doing. They've got a DNS terminology document, and I think they're now on version four of it in around five years time or something. So we could just sort of have the agreement and grow that we will just take this document and we will do business really often And, you know, not, we don't have to always like cycle for 18 months two years about making small updates we should be able to do them fast if the working group understands you know, we'll do this, we'll do another one, we'll do another one. It's a lot of FAF to make a minor change, but it's possibly less FAF than trying to do the living document idea again. I mean, there's no reason that we can't publish this and six months later start publishing the next one and six months later start publishing the next one. It's stupid, but process"
  },
  {
    "startTime": "00:20:01",
    "text": "process Yeah Rudy goes in the queue. Oh, Rudy was in the queue, sorry Oh, okay, go ahead I don't disagree that we could do that. My concern with that is that the steam goes out of that and one of those revisions just ends up being the last revision And I would kind of, like the sense in which I quite like the TTL idea is that I think it needs to kind of automatically die in a fire if we don't have the energy to continue that effort. Hence my idea about the kind of ever the living forever internet draft because at least does you know, there's a big red sticker that gets put on it saying this is out of date I mean, yeah, that's that is an option. It seems like it's just a crappy way to do basically what living document should have done Maybe if we do this, we can then revitalize the idea at some point of living documents being like grow has had to do something stupid to work around our inability to sort our lives out But yeah, I mean, if we do, I think it should be very clear at the top of the document. This is something that we're trying to keep updated and so you know because also even when drafts expire they now are not automatically removed from the repository. They're just marked with a little words that expired. So what we could do is what we could do is we could put into the BCP 194 thingy like for implementation specific look at the newest non-expired version of the following two drafts, A terminology, B, techniques well you look nowhere if one of them is expired, and then do indeed this keeping updating. And honestly, I kind of like the idea because it's like basically running code for living documents and easier to ask for forgiveness and for permission"
  },
  {
    "startTime": "00:22:01",
    "text": "for living documents I guess One's going twice. Okay Then we are quick. Thank you very much for the chat Next up, Camillo, from Nippon Telegram, and what is the other thing, telegraph Yes, we noticed two requests for launching calls for adoptions Okay, thank you. So this is coming Cardona from NTT. This is a update on the BMP jam module. Next one please. For this version, so basically I think the model is, I mean, if you wanted to call it minimal biolid product I mean, number two, it's some think the model is, I mean, if you wanted to call it minimal biolid product, I mean, number two, it's something that can work already The document is huge, it's like 70 pages because we actually well, besides printing the model, which is big, we actually go part by part of the module and explain what our ideas were for each section We have examples or examples are validated in jangling I don't think what else we can have there So please read the document Hopefully find errors you have, you find don't think what else we can have there. So please read the document. Hopefully find errors, you find gaps, you find stuff that you don't like because that's how we grow the document can you go back yeah sorry magic, we already had the TCP option that Jeff presented last time We already have like options to configure it, even though it was included you know you need a standard for that but so it's good. The model has flexibility there and we didn't have any option for"
  },
  {
    "startTime": "00:24:01",
    "text": "for configuring BMP in the peer group level we added that. So take a look and give us feedback, please next one please so what is the problem now? So how come we are not asking young doctors to go? and check it out and see we can move forward is that unfortunately, the model depends on the vGP model and depends on the to go and check it out and see we can move forward is that unfortunately the model depends on the VGP model and depends on which depends all of them depending on the network instance model the network instant model is requires a scheme amount A scheme amount is not really supported in general The tooling is extremely poor Jan Lind only basically supported a couple of years ago. It is a paint to learn how to configure it, because you have to configure it easy in a young library and you have to, you have some how to learn it I still haven't had the time, for instance, to go and learn it and do it correctly and I don't and I just get segmentation for faults and everything so it's a pain they know how like I said it's uh it's problematic um maybe I guess Rob knows if you ask him, but from nothing, learning how to work with it is really hard. And I really hesitate that the rotor support will be big on this one and so I do not know if we want to just make a model for the sake of making a model and not something that we actually can't implement. So, I mean, this is a general question so next one please so what we can do, we can try to play tricks on the model, make it that it validates a bit less but not depend on a scheme amount this is what is sort of doing now. We can continue with a schema amount, see what we can do with it maybe someday everybody will support it or we can wait for other type of solution. There's the full include that Gina Beanoa are proposing but that will take some time. Right now"
  },
  {
    "startTime": "00:26:01",
    "text": "the VMP feature set is growing so I think it might be fine if we wait for a few months and years. Just see the model supports it and supports these new features and continue or we can always create the first version and then do B bees. I mean, everybody seems to be very happy of doing bees at this moment in time and so I don't know up to you right now the model works. So give it a right, right? I did a quick Google odd schema, man right now the model works so give it a right right I did a quick Google what scheme amount is and it appears to be a document from 2009 but perhaps you can summarize for the crowd what a exactly schema mount does. So a scheme amount, let's take the network instance model so the network the network instance model well, you're doing network instances or VRX It allows you to plug a module in the in, in, in, in, another module But it does it what they call in runtime. That is, you cannot, you don't really design with it the router basically has to do some trick and put it with another container Honestly, I don't think this is a good explanation, because I really don't understand it very well myself uh so maybe somebody here can just raise their hand and explain it well. I do not mind. Maybe whoever will do it Simple mind explanation for me is in Unix file systems, you can mount a file system from a different device and then it looks like it is integrated into your whole data store and as far as I understand"
  },
  {
    "startTime": "00:28:00",
    "text": "kind of a schema mount tries to do the same for young models see as fruit then yeah Something like that. But so the problem here is that we within our module, we do need to go out of that, of that monitor. So if we were local, it only within the mounted tree we will work, that will be fine But no, we have to go out of it. And there are ways of doing that but it's really hard to do it but so the ignorance of my part or part, because I cannot say of our part. I would say of my part, I'm not knowing this enough might be of blame but the fact that routers were not supported because I have heard of vendors actually giving me that feedback, I actually think that concerns, should concern the working group. Yep. So we can always just do, like I said, maybe doing these versions is becoming trendy, maybe we do that I don't know we can always just do like I said maybe doing these versions is becoming trendy maybe we do that okay a comment from the chat from jeffrey haas, who unfortunately only is in spirit with us I miss you, Jeff. Jeff says, come in it's okay if the model isn't perfect in terms of having everything Yang augmentation works very nicely the critical detail is to have the skeleton for the new nodes to be mounted later I don't know if you used the word mounted on purpose But yeah, I guess it is worth considering to get something out of the door and maybe refine it later on because, as they say, perfection is the enemy of good pizza so who volunteers to read the document and give a review? I am assigning everyone in this room, including Sue Harris. Thank you you"
  },
  {
    "startTime": "00:30:01",
    "text": "you Jeff has, have you read the document? at hand? The political answer came back not recently It is indeed a 70-page document But most of it is just the tree three ben maddison, I think on. I think the key to answering this question personally is whether there is something about, it's not, the scheme amount stuff is not something I'm familiar with. It's not clear to me whether it's unimplemented because it's not currently very useful and that will change dramatically when the BGP model ships versus it is genuinely hard to implement and so the vendors are trying their best to sit on it I don't know. I don't know what the answer to that is. It would be, you know, seeing as such people with such information exist, it might be nice to hear from them. Can you ask Jeff if he knows anything about implementing a schema mountain in Juniper? Maybe he knows. Jeff says, I have to step out for a call All right. We will continue this conversation but it's good to note interest from both Jeff and Sue Harris. So I'm sorry I forgot to I could not join the queue but Schema amount was very... Can you mention your name and company? My name is Rashad. I work for Equinex When Scheme amount was done, it was very controversial then I've heard from people who tried to implement it is that it's very difficult. Will it ever be? No idea So very good feedback, yeah So the takeaway is perhaps try and avoid schema mount and after that we should review the documents again Next up. Jenny?"
  },
  {
    "startTime": "00:32:00",
    "text": "Jenny Oh, is that good? into the mic Is that good? Okay. Make sure to talk into the microphone This better? Very good I'm Jenny Ramzair. I'm from Meta. I'm here today to talk about the appearing API draft. We presented it at the last IETF 119, so I'll give you the updates today. This is joint with carlos aguado, Matt Griswold, Arturo Serene and tom strickx, but I'm here to present today since they couldn't make it next slide please Cool. So I'll give you a brief overview of the draft Then the updates we've made since we last presented, along with the work we have planned, and the next steps for the draft Next slide. All right, so the goal is we want to provide an API that lets you standard the way to request public peer connections between two different parts We offer a couple of endpoints. You can request new connections. You can list both existing and possible connections. You can also list mutually available locations at which you could peer along with requesting to delete any connections that you may have For authentication, we offer both Oath or OIDA support from a variety of parties, along with RPKI signed checklists Next slide. All right, so the updates since the last meeting, we've added a section on the RPKI sign checklist authentication. We've included a diagram to explain the flow of the API, Feedback was that it was hard to follow exactly how the API calls worked. Hopefully it's clear with the diagram Please let me know if you have feedback And then finally, we've tried to clarify the security and authentication section to make it a little clearer how exactly we expect this"
  },
  {
    "startTime": "00:34:01",
    "text": "to work. Next slide Yeah, so in June, there was a call for adoption on the Grow List. Thank you all very much for the discussion there. To recap, we sort of had four main points as I understand it. First off, our route server in scope for the draft, our position as author is that there are no additional fields required in the current specification in order to support route servers, everything that you would need additionally to support that should be available in whatever peering database you're using Should I go for the question now? I'll finish this slide Okay. Second question was, you know, given that you have RSC, do you really need OIDC? No We're leaving it up to the server to decide which authentic requirements you would like to enforce for your network. So you could have OIDC you could require RPKI you could require both, it doesn't matter to us in the draft We leave it open. Finally, somebody asked, you know, could we use young models? There are young models that are sort of similar to this API. Our decision was no we're not going to use the young model because we want to model the business decision between two parties for configuring peering so we will the young model was too specific. And finally, is there running code? Yes, yes, there is running code 20C my co-author has an API instance available now and meta is developing one, hopefully, to be released very soon. Next slide Planned work. We also received feedback on the list. You know, you really shouldn't mention Peering DB as the source of truth in an Internet draft specification. That's very fair We'll remove it and list it more as a possible example Thank you very much. We'll further clarify the authentication. And then finally, we'd like to see more industry adoption for running code"
  },
  {
    "startTime": "00:36:01",
    "text": "That's hopefully in progress coming soon Next slide maybe so the next steps again, if you're interested in implementing this API as a network, please come talk to me afterwards. We'd love to have more people use it. Again, this draft is only for public peering. That was very intentional. We wanted to get the first version out just support public peering and just clarifying the authentication requirements for the API. Obviously, the follow-up is private peering, which we're starting to think about now hopefully to have a draft coming sometime later this year. If this is of interest to you or if you have any feedback or concerns, please come talk to me afterwards. I'll stick around so I'd love to hear your feedback Finally, the call for adoption on the draft went out in June, but it hasn't closed yet. We, as the authors are wondering, should be closed the draft issue another follow-up call We'd like your feedback in that regard Any questions? That's all I got yeah Q Mycel, MPI-Enth, speaking with my small operator hat on I will admit I have not read this draft, but what? considerations have you put into this? for small operators? I can understand this is a wonderful draft for large company peering with large company, but if I want to set up peering with large company and I am small company, can I just set up something that, you know, it does the API stuff and turns it into like an email in my inbox? Is that possible? Have you thought about that? Is there further work to do on that? Yeah, this is a good question. We have thought about this. Obviously, we cannot expect every network to run an entire API instance custom made themselves Maybe in the running code bit would be made a minimal implementation that a small operator could just deploy and connect to their SMTP server or something. Exactly, yeah. We've been in discussion with a couple of"
  },
  {
    "startTime": "00:38:01",
    "text": "open source tools in the hopes of getting this implemented in the common open source tools like a peering manager and a couple others Hopefully we want to make this easy for everyone to use So yes, we're working on that. If you have any suggestions, I'd love to chat Yeah. Okay, cool. I'll talk to you later. Thanks First to cue, pardon, this is randy bush Arcus, and IJ research. First to Q talk to you later. Thanks. First to Q, pardon, this is randy bush, Arcus, and IJ research. First to Q's question, visualize peering DP putting up an API or a webpage for you So I don't think this is a problem, but a question regarding the private peering do you intend to do that as a separate draft or incorporate miss? Are we intended to do it as a separate draft, but if the group would prefer us to do it one way or the other, I have no strong feelings. I just wanted to keep it separate. No problem either way, just curious yellow job snijders, Fastly, some comments as just as working group participants participants I think the implementation effort, having read the draft in its current instantiation, it might be able to do something in under a thousand lines of Python. I think the API is pretty straightforward, so I think this is good news and I think this has the potential for you know, if it gets integrated in Peering Manager then arguments that it's not accessible to smaller options will be because moot. So I'm optimistic As to the contents of the draft, I followed the discussion about whether accommodation should be made for route servers or not and I think it is helpful to consider adding"
  },
  {
    "startTime": "00:40:01",
    "text": "a bullion field. This is a route server or not because the moment you set up here so as I understand the mechanics of the train you and I agree to peer you have to look up in an external source such as peer to be whether I'm a route server yes or no and based on that, you on your side will configure a allow transparent AS, yes or no and this dependency on an external data source for operational configuration management that is specific to a BGP session is not specific to an AS Because imagine there is an AS that has both types of sessions you cannot really express that well in Peering to Bees data model. Sure, sure And and if the session comes up and you're not expecting, a route server but I am acting like one then the first be sure. So, and if the session comes up and you're not expecting a route server, but I am acting like one, then the first BGP update I sent will cause a terror of the session and an error will be locked locked So I think there's a case to be made to make a bullion field, this is a route server or not, and I think this is beneficial to users of this API because the moment you tell me or I tell you, I'm a route server, you can give me an error code like no no that's not what I want So it allows for more fine-grained application of interconnection policy And then secondly, I think another field could be added next top self because a route server may send prefixes where the next stop is not done themselves, but appear may also do that and I think it is good if pure upfront declare whether they're going to send next hops that are in the link net or not. And again, if I tell you, I'm going to send you next hops that are not me"
  },
  {
    "startTime": "00:42:01",
    "text": "you can throw an error code be like, oh, actually, that's not conforming to my interconnection policy So I think those two fields have the same, should be in the same place as say the MD5 secret OK, that makes sense. We can add that And I will use the microphone because I'm talking way too long. We close to queue after this because we're over time. Ben, work online. I think that the current draft is a substantial improvement Thanks. I think that I think there's a middle ground on the Yang thing. I think that reusing someone else's existing model is I think, probably not the right approach. I don't think there's anything that's a great fit for it I think expressing some of the types that you're using in a Yang module and actually formally describing the data structures that are involved here is a good thing and would make a special kind of demo implementation writing much much easier for some people because you can just lean on the tooling. So I'd suggest looking at that, maybe not like right now, but as the draft matures and you've got a clear idea what those trade structures look like On Yob's point, I half agree. I think that it's, I think the multilateral period thing is something that needs to be expressed in the API I don't think that you want to express that in terms of the policy artifacts that require something that needs to be expressed in the API. I don't think that you want to express that in terms of the policy artifacts that that requires. I don't think that you want to like am I going to be prepend? myself to the AS path? Am I going to be setting next third part? next hops thing? I think that's, I think it's a I'm expecting to be a multi-lamp peering service. Do with that locally what you were I think that's the balance to be struck because otherwise I think we rapidly go down a rabbit hole of trying to communicate arbitrary routing policies over an AP and we become RPSL"
  },
  {
    "startTime": "00:44:00",
    "text": "Implementation details So, Tobiasiwich, Max Planck Institute of Informatics for myself I'm disagreeing with the Boolean field for the route server. I would more argue that it would be better to just throw in BGP roles there So you signal to like the request of the BGP role because then you cover the route server case and you could technically also do weird things like, this funny auto up streaming etc Let me to clarify. We have an RFC. RFC 9234 which defines robles that peers have with respect to each other and they are signals in the open policy in the open BGP message So the peering API could reference RFCD 9234 and have the role be part of the one of the fields. Okay, I'll have to read that one but I will read that one and consider it. Thank you Thanks, everyone. Thank you Thank you. Oh Hello, this is Paolo So three draft presentations. We start with the TLV one. Next slide, please There is an intro slide as always, you know, a problem statement. We are you know bumping the version to version four and we are bringing TLB in all the messages that we have in BMP, including who route monitoring that doesn't have it right now and next slide please there is not really"
  },
  {
    "startTime": "00:46:01",
    "text": "been any additional work to the draft since the last IETF I would say that the draft content after you know a pretty sheet 2023, it's steady state right now i would say we have just two kind of open questions, which like if anybody has a comment I mean I thought we are the first comment So whether we had any feedback on this so guess you know in a BGP, PDU, we have, you know, we can have reach and reach and things like that. So we have a number of seconds on this. So guess, you know, in a BGP, PDU, we have, you know, we can have reach and reach and things like that. So we have a number of set of NLRs If you have read the draft, you know that we are indexing the NLRI and we start like from the first to the last end, we start from one until the end NLRI. So what do we do when we have multiple sets? We just count the from the first to the last one in the order which would be probably my preference, is the easy or no complications. Or shall we add any further complication like that I don't know, like the reach will be a set one, a reach set, two, and then we have sub-indexing as part of the set right? So those would be, I think, the two main choices I am personally to keep it simple This point was raised by Luke and it deserves some thinking so if you have any feedback any opinion on that please provide that and the second open question is that the draft right now doesn't allow a group to be part of itself and of course that's healthy but also that a group cannot be part of other groups. So now let's think about again the fact that we can have you know sets like we can have reach and the reach in a message in a in a in then"
  },
  {
    "startTime": "00:48:01",
    "text": "maybe we can, we may want to do groups in a in a in a in a in a you then maybe we can we may want to do groups of groups so in other words I would just unlock the possibility. I don't see it very high harmful, although what? I'm a cut off. No, no. We are being crowdstri Okay Thank you Fantastic. But so, yeah. So that was the thing. So, like, unlock the possibility of groups, of groups. I mean, I think it's harmless to do it Again, if there is a new opinion, I mean, just let me know Any immediate feedback on it? of these two questions? Oh, we cannot know from remote people, right? No, remote people haven't said anything yet. Okay So what? do I do? I wait Okay You have to click something I don't know, just try it. That's right"
  },
  {
    "startTime": "00:50:00",
    "text": "The problem is it's Okay They said the public thing is having Yeah. Ethan Pat also had issues That wasn't my fault Friends of it Okay So you want to go to your next set of slides? Yeah okay. By heart thing, I only remember n plus one. So the next slide was about, you know, what's the kind of status? So as I was saying, there is not being a any... The slides are really pretty you guys are like missing out on something missing out on something. So, but what I was saying is the next slide is that like we should you know, action item right now it's that because we are in steady state, probably we should start implementing this thing so it would be very beneficial if there is anybody willing to do that. I'm looking at one guy in particular in this moment exactly, much sense, but yeah, it would be very nice if at some point we can make the implementation of the TLV draft and proof it working, something like that slide the next draft was about the RELD-REL, the route event logging and I remind myself what I wanted to say Right. So, okay"
  },
  {
    "startTime": "00:52:01",
    "text": "there is a recap of the, what the draft does. Next slide slide At least, I think at least remotely they are seeing the slides, right? yeah okay so it's only for you Exactly So what we did in the rail draft is we added the cross-ed warning bound and the crossed upper bound right, so which are the two checks when you have a prefix limits, right? So the warning and the you know the session was for example cut down So we added that TLVs and the code points in a the event recent TLV, right? And of course the TLVs are just 4 bytes integrs so where you can express what was the amount of prefixes that you know, triggered the event I did work out further another couple of tiers like the malformat packet TLV there was some feedback from Ben at the last meeting in which we were debating whether this was overlapping too much with root mirroring, one of the use cases and Bang brought a good know a good consideration saying that maybe you want to do some observation you want the routes in one collector, and maybe you want to see the events in a different collector so it may probably more sense to have it in this draft right and then I worked out a little bit more the policy discard the TLV before it was just a recommended to make a string and now this string that is meaningful and now"
  },
  {
    "startTime": "00:54:01",
    "text": "with the input of Thomas that is here the recommendation, it's still a recommendation it was being a little bit constrained a little bit mark thomas was saying something very true that we have, you know, a young model for policies and a young model for BGP policies, and then essentially like we could start to talk about, you know, policy name and statement right which are two elements recognized in these young models, right? So that's just a recommendation We can talk about it and see if it makes sense or whether that is still insufficient and we want to close it a little bit more. For sure, the idea is not to close it too much or convert the recommendation in something mandatory because otherwise then we may have possibilities in which, yeah, we close it too much and then it becomes not possible next slide please um Yeah, and then rework the operational consideration and other acknowledgements, which brings me to the point that you know there are quite some acknowledgements are the most so for a draft that is quite, let's say, yeah know, acknowledgements, which brings me to the point that, you know, there are quite some acknowledgements at the moment, so for a draft that is quite, let's say, young, I mean, it seems it's drawing some, you know, interest and I'm happy about that. Second, um, there are quite some acknowledgments at the moment. So for a draft that is quite, let's say, young, I mean, it seems it's drawing some, you know, interest and I'm happy about that. Second, next slide, please. There is at the moment no feedback to process. I'm still culpable for not having worked out all the TLBs that I have expressing the event reasons I would do that. And then there is the usual questions still up in the air, which is, you know, good for the audience to provide feedback which is like, is the message type good as it is so it mandates that there is, there must be a BGP PD TLV in the in the in the message or we want to, you know, make it optional and so that would open other use cases, we could report on more stuff"
  },
  {
    "startTime": "00:56:01",
    "text": "even close loop kind of operation and things like that so that's uh that's still a question that we should think a bit about it next slide i have the next uh presentation so maybe I take the question from or the comment from back Yeah, my comments are very specific to that draft, so it's probably best now to that draft, so it's probably best. I like the idea of trying to refer to the BGP policy model to find where Lurie got dropped. If we're going to do that and we're going to concatenate two strings with a comma let's just double-check that commas are forbidden in both the referenced fields because that's a can of worms we won't be able to close again. Absolutely No, no, no, you're super right. In fact, it was just to have some text to nail and see whether we agree on the idea and the comma think. I totally agree it's not a good thing Probably we can do also a sub-tlV or something like something more Right, right, of course, of course, of course, of course okay fantastic and so we have this new draft that was submitted actually yesterday the filtering adribing and adribal to BMP receipts which is in your work with Camillo and Mukul from Juniper. Next slide, please The intuition is super easy. It's super simple This Jeff, I don't know if it's for this draft or the other one, but so the intuition is super simple, like we can filter lock-rip, but we cannot filter post-policy, Agri-Being or Adjribout So let's just do it I mean, let's have a flag so that we, there is this possibility. Two main reasons. I mean, first, we make all things equal"
  },
  {
    "startTime": "00:58:01",
    "text": "which is always nice, equal consistent, and second I mean, we have use cases like we can limit the fire hose of you know, routes that reach a collector or that need to be packed by an export we can filter by the address family and things like that. Next slide, please So super simple, like we have a registry called BMP peer flags for peer type 0 to 2. Let's add a flag F over there. If we want to filter, we set that value to 1. Then essentially, like, stat math messages should reflect you know the filtered state and not the original state and then if any characteristic of the filtering is changing which a collector wouldn't know, I mean the should trigger a peer down and restab the peering essentially. Next slide please. There is also a recommendation that, you know, we should set the VRF table or a VRF table name or the VRF name to a meaningful value. So that means just a string that makes sense for, you know, whoever is packing the information And there are two ways in which you can do that one optimal for who is packing which is like in the pyramid you say this is the table name or optimal for the collector, which you like you do it in the route monitoring message so that essentially like you don't have to go back and look at the peer up what was the name that was in the PRAP. It's an always like the route monitoring message, so that essentially you don't have to go back and look at the PIRP, what was the name that was in the PRAP. It's an always debate where it should be the optimality stand. So for now I'm leaving the two possibilities out there, and then we can discuss and see where life takes up next slide and it's a the two possibilities out there and then we can discuss and see where life takes us next slide and it's uh yeah uh receive feedback uh keep"
  },
  {
    "startTime": "01:00:01",
    "text": "working on the text, and maybe working group adoption it's really not a big drama kind of draft So I would say it just makes sense to do it So that's it. Your request for a work group call for adoption is noticed by Warren. Camillo Yeah, Camillo. No, just to say that wen lin the BMP model, we have an option to configure the filtering. So they kind of go honey-hand entity. No, just to say that wen lin the BMP model, we have an option to configure the filtering. So they kind of go hand in hand just to give that. Fantastic Left hand, no swam model, we have an option to configure the filtering, so they kind of go hand in hand just to give that. Fantastic. Left hand knows what right hand is doing Thank you, Paolo Next stop is Yisson with BMP route message aggregated Hello, Chess. Can you hear me? Let me I should not be touching this Yes, we can hear you Give us a second to get the slides on the screen Okay, thank you Thank you for joining us, Yusung. Take a you for joining us, Yusung. Take it away Okay, I can control Hello hello everyone. I'm yisong liu from Chen Mobile. And today I will introduce the aggregated BMP with monitoring message And I will be half of my co-authors from the H3C and Juniper Firstly, I will give the brief introduction and the BMP route monitoring that called RIS RM message is used to send the incremental BDP routes at"
  },
  {
    "startTime": "01:02:00",
    "text": "withdraw by peers to the monitoring station According to the implementation of the BDP group packing, as I know at many vendors have a implemented the feature like the Cisco, Huawei, H3C, etc And there's, and according to the feature, we have proposed the new type of the Greek Katie, located beyond it will compare the multiple bmperm message into one a regated BMPR message. And it will reduce the amount of the reported BNR messages and it will reduce the expense of the server and it will update the RFC 7854 by adding the new BMP message type And for the background, for the BMP, group hacking, suppose that the R with multiple clients, they need to send the roads to a large number of BMP client appears, for example for 100 clients, and most of them clients maybe have the same configuration And the BGP group packing technology we will treat the older BGP peers with the common configuration as a packing group So, it should be sent is only packaged only once, and then send to order the neighbors one-by-one in the packing group If the practices are the same, for the BDP update, so where if the are N peers and need to be"
  },
  {
    "startTime": "01:04:01",
    "text": "sent and the the practice is in the in the in the are N peers and need to be sent, and the practices in the normal way, and the practices will pay pecking from the peer one to the peer end and we will packing n times and the sending to the peer one to peer n and the send times is in times and the the a group packing mechanism and the n times. And it is sending to the peer one to peer in, and the sending times is n times. And for the group packing mechanism, and if the practices are the same, and only once packing for the group and sending to the peer one to peer end for end times and we'll see that the comparison of the two packing methods and the the the packing times will if you use the packing group packing for BGAP and we will reduce the packing times in minus one So for the BMP, our message include the common header and the proper header and the BGP update BTU And for the, if the practice are same, if we have N peers and the many need to the package n times and the same N-arm messages to send the server away in this if we use the the aggregated BMP route monitor message and we define the the format for the common header and the multi-peer header The multi-peer header format for the proper header from 1 to N header and the multi-peer header. The multi-peer header format for the proper header from 1 to n. If the BP pass actually attribute"
  },
  {
    "startTime": "01:06:01",
    "text": "for for each of the proper header, it can carry the unique BDP path attribute of the corresponding per peer If no BDP path attribute is carried. So the proper header only contains the peer address. And if the if the prefixes are the same. So if we have are N peers, it only may need to package one time and assemble one aggregating message On a condition that there is no unique BDP pass attribute for the P peers the peers. This is the comparison of Mr BMPR message for the aggregating aggregated way. If the preference are the same, so the package time and the payloads or for the for the common header the same BGP path attributes and the prefaces, the package times and all the payloads or all reduced by the minus 1 times So that a simple mechanism for the aggregated BMP arm message So we welcome the questions and comments That's all. Thank you Um, speak as individual contributor, I think pack is a very interesting concept We've seen in BGP that it can greatly reduce the number of messages crossing the wire"
  },
  {
    "startTime": "01:08:00",
    "text": "And I imagine that similar optimization opportunities exist in the BMP protocol protocol So of course, it's very tricky to figure out how to do packing or whether it should be compression with dictionaries that are generated on the fly So I encourage you to see collaboration with other BMP implementers and find common grounds what exactly the most efficient and convenient way of implementing such a mechanism would be I didn't hear a request for a call for working group adoption but do you think the documents is ready enough to take that step? If so, I'd be happy to Yeah, yeah Yeah, I think I ask for the adoption I will send the request Okay, next up in the queue, Jeff has haas. Hey there, thanks for the presentation. So general feedback for the working group on that draft. The behavior we're looking for isn't necessarily to reinvent all of the pure semantics for group packing and BGP with all those complexities you know there's the sort of long for isn't necessarily to reinvent all of the pure semantics for group packing in bgp with all those complexities you know there's the sort of long-term desire i think that the working group wants is that when rib out is used, rib out is a very very noisy feature and people that turn it on sort of regret it in some cases when they're running their station a feature that just simply takes the reggae very noisy feature, and people that turn it on sort of regret it in some cases when they're running their stations, a feature that just simply takes the redundancy of the stuff from a BMP reporting point of view and hide some of that piece of complexity would probably make people that want to consume rib out a lot happier And that's that's the criteria to just analyzing it from Thank you"
  },
  {
    "startTime": "01:10:03",
    "text": "Any other comments? All right, thank you so much for your presentation Thank you Next up Jin Ming about BGP RIP statistics Yep Hi everyone, this is Jimmy from ChinaMobile This contact, I'm going to intro several new types of BMP statistics added in this draft, which are up updates based on the existing working group drafts Next please You have control the slides. Sorry, I should send that earlier On your screen you should see a right pointing arrow and if you click at a slide. Oh, I see Thank you screen you should see a right pointing arrow and if you click at a slide. Oh, I see. The types of BMB protocol statistics are defining RFC 168 and which can be used to collect interesting information happening on ROTUS. However, the existing base types cannot meet the other observation needs for more and more detailed data the BMP statistics types need to be expected expanded Perhaps you still remember that someone introduced these types at the grow wall to be expanded. Perhaps you still remember that someone introduced these types at the Grow Walking Group meeting of IETF1 118 and 119 They can be divided into categories based on Reveen and Rebot. This meeting, is mainly to clarify some changes. As you can see on a certain day in the past few months, we merged draft view into draft IPF, the content within the"
  },
  {
    "startTime": "01:12:01",
    "text": "red square range in this slide is the main updated content It involves the statistics of routine threshold, ESPASS, and the statistics of RPKI validation results The first 11 type are from the original drafts and I haven't showed them here again. If you are interested in them, just click on our draft link to have it look Type 12 to 15 are all about the statistics of routing threshold. The difference is it the statistics of routing threshold the difference is that the latter to pay more attention to the routing thresholds of a supplier license. So it is recommended to use the enterprise-specific TLV encoding The specific definition can be found in section 3.3 of their draft IETF group BMP TLV Ibit can be found in section 3.3 of the draft IETF group, BMP, TLV, EIT. The next time sitting and 17, 17 artist that takes stakes of ASPass and it's worth mentioning that we have added this static stakes types of RPKF validation results in the draft some ways think someday RPQI will definitely be wide delayed out of the world, adding the RPCA statistics will be useful then and rebates the rebalt static text type defining the draft is no difference from Rabin They are still the statistics types of AAS pass and RPA validation"
  },
  {
    "startTime": "01:14:01",
    "text": "results, but it should be noted that RPKAE, and RPEC, and 9893 has some influence on the static stakes of RPQ results in the case of revolt, thanks to Jeff's comment in the mainland list, this type should not be reported unless RFC ADA 93 is applied on the routers still RPK So it should be nesting left here. Any comments, welcome? It doesn't see there are questions or comments at this point in time Thank you so much for this update Yeah, Sam Next time is Maxine Maxens and or Pierre Peter. I don't know Hi, I'm Maxence from in Salion. So the first draft I'm going to give an update on a little bit closer Okay, yeah, okay. So the first draft I'm going to give an update on is BMP local rip pierre dress so the goal of this draft is to include the peer address of the peer you receive the route from in local rib route monitoring messages messages so we had received some comments on this draft Basically, we were missing the INA section, so we added this one inside we have allocated"
  },
  {
    "startTime": "01:16:01",
    "text": "TLV type for the for multiple TLV types for like the VRF import origin VRF the peer address and all of the basically all the TLVs we find in the draft And we also received the comment from Jeff, I think, that the address selected was sufficient for IPV4, IPV6 but not IPV6 link local address So we added address type field in the Erickspier address TLV, which allows us to define, like to specify which type of address is following in the TLU value we have next slide please We have, sorry, it looks like this we have five types right now which are self-originated like this we have five types right now which are say for several originated address type so basically when the router is the one originating the route, we don't put any pure address. The IP4 address type, so the class IP for address of the pier Type 3 is global link IPV6, so one is set forward as well. And then we have type 4 and 5, which are IPV6 addresses and the interface identifier there are bound to, so either an ID like a variable length ID that is numerical, or a name, which is a string, basically, variable size string. We don't know which one if you want to keep like both of them or just only one I understand string basically variable size string we don't know which one if you want to keep like both of them or just only one I'm not sure yeah that's it for this one so next slide please Yeah, we had issued a working group adoption call I think"
  },
  {
    "startTime": "01:18:01",
    "text": "we had like a few people that were interested in the draft but I think we still are in the working group like waiting for the adoption call I'm not sure so yeah I'm not sure about that My apologies. I should have closed this call earlier on there I would argue there was a lot of support in favor, but more importantly, there was no objection. So we will proceed to adopt this document as working group documents and continue on it jointly. Thank you OK, next slide, please. Yeah, so the second draft is the local pass ID. Basically the goal of this draft is to have an idea that identifies a path that's exported by BMP. That helps us first to avoid network modeling and also because sometimes network modeling we don't have enough information to do it So that allows us to actually identify the path without making mistakes when we are recreating the state of the rip in BMP next like this Yeah, so the changes In BGP can redistribute paths, so basically you can import them from OSPF or SSA, something like this Previously, we were not a local an ID for a path that was coming from those if they did not provide it. So now if you import a path from say OSPF and OSPF did not allocate local pass ID, PGP should BMP should allocate a pass for the ID for the pass We also added some descriptions of the error codes, so those error codes are for when you don't have a past, you would like to know, you don't have an ID for the past so you'd like to know why, and we've made the INA section with basically all the"
  },
  {
    "startTime": "01:20:01",
    "text": "like a registry for the past ID and a availability reason codes and some editorial change next like this yeah so we have an implementation in FRI routing on a fork So it's working And we are going to work on an implementation on the collectors side, so probably in PMCT and so yeah I would like maybe to start working group adoption call now okay and yeah, I think that's it. Thanks The adoption call has been closed Oh, sorry, where did we last call? Ah. Yeah, no. Yeah, adoption call for the second draft. Yeah, local passage ID. Ah, sorry I'm sorry. There was two in the same It will help if you email the mailing list that. Yeah, yeah, yeah, yeah, we will. Thanks Thank you so much As always, uh, as co-chairs, especially myself, are fallible humans. So if you're waiting for some action from the grow, co-chairs, always feel free to email us privately or publicly and be like, hey, I'm waiting on you and we will take a look So with that, I've think we have reached the end of the growth session at IETF 120. The next session is going to be in Dublin, in a beautiful country of Ireland in November And I hope to see you all there. Thank you so much. Have a good day"
  },
  {
    "startTime": "01:22:12",
    "text": "Eight minutes to spare. There you go Need up time. Hello Sure Um, I always heard an email, let's say say,"
  }
]
