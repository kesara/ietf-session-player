[
  {
    "startTime": "00:00:34",
    "text": "Good morning. Was Good morning. We will start in 1 or 2 minutes. You know, and My old sparkling is okay. Nice. So I made spreadsheet time is. It's It's just Yeah. I will do that. Okay."
  },
  {
    "startTime": "00:02:25",
    "text": "Okay. Good morning. We will start in one minute. Alright. Good morning. This is. Working group session to Friday morning. Welcome, everybody. 7 Sorry. So this is, the openings and the chairs. My name is Benno. Susanne, my coach here, Tim, is online, remote, We'll do the, the current updates Update of current work, for the for the working group. Immediate"
  },
  {
    "startTime": "00:04:00",
    "text": "Boren is our area director, sitting in France, and we use METAC or Zulu, etcetera. It This is an IETF meeting. Working group meeting is an IETF meeting. So the note will applies. I assume everybody is aware of the notebook. What it says. Good. This is, Yes. We don't have blue sheets anymore. Someone mentioned nobody knows. New generation don't know. What's the blue sheet? Oh, excellent. They're the blue sheets. It's quad code. Excellent. Please sign in with the online tool. So you sign the blue sheets. For remote people, of course, they are signed in and signals of the blue sheet. So the the meet echo at, signing, attendance, instant blue sheets. To make sure sign in. If you want, walk over to the mic, use the online sorry, on-site tool, to raise your hands. You get or the for the remote people just raise hand, and you will be cute. That sets those are kind of code of conduct guidelines, also part of the note well. Take this seriously. So bottom lines be respectful and friendly to each other. Good. So this is agenda for today. Agenda Bushing, current Cheers, updates, Warren will give, need who will We'll give an update of some other documents and ISG work 5 minutes we go to the current working business and then for consideration, Elias Hall, We made small change. Normally, we go for working group business, but due to travel schedules, etcetera. And this wasn't draft that has seen some discussion in the mailing list. We put delegation management fire DDS."
  },
  {
    "startTime": "00:06:01",
    "text": "Is first on the agenda. Later, the current working group business. I shared it also on the mailing list Paul Hoffman will give 2 best documents. Thank you, Paul. There will be more updates on compact denial existence and SVC Bank, then. Sorry. Sorry. Ben. And for consideration. A number of documents. They're all on the agenda including including, slides and, URLs to the data tracker documents. Good. Also, at the very end, we have 2 presentations. Lisa saw with other working groups, ricks. Middle presentation by Scott Scott Hollenbeck, and McKinney Landers will give Leah Sol with actually, I doctors when, 22 or 1. Seabor of core and, well, not a working group, sorry, machine. You can correct me later. These are the document updates, we mentioned this last, idea Sorry. And Here we go. Tim, please go on. Oh, actually, I was thinking Warren should should speak now. If if if If you can cut him in there because I think this is the talk about 5933 biz. Yep. Excellent. Yeah. Yeah. Gifts. Okay. Guess when you come back to the system, Hello, everybody. I don't know. I have to look where are Yep. Yeah. Yeah. Hello, everyone. So a failure to communicate or draft ITSub DNS of blah blah blah."
  },
  {
    "startTime": "00:08:00",
    "text": "Next slide, So some history on this. This was the use of Gus 2012 signature algorithms in blarg, The working group adopted it in, 2020. And then It had working group last call, And then it was sent to me, and then it went into ATS last call. And then it went to ISG eval, and then it went on the tailor chat. And then There was a disgust from Roman. Which was largely saying the IETF is steered away from doing crypto stuff in working groups. And He made a suggestion which was this should probably go to the ISE because that's where we do these sorts of discussions now. You know, you know, you know, d Security group thinks that these discussions happen in the ISE, and we're trying to not do them in the ATF quite as much. And that's sort of the security agents view. And so there was a whole bunch of discussion with the working group. Right. Nope. Somehow, Warren managed to drop everybody off the thread where this was discussed, the sort of like, hey, here's the plan, you know, we're trying to see if this can go through the ISE, Is that okay? Anybody have any major heartburn? Apparently somehow I just managed to drop DNS off. Thread. And so we're trying to figure out how we fix this now. We only discovered that the working group had been dropped off the thread, when there was this conflict review when the IAC was trying to move things through and was like, Here's the plan. And I was like, oh, yeah, yeah, this is all good, you know, happened in the DNS soft working group. Nobody seems to mind if we send it through the ISC, And so what I am asking is, is"
  },
  {
    "startTime": "00:10:02",
    "text": "the ISE does not want to progress any documents, which steps on a working group's toes. Which I think is the obvious right thing to have happened. What I am suggesting slash asking is dean, dear, DNS of working group, this was originally a DNS of document It would be very hard to get it through the IESG at this point. We could Have it become an a AATF document and try push real the security ADs, or we can just say, dear ISE, can you please publish this? My view is, you know, the ISA is moving along that seems fine to me. But, you know, this was clearly a failure to communicate should have asked the working group I should not have accidentally dropped you off the thread. Does anybody have any major objections to us moving the document along? It goes to the IAC stream instead of the IETF stream. Hopefully, some of this was, like, coherent, and I didn't just ramble that's Friday, I feel like I might have struggled So Andre? Hi. This is Andrei. So I do have this request to review. I sent 2 digital signature algorithm for a sec. This is similar situation. What should I do with that then We should probably discuss with the security ADs the security AD thing, and there should be a wide discussion with the IETF I believe the current view of the security area, is that national crypto algorithms or actually all crypto algorithms should be discussed through CFRG. And if they're not being discussed through CFRG or their national crypto probably the ISE is where the documents that discuss this should happen, but again, that's the ISE's"
  },
  {
    "startTime": "00:12:01",
    "text": "Thank you. Sorry up there. I see. Yeah. Quick clarification. The draft that you're talking about an independent submission. Yes. Oh, sweet. Province out. Okay. So I should just review it You done with it. Okay. Great. Thank you. Peter, Hello. It's Peter from DSIC. I just wanna say that I I like how how this is handled. And, I mean, mistakes happen as we have transparent. Thank you. Sweet. Thank you, and also thanks to the person who noticed take, take, take, when this went through the conflict review. And I was like, I thought we had to hold it. Oh, crap. Y'all weren't on the thread. So, thank you. Thank you, Lauren. Yep. Yes. Thank you, Warren. We also wrote a long email to the authors sort of explaining all this, and we forgot to we dropped DNIS off as well. And so that was a combination of just whoops kind of thing. We're trying to hide anything. We were just going through the whole process. So Okay. Tim, shall I run the slides? Yes. I think, yeah, that will probably be better. So if you can And then we did that 2 Tuesday. So we oh, so and we wanted to double just go back over DNIS SEC validator requirements I know we discussed this last meeting. The chairs and Warren, we've made it decision to park a document due to lack of consensus, The authors have decided to submit the document to the independent stream, which is They're right. And in that case, the working group will still need to be okay with this path. And I believe Elliot will contact the list, or there'll be something that'll go through and and I'm sorry, Elliot. I don't think it's happened, but I know we've sort of talked about this one. 5th And so we just have to make sure the working group's okay with this path. And that will come up at some point."
  },
  {
    "startTime": "00:14:03",
    "text": "Next slide. We've got 2 documents in the editor queue, which is good. Things are moving along. Next slide, So in working group last call, The domain verification techniques, which, of course, was discussed Tuesday, it'll need a new working group last call with all the updates but we're gonna wait till they come back from the cab form. With some details. Now the next one The Dean insect bootstrapping document The working group last call is ongoing with Little feedback, This may be my fault with how I wrote the email But I know there's been several implementations of it, so that's good. People are doing stuff with it, and we're just trying to get some senses from the working group Should we proceed with this thing? And I I put a note in here. Do we use the fancy mid echo Show of hand tool to get people to sort of Speak up on this. And I'd like to hear stuff from the from the room or, we should hear something. Yeah. Tim, we're, I'm looking at time, actually, and maybe Oh, we're running out may make maybe, give folks a chance to swap this document back in and Okay. Just reminding people that for a working group last call, we do need positive support for publishing the document. So if you read it and it seems okay to you and you think it should advance, It's really helpful to us if you say that It's not just, reviewer comments or criticisms. We need we need positive support. Yeah. And we know people have, must like it because they're implementing it. So there is that going for it. So let's do the next slide. Another one that's a working group last call, 8109 Biz,"
  },
  {
    "startTime": "00:16:00",
    "text": "and that's kind of sitting. The first work group of last call was botched, and that was my bad. But it's Got no feedback on the second working group last call, but Paul Paul's gonna speak to this year shortly. Next slide. And the same thing for the working group adoption on this on this short date to the Trust Anchor RC, it's It doesn't. It there's not a lot of stuff going on, but you know, Paul, again, is gonna is gonna sort of speak to this here, like, right after this. So next slide. These two were kind of been kind of stuck, but Benno talked with, the authors and you're getting an additional author on DNSEC Automation. But For NS Validation, we would like to sort of Ask the working group if anybody's interested in helping Shuman on this. Please reach out. Speak up or something because we do feel we need another author on this one. To move this along. Next slide. So structured DNIS error work still going on. It's, you know, people seem to like it. QD count is 1. This was mentioned Tuesday, and we sort of feel it's pretty close to done. And of course, generalized notify was adopted recently, and there's been some good discussion on the mailing list that. That's good. So next slide. What else is going on? Oh, yeah. Two things on today's agenda, compact and auto existence, and and service be Dane. And then CDS consistency, it's gotten some of the earlier reviews back, and we believe it's ready for working group last call. We're gonna sort of put that on, you know, on the pile with with a few others. So that's good. So next slide."
  },
  {
    "startTime": "00:18:02",
    "text": "Oh, yeah. Other documents. This happened yesterday in DNS SD. So QD counts now greater than 1. There is an there's a use case for this in low capacity networks. And I know Ted and Stewart are both in snack, and so they won't be here, but I'm sure Ray is around, But basically, the suggestion is to is to basically resurrect his multi q type document. And the question was posed in DNS SD should the document exist in DNS or DNS op, and Our opinion is we're very open as to which way it goes, and will it by whatever the working groups you know, sort of what direction they they give us is rural abide by? So There were some questions in DNS SD about that yesterday. So next slide, and I think Yep. That's our steps in the data tracker, of course, GitHub, And that's I I believe we covered all the documents. And I know it's early. It's Friday morning. So everybody's sort of fried. So, reach out to us make sure we've got everything We didn't miss anything, or we've we're right place for, status and stuff. And I believe Next up. Oh, no. Not Yohan's first and then Paul. Yeah. Will let you go. Thank you all. Are there any questions, comments after the chairs update? No. Okay. I would like to invite Johan for, Right. The It's the kicker. We need to rearrange this."
  },
  {
    "startTime": "00:20:04",
    "text": "Here. My name is Johan Narayan. Sorry. My name is Johan Stanstom. And I work for the Swedish registry and, do things with dentists. So there has been a fair amount of of discussion on the mailing list about this proposal that I'm about to present and also the generalized note class, which is a working group document because they have clear overlap. In How to identify or rather how to announce services from the parent to the child. And I would like to sort of take a step back before I actually get into my read presentation, which is about the dynamic update stuff. And just break out the part of announcing services from the parent's side. So if we look at this, sort of from a slightly higher perspective. We have a delivery mechanism for some sort of service. That delivery mechanism could be through a notify. That's the general generalized notification stuff, or it could be a DNS update possibly according to the the drop time presenting a few minutes, or it could be something else. There are ways of delivering service. And then we have the separate issue of how do we find where this service is being provided. How do the how does the parent announce the existence of and the location of this service. And those are actually 2 different things. So There has been discussions about whether we need a special record type to announce this stuff where whether we could go with it. So a m name or we could just send things to the authoritative name servers, and we could do all sources"
  },
  {
    "startTime": "00:22:01",
    "text": "different things. But those those discussions are really mixing up the delivery of the service with how to locate where the service It's So if we take a step back here, We just think of something which isn't notifies. It isn't updates. It's Let's say something out of bad. Some sort of of out of band provisioning thing And here, we used example of, some some sort of service where you can request through your registrar to the registry, a change of the TTL for the records that constitute your allegation. So how would I announce this? Well, According to to the different alternatives that we have, in the in the mixture of the update draft and the generalized notifications draft, Well, we sort of think about this as, yes, We just add another scheme. We have 2 schemes, essentially. One is to notify scheme. 2 is to update scheme. And we have the 3rd scheme, which is there is an API somewhere, an This is how to sort out the API details. The point of this is not in any way to say that this is an important service that the world absolutely needs. It may be. That's a separate discussion. The point of this is to abstract away That announcement of the existence of a service is separate from the delivery of and let's not mix those 2. Does that make sense? Okay. So given that, Let's get into the update stuff. And, unfortunately, because this is sort of stuff that happened on the mailing list yesterday, etcetera, that the presentation I have, not to mention the draft I had. Is sort of written from the point of view We have this problem."
  },
  {
    "startTime": "00:24:02",
    "text": "We announced it the same way that we do the generalized notification and these are the pro cons, and this is the result. I I honestly think that part of what we should do here maybe that we should restructure both documents Sorry. And have possibly a separate document that only talks about how the parent announces services to the child. Nothing else. And then we have a separate document or documents that essentially define their services. But that's not how the documents are structured for the moment. So Bear with me. So the update stuff. This comes from sort of looking at the the the problem space of the generalized notifications and how to speed the scanners and make them more efficient. Obviously, the notify that you send to a scanner, if we get kind of service will make the scanner more efficient. But then I thought Well, sort of roundabout. If the child primary already knows, what the change is, and it could just not only notify the parent, whether it is drawer or whatever, it could actually provide the change yourself in bad That's a dynamic update. And it just has to sign the update for the parent or the registrar to be able to verify that it's authentic and it can be trusted, And that's where the problem statement comes from. We do have these synchronization issues between parents and children. We want that to go away. We want that to become completely automated And just like the the scanner does this, for the signed child case, not everyone runs scanners. This proposal has a couple of other"
  },
  {
    "startTime": "00:26:00",
    "text": "properties which make it interesting. So Speaking of scanners, Yeah. There are parts of the world where there is a scanner that actually scans stuff and finds new CDS records being published and finds new succinct records being published and does the right thing afterwards. The Swedish registry is one of those places. So we we actually do note automatically when children make changes. So We're sort of good with just generalized notifications to make the scanner slightly more efficient. But That's not true for the entire world. Are lots of places where there is no scanner. Even though the children may be signed. And there are lots of places where there is no assigned children. And there are even more places where some of the children are signed and some are not. So The generalized notifications will only help the part of the world where there is a scanner and all the children are signed. Would like to find some sort of solution for the rest of the world. So the rest of the world, is actually law rather large. We have 20 years of DNS ex deployment but, actually, we haven't managed to sign all of it. There are lots of unsigned children. A few unsigned parents also. Not necessarily in the TLS space, but other kinds of parents because There are other kinds of parents, a fair number of them. So I primarily care about these other parks, the non TLD parent parks. Not saying they are not important, but they can be solved through other means like scanners and notifications. So let's see where we can go with this. And Yes. I basically said that scanners required in a sec. And that's I have no will be action to that. I'm just stating it as a fact."
  },
  {
    "startTime": "00:28:00",
    "text": "Suggests, they do require DNSX to be able to develop things, the CDS or the Csinks that they find and not every child is signed. But they're also complicated. Scanners are a new service. We we can discuss whether they are are, a good design or not and the generalized notifications at least make them efficient, but they are still So They work, but they add complexity to the system. Could we do this without the scanner? And the answer is obviously yes. We could. Dynamic update is one such mechanism. Yeah. There is such support already in software that has been deployed for 15 years, Here's here's one example in using bind. You could define so called update policy that says a key with the name Foodot parent, for instance, can only update delegation for food or parents. So you cannot change your neighbors delegation, etcetera. You're sort of locked into only being able to deal with your own delegation stuff, that's fine. Yeah. Or let's say would at least okay. It's not inherently unsafe. You you get some rope and you can obviously tie yourself in a knot and fall on on the floor, but at least you will only tie yourself up on a knot. And no one else is always good. I I I do get some pushback on this. And not everyone thinks this is a good idea. And But I think we should still consider this a bit. And when you start considering this a bit, you realize that there's lots of prior art here. This is not the first time we see this. This is actually not a new thing at all. But for some reason, And Mark has done most of the work here. For some reason,"
  },
  {
    "startTime": "00:30:01",
    "text": "It hasn't taken off. Why is that? I mean, that's really the key question. There's no point in revisiting the same thing over and over again, unless you identify some sort of reason why it didn't catch traction the last time. I think I know why this hasn't caught on. The first reason why it hasn't caught on is because it's sort of hard to know where to send the DNS update. Across a song cut across an organizational boundary. We have oceans of DNS update. Insight to organizations. It works fine. We use it for everything. But not so much. Across organizational boundaries. Because it's hard to find to send it. And even if you knew where to send it, It's not necessarily the case that you could send it there. Because the primary of the parent is typically firewooled off and it may be hidden and it's like, like, design not meant to be reachable by random people on the public internet, like children, So We need to figure out how to know where to send it. The second assumption And I really think this is the key difference between this drop that we have now and Marks Droft 10 years ago. The second assumption is that's that's for a long time, We thought that a dynamic update has to go into the primary And if it's validated and the signature is accepted and etcetera, etcetera, etcetera. It would go straight into the soul. So the parent would have to be a dynamically updated zone. Which is clearly not acceptable in many cases. And even in some cases where it could perceivably be accepted it doesn't have a slot for, well, let's call it additional"
  },
  {
    "startTime": "00:32:03",
    "text": "policy checks and verifications, and and make sure this is really not their child. Shooting itself in the foot. Discussion, if you want me to for discussion. Yeah. Sorry to interrupt. Go ahead. No. No. That's fine. So so A very good thing with the scanners is that the scanners taught us that we can have a separate thing that makes these policy checks makes this these verifications that whatever changed it being proposed, like a child announcing a CDS. And that's look at that CDS, whether this is actually something that is saying that will not cut the child off or something. All those things can be done separately. So we do the same thing. We send the dynamic update not to The primary nature of the parent was send it to some sort of receiver service. And the receiver service is essentially the scanner, and all these policy checks and stuff. Without any actual scanner. It's just a verification part, just a check that everything is good before sending this onwards to somehow be added to the parent's own. So we obviously have there is alternatives for figuring out where to send it. I would like to sidestep this completely now and say, this is a separate issue. We spoke about this on Tuesday. It's been debated on the mailing list, and there are proposals, and I think it should be discussed separately from the update stuff. So it will just skip Yeah. This brings us to an interesting place because we do have essentially 2 types of parents. We have the parents that are essentially registries."
  },
  {
    "startTime": "00:34:03",
    "text": "In many cases, those registries have registrars and there is EPP and there are provisioning infrastructure and place of various kinds. And in many, many cases, those are signed. And then we have all the other pants. Those are the guys to date. I care about here. And For the other parents, update based design would work fine both for the assigned children and for the unsigned children, which happens to be the majority, And in the the upper leftmost corner, obviously, we already have a solution registries with outside children, well, That's an interesting problem space. I don't have a solution here now, but I think it's something that should be thought about. And I will skip this. And I will skip this. I will just say that update receiver is not a complicated piece of software. So where are we? We'll we we we have a scheme for how to know where to send downstate. Were you just reusing the same same system for announcing parent site services that were used for the generalized notifications. What whatever we come up with as the final result. And then we've essentially solved the first primary problem of of why the old suggestions in this space have failed. And then we send it to service so that we can do any kind of of verifications and safety checks and making sure that the child is not shooting itself in the foot. And then we essentially solve the second problem. So we we end up in a bachelor's based than we are today. So The the the remaining thing here is really what to do about his. How should the parent get"
  },
  {
    "startTime": "00:36:00",
    "text": "the public key to verify the signature on the update. That's obviously important. So let's ponder that. In the signed case, what the child is signed, This is Rodarice. The child does publish his key, presumably in the apex of the child's soul as a key record and parent can just look it up and validate it and and refine. You can look it up every time, or you can look up and store it in your own key store or whatever. There are solutions to this. In the unsigned case, it's slightly harder. And there's no point in beating around the bush here. There is no magic bullet. But on the other hand, it's a problem that we haven't sold for 30 years. If you look at from from another point of view, somehow every single child in the universe manages to communicate some information to the parent, to get the delegation. It may be a piece of paper. It may be a web form. It may be some stupid thing or or a local API as a organization some sort of mechanism And, obviously, we could use the same mechanism to communicate this key, but it will not work for everyone. It will work for some. And that's what we're aiming for here. So Just to summarize, I want to combine two things. One thing that we already have, which is dynamic updates, with another thing which is already a working group document, which is generalized notifications and a mechanism for locating parents' side services. Into this proposal. There's essentially nothing new here. And if the working group would like to adopt it, I would be happy. Questions? Yeah. Go ahead, Wes. Yep. I'll keep this short. West Hardaker, USC, ISI, and the ICANN board"
  },
  {
    "startTime": "00:38:00",
    "text": "definitely not speaking for the Ican board. Really like this. I I, you know, it's a mechanism when seasick and in which I'm an author of and CDS were designed. We had no ability to to do notifications for where is the registrar that you of pork. I think this solves that problem. I think you know, you indicated at the end the other problem that you didn't put on your problem space. Which is the key distribution and and authorization and authentication for all of those becoming extremely difficult, and that's why you know, we ended up doing scanning instead of something else. You solved the notification problem, but it won't help the inside people because there's still no way to you know, distribute an an auth token. If they could do that, they're probably gonna sign instead essentially, I agree with you. However, as the focus is on, let's call it, smaller parents, a university with a 100 departments or health care system or whatever. They already have mechanism for communication. And they do it manually, and it's error prone, and it has problems. They can if they so choose. Just do that once with this key and be done, and everything would be automatic in the future. So it doesn't solve the initial problem, but it could make the long term value worse it. Ed. Yeah. Louis, I can, and I have nothing to do with the boards. I'm just an org member On your third slide, you had a a example that involved TTL updates you don't have to scroll back. Okay. I just wanna say that in reg access today, that was the same example used to do an update to to EPP. So, and there was this, this is actually a, you know, provisioning problem. Yep. Second thing I wanted to say was, about 21 years ago, I did a memorable ontorio unsecuredynamic update. It was very, very memorable event. But I do and after that, I went to work for registries never in 20 years, did anyone suggest using dynamic update in actual production outside of our internal updates for"
  },
  {
    "startTime": "00:40:01",
    "text": "database. No one ever thought of that as a public facing servers, and they're won't go into reasons. We, you know, don't have time, but just to let you know, that experience said to me that operators did not want that to be an external, offered, sir. Okay. Thank you. Sorry, Troy Tale. We close the queue. Yeah. What I'm thinking is actually that, there's a great deal of complexity here, and also it seems working group is really interested. So it might make a lot of sense to go ahead and do a dedicated interim on the complexities and issues and general level of interest because that way we would have more time than we have today. Thank you, Johan. And, please continue discussing on the mailing list or on the hallway. Next to or Hoffman. Thanks. Thank you. Wanna hear my forehead? Oh, no. Hey, none of us. This is can use spoken either. This is great because it's actually one slide. Okay. Oh, here. We'll just so so we know we're talking about this is already a working group document. It's 8109bis. About, how do you initialize a resolver with priming queries? So the working group last call started in September. Some people noticed that there were questions about it, so they closed the working group called basically Working group last call got started and someone said, hey, there's still open issues in this document, why are we in working group last call? Closed it. I'm sorry. The chairs closed it. The authors put out a new draft at the beginning of sept of October working group. Last call started again about a month ago, We've heard crickets"
  },
  {
    "startTime": "00:42:02",
    "text": "actually, we haven't heard crickets And it's still in working group last call. So this is a request that people actually read the document as Suzanne said earlier, if you like things working group last call, you should say so as well. Certainly we're open to, anything where people say, we don't like parts of the document and such but it is sort of an important document to the ecosystem of the DNS namely because priming really is a hard thing. We know that there are that some people have disagreements about what you should do for re priming, we tried to cover those in the draft. I mean, we do cover those in the draft. Would really like especially implementers, of resolvers to take a look at this, but also anybody, because this is an update to something that is fairly fundamental. This is not an extension to the DNS, this is like the basis of how do you get going? So that's it for for that. Any questions Probably not because I suspect people have not read the draft, which is why they didn't comment on it. So please do comment. Yeah. That's a real simple message. Go ahead and take a look at it. Speak up. He knew Depp is being shared. Okay. Different document completely. Is about the DNS Sector Trusting Here, let me just get into this. So, this is what I'll cover here. It's still not many slides. I'll talk about the status of where it is now. I'll talk about why we are revising a document So soon after we did and then what's next? So there is already, again, call for working group a doc, adoption. Of this document started again about a month ago"
  },
  {
    "startTime": "00:44:01",
    "text": "one person indicated support. No one has opposed but the call's never completed because One person saying they're interested does not mean the work in groups should do it. On the other hand, normally you don't adopt if people say don't adopt. So please read the document I I consider it to be fairly important for these reasons. Right now, as we are talking about the trust anchors that are going to be used in the future people look to the, you know, to the original RFC, And, there's a really huge gaping technical, problem in the original RFC that wasn't noticed until later. Yes, we have the ErADA system. No, almost nobody uses it. So if for no other reason, I would say that the first bullet is is a reason to do the update. But in addition, as many of you know, the trust anchor, file is XML, We actually added we're saying that they that IANA can add things namely a public key, Right now, it's just the hash of a public key. Why not put the public here? There was a simple reference update the other thing with the XML people have said, why are there not comments in the XML saying stuff. And the answer is even though that's legal in XML. Nothing in the original RFC said that they might appear And we all know people who will parse out to Mel not using an XML parser, they'll write it in Python, they'll write it in Pearl. They'll write it in the list and they will freak out when they see So this explicitly says Look for comments. The other reason why we want this as a a working group document is that people have always had mixed views about whether Diana should publish"
  },
  {
    "startTime": "00:46:03",
    "text": "a P kicks or a CSR file and when they should do it, Iain is willing to do what the IETF wants. By the way, I'm not speaking for IANA, but I speak with IANA. They're willing to do what the IETF wants here therefore, this is, you know, it would be good for the working group to say We like these files. We don't like these files. They're redundant. Whatever. I haven't actually filled in in the document what happened in 2017. Turned into 2018. But so so these are our reasons to revise. And why are we doing this now? Because we learned a lot in 27, 2018. And we know that Diane is gonna roll the KSK in a couple years. Now again, This is rolling the RSA KSK. We're not talking about algorithm rollovers at all. Although this document will certainly deal with algorithm rollovers And just as a side note, IANA has published a plan for rolling the KSK algorithm. It's, public comments are open now. As is typical for ICANN there's a public comment period, everyone waits till the last day. And tries to, you know, like, tries to be the last one in or whatever. Please don't do that. Please do review that. That will affect this because we know that the trust anchor file Again, some people are are manually scanning the trust anchor file. They're gonna freak out when there are are a comment in there saying By the way, this is a new algorithm. So that's the last slide. How long do we have Thank you. Let's have 3, 5 minutes 3 to 5 minutes for discussion. This is possibly a really stupid question. Under a really stupid idea. Good. As you point out, people parse XML by hand Mhmm. Logic because XML parses are awful."
  },
  {
    "startTime": "00:48:01",
    "text": "Might we wanna consider having it published in something that's, say, you know, a less awful format than XML, like, JSON or Yang or anything that's not XML. We might, and that would certainly be part of this. I, I think they would not abandon XML, but there's no reason to not do it in parallel. But they would probably only do that if the working group asked. Peter. Peter Dasek. So it's like 2 or 3 said that there will be public key field, And so far, there's only the hash, and then, okay, why not the public key? Yep. Okay. Fine. But, that the hash also works. So so what's the motivation? I mean, it's extra implementation complexity. I'm Because the trust anchor file is published before the key actually is, used This is a way of preloading the the key into for example, a lot of software distributions would like to see it ahead of time. Seeing the hash doesn't tell them what the key is. Okay. So, I think it's a good idea to ensure that the hash is always there, even when the public key is there. Yep. So this would be an optional public key. The hash is already required. Okay. Good. So take a look in the document, make sure the XML matches what you expect. Okay? Okay. Ed. Ed Lewis, I can again. I just wanted to clarify the last point you had, The the IANA public comment is not about a plan to roll the KSK algorithm. Is a study to see what has to be done before we can have a plan. Just to set expectations of So if you have ideas in that get involved with that Yep. And put a plug in from that too. And Ed, Ed, or I can point you to that. So I think that's it. So chairs will, you know, again, We would like to see this adopted. Shares will figure out when when the adoption sort of ends but great. Thank you. Thank you, Paul. I think"
  },
  {
    "startTime": "00:50:00",
    "text": "chairs already shared it also on the mailing list. We think the chairs important document. So please give it a review or well, share support for adopting the document. Thanks. Up next is, Shuman. Mhmm. There you go. I wanna thank our speakers for being so careful. Audience? Because we had a little bit of a challenged with that the other day. Yes. Okay. So I'm Shimon. I'm going to give an update on the compact denial of existence strath, And, Christian is here somewhere. Do you wanna raise your head? Okay. Good. I'm not calling you a few times. Alright. So we, pushed out the latest update to the draft, at the cutoff in mid October. That's version 1, and I'm gonna running through the changes. The implementation status section. So we have added a note about Cloudflares, kind of pre standard deployment of the, the next name Type using, for now a private RR type code. And, Another thing, this is not actually in the draft. This is mainly for your knowledge NS 1 has also you if you're on the OR Dennis operations mailing list. You may have noticed that they posted, earlier this week, actually, that they are also switching to the Nx name, Sentinel type, and that will happen, I think, in a couple of weeks, Jan Kellach, who announced that he was here at earlier this week But I think he's lapsed. Right, Shane? But Shane is here. You wanna raise your hands. If you have any questions, ask that guy."
  },
  {
    "startTime": "00:52:00",
    "text": "Okay. So where, where landing is that the Consensus is We are only going to specify the n x name pseudo type. And the ENT type, which is has been out in the field. As part of, NSOne's deployment. That will be effectively retired and mentioned in the draft for historical reasons. As far as I'm aware, there is only one dissenting view in the working group that was Richard DuCovney. Who, first suggested that we, maintain the ENT type for backwards compatible backwards compatibility reasons, And I think that was a perfectly reasonable suggestion, but then later on, he went further and said, Maybe we should only have the NT type, but not the, nx name type too. So, I think the authors disagree with that. Mainly, our main compelling reason is that having only the NT type does not allow us to distinguish Annex domain responses across different implementations of online suddenly, for example, Compact denial versus traditional white lies. So that's the reason. So unless we have a barrage of people coming up to the bike arguing, for that case, we're gonna forge your head with, what I just Okay. So the next topic was, many people requested that we need to have an a set the draft that explicitly talked about what a DNS server does when it receives an explicit query or the n x name type. So, normally, we wouldn't expect any software to do this because it a meta type. But, you know, attackers or other people could do it. So we need to know. What to do. So our initial attempt was to kind of treat it like a normal query type and give it kind of a harmless response. And we tried to do that, but I I think we ran into a few problems. So It there there are basically 2, cases to consider. 1 is"
  },
  {
    "startTime": "00:54:03",
    "text": "when you get in a next name query for a name that actually exists including an empty non terminal and nothing different needs to happen in that case. The only special case is if you receive an Nx name query for a name that actually does not access. So the draft says in that case, to stick in this special Sentinel and its name, into the tight knit map of the index record. But if you do that for the annex name query itself, you create a little bit of a paradox because the handset record in the response, claimed the data of type Nx name exists, whereas the data has an empty answer section. So tested a couple of resolvers, 11 or 2 of them at least served failed. So then what will happen is is that a problem? You can say it's not a problem. I don't care if they're surfing, but some operators might because the resolvers, again, then gonna spray a bunch of queries to other authorities. Maybe you don't wanna do that. So the quick solution the immediate solution is just special case and next name and pull out this special type in that response. And that's what we've written in the draft, but now I'm reconsidering this week when I thought about it a little more. Because that creates another problem, which is potential loss of the an X domain signal, which is the very thing we were trying to repair on the craft. So an attacker could cause you to temporarily lose that signal for that non existent name. So at this point, I'm back to my original instinct when people ask this question, which is that this is a meta type which is treat it as a meta attack and just don't respond to it normally, give it an error. So I know that resolver implementations like bind and unbound they will give an error. I think it's format error, r code 1, if you get if if you give it a query for a meta type and they won't transmit very upstream. So that's where I am. I would, love to hear your opinions, on on this topic, but let's move on to the next one."
  },
  {
    "startTime": "00:56:00",
    "text": "The the the last thing we wanted to do was to figure out if there is a way to safely restore the Nx domain code point into the into the ARC code field. And that's relatively easy to do with, non DNS second able queries just step give it a normal Annex domain response. Although for the authoritative server, there is a question about whether it's really worth doing because most of modern resolvers will always send 2 equals 1 query. Queries. It doesn't matter what the downstream query are, sent it. Because by spec, if you are a DNS sec aware resolver, you have to send Dio equals one upstream because you have a population of clients behind it, so that may be validating, so maybe DNS like where you just don't know. For iterative resolvers, they could also do something, special. They can examine the Nx name signal, And then for due equals 0, clients behind them, they could just change the no error back to an n x domain. That would actually work I think Cloudflare has discussed this idea. The idea is in the draft, but I don't think anyone's implemented it, but, Christian can correct you from The trickier, situation, of course, is what to do with the NS Second Naval queries. And as I've discussed on the mailing list, in the past. As far as I'm aware, the only way we could do this by introducing special signaling. So that's what we've proposed in the draft. We, now define a new EDNS header flag called Compact Answers Okay or CO. The idea is that if a resolver sends this flag upstream to a compact denial server. They can respond with the n x name enhanced no data. Response, but set the r code to Nx domain because the resolver promised that they understand this and they won't mess up the DNS set proof. And then, of course, DDNS is a hub by hub signal, so you're gonna have to do on the downstream connections, the resolver has to"
  },
  {
    "startTime": "00:58:01",
    "text": "examine the annex name and differentially respond to clients depending on the presence of this kind of flag. So this is an excerpt from what is in the draft today. The the thing in the red That's CO. That's the new, EDNS header flag. That we've, suggested we are aware. We've talked to a few resolver implementers who are interested in implementing this. So aware that there's probably gonna be pushback from others that don't want to. Or will not read this draft. So currently, the text says it's optional, but recommended. There's no specific normative language in there. Another thing I wanna have a discussion about. And, the last thing I will end with is I asked this question last time too, and I didn't really get any feedback. But it's a topic that has come up in discussions with other people. About, you know, we recommending that this draft should be used And, what I'm saying is It isn't really a recommendation. What I'm what we're trying to do is standardized in existing deployment practice, and fix some defects in the graph. And What we could do is have an applicability statement that says for Nuance SignLink new implementations of online signing, What should they do? So we could say that if they don't have the specific requirements, for, what motivated this draft? Maybe they should not do it. Maybe they should just use white lies our traditional minimal and sex. So I'd be interested in your thoughts about that. And with that, I will stop for comments and questions. Had there was still a bike in I have a question earlier. You're talking about the explicit queries for annex name. Yep. NCAC 3 record. It you the NCAC 3 record is not a la is don't know what the right word is. It's not allowed. Just forbidden to query for NCAC 3."
  },
  {
    "startTime": "01:00:00",
    "text": "And, have you I don't know if that's a a rule that people know of. Does that come up in the sky? I just, you know, this I just thought I sent We can we can just say you're just not allowed to ask that question. Sure. Yeah. I mean, we could define it that way. We could say that this is not allowed to be queried We still have to deal with the problem of what happens if you receive this query? Well, for insect 3, the answer was you just come back. I've got it's it's in the spec somewhere. We just I I work with. If your applicability, that we've talked about this that Yeah. It is you're you're documenting things that are actually happening out there, which is a good thing to do because you wanna playing to people why they see this thing on the wire. Right? Think it's also I mean, this is work I'm doing side that I don't have completed yet, but in operations, simplicity is the way you have to go with things. Complexity is a problem for things. And you can see in in all of the things we're going here, this is a very comp a somewhat complex lot to describe. We should just keep that in mind as this goes forward. I mean, I'm not gonna say this is a bad idea to get rid rational and all that stuff. But we have to recognize that it's getting very hard. And you you see the players that are that are deploying this our major operations. For other places that may be harder to know how to do this correctly. So I just I think the applicability statement is is really a good thing to have in there saying, yeah, you do this unless you really know how much work it is to do that. Okay. Great. Thank you, Ed. Question. Cristiano Mould Clougher. Just some notes on the operational status of this. Currently deployed is supporting Nxname as mention. There's currently a change in the release pipeline to not return the Nx name for the n x name query type itself, so I will probably discuss with you, Shuman Sure. Whether to back that out we are not yes, responding correctly if we decide to go with the Ediness flag, 4 then then doing the and it's domain upgrade. But but but"
  },
  {
    "startTime": "01:02:02",
    "text": "Okay. Be fairly Okay. Thank you, Christian. So let me before you leave, let me ask a follow-up question. So you're thinking of doing this thing that's described here. And then so for for meta types, does the cloud cloud, you're you guys run a resolver to? Do you treat those especially and, like, not transmit those upstream and return an error? Do you Do you know what? You guys do. For most of them, we surface or do for For Mara. Okay. Okay. That's good to know. I was hoping that was the case. That's the thing we could settle on. The last line there the only problem with that is there's an issue in the intervening time before we get an official iona allocation because we're using private codes, And there's no distinction in that space about what what's reserved for man many times. So I think that's a bug in the INA classification of the RR type space, we should probably fix, but I don't wanna fix it as part of this trap. I'm just throwing it to the working group is something that we probably need to consider. Yeah. Yep. Next is Ben. Sorry. Ben has a question for you. Sorry. Sorry. Is also the next presenter? Yes. Ben. Hi, I should keep it quick since I'm competing with my own time. That So with this whole draft, I've always been puzzled because, I don't quite understand the motivation. It's if I understand correctly, it seems like the the minimally covering NCEC system, while it requires 2 or 3 Ensec or NCAC 3 records in the response Only one of those has any dependency on the name that's being queried. The other 2, are our our, like, wildcards or"
  },
  {
    "startTime": "01:04:01",
    "text": "basically static things related to the zone. So if you have any level of caching in your okay. You're doing online signing, but like, any reasonable implementation of online signing has a cache, but, to, like, reuse recent signatures. And if you have any level of caching, then those signatures are going to just come of a catch because they're the same for any any annex domain, any missing domain response, So that means that in my view, this this Draft does not save any CPU time in any in any reasonable implementation So I guess my, you know, first of all, is it really worth it? All this, like, incredible complexity to save basically just, you know, response size. Since it doesn't actually save CPU time. And Secondly, can we Can we update the text a little bit to clarify that and you know, you know, in terms of recommendations, be clear about what the the benefits are. Yeah. Thanks, Ben. So I so, Christian, do you wanna take that? Because you guys were the originator of this I can definitely say that any installation of the size of cloudflare will save significant CPU time because of this because you'd cannot necessarily be certain that the same metal, the same service will actually be responding to next career coming in for the same zone. So there is significant CPU savings to be to be had from that. So so, essentially, it sounds like you're saying that the that the signature caches aren't big enough to cover basically 1 or 2 responses for every domain. Because, like, you could just cash the wild card signature on every zone. That's, and then you be done. If you have millions of zones, then maybe that your cash can't be big enough. Both screen."
  },
  {
    "startTime": "01:06:03",
    "text": "So Christian, I think there's also the, and Ben, this is there's also the packet size argument, right? So you are using size of the packet. I don't know how big of a concern that is, but That was what Yeah. I I just I just didn't, bring that up since it's been already mentioned the decisive. Yep. Thank you. Okay. Thank you. So Sure. She ain't be closed the queue, for questions. So, thank you, Shuman. And, follow-up discussions on the mailing list. I didn't have a question. I did have an additional answer, but I can because, well, so we don't end up to generate answers that aren't the same, so there's no cache Okay. Thank you. Thanks. Yep. Yeah. We're running a bit late. It's our fault. 5 minutes. So I try to be keep the the presentations in, and the discussions in time. Next is, Ben. With with SPC bid then Here we go. You want to run the slides? I will run the slides. Yep. You can request, then I can ended up to you. I did. Oh, yeah. Yeah. I saw you in the queue, but this is even even even Yep. There you go. Okay. Great. Hi, everybody. So this is a working group document called using service findings within, oops, the DNS director requested a change to the title. It's now called something like using Dane with service bindings and quick. So just as a reminder, Dane is the thing where you have TLSA records and they're signed with DNS sec. That's are 7671 and 72 is Dane with MX record 7 free is Dane with SRV records because every time you have a different kind of in direction where you're going through extra hops in the DNS you need some explanation of how that interacts with Dane"
  },
  {
    "startTime": "01:08:00",
    "text": "basically, what where do I look for the TLSA records? And so this draft is just following up in that chain for the service bindings records. So here's your basic Dane situation. Although this there's, something slightly strange about this example, but never mind. The so you have your owner name for an address record and then you have some prefixes that go onto it to to get the TLSA record. And here's what this draft says and has said for I think from from dash 00 which is if you have a service bindings record like an HTTPS record in example. Then the TLSA records go essentially on the final transport endpoints. That go alongside the address records or in formal terms, the TLSA based domain is, the final service bindings target name. This is exactly the same as what 7673 says for SRB. So we're just replicating the SRB pattern here. There are some changes in this revision One of them is a a recommendation, based on feedback from Victor Duchovny, to not rely on Dane's pretty weird cname behavior, which maybe we should just get rid of entirely, but it seems like a kind of invasive general Dane thing to do in this draft, which this draft is supposed to be pretty narrowly focused on just using name with service bindings. A bunch of other minor terminology tweaks there's one big new thing in here, which is discussion of unknown key share attack. I wanna talk about that. So there's this individual draft from a while back and that describes unknown key share attacks and basically, argues that Dane is"
  },
  {
    "startTime": "01:10:01",
    "text": "unsafe with HTTP. And and re and, like, recommends okay. This is just an individual draft, but it recommends a bunch restrictions on the way that Dane is used. And if you if you took those to heart, that would really impair the way I think about this draft being used. And so I went and and tried to think very carefully about that attack and basically concluded that modern HTTP is actually not vulnerable to it. And so We are okay. But there is a recommendation in this draft not to use ancient versions of HTTP with Dane. So, I think the technical content here is stable and we're ready for working group call, but I wanna note one more thing, which is that these the this these slides, were made a week ago, which means they predate the, the flurry of activity around the Deleg record I think a lot of people might look at this draft and think, like, you know, you know, does anybody really use Dane? Like, why are you even bothering to put all this work into specifying the way Dane interacts with service bindings. What's the use case here? And, for me, although the draft is is specified in a fully general way that real motivating use case has been this kind of authoritative encrypted DNS, the the a dot or authenticated a dot use case. And that is also very much tied up in the know, that's pretty much closely related to the Delek discussion, which also adopts service bindings and also is trying to achieve the the same end. So if you're interested in the Delek conversation. If you're interested, in authenticating a.setup I would encourage you to take a look at this draft and think about whether it's"
  },
  {
    "startTime": "01:12:00",
    "text": "suitable for that use case. I believe it is, but we designed it. Basically to work for that use case. Thank you, Ben. Any questions? In the queue, Nope. Okay. So please read documents, the chair, I also think it's ready for, almost ready for working group school, So please give feedback to Ben's draft. On a mailing list. And We'll take well, we'll get in contact with you, Ben, to plan a working group last call somewhere after the IETF and then scale it in well, well, mostly, Timin, Suzanne and I will kind of plan a number of working group calls, So they don't overlap, but make some progress in great. Yep. Okay. Thank you. Next is, Philip. Yep. Hi. My name is I worked for an enalnetlapse, this is a relatively small ID, but I think it's worth, documenting. So that's why I'm here. Basic ideas that's, you serve, DNS using some kind of, any cast network you would like to have a note somewhere far away in a remote corner. And for whatever reasons, you expect a little bit of traffic but for example, your zone can be fairly large. So then you have a lot of overhead keeping your sound up to date. For a little bit of traffic or on your server, you have a huge number of zones, Some of them may be locally,"
  },
  {
    "startTime": "01:14:03",
    "text": "relevant, but many of them are not and you would have to serve all of those zones. So The goal is, can we have some sort of specification that says, well, and any cost note, which should act like secondary can actually be a proxy. And then, you can solve those problems because basically you're having a cash and you don't have to so you can do a few basic things like you will probably want to clear the ID bit to avoid, forwarding loops biggest change probably compared to you would normally do in a cash is that you want to serve the original TTL. Because you want it to look like a secondary and not have just weird TTS that very confused. If you do that, then you need to redefine a different cash replacement strategy because you basically don't want for CTLs to expire. You want to have something that looks like a secondary, so it took probably do what secondaries do and let this look at, time outs in the soil, look at notifies, there's also some other time out mechanism. And then when you become aware of a new, so a version that you should basically the cash. And then, get your data. Costs in the current DNS, there's no way really knowing what changed though can see a rear view but the code really far, you can feel also maybe but you probably don't want to do IXFR and stuff like that because that might be too expensive. And then if if you want to be more advanced and then you could say, well, dropping a cash may get a huge traffic spike. So then it's possible that you want to sort of preload new entry for for your your hot cash items, before you discard. And all parts of the guess"
  },
  {
    "startTime": "01:16:06",
    "text": "There's some other things you can do. Of course, you can do aggressive negative cashing, I have no clue if there are any cost deployments that actually do something, with the, eDNS client that option. If they do, then, of course, that also creates quite a bit of complexity. So that's basically it for me. Wrote down, some ideas in a draft, put, the source on GitHub So if people are interested in that then then then It's worth continue working on it. Thank you. Ed. Hey, Ed, Louis. I can. When I read this, this this sounds like lazy evaluation of zone transfer. Yeah. Yeah. That's what what you're doing. And the question I had was, like, how what how do you predict what parts the zone transfer you actually wanna get? Are you just responding to what I'm being asked for, and then I'll just maintain keeping bit getting that. Oh, I wanna that up to date, SOA wise. I mean, because once in the authoritative server, we you refresh from the the source based on the S Way timers if you're not doing some other artist or whatever, I think. So I I was I was the question I had. How do you how does the this this remote authoritative server know what part of the zone it actually wants to keep Is it predict that, or is it just reaction to what it's getting queries for? That that's That's the thing I was wondering about the use case because I can I've seen it. We've had where I can pass lies, servers on very thin T1s. Big zone and but but expert worked. To keep the update if you lost it. It was, you know, I understand that that has a problem case. But I'm just curious how you wanna predict what parts of the zone you kinda want a lazy eval. It at his own transfer sense. Well, my current plan of thinking is not do anything special. So the assumption is that connectivity"
  },
  {
    "startTime": "01:18:01",
    "text": "is good enough that for the few queries you get, you just ask one of the full secondaries for the answer, and then you serve it locally. Of course, this can be extended. That if people say, well, we have really sort of bad network connections and we want to prefetch stuff and stuff like that. Yeah. That's probably, a separate issue them, yeah, with that, with the, this whole Thank you. Stay on I like this, idea. We all, at times, idea, we also, thought about it And, if possible, I would like to help you with this draft. Thank you for presenting. Okay. Thanks. Thanks. Peter. Hey, Peter Dsick. Just wanna observe that to me, that sounds like a resolver with certain restricted functionality, like, no TTL discounting and it essentially only talks to one upstream doesn't do full resolution. So, It might have had phrasing it in these terms in the document or an implementation. Yeah. Oh, with certainly in the context of off when you say a resolver immediately think of a recovery solver and then it becomes very confusing. So so this pig had only 4 weeks to whatever co figures secondary of the server supplies the real answer. It doesn't do anything else, So, so, technically, it's it's a resolver, but I think from a monology Whitefield might get confused. Thank you. Johan? I thought I thought I was in the queue somewhere. So so I like this, and I I discussed this with with and then that allows before. But to go to, to Ed's question here about what I what part of life or it's for our to optimize for. My my answer is that for for"
  },
  {
    "startTime": "01:20:02",
    "text": "for many zones, especially large zones, you actually will never ever. Kevmer. Ever. Use most of the sullen at a particular place somewhere in the world. So It's not a question of optimizing the DX so far so much as not ever ever ever, ever moving those 90% of the zone over to that faraway place that will never ever use it. M, And that that's the That's the background for for something like this to be useful. And I think it would be extremely useful as more and more of the world uses any cost all over the place with zones that actually don't get queries all over. Place better. But there's Patrick, see I'm aware of at least one theory which is doing this today, and it's just byte, service over configured with limited number of zones. And proxy in front, we just flips the RDB. So the idea is kind of something a sense that it is done today for weird reasons, but yeah, people want it. So maybe it's worth describing how to do it properly instead of know, everyone hacking it together in slightly wrong way. Okay. Okay. Peter, final, Yeah. Thank you, Peter. So this this idea pops up over and over again, and has interesting use cases on a happy path. From the terminology side or from the abstract side, what you present is is an authoritative, which just has a very long line to the database. So I'm wondering why you would want to standardize on that. It's just a a special case what I think would be helpful is to document the operational considerations. The trade off between the benign traffic"
  },
  {
    "startTime": "01:22:03",
    "text": "that is expected versus the transfer of the whole zone is, of course, obvious. The other one is how does this behave under Hidos or under an attack that tries to exhaust this and enumerate the zone for example, which makes this approach much, much less, attractive, actually. And that's I would like to see documented because that's the the operational part. And it's the NS op after all. Thanks. So, basically, you say you should be some text about how to respond to denial of service attack or what to expect but I did have searched that tech happens and you have something like this deployed. Well, the the the DDoS doesn't have to be a a traffic is exhaust or volume exhaustion, it could just be somebody enumerating the zone incidentally or intentionally, which makes this whole setup a bit questionable. If you can preclude that, that's fine, but that's exactly the discussion that might be held full in in that case. And again, protocol wise, this is an authoritative that has a long line to the database. Thank you. Thank you. Next step is libar. With presentation forward. Yeah. We're good in time. Hi. I'm from. I will not be talking about solving fundamental problems of the DNS, but Yeah. Just a tiny missing piece that I believe is Hey. Deserves to be filled in in standardization. Let me start with RFC 8427 which defines the JSON format of DNS records and DNS messages. I guess this, miss RFC does an excellent job of defining"
  },
  {
    "startTime": "01:24:01",
    "text": "The the JSON format, not only, like, for for example, alternative format of zone files, but mostly as an out format for utilities like Dick which can be done used by server scripts that easily pass the format. If it's Jason, So I like this out of sea. But it's interesting that this RFC has never been adopted by Mister Kuman has now been adopted by the NSOP and it was actually promoted an individual submission by Paul Hoffman. Thank you all for that. And therefore, it's an information on the command despite its clearly in normative nature. I also find some tiny inaccuracy, but which must attempt it to be fixed by Erata, but, unfortunately, not in the matter, biggest missing points I found is that the definition of the JSON format for ED and a pseudo record. Is not at all defined by this document. So when I was myself, implementing this for, okay, the utility. I tried to inspire myself by Dick. So I tried what Dick does when, when asked for Jason format, and I found surprisingly that There is no mention of the EDA cell record at all even if it's included in the packet. So I shared this surprising finding with the world, and there was pictures per check around who encouraged anyone to just, yeah, take the take the effort and write the specification of the JSON format specifically for EDNS and also the standardized texture for math for a DNS option because CSD authorities like dick or k dick or whatever. Do display the contents of the DNS but they do it like in an unstandard"
  },
  {
    "startTime": "01:26:00",
    "text": "weird way. For example, they also mixes up a separate in different fields by commas at one time and by Semicon and other time, So this also deserve some attention So I decided to volunteer and take the efforts to to write some use use of a specification of those formats both for ADNS. And Peter Patrick also told me that it would be I agree that it would be desirable that this format is really human readable. It's mostly intended for human eyes. So it would be a really great if, that that that that that example, text human mnemonics are used instead of so numbers. And if the structure of the 4 follows the semantic, semantic sub DNS option that added it, for example, their binaries in tax. So I, like, wrote down the requirements that I could have and it's, actually showed up there is, not much maneuvering space for my own creativity to define the format simply the requirements requires that the format looks like it's looks now. At first, for example, in the in the Presentation for Matt for the DNS I've tried to inspire myself by by a VCB presentation format, but in the end, it was it actually showed us better to to mimic the current texture output of the so that it's similar to to what exists now. So I I bring this specification to the NSUP and I did not get too much of feedback. The feedback I got was, really excellent. Thank you Peter and Ben for your emails. And so This This draft has evolved to this version 2. And the news is there is also an implementation in KDP c point, 3.2."
  },
  {
    "startTime": "01:28:01",
    "text": "There is an implementation that, follows this, this specification, both in EDNS Jason for Matt and, EDNS presentation for Matt if he was there right now. And, yeah, I would like to get a feedback from anyone in the episode because it was useful so far, I would like to So here, if the actual users of those utilities are interested in it because they might be the consumers of the of the outputs And I would really like to see Dick implement at least the adjacent part of the specification because I think that the EDNS record is serial missing in the JSON Optotic And in general, for this document, I I would like to that it's a and finds the right structure, IETF, if it if it's desirous to be adopted and promoted by. So that would be a good good way. If it's desired to be informational, I can submitted information at the like you do, if you see in the beginning, So I welcome any questions here, or and a email. Thank you. Thank you, Leroy. First of all, So to answer your question of why it was informational and not in DNS, saw, I asked if this should be in d DNSoft and people said, This isn't a specification for anything that we need it's also very optional in the sense that the original RFC has 2 or 3 ways of showing lots of different stuff. It doesn't say you must do it this way because some people wanted things in the binary format. Some people wanted it expanded as text. I think you're gonna hit the same thing here. I think it's fine for this to be informational. I don't think it needs to be in the working group."
  },
  {
    "startTime": "01:30:01",
    "text": "As an informational document, although could be in the working group, there's no reason for it to be one way or another. But it should be informational and I don't I've gotten very little feedback in the past on the on my JSON format. People said, oh, yeah. And then they always say, why didn't you tell me exactly which one to use? And I would say because I would guess wrong, which is exactly what you're gonna have here. Especially with EDNS because people don't even think of EDNS as much as they do the main format Don't know if it's not in the working group, you can certainly go to Warren and ask to be 80 sponsored. People will review it. I suspect it's just fine as is. Thank you. But I see again I will add that the original motivation for standardizing EDNS presentation format was a test DNS software because we wanted to have people creating weird things in DNS and make a format which can be reused between different implementation That was the very urgent implementation, idea. I dropped the ball. Thank you, labor, for taking it on and good luck. Thank you. Jim Nate's, I'll give a shameless plug for the DNS directorate So if you're just wanting to have a review of the documents, Perhaps the working group gs here could chat without giving over the DNS director, you at least you'll get a review of the document as a result of that, as to how you then negotiate it through to get its standards, think the suggestion that was talked to before about an AD sponsored document might be the path forward. I don't think you need to bring this to the working group. Thanks. Thank you, Greg. Smaster Greg George, also ISC, but in support. So, trying to convince customers to use big rather than earnest lookup. As a full time job. And"
  },
  {
    "startTime": "01:32:00",
    "text": "if there were a much more there were a much better way for them for them to understand into their heads, what it is that they're looking at, that would be good. So I'm all for this. Okay. You very much. Thank you, Liber. Thank you all for your questions. Next, BOMOCA. And there we go. Thank you, Tyler. Yeah. Yep. Yep. Yep. Don't need it. No. You may use, whatever you like. Hello. Hello. I'm Momoca, and Oh, okay. I'm gonna just take this. So obviously, 3901bis. So, I'm fairly new to the IETF. This is my 4th IETF. And so you might be wondering why am I running this draft. The answer is because I want a working ipv6 only resolver. And, I saw this overseas that had the wood IPV 6 and DNS DNS on it. But it was from 19 years ago. It was written in 2004. And in the last 19 years, 20 years, the adoption of ipv6 has grown, and maybe it's time for an update. I'm here to ask the group. If they agree or not. So, this nice graph is made by my co author Tobias. You can see, this is how many Now, the number of zones that can be resolved by an ipv6 only resulted in how many need ipv4 connectivity. So you can see for TLDs, you can resolve it by only ipv6 resolvers. And even for,"
  },
  {
    "startTime": "01:34:01",
    "text": "top 1,000,000. It's, like, still, like, 70% ish So it's not like all of it, but it's growing and growing you by year. So, We'll get we'll get into it. So, what do I wanna change in the text? In this job. So I have 3 main points that I want to change First, guidelines for DNS zone configuration. Currently, and, obviously, 3901, it says every DNS zone should be served by at least one IPV for reachable, a third of name server. So, and I think maybe it should be changed for at least one ipv4 reachable 13 names of it and at least one ipv6 switch both of it and then so that The second thing I wanna change is, the recursive result of this side, the current text says should for either ipv4 only your trial stack But, even though I said, all 30 name servers should be 12 sec, that doesn't mean all our third and name servers will follow that. And you might need ipv4 connectivity, or you might need ipv6 connectivity. So the PISCO in practice is you should have both ipv4 and ipv6 connectivity to resolve all zones. Lastly, I think in addition to the text of an example of misconfiguration that can lead to ipv6 only. Because the resolve is failing should be added to the text. So I think, there's already I don't know, but there's a text that speaks about how misconfigurations can happen for resolve result for resolving to Dale But, There's a lot of misconfigurations only for specific specific to ipv6. And they've been kept unnoticed because"
  },
  {
    "startTime": "01:36:02",
    "text": "IPV 4 works. So if it can be resolved in ipv4, nobody has thought of changing it and fixing it. So I think an addition about how misconfigurations can happen for specific IP address. And lastly, I don't No. I don't like this isn't a strong opinion, but maybe we should ask IANA because they do a testing for, TLD Name Service, and we may add them to add a connectivity check for both IPV 4 and ipV 6. So, my question is should we adopt or not adopt and so I've sent an email to V Six ops. Yes, Day, and Jeff Houston, are you seeing on the queue? You gave nice, concern about ipv6 and dnssec and long pack sizes and I see your concern. So, Also, if the people, if you haven't seen that thread, it was that V Six ops, not this, list. So I've sent the link to the V Six ops. Good to this DNS ops that mailing list. So if you haven't seen it, you can see it on the list. So, yeah, Jeff Houston. Thank you. Jeff, Jeff Houston, look, much as I don't want to sound like a heritage in the, heretic in the church of V Six, I'm a heretic. I am a non believer. And the reason why, particularly with application into the DNS is that one of the one of the few things V Six changed was the treatment of packet fragmentation."
  },
  {
    "startTime": "01:38:01",
    "text": "Now the DNS doesn't handle only 512 bite or smaller responses. With things like DNS in in particular, we're dealing with much, much larger packet. And and this has been a problem. Now in V Four for a long time, we simply went are well. Let's just do forward fragmentation. I mean, it all gets too hard. And you actually set the buffer size truncation bit and fail over to TCP. In these six, the likelihood of that packet simply getting lost is very, very high because the combination of large packets, and V6 and its fragmentation behavior and reliance on ICMP and the DNS is a remarkably poor fit. So Joao and I decided that this is not just opinion space we should measure. And we stated mass measurements across the DNS and found that when you actually do Large response behaviors over V Six. The fact you're right, goes rocketing. Now this has a number of impacts. It takes longer to get the answer. Because the poor old client that's wanting an answer and has to fraud through all the other servers to actually find one where it can get an answer, typically, on B Four. Or if it's going to do a truncation and a retry over TCP, make sure you gotta do a time out And the timers in the DNS set client software, a much, much longer than TCP round trip timer. So by saying we should do v 6. You're kind of saying, I hate users. I wanna make their experience crappier. I wanna put more load on the DNS I wanna make it go slower I don't think it's foolhardy to say we should do V Six. I think it's completely irresponsible. As engineers, trying to mandate a behavior to which we have observed and measured to work poorly is not a good idea."
  },
  {
    "startTime": "01:40:00",
    "text": "Now What do we do about this is kind of the next question? Maybe we all do DNS flag date. Maybe we all go and change this and do the truncation bit. That's still one round, in fact, 2 round trip time penalties. One to get the truncated bid and 2 then just bring up the PCP session. There's no good answers to this problem right now. Nah. And to say that we should do it, we don't have a just strikes me as crazy. Thank you. Eric? Eric, can I Eric Nagran Akamai? Thanks. Thank you for doing this. I think it's long overdue that we've we we do this. I think There might, like, Jeff has some concerns that we should work through, but there's also a lot of of of of authoratives that are dual stacked at this point and a lot of recursives that are dual stacks. I think we're better off going through and finding some that they behavior and recommending it in defining how to kind of work around some of the issues and documenting them, then I've been in guarding it at this point. Thank you. Wiz at West Hertica USC ISI and the ICANN board still not speaking for the ICANN board. Thank you for bringing this work. And I, I'm, I'm super happy that you're new to the IETF and bringing a draft that's, completely awesome. And I am strong support of this. I think that we do need to you know, require things that happen. There are use cases where, Just concerns are completely valid, but there are also use cases where they are not the right way to to go forward is to fix the problem. And Jeff's right. There's hard problems and we need to fix them and we're not doing But that doesn't mean that we shouldn't be driving forward. So thank you. Recreate Thanks. Ralph. That's the lack of my I'm also very supportive of this. And incidentally, I've also did,"
  },
  {
    "startTime": "01:42:00",
    "text": "a a presentation on work a couple of years ago where I sort of had a similar question. Is the DNS V Six ready? And found where it was not V Six ready, and I'm thinking that we are getting people that are not yet released already. More to doing stuff so that the concerned that Jeff had will get lower over time. And the other thing to keep in mind is that new networks that come on to the internet often the V Six pass is much faster than the V Four pass because of CGNET and all the other share banks that have to nobody gets before address anymore. So thank you for bringing that Okay. Final Tobias. So to PLC, a co author of the draft. I do hear the arguments about especially MTU being an issue for the DNS. However, a, we did have our DNS flight day settings and message styles to, 13 Sorry. 1232, I remember correctly. And, I think that MTU issues do not only affect DNS. It's basically a huge problem across all protocol families, especially with your RFPF running into a lot of issues. And I think even though I Here, the arguments against change. I personally feel like the same arguments could have been made against the introduction of something new and fancy called IP, IP, and the discontinuation of walls. Was done on teams before. Okay. Thank you. Andy. For a short question. So, we've been looking at the issues the post-one relevant. So, polls for DNS and DNS sec. And, I'm I'm kinda supportive of that Jeff does this research, and I feel that, is a good example of how,"
  },
  {
    "startTime": "01:44:01",
    "text": "the research should influence the standards activities. And, I just take, Yeah. Sometimes we can make decisions that could have huge impact, So it's not really a question. It's a common Thank you. Thank you, Mervaka. Next is called So so to be clear, follow-up discussions on the mailing list and also the question. It's either DNS op or ipv6 should be the home Thank you. K. Thank you, Benno. Thank you, Suzanne. Scott Hollandbeck here. Mostly regex work here. I'm here because there are some issues associated with delegation titles there, you can find it in the usual place. Next slide, please. Okay. Sure. Yeah. Thank you. So the goal of this particular draft is to mitigate some risks of domain name hijacking that have been observed in the wild based on some domain registrar practices for managing what an EPP are known as host and domain objects. A these objects ultimately produce delegation actions in zones. And right now, the EPP PRFCs have some text in there that basically says If you're going to delete a hosted domain object for which there are active delegations Don't just do that blindly. Right? And orphan, all of these delegations. There's some text that suggests that you try to clean up the delegations first. Unfortunately, because of the way, host object architected in the way the DNS works, you can get situations where you've got 2 different"
  },
  {
    "startTime": "01:46:02",
    "text": "domain name registrars, you know, acting as EPP clients, where one creates this host object and has administrative authority over it but a second registrar uses that to define a delegation. Right? And so when registrar number 1 attempts to delete that, host object, for example, delegation that registrar number 2 has created. So what we're trying to do in this draft is first off describe the problem describe what we have seen in the wild as practices for managing, the situation and mitigating the risk. And hopefully define some best practices based on community consensus. So I've already covered the problem a little bit. We'll skip past this. We're currently looking at version 1 of this draft. There is version 0 0 that was produced around the time of IETF117 the big delta with 01 is that We have changed the, Organization of the draft instead of describing what we thought were best practices, we've tried to describe the the known practices. And describing some benefits and detriments to the existing approaches And right now, the best practice section is basically a big TBD. We haven't made any objective observations about what we think is best ultimately, that's where I need some help here. So as I said, I'm at a a point where I'm looking for help. And I'm here because the issue has both delegation management And EPP delete processing aspects. I realized this is probably more of a regex thing. But I, you know, I need DNS op input. And so when I say which is a better home than the other, I'm really talking about the cushion, Right? And I and it's gonna be kinda hard to have discussion on 2 mailing lists. Maybe that's the right thing to do. I don't And as I said a moment ago, what we need help with is identifying what we think these best practices really are. Maybe."
  },
  {
    "startTime": "01:48:01",
    "text": "From a DNS sense, if everyone is okay with the idea of simply deleting domain names, you know, deleting zones or deleting you know, glue records and letting the chips fall where they may. Fine. But we'll we'll say that. Think that's the case, but if that's what we think our best practice is, we'll say that. And as I said, if any help that can be provided, you know, from the DNS South Working Group DNS directorate, we're looking for it. It's it's it's some sense of consensus around what those best practices are. And frankly, I don't wanna hear myself talking for the next 6 minutes. I look I'd like to get some discussion, some feedback from you folks. So that's my last slide. Thank you, Scott. We have 4 in the queue. And thank you for reaching out to the Dineshope. Yeah. Yeah. I propose that you set up a new mailing list. I fully agree that there's no way to have this discussion on 2 mailing lists at once. I strongly believe a lot of people in this room, don't follow red checks. They don't understand the tone of house. Sometimes it's deep in the weeds of EPP stuff and other times it's high level like this about what's a best practice. I think a mailing list that is announced on both an IETF mailing list that's announced on both It also could be long term because I think what's gonna happen is it's not just for this draft. It's gonna be other best practices about how do we maintain things that have died? You know, no one no one in almost any of the cultures in this room care about, you know, or want to think about dead things. GNS is very susceptible to dead things. And and and and At least I can. I was thinking about this. From the DNIS point of view, it gets protocol point of view that this room deals with. In the DNS, we're dealing with the fact that the DNS doesn't really recognize the operator. When you when you delegate your deli into name servers, you don't know who's actually operating in this case, it's not operator, but it's registrar."
  },
  {
    "startTime": "01:50:03",
    "text": "And it the analogy here is that these are both the operators and and registers are the kinda like the meta that the behind the scenes thing going on here. When it gets into the DNS protocol itself, the protocol today doesn't really CE to any of them. So I don't It's a tough road for, I guess, for this relate to a DNS protocol issue, but I'm not I'm not just kinda pointing out from the discussion, of that. Although we do have work to bring in a DS operators into DNS protocol, but Still, the provisioning side is really not necessarily It's hard to map those 2. I'm familiar with both, but they don't really impact each other in a way that's pretty obvious how you how the DS off would fix this. But I understand the problem. I just wanna point that out. I don't have Peter? Peter Tiesick. So the root of the problem seems to me that when things expire, then the databases It's a it's a registry and various registries make it inconsistent. I think the best thing we could do is get as close as possible into something that's consistent instead of working around with, a s 112 and other kinds of things. So so my preference would be to delete things that are dead. It doesn't mean that the register loses the domain. They can still keep the registration. But if their name server is dead, it's dead, and there's no no point I think in keeping the record around and waiting and understand it's it's multiparty problem and difficult with a very disadvantageous changing all of that. But I think Getting as close as possible to that would be the best solution. Thank you. You? He's now Yeah. Warren, your last. So, I mean, I don't really know where it lives. I thought there was reject, and also thank you for writing like, I encourage you to write it because it's an act of problem. You know, maybe the idea is we have an another mailing list if we need that happy to sponsor it. What I would really ask is this is an ongoing problem, and there's been a bunch of papers like, showing that it's a problem and it's being actively exploited"
  },
  {
    "startTime": "01:52:00",
    "text": "like people register names that registry, sorry, registrar's, like, delegate this to But they hook up the risky business document. So I'd like us to please work on this and work on it quickly quickly, So, you know, don't care where, don't care how, let's just get make sure it moves along so we can fix the problem know, you know, get back to real Yep. Yep. Warren, and I should note that there's also an active SAC working group looking at this. So, yeah, to to your point, Warren, one of the things I wanna do is, you know, get some notion of what these best practices as are and try to get the document finished as quickly as possible. Yeah. KC Kaffee and somebody. I can't remember his name wrote a really good document on this. Think of the paper is called risky business, BBA said NESS. Gautamatawaki. He's now a co author of the draft. Right. Thank you. You, Scott. So final presentation by Martina, We're running 3, 4, 5 minutes late. So please, stay with us. Here we go. Yeah. And I tried to, summarize 2 drafts I am currently working on within 2 other working groups in under 10 minutes probably. So Bear with me if I talk a little bit fast and maybe skip some slides I don't want to get into your lunch break. So I'm talking about DNS and train networks. Namely, there is a transfer protocol for that DNS of a co op and a message format for this based on Seabor. And, our motivation is basically that we want to encrypt DMS messages for IoT devices, and The problem is that we don't talk about IoT devices such as voice assistance, switches or even the, raspberry pi, but constraint notes that only have a few kilobytes of RAM and rom And we don't communicate via Wi Fi. We communicate via constraint networks."
  },
  {
    "startTime": "01:54:01",
    "text": "Which are characterized by low throughput, high packet loss, and asymmetric link characteristics, and they have a high penalty on large packets. This can be seen in this table. I want to note, the right column for lower bound where we have a frame size of, oh, sometimes only 5 59 bytes and a very low data rate. So we want to avoid fragmentation as much as possible. The possible solution for encrypting DNS are currently DNS DNS, DNS over TLS, DNS of a quick MDNS over detail. The problem with the first 2 is that they run over TCP, which conflicts with our resource constraints, the other STNS over quick, which and DNS over details has a problem that we have no segmentation in it. So we we we can't, for, get it small enough for a constrained link. So our proposal is to use DNS over co op where we haven't tripped communication using either DTS or OSCO, which is us the object security. So think of PGP over the over, No. No. PGP. PGP. Sorry. Over over the wire. And, block wise message trends for which basically provides a Swiss message segmentation and also also recovery, and we also are able to share system risk resources list. If you have already a cohort application present, So this basically explains why we use the fetch match set in core by just skips this quickly, if you want to know, just recent draft. And this basically is an evaluation of how the memory consumption of implementation that uses UDP as a transport works And we see, if an COAP application is already present, on the right side that at least for Rome, we have a clear advantage when using Oscar, over the other encrypted protocols. Have that summarizes this as well."
  },
  {
    "startTime": "01:56:02",
    "text": "Exactly. And when we now look at namesizes, we see that there are similarities with typical Ixp, names in the IoT, this is based on a consumer base, consumer device, dataset. But we have longer names, in the IoT, actually. And this is because we have, these devices typically communicate with cloud services and CDNs, which use names such as this, And if we just look at the smallest one and Yes. We introduce some new headers, but this, are not the smallest headers that we can see, but typical ones. Let's say that even for this, small name, the DNS name is for the DNS message is already too long. Exactly one byte. So we get fragmentation in link layers such as 802154 So Remember, high penalty on link layer fragmentation. So We also need some kind of concise DNS message format to get this done. And this is why we introduce the application DNS placebo media type and content format. Which means you can use it with both stock. And if you are in some crappy open I hotel. Wi Fi, you can also use it with your age if you want to. And if you want to have more information how that would work, you can read our draft. So just to give it a small overview on what happened in the other working groups, the DNS over co op, graph was first presented at IT F 113 in Vienna. The work there is mostly done. We are just waiting for some more implementation. There's some, ongoing discussion still about bootstrapping dock with service fee records. The problem there is set for the AOPN ID, there's is nothing defined for COAP over DTS yet. And"
  },
  {
    "startTime": "01:58:00",
    "text": "for a talk that's completely it's completely unspecified However, there is large interest in service fee records in the in the code working group in general. Because, for example, we want to also, reduce the numb growing number of these UIs that in the format of core plus Top. Top. So we are planning to publish a problem statement on that that then will be referenced on by the draft. And regarding CBOR, this was first presented in, London, in at IETF 115. So, there the discussion currently is about name compression. It's not a problem that we can't compress names. More that we have with Cboe pack multiple methods to compress against just deciding on how. Then the last question that we had is If you want to allow for more than one question in the message format count, we we don't, but as we saw in one slide already before, there is now some, necessity for that. So Yep. So, in conclusion, DNS of a co op is needed because our, the, UDP conflicts with our privacy constraints, the other performance conflict with our resource constraints. It is on par with existing UDP based, transfer protocol in, but has an advantage in packet size and memory consumption compared other encrypted transfer protocols. And we also introduced a single based message format to avoid expensive fragmentation. And also, there are 2 reference implementations of each. So both, transfer protocol and submit a message format in Python and for the embedded operating system. Right? So and what has a question? Thank you, and thank you also for the well, high speed presentation, Excellent. Thanks. Edward. It was it was again. So I read this quickly, and I'm trying to remember the draft, but it"
  },
  {
    "startTime": "02:00:01",
    "text": "something struck me in a in a was that you assumed that in the responses the domain name owners would be could be, like, one owner of of all the and I thought right away, well, DNS sec blows that away. That kinda opened up the whole question in my mind is Are is this Are these devices thought to be doing their own resolution where they're gonna hunt from the root server down to the answer. Or are they gonna lean on a recursive server that's kinda dedicated to COAC as a transit. That's my first question. It's more, leaning on the doc server as with the DNS of a co op server to, do some processing of the messages beforehand. And regarding, for example, DNS sec when not sure if this makes sense to sentences over such a constraint domain. And if we have Oscar or detail as we basically also already have the authenticity of the messages somewhat uh-uh confirmed. So Yes. So so if you if you're going to a trusted recursive server working on your behalf, Yep. Yep. Then the security becomes more of a channel security than data security. To some sense. I mean, on one hand, when you see now the data is transferring hands. Basically, I'm taking out of one train that can't the station reporting to something else. You might at the end, vice may still wanna validate that that was from the source. That's where DS secretary becomes you know, maybe a positive to the end thing unless you really trust that device on your behalf. The other the other reason why I I know this could be a bigger discussion, but The other part of this was, Dylan record. Talk is going on there. The Delek record might be really huge. And its intent is to help you get from this kind of DNS to that kind of DNS. And it's necessary to do that. But That would go the wrong direction for this unless it's saying we're gonna go to the DNS to help co op devices, but you're gonna take you're gonna then report all the data back into co app. Like, a multistep process. So this is where I I think this this"
  },
  {
    "startTime": "02:02:00",
    "text": "case should be looked at by the Delek folks to say, wanna make sure we accommodate this and also understand we accommodate what's needed here. Like, it's just like, basically, like, a a a sub resolver relationship, not a necessary resolver to authority relationship, I believe. So no. No. Thank you. Next. Ben remote. Hi. So thanks. Thanks for bringing this to DNS up. I I think it's really great to get the review here. I, think that the DNS over coapp side is looking good. And I'm definitely more concerned about the DNS seabor sign. You know, this is a lot like defining a JSON representation for DNS in fact, I think it actually may define a d, implicitly JSON representation for DNS. And, as you may have just heard, the last time somebody tried that, it couldn't couldn't get through DNS app and ultimately went through independent stream. So think it's, It's an interesting challenge. I think it's gonna be really helpful to be very precise about the targeted use case and and you know, and the level of generality. You for your fee. Excuse me. You for the feedback, Ben. Sorry, Carson. We closed the queue We are running 3 minutes late. Thank you, Martina. Maybe if you haven't done so, post some links to the mailing list. For, for review, And maybe we can also ask the DNIS dear direct to it. For reviews of already. Communicated with excellent. About it, but, yeah, again, again, poke them. So Thank you very much. Thank you. This concludes the DNS op working group session 2 on Friday."
  },
  {
    "startTime": "02:04:01",
    "text": "See you probably during an interim and also hopefully for the next IETF 119 in Brisbane. Thank you. Thanks everybody. Okay. That's"
  }
]
