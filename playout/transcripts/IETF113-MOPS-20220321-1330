[
  {
    "startTime": "00:00:29",
    "text": "thank you for this go away um hello"
  },
  {
    "startTime": "00:02:05",
    "text": "looking forward to my 7 30 in flight okay leslie um i i don't see my slides uploaded or did you approve my slides i uploaded the mops a couple days ago um you should they should be there i thought i just uploaded them hang on sorry when i click on meeting materials in meet echo i see slides for the chairs and i see slides for dash webrtc but i don't see the slides for sva have you refreshed your browser because i uploaded the rest of them about 10 minutes ago i just logged in about three minutes ago well i see them well okay um let me leave and try to come back then yeah and if it doesn't work out then um i i can in theory anyway if i've done this correctly i can share them and we can do the next slide thing okay yeah i was kind of waiting for kyle but ah there he is"
  },
  {
    "startTime": "00:04:06",
    "text": "all right i think we'll get started welcome to the mops media ops working group session um your co-chairs are leslie daigle myself and kyle rose who is hopefully online successfully from an undisclosed location on vacation before we get any further we'll do the usual uh the usual introductory materials but i will tell you now that at the end of the introductory materials i will stop until we find a volunteer to take notes again this is the just i need a designated stuckey who will be in charge of making sure that the right stuff lands in the shared notes document um the rest of us can be in there and helping write so you don't have to do all the work but i need somebody who will be a stuckey um okay so but do note well that this is indeed an ietf meeting for those of us in the room it almost feels like an ietf meeting except that we're missing all of you who are not in the room with us who also probably feel like it's an ietf meeting because you're up at some unusual hour and on video um so but as a reminder that there are requirements in participating in an ietf meeting following itf processes and policies i refer you to bcp 79 for all the details this is a pre-see summary of some of the things that you agree that you are uh agreeing to um in order to participate in this meeting and a particular note um now that we are actually within within arm's length of each other um we need to remember that we are working respectfully with each other and if you observe any disrespectful behavior or are the uh subject of some disrespectful behavior we do have an ombuds team and please do reach out to them in order to"
  },
  {
    "startTime": "00:06:01",
    "text": "help resolve any issues all right um and lots of rfcs to give you the full documentation on what that means and where to go and who to see all right we have an agenda and i think i skipped a slide oh great we have the slides but this isn't the right set of slides i think i know what happened hang on a minute it's the wrong version um so i want to do there's the understand you're you're not a muted guy so leslie on the uh slides it it turns out when you go to the slides view for me echo um using that refresh button in there does help um logging in log you know you still get an old version of the the overall materials but you need to give it a kick not the right version all right all right so do we yet have a volunteer take notes at this session i'm not seeing anything in the chat i'm not seeing any hands up online not seeing any hands up in the room all right thank you sanjay sanjay is volunteering to lead until 4pm i think that means that we better get this meeting over within 90 minutes all right vadi is sorting that out and i've got to get"
  },
  {
    "startTime": "00:08:01",
    "text": "glenn can you tell me how you refreshed your view of slides because i'm not seeing the updated yeah in the media materials tab up sort of in the the left view of it there is a reload medium materials twisty thank you madam co-chair are remote attendees eligible to take notes uh yes they are just just so you don't have to make eye contact with everyone i i understand that um okay hang on i'm still trying to get back to the agenda because this is this is all just killing time so that you can talk amongst yourselves and figure out who's going to be stucky after 4 o'clock all right one more time with feeling um and i will i will help take notes uh after four o'clock thank you thank you all right um so this is the slide that i wanted to make sure to uh get to i think by this point in the day it's possible that in-person participants understand that you have to scan the the qr code is the fastest way to sign the blue sheet for this session but otherwise you can just log into the on-site tool um which will also log you into our blue sheets it's how we know how many people were here and we can plan for future meetings so we would appreciate it if you did uh plus also we will be running the question queue out of the meat echo interface so by signing in using the on-site tool you will have access to raise your hands if you just show up at the mic you'll be showing up at the mic if you want to"
  },
  {
    "startTime": "00:10:00",
    "text": "speak at the mic you have to put up your hand and we'll go in the order uh that the media echo cue shows us okay i think that is uh and yeah remote participants please make sure that your audio and video are off unless you are sharing presenting or asking a question um okay and kyle's undisclosed location has terrible internet so so he'll just have to make do all right so the agenda we have noted well um we have not bashed the agenda we do have a scribe we have a minutes taker uh jabber scribe is somebody somebody willing to say that they'll keep an eye on the chat well eric's nodding his head so i think okay eric will make sure that we don't lose track of the chat um are there any further bashes to the agenda i did sneak something in just before the meeting the late ad noted under working group docs the discussion of 80 review comments on the ops cons document in case there's any material there all right then not hearing any bashes to the agenda i would invite magnus up to tell us about the mock meeting so yep i'm magnus westland i will talk about the media or quick buff which is on wednesday at 10 o'clock central european time so let's go next slide so is"
  },
  {
    "startTime": "00:12:21",
    "text": "yep sorry about those online that gets to scratch it so um anyway those for onsite it's grand clean tool 2 it's a non-working group forming buff and the kind of high level goal is to judge the need and scope of interest in working one or more new media delivery protocol built on top of quick my co-chair is alan frindle so let's go a little bit into depth here about what's this until next slide so the goal here is really to look for solutions for today's world a significant reason for doing something here is really to anything in the new delivery protocol would be due to the evolving world cdn's good security model models and authorization the fact that it's distributed systems there's diverse set of clients definitely built on top of cloud all those things that you need to think about and maybe that your incumbent protocols maybe didn't really see when they were built so next slide and it's quick and quicky is really a facilitator it has a number of capabilities that are attractive multiple multiplex streams unreliable datagrams it's congested"
  },
  {
    "startTime": "00:14:01",
    "text": "controlled it has a good reasonably good security with tls point-to-point flexibility and reality reliability all the way between full and partial basically a single shot datagrams you have path migration to support clients moving between networks you have user space implementation making it fairly easy to deploy uh so building on this can simplify the protocol and improve the possibilities to deploy so uh next slide so the big question for the buff is gonna be what to tackle and it's it's a fairly i mean big range here from and one of the major factors here is probably latency from quite short latencies to usually gaming remote desktoping and telephony video conferencing requires to live media it's still very wide range from maybe just some seconds to 10 seconds and we have on-demand media yes personal observation here is probably the on-demand media is not targeted to this but um i'm just rather questioning of how much of the above we need to tackle uh next slide so live media is probably a starting point and there's interesting things here around this this is pictures i got from james gruesing who's going to present to the boss but it's looking at typical kind of basic case of a tv production chain for light tv all the way over to distribution both on demand over satellite terrestrial networks"
  },
  {
    "startTime": "00:16:01",
    "text": "and those bigger arrows are what's maybe interest here and what's related so we have three different ingest arrows and they all are different colors for reason because there's some subtle differences here and requirements syndication it's a can't be either distribution or in guest or it's something around there also slightly different requirements the content delivery with this streaming arrow there getting the media out that's different yet another set of requirements that's different so um next slide on top of this we also have these kind of hybrid use cases so what's it does exist beyond this evolving the classical use case improving them so i call it hybrid because it's use cases because it's combining aspects of several use cases i think a fairly straightforward example here is corporate all employee meetings requesting answers you have the the big guys up there speaking speaking speaking and then you get the questions and answers and suddenly someone okay you want to ask a question and you want to actually let them ask live easily without any kind of like i mean we notice here let me take when you add some there's a short powers etc can we get something that works without any kind of clear change so that's the case i think where live media delivery meets video conferencing so there are more use cases like this nature i think the existence but it's both positives does it get us a more useful solution is it more long-term evolvable but can we do this without"
  },
  {
    "startTime": "00:18:01",
    "text": "boiling the ocean is it something we can find the right scope to get a good start deliver something initially evolved it's all questions so next slide so noob slides it's not yeah so it's a lot of questions for this buff but um if you want to prepare you could take a look at some of these documents that have some inputs or proposals etc or things that been done to maybe better understand where people are coming from so um [Music] yep take care i don't have that much more i think it's you're welcome to counter buff on wednesday morning and have prepared with your questions etc follow along the discussion contribute with what's your views etc so yeah you can take the next slide but um so any questions from in these sessions about the buff not trying to hold the warfare but if there's any questions or things that you should think about yeah if you want to get in the queue please raise your hand in great then you can stand up and say um sanjay mishra yeah um on your very first slide you had uh cdn um acknowledgement so i know you you were short here you know yeah yeah i'm sure yes and i don't know if it's like it's it's cdns are there they're a part of a lot of the media delivery and i i think it's it's"
  },
  {
    "startTime": "00:20:00",
    "text": "our protocol maybe not acknowledge them but if you're actually looking at system wide view you usually need something how do you deal with a fan out who's this part of the fan out it's affecting security and things like that about what security mode can you have with a cdn going through those having multiple cdns because if you're large enough a single cdn is not enough you probably have severals et cetera those kind of questions these are things we need to consider so yeah glenn hey there sorry i couldn't be there in person um so one of the interesting use cases that i don't see on your list that you might want to consider if in fact this does become a working group or the work gets taken up someplace is the situations in which you end up having because of your immediate workflows and the practical reality of who's going to support quick and who might not um there's a case where you have to do transitions along the media workflow potentially from quick to some other transport back to quick even um and those transition points may be areas of either like a best practices document or even maybe some innovation around the quick space um around those transitions between protocols it's just the reality of complex media flows that you end up with um these like you know islands of things that don't support the latest and greatest and you have to sort of transition in and out kind of like you know six before back in the in in in that other world so just that one comment the other thing is an excellent consideration come to the buff and tell it there your your timing could be worse 10 a.m cet when you live in california it's pretty painful i'll try we'll see no promises yeah the other thing i'll highlight here and then you may want to take back to your boss but i'll talk about in the sva slides that are coming up next is the streaming video alliance is is putting together a quick uh streaming plc"
  },
  {
    "startTime": "00:22:02",
    "text": "uh not to sort of do a bake off of the the quick protocol but to really build a test environment for media operators who want to understand quick and evaluate against their current operating environment and understand what what it means so just a point over to that and it may be relevant work to the stuff you guys are doing in mock okay thank you so much mo uh mozinha just to chime in on the point about cdns two of the drafts uh going into the buff the quicker drafts do explicitly mention uh relay nodes they don't think they call them cdns and such but it essentially is a cdn so they have an explicit uh provision in the protocol for those relay nodes their function and how they handle publications and subscriptions so you want to take a look at that yep okay thank you so i think we're done here oh no sonia sanjay misha a real quick question again to mo um you mentioned uh see a couple of rfcs or something can you can you repeat that again draft it's quicker qicr they were my reference in this industry okay thank you see you on wednesday thank you very much magnus all right glenn you are up next and i'm assuming you want me to drive or did you want to drive um no i can drive i think um okay sergey's in the in the queue decide you have a question for me well sanji is out with you um how do i drive thank you what are you doing let's just be easy no no you could drive all you have to do"
  },
  {
    "startTime": "00:24:00",
    "text": "is you have to ask to share and i will let you share no i want to use them out of the um just out of data tracker all right uh so hi there i'm blending well i'll turn my video on so people can see me hi everybody i'm glenn dean um and i'm going to give another one of our uh updates uh on the streaming video alliance there's obviously a considerable overlap between the interests of the streaming video alliance participants uh and the itf so we've been doing these updates now for quite a while in mops in fact even three months uh and uh just for your knowledge i tend to do these updates the other direction too over to the student video line so they are aware of what the ietf is up to next slide please uh so for those of you who are not familiar with the good old sva um there is about 100 members now these are people that tend to focus on uh the actual practice of delivering streamed video to people's houses uh you know they the people who participate are content studios streaming services technology providers and cdn operators um there's a very strong intersection between both these topics and the ietf but also participants a number of people even in this working session such as sanjay um are also uh very active over in the stream of video alliance as myself and and leslie as well uh so um if you if you want to sort of position what the sva does it's a little bit like uh like an operator's group like nano uh would be to the itf for protocols not exact match but pretty close and the working groups that the it or the sba uh focuses on are the ones listed right"
  },
  {
    "startTime": "00:26:00",
    "text": "there um in particular to the itf are things like live streaming and open caching uh which have direct tiebacks to the itf as well as a group i chair the networking transport group which is where the quick dlc is being done uh we also do vr work uh players and playback and privacy and protection uh measuring qe all the kind of good stuff that relates to taking video and delivering it over the open internet to customers next slide please uh just so you're aware as i pointed out a few of us are around so if you want to know more and have questions after this i'll find sanjay in the hall i see he's there in vienna uh or find me there's our email contacts for both of us we can help you understand the group and and and and build bridges next slide please so let's talk about a few things that have come out since we did the last update um last update i talked a little bit about the open caching api uh becoming available uh it was sort of early release then it is actually full release now um there is a url down there at the bottom and this open caching testbed is you know one of the key things the sva has been producing is an open caching specification uh and the the apis and we have a lot of people in that room who are building the thing and deploying it and so one of the obviously one of the important things is interoperability and the uses apis and testing of them so that we've stood up a service now uh where you can actually go in and test your apis against a reference testbed and uh to verify that they're up and working and doing the thing they're supposed to do next slide please uh i also want to point out some open caching configuration interface specifications that came out uh uh officially back in the beginning of"
  },
  {
    "startTime": "00:28:02",
    "text": "overview architecture uh a extension for the cdni that's the itf cdni uh metadata object model and the publishing layers apis and i also point you if you're interested in these things uh go over and look at the itf and you'll see or sorry cdni at the itf uh mailing list you'll see like uh documents and stuff that have flown over from sva to the itf around cdni and these specifications so there's a strong linkage there for us next slide please uh there's another paper i wanted to point out to you this is a fairly long uh white paper that the sva recently published it's around 5g edge cloud and it you know given the work the yes the itf has done around um you know network slicing and other things like that i think there's a lot of internets here that the itf community would find interesting to read uh it's about 110 pages fairly long uh and we try to balance between a little bit of marketing not a lot of marketing really and technology without getting down to the leads so it really should appeal to the itf reader of this white paper next slide please so i mentioned this uh when magnus was talking um one of the things you know we've been looking at from an operating perspective for delivering video is you know everyone's talking about quick and from the itf perspective sometimes you know quick is like hey we shipped it it's ready to go from the adopter perspective it's still early days in some cases and so one of the questions that a lot of uh implementers uh and users of quick in their media workflows have said is well this looks interesting but it's a pretty big change for us it's shifting from the world we know which is tcp based and all the optimizations we do there and all the uh you know tools we have for end-to-end monitoring and and problem fixing and detection those all change"
  },
  {
    "startTime": "00:30:00",
    "text": "what changes in my workflow and so one of the things the uh sva is doing is producing a a testing poc uh that effectively is working to produce a sort of end-to-end reference evaluation architecture that would allow anybody who wants to evaluate quick or deployment in their media workflow to take that along with instrumentation recommendations and proof of concepts how you would do that in players and on servers and build that reference and document it sort of test implementation for your company or your organization to be able to uh use quick and do a meaningful evaluation of how it fits into your workflow this is not meant to be a you know quick versus hgb2 it's not you know meant as like this is better this is better than that other one it really is an ability for organizations who want to adopt quick to understand the impacts and evaluate it and so reference testing infrastructure is something a lot of people identify and so something we're working on right now to produce and publish next slide please and finally if you want to get in contact uh about any of these mentioned projects or slides or just information in general uh here's some contact points you can reach out to myself uh sanjay as i mentioned uh there's also uh jason thibodeau who uh is the executive director over at the sba uh and he can uh you know help point you and put you in contact with the right working groups uh and or tell you about what's coming up from the group and with i'll take questions thanks glenn so any questions in the room or online amber hands up and meet echo i think he must have explained it all very very clearly glenn awesome well thank you very much for the chance take care thank you all right"
  },
  {
    "startTime": "00:32:00",
    "text": "um moving right along next up is julia kenyon who i think is online yes alrighty um and i assume i am sharing the slides right go ahead julia all right video hello um hi i'm julia kenyon i work for a company called uh phoenix rts if you've never heard of us that's not surprising um we do streaming using webrtc and we've had a lot of use cases that intersected with dash over the years so last may a bunch of colleagues joined dash i f to talk about what kind of use cases we could support if we were to kind of integrate dash webrtc so if you pull up the next slide uh so there's a number of different use cases you can get from integrating dash and webrtc one is fall back from weber completed dash so if the device doesn't support webrtc if the network connection isn't good enough to sustain webrtc and you have to do more buffering like support um or if someone's offering a real-time experience that's premium and someone's not paying for it they can call back to the higher latency hash stream there's also use cases where you use content that's interleaved so you have real-time webrtc and then you interleave that with dash so you're switching back and forth between dashboard rotc for ad period or uh"
  },
  {
    "startTime": "00:34:00",
    "text": "say pre-recorded content like a movie and then interactive periods where you talk to and we use director stuff like that or you could have content that's concurrent which would be uh overlaid pre-recorded ads for pre-recorded dash content with supplemental live web rtc streams or a lot of co-watching experiences that people think are really cool because then you can you know interact with friends that maybe are elsewhere not that we would ever need to do that for any reason whatsoever um side face so just real quick in case anybody's not familiar with webrtc uh coach everyone knows dash where dash uses mpd which has content descriptions for everything that's available and is the same for all users webrtc uses the sdp which is unique for each client and typically only describes one audio in one video in dash where the client selects the media and the bit rate in the codecs webrtc just negotiates the codex to the server and client and the server is what's adapting the bitrate in dash subtitles and captions are standardized whereas webrtc all implementations currently are proprietary uh dash uses buffered and time synced timing whereas webrtc just immediately renders everything it doesn't do much buffering and uh does that always adds latency which is is bad uh dash even for low latency dash you can get down to three or five seconds uh webrtc is usually less than a second often less than half a second uh dash distribution of course is via cdn which is low cost and widely available webrtc servers are more boutique there's using standards but they're all proprietary implementations and dash has first libraries whereas overseas built directly into browsers so most people don't even need to download anything uh next slide please"
  },
  {
    "startTime": "00:36:04",
    "text": "so how would that work um you've got for hybrid delivery you'd have a publisher publishing a live content it would go up into the cloud it's transcoded packaged gets delivered as webrtc stream through a scaled delivery system and to the subscriber that same content can get pushed out into a dash manifest in chunks and delivered via cdn's or particular recorded content can go into that same processor for dash which provides a manifest and chats and through the cdn subscribers so that's pretty straightforward but of course all these boxes contain a lot of details as you don't like that next slide and the client would be more of a webrtc client kind of grafted onto the side of a dash player so you'd get your typical dash player getting mpd's and segments and then that would talk via a set of apis to a webrtc client which is the standard stack an http client a websocket that then talks to the webrtc server and they just go back and forth using a set of apis that still need to be defined next slide please so the workflow would look like this so the dash player gets the mpd which then comes back with a set of webrtc adaptation sets the dash player would pick out which which tracks it likes so if the mpd says hey there's a german track over here and an english track over there it would know your preferences or you'd ask you and you could select one it would send that information about those specific streams to the webrtc client which then does very standard sdp negotiation except that that's not standard yet but we'll get to that in a minute um does this does stp negotiation then establishes this webrtc connection"
  },
  {
    "startTime": "00:38:00",
    "text": "establishes a websocket connection and then media starts flowing from the webrtc media server as well as events over that website next list um as i kind of alluded to earlier the current state of real-time streaming the webrtc stream is standard but getting there is not so if you want to connect to a system that's doing webrtc streaming you need to get some kind of proprietary manifest and the system to get the session negotiation is also proprietary so you can't just take any client and connect to any server you need to have a bunch of stuff before you get there and we would at some point soon like to make those more standard so that clients don't have to all speak the same language as their specific survey okay that's fine so webrtc's got a lot of work to do um as far as uh the standardization efforts so a signaling protocol which is currently in work as far as the the whip protocol um which is a bit much a bit like an atm machine um so there needs to be a standard session management protocol there needs to be some kind of stream switching that doesn't require starting over again with stp negotiation um there's a bunch of work around time synchronization time synchronization with dash and collecting metrics so dash clients collect a lot of good metrics that would be good for webrtc sessions to also collect and then translate those into existing metrics and then send those via the apis that were in the system diagram okay next slide please and dash"
  },
  {
    "startTime": "00:40:00",
    "text": "needs to determine the apis that go between those webrtc clients and the dash clients to try to define how webrtc information gets presented in those mpd's decide whether dash and webrtc would both render to a single browser video element or switch between two and support hybrid operations between dash and webrtc i think that's the last slide oh sorry okay so dash i have worked on a report that summarized that there's a summary of that report at this link the full report is at the other url and we also have an interest survey where we're trying to find out which people are interested in this for in furthering the standards work that we've defined and um what use cases they're interested in so i would encourage everybody to at least look at the summary and if you even if you don't find it interesting please fill out the interest survey because one of the options is that you're not interested at all great thanks and and if you've been following the chat which i'm sure you were doing while you were presenting not okay yeah there are some suggestions that this looks like it's got some good overlap with with mock so hopefully you'll be able to make the mop off on wednesday um ben i think you have a question yeah hi there um nice presentation julia thanks um glendon here from compass embassy universal uh so a couple questions uh one in this sort of workflow this hybrid workflow how would trip play like the ability to pause rewind jump back to live what's the vision for that and then you want to take these individually or shall i ask them all at once well if they're all if they're all"
  },
  {
    "startTime": "00:42:01",
    "text": "connected then i would just ask them all at once and then we'll we'll see which ones i remember uh and the other one was um you know the watermarking is done today through dash manifests with it with the av trick baby selection trick um any thought about how you do that in this world um well i'll start with trick way so keep playing the way we the way people are doing it right now is you're you're on the live edge and you're watching you know what happened say on the football field just a second ago and you can pick which kind of football you like uh american or real um so sorry not sorry um so you're on the live edge and something happens so you want to back up so then you have an option usually in ui to pop backwards when you go backwards you're you're then going into the dash world right so then you're in the dashboard you can scrub you can do all the usual things you can do in a recorded stream and then when you watch and see oh that's why that guy got a red card or got a flag then you can then pop back to the live edge and then you're back out of rtc and and so with the weber so i noticed your media flow that you at webrtc both being um packaged as a dash manifest element but also direct delivery into clients um how would the direct delivery in the clients work there they basically see a black black box of the webrtc content during the trick player this is your segregation is where i'm going with ultimately yeah and that's that's kind of one of the things that we want to work on in additional that's kind of the further work additional reading kind of thing we need to work on so"
  },
  {
    "startTime": "00:44:02",
    "text": "what what we do is we'll actually just have you have a an app that just shares a window and either the webrtc client or the dash client or control that window at any given time so it's not really synchronized i guess i mean they're you're not you because you can't get the dash data there at the same time that you get the webrtc data that's you know that's kind of the whole whole thing is always going to be delayed right yeah so so an observation that we talked about what i'm working in a minute two one one question one observation one observation is potentially you might run into some um if the code rates for like the the the the the the the webrtc versus the dash content or a different uh frame rates or different uh you know different verses um you might write into like some weird interactions there that you'll have to sort of synchronize in addition to the time synchronization but the frequency synchronization um and then that's the observation the question is and why i assume you're referring to real football being canadian football when you make that comment now now no australian rules football actually but yeah okay so so and then the question about um how would you potentially do uh the watermarking uh uh at this point um at this point we don't um so that's another thing that would be good to kind of hash out as far as would you have completely separate streams or would you just say live edge we're not going to bother with that or you know do some other way of content protection and then just do the the av selection on the dash side well we use watermarking also for like measurement and like"
  },
  {
    "startTime": "00:46:01",
    "text": "impact beyond content protection yeah i'm i'm familiar used to work at parents um yeah so i mean you could you could still watermark the content as it's going through for uh if you wanted to put that kind of mark in indeed right so so you're sort of i just want to kind of riverside would be the answer you do versus client side yes okay their answer thanks great and everyone can see ellie's comment about everyone should uh look at the report and probably do that so and i'm wondering if you guys don't have enough to read already does anybody else have a comment or a question to follow up either in the room or online not seeing anything in the queue i will say thank you very much julia that was great thanks everybody all right uh next up is um we're on to working group docs and we'll start with the um ar document and i think riemann is online for that yes uh rena did you want to present the slides yourself or shall i do it yes please can you drive the slides sure thank you hi everyone my name is raynan and i will be presenting an update to our draft uh this is a joint work with a grammar next slide please so the updates to the draft are in the abstract and the introduction we will talk about the changes in the next few"
  },
  {
    "startTime": "00:48:01",
    "text": "slides next slide please we have got a detailed feedback in the mailing list many thanks to spencer rohit jake kiran and ali they provided both feedback and comments on the mailing list we have responded point by point to the feedback on the mailing list we will now discuss our proposed changes in response to the feedback exactly we propose to replace the term augmented reality with the much more broader term extended reality we believe this reflects the scope of the document more accurately we will discuss the scope in the next slide extended reality is a term that includes augmented reality virtual reality and mixed reality er combines the real and virtual is interactive and is aligned to the physical world of the user on the other hand vr places the user inside a virtual environment generated by a computer mr merges the real and virtual world along a continuum that connects completely real environment at one end to a completely virtual environment at the other in this continuum all combinations of the real and virtual are captured now let's look at our proposed scope of the document of the draft as well as the intended audience next slide please it was pointed out by the reviewers that the scope and the intended audience needs to be defined first depending on the choices made the draft can take different parts so this is our proposed scope"
  },
  {
    "startTime": "00:50:01",
    "text": "this document explores the issues involved in the use of edge computing resources to operationalize media use cases that involve extended reality applications in particular we discussed those applications that run on devices having different form factors and need edge computing resources to mitigate the effect of problems such as a need to support interactive communication requiring low latency limited battery power and heat dissipation from these devices the proposed intended audience for this document are network operators who are interested in providing edge computing resources to operationalize the requirements of such applications next slide please so we'd like to solicit the working group's view on the proposed scope and the intended audience we welcome other pertinent issues that the working group would like to include in the draft reviewers and contributors are invited to support the draft the link to the github repo is given in that slide many thanks to kyle so with the chairs permission we'd like to open the floor for a discussion so any discussion on what has been proposed here spencer is looking for the button in the end all right spencer is in the queue this is i'm spencer dawkins and i'm really struggling with uh the first itf out of the last four or five when i have not had two 24-inch"
  },
  {
    "startTime": "00:52:01",
    "text": "monitors to go back and forth with others here may feel the same way so thank you for this i did have one question that the scope you proposed uh seems focused well i mean it is focused on people doing whatever whatever ar is that are going to be using edge computing for things like split rendering um and i'm curious if there's anybody who is not who is going to who's going to try to be supporting ar but not using edge computing as a way to support ar and that's a question for the group of course so clarifying question spencer by not using edge computing what are you suggesting or that they'll do it in in cloud resources or yeah i mean any any other way some of which people in this room may be inventing on their laptops now uh that you know i i guess i'm kind of asking if if there are such other ways to do this do we do you know do we expect are we planning to expand this document or write another document about cl you know we're doing it through cloud or what like that and i'm like i say i'm mostly asking uh for the working group to think about this and uh i have been where um renin is uh as you know and so have aliyah and jake um as far as you know you've got to work your document and you're not getting a lot of input for it and it really it really improves the"
  },
  {
    "startTime": "00:54:00",
    "text": "document when when the rest of the working group is paying attention so like i say i'm i'm not asking the authors to make me happy i'm asking the authors to make the working group happy right reena do you have any thoughts to share or yeah uh i think um the use of edge computing essentially comes into play when you are talking of uh offloading computationally intensive stuff which might result in heated equipment or limited battery capacity so the battery runs out uh in addition to your standard requirement for uh very low latency in such applications so what we see uh going forward is that the edge computing uh solution is an overarching umbrella under which other possible things can also be added to uh so i've had discussions with people who suggested uh things like uh multipath uh dcp uh just you know just throwing that to the working group uh but we we do feel that edge computing has this uh uh umbrella umbrella-like property where you you can do a lot of things uh once you have solved the problem of uh uh of highly computationally intensive uh applications running on your device and you have just offloaded it to a nearby set of edge servers and then you can use all sorts of clever tricks including adaptive bitrate algorithms to further mitigate the the problem so we do feel that edge computing is is is the key thing but i'd like to hear other people as well yep i'm i'm scanning around to see if other people have comments to make on that and it looks like jake does"
  },
  {
    "startTime": "00:56:01",
    "text": "go ahead jake there we go wrong buttons uh okay so it i thought our remit was more about media and less about edge compute there's like the coin rg work uh research group that's doing some work on edge compute are you looking there to refine uh edge compute use cases if that's the sort of direction you think is is right to be headed so i i thought the question was slightly different i thought and and i could be way out of line here but i thought it was more that because because the computing is being offloaded to the edge there are different media delivery expectations and requirements um than there would be if it wasn't being done on edge computing not not the question of you know how to do the computing there which i think would be the purview of a different group yeah okay could be and and then spencer's question was if you weren't doing it at said edge device but we're doing it somewhere else like in the cloud and he's going to come and explain to us where uh then the delivery requirements might be different and therefore would they be covered in this document or would that be managed in a different document spencer wanted to follow up thanks um yeah spencer talkings again the um so the thing i'm wondering about is whether so coin rg is a great research group but it's a research group uh they can't they're not chartered to produce itf standards among other things um so i guess my question here is"
  },
  {
    "startTime": "00:58:00",
    "text": "um do we it you know are we talking about engineering here or are we talking about research and even if we're talking about engineering this is an ops working group which is an odd place to talk about the engineering stuff many of the comments that i had on this draft uh versus previous versions of this draft were not arguing with the draft uh was more like are we sure that we've you know got this draft these draft this draft contents pointed to the right research group i note that uh mops is also chartered correct me if i'm wrong but moffs is also chartered to provide input to protocol working groups about gaps and protocols and things like that i wonder if we're not looking at a situation where that's the case here because if we're if we're pointing you know if we're pointing to a research group as the best sort of input that we've got that kind of that kind of makes me wonder if it's not if this is really engineering or if it's research eric you're going and spencer you may discover something indeed so to be honest i need to read the draft and the changes and the charter but it's something we need to pay attention to that's a given thank you for this so i i certainly agree that if we're off into that kind of research space we should revisit um but i'm i'm also smelling"
  },
  {
    "startTime": "01:00:01",
    "text": "potential rat smells as in we might have fallen down a rat hole um i've pulled up the document and i i i would have to reread it again with that lens as well but i think that the i think that we are focusing on the xr side of it and not on the what's actually pertinent here which is the media challenges given that the the computing isn't being done on the device right so you're creating and i'm i'm looking at the screen i'm sure that that doesn't help bring it at all but but the it's only so virtual the the fact that you are trying to create this immersive environment and aren't doing the compute local does create a different cloud of realities for streaming the media and i think that's the area of focus and interest here renin does that sound at all like the document that you wrote uh yeah absolutely so um when we talk of operational requirements i would include things like how many edge servers do you need for example to support some use case and what are the kinds of uh protocols that you might use to to support those use cases and uh what are the limitations of those protocols so these all these all questions arise when you start to think about operationalizing uh use cases such as the one that we have presented right thank you uh i see colin in the queue and i see that spencer would like suhas nanda kumar to be in the queue colin yeah i mean i i think this document sort of is operational i mean i i view it i don't you know edge compute and cloud compute really all you're talking about i mean as far as this document's concerned it's compute and it has a different latency going to it you're talking about the operational latencies of where you put your compute um how much latency there is to that point"
  },
  {
    "startTime": "01:02:01",
    "text": "and that's not related to anything that's going on coin rg or anything it's just like yeah there's going to be some compute and it can be different latencies away and we can use that to trade off against things like power and heat on headsets and you know whatever that all seems very reasonable to me it seems to be in in the scope of what we're talking about here thank you colin and i see suha says join the queue please go ahead can you hear me yes yes i cannot say no to sensors right here um i i just wanted to run on to look at the computer compute our networking box which kind of captures its computing and what how can you kind of offload some of the work to the edge nodes might be used something useful there not sure thought of sharing the thought thank you for the pointer and if my memory serves and it probably doesn't that's on wednesday of this week see told you my memory was suspect great thank you all right spencer you're in queue so i'm not going to check the agenda before that will and leslie's memory this is this is spencer again the thing for me i think is looking at the draft contents most of the things past the introduction haven't changed a lot and there's a very interesting description of why latency of targets are tied with ar and then there's an uh there's a description of the eotcp considerations which what it says isn't wrong but you know if you're doing ar over tcp that's you're going to bump into a lot"
  },
  {
    "startTime": "01:04:01",
    "text": "of buildings um but for us to to for us to really think seriously about um what's needed here and i i take cullen's point that there are people in the world who do this every day um so i have no doubt that there is engineering work to do here um and that if you stood in the right place and squinted hard enough it would be operational engineering work to do here uh but like i said i just i'd like to have us have a really good sense of what what the right scope is for the working group document before we do a lot more wordsmithing while we're still talking about the scope does that make sense yeah so um and and a side note um you your memory your memory wins i just looked it up if the can buff is tomorrow that will not happen again [Laughter] um but the so to the point about scoping i think we are fairly clear on scope and i think the challenge is determining how to make sure that the document stays within scope um and the big move between the last ietf meeting in this ietf meeting was the move to get this into github so that we can pursue it more methodically so um i'm pretty sure that renan would appreciate some help in going through and identifying sort of which areas align well with um the scope that we've agreed which is media delivery in on operational sense um in which areas maybe are a little less directly related to work in this group so wait for it volunteers and spencer's looking around the room too well like uh but but you you're at a you're you're in a computer so you could"
  },
  {
    "startTime": "01:06:00",
    "text": "actually stare meaningfully at the people who are remote i'm willing to help with this but i think the i think the really important thing for the for working group contributors which is more than me to be writing issues rather than prs at this point right and i think i think that we should applaud kyle for setting up the repo for this draft and uh we should do the right thing after that yep and and certainly fair point about um i can see the list of people in the room um because i mean one of the challenges as we've been working in this mostly remote mode has been really getting that sort of cycle of motion going so i'm a little concerned that we'll walk out of the meeting room today agreeing on what needs to happen here and then we'll have the same discussion in a few months in philadelphia or remotely in philadelphia um so i really like to make sure that we agree having agreed that this is a working group document and that there is working group work to do here let us do some working group work here um and if the right thing is to say right for the next month and i would say it's the next month not the month before the july meeting for the month following this meeting let's focus on identifying issues and making sure that we can get this document to line up with with you know we know it needs to be covered in order for this document to be useful and aligned well with our working group charter then i think that would be helpful and maybe having a side sidebar conversation with jake while everybody else is listening but jake was talking about the difference between uh media delivery and what it takes to do media delivery i"
  },
  {
    "startTime": "01:08:01",
    "text": "think that i think that was his point uh in his statement and uh for us to i would suggest that that was a really useful filter for us to use to think about what we should be doing thank you oh thank you let me jump in to clarify then um yeah i was i was stalling so you'd have time to yeah sometimes the buttons are tricky um so i i i take the point i think they're i think uh what colin said is is right there is some uh you know some good ops work to do here i guess i would so one question is like how central is the compute uh offload to this but another maybe way to focus here is to like think that it it presumably there is some component that that's there and to talk about like uh what are the kind of bandwidth and uh latency and reliability requirements around that i think would be the kind of useful direction to flush out like what you know if you tried to run a system like this then what kind of network are you going to need you know and can wi-fi do it and like how many how many you know how what are the scaling considerations i guess as well because you know i imagine this museum tour that you've written about uh you know if you try to bring 100 people instead of 15 people then you know what's that going to do your to your wi-fi and or is it even wi-fi i don't i'm not i'm not really sure what the state of the art is here so i'd love to see more"
  },
  {
    "startTime": "01:10:00",
    "text": "about that in the doc and kind of what can be achieved with what with what kind of parameters at a quantitative level i guess um do you need me to put that in a github issue or can you take care of that i tell you what if you could capture some of that in the meeting minutes it would be most helpful because i think those are good broad level questions to use as sort of a a review set of questions going through this document so it's not just to answer your questions but i think it's it's they're a good set of questions sorry kyle go ahead oh no i was just gonna say i think it's probably worthwhile to put it in a github issue as well just so it doesn't get dropped sure all right so i think that was a helpful discussion and some helpful pointers to where from here anything else you would like to get out of today's session uh now i would like to thank everyone for participating in the discussion uh and just wanted to reiterate that we for this iteration we only focused on the abstract and the introduction because you think it's it's really important to fix the scope of the document and also to uh to fix the intended audience and so that was the goal of this particular update and uh to spencer uh we have taken your comments about the tcp section on board and we have replied to you on that point as well but really i think our goal is to make sure that everyone in the working group uh agrees with the scope and the intended audience and we can take things forward from there yeah great all right thank you very much thank you thank you and i'll look forward to further discussion on the list and in the git repo um okay so that brings us to"
  },
  {
    "startTime": "01:12:01",
    "text": "the uh the late ad discussion item so thank you eric you sent some comments as an 80 review of the draft itf mops ops cons um i think that there's material there for the draft authors to work through but i didn't know if the draft authors wanted to spend some time either talking to some of the points or asking further questions and i'm going to assume that everybody here has read that discussion on the mailing list because you're all subscribed and active contributors go ahead spencer yeah spencer dawkins and noting that there are two other draft editors on the on the uh here in meet echo so i invite them to help me think i looked at eric's uh comments and almost all of them i knew what to do with the only one that i did not know what to do with was uh his observation that some of the description of latency seemed overly lightened in the draft and after a spirit spirited conversation on email between me and ali one of the other editors i've convinced myself that what that the definition of latency categories in the draft which was hammered out at great length uh in this in this working group is reasonable for streaming media and we can talk about whether we should even be even mentioned"
  },
  {
    "startTime": "01:14:01",
    "text": "video conferencing as a streaming application but i agree with ali that opening the conversation about latencies is in the context of this draft is not the right thing to do so i'm given that i think i know what to do with pretty much all the comments that that eric made and uh thank you eric for being gentle and uh let other people um express opinions about any of the other comments that uh may have been made i'll just go ahead and say this now if i can um i have been living with the nice people that are doing the mockmoff and the latency categories that they're talking about there are not to say you know not necessarily the same world as operational guidance that we would we would provide to existing people who are doing video streaming uh today and so like i say i've ali convinced me that uh we're talking about two different problems and it's okay to not change stuff in one description just because of the other thing we're talking about thank you okay thank you eric yeah andy all my comments are saying are pretty minor they are more the editorial side and really technical for me i have two things the latency i really want to point you on this if you confirm that you are okay with it i'm all set right you are the expert i'm not and the other parent is about the living documents and we got the discussion this morning within the isg we have not yet a way to do this so it will mostly be"
  },
  {
    "startTime": "01:16:00",
    "text": "static when it's published maybe we can change it at all 48 to get some refresh and then after you will need the beast we hope to get something more coming in the one year two year but not for this one yeah so so it would be great to have a general ietf wide answer to the question of what to do with living documents i i will just throw out that in an earlier draft of this in an or in an earlier draft of this there was a discussion with uh john levine about how to refer to things um and i think that's a piece of the puzzle as well oh and i see that warren is about to warren's head is about to crater spencer spencer's in the queue though well spencer you really better anyway okay uh this is your regular host uh spencer dawkins and uh so if i'm remembering the conversation that we were having correctly on the previous version of the draft it was using something like tinyurl to generate the urls and so the question was what happens if tinyurl goes away so i think that one reasonable suggestion which people tell me is not totally crazy i would likely put in a pr for would be to create a dead pointer to a living document and at the end that the dead pointer which would not be which would not be updated would be pointing to a document maybe in the mock github or something like that where we where we could maintain it where we could maintain the really very useful list of things you ought to be following and things you"
  },
  {
    "startTime": "01:18:01",
    "text": "ought to keep an eye on uh that are that are now in the draft if if not everybody has noticed that because it was added in fairly recent revisions uh it's worth taking a look at but i think it's really i think it's really useful for us to provide that to the readers uh and if we don't have to drive the rc people crazy um yeah and we can solve it if we can solve our problem ourselves maybe we don't have to wait for that thank you yeah well some of the implications and ramifications are the reasons why i would really look forward to an isg solution for this across the board because in a previous life i was known as our lady of identifiers and i'm trying to get over that but this is servicing a lot of the challenges with you know what is permanent what is i mean heck let's get into document formats too um while we're at it and um yeah so let's i'm not really not trying to drive warren under the carpet did you need the mike horn i'm gonna let warren have the mic and then we'll get back to the queue somebody's gonna have to cut me off because otherwise i'm gonna go on a 20-minute rant um so we've tried to the living documents thing a few times and part of the problem seems to be that everybody's got their own use case so figuring out exactly what the use case would be seems like an option um i think the easiest thing that we came up with last time was there is one document which is owned by the chairs or someone and they just update it to point at the most recent version of another document which seems to be what everybody kind of agrees as the currently best viewed it's like the chairs kind of determine consensus that you know this thing is what everybody kind of agrees at the moment and they just have a document that points at that it's"
  },
  {
    "startTime": "01:20:00",
    "text": "incredibly messy and ugly but it at least gets you something for now um but if people have the stomach to have the living documents discussion again that would be really useful i still think it's worth doing it just sort of as one of those endless discussions like document formats that just dies yep no and i think that the real challenge there is to have the discussion in the broader context than than the mops working group so yes and no well i mean i understand the theory as spencer suggested we could just solve our problems yeah yeah the issue is there's like 47 different use cases and if you have the broader one everybody's like mine's the most important yeah and clearly the mobs one is the most well naturally all right uh glenn you're next in the queue oh sorry conveniently spencer you're after glenn in the queue if you really wanted to say something um a couple of things uh in in no particular order um on the latency discussion i agree with the comments valley made and i'm glad spencer came around um overall you know latency is going to be a moving benchmark uh because it's an area of a lot of operational investment by various parties both in standards and also in technology to move latency into uh ever ever lower numbers so it's always going to be a moving thing uh on the discussion of living documents um you know one one thing mom should consider if we're going to do this sort of isolate alone and not try to solve the bigger picture which i agree with um is also the concern though that if the itf does get requests for uh citations by lawyers and and signed you know what happened when um whatever solution we decide in mobs should be able to support uh those legal frameworks that the itf does get pinged on occasionally uh by law firms so as a consideration"
  },
  {
    "startTime": "01:22:02",
    "text": "and github probably is not the best place i've said my piece right thanks for that spencer did you wanna and then i think we will unless there are other unless there are other issues with the document and and this one this is on this is on that one uh the my my uh my question is just i'm not going to break i'm not going to raise my hand about this at the plenary right we all agree okay just making sure yes um okay so i think that that was useful discussion around the points in um the mops ar you know sorry in the ops cons sanjay did you want to jump in on oh yeah this is sanjay just real quick i mean the the decision on living document does not have to be made i mean if we should publish the document of course if there's consensus and if after the publication there's a really good use case that we think belongs in that document then we can always you know revisit it but i don't know if we want to consider this as a like living document you know forever yep all right so i think i think eric you correctly identified the two major issues with the document latency and the zombie document problem um okay then thank you very much for that and and i'll take this opportunity to say thank you very much to sanjay who is the document shepard and did all the work to do the write-up and get it to the isg so thank you sanjay all right um and now we should move on to the milestones discussion um i wanted to uh to get there because the current state of our milestones i won't say is woeful there are certainly more woeful milestones lists"
  },
  {
    "startTime": "01:24:01",
    "text": "and and of course you've you've all seen these because i sent all this to the mailing list on friday-ish um so i've just noted here the the items that are uh either either seem to be out of out of scope or whatever so we were we had as a list on our list to last call a document on sm simpty's use of our reliance on our protocols since we don't even have a draft of that and simply seems to be moving away from some of the uh really ietf related work at the moment i think that it just doesn't seem to be i don't think we should have this on our list at all i think we should punt on that one revisit it when there are more in-person meetings for both the ietf and symtee um and then see where to go from there for the streaming video alliance document that also doesn't exist yet um i think we move it out a little bit because um i i believe we've updated a possible pointer to a plan that's enough layers of indirection to cause that document to to exist um and i think that by july we should be in we should be possibly even seeing a draft of that document so that's my proposal there um we have done two of our milestones um and um yeah the november 2021 71 also out because it didn't happen um and then there was a bogon um i think that there was a mist we just didn't clean up the milestones properly last time um and we do have a revised um ar use case document so all of that markup is kind of messy and the net net is it i'm proposing this for our updated milestones you don't actually have to decide this here but i would certainly look to see if there's any discussion or pushback or"
  },
  {
    "startTime": "01:26:01",
    "text": "thoughts that aren't on cleaning up the milestones this way and i'm assuming that was our area director's agreement these are the most stunning awesome milestones they've ever seen yeah go ahead colin well i was just going to ask just an informational question just what how do you imagine that you're drafting the reliance the sva reliance what do you imagine that looking like is that just like a list of references of the stuff they use that we're doing or what it what was that what does that look like so um i think it's useful to know what things what the relationships are between the work that we're doing and the work that sva is doing and you know we've had reports every meeting from sva saying you know we're doing this and this is how it touches some of the ietf protocols for example the work on cdni with which sanjay is intimately familiar and and that was referenced in in glenn's presentation earlier so sorry dry air i'm gonna cough um it's i think the important thing here really is to understand how entities that are doing more evolved things with video or more industry specific things with video are relying on our protocols so that we have some understanding of you know who our users are and what we might like to take into account i don't think it's directive in any way i think it's entirely informative okay so look i mean i just as two examples of ranges of spectrum for webrtc i capped a draft that just had where the status of where all our all of our drafts and rfcs were that the w3c could use to look at that there's and it had everything that the w3c depended upon that for webrtc um and that was one in the spectrum and then the other inspector back when we were doing a lot of sip stuff i mean the liaison managers kept an amazing excel spreadsheet that was reviewed at every"
  },
  {
    "startTime": "01:28:00",
    "text": "you know every three months in a formal meeting um so i i anyway and both of those turned out to be really useful so i'm not quite sure you have in mind here but it was useful well thanks very much for those suggestions and uh i think we'll certainly keep them in mind and i think somewhere perhaps somewhere in between and perhaps a little bit of a backing story in part because you know part of the goal is for people to know that the sva exists and for the sva to remember that we exist spencer is that a new cue it's a new queue thanks colin this is spencer dawkins and this is actually just a follow-up for cullen's thing i mentioned earlier yeah we are chartered to provide input to protocol working groups about gaps and deficiencies in the protocols that people are trying to use so i think that uh the producing that document for someone who's trying to do more than just show up you know show up show a video uh is is a really useful first step towards saying do what you know do we have do do we have everything that we need uh or you know or is there other stuff we haven't really talked much that i've that i can remember about uh gaps and i think that um having mops members participating in the mock-up on wednesday it's going to be a really good opportunity for that kind of input to happen uh i know we have one person from the broadcast type business that's been active in discussions about and mock but uh a lot of other kind a lot of other kinds of operators that haven't haven't been represented at"
  },
  {
    "startTime": "01:30:01",
    "text": "all i think it'd be useful to have that uh in a non-work group forming buff yeah so i think part of what i'm hearing and what you're saying is that um maybe we shouldn't expect to be last calling the document a couple of months after the first draft appears um so the november 2022 milestones should probably be moved out or changed from last call to an update or something yeah okay all right that sounds good um i will send that update to the mailing list and you know gather whatever comments other comments show up there give it a couple weeks and plan i think file and i will confirm that it looks like we've updated milestones and then do the updates so with that um is there any other business not hearing any other business going once going twice and i asked kyle a couple minutes ago but i don't know if he's lost his connection it's been fine since i've switched to my tablet and had my video off so but i don't have anything else all right well that's the important bit then i will say thank you everybody for coming virtually or physically and um yeah close officially close the meeting thank you all you um"
  },
  {
    "startTime": "01:32:20",
    "text": "is but if they were as soon as i said they just moved away they were very friendly they just didn't notice yeah hi warren hey how are you sir not too bad not too bad yes"
  }
]
