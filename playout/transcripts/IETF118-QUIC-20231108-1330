[
  {
    "startTime": "00:00:11",
    "text": "It's Okay, folks. It's I mean, mute my computer. It's the bottom of the hour. This is the quick working group session. Have a few people filtering in, but we'll go through some of the admin process first. My coach and Mac can't be with us. He's had an emergency, so I'm on my own. Have some patience, please, in case I can't use a computer, it's been proven in the past, haven't got any evidence that it won't be different this time. Let's move on. Is the note well. By now. Hopefully, you should have sent us some sessions and be familiar, but if you're not The note well describes policies and procedures and processes, that are for how you participate in the IETF. There's a bunch of documents on here. If you're not familiar, please go and have a read, but some of the key points are around standards process itself, how working groups work. Pay your contributions and and rules about ITR. Work here, importantly, things like the code of conduct and you're expected to interact with other participants in the IETF. And this working group, especially because we're here now. Some of the meeting tips, if you're in person, please please scan the QR code and get registered. This is the effective virtual blue sheets that we used to have. This helps with attendance and to understand if this is the right room size or it's too small, etcetera etcetera. You can also join the queue from this. This is great because remote participants and on-site people can be,"
  },
  {
    "startTime": "00:02:01",
    "text": "mingled, who don't get from mingle enough? Remote participants similar. We don't share your video. If you can avoid it, please wear some headphones. We like good AV. Administrative note takers, foreign trammels, or already kindly volunteered the link in this document's wrong. Robins posted one into the Zulu chat, which is great. Anyone else wants a volunteer to help with Brian, just things like typos or fix up always greatly appreciate it. Says people talk fast sometimes. So if you could take it as a I don't know. Red black striped rate array or something. Great. We've got the blue sheets, chats, and, yeah, Eco Zulik, I'll try and run the queue as best I can. We'll see how we get on. The agenda for today is, chair updates. We're gonna spend a lot more bit more time than just this stuff. I've gotten an issue that our AD has asked us to. Bring up, and maybe we can try and resolve within that timeline. We're gonna get them to work and group items. We're gonna have multipath and stream resets and q log. Then some of the items potentially need work or related work with quick. So that's natural reversal. Can see if time stamps quick EDP frame, and then to, presentations about FVC. If we get at the time, and I can get the slides been loaded up and show and we'll see how we get on with that. Is there any agenda bashing for that? To see anything? Okay? Great. Update since the last meeting is that the act frequency has gone into working group last call, we managed to drain the queue of issues. So that's been good work from the the author's there. Thank you very much. That working group mask call is is still running. Wanted to run it before the IETF in case anything came up, and we would have an opportunity this meeting"
  },
  {
    "startTime": "00:04:03",
    "text": "discuss either in the meeting or around the meeting. I think there's one issue that probably needs a bit of discussion, but we're not gonna take any time right now to do that. I think we can try and sort that out in the corridor or maybe take it offline. But please, that's a great chance. We heard previously that working group last call, It's kind of for some implementers this is when they would start to look, and they wanted to wait and think till things stabilized. Please do the more drop or implementation experience we have with these things or the better. Onto the other, the other item I mentioned, our our writer reports, we had one raised by Martin Seaman about the multiplex in quick. This was a while ago. I don't know if my niece still has some opinions, but I'm gonna try and present kind of where we got to before, life got in the way for various people. There is some list discussion here linked up on the quick list. And read if you don't believe my summary. That's fine. I won't be offended. But effectively to give some background here This is around Demux. So Now something in in quick, long header packets called the quick bit. And it's, for for all long packet except for version negotiation. The draft says it's must be set to 1 And the reason for this is that it allows quick to coexist with other protocols scenario here is listening on a single port number. And receiving packets that are intended for different UDP based applications and, fitting in with an existing demultiplex and profile described by our C7983 And this this is fine. We picked means that we're in the number range that, won't be accidentally forwarded to RTP or something like that. And Vision negotiation packet is a bit different. The spec says where quick might be multiplex with other protocols."
  },
  {
    "startTime": "00:06:00",
    "text": "Servers should set the most significant bet and that there's no requirement on other visions to make some of the recommendation. And so the concern here sorry, the and this is the the the Deep Hudson the the max model. If you notice the RFC number is different than what was described in quick. It's already kind of in a a slight decent situation where the the the recommendations for UDP DMuxing were updated after Quik was update So there's always an opportunity to update doc references. I don't think that's a big the high end a bit here. But effectively, problem we have is that the the server can't know what the client is muxing. Doesn't have the correct information to know if it should set a bit 100. Which is this kind of a bit sucky, especially when the spec says it. Doesn't really provide any information there. So there are a number of proposed solutions on mailing list. Some of them were made and subsequent discussion may have ruled those proposals out. I didn't wanna make that call. I just wanted to survey all of the ones I could find this morning and and get ready. So One of them was to change RFC 9000. To to towards always setting the bit to one. And to remove the subclothes where you know, we might say, oh, where the protocols might be used. Other option was to change the logic in RSC 9443. To kind of effectively change the definition that I just had up on this slide and change something. That's not quick. That's gonna require a lot more time and if we decided to go that route, Another option was to change RFC 9000 to say you must set the bid. Unless there's some out of band knowledge that you could have That's different. That what we do now, it would upgrade us should to a must"
  },
  {
    "startTime": "00:08:04",
    "text": "And then finally, kind of the one that was the last thing on my mind and I think was discussed on the list was that we just change the text that decorates that should, to provide a bit more information towards is about why setting it to 0 or 1 might help or not depending on outbound knowledge and that people wanna take risks you can make guesses, that's fine, but they they understand what they're they're asking themselves for. So I think I think would be great now if anyone has strong opinions on this to come and speak at the micro I'm and say. Maybe the people need some time to digest it. Could take it to the list, but we just wanted to, bring this back up so we didn't forget. So we can just make take action and move on. This needs to be held for document update, Zaha, you can remind me current stay. I think it's held the document update. We should decide what we actually want to do now Yes. Mirror. No strong opinion, but 4. Okay? Kazuo? As a whole. I also think 4 is good. Because when we design RSCN, we thought that the demaxing thing is a going also where as budget negotiation is going to be baked into the form long, longer time. Thank you. Yeah. I'm sorry. So to clarify, this is just for a version negotiation packets. Just for vision negotiation packets because they're the the odd child there. Long had this Okay. Then I'm gonna say probably, number 3, but Any of these are fine. I agree there's something that's changed. K. Thanks. Alesandro Giddini Cloudflare. I'm not sure. Do we actually need do anything? Like, when it says where quick might be multiply with other protocols, isn't that equivalent to"
  },
  {
    "startTime": "00:10:03",
    "text": "you know, unless out of band knowledge clothes. Yeah. I think that the tech we might come up with as a proposal. Could clarify that points. I I had some prepared. I didn't want to put them up here. Wanna think the opinion, but Yeah. So, I mean, I don't really care that much, but for seems like, the better option Okay. Thanks. Christian. Well, for option 4 as well, if we have to do something, but but that's happening. Unfortunate for as well, but, I I would like to point out that version negotiation as defined is probably a mistake. Because it's an clear text packet, authentication. It's a greater tax factor to take down ongoing handshake. So maybe we should think about that to k. So reopen the complete kind of wins on version negotiation. Is that on here? Okay. Consider that one tonight over a strong beverage. Thanks. Martin and Simon. Well, there's a lot of ways to bring down a quick handshake in the early stages. So I'm not sure if we need to fix version negotiation, in particular here. I I have a strong preference for option 3 because for sounds like, if you're running an implementation, it sounds like you probably don't need to do anything. And, You do. You do. If you're running a, publicly reachable quick server, you don't know what the client is demultiplexing on the same socket Okay. David's Ganazi. David, it's Ganazi, quick enthusiast. I, you know, changing RFCs is great and all, but that doesn't change what implementations are doing. Do we have any data on what"
  },
  {
    "startTime": "00:12:00",
    "text": "that, like like like like common servers are doing these days. Because the specific case where I see this being relevant is someone doing a peer to peer application with their multiplexing on both sides. I can most cases, the client is a multiplexing. If they're doing that, They don't care what the RFC says. They'll set the bit to one on server and be done with it. So it doesn't make sense to modify the RFC. Like, what's the motivation for doing all this work and figuring this out? Like, do we even care? I my my my take just personally not as chose, but like, we want uncoordinated endpoints to be able to work on the internet. And that's it could be an issue, and that's to to the changes that we're discussing are not to the key protocol itself, but just clarifying an intent we probably had. The question, do we have data is amazing? We just saw in the Map RJ earlier this morning people looking at spin bit maybe looking for in version negotiation frames, bits could be of interest. But I wouldn't wanna block this on that. If it assists the decision making FAP, But, yeah, Thanks, David. Jonathan Lennox. Yeah. Jonathan Lennox. First of all, I don't think nobody's recommended it, but I just wanna emphasize not to because the next four bits are the sequence number and half the time stamp, which could validly be 0. Obviously not likely, but you know, 1 and 2 to the 32nd or whatever. And, the other is that It's not clear to me that there a situation where You're not Muxing, but your peer is because 9443 already says you need to pay attention to about 5 people you got it on. And, you know, because that's how you distinguish quick from turn. So I mean, you know, if you know that, you know,"
  },
  {
    "startTime": "00:14:03",
    "text": "this five people, it's just a quick server and it's not muxing with anything, then just always treat it as quick and don't worry about it. It's only when you actually have things running over the same. Five people that you need to worry about this stuff. So Yeah. I think the it's my my recollection of the concern is the the client is listening on the same port and the can't know. Yeah. But it's listing on the same port, but it still knows what IP in port it got something from. Big time. You know, say, this IP in port is a quick server. That IP import is you know, RTP. Correct. But then if you say had a a local process using the same source port and for quick and RTP. And those things were being Yeah. I I, yeah, that that you you could end up ordering packets to the wrong that was my understanding. It sounds like there's some interest here, maybe some emerging feel, I I think that's good input interaction, and we'll carry this discussion on the list Thank you. And with that, that's the end of the chairs section. So Next up is multipath need to switch slides your faith? Sorry. You got me. Okay. Okay. Good afternoon, everyone. I'm Yumi from Alibaba. Today, Mia, and I will introduce the extension for quick this time, inside, please. As as usual, we we introduce the difference between there are 5 to 0 6 and the internal reports this. So and about the talk about the over issues. The discussions and, and the next steps"
  },
  {
    "startTime": "00:16:02",
    "text": "Next slide, please. Yeah. Actually, the difference from Daryl 52 dialysis is quite small. The most important difference we have made is we is that we add 2 new frame types the past standby and past available. Actually, we split the the past data frame into 2 new frames. The, passed that by is exactly the same way the standby sitters from past sitters with the past available frame is exactly the same with the available status of the passenger screen. In the previous draft. And the, how to use exactly the same way And and also, I want to make sure one point is that past status are recommendations from the receiver side to the center side. About the past usage for sending data that means, these these past data frames just influence the the sending the data sending about the pass, about the, stream friends and the day too. Datagrams, And you can always send out the control frames quick transport on all the passes freely. Yeah. The the second point is that we make it clear that any frame can be sent on the new pass at any time. When the an anti amplification limits and congest control limits respect it so in quake, in quick multi pass extension, we share the same security consideration with script transport. And we want to make sure that it does not means that you can initial, in in need new passes from the server side"
  },
  {
    "startTime": "00:18:00",
    "text": "just client side could need new passes. The next size piece. Yeah. At this point, it doesn't make any change. We just make it clear that as past is determined by for turbo and points could use different port with the same IP address when using multipass extension. That would be more convenient for people to test on their devices, which has only just one IP address. Yeah. Now now slide, please. Yeah. And we, we have in interrupt task in this hackathon about Darryl 6. Actually, we have 9 cases at this time. It's quite complete. We add, past status and the key update and the CRD change and the CRD retirement cases for this time And we have down a four table for these these 4 implementations, And and I'm sorry. Yeah. Yeah. I had to finish. Yeah. And active I'm sorry? Sorry. Sorry. Yeah. And, and we have 4 implementations participate in this time team. In in his time to interrupt tasks about free real quick as quick route and creature. And everybody has done a good job. And we really encourage volume in implementations could join this internal test also, we had a poor request for the interim test runner. About the multi pass cases, people could use that way to test later after the HEXO. Yeah. And I will let the issues for Mia. And"
  },
  {
    "startTime": "00:20:01",
    "text": "Perfect. Thank you. Now we can go to the next slide. So, good news we have about 25 issues open, but lot of these are either for, like, completely different draft or, mostly editorial as more changes and so on, but we have one big issue, and that's the one about do we want to have an explicit pass ID? So at the moment, the connection ID is based basically defining the packet number space, and that has some implications So first of all, it also impacts the decryption because the CID is used as an every time you change this, you also have to change your encryption. Then it also has an impact for loss detection every time you change your CID, it might be actually harder to figure out if a packet was lost or not. Because you suddenly have a new picker number space. And then all during net rebindings, if you have, have to have a net rebinding and a, connection IDs change at the same time. Then it's not here that is considered as a new path or not, and that's also another open issue we have, but it's connected to this one. So there was also a proposal to just not do change the connection ID. I don't think that's the way you wanna go forward. It's still an open issue, but I hope we can close it because we have this rotation mechanism for avoiding linkability, and I think we wanna keep that property. From ROC 9000. There is an alternative proposal. Actually, it's kind of more or less the same proposal in 2 different issues. And the alternative proposal is to actually have an explicit pass ID. And that also means you changed path management, you have to, like, have new frames for all the frames where you provide the path, the connection ID, and you to add a pass ID to it. And that does change that does solve all the problems above. But it acts a little bit of more state, complexity, however you wanna call it. So the re question is, and we are a little bit split on this. We have people who say, yeah, these issues are not that important because connection ID changes don't happen very often, so we can handle them in some way."
  },
  {
    "startTime": "00:22:02",
    "text": "And we have people who say, but we have this nice solution. It adds a little bit complexity, but let's know, solve it in a clean way, tear way, So what do you wanna do? Because it's all good. So I think we discussed about this specific proposal 214 in the previous previous, IPF, and this seem to be slightly more people arguing against it. And since then, we haven't made any progress. So I kind of wonder how we can make progress now without closing the issue so, I mean, that's exactly the problem. Right? We discussed this last time, and we seem to be split. So But she hasn't told me what to do. But maybe one more point I wanted we do a ham today or something. I don't know. But one one point I wanna make is that, like, the option is basically to change a draft or do nothing. Right? So changing the draft will be a little bit of work and also needs a little bit of additional implementation effort and testing. So if we do nothing, we are basically done If we change the draft, we have to change it. Okay. Kristin? So I am firmly in the do nothing camp. Because, I think that, the the hole that we have on CID rotation, is kind of by design. The the purpose there is to do CID rotation so that the the new pass cannot be correlated with the previous, the 1, the new stream a new CID cannot be credited with the previous one. To get that property, you have to some kind of distance between the new bus. So in practice, you are not you you don't want to do that when you send one packet with 1 CID and the packet with the next CID, a microsecond apart."
  },
  {
    "startTime": "00:24:00",
    "text": "Because, I mean, linking the 2 together will be trivial. What you want to do is wait and only do that quotation when you have a a long silence. And if you have a long silence, yes, you get the policy effect. But if you have a long silence in practice, also have a new pass. So the fact that you have a new pass if you wrote at the CID after a long silence It's kind of by design. It's not a bug. It's good. So don't change anything, and let's let's publish a meeting as to have We have been working on it for way too long. Actually, I want to correct myself. We still have to solve issue 118 But I don't think that's a protocol change. It's just some clarification needed there. Yeah. Okay. Martin Sewer? So I don't think the only problem here is the rotation of CID the past. If that was the only problem, I would agree with, Christian. There are a number of of other issues. That come up when we don't have path IDs and a describe them in, in the issue of 214 here, I haven't implemented multi path myself yet, but I have thought about how I would implement multi path in QuickGo. And I know that one way would be a lot easier than the other way. The easier way would be by having explicit path IDs. So I'm I'm strongly in favor of making the changes here. So I think it actually depends a little bit on where your how your implementation works if it's easier or not. So it might be easier for one in place. It might be harder for the other Ian Swek, Google. I'd prefer it without half ID's. Overall. I do agree that connection ID rotation is slightly annoying. Although, I think the loss detection,"
  },
  {
    "startTime": "00:26:00",
    "text": "changes a implementation dependent change, like change the connection ID, then it's the same path, then you can decide if you want to keep the loss detection the same contact the same c, you know, can kinda do things to fix that. And the decryption encryption thing is I mean, unless you have a ton of CIDs in flight, that are different. It doesn't seem overly complex, then my personal opinion. Martin Duke Connection ID enthusiast, yeah. So I'm we we definitely have to have a CID rotation, not just for the privacy thing, but because, like, that could break routing. If there's a load balancer on the new path. So this is like, this is an absolute, like, compliance requirement. You can click close if you want. Or your contract. Kindly close on that issue. Which issue? The 273. What 27 3. It's 3. I I hit 2073, and I've had a panic Try to do multiple things at the moment. But I'll take a note to close 2073. Thank you. Sorry to stand up again, but I just wanted to point out that So this past ID proposal makes certain things easier. That's true. And I I think so. There's reason for people argument. On the other hand, it does change the data structure. More different, from what we have in Qlikview because they are now two layers of past I mean, while being the pass group, I can find the pass ID and then the connection ID So the data structure is going to be much different, and they'll be paying for existing quick implementations to support multiple. So this is a trade off. Like Bishop. Hi, Grace. I just wanted to find out a different between what I hear people saying and what I see on the slide."
  },
  {
    "startTime": "00:28:01",
    "text": "And I think the slide is probably a more useful way to think about this. The proposal is to separate path IDs from connection IDs. We already have A sequence number for the connection ID identifies the path on which is being used. You can use that to index things and new date structures. And the proposal here is really for that path ID we already have, do you have 1 or do you have mini connection at If you if we choose to say 1 and you wanna rotate CIDs. You generate a new path that looks startlingly similar to the old one, but it has on CID. I've This seems like needless complexity, unless unless I'm seriously misunderstanding certain. Clarification question, like, what you you do not believe that path ID is required as I believe we already have a path ID and it's the connection ID sequence number. Okay. So so do nothing. Okay. Like, said correct. Kristin? Yeah. I mean, I I agree with what Nious said that we cannot do away with, like, with COD rotation. What I disagree is that the problem of having simultaneous not rebinding and CID rotation. Is extremely rare if you are sending your packets back to back. Because if you are sending packet back to back, the the Nazi is not going to change the the binding between 2 buckets. The nets typically exchange a binding either when the nut reboots, I mean, for some reason, or when there is a big silence. When you have a big silence that is the point in which you might have effectively a new pass, But if you have a big silence, it's also true that your congestion control"
  },
  {
    "startTime": "00:30:03",
    "text": "should change. It's also true that, your loss recovery is probably irrelevant because if you had the silence. You don't have any package in transit. So I don't think that in fact, we have any practical problem with current solution. I totally agree with you, so we're not disagree. And the the problem that we still need to solve is if you if you are in this situation, you're not sending forward. You get, not rebinding, and you use a new connection ID. Then one end thinks it's just the same person. The other other end end will see a new pass. And so you also have the old pass still there. Might not work anymore. And so what we need to describe in the draft is how attack this quickly and then only use a new pass. So but that's I think not in editorial or, like, recommendation work. It's not changing the protocol. Look, I mean, if that is really a problem in practice, we can always do an extension with a new firm that that that that should be say, hey. This particular passes a continuation of the previous one. If that was really a problem. I do not believe it's up to you, problem we have interrupted with a current solution. I I don't think it's fuel. K. Thanks, and Martin Seaman in the queue again. Yeah. And it just wanna point out a few, a few more problems. So, with our path IDs, We don't have an, we don't have an explicit, limit on the number of path. The number of path is only limited by the number of connection IDs, which is probably higher than the number of path that you want to allow. So the the resource management, aspects of not having path IDs are strictly worse. Not having a path ID also can lead to this really weird situation where you receive a path status path a standby or path a bent in frame. With a"
  },
  {
    "startTime": "00:32:00",
    "text": "connection ID sequence number that you have already retired. The point of retiring is that you can clean up state in your in your stack. And, it is not clear to me how you can, how you can do that. Without the path ID because you need to remember you you need to remember the sequence numbers of the connection IDs because you might receive this frame and frames might might be, arbitrarily to later than the next point is that, lost loss recovery as described in 9 1002 is tied to the packet number space. So I think we all agree that loss recovery on one path loss recovery should be per path. So when you when you rotate the connection ID and you also end up in a new packet number space. Loss recovery suddenly gets, a lot more complicated. So you you you might be able to to work around this in your stack by having some additional tracking of, like, oh, these pack number spaces are actually just one space and, do some, do some math to to still do it, do loss recovery there. It's more complicated than just having a single pack in the space. Just to comment on the loss recovery, at least. So you can either try to track most of them for a little while if you want to be careful or you just, like, lose a couple of packets, which is also not problem because it shouldn't have very often Yeah. I I would also point out that, Martin, when you said that you remove state in your implementation, it's actually a sleight of hand because we you've removed state at the cost of maintaining more state for the past above that, and I think that's equivalent. Cheers. What do we do? Yeah. So I'm I can trying to listen and and collect my thoughts, as a solo chair. That's hard. But I I'm hearing those trade offs."
  },
  {
    "startTime": "00:34:01",
    "text": "I'm hearing a few people not bothered to try and do anything because what we have is kind of good enough it would help to take a show of hands and see how people feel in this room, but I wanna make sure I phrased the question correctly. So we Yeah. Yeah. I I think, we might we might have a decision at this time, but we could make a decision later, maybe in a intermeeting before the next directive. Think we still need more experience from the implementations. Actually, it's a trade off between these two solutions. K. I I would be happy to get at least a sense for where the working group stands. Because I'm a little bit lost. Where the booking groups stand. A sense of what? Sorry. I mean, this is a couple of voices, but maybe there are more people who have an opinion and didn't come to the mic. Yeah. If you do a show offense or something, I think it would be very helpful Okay. Have a few people in the queue. I'll take take them. And we're trying phrase something up. Kazura? As a whole. So And if I'm going to, show hands, I I I pointed out that the proposal is not even employed. So we don't know the details. So I mean, if we are going to take as I I think probably you can say if we have interest in exploring this possibility on that, but we cannot choose between the two at this moment. That's, Brian Tremmel, that's more or less what I wanted to say because what I'm hearing is that a lot of the a lot of the opinions one way or the other are coming from implementers who are actually trying to make this work and think we'll get more information from a future interop like, I, you know, if I'm trying to figure out what I'm going to put my hand up for,"
  },
  {
    "startTime": "00:36:02",
    "text": "that's gonna be based on just sort of like an arbitrary understanding of the complexity of the situation, and complexity is squishy and moves around a lot So, like, I probably won't put my hand up for either of these because I really wanna get a signal from from the interop on how the how this affects the implementations. So, but, actually, that's a good question. Like, who would be willing to implement the proposal. Yeah. I I think yeah. Because, like, if we're gonna if we're waiting for testing from that, then we need to have something to test. A really good point. Yep. I think we can we can propose those two questions as a show of hands. See what people feel. So give me a moment to type shit. So I'm gonna ask, are you interested in exploring path IDs further? Yes. Or no? Does that seem like a reasonable question? Yes. I'm seeing some notes. Okay? I'm gonna start that. Okay. Well, our speakers are saying, Yes. Yes. Yes. That's okay. Let me give this a few more seconds. K. I'm gonna stop it there. For the record."
  },
  {
    "startTime": "00:38:00",
    "text": "Oh, no. It's gone. Oh, no. I can I can still see it? So for the record, of a total participants of 134 twenty people said yes. Eleven people said no. And and 103 people had no opinion or take the the next question and then maybe ask I knew Hunter said no. It's why there are those questions come up and ask why, but Let's take the next question first. If I forget what it was Actually, to be sure A what? A real show event. I really I wanted names. K. The question here will be, do you have interest in participating in an interim or interop. To explore path IDs. Okay. Yes. Well, no. Clearances, So let's start this question. Yes. Time I'm gonna cut that off. Here. For the record, we have 138 participants in the tool. And, 9, yes, 19, no. And didn't turn your opinion. Plus my speaker said yes. So that will add some more in the yes. I'm not too worried about the nose for this one because people, busy and don't have time or or an implementation, but the the yes is seems like a"
  },
  {
    "startTime": "00:40:00",
    "text": "size ball number, actually. We don't have 9 implementations, right? Or like maybe we have, just let me know. Well, that'd be that's good useful information as well. So, if anyone thinks, strongly on on any of that, please join the queue. Otherwise, I think This is useful information. We can take away. Like, I'll just point out the second question completed an interim versus in Rob, So there are probably more people willing to participate in an interim than actually have an implementation that could do interrupt Correct? So I The and the point Mary is making is well taken. We should probably separately ask which implementations would be willing to implement the PRF 1 existed. And that can just be a, like, 2 or 3 people raise their hands. Yep. We have it in the room show of hands who would like to into into interrupt with this just in our implementation, whether it's open or private I'm not saying any hands. Well, I'm I'm seeing half half an arm Sorry, Ted. Bathroom Okay. Yep. I agree. So I think the action for the authors is maybe we need the proposal to understand if people would be willing to implement but that if you don't know if people want to implement it, then you're probably not do you want to write a proposal So we're stalemated, which isn't great. Could I ask folks who care about this deeply to to meet for a coffee? Maybe afterwards, and we can get together and and figure something out. To Yeah. Yeah. Like, we need to make progress on this. Some some Actually, I would There were, like, around 20 people saying they were interested in exploring that Correct. So I would like to see more people at the mic line in telling, telling,"
  },
  {
    "startTime": "00:42:00",
    "text": "be why they voted as if there's any option for Brand Tremmel. Yes. Enthusiastic. So the main reason that, like I said, before, you know, the judgment that I'm going to make on whether, Whether I'm for against putting the path ID is sort of a complex, a conceptual complexity versus simplicity thing, not an implementation flexity versus simplicity thing. And, I like it explicit signaling over implicit signaling. Right? That was my judgment. That's why I said that. Right? Like, if you have a path, you should have a data structure bit points at the path. I put my hand up in order to say something different though, to give, Lucas since he is missing a coach here, a little bit of, friendly advice from the peanut gallery an excellent way to fix a stalemate is to say that the no build option is the option that we go with. You can just say, we're going to do nothing. And then if you say we're going to do nothing, people appeal, well, now that you understand that you actually do have a strong opinion in the Okay. Thank you. Christian in in the queues. Well, if that if anyone else wrote it yes and has a strong opinion they wanna bring to the please enter the queue now. Christine? Okay. I want to know, as you might guess, and I have a strong opinion. And the reason of it, you know, is that the The proposal to have an independent pass ID from the CID makes the encryption and decryption part harder. Specifically the the occlusion. Because right now, the requirement for the decryption is that the decreasing engine, which is some some which is often offloaded. Just needs to know the c I the CID number corresponding to an exceeding CID. And that's something you can do. Unitiative"
  },
  {
    "startTime": "00:44:00",
    "text": "by saying, hey. I have this CID. I can forward you. They might be used this sometime. You have them. It's immediate. If you disconnect the 2 Then you have to have state have to have a negotiation about what is the pass ID linked to particular CID? And you need to push that to your decrypting hardware. And that's sizably more complex that whatever data structure you but in your code. So I think there's days of very strong reason. To not take that additional complexity. And that's why I'm really strongly against it. Thanks, Ted. Ted Hardy, also an explicit, signal enthusiast, like my friend, Brian, over here. I put my hand up for yes. I'd like to explore a further in part because I I see the sequence number and the path ID as doing very similar things and possibly the same. And so I'd like to see a PR where what we basically did was to treat the connection ID as a 2 poll. The sequence number and the rest of the connection ID as a tuple function as the current connection ID does. And then from that perspective, take the question of, like, what happens when you mutate? If you need to change one, but not the other, how does that work? And I that's why I said to to Lucas, I'd like to see an actual PR because depending on how you do this, if you just duplicate it and have you you have a separate path ID and a connection ID with the sequence number, you you are in fact creating more complex and I I think that that's potentially problematic. But if you actually treated them as, an identifier that's in the form of a tuple, you might be able to avoid that that comp complexity and still get the benefits that I think Martin has pointed out. So, I I would like to see a PR. I'm I might be able to help with the coffee, fetch it and bring people to who's got implementations. But I definitely fell into the willing to participate into an interim not bringing an interrupt"
  },
  {
    "startTime": "00:46:03",
    "text": "application with me part of the bucket. And I think that's part of why you're seeing a little bit of difference there. Thanks. Noted. Okay. This is good input. Yes. I mean, We don't have a PR right now because it would touch the whole draft. Think what I'd be looking for as a chair is that anyone who did want to explore this further, the please help the elders would preparing the PR, whether that just be discussion or something. We can't expect these folks to do it on their own. As we see. Some some people are happy doing nothing. And nothing will be done in that case Brian? Choose be quick. I'd like to move on to the next topic. Sorry. I'm just just heard another thing that that seems like a possible anti pattern. Would it would it make sense to write up what this sort of twofold based PID, CID system would look like without touching the draft. Like, having it be a PR, but have it be just like, here's a 3 pager that here's how we'd like to implement because I don't wanna I don't want the reason not to do this to be, like, it's messing with with the draft if you see what I mean. Right? So I I I'm not convinced think this we might be taking this to coffee. proposals are so much different from what Martin has already begun I mean, the encoding is different, but I don't think it makes a Victor. So the market has a quite extensive description of that in the, in issue 114, 2014. Sorry. But what I'm saying is it it does touch the whole Right. Draft. And I think, like, doing the exercise of actually creating a PR to see how much it does touch. Is what we're missing. And we didn't do that because if people tell us they don't want it, then I don't have to do it. Act. Yep. Yep. K. So I think somebody has a task there to make a PR. And I'm looking at Martin. And he's nodding. Oh, amazing. Okay. Thanks. I Yeah. Yeah. That's you have one more slide, but it's the next step. And I think wherever time I'm more happy with these So"
  },
  {
    "startTime": "00:48:02",
    "text": "based on the progress between now and then the next IETF, we will take a view on last call, but it's it's, you know, contingent on what happens next. So we we all want this to get done. I think is nearly done. I I really hope people can put some effort in So thank you all Yeah. Thanks, speakers. Next up. Mancy meant to talk about reliable stream resets. If I can find the slides, here we go. Okay. Yep. Yes. Oh, Sorry. We had somebody in the queue. I wanted to close the queue, but I couldn't find the button. We we need to move on, Hanyu, unless this is like, to reliable stream resets I'd ask you to put it in the the Jabber or send it to the mailing list, please. Hey. Reliable stream resets, next slide please. Too, Right. Oh, Okay. Okay. Quick recap. In in quick, version 1, you can reset the stream. Which means that, potentially none of the data that you've sent stream is getting delivered to the application. And for various reasons, we want to have a, an option to say, like, yeah, this screen is reset. And I'm not gonna transmit everything of it. Like, this short piece at the beginning, I am committing to to try meeting reliably. And please deliver that to the application on the other, on the other next slide. So since San Francisco, we've made some progress. In, in the draft version back then, we had 2 variants of this frames. Which allowed you to reset the stream, with an error code. And without an error code. And we, we discussed the and we, we concluded that having a variant that allows you to reset screen without an error code is kind of ugly."
  },
  {
    "startTime": "00:50:03",
    "text": "And, it's not clear how to implement this, in, in, a lot of APIs there around. So we decided to remove that variant. And and and and we made the update to the draft. So now we only have one variant of the stream which is, it looks like a reset stream frame with an additional field for the reliable size. We also added a lot of text describing the, The Streamesteak machine, this is most editorial but necessary to make, to make the disc description as as rigorous as we, we would like it to be we also added some implementation guidance because we have we now have, at least 3 implementations, of various versions of this graph, and we'd run run into the same problem so we hope that the implementation guidance can help future implementations to not make the same mistakes. And Coming to our favorite bike shed. The name of the frame. It used to be called reliable reset stream. Then we renamed it to close stream. Now we have a new name suggested by Martin Thompson. It's now called the reset stream at Frame, frame, And I really hope that we can keep this name. I'm I'm seeing a lot of thumbs up. Thank you, guys. Next slide. We have 2 remaining issues. One is Do we need a stop sending at Frame? So this proposed is also a proposal by, Martin Thompson. Back then it was called the enough frame, And the reasoning is is defined. So when you have quick version 1, had you the, the the the receiver of of a screen can say, like, stop sending stop sending, sends a stop sending frame, and this request, a reset screen frame from the pier."
  },
  {
    "startTime": "00:52:00",
    "text": "So now that we have a res reset stream at frame, We need the equivalent for a stop sending at which means, like, I'm I'm asking you, yeah, please stop sending on the stream. But deliver the first, a 100 byte a 100 bytes to me, reliably. The use case is not as clear cut as for, reset screen. But there, there is a use case. That we, that we came up with, So imagine the situation where your you're draining, you're draining web transport, a web transport session. You receive the second bite of the screen. Know that you don't that you don't that you will never want to read from the stream, but for, like, resource accounting, purposes, you still need to know which reference would that belongs to So in that situation, you would send a stop sending at frame that would still allow you to receive the web transport session ID. We do have some, some text in the PR that I linked here. Still needs to be updated. To the new name. But we could, we could make this change pretty, pretty quickly. Any thoughts on that? We we have some people in the queue. If you would like to respond to the stop sending at discussion. Hano, you are still in the queue from last time. If you have something to say now, otherwise, I'm gonna skip to Jonathan. Hey, Jonathan. So to be clear, this means that the receiver has to know what's in the stream it didn't receive. Right. Right. Right. Right. Right. Right. Which is, I mean, which assumes certain structures of, I mean, you assume if the web parent sort header is always a fixed size, then that works. If it's a variable size, Alright. If if what if whatever is the the"
  },
  {
    "startTime": "00:54:02",
    "text": "you need for the accounting is a fixed size that works. If it's a variable size, this is not used Yes. In general, yes, in in work front, but it's, a variable length integer. So you know that the maximum length is 8. It's what you would say. So you have the maximum length. Okay. Yeah. It still seems a little weird. That to have to know something you didn't get, but I guess sometimes you do. Yeah. The same question, even if you know the length, how do you decide if you don't know which stream it is how do you decide that you don't need to receive it? Was annoying the number. Because you you you said, like, the go go away. Like, your your grain is quick and are you draining the whole connection? Mike? So my comment is similar. I feel like We probably are still okay with stop sending because you send stop sending when you've read enough of the stream to know that you don't need anymore. And the case where say you've read enough of the header to recognize what the cutoff is going to be at which point you don't need any more Probably that date is already in flight and wait a few milliseconds. It'll be there. I don't strongly object to this. I'm just not convinced we need Yeah. As I said, I I I think the use case is not as clear as far for, reset stream at, like, there's There's the the aesthetic argument that it it restores some symmetry to the draft. Victor on remote so I'm Not in yeah. I I have the same concern about it, and I guess my outlier observation is that stop sending already kind of acts as enough in the sense that there is nothing preventing you from replying to stop sending with a resets stream at instead of 1st stream. If you know, it has some constraint, like,"
  },
  {
    "startTime": "00:56:03",
    "text": "related. Like, it's a web transport data stream. Me. Insert myself as an individual. I think I do like the symmetry of this. If I remember correctly, I've been looking in ABT core and watching RTP over quick and this question has come up. Is there such a feature, or there's been something proposed. This could be useful. Maybe it wouldn't that is maybe tying up progress on RTP of a quick that they they would like to be done or to wait for a decision to make made. I think we should try and decide quickly or not I what I don't appreciate as an individual is is really how much how much does this complex define implementation or the spec to me, it doesn't seem that much And if so, would anyone object to just putting it in and if or if people want it, would they be actually willing to interrupt that's a question as an individual, not chair. And I'll try and do some backshowing to see what this all means. Thanks. David? Do David's Ganazi, quick enthusiast. So I can appreciate that there's some symmetry here. And I will save that We don't care. The IETF does not make pretty protocols. It makes protocols that work, when we're lucky. Like, this looking and feeling good is not a good reason to put something in a draft. So I would I'm very sympathetic to the concerns that have been said before. It seems kinda nonsensical to say, stop sending, I don't know what you could even end up in some weird situations. So unless someone has a clear use case for this, I would strongly object to putting this in. It's adding work for everyone for an No one has been able to give a use case yet."
  },
  {
    "startTime": "00:58:03",
    "text": "Mirra? Yeah. Kudun, yeah, everything David said. And, also, if you really need this. You can just have another extension in Habit. Caso HOKO, I point out that, application protocols as complex as needing something like can always implement this in the application space. The reason we have stopped sending in quick VOI is probably because we wanted to duplicate the functionalities of TCP that provides us by your extra reset as a transport feature. But TCP doesn't have something like stop sending us, so it can always be a application. Frettable feature in case of quick. Tep Moe. I'm kind of cute by the way as well. A few concrete use cases do come to mind, being able to deliver letters that you know are important without their payloads is very useful in media applications. I can envision mock eventually using something like this for when you know that you're not able to get all of the segments that you intended to, but you still want the media headers because they give you really critical information. Sometimes information is required continue decoding the rest of the stream that you are gonna be receiving I think this would be very useful in cases where you know there's a fixed chunk of data only be a few bytes, maybe 10, 15, 20 bytes, you don't wanna receive the entire 20 kilobyte payload after it. This would be very useful to at least get that first chunk that's critical for other steps later. And, like, Just wanted to repeat something that I said in the chat. That if we don't do this, I would definitely support a text change to clarify that receiving a stop sending can elicit either a reset stream or a reset stream map. Okay. Because that is very useful for the media case where the server knows where it's header ended"
  },
  {
    "startTime": "01:00:00",
    "text": "K. I Hope the authors noted that request. I would just say, looking at some of the chat and hearing some of the comments To my mind, just a lot of this is kind of you're going to stop sending out some big number. Like, you're gonna over commit to guarantee you receive the data you really want. And you could just wait until you receive more data. It's potentially have a optimization and Optimizations of the cost of complexity, the protocol, don't necessarily sit that well with me as an individual. That's Let's move on. Yep. Okay. I'm I'm a little bit confused here because I'm getting getting mixed feedback. Like, I, I, I would like to, to ship a new draft version of this. Potentially enter working group last call soon. So, we need to resolve this one way or the other. And I would like to have a decision what we, what we will do. Another another show of hands. Make my fingers work hard today. I'm gonna make this easy, Do you want stop sending at Yes or no? Does that seem like a fair question? I'm seeing lots of notes. I'm sorry. Stop sending at in this draft. Somebody wants it and then wants to come along later, because could I say quick thing while you're typing? Sure. Just so stop sending. Carries an application layer error code. So for any protocol, like the example where you would want to have metadata, you could send stop sending with an error code. That means By the way, reset stream at after the metadata or after the web transport stream ID. So I think we can solve all of this without stop sending at. Okay. Thanks. I am gonna start the poll. Please get in the tool and make your vote"
  },
  {
    "startTime": "01:02:10",
    "text": "I wanna be quick here. We're seeing a a clear pattern emerging that's, a lot of no's. So Yeah. It's Timinate. No. That's that's nice. Yes. This is a clear signal. We will, of course. Thank you for that. Take this to the list and do a consensus, call, but from what we see here. We have 2 yeses that was for at some point people to change their minds. 30 knows. 110 opinions until participants 142. So Yeah. Thank you for that. Thanks for the discussion. Let's move on. The second issue is, the draft currently says that you can you can you can send, reset stream at for a certain offset, And then you can, at a later point, send another, reset stream at frame. With a with a smaller reliable size. So the last part is important here. You can only ever reduce the size. You can never increase it because you don't know if the, if, a receiver has already delivered everything, up to the application and declare that it's done with the stream. This isn't a draft. It's, I, I've, I found it easy to implement in, in, in my stack. But there was some discussion in an issue if if we want to keep this around. Martin Duke Google. How how can you guarantee that that, like, it arrives in the order that it is always decreasing. Like, with with, like, losses of your transmissions, could you end up accidentally increasing it? So so so this is the same as with with with flow control updates. We say, like, when, when you receive a frame, you check, it's is it increases the offset. Okay. So you just so it's actually the lowest of all the and adherence. Yeah. You you you you only act upon the reset stream at frame with the lowest reliable size that Cool. Thanks. Like that."
  },
  {
    "startTime": "01:04:04",
    "text": "Things that make sense, and we still want to support reset stream, regular for reset format, and Reese's stream regular is kind of equivalent to Reese's stream at 0. So but just it, it should be fine if I encountered that this is not fine during implementation, I will make sure to complain, but k. Okay. Is that is that clear enough to the authors? Yep. Yeah. This is this is very, very helpful feedback, and it means that we don't have to change the current version of the draft, which makes the editors happy Okay. So, I guess this is a question for the chairs. We can, we can cut a graph version basically right now since we don't need to make any changes, we're starting working group last call anytime soon. The from what I've gained from this discussion, I I think that's probably a thing we should do. I will need to confer with my coach So it's not opening this week. And and will respond and let people know either way. But, yeah, thanks. And I I wanna remind folks this this this extension is an enabling technology for other working groups. We're able to adopt this pretty quickly and turn it around. So I'm I'm very, very pleased with with that. It's been good work from all involved. Of course, if there's implementations just just keep going and and maybe try and find any bugs while we're doing that working group mask call. Great. Thank you, Martin. David is still Just, speaking as chair of the web transport working group that's relying on this, thank you for doing it quickly. That's been really great and appreciated. It's gonna help us a lot. Thanks. Cool. Now we've got Robin"
  },
  {
    "startTime": "01:06:01",
    "text": "It's q log. Oh, Robin's asked to share flight. I don't know. Are you gonna are you gonna progress? Or Alright. Mary is coming to my rescue. Hang on a moment. Basic Yeah. Here we go. I Let me stop Look at that. Trends Hey. Hey. Hello? You attended my US MRG, talk. Earlier Jonathan. You'd know why I didn't attend the trying to schedule for this. Anyway, sorry, Robin. Please please refresh my Alright. Hello there. Last time we had the Barbie updates. So this time, of course, we need to have Oppenheimer updates to close the loop. Oppenheimer's is up for today because we are dropping a big ball on you. Maybe we'll see. There has been relatively little progress in the draft since last time. We have added some ECN events, and we have some the total updates. Remove the IANA considerations because we don't think there are any but then the main thing we need to do today is get your input into issues that we didn't merge yet, because they're relatively big or sensitive. First of all, the easy thing, though, we had an ECN. This congestion notification we think what we added is sufficient to support whatever is needed there in the full state machine. However, if there are any ECN enthusiasts that would like to take a second look at this though it's merged already that, of course, always be welcome And then the big one, that we want to discuss today is to maybe remove Q back from the core queue log documents to move it to its own document and postpone until later."
  },
  {
    "startTime": "01:08:01",
    "text": "Why is that we currently do have conceptual Cupac support, but it's very close to the wire image. You have events called things like set dynamic table capacity in instruction or literal huddle The literal Heather field with name. Records very easy to pronounce and immediately clear what they do. But still people want some more high level events probably there as well. Things like indicating when something was head of line blocked by a late q back in construction, for example, when things were added or removed from the dynamic table, And those are the kinds of events that we currently Black. And it would arguably most would be most interesting to more high level implementers or debuggers. Of higher level stacks. We've tried this for a long time, but we can't seem to find people with actual, implementation experience or debugging experience of qpact stacks that can tell us which of these events would actually work best in practice. For this type of, this type of debugging. So, basically, we don't really know what these high level events should look like. To be most useful, And so we would be, like, fantasizing about what might be best. So We we would be doing the equivalent of no running code or no interoperability. Not something we're looking most forward to. Second issue here is that this is currently actively blocking progress. So we think this is the last big thing wouldn't be needed to fix for for even thinking about a working group last call. In the future. And so one potential solution would be to move this to a separate document. To be tackled later. So move out of the cure the the the core 2 log documents and then tackle it later. We have some precedent for that. We have many quick things like multi parts or reliable stream recess that we just saw. Those course, also won't be in the QR code documents. So that's possible. It's just that this was previously agreed about that it would be in the court documents."
  },
  {
    "startTime": "01:10:00",
    "text": "And then now we're proposing to move it out. I think all the editors currently agree that this is the better option. To allow us to make progress. But if any of you have different opinion, and preferably also an idea of what the high level events should look like. Then you should probably speak up now we're on the mailing list. I think we have people in the queue. So Yep. I put myself in just as a as a author, just to clarify that one Well, maybe Robin made it clear. I just wanted to reiterate the point. When we say move, it doesn't mean the text we have would go somewhere directly. It means somebody else would go and do all of the work that we dumb, all can't do right now. We have a PR, which is just deleting everything that's in there already. Tax was was the tax that was in the adopted document. That's why we wanna make sure that the working group is happy if we were to take it out That's all. I'll let the folks in the queue go. So Alan Alan Fendell, Meta, and QPAC enthusiasts, I, I think I had commented on you in q log, or at least I had worked with Luca who maybe relayed the comment when we put our heads together. About what the high level events would look like. And so is Did that maybe not get to you, or it was information was there, but not translated to a PR in a timely way. And it's blocking you now. I would suggest Lucas take this one. I I would say, that did make it through to us. But as as having a PR is just step 1. You know, we we're short of cycles, this is an important thing. Is that anyone reviewers or proponents of the things, but, just having some stuff doesn't necessarily mean it's it's correct for everyone. You folks have been Daniel things, that's great, but other implementers might need stuff that's like different. And what we're not seeing is any implementers"
  },
  {
    "startTime": "01:12:00",
    "text": "want this. And if those events aren't useful, this is just more tag or more things to to have to do to delays. And we would like to just get this doc done. Yeah. So I understand. I mean, I think I, you know, I have done extensive debugging on our QPAC implementation using my own spoke logging rather than key logs since key logs had an option. And I don't really have time to write FPR for you, and I don't really have time to to implement the the queue log events either. So the next time somebody says there's a QPAC issue, which by the way, there never is. It's always a transport issue. I'm not sure that I can help you. So if if it's blocking you and there's nobody else who cares, then I I'm okay. Of it. Cut. Cut. Cool. I've locked the queue here, but we'll we'll drain it, Brian, please. Having dealt on multiple occasions in my career with having to deal with, choices that were made around a single implementation for debugging and logging stuff, including one that I have to deal with. In production, every day. Was my own damn fault, Nougat. Okay. Thank you. Q. I can be here now. Yeah, I say move this own document, qpark is its own RFC, saw what its own specification for Q log makes sense. If this is what everything's getting dotcom when there are so many more useful things in q log that we could just push this atomization. Do it. Thank you, and, Mira, Mhmm. I just wanted to comment on the end part quickly, and maybe it's just an editorial issue, but maybe there's something Can you go spec once in it? Robin? Because it says, like, capable, and then it says, like, now sending with ET, ECT 0, but just because your capability doesn't mean you also have to use it. Maybe it actually makes sense too. Keep that separately. And, of course, you could also use ETC 1 for FS. And you can change that anytime. Right? You test at the beginning, then the pass is capable and then"
  },
  {
    "startTime": "01:14:00",
    "text": "decide anytime if you wanna use it or not or whatever. The Okay. It sounds like we should talk to some more and tweak their stuff, and that sounds pretty really trivial to accommodate So, yeah, thanks for that feedback. On this I'm not hearing anyone objecting to the key back thing. So again, we'll we'll probably take this to the list and just make sure everyone who maybe isn't here has an ability to object, but, otherwise, it seems clear in we should just remove this thing. Please progress. Robin? Yes. So the next big thing that has been around for a while is how to deal with Parts stuff and connection migration and associating IP imports. With individual events, we've been dancing around there for a long time. People had opinions, but no clear, proposals. So I went decided to go ahead and launch a first proposal. Right? So this is what I think is sufficient. But this as a starting point of more discussion, the idea would be to just have a path field for each individual event, like, a top level field is what we call it. Next to the time stamp and the name and and the data you would have a part and the barber says the string string string can be anything you could encode the IPs and the and the ports the connection ID in there directly, which is somewhat okay for ipv4. Somewhat less okay, maybe for ipv6 as we can see. You could only encode a connection ID. You could encode a hash of these things. If you don't want to log the the stuff directly for privacy reasons. You could even, like, choose any type of string that only makes sense to you and your own private. Implementation, anything goes. Price. Now the thing is if we would have only this, would be kind of annoying if you really want to have this this magical state forecasting inside of the path ID. So what I propose to do is just have the part ID to be anything you like. And then have a separate event that couples the part ID string"
  },
  {
    "startTime": "01:16:01",
    "text": "to the specific metadata you would like. In most cases, this will be your IP. Your ports and then 1 or more connection IDs. So, basically, the path ID will be can be very short. Even just a number that you increment. And then the actual association with the part information happens in a separate event. Is currently called path assigned, but we can we can bike shit that, of course. One of the nice properties of this is that you can keep updating this metadata. You just log a new path assigned event. Same fault ID, but but new part endpoint info. What I've called it now. You can also just have, like, a default bot ID of empty string which indicates you're not doing anything special with us. You're normal quick connection without multiple files for connection migration, which most people have been doing with Q logs, so that's kind of it's it's nicely backwards compatible. There as well. So relatively simple, very generic, very flexible, I think it covers a load, and it makes it possible to associate policy information with each individual event. Which is what what is often needed, I think, which is still missing You could then use this if you have the parts field, and then you can look at path response and path challenge frames and things like preferred address. And you could tools can can somehow come up with what the implementation trying to do with connection migration. Just by that. I do think it's useful to also have, like, an explicit additional events. To indicate when you're trying to do connection migration. The tools don't or the people looking at the key logs don't have to manually figure it out. You also have explicit events that tell you this is happening. We have other similar events in q log there as well. So this is kind of superfluous, but it's nice to have this explicit indication if if you needed, for some reason,"
  },
  {
    "startTime": "01:18:00",
    "text": "And so that's what this new quick migration state updated event would would add, which is especially interesting. I think if if the migration fails, or do you have to abandon a probing attempt to that kind of stuff? To log that explicitly and to maybe log a reason why you abandoned, the attempt there. To make that easier to debug, basically. So Basically, I just propose to have a parts part ID for each individual event. This is then associated with necessary metadata in a separate event, so the path assigned event this can keep the part ID very short, so it doesn't include need to encode any information in itself. This also makes it much easier to make it privacy aware You can either strip or skip logging IP and ports and connection IDs. And then you can also be more explicit about the connection migration with one additional event. So it's a relatively small change. Conceptually that does what it should do. There was a lot of discussion last time as well. About, you know, the main thing you need is tooling support. Also for things like multi parts, I think this provides it I discussed this a bit with, Kanta from the multi part team from definitely not a multi part enthusiast. Sorry. But from What I can understand from how multi part works and the connection ID stuff. This should work out of the box. And even if it does not, it should be trivially extendable to what multi path needs with, for example, a custom multipalt assigned. Events to couple the path ID to to whatever you need there. Also have tools, make make use of that. That's basically the end of this. ECN is added. I think we get a clear signal that we can move queue back to a different, document we'll see on the mailing list there as well. And then Please take a look at the the path proposal, which is in the PR right now, should take as a good starting point."
  },
  {
    "startTime": "01:20:01",
    "text": "To moving forward. Just one thing to be aware of We explicitly don't want to add full multi part support in this yet. That is out of go for the q q like documents. But if whatever we come up with has, let's say, 99 multi parts supports that would, of course, be the most excellent outcome Thank you. Miria. Yeah, by adding a pass ID, you can nicely covers migration case where the pass ID or the connection ID changes, but it's the same pass. And then have that notion as well. But, I feel for any kind of ek information or packet number information, you still need the connection ID because every the connection ID changes the packet number space changes when the connection ID changes. Say, if you have this concept of past, you might still have the same past, but if You have a new connection ID. That number doesn't make sense anymore. So you you then need to know what what which connection ID was used in order to make sense out of the packet number. Yes. So you you can associate multiple connection IDs with single part ID. As you as you can see it on the slide as well. The connection ID 0 or a list instead of a single one. As far as I understand that that should be sufficient, but that could be wrong. But then you you receive an event that you say egg received, Right? And that has a pass ID and a packet number and that's not sufficient to actually identify where it belongs. Okay. For multi parts, not for quick. Right. So for multi path here. Okay. The just trying to check, we we ideally wanna focus on the core specs, but this sounds like something we could add like, trivially later. Probably, probably. So we we might want a bit more discussion. I put myself in the queue because I wanted to say, Quentin's multi pad stuff and, well, Quentin"
  },
  {
    "startTime": "01:22:00",
    "text": "contributed connection migration to clarify's quiche. As quiche does q log that I've maintained. I wonder if there's just of maybe experimentation we could do, Robin, offline, to see, you know, can can we make this thing work and and get some tooling to analyze it as well. That's some clarification. So it might come back to to to Mary as well with some questions. But this this is a big step in the right direction, I think. I've only just seen this today as well. So there was some thumbs up in the room as well, Ruben. So, yeah, thanks for doing this. Yeah. Let's let's progress on. We have next step on the agenda, Martin Seaman. With Nutriversal. The what? Oh, okay. Yeah. Yeah. No. I do not want to share my screen. Yeah. I'm here to talk about, peer to peer quick. I've submitted, two drafts for that. And we'll start with the first one, which is, pretty easy one, and I don't wanna spend too much time on this. Can I get the time on this? Yeah, let's just hang on one note. Next slide. So, Okay. Thanks. The question is, I got it. Assume you are running a quick note in in home network or corporate network, behind any kind of firewall behind any kind of mat. You don't know the public IP address of that note. So what you can do is because we designed the quick header, to be a protocols, in particular, with a stunt protocol, as we discussed earlier today, you can run"
  },
  {
    "startTime": "01:24:01",
    "text": "a UDP socket and then run stunned on that socket and run quick. The same sock And you can use stun to contact any stun server that you like. Learn your public IP address and then you can also run quick traffic on the same token. So that works. Next slide. But what if we, what if we could do all of this quick so we don't have do any de multiplexing so we can use the, quick grease bit extension and just don't have to run like multiple, multiple things on the same. On the same target. That's what my draft describes. So there's a defines a couple of frames. One of them is a request address frame. Which are sent on a path. And Request the other peer to tell me the observed address on that path. And then it sends back an observed address frame with that address. Next slide. So that the nice thing about doing this in quake To that change. Slide. Yeah. Okay. Is that this beautifully works when you have multiple paths because you just can just send a request address frame on the other path as well. Get a response there. Next slide. The, as I said, the draft defines a couple of frames we've already seen, request address. We have already seen the response to that. Was it which is in observed address frame, and there's a, request declined frame if you don't want to answer such a request. Importantly, these frames don't only work in one direction from the client to the server side, but the server might be behind on that as well and might also want to learn, might want to learn, the address. So they can be sent in other direction as well."
  },
  {
    "startTime": "01:26:04",
    "text": "All these frames are defined as probing frames. So you can send them during path validation and bundle them with path challenges and path responses without actually committing to a new path. Next slide. I would like to ask if there's interest in this kind of work. In in the in the working group. Already sent this to the list and received a number of of responses. One of them was from from Igor, and he was he was asking if request response is the best solution here. And he proposed that there should be an unsolicited frame that that I can send whenever this, this extension is negotiated. I want to tell my peer about, the IP address on a new path. I I could, I could just send the observed address frame. Without any request. Don't wanna get into too much detail here in the interest time, it's just saying that there's some, there's some work to do in, in, in that area. Thank you for presenting this. I think this is fairly easy to implement. They're regarding this question. I think the current request response protocol without any flow control has the some problems that we experienced with HTTP to rapid reset attack. And I think moving to about eagle propose makes perfect sense. And it also improves reality, as you said. And regarding the previous flagged. I'd probably say that it this frame doesn't have to be defined as a probing frame because we can always send this on the path that's already known to work. If we go to connection ID, sequence number in the frame. Okay. Yep."
  },
  {
    "startTime": "01:28:04",
    "text": "Hi, Colin Perkins. You can clearly do this, and it will clearly work and in many ways, I think it's a good idea. Where I think I'm a little concerned is that, we currently have one way of doing that traversal, which is widely used by a lot of different locations using stopped And I'm a little concerned about fragmenting that so we have different ways doing it's And as a result, people stop supporting stun or stop blocking stun traffic. Because everyone do everyone in importance is using quick, to do natural reversal. And that then costs you a bunch of of other applications to break So I agree. You can do this. I agree from point of view of quick. This is a good idea. Think we should think a little bit about the wider implications. Of whether it makes sense to do it for a broader ecosystem point you or whether we want to stick with just the one way of doing that traversal to everyone who even if that's suboptimal. Thanks, Colleen. Mike Bishop. I agree that you probably don't want a request frame here, but I think the the way that you get a request is to separate your setting into separate I'm willing to see these frames and respond to them well. And I'm interested in receiving an observed address whenever you see my IP address change. And I understand what this setting is. Maybe you don't even need the second one. It's just I'm Well, yeah, you need the negotiation to agree that the frame exists. Yep. Yep. But you can have a separate setting for, I would like you to send Yep. That makes sense. Peter."
  },
  {
    "startTime": "01:30:03",
    "text": "No. Peter just left the key. If you meant to hit, yep, Sorry. I meant to hit the unmute. Can you hear me? Yes. So two questions. First, does this happen before or after the handshake. This happens during the lifetime of the connection. And during the lifetime of half. So it does allow you to observe, net rebinding it's No. I I just mean the the crypto handshake. Do you have to do the crypto handshake before you send this or Yes. These are frames that I sent in the application data packet number space. That means, 0 RTT and 1 RTT packet packets, I don't see any use case for adding them in the, the initial packet because that would make them observable to on path, to to to everybody on the path and I just don't see why we would need to do that. So in the with without 0 RTT, in in the one RTT case you'd have in extra round trip compared to stun Is that correct? Because you'd have one RTT to do the handshake and then a second one for requesting and retrieving the address. I don't imagine that this would be a replacement for stuff. So the this this would be more applicable if you're running a a peer to peer node that's handling a bunch of quick traffic anyway. And you are now using that quick traffic to also learn about, your address. But that's the whole reason for stun So it seems like you're creating done over quick, which is I just wanna understand the pros and cons. Another one is a authentication. So has a built in authentication mechanism."
  },
  {
    "startTime": "01:32:00",
    "text": "He's, sir, gonna be a mechanism for authenticating to a server that's responding to these requests. I'm not sure what what you would want to authenticate here be, beyond the encryption that quick already provides but maybe I'm just unfamiliar with what's done exactly just there. I I don't wanna get the bogged down in technical details of a drive that's still in and No. Not even adopted yet. Can can we move on to the other one we have Mike in the queue. I don't wanna run out of time for these things. So Okay. Yep. Let's move on. I did see see the people coming after I locked that queue. I think let's go to the next set of slides and and keep your questions. Yeah. Yep. So that's about, actual quick net reversal, and I already did a speaker end of that in in San Francisco. And now I have a little bit more time. Since San Francisco, I completely rewrote the draft. Based on feedback I got on the list and, in the room, and and And, Eric Kanir from Apple joined as a co co author of the draft. Next slide. Okay. So quick version 1, quick question. 1, the assumption is that the server is always publicly reachable, very explicit about this, in the text. Only the client, might be behind a net or a firewall. That's why we only have to deal with, net rebinding on one side of the And, we also say, like, connection connection migration also only happens, the client side because the server is, probably in some kind of data center in Hess. A stable IP address. Next slide. Next slide."
  },
  {
    "startTime": "01:34:02",
    "text": "So the purpose of this draft is to make, quick work in the peer to peer use case, meaning where both nodes might be behind, in that or a firewall. There's a bunch of use cases for this. For example, you could you could imagine that once a WebRTC over quickest defined you would need a way to get through these nets to establish an extra peer to peer connection your video call. But there's a lot of other peer to peer protocols that would benefit from this as well. Next slide. Coming back to the question that was there was raised earlier. Do we do we need to do anything? We already have sun. We already have ice and you can reasonably run ice on both endpoints. Let ice do all the all the natural vessel or the whole punching. Take some time. But at the end, if possible, you will end up with a, peer to peer path. And then you start your quick server and your quick client, and you can just establish a direct connection there. Downsides is, obviously, takes time. This whole punching, whole punching requires, like, transmitting addresses back and forth, requires sending packets retransmitting packets so it takes, it can, can take a couple of also requires you to run ice is something that you might or might not be willing to do. It also run, requires that you run a non quick signaling server. So that the 2 ISA agents can talk to each other. Next slide. So what if we could do all of this in quick? We could start from a proxy quick connection that was served as a signaling channel between the two notes. Example, our friends in the mass working group have been working on exactly that. Called Connect UDP. Listen. And it allows a note to expose"
  },
  {
    "startTime": "01:36:01",
    "text": "a, to, to ask the proxy to, to allocate a a UDP part that other notes can connect you. So we have a way for, 2 nodes behind a net to establish, a direct connection between each other. A direct quick connection. Which means we can already start whatever application protocol we want to run on top this connection. So you could, you could, just establish the proxy connection and start start setting up your your WebRTC session. And start start your video call. You could then that second step would be to use, quick path probing as described in in in the RSC. To, to actually create the net bindings that will then in the 3rd that allow you to, to to establish a direct path between the two notes and migrate to that path. There's a slight change that's required to, to what we've defined in RS 9000 because an RFC 9000, it is only the client that initiates the path code. The server doesn't send any, any pro packets until it has heard from from the client. So we need to need to allow that Next slide. So the let's let's go a little bit into detail how these steps work. In the first step, this We set up the proxy quick connection, and we we, negotiate the extension a time, I'm proposing here. The server then sends a list of address of its, public addresses to the client. And How how would you arrive these addresses? Doesn't bring your matter here? Could have you just done? Or it could have used the, the extension that I just presented early. These addresses go in to a, a new frame that we're defining. It's called an at, at, address frame. It can be sent all at once, or the server can also trickle these addresses or"
  },
  {
    "startTime": "01:38:00",
    "text": "critical is like ice terminology for like, oh, I'm discovering an address a little bit later, and now I'm also sending it to the client. The important bit here is that this is, this is a one directional thing. Only the server is sending the addresses. The client has never sent transmitting its addresses to the server. Next slide. The client then receives the service addresses and it goes to its own list of of IP addresses. Public IP addresses that it has informs the candidate pairs. You have very similar logic, like this in, defined in eyes where you pair addresses that could potentially be on the same network and that could potentially be, allow you to to, establish a direct path. For example, if you have an ipv6six address, you would of course, like the the other address that you're connecting to, but also need to be an ipv6 address. And this. Various rules about, like, local and, and, like, public IP addresses. How exactly the client does this matching doesn't really matter because it's only happening on the client side, but I don't see why we we couldn't just reuse the logic that's described in the, in the ice RSC. Next slide. Next step. The client now takes all these all these pairs that it has generated of IP addresses and sends them, to the server. So now both peers have the same view of what's going on Like, these are, like, 3 3 possible combinations of of, pass of direct path between the two notes. Now both, both of them, send probe packets. These are, normal, quick, quick probing packets to see if the path is actually is actually a viable path. By sending these packets, this creates the NAT bindings in the routers on both sides will then allow the other peers packet to make it through. So this is the whole project step."
  },
  {
    "startTime": "01:40:01",
    "text": "Timing is a little bit critical here. So you need you you obviously need to create the binding in your router before the other PS packet can make it and make it through. So it might be necessary to to retransmit, retranslate the packet after a short while, to catch some corner cases. So now let's assume, sorry, previous slide. Let's assume that the nets are well behaved and we can, we can actually punch through them. And we end we might end up with one pass. With the direct path between two notes or we might even end up with multiple paths. These are now, inactive path according to to what quick version 1 defines. But now the client can initiate a quick connection migration and migrate the entire connection to a to a direct path. Next slide. So this is, is really nice because We started with the connection. We already started the the the video call on the proxy connect and And all of this, what I what I described was happening in the background and the user didn't notice anything of now that we have the direct path, the the call can continue on on on a on a more optimal, the more optimal route optimal route between the two pairs A question that I I I got, I I get basically every time that I I present this is do we need we need to make, quick multi path a requirement I don't think we need to do Because in both quick version 1 and in quick multiple paths, clients are already allowed to to probe multiple path at the same time. Similarly, in both VV1 and in multi path, the server is not allowed to probe path. We need to we need some additional lodging. To, to allow the server to actually do that. The advantage you get from MultiPath is"
  },
  {
    "startTime": "01:42:00",
    "text": "obviously, you can use multiple paths. But that's just an optimization that you can get. It's not a requirement for for this extension to work. Next slide. This is a pretty early draft version. There's still a lot of work to do. And there's a lot more open questions than I than I put on the slide. For example, you might, you might wanna probe a lot of path at the same time. And, probing a new path requires you to have a connection ID and usually quick implementation set an active connection ID limit of 3 or 4. You might, you might run into this limit pretty, pretty quickly. The other thing that there was brought up in AVT Core whenever presented it in San Francisco was that there's, that you need a little bit of bandwidth for the the path probing And in some, in some cases, that might be more than is available to you. I'm not sure how how critical this is and how common this is, but this is something that that we need to think carefully about. And then The last one is kind of important. The client is asking the server to dial, many addresses in parallel or to send pro packets to many parallel addresses in parallel. So we need to be careful here that we don't create an amplification vector. This is not a new problem. We already have this during the the quick handshake, and we have this during connection migration, but we need to be we need to be careful here that we don't build a NEM Okay. We are time, we have four people in the queue. I'd like to hear from them, but if they could be very brief, be, amazing. Peter, And could you scroll back a couple slides to the one where you were saying something along the lines of we don't do ice. Which one?"
  },
  {
    "startTime": "01:44:03",
    "text": "I don't right there. This one. Yeah. That's the one. So when you say it doesn't in this new way, it doesn't require running, guys. I think a better way of saying that would be you're doing ice it's just you're using quick packets instead of done back stunt packets because you're using all the same techniques. Right? And while I think that that a very interesting idea to explore. It's also gonna be a a lot of work. After experiencing doing ice biz, And so I think it would be very important to enumerate the benefits that we expect to get from doing it replacing spam packets with quick packets, basically, The the 2 other things down on this list, they don't think are accurate as, benefits I could think of, say, 7 or 8 benefits off the top of my head, but I think before delving into a tremendous amount of work, we should really understand the, benefits we'd get and have a good understanding of the amount of work, which I think is quite significant. Thank you. Jonathan. Yeah. So, My first point is I've think In most cases, certainly for the WebRTC use cases, you're still going to need some sort of rendezvous server since a server that's behind a net isn't going to have a cert certificate signed by a CA. So if you have, if you have self signed certs, you're gonna need to exchange fingerprints. Which is going to require the out of band signaling server before you can get connection up. So at which point, I feel like you know, the sort of the somewhat convolutions you go to do not need a that pre that that early that,"
  },
  {
    "startTime": "01:46:00",
    "text": "Not need that signaling server. It doesn't actually gain you anything because you still need to exchange the other thing is that This does require that the server maintained a publicly routable address you know, it it may be on a a mask server, but it's probably the right of address. Ice doesn't actually require that ice ice with turn, you only accept connections from the other side's candidates And so I'm worried that that's more exposure because anybody can to start probing you and try to connect you mean, obviously, the fingerprint exchange is not as big a deal, but it's still a little worrying. So I I mean, which I think you might be able to get away with that if you do have the the external tree change the extra rendezvous, but I didn't think about and probably we should talk about that offline. Like, but I do do you have time after this? We can Colin. Can please be as brief as possible? The Con Perkins. The brief version is a group Petefetcher. Okay. The the reason ice works is because of the match algorithm and because of the multiple round trip times and the proving. That's spectacularly hard to get rights and you're not going to be able to beat it by be implementing this in click. So I would really urge caution. There's a lot of hidden complexity in ice and the timing and the the multiple round trip times in the process is critical for making it work. Good night. Just respond to that. Yep. Yeah. So so in the very first version of this graph that the one that I presented in San Francisco, we were basically duplicating what we're doing in ice. This one is not duplicating what we're doing in ice because the errors matching is only happening on the client side. So you remove a lot of the a lot of the logic that's required to to make sure that both peers are whole punching the same address at the same time. I I would urge you to check"
  },
  {
    "startTime": "01:48:01",
    "text": "check that that works really thoroughly because a lot of the complexity and ice was because people found chronic cases months after the initial algorithm was specified. And we had a horrible, horrible time defining the initial version of ice. Because people kept finding cases where it didn't work. So if you simplify that, be really careful. K. Thanks, Colin. Luke, very, very briefly, please. Yeah. Agree with everybody in the queue. And I also say, do we need an extension for this? Could we have something on top of quick that just shares the IP address? Like, you know, stun. I think there's a layering thing here too. Thanks. This is, like, the second time this has come to the working group as people seem to feel passionately about different aspects, whether it's a technical solution or not through the work at all. Or that it could be hard. I think what we're probably looking for is is a sufficient interest that that naturally related work should be done in the quick working group. And the right work to actually do is is a factor of that too. So think I think I think I'm not talking about adoption or anything right now, but I think it would help to get a clear signal if if of interest in trying to do that. That is probably a discussion with the DAD as well. About these kinds of things given the relationship to other working groups in in the area. So I want to take a very quick show of hands probably gonna be a really badly written question, which is gonna be is the, are you interested in adopting that related work into the creek. What great So doing not related work and working group. NAT related in general. I don't wanna make it specific to any particular draft or ozole, if you have something great. If not, if there's other people who wanna suggest ideas, 2, then that's the discussion we can have later on. And I can't type"
  },
  {
    "startTime": "01:50:02",
    "text": "Okay. I'm gonna start that, and we need to be brief, just answer as quickly as you can, and then we'll wrap things up. If we have more time, I would ask anyone saying no to check to the mic, we do not. But if you wanna take your opinions in favor or against to the mailing list, that would be great. Or directly to the chairs. That'd be very helpful. So I'm not against it. I'm just not interested. Right? That's what you're asking. Yeah. That's a bad question. Hey. Where's my coach here? Okay. For the record, We'll stop that. That's a 135 participants, a 134 participants, 20 11, no, and 103, no, you know, Let me go in and address those numbers and speak to some people. Thanks, man. Great. K. Next step we are compressed on time. And we have a few other things in the as time permits. So the accuracy time stamps I'm not sure who is presenting that on behalf of Meta. Hi. This is Charlotte. And I'm calling this on Miller Park. Great. Would you like me to run the slides for you? Or Yes, please. Yes, ma'am. Okay. Go ahead, Chuck. Greg. Hi. So I'm sure Jesswell, and I work at Meta. We wanna start the discussion about, reviving, an RFC draft which which is a quick extension just to to basically describes the variant of the act frame that allows, the receiver to convey the stamps on when factors were received we have implemented this job here at meta, with the applications that"
  },
  {
    "startTime": "01:52:01",
    "text": "range from bandwidth estimation to condition detection that we will touch on time Bomas Right? So, so Very quickly. Next slide, please. Listen. So, the time stamps and wind packets sent and received already a critical ingredient of, round trip measurements and panic estimations and quick one issue with the, with the existing granularity of measurements that it all depends on the frequency at which act packets are sent by the receiver. So, let's assume that that, you know, a a common frequency would be, let's say, 20, and and we can every 20 packets. And if there are any network fluctuations that affect us, of packets of these packets or happen at the time scale, that's, a shorter than when the act was sent, then then these conditions will currently be replicated. In terms of what we can infer about the next time's next next next slide, please. And, this this this problem becomes particularly interest so important when you're dealing with latency sensitive applications. And and at the intersection of these applications and say wireless net. X where where both the scheduling algorithms and condition conditions can, you know, obligation. So, so So so so the the the the new draft, the the draft that we wanna talk about, let's go to that. To quit Next slide. So, this was a draft that was submitted by, Smith and, sue it at all. I think last year, and we it interesting, and we went ahead and implemented it. I will, in the interest of time, not go into a lot of details about the implementation details of the draft but, we'll we'll"
  },
  {
    "startTime": "01:54:02",
    "text": "quickly summarize on the salient points. The the the extension basically involved on initial transport negotiation. In which the here conveys sorry, in which the each endpoint conveys for the beer. How many time stamps it expects to receive from the endpoint. Right. And and and whether the timestamps are enabled. It conveys an exponent that that is basically signal to what's the granularity at which it expects to receive these time stamps or what's the validity of these time saying could it next slide, please. This one. No. This is the this is the, basically, the meat of the extension. So the the extension basically is proposing a new frame, the accuracy is time time. Train, which basically carries all the fields that exist in the current act frame and and the the the the the new fields basically in code, how many timestamps are being sent and, and and and some more information about uh-uh, how they're being sent. So so let's talk through that quickly since that's, I think, somewhat important. So the basic area in the exclusion is that the time and as ranges, Okay. And each range describes a series of contiguous packet received time stamps. In in descending package number. And, timestamp order. So so so so and and each range consists of a gap indicating the largest packet number in that range. Followed by a list of timestamp deltas. Cribing the related received time stamps for each of those packets. So, the next sort of explains this a bit more pictorial. You can we go there So so,"
  },
  {
    "startTime": "01:56:00",
    "text": "So, yeah, so so each each the time stamps and encoded is ranges just like act And as I mentioned, the gaps indicate the the, and and and critical aspect of this coding as the timestamps are not sent for out of order packets So gaps indicate impact of which of those gap gaps in nature of the out of order packets and and the data as an indication of what's the what's what's the time difference when the backup is received versus the previous pack. So right. So so this is how this is what the RFC has now. Let's go to a minor extension we did to it. Which is in the next slide. So, as I mentioned, there are Eric's time sense and not for the further packets. And, 11 ex 1 extension we did in our implementation to also convey what was the latest receive fax number and the latest receipt, Practictine Delta was for when when when this act when this accuracy time frame was sent. Now, having some information is actually quite useful. Because assuming that an act was sent for an out of order packet, then then, it it lets us know that this this act particular act percent for an out of an out of an auto packet. And assuming that, you know, the previous act 4 even act for the actual largest package that was received lost, it it tells you that that that basically it it actually helps you correct a faulty RTT measurement that could have been done. Where they build because this this would basically have been after this that that was delayed because it went out for the back So so, so this is actually another interesting aspect of this RFC that, these received time stamps not just give you a more fine grain visibility into network conditions, but we believe with some extensions"
  },
  {
    "startTime": "01:58:02",
    "text": "it can also convey a lot of interesting information about when out of order packets happened and what was the tint of the delay of the out of order pack. Right? So, let's move on. Interest with time. So this is just an, illustrative example how we are using this Rx time stamps in that matter. This gray box in the middle, basically, you say it's just an up traction or kind of a wireless cellular. This could be a base station or a Wi Fi series. And the basic idea is as that as condition occurs, then then, I mean, it it it manifests let's assume that, a package was sent in a burst from the sender when condition occurs in the last mile link, it manifests in either the packets, the the burst can be aggregated at at the wireless link or basically getting spread out further. Right? So so, basically, matching the Rx times terms, the standard time stamps, and and looking at these patterns of the inter arrival times of bus. So the size of the bus you found him to be, pretty useful signal in in detecting, when when for example, the network rates went down due to due to actual contention and conditioning wireless networks, and and also for basically more fine grained bandwidth measurements that that have been very used will fall especially low latency video applications. So that's the That was the second slide after this. Which I kind of did give a preview of before this Can we can we wrap this So I think I think I'm pretty much at the end. Let's go to the final slide. Yep. So so, So so, yeah, I just want to pause and gauge interest from the room. Firstly, of of of reviving this, RFC draft."
  },
  {
    "startTime": "02:00:00",
    "text": "For which we have already implemented and got some real world experience out of of And and I also want to particularly ask this question on whether there's interest in expanding on this draft to carry more information, of of, about about all of our eyes to this Okay. Does not touch upon that as much as you could carry more information about all of other package that we believe, could actually clean, useful in in, in other proposals, like, you know, tariffs to return and stuff where in the folder of ordering may be even higher than the typical network conditions. So Okay. I'm gonna I'm gonna stop you that. We're we're at time or over time, and we had some other as time permits talk we've not been able to get to and I'm very sorry to do people. We have some people in the we haven't got the time for that discussion. There's there's been a few, drafts, relates this topic, I would encourage people who are interested in it to discuss some more. And maybe come come back to the list with more experimental data or more proposals, and we can discuss that. We did have some topics talk about fec and quick and to give some data about people's experiments we don't have the time to get to that. I'm afraid. Again, I'm sorry. Francois and Michelle will gonna be presenting at the MOU group. I can't remember what session that is but, please look that up in the agenda. For that. We also had, Gory who's gonna be presented by the BDP frame. Been some discussion about this on the list. I think Again, that's a good discussion. We can carry that on there. Again, very, very sorry about that. We'll make sure anyone who missed out on time this time around. If they wanna come in at the next IETF meeting, move will will will will make sure that they get the opportunity there. Okay? With that, I will wrap up this session. Thank you all. I think we've made some very good progress"
  },
  {
    "startTime": "02:02:00",
    "text": "the adopted working group drafts such that we can get those cleared so that new items have a bit more time for discussion. Or potential new items. Thank you all again. Thank you, scribes and, Jonathan Morton and Miria and everyone else who helped me today. A virtual goodbye, Sharad. Yes."
  }
]
