[
  {
    "startTime": "00:00:11",
    "text": "thank you foreign thank you guys foreign"
  },
  {
    "startTime": "00:02:20",
    "text": "okay oh yeah okay yeah so yeah I think maybe a couple of minutes yeah"
  },
  {
    "startTime": "00:04:01",
    "text": "I go to the next slide yeah it's all done by uh and then Vietnam all right and if you want to be the first few or should I do that yeah yeah next time foreign"
  },
  {
    "startTime": "00:06:08",
    "text": "yeah we'll go for right now the opinions were representing what's on here you can do that yeah foreign was hard no check some"
  },
  {
    "startTime": "00:08:01",
    "text": "can you hear me for Lorenzo can you hear me foreign try again can you hear me yes okay I can eat you okay thank you all right ready to go okay all right well thanks everyone um as you know uh the the hackathon the whole thing is a bit of a a flurry of activity and getting things uh together quickly and that that goes for uh our the way we share the results and the recording of all that it's kind of always a a test and a a bit of an experiment so I think we're all set to go thanks for your help in getting the presentations uploaded and uh and we'll go ahead and get started I have a few things just to cover um first of all just a reminder I know some of you weren't here yesterday morning when we started but uh um we do have our our Mass policy you need to wear a mask when you're presenting up here you're free to take it off take it off as I have now um but when you're at your seat unless you're eating your drinking please please wear your mask and wear it properly uh just uh make everyone else"
  },
  {
    "startTime": "00:10:01",
    "text": "safe and comfortable we'd appreciate that um a reminder of the note well uh the the presentations you'll be doing here uh do fall under the note well just like the work you do within the working group sessions and and whatnot so a reminder of that um this is where we are in the agenda and uh so again with these uh results presentations I think it's great that so many of you have put them together and you are doing them our goal is to be able to to get through them all relatively quickly we'll try to keep the uh things flowing uh smoothly up here to the best of our abilities and we really ask that you you keep your presentation to uh four minutes at the very very most I'll be running a timer there and I'll let you know when you're down to two minutes uh when you're down at one minute and when your time's up we're really going to have to cut you off unfortunately just just to leave time for everyone else um so sorry about that but please uh you know try to be brief and know that there's other opportunities including hack demo happy hour tomorrow where you can have much more in-depth conversations with everyone and uh with that uh oh one more thing if you haven't already uploaded your presentation please upload it into GitHub what's happened is behind the scenes all the presentations you've put there uh assuming there's a PDF file if you're able to get the PDF file there in time those have all been pulled into miteco and we can uh run through them directly from within me Techo um if you upload a file afterwards if you haven't don't have yours in yet be sure you convert it to PDF first then upload it and we'll do our best to you know get back to it again uh at the end otherwise we're just going to run through the presentations in order any questions about that okay"
  },
  {
    "startTime": "00:12:00",
    "text": "um then I'm going to turn it over to one of my co-chairs here Beno to uh to help with running through the presentations oh there we go okay from top to down sorry hi welcome so we're running the presentation from top to down as they appear in the mid Echo so no no specific order maybe first come first serve so I would like to invite the first presenter of explicit flow measurements it's in the room thank you so you have four minutes we will indicate to one and then and you're allowed to if you're in time you can also ask some questions from the room but okay thanks left and right yeah okay okay um my name is maximonido from Telecom Italia's team okay yes and this presentation is about the results of uh spreadsheet for measurements and um in this particular is related to passive misordinates that use the customer traffic it's not artificial traffic what we try to understand in this hackathon if the quick speed is"
  },
  {
    "startTime": "00:14:00",
    "text": "supported over internet by the mainly by the Ott or any kind of company web server and we made that implement we have already made an implementation of uh in our open source browser in this case is chromium and with the modification for support of the quick spin beat here we made some tests uh over the Internet versus the over the top web servers and mainly they doesn't support this uh spin beat because it's an optional parameter in the standard but we made some tests versus an openly speed web server that is an open source project and this is successful we got the spin bit running as you can say in the screenshot in the right bottom of the right the spin beat is spinning and we obtain some delay in solvents with a left LTT that is from the client side and on the right LTT runt replace it is related to the mainly on the internet side and is quite presses affordable this is the other thing that we try to investigate in this hackathon and we try to implement a new delay measurement technique and these new experimental technique that is a modification of the spin bit requires only the um the the modification of the client of the client side it's the realized on internal protocol LTT evaluation we always use okay we always use in this case the quick and the user the same square wave mechanism that is the with the alternate"
  },
  {
    "startTime": "00:16:01",
    "text": "marking uh the of the spin beat with some preliminary tests which we've done here we obtained some good results that is we can obtain also the delay measurements and the mainly goal of this implementation of this method and we can use this this alternate technique for the delay instrument only by the modification of the client and so we don't need any way any anymore a support by the server side that is we don't doesn't need to have the the support from the reflection bit on the server side okay okay this is a screenshot of the user device and this is the team that you're working here okay if there is some question we are here okay no questions it's good thank you very much excellent foreign right I don't see your name yet yeah okay no pdmv PDM V2 who can I invite to come up front oh there you are excellent thank you"
  },
  {
    "startTime": "00:18:02",
    "text": "okay so I'll go through this click okay how do you do the next one oh this one okay thanks oops yep so we're working on three different um extension header testing uh things uh two of them will present him at V6 Ops and one of them at ippm we have quite a quite a crew working on this uh a number of students uh from um uh from India as well who who are working with us and so our plan we're trying to do some cloud provider testing at the hackathon decide on the registration protocol that we need for our encrypted PDM and then we did some presentations with ebpf and free router which the students in India were working on essentially the the the point of our project is to figure out if IPv6 extension headers can be used on the internet and we did a presentation uh at iepg on them and we feel that it's really important that extension headers uh work because it is a very good way that we will have to measure uh encrypted Networks and uh what we've been doing is to figure out if they're being blocked exactly where are they being blocked and we will have a whole side meeting on Thursday an hour to talk about uh the the whole situation uh it seems to us that there's uh three different topologies involved uh bottom line if you're doing just client internet server things seem to work well if you're if you have a CDN provider or uh if you're in a cloud provider environment things work less well and so"
  },
  {
    "startTime": "00:20:02",
    "text": "we need to uh work together with these people and uh the way we're doing our testing is we used ebpf to create a stack which will append an extension header of our choice to each packet uh going in and out of the system we are also making modifications to free router so that we can put in hop by hop headers and ideally position free routers at various places in the internet so we can see exactly where extension headers might be stopping uh we also did a great deal of discussion of our registration protocol for our encrypted PDM I'm not going to go through this thank goodness more breaking news as it happens Lots going on come join us and we'll be happy to talk your ear off questions yep great thank you [Applause] thank you next is the DNS hackathon results there you go yes so these are the results from the DNS table uh uh we worked mostly or there was a big group working on DNS air reporting so this is the draft which specifies"
  },
  {
    "startTime": "00:22:01",
    "text": "that the builds upon extended DNS errors but instead of informing the query about what went wrong it's informing the operator or the owner of the domain and it's basically works as follows the authoritative sensor reports receiving agent in an edns option which is just a domain name and a resolver if it detects an error sends a query to the reporting receiving agent with the the error uh so Roy arens one of the authors of the uh dwarfs was at table two and we gave a lot of feedback uh we discussed that the care query type should be text instead of no uh so you could have different ttls for different errors and also the error code was moved towards the domain name to facilitate that as well we thought of a mnemonic for the edns option DRC DNS error reporting Channel and overall the the draft has better language now so there's implementation in inbound built upon Also earlier hackers of work you can find it in this GitHub tree we have a open testing resolver uh responding to the edns option there's also we also have a authoritative site sending option in ebpf which just works for any authoritative survey it augments the responses with this option uh there was a implementation done by"
  },
  {
    "startTime": "00:24:01",
    "text": "Stefan bertzmeyer in the authoritative names of a drink it's a dynamic name server it can do stuff when it's queries for uh stuff and it's great for experimentation here's the GitHub link for it and besides sending the Eds option Stefan also started with doing DNS errors reporting processing so doing something with the reports so there's another authoritative implementation in the neighborhood authoritative names have called Trex which is ns1's proprietary authoritative server and it also worked it's tested it worked Mark Andrews submitted the tickets for uh about nine and also the authoritative site is already working uh another project was to create net DNS resolver inbound pull bindings for lib inbound and make that work with the resolver in an Adidas and last but not least they encrypted client hello uh thing in Connect by name a library that does ace happy eyeballs Dane and everything you need to shut up uh sessions uh securely and privately so we had a really good time the food was amazing DNS error reporting just walks so the these were the participants thank you thank you okay next up is"
  },
  {
    "startTime": "00:26:00",
    "text": "let's see yeah drip d-rip there we go drone remote identification the chance will indicate about two minutes okay so uh I'm Stu and my affiliation for these purposes is a company called ax Enterprise and how am I advancing here we go yeah I tried that okay so what strip um wireless network based equivalent of a auto license plate for uh unmanned aircraft but the media love to call drones um the Baseline standards are external to ietf um but the problem is the Baseline standards are not well informed from the perspective of cryptographic network protocols so uh thus the drip working group which uh Builds on the Baseline external standards to um to provide those properties so arrow keys not working Okay Chrome Focus here no all right wrong votes here we go thanks so um the goals for yesterday and today we we've had to be fairly careful with our language in our graphs and so we have endorsements that are largely in the sense of the rats working group and um problem is a lot of the work that's been done uh by Adam and myself is for an employer who unfortunately will not release it as open source and so in the interests of moving this forward within ietf we want open source so"
  },
  {
    "startTime": "00:28:01",
    "text": "um our volunteers worked on an independent implementation uh that will be released as open source it already been uploaded um and uh this will produce endorsements and um Import and Export them in the necessary formats for over the air did the work in Python to get it done in two days and also the linkaping university implementation which is open source of drip and open hip needed to be brought up to the latest draft level and yeah uh our volunteers got it done and uh demonstrated this morning interoperability with the uh closed Source uh implementation and the Lincoln University work is going to be more extensive than could have got done in two days but we figured out what needs to get done and so our new volunteers did need a little help from the folks who wrote the drafts which suggests that the drafts need some clarification we need to take the Json out of the drafts and replace it with cddl and we found some Corner cases that will be addressed and so our team leader was Adam wave your hand at him and our volunteers on site uh Philip and Marius with your hands and uh we also had the Lincoln University folks in remotely and Bob and I were here to uh kibbits and we really really really need reviewers for our drafts that's it questions nope next thanks [Applause] next is uh right quick handshake classification foreign yeah thank you Charles will indicate die okay thank you thank you okay perfect all right hey guys uh I imagine this is Jonas with a quick"
  },
  {
    "startTime": "00:30:01",
    "text": "handshake classification API team and just to have a really quick uh or yeah short recap of what are the design goals of quick uh basically with two things we want to reduce the round trip times and optimally we have uh one-way round trip time and also we want to prevent the amplification attacks so uh the servers are only allowed to respond triple divides that the client sent to the server and we wanted to check whether during deployments actually comply with these design goals and obviously with the RFC and our starting point were two tools and we had quick reach and quiche which we both extended uh we extended quick reach by the retry support and we extended the keys to support all three TLS compression algorithms and in the end we wanted to have an API which basically uses these two tools to perform uh the checks we are interested in so um what do we got um basically we now have an API and also a website which uses this this API and you can enter any quick domain for example google.com and then you see the results how the quick handshakes behave so for example here now the quick handshake with Google takes multiple round trip times because of large certificates uh we have cloutra which has a slight amplification uh of four or a small amplification um then we also have uh the compression which I talked about so basically we show how efficient the the compression levels are so here in this example we save around 30 of data if we activate a certificate compression so in the end we have an open website which currently is under accessible under my private domain but you can also we are currently moving to understand"
  },
  {
    "startTime": "00:32:01",
    "text": "the quake.net so uh please check out our tool our API and if there are any tests which you think are missing just talk with us and in the end uh we this is not about finger pointing we just want to Foster the discussions about quick handshakes and improve the deployments questions all right thank you very much [Applause] next up is young young automation tool are the presenters in the room yep I see can you hear me yeah I'm remote okay uh I'm functional from Power let me introduce our project yeah models to Automation and next please uh there are three modifications about my our project and firstly yankalaga Pro Wife online young customer meditation tool which can then data via modules regardless dependencies but there's no offline tool can do it second only provides some query interfaces it's difficult to fully meet the requirements of a young model of Automation and thirdly no two is a variable to compare two revisions of your model according to customize the compression rules our goal is developing a young automation tool to compare their models by reserving"
  },
  {
    "startTime": "00:34:01",
    "text": "dependencies automatically and provide the product plugging system to all the customized functions for example for the youngster communication according to colonized conversion rule uh the related drugs and active and leave below next this figure shows the architecture of a young compiler the model to be compared as input and then compiler will search that the dependencies from a local recall if not found young Cabela will request the remote Ripple fetch the needle difference to a local repo and then after uh build building the young female contests young fellow Will will call the plugins to perform extended functions next uh this figure shows the workflow of young female accommodation plugin that will customize the compression drawers and two divisions of young modules aren't as Imports and the plugin will where I can compare them and get the differences under the customer azures will be applied on this difference and then output the the conversion without including compatibility adapt next you have one half minutes okay what do we learned"
  },
  {
    "startTime": "00:36:02",
    "text": "yankovician and customize the compatibility Road can attempt different scenarios our next steps are listed below next I think our team members and we have two reports in GitHub if you have some some interesting on them and please visit any contribute a welcome thanks and oh thank you very much are there any questions no okay thanks thank you very much right there we go the next one is BMW G container benchmarking okay hello can you hear me uh hello everyone um I'm from the IRC from South Korea so uh our hackathon activities is to verify our consideration very much in their performance container infrastructure drive so we uh he's got a different considerations that can affect cutting a level performance including network access and model and different department configuration settings next slide please [Music] so in the previous cartoon we have already start initial tests of the pdpf a service model performance with the OBS if sdp support V switch and easy hackathon we continue to explore other variations of EPF acceleration model they are VDP V switch with a memory interface the Intel quality data plane"
  },
  {
    "startTime": "00:38:00",
    "text": "with a coded I have HD plugin and a CD xip uh so this is the uh the architecture of the VPI sdp this week so the vpv suite info is a spray is a baby switch and it's called the package from the IMDb socket to the af's ADP promo driver for the champion between the V3 the container it use the same memory interface let's say please for the cndp and the Champions limited indicate users pay user hdb socket original one and the Chipmunk is displaying container using the their own communist plugin so these are plugin move the network device from the horse necklace ready to support network display directly attacked the network device support so the quad can socket next slide please for serums and Serum is the only one that utilize the EBP app for both north south and Eastward traffic acceleration the EPF at the network big drivers before the muscle and at the soccer layer for Israel next slide please so this is our test bets and so we use EPF support Nick and kernel with some cni that we mentioned interior side next side piece see that our configuration next type is this is why you learned so we compare OBS we host VP in a bit and cndp so VP outperform obvious because of the better performance of memory against the V host and the cndb auto will have different implementation of ETF you still cannot"
  },
  {
    "startTime": "00:40:01",
    "text": "catch up the performance of PvP with Hyper package sign this service for the psyllium serums I have already published their own very much gain for their cni and this year you can simply refer to their result so the figure here so the most cell and Israel traffic acceleration using eppm on silu let's type in so for the future work we uh in finalize the Trap and I saw reviews we would like to welcome any questions comments and contribution to our draft to start the publishing adoption process the service this is our team member and we have project repository thank you thank you very much nice project are there any questions in the room no okay then I thank you for your presentation thanks next up is let's see where are we now satellite Network that's all I have for you for now but now we have a presenter excellent okay and Charles will indicate time okay okay and I will give me yeah okay okay and this we have two parts next okay and uh we have two parts of"
  },
  {
    "startTime": "00:42:01",
    "text": "this work one is the capital platform of the simulation platform and the next is the uh our platform from Nanjing University and about the quality platform we have three passions and one is the generation of satellites uh the topology of the network and the second is we use the topology to calculate the routine in the N3 and the third part is we will give a resolution of the satellites and about the actual Star platform we have two parts one is the we can give our configuration and the basic condition we can have a solid topology and the next we can defect the seller's failure about the search okay okay uh our development is based on the uh Ubuntu links and use the pattern and the G and G CC okay and uh this is we have three yeah let's just introduce them before and and in the future maybe we have more work about the like the orbit Dynamic and the evaluation of the constellation performance and the simulation of ICT and other traffic performance in the future maybe we can do and there's a lot of balance and routine awesome look at this okay this is our demo result we have no we have three types and this is the actual star about the uh his tune about from the 19 University and this we have the topology Network management okay"
  },
  {
    "startTime": "00:44:02",
    "text": "okay from the duties of the action we I think the simulation platform is very helpful to the solid solution Network and other maybe in other other area we can use the platform simulation another thing and in the future I think we will maybe we will have the adoption more routine hotels to the simulation platform and to the satellite networker and we have another TBR go phone yeah this is both and maybe we have some salad use case and to discuss in the off and maybe the topology change the period is a common use case and in the future maybe we have some courage with the funnel okay this is our members and we have an open community at GitHub if you have some investing and you can join us any problem thank you thank you very much there we go next alt BSG presentation it's here in the room or remote okay okay excellent you can use the arrows which also indicates good right uh thank you yep so I'm Jordi rajuwald I'm with Qualcomm and I'll be presenting our hackathon optimizing XR Flows In The Edge Cloud using Alton bald neck structure graphs yeah so the goal is to optimize XR flows"
  },
  {
    "startTime": "00:46:00",
    "text": "the steering of XR Flows In The Edge cloud and the the idea of this hackathon is to use Alto to get the state of the network and complement that with bottleneck structure graphs which are currently not in the standard it's been discussed but it's not yet in the standard so it's exploratory in terms of being able to explore and leverage some of these capabilities from the DSG graphs um these are the the RCs and the including a draft and bond like a structure graphs um and so the the challenge here is about integrating end-to-end the whole workflow which I'm going to present next um yeah so that's the workflow so starting from a multi-domain network mostly The Edge Cloud which could be Wi-Fi 5G 4G and eventually 6G it is to close the loop so on the right side we have the host and the user equipment if you will uh running an XR application then you would have um you know some kind of source routing algorithm segment routing and then to close the loop um you know we have netflow or you could use also as flow then we have the computational bottleneck structure graphs here which is the what that's sort of the math and then we fit that into the alto server which is the the standard and then we have an auto client pulling from from the alpha server that information the state of the network and the bottleneck structure of the network and based on that we compute an optimize path that ensures maximal throughput while maintaining a latency requirement based on the bottleneck structure analysis and then we fit that into a path computation uh module that goes back into the source routing algorithm to help us steer the flow through the edge cloud and sort of at any point in time helping help it find the best the best path possible so uh yeah that's the the topology that we've been testing against it's a 5G topology uh it's actually extracted from an actual deployment in Philadelphia but it's uh everything is running in an"
  },
  {
    "startTime": "00:48:00",
    "text": "emulation mode actually this um and um and here we have um you know there is an edge Computing resource here this could be this would be the XR server and then um a host running the actual application and then two possible paths to choose at any point in time based on the congestion dynamics of the of the network and this is the result of the demo that we are running uh so uh what we show here is um you know you start the Excel application it's getting getting 10 units of bandwidth then congestion kicks in on that path and then while next structural graphs recompute in real time the the Dynamics of the system find that there's a better path that still maintains the latency requirements so and so as congestion builds up then eventually finds the better path and then switches back to to find to to higher throughput pass so the blue the blue flow here is the XR flow you know as congesting kicks in then uh eventually increases back to finding to reroute reroutes and finds a higher throughput path to maintain um you know at any point in time giving you the highest throughput available so what we learned uh yeah so bound next structures graphs as I mentioned are currently been discussing the alto working group they are not part of standard but this is a demo that allows us to sort of bring some uh some of the um the foundations or the understanding of how this would work in integrated end-to-end with with to close the loop you know integration with uh with that flow with um as flow and and Alto and the source routing algorithm uh the demo show that it's you know that's feasible to run this uh actually you know in real time finding the the you know the congestion dynamics of the problem uh we have actually a deployment of these introduction Network at the national research platform in the US uh and so the demo provides uh some practical uh feedback into the auto working group"
  },
  {
    "startTime": "00:50:00",
    "text": "um the uh the idea is that bottom infrastructure graphs uh provide a compact and a scalable approach to incorporate traffic engineering information into the out of standard which is something that the ultra standard currently doesn't do but it's something that we're consuming and that's the theme uh so this is most people from Qualcomm uh Yale University Caltech uh UCSD um and Sichuan University and Huawei it's part of part of the alto working group and that's it [Applause] okay sorry your mask is up next we have uh let's see the right group over here close by yeah example there we go Charles okay uh yeah um yeah I present for right I'm a team um the other people that contributed to our several sub projects also listed there in total we had four sub-rex projects um the first one was about integrating the um platform security architecture for crypto interest um where four so uh four problems were worked on first of all the persistent storage for using PSA for that we have now a working pork and we can store AES keys in flash memory um then the integration of additional crypto backends um for that we also have a working park with the SD safe a secure element and it is possible now to switch"
  },
  {
    "startTime": "00:52:01",
    "text": "between different secure elements then the third problem was the automatic selection of a crypto backend the pending of the hardware capabilities and that is now integrated into the build system of Riot with kconfig and make files and the problem of integrating the PSA architecture test suit was solved by integrating the test as a so-called Riot package um so we can now run the tests that are provided by um um the second project was to provide IPv6 support for uh IEEE 800 215 4E dsme using six lopen for that we have now a working implementation and the review process for merging that into the riot Mainline has started um then the third project we were working on is was a Schick plug test between the riot implementation which uses the external lipstick and openshik at the openshack table on Saturday we basically just did preparations and tried to find out what was possible and then we found out that on both sides with compression rules there's some handling that still needs work on the lipstick side it's basically the mapping between the offsets with abscess for example when we use Co-op types and when we try to compress Yuri components more than one Euro component that doesn't work either at the moment and on the openshift side uh etecs and blockwise options compression is not yet supported really so we agreed on some common chick rules um namely IPA ap6 icmp and UDP just then then use values based on our release specifications to find a common ground and then we did some plug testing today where we found out that the icmp header"
  },
  {
    "startTime": "00:54:02",
    "text": "message parsing still needs some work and that it's probably a good idea to use coreconf to address to configure routing and neighbor The Neighbors which brings us to our last project for Quantum Riot where we now have a working implementation the discovery of available models is still missing and the problem [Music] that what is mandatory to implement where we refer to the response specs and how to discover the capabilities of constrained devices their response has a mechanism which is not available in corcoin Fiat and we there was some discussion to carry over RC mon uh over to corconf and uh yeah future work is then provide a pull request and by it thank you are there any questions thank you very much next we have let's see Riot and then SRV 6 data plane visibility there we are excellent so we can use left right okay very good uh hi everyone any books from swisscom and I have Alex I'm fine from inside University of Leon sorry okay yeah so it was about uh data plane visibility in srv6 so basically the goal of our exercise was to validate and visualize to ipfix implementations of the srv6 SRH draft"
  },
  {
    "startTime": "00:56:00",
    "text": "we got just in time one implementation for Huawei Huawei vrp and another implementation done by inza of the VPP so the first topology we built for the Huawei vrp uh topic was composed of eighth notes we see um the egress nodes on the left upper corner there where we configured three three different srv6 traffic engineering policies where we push these City lists which accomplished then the three different colored paths which we want to see then individually visualization at the end of the pipeline later on um yeah of course to get these flows exported we had them to set up some traffic across which we did from the upper node there uh the second topology yeah the second topology we tested was uh the vpp1 uh so we had the topology is a simpler one we have only three nodes with a cement routing policy between the first note and the third one third one and we are using traffic engineering to send the packets uh so through the topology the goal here was to implementing the ipfix export uh of this samaritin header so on each note at ingers interface we are aggregating the data for uh for each uh SM routing flow and exposing it through ipfix exactly so at the end of our pipeline which actually had also to be uh um enhanced to decode these new elements uh we have this nice visualization where we see uh you cannot see it but you can see it if you download the PDF later on you see in the first number the segment list so which corresponds to the politics of the three different policies we had"
  },
  {
    "startTime": "00:58:00",
    "text": "before and then for this you can just raise the the path with the segment left and you see also which active segment is used for forwarding and of course you see the peer episodes so from which node this has been exported yeah so to conclude what we achieved through this hackathon was testing this semi routing policy within different topologies we validated the this ipfix draft and also testing the whole pipeline So reading from the database the collected data and a funny thing we we also tested the actual use case we had two two members of the team working on the database and two members working on the topology and the database team actually saw these changes and oh there was a change in the network so for our next step we are working on on task Telemetry which is addressed uh who tries to export the delay between every node and then we we will try to also validate this data planar visibility for srv6 uh in l21 L3 evpns and we just posted a new draft with minor updates today so what we learned so also thanks to our hackathons networks our crowded team where was able to invade other tables and gain some power and space uh as always beers are are always welcome and uh a bad thing is that in in our lab access was a tricky thing and uh yeah to wrap up that's our team thank you very much"
  },
  {
    "startTime": "01:00:01",
    "text": "[Applause] thank you oh thank you I want to thank everyone also for keeping on the given time slot for four minutes it's going great thanks next up we have let's see it's Nesquik I've seen them somewhere over there yeah there they are in this Creek that works the next week that's why everyone okay good um so um I'm Maxim this is Francois so we're a PhD students from uh luva working with our advisor officer Olivia Bonaventure and so we've been working on on Nesquik and Nesquik is not just a cocoa powder that you've been seeing on the table it's also a tool that we are shaping up to do um Network testing or internet performance testing with quick so the goal for the akaton uh was to try to do quick measurements with mlab NDT so mlab NDT is a tool from measurement lab if you don't know this tool the easiest way to access it is just Google speed test and then you will find a pop-up that prompts you if you would like to do speed test and so that's part of the um lab initiatives who is collecting which is collecting so um uh speed tests from all over all around the world with this so our goal was to do was to try to integrate quick measurements into this tool and so we took a quick HTTP 3 and web transport and tried to integrate all that into the tools of mlab so um we did actually quite well so we have a working prototype which integrates"
  },
  {
    "startTime": "01:02:02",
    "text": "into the entity server um and on the client side we have switched from websockets to web transport in the NDT JavaScript client-side code and so thanks to Google Chrome and um and and web transfer go we were able to make the two discuss together and so now we have some proof of concept for download and upload tests using HTTP 3 and quick right from the um from the browser so um that's just one of the first points so why why are we doing this are we interested into doing a quick internet performance measurements because we speak we can have much more precise metrics about delays loss loss patterns and stuff like that um and then we will need to in that way we will need to uh update also like how we get metrics from the quick Stacks up to the uh to this measurement performance so look at what we can have similar to TCP info um and benefit from all that and to do in end-to-end measurements over the Internet because quick goes through any path that is in the way uh so that's it I guess if you're interested in that go uh go come chat with us we will be staying at the next quick table for for a while thank you foreign all the impressive equipment over there"
  },
  {
    "startTime": "01:04:02",
    "text": "thank you okay next two parents just arrows left and right okay thank you okay all right hello thanks uh everyone um I'm Greg white cable labs and joining me is hi um this is the second uh interop for the l4s project at the iitf hackathon uh first one was at iitf 114 in Philadelphia um and uh l4s if you're not familiar stands for low latency low loss and scalable throughput it's a new congestion control and active Q management architecture for the internet um there are three core drafts which are currently in the RFC editor queue that defining architecture and components um there's also a fourth draft which covers the congestion feedback for TCP um as we referred to as act for dcn there are three components to the architecture the sender side congestion control the congestion feedback in the network of suggestion signaling in the network and the feedback at the receiver side to feedback that congestion signal to the sender so so we have multiple implementations at the table the long table in the back there on the congestion control side we have apple quick prod uh Linux TCP prog Google bbr V2 is a TCP implementation and two real-time congestion controllers one from Nokia called RT prog and one Erickson called scream and then there are certainly five marking feedback implementations at the receiver side quick TCP and real-time applications there also are a couple of um some of the testing we've been doing is using um iperf to send TCP or quick traffic"
  },
  {
    "startTime": "01:06:01",
    "text": "but assuming testing also uses for the real-time applications use video streaming that adapts the video Codec rate based on available capacity in the path and maintaining ultra low latency along the way all right on the bottleneck side in the network we've got four implementations there wi-fi and 5G and fixed network from Nokia as well as a 5G Network American that uh is running in the room and uh we've been testing multiple links there we've got done so far I'll hand it over to June yeah so a lot of interrupt testing has been done too much to uh explain I think um so with the mainly a lot of congestion controls have been tested on different platforms and also a lot of congestion controls I've been testing against each other whether they converge to the same rates which is of course important if multiple applications share the same bottleneck that they're evenly dividing the the flows and we still are here for a few days more after the hackathon to do further interrupt tests going on maybe one of the results and to show you why it's important to have alpharettes on a typical 5G Network you see at the top the latencies uh which are with classic TCP up to 400 in reality even above a second if you really do downloads with detail for us here we have a 99 that below a few milliseconds two three uh 99.99 uh four milliseconds you can see it in the slides for the details uh and I think then sure so we have quite a number of organizations participating this time um this is on the slide I want to read through them all but um"
  },
  {
    "startTime": "01:08:00",
    "text": "and uh in terms of actual individuals listed here 21 folks that are joining us most in or many in person there are a few that are remote um participating as well and then finally to wrap up um this isn't the end of interoperability testing for l4s we um this is actually this I mentioned the second uh one at ietf there actually was one in the interim between last IHF and here that was hosted at cable labs in uh in Denver we do plan a second one um in Denver at uh in January and then we'll look at scheduling uh at ihf116 at Yokohama so if you're interested in participating uh reach out to me um and I'll help you get involved thank you thank you sorry you will be around for the next couple of days in the year in the hackathon room okay excellent so people interested the group will be working in that coroner for the next week until Thursday right next up we have let's see no no no no no no oh sorry this almost 12 plus one the open I don't know how to pronounce it open c c h c presenter here yeah I just learned from Martin how to pronounce it but I don't know um so this is the the work that we've done at the open check table in that corner over there flights"
  },
  {
    "startTime": "01:10:02",
    "text": "okay just some dealing good um so a little background which is shake shake his header compression and fragmentation for um IP protocols over a very constrained networks which are usually referred to as LP ones you might have heard of Sig vox01 for example if you know six low band we're talking even more consuming networks and six open we were targeting payloads from 10 to 100 bytes and they trades from 100 bits a second to a few tens of kilobits a second that's our area of operation um the the work the specification work is done at dlp1 working group in the inter area and we've produced a few rses already with more coming um and so uh over the years in the architons and between the hackathons we have developed an open source implementation of this protocol um in Python 3 and this project is called open check um and we're very happy that it was adopted by the lower one Alliance as a reference code to certify the IPO IPv6 overall R1 devices at the lower Alliance um okay I pressed the button and nothing happened yes okay suddenly so what have we achieved uh over this weekend we cleaned up the the GitHub repo for project merge a few development branches cleaned up you know a dead code Etc uh improved the documentation we have a tutorial to go with the the code which is a step-by-step instructions on how to run examples and get acquainted with the code um we also had a newcomer experience"
  },
  {
    "startTime": "01:12:02",
    "text": "engineer but newcomer to the ietf and the lp-1 work group who decided to develop a new Clean Slate implementation in micro python which is very handy for constrained devices we also had one participant designing a connector between openshack and a real Network server for sigfox Network so we can exchange packets over a real radio network and we did interrupt testing with the riot team as was mentioned before we exchanged a few compressed packets both ways very simple it's a start but good news and also working on the interrupt between the micropy and clean slate implementation and the Legacy open check implementation um and what we learned having a newcomer with the rfc's uh you know the fresh look is always refreshing lots of good questions came up about you know how the rfcs worded and also design choices where did you do this this way or that way and uh you know we could do things in a slightly different way using the same toolbox because it's a generic protocol and so this led to some ideas we might extend the young model do little protocol extensions to do things differently which might be better on a very constraining device for example and of course we'll bring that feedback to the working group during the week or at an interim later on and that's it that's a team with two newcomers and happy to talk to you about open check if you're interested [Applause]"
  },
  {
    "startTime": "01:14:01",
    "text": "there we go she goes project presentation there we go thank you okay yeah so T cozy is a an implementation of cozy cozy is a seaboor object signing encryption a a new message a new format for signing in encrypting messages so tikosi stands for trusted cozy uh it's a c implementation of 1952 and 1953 suited for small devices and small memory use it's aiming for commercial quality and it uses it can use either the open SSL or embed TLS crypto libraries so here's the hackathon progress kind of relative to what happened in 114 to 115 so uh we compared to one at 114 we we've got uh Mac zero uh which is a it's a format for Mac messages that is now uh kind of on its a pretty well integrated into what will be uh T cozy 2.0 uh we're supporting custom headers uh that's pretty well integrated and uh we're kind of halfway through uh because they sign which is multiple signers and uh probably halfway through maybe not quite for kozay encrypt so that that's because they encrypt uh with um hpke which is a a bit of a moving Target at this point so that was our progress for the for the"
  },
  {
    "startTime": "01:16:02",
    "text": "hackathon and then uh briefly uh there's other progress it wasn't kind of really hackathon related uh since uh 114 and that was RSA in eddsa was integrated into uh ticos a 1.0 that will eventually move to ticos a 2.0 and uh just this GitHub project uh T cozy so happy for to use it or or contribute thank you [Applause] all right up next so next is web RTC encounter media here in the room ah there's all right you can just use the errors so page down okay okay this will be shorter isn't that much to talk about so idea came up at the last T Pack and September and WCC that we should before we start defining new apis we should really try to play with them so they suggested to have take the opportunity of a hackathon of course it was a bit short because well only I showed up here a couple of others expressed interest but couldn't make it in the weekend but uh they wanted to Define some apis which is not what the IDF customer ID does but uh this apis manipulate stuff that is then passed through IDF protocols so it kind of links to the ITF and we got some working code done"
  },
  {
    "startTime": "01:18:02",
    "text": "this does this is totally unreadable and so if you want to want to see what it actually is then just get a GitHub that the source is available I had fun and we got a little bit further towards figuring out what can be done and what's what doesn't need to be part of the specifications so have fun thank you Lord all right so here we are in this Auto visibility open auto implementation press enter here and online thank you awesome um so I want to talk briefly about implementation deployment and LHC one use cases for the open Alto project next slide so the open Alto project is an open source implementation of iitf's Alto and then we also worked on openoutso.org which is a running deployment of this open Alto project next slide specifically open alto.org is used with lhc1 a layer 3 VPN for high energy physics data out of CERN next slide please so what we got done during this hackathon was primarily focused on visibility of lhc1 network routing States and then we also briefly touched on alto-based replica sorting and integrating this visibility into dataflow orchestration next slide please"
  },
  {
    "startTime": "01:20:01",
    "text": "so our first achievement on the visibility side was geoip and geo-distance and this quite simply was allowing endpoints to use the standard Alto endpoint cost service to gain zero distance information next slide please please our second achievement was on obtaining routing paths so there are many ways to accomplish this but we focused on the data plane using looking glasses G2 snapshots and equivalent classes next slide please on the Looking Glass implementation we were retrieving forwarding information bases from looking glasses in CERN and giant and were able to query the path vector through that next slide for the data path sampling driven implementation we were able to obtain similar information using equivalent classes and this was in reference to National research platform next slide please our third achievement on which we made good progress but was not completed by the end of the hackathon is using open alto.org as a global query orchestration platform so the idea is that this allows multi-domain query processes in lhc1 um the process is generally looking up the source IP in irr to obtain the source as clearing the appropriate Alto server associated with the source as to obtain the as path and then refining that as path into a general path representation which I won't go into detail here but a good description can be found in recent working group email next slide one half minute and then our final achievement was integration of this visibility that we'd established into russio Source selection next slide please so this first involved the configuration"
  },
  {
    "startTime": "01:22:01",
    "text": "of Alta resources to fetch information about resume replicas and then expressing how we needed these Russia replicas to be sorted and final slide please and we're able to deploy this versio implementation integration into mininet that support that partially simulated lhc1 networks and saw success in disintegration that's it thank you thank you very much thank you Lauren [Applause] brings us up to this one I2 NSF project presentation yep excellent foreign group so basically uh we want to propose a new security facing interface for itunesf for multi-domain environment so this is the poster for our project so basically this uh failure shows the Premo of iTunes framework so this time we want to implement ipsec Pro protection based on sdn so basically RC 90 61 is for one domain IP stack upload protection but this time we proposed West and Easter Bond security facing interface for multi-domain environment"
  },
  {
    "startTime": "01:24:01",
    "text": "so this figure you can see so we have two of domain domain and B so security control a carbon domain a and on the other hand security control B carbon domain B so basically nsf2 and another three are belonging to uh two different domains so we want to set up ipsec Pro uh using ituna set so basically you can see security uh controller B uh providing um ipsec Ike so parameter through security controller a and finally an asset 2 also NH3 can get a security um related parameter can get from B so this one can be done using our proposal so this figure is p80 pure authorization database Ike and security policy database we can snapshot so this one or also snapshot so once uh Ike wasn't to protocol exchange is done and then you know ESP uh packet uh traveled between two network security functions so in the middle nobody can catch the information because the ESP packet delivered okay so we got done uh so during this hackathon we showed the IP stack uh security Association uh can be done using our itunesf extension and next step we want to also implement the icon list case which means security control can generate uh sa parameters instead of IQ button 2. so this is our open source guitar this video clip and this is our team thank you for your attention thank you [Applause]"
  },
  {
    "startTime": "01:26:00",
    "text": "okay yeah um okay great this is efficient okay there you go okay hello oh this is the second presentation the ipmont is a new uh Bob I tried to introduce this buff so the basically iPod 6 moving object and networking is after ipoable working group work so we want to provide the v2x b2b2i among many kinds of moving beakers such as a weaker thrusterial vehicle or area vehicle drones also the Marine Vehicles so this one based on our IP wave working good problem statement this is already almost ready approved by IC almost okay so you can see many kind of objects here so we want to build the particular architecture uh using many kinds of vehicles you can see pedestrian terrestrial vehicle entrance area vehicle and also Marine Vehicles something like that so we also take advantage of storage PP 5G v2x protocol in addition to um OCB mode so this is a poster so basically uh we want to prove the concept context aware navigation protocol for IP based the particular Network also we implemented our work using omnip plus plus simulation and 5z simu 5G for basically you can see so the drones can communicate with each other also deliver its position information to server through the in the middle we have a genoto b and connect to the server so"
  },
  {
    "startTime": "01:28:03",
    "text": "efficient navigation for three-dimensional drone paths so what got done so we checked whether our 5D stock can be implemented for uh context of your navigation protocols so we proved the 5G similarity can be uh used also so in the next step we try to implement a multi-air address as configuration and also loading efficiently this is open source and this is a demonstration so um so we got some privacy free tracks is a feature for ip16 networking this is my team members so thank you for your attention okay thank you [Applause] and this one thank you post Quantum crypto yeah I'm correct excellent you can use the arrows the arrows okay okay hi I'm John Gray from entrust and uh this is the first hackathon for myself and I think pretty much everyone on our table so we had a lot of fun so our goals for this event was essentially interrupt testing of PQ Keys certificates pkcs 10 essentially x509 based artifacts and um also using the new nist crypto Primitives uh dilithium Falcon and"
  },
  {
    "startTime": "01:30:00",
    "text": "sphinx and also alone but also in combination with uh and composite combinations with traditional and uh with traditional crypto as well also we wanted to solve asn1 encoding issues to help clarify specifications and obtain experience using these new algorithms and also provide an artifact repository so that other people can also use these artifacts for their own testing purposes I just referenced some RFC drafts that that we used there was a lot of them and also there's been standards around x509 for like 25 years so we're also using those okay so what got done so we did create a GitHub artifact repository that's actually in the hackathon so you can see There's the link right there it's called pqc certificates so take a look yeah we also defined a zip file format just to make it easier for interoperability testing between the different artifacts that we each produce um we also agreed on public and private key encoding so a little bit more on that later and the other thing we have seven different implementations that we're testing um so I think this is a great success for you know first time hackathon we have um four vendor Implement implementations and also three open source implementations involved bouncy castle openssl and python so what we learned so there was a lot of discussion in the mailing list about octet string encodings but there's actually it turns out there's a sec one draft from a while ago that basically says to to treat a bit string an octet string identically so once you do that it solves the problem you say four bytes as well so you know over time four bytes might save you know gigabytes of data so anyway that was a good way to solve that and we agreed with that for the private key we also were having some issues with octet strings wrapping octet strings we decided there's no point in doing that and we'll use the representation from"
  },
  {
    "startTime": "01:32:01",
    "text": "59.58 the other thing we talked about was object IDs at this point there's no standard object IDs we know this is going to be um standardizing them soon but until then we need to be flexible at this point so we've also need to make our implementations flexible to read different types of voids we also suggest using an arc a version and a security level so you can actually encode some data into the oids and the most issues found that we found anyway are not related to the PQ algorithms so the last slide I just wanted to wrap up again this was pretty much a team of first-timers there were 16 of us and yeah we had a lot of fun we are planning to continue to meet on a monthly basis so the next meetings Monday December 5th that 12 UTC time we actually have people around the world all the way from Australia yeah all over so if anyone wants to join us you're welcome to do that and we also plan to expand the artifacts and go into protocols in the future so thank you I think good to see that was a good first experience for you at hackathon next one is soaked stream if I pronounce it correct it's a remote or on in person okay there you are foreign I'm Stephen mcquiston from the University of Glasgow and the project I was working on was streamlining social decision making for improved internet standards so slightly different to the"
  },
  {
    "startTime": "01:34:00",
    "text": "talks we've had so far now our plan at this hackathon was to try and measure the sentiment on the ITF itf.org list so using NLP techniques to try and measure whether or not the tone or the levels of toxicity on this mailing list have been changing over time identify people that are posting negative or positive messages and and basically to analyze Trends in that data set so what we got done is we ran all of the emails sent on that list through a tool called Vader and again that just gave us scores in terms of how positive negative or neutral each message was we then started to plot the broad trends that we could see in the data set both over time and for individuals and and answering other questions about the data that we gathered we developed some tooling previously and during hackathon we identified places where we could perhaps improve the documentation or the packaging for that tooling so what we learned was that broadly the ITF itf.org list is positive or neutral so about 65 of messages are identified as being positive um about 15 or neutral and then the remainder were identified as being negative um that's not really changed over time it maybe feels like it has but according to the data it hasn't we've got some initial evidence of some slightly more interesting trends um again it's relatively low levels of negativity that we found we found more negativity on weekends um we found that people using their personal addresses versus perhaps corporate addresses were more negative and the people were strangely more positive on Mondays um I don't know I don't know why um the the uh the sort of other takeaway that we had was that sentiment analysis"
  },
  {
    "startTime": "01:36:01",
    "text": "over technical uh language is pretty difficult you know phrases like Drop packets and kill process and abort transmission are all on the face of it negative using the tilling of course there are fairly neutral phrases given the given the context and we need to work on that we need to build a lexicon of these phrases that we can identify as being neutral now just to wrap up we had team members from the University of Glasgow and from Queen Mary University of London we've got lots more information we've published papers on various other data sets around the ITF at that link if you're interested in any of this there's going to be a side meeting on researching internet standards processes on Thursday afternoon there's more information at that link just want to conclude with a request for your help we're trying to build a tool that will help working groups to identify suitable reviewers for their drafts that's based on context from emails and from other data sources that lets us know the interests of different participants we then scan the drafts to identify the topics and then try and match the two up we've got a tool that will let you look at different drafts and to see if our suggestions are correct so if you scan that QR code or visit our website you can use that tool and give us some feedback on it thank you very much [Applause] I wondered why if you saw impact of the power outage from the mailing list let's see the next days the vehicle on hackathon presentation oh there you are yeah yeah great thank you"
  },
  {
    "startTime": "01:38:02",
    "text": "uh hello my name is Thomas Dan and I worked on vcons for this hackathon I'd like to I'm sure vcons are new to most of you a v-con is a Converse is a container for a conversation and it has four parts um and I really love the sentiment analysis of the last group I want to remind them though that if you have a model or a conclusion that you've used for with customers data with people's data if they take their data away you have to retrain your model what V cons help you do is keep track of what data you used to create what information Downstream for personal privacy informations and to support artificial intelligence and machine learning so what did we accomplish um Dan and I uh redactions so be cons carry the information of a conversation and but not all the information that's contained in it is appropriate for every single business use for instance it isn't there's no reason for a business analyst to know what your birthday is so uh what we did was we used vcons to implement transcriptions and what we did was we used open ai's whisper program to transcribe it then we also use Capital one's data profile to identify which personal information existed in the the uh the transcript can we use those two those two together to redact the transcript um we could have used text-to-speech to really um depersonalize it or you wanted to save something for ietf 116. uh so what did we learn it basically Works um but we also learned that maybe specifying um and uh standardizing a transcription object would allow us to use different transcriptions engines and be able to test them more reliably um I want to show you uh what we came out with so here's an"
  },
  {
    "startTime": "01:40:02",
    "text": "example of our of our work we use the at sign for the redaction and this is actually from my my particular job thank you uh my my company sells new cars for a living and we about a million times a year we take people's personal information and we're looking for better ways to handle them here's a transcript of a customer conversation a couple wins a couple losses apparently the agent's name is not private and of course that it is but the but the car's name apparently is considered to be private and it's not um but I will tell you one thing which is really um the point behind the vcon if you notice part of this conversation he says I'm putting the volume up because you're so loud we have 100 agents that work all around the the world and we have no idea what the audio quality is between any two participants in a call this told us that for some reason before our agent got in the phone it was a low volume call we wouldn't have known that without looking at the V con because we needed our customer to tell us that okay so for more information we have a mailing list we've just submitted our internet draft uh we're going to be at the heart RFC later on today uh but the best one is the vikon bar buff it's going to be on Thursday if you're thirsty or interested in vcons or just thirsty come visit us at the uh at the buff thank you foreign [Applause] let's see did he gone and okay ntp love it you can use the arrows yeah hello I'm David we spend together with a"
  },
  {
    "startTime": "01:42:02",
    "text": "few other people at the ntp table the weekend uh working towards ntp uh the plan was mainly to work towards ntpv5 um focusing on for now experimental implementation see if we the implementations we have are interoperable and see also what technical issues we still run into in the draft as it stands um so what we've got done there is now to two experimental implementations that both are verified and drop horrible yay um we did some work on draft identification for ntpv5 so that once we start to make a lot of revisions to these drafts we can keep track which implementations we use which drafts and which servers you switch drafts so that's nice uh We've identified a few minor bugs in uh particularly the ntpd RS implementation of nwv5 and we've had a lot of discussions on time scales and leap seconds because those are always difficult um there were two main takeaways that we've got from the weekend that is that time scale offshots will need a little bit more attention particularly around ut1 again because ut1 is currently defined as being always within a second of UTC but leap seconds may or may not go away in the future and at that point time differences might become too big for the current data types and we've identified that we still need to work a little bit on the because of that packaged mechanism for ntpv5 because currently um there's not sufficient mechanism for that in the specification um so these are the people who worked on uh the ntp stuff this weekend and some links to both the nttp 5 draft and the two experimental implementations are"
  },
  {
    "startTime": "01:44:02",
    "text": "there any questions good [Applause] right so um yeah erasing the ends um the one tax API presentation that's remote or in person all right can you hear me remote okay okay um so give a brief overview of some stuff I looked at this weekend um next slide please so looking at RFC 8032 and um one of the issues raised from the last hackathon is that has been suggested a new series of test vectors which might give different results with different implementations of adsa next slide please so ideas to look at different libraries and I guess this weekend I was just able to look at NaCl and there's been previous work on a port of NaCl to JavaScript um and also found a few other libraries and I guess one was mentioned earlier today so if you look at that as well um next slide please and so I found is that uh NSL implementation and C professional one and the port to JavaScript pass and fill the same tests um next slide and that's it um so this is the neurotomy progress to"
  },
  {
    "startTime": "01:46:00",
    "text": "try and update this uh RFC thank you thank you for your presentation thanks [Applause] um next one is webrtc encoded the media presentation remote okay it's it's jumped to the to the bottom line yeah it's yours Harold okay then we go to let's see no oh just okay it was a presentation without a title probably uh you know sorry okay next up is okay I think we have this already okay okay so there's some doublers hackathon this okay so this is yeah so there are some some doubles here yeah I have one tested TLS presentation yeah okay"
  },
  {
    "startTime": "01:48:02",
    "text": "excellent yeah you can use the arrows great so uh I wanted to give a very quick update on our work on a testiculous so at the intersection of yes for the bus uh the intersection of rats and TLS working groups so we're trying to introduce a new TLS extension to add support for attestation evidence and results as first class credentials in TLS so instead of x59 certificates um our goal is to support both um background check and passport models and to support both sides of the TLs handshake to be able to adjust themselves for Authentication but for for the proof of concept that we're actually working on we focus mostly on the clients investing themselves and using the station evidence as the credentials so we've been working on a free funds essentially so the first part is adding support in embed TLS for the handshake so trying to bring it up to speed with our with our draft then on the route of trust side we're trying to use the TPM and we're trying to adapt parsec to produce the the correct type of evidence and then on the verifier side we're trying to use Verizon and adding support for um for the same kind of formats uh that parsec is producing [Music] yeah so what we've learned mostly is that we had some gaps in some of our formats for example for in the in the evidence we needed to include some inbound reference to the verification key the testing key and also uh the interface between"
  },
  {
    "startTime": "01:50:02",
    "text": "Verizon and Matt TLS we needed to embed some sort of that's going to be used in our in the TLs handshake so yeah that's that's something to to do and change the documentation as well and yeah that's about it this this is our team and we're trying to Harbor this under the confidential Computing Consortium thank you thank you so this is the final presentation we have in the in the meter Echo did we miss a present project presentation no okay then I'll ask Charles to the closing I think you want to go here okay uh great well well thank you everyone for those great presentations been a fantastic job running through them all uh may have been a record number I'll have to go in and check our previous totals but uh really appreciate um all of you joining the hackathon all the great work you did and and sharing your results that was really fantastic another thing I'd like to invite you to do is tomorrow we have hack demo happy hour it's from six to seven it'll be in this room I think this room won't be quite as large it'll be divided up but we'll have some space here with tables we'll have a cash bar and so what you do is you sign up and then you'll get some space where you're"
  },
  {
    "startTime": "01:52:02",
    "text": "signboards and you can talk to people about your projects in more detail right you'll have a whole hour where you can go a more in-depth conversation about what you did and and discuss with them some of the finer points around it so I encourage any of you who are able and wanting to to do that to take advantage of that opportunity uh we usually get at least 10 or so teams sign up and have a good crowd of people coming through some of who participated in the hackathon but a lot of them who who aren't here who are just arriving now and and maybe heard about what you were doing so um it usually ends up being a really good opportunity a really good experience the other thing uh I think you heard the l4s team is going to remain with their stuff set up and they'll be continuing to do some work during the week all of you are welcome to do that we'll have space in this room um set up kind of as the the ITF Lounge but also as the code Lounge a part of it will be kind of separated off we'll make sure we have ample power and whatnot for you to come down uh if you want to you can you don't need to reserve space or anything like that but there is a a sign up board where you can just advertise to everyone else but when you plan to be here just to help coordinate schedules a bit so you can go to the the webpage that's there you can sign up and you're also free just to pop down here anytime so that'll continue throughout the week Monday through Friday uh then uh mentioned this before but also wanted to say it again we really do appreciate our sponsors I think I know I had many people tell me hey you know like the the food and beverages here that was really great they appreciated that uh [Applause] so you know thanks to the uh um"
  },
  {
    "startTime": "01:54:00",
    "text": "our our sponsors for that we were able to to make that happen I think we all appreciated it and for each hackathon we always uh need new sponsors or are looking for for new and additional sponsors as you can see here we're able to have more than one that we have sponsorship at different levels um so that's all very appreciated and enables us to continue to to do this and and to have a nice setup and all that so um please encourage if you work for an employer or anyone else who who might be able to sponsor us in the future that'd be great and I want to give an early reminder for the next opportunity the next hackathon it'll be uh in Yokohama so what I have up here are the dates of the entire iitf meeting I guess uh the Saturday and the Sunday it will be the hackathon so the 25th 26th that weekend of March uh maybe mark your calendars and start planning your uh your time so that you can you can be there we'd love to have you there and uh with that you know we're we're wrapped up here but I do want to uh say a big thanks to I think Barry had to run for another commitment he was back there until just about a minute ago um but he was helping behind the scenes with a lot of your requests to get added to to mailing lists to get added to the GitHub to upload your when you uploaded your presentations to the GitHub he was getting him into mitecho so that that no could actually bring them up uh the miteco folks were working really hard because you know it's it's a lot of presentations all coming together at one time that's not a typical thing for a meet Echo session and uh and I think it worked uh relatively well so so thanks to everyone who helped make that happen also the Secretariat and the knock team that's been helping us tremendously throughout the whole day so thanks to everyone congratulations on a great event and I hope you have a fantastic ietf week"
  },
  {
    "startTime": "01:56:00",
    "text": "foreign"
  }
]
