[
  {
    "startTime": "00:01:09",
    "text": "hey y'all um we're to get started in a moment but do we have a note taker is anyone willing to volunteer to be a note taker oh great thank you i think uh chris woodville and threatened earlier for whatever parts he wasn't speaking for but a second second set of hands would be good all right richard good to get started perfect yep whenever you're ready yeah i think if you think we have the people we need"
  },
  {
    "startTime": "00:02:00",
    "text": "what's going on your audio's a little bit um unclear to me but maybe that's just me but okay cool all right um welcome all to ohai i am one of your chairs siobhan and we have richard joining in remotely and yeah i think this is the note well please note it well also the ietf has a masking policy which means that if you're in this room you should be masked so just keep that in mind and just a reminder that we are using meat echo and we will be having like a virtual show of hands at some point in this meeting so you will need to use the on-site tool if you're in the room and then in meet echo i think if you're online then you should just be able to you you'll get a pop-up um over there so yeah just um just keep that in mind that you might be asked to use the on-site tool um perfect and we have a note taker thank you eric so i think we can get started um chris or martin who is doing the presentation chris okay perfect what's that yeah all right okay um this is just uh hopefully the last update for the main document that we're working on this on this particular group ohttp next slide"
  },
  {
    "startTime": "00:04:00",
    "text": "please there are a number of updates based on the last version of the last couple versions of the draft between last itf and uh and today i think the biggest one is the state-based anti-replay mitigation that we discussed in ietf 113 basically the idea being that if a client sends an encapsulated request to a gateway that can't process it because it was like too old in the past or the clocks are too different the the gateway would just respond with like here's a new uh a date to retry your request with such that i can apply like anti-replay i mean in a meaningful way without keeping endless stay on my side um we went through the use case last time went through the proposed mitigation um the pros mechanism and uh the text was landed in the draft uh however as i'll discuss in a little bit um we've now yanked uh some of the the the contents of this particular mechanism that were previously outsourced to another draft that martin wrote back into the main spec here um and there's a pull request up for actually landing that particular integration um and that's one of the like remaining things to be done but it's it's basically just moving bits around between two documents anyways um beyond that actual mechanical change in the draft there's a number of like actual terminology uh and editorial things that we we we fixed um we we as people probably saw we had this tremendously successful bike shed on the mailing list where we like moved away from proxy to relay and target to gateway um hopefully to make the different roles of the parties in the in the system more clear and there and what they're doing um and we we did our best to make sure that the the contents of the the draft actually match what was uh discussed in the mailing list but there may be some like residual references to proxy or whatever so if there are please be sure to let us know um"
  },
  {
    "startTime": "00:06:01",
    "text": "improve text on um various like privacy related things in particular like what can happen if a relay happens to be uh offering different services to different clients in response to like how a client is interacting with a gateway uh or how a client is interacting with a relay and what that differential treatment has on the privacy posture of the client interacting with the gateway um the the primary motivating example for this particular body of text was the shadow banning use case where relay might want to signal to the gateway hey this particular client is uh you know has been flagged by some mechanism and the relay or the gateway might then choose to act differently based on this particular bit and how that impacts the the overall privacy posture of the client uh is worthy of consideration so now there's text that actually talks about this um the big like breaking change in the latest version of the draft thanks to david benjamin is a change to the key schedule a very minor change but it is a breaking change nonetheless um and we'll i'm just going to quickly summarize what happened uh in the next couple slides so next slide please um okay so the old key schedule looks something like this uh i've simplified things uh a lot just to kind of show where different inputs to the the key schedule go um some of the inputs like for example on the on the left side with the client you have like the the gateway's public key uh you have the context string for hpke that's fed into like create an hp context for actually encrypting or encapsulating things to the to the gateway um at the bottom we have what i refer to as the ohb configuration parameters that includes like what uh what hbt cypher suite chem kdf aad and whatnot was configured what the key id uh was for that particular uh uh and those are bound to the actual"
  },
  {
    "startTime": "00:08:01",
    "text": "encrypted request that goes out uh note importantly that the the these configuration parameters are not bound to the key that's exported from this http context um which is relevant should go to the next slide please because this exporter key is the thing that's piped in uh and used by the the the gateway for actually encrypting a response back to the client so um we had the situation where the ciphertext was not entirely bound to like basically everything the client had when it started its encapsulated request it was only bound to public key and the content or the context string which is ohtp uh slash request and the fix was simply to next slide to lift everything that was previously piped into the aed and just like plumb it into the hpk info uh based into the hp key schedule so that it gets folded into the export key such that uh the request that gets encrypted from the client as well as the corresponding key or content that's encrypted from the gateway back to the client using the exported key it's all bound to uh basically everything um and there's not like at the bottom i've written that there's nothing that's sent to the aad as additional authenticated data because everything is now piped in through the hp uh info parameter and therefore about to the key schedule so there's not any more possible binding that we can do i think this is like the this is complete okay um and then as i was referring to earlier we had this other other uh big kind of mechanical change that was landed in the last version of the draft between uh or since the last meeting um we were previously referencing this this draft that martin wrote um but uh kind of in a unknown stalled state in http right now so we figured rather than just block on that and definitely let's just yank the stuff out of that draft that we need for"
  },
  {
    "startTime": "00:10:00",
    "text": "osu tv specifically um and then make forward progress so there's a pr of pr137 that basically does exactly that it takes the pieces that are relevant for oh tp adds them to the to the document and describes basically how clients should respond if it receives a date or a response that's not successful with a date uh header in it um and it talks about how a gateway should use that header uh or that yeah sorry use that date header for the purposes of triggering this retry functionality from the client um and there's lots of privacy considerations there about like clients should not just indefinitely retry with you know uh um uh new dates and whatnot and should not use a date from a response uh that it gets from a gateway for more than one request and so on so relatively straightforward um and this is purely editorial just lifting text from one document to another thanks a lot please okay uh at this point i think uh barring merging this particular editorial change the documents feature complete we have a number of interoperable limitations at this point it's a simple protocol and i think at this we're kind of ready for a working glass call unless there are any other things that people would like to add so uh i'll turn it to the chairs now to see what they want to do yeah i mean if folks have comments on that please line up i guess on both the issues and on the particular issues that chris talked about but maybe you can start with that does that sound okay to folks okay do you folks have comments about uh last call we'll also do a show of hands but if there are any um serious concerns then right now would be great to hear them"
  },
  {
    "startTime": "00:12:01",
    "text": "does anyone know any reason why we should not uh send this document off in the working group last call speak now or hold your piece into the last call maybe a good question to ask is have folks read the draft i'm going to start a show of hands online um if you're on site you will have to join the the onsite tool i skimmed it so we have folks chiming in right now about an even split so far okay you know nearly a dozen people who have read it seems pretty reasonable you have about 68 people in the room so it'd be great if folks can say what they whether or not they've read the draft just giving it a few more seconds okay i'm going to close it now there's about i guess out of the 40 people who said the people who participated in the poll 15 people said that they have"
  },
  {
    "startTime": "00:14:00",
    "text": "and 26 people i guess did not raise their hands um so then let me just end this and then ask my second question which is do you think the draft is ready for last call do you want me to look for you okay yeah and the folks who said no it'd be great to hear why or if um if folks don't have if the people who are saying like who voted for no i can also assume that that that means that um you don't have an opinion which is fine but uh it would be great to hear any concrete reasons as to why not okay i think we can close the session um like overwhelmingly people who participated in the poll said yes so i think we'll confirm on the list as well but this looks pretty great um great is there anything else you guys want to talk about no we'll uh we'll we'll merge the the pr's that are open um we'll add some editorial text for your issue and then i think we can move forward we'll cut a new version soon sounds great thanks chris"
  },
  {
    "startTime": "00:16:08",
    "text": "i think yeah tommy um did you want to talk about the svcd okay hello everyone i'm tommy pauly from apple and we have a document we talked about last time i think uh teru also was helping on this and essentially now that we have our basic ohtp definition uh this is getting a little bit more into some of the use cases and deployment models um the kind of default that ohtp has expects that you have very coordinated deployments where the clients and the targets and the gateways and the relays kind of all know that they're working together and that is all out of band that works fine that is certainly one way to use it but there are also potentially some use cases for doing a bit more dynamic discovery and so that's what this document tries to talk about next slide please so i'll talk about two different use cases here of like the general model for how you would imagine this particular form of discovery being performed so we start out in this world with a client that knows it wants to use a particular target service it's talking to it"
  },
  {
    "startTime": "00:18:00",
    "text": "already or it knows it's about to talk to it and the client also knows that it has some trusted relay service that it prefers to work with or it knows has access to somewhat generic um ohtp gateways next slide and if in this scenario the client can learn that the target service has an associated oblivious gateway that this target service prefers to use to provide access to it then next slide the goal is you know is there a way to essentially upgrade this path if the client wants to to go through its oblivious relay through that oblivious gateway to get to that target service as an alternate way to reach that target service as opposed to going direct next slide the second use case is one in which you are using this target service through the oblivious gateway as an option that you otherwise would not use so the model that we have here is something that we practically have when we're doing dns over oblivious http and in this model let's say the client has its trusted relay again and it has a default oblivious gateway and a default dns resolver that's going to use in general it already has this provisioned out of band but then it is interested to say that if in under a certain scenario like it's on a network that has um a resolver configuration that it would prefer to use because it provides the right either filtering for the requirements of being on the network or resolution for access to uh internal domains that are particular"
  },
  {
    "startTime": "00:20:00",
    "text": "to that network if the client can discover that there exists this dns server that has a oblivious gateway it could use that in addition to its default service or in place of its default service and this works well with some of the add work around discovering designated resolvers so those are kind of the two models that this document can serve through a single mechanism next slide so the scope of this document it's pretty short um we've gotten good feedback and i think the the current shape is something that kind of is a bit more of a complete story and can actually work viably there are two parts to it one is um essentially a way to learn that a service has an associated gateway which is kind of one piece of the puzzle and i would like to thank the main ohtp authors for clarifying terminology around gateways and targets because that makes it actually much easier to refer to things and be clear about what we mean so essentially you have the full uri of the gateway and that can be stuffed in a dns record in svcp parameters and then the other thing you need to do as a client is know what is the key configuration and the current way that is done is just saying hey if you have this gateway that you would normally do a oblivious request through a post to let's just do a get and specify that i want to get the key configuration from it and that is a way to fetch that these are just essentially the proposed mechanisms i think for any discovery mechanism like this thus trying to achieve those goals these are the two pieces of information you need um so we can of course debate what is our preferred way of getting these pieces of information next slide please so just concretely"
  },
  {
    "startTime": "00:22:02",
    "text": "we have the dns response which can include the oblivious gateway and it's just encoded there as a url and for the key configuration query we just do a get and we say i want to get the ohtp keys so it's pretty straightforward from that perspective next slide i think the interesting part here is how you protect against uh key targeting or url targeting and making sure that uh user that's learning about this isn't being singled out um if you do have a unique gateway uri or unique key config then the client could be targeted or identified when it's using the service um you could have your proxy or relay try to participate in recognizing like oh yeah this is a common gateway versus that's a gateway that only you are using um but there are different ways of doing this i think this is where a lot of the interesting discussion lies and i know that there are multiple other conversations in this working group and others talking about consistency and key targeting and ways to mitigate that so i think this can fold into that broader conversation as something that would like to benefit from those next slide so that's it um i think at this point it's mainly a question of you know is the working group interested in taking on uh the discovery of a gateway and config problem um i think it's in scope for what is in the working groups charter we're kind of done with the main protocol so it seems like if we want to do this at some point then this is a decent time to do it um love to hear your feedback ben schwartz oh i forgot to use the q"
  },
  {
    "startTime": "00:24:01",
    "text": "martin's actually in the queue um so uh i i'm having trouble understanding the the security properties here uh it looks to me like this still suffers from some of the same problems that that i was concerned about with the the first revision of this draft which is that an intermediary on the dns path that is that can modify this this record could swap out the gateway for entirely for their own gateway and as far as i can tell there's nothing here that would that would uh that would detect this on the on the client side so i could take any origin in the world even in origin that doesn't have any support for oblivious http and if i can intercept the dns then i can inject myself as the gateway claim that ohttp is supported and then impersonate that origin essentially bypassing the protections of tls um so i think in in this case that mainly comes down to you know how do we do some sort of consistency check on the side which i think it's important and i think that's something that we should talk about so the thinking about consistency for a moment it depends what you mean maybe if consistency is about making sure that a given gateway shows the same key configs to everybody then it's definitely not sufficient here because i can mint uh first of all that i don't need to um i can give a a single the attacker can can have a consistent gateway uh and still be consistently impersonating yourself well and i think one thing important parameter to keep in mind here is that ojai provides no"
  },
  {
    "startTime": "00:26:01",
    "text": "if you're accessing a target over over oblivious http there is no confidentiality or integrity protection against the gateway uh that's right and that's why the gateway always has to be provisioned through a trusted channel and in this case i see the gateway being provisioned through an untrusted channel at least in the threat models that i'm used to okay so on the adoption question i do want i do want something along these lines i do think that i'd like to to see the working group work on discovery but i think maybe we need to have a little bit more consensus about what direction we're going to go before we proceed with an adoption sure i'm happy to have the working group work on that too i'm more interested in saying that the working group should be working on the problem that's a good one yeah so i i think this is an important point and and i i've just made some changes i think to the to the base specification that sort of addressed this point if you have the gateway operating on the same server as the target then i i think the concerns that you have uh are less lesser yes than than previously and i think that's what tommy wants to do yes but that is an interesting point that if they are not co-located how do you establish that they're actually related but if they are like if you use the same tls handshake to get to them no matter what right like if the thing i'm fetching my key config from with the get request is the thing that i that is my target service does that provide enough finding to trust it yeah but but no ben's right um he shook his head there there is there are those scenarios where you have multiple tenants on the same host sure some of them have control over some resources but not others and if they're in a position to put themselves in the position of the gateway they are then able to do that which is why i think the use of dot well known in this context does give us something"
  },
  {
    "startTime": "00:28:03",
    "text": "uh okay i i moved off of well known because you said you didn't like it i know i'm happy to move back not well known yes but i've i've realized that i think perhaps in this case we probably need something along those lines because of this reasoning and and that's only a recent realization of my part and i think thanks to ben and richard and others for pointing out some of these flaws i think that's probably where we're going to need to go with this one unfortunately that makes sense might be better because we have fewer parameters in there yes in our service which is awesome yes yes it does simplify that yeah eric gorth google um i i believe i agree mostly with what ben and others are saying about all the correctness and consistency concerns it is an area we definitely need to solve there's huge concerns there sure but i think that's big enough area to solve that that should be a separate draft and i think ben's presenting one that one something like that in 15 20 minutes from now so we can discuss that a little bit more there but assuming we have stuff like that solved in a separate draft saying here's how to get these packets of information securely and consistently i think there's good room for this draft to focus much more on just the payload itself say here's how you give the discovery from the key info in dns here's how you give it in an hp request and then point to the other stuff and say these are the ones that tell you how to fetch that securely and safely and all that stuff and those ones can point at this one say here's the the format of that so i'm very supportive of working on stuff like this and adopting this as long as we focus on that and probably in a separate draft we have to handle all the consistency and corrective stuff because that's hugely important and probably poor enough to be separate draft from this one yeah makes sense i think with that the group does need to work on discovery i think it's really important um i think though it'd be helpful to try and ensure that there's a separate discovery"
  },
  {
    "startTime": "00:30:01",
    "text": "for the gateway and the relay to minimize the risk of collusion between those two they're discovered using the same mechanism i think that that is risky right and this mechanism is explicitly only about the gateway associated with the service which to martin's comment earlier probably needs to be entirely co-located in order for this to work like essentially to recognize that the target has a gateway um the document says like yeah the relay discovery is out of scope and i think if people are interested in relay discovery which is fine that is something that needs its own considerations and likely would be related to discovering more general purpose relays because an ohp relay likely would be able to serve as a much broader category of relay for things like mask or just being able to do other dns services so for the avoidance of now i think both should be addressed so it'd be good if both were in scope yeah um i i do have a little bit of a question on the the relay discovery question if depending on what that mechanism ends up being that may not belong strictly in ohio if it is something that is potentially more generic whereas the ojai gateway configuration really is truly specific to ohio and doesn't apply to anything else so that's why i believe it does belong clearly here and i'm just not sure about relays do folks have opinions on whether this like as the document right stands right now like this is the right direction to go in like gateway discovery driven by target yeah chris would i i do think so i mean sure there might be some key consistency things we have to sort out but um this draft is a good step in the right direction and i think it should be adopted um i do not think we should pull in things like uh relay discovery i think that's a"
  },
  {
    "startTime": "00:32:01",
    "text": "separable and much harder problem as you have indicated so and i'm i'm happy to like switch things to well known and address the security thing before we talk about adopting it too like that's a that's just a trivial revert they all they also seem like perfectly reasonable things to bash out in the working group i think the problem is clearly stated in this document and i think we all understand it and we think it's useful to solve um that's my impression do you think maybe like a revision first and then yeah yeah i can revise that like next week and then we can talk about further thank you sounds great thanks great i think we have dan next yeah can you share my slides or should i yeah cool um i can handle the control right okay you should have control now then okay um so i'm presenting um on behalf of my co-authors um turo just started working for nokia this week but because the draft is still showing him as the um affiliated with akamai we're we're leaving it there so we made some changes to update uh the document based on some feedback and to align it with the http api rate limit headers we'll talk about in some details so to recap what this draft is doing is trying to help identify misbehaving clients that are abusing the target and allowing the the proxy to know about those and uh slow those down because the alternative is bad"
  },
  {
    "startTime": "00:34:00",
    "text": "the alternative is slowing everything down um so the um the change to use the http api rate limit headers is we're extending those slightly to include detail that is just for the proxy so that the proxy knows that it's supposed to process that header and deal with it and not pass that on to the client because it's it's not useful for the client um so the uh underscored and highlighted uh text here is the extensions uh that we're describing in the draft now uh the http target equals two i talk about in a couple of slides from now and uh that that is a signal to the uh proxy that this is um a certain style that you know of a attack and a certain style of behavior that we would like to see from that proxy and if the proxy can't meet that there's there's no feedback that it can't or it won't it's just a way to hopefully prevent all the traffic from that proxy from being throttled by the target because of a single misbehaving client such as one sending malformed http or or some other sort of attack traffic that you know is is either purposefully malicious or accidentally malicious because something has gone wrong in the client and this is the example message flow um it's very much like uh the http api uh that we're patterning this after uh but we're just tacking on the o http target parameter to this uh that is processed by the relay that's proxying the traffic"
  },
  {
    "startTime": "00:36:06",
    "text": "and uh the interesting one here uh you know one is somewhat interesting um number two is is where it's more interesting uh in that the the client traffic is identified by the target as being somehow malicious malformed http is the easiest one to conceptualize and the other change that we made that is probably interesting to the working group is the proxy doesn't need to take take account immediately but can wait until it receives several of these messages from the target complaining about about the same client and then start taking action against that client to rate limit uh what it's doing the purpose of that is to prevent uh the partitioning of uh good clients from bad clients uh or rather they pretend to prevent the partitioning of good clients and good clients such that we're only partitioning the good clients versus the bad clients where the bad clients are generating uh bad http and bad transactions uh and one other addition to the draft is a mechanism for the proxy and the target to communicate with each other about which headers that they're going to understand between each other the value here is if they're not configured by the same entity where the the changes can be pushed out at the same time then this helps prevent inconsistencies in the configuration between the proxy and the target so that they understand the headers that will be stripped by the proxy and the headers that will be sent by the target and that's this draft"
  },
  {
    "startTime": "00:38:00",
    "text": "are there any questions and schwartz uh so yeah i i think this is similar to to my previous concerns here the the o http target equals two setting appears to allow an instruction from the gateway to the relay telling it to apply special treatment to a particular user uh it seems difficult to me to understand how you do this within the ohtttp threat model basically the the gateway if it wants to try to link different requests if it sees a bunch of requests coming in uh and it wants to slow them down that that in a sense by definition is linking them right if you believe that that this particular flood of requests all comes from a single user being able to answer that question in any way breaks ohtttp's unlinkability guarantees so uh so it's i'm not saying it's it's technically impossible i'm saying that we need to be very careful about what we recommend here because we're punching a hole in our own in our own privacy claims right okay uh and so i think uh i think there's a really interesting question here about you know what a relay can safely do or how much damage it does when you know when a relay starts to comply with these kinds of requests and i would certainly before the draft was adopted i would want to see some some very sharp analysis about what damage that is okay that's fair thanks yeah i think i i think i have similar concerns to ben here i think that there has been some changes in the base"
  },
  {
    "startTime": "00:40:01",
    "text": "document where we talk about the sorts of things that a client might be need to be aware of in terms of the way that the proxy or now the relay might apply differential treatment based on characteristics of the client so for for example if if you wanted to implement a shadow banning type arrangement and the relay was aware of a flood of messages coming from a particular client it might include a one bit of information toward the gateway or the or the target that would allow the gateway and target to differentiate behavior with respect to those particular requests so that's one type of treatment that we've considered but in doing that we've been trying to be very very clear that the client needs to understand the scope of the things that are possible in that context once you add feedback into the loop it becomes much more complicated in terms of giving the client some confidence that the um the gateways and the targets aren't trying to back out the privacy protections avoided by the relay and so i see a lot of positive movement here i think that um the sorts of things that you're doing in terms of trying to disconnect the immediate effect of the feedback from from the actions that um occur is probably a good direction to have i'm afraid i haven't read the very latest in this but i would like to be more confident that that analysis was good before i be confident moving forward i think there's probably a few things we could change about the spelling as well but that's that's separate okay thanks man does that sound good ben sounded like the consensus is not yet um and we can revisit this in a bit okay sounds good thank you thanks"
  },
  {
    "startTime": "00:42:09",
    "text": "ben uh hi benchwards is there a clicker is there a magic clicker no okay uh the agenda said i had five minutes so i squished these slides down to nothing to uh to try to squeeze it all in it seems like maybe we have a little more time than that yes uh but so maybe i'll i'll try to explain a little more what's going on so this is a presentation of the first presentation of a new draft from just me for ojai and this is about trying to solve what i think of as the gateway key consistency problem for for oblivious http although it might have some more general applications um but let's let's move to the next slide so uh i think it's easiest to to think about this in concrete terms so let's let's pick uh an arbitrary concrete example and talk about this sort of telemetry use case that's mentioned in the o http document so imagine that your os default installation state reports telemetry to some sort of remote service and that remote service supports ohttp now you believe that the os image or i'm sorry i believe that my os image is the same as everyone else's i haven't been served a custom crafted os image that points me to to a unique uh instance of the telemetry service so i believe that that there's essentially that is already consistent um but i still don't trust the telemetry"
  },
  {
    "startTime": "00:44:01",
    "text": "service not to try to link my reports together if i trusted it then i wouldn't need ohttp so i've configured my os to make use of that oh db service i'm using an ohttp relay and i trust that relay not to collude with the telemetry service but in this case also i don't fully trust the relay i don't trust it to see the plain text context of my reports otherwise again we wouldn't need ohttp so this is this is trying to get to the point where we actually need ohttp at all uh oh db serves a pretty narrow use case okay so so with all those assumptions how do i convince myself that i'm using uh the gateway url key config and target url so in this case the target url is the telemetry service how do i convince myself that those are authentic i'm actually talking to the telemetry service not some random attacker and that they're the same ones that everyone else is using because if any of those are unique if the gateway url is unique if the key config is unique or if the target url is unique then i am uniquely i'm linkable and so i've i've lost my ohtttp protections that's the so that's the problem how do we actually get the ohtp protections next slide okay there's an easy answer to this you just hard code all of these right into the os image we've already assumed that the os image is globally consistent and i haven't been served a unique os image that was custom crafted as an attack on me so that's that is the easy answer and it does work and we can generalize this and say you know any any o http system assumes some kind of trusted bootstrap stage that is serving providing consistent information to the world i could just get all of this through whatever my bootstrap stages that's that's fine"
  },
  {
    "startTime": "00:46:01",
    "text": "but i i don't think it's very attractive as an operational practice among other things it prevents key rotation if you bake the key configs into the operating system you can't rotate the keys so that's a that's a pretty obvious problem and there are other changes you might like to make maybe you want to maybe your gateway is operated as a hosted cloud service and you want to change service providers to a different gateway operator next slide so this proposal tries to solve that it tries to enable in a sense dynamic bootstrap without losing the ohtttp privacy guarantees and this is how it works first first you you create some kind of config file that holds the gateway url the key config and a description of the actual service you're trying to reach target url i have been calling this the service description host uh that's the origin that hosts this thing uh this is all uh there's another draft that i'll be talking about in mask that actually lays out a format for this kind of config file but the the exact format doesn't really matter here so uh we fetch this config through the relay and we ask the relay to act as a cache and this is basically just an http cache this is like an old-fashioned http forward proxy before https so it's like a caching forward proxy we just ask the relay to fetch the the service description for us and since it's in cash it's usually in cash uh we we get back the same answer as all the other users of that relay crucially uh one of the one of the crucial observations here is that the consistency problems for ohttp are only scoped to each relay it doesn't matter whether users of"
  },
  {
    "startTime": "00:48:00",
    "text": "different relays have consistent views here so like we've talked one of the things that comes up occasionally um and chris wood has enumerated and i draft all of the sort of basic strategies for for dealing with the key consistency problems some of them look like blockchains and uh you know that's a very powerful global consistency mechanism but it actually doesn't really matter because uh it doesn't matter beyond the scope of a single relay if you if you're using a different relay you're clearly a different user so uh so to to get consistency scoped to a given relay we just uh essentially read the description out of cache held in that relay so all the users get the same copy and that gives us consistency but it doesn't give us authenticity again we don't trust the relay not to try to impersonate the gateway so uh the the relay could just be lying to us giving us its own key config so to solve that we fetch it again and this time we fetch it directly from the service description host over a standard authenticated https and now that gives us authenticity but it doesn't guarantee consistency so to make sure that we have both we just check that they're identical and they should be identical there's a little detail here that we ask the relay in this system to also be a mask proxy so connect udp proxy uh that seems as as tommy suggested earlier that seems like something that may be pretty common and that's not strictly necessary actually for uh for our consistency guarantees but if you don't do that then the gateway ends up with a list of all of the ip addresses of the users behind the relay and while it can't uh can't then link requests to one or the other you can imagine that it might for"
  },
  {
    "startTime": "00:50:01",
    "text": "example take those ip addresses to a data broker who tells it more information about the users that it could eventually use to profile them and identify you know this this request is really only likely to have been from this particular person who i know know quite a bit about via their ip address and quick quick clarifying question here uh you're assuming the relay and the service description hosts are not colluding correct i'm sorry i can't i didn't quite understand the audio sorry i was asking if you were assuming that the relay and the service description host are not colluding with each other because it seems like if they are then the relay could lie about the cache the data in the same way the service description host does i think that's right the service description host is is with the gateway and target in the sort of ohtttp partitioning of roles so the service description host is assumed to be an agent of or closely affiliated with the gateway and target okay thanks okay next slide okay there are a lot of details in the draft about exactly how this works it's all in the draft in this proposal it's all stitched together from standard http stuff lots of different headers for standard caching headers there are a few slight tweaks beyond what is just required by the standard implementation of these headers and that gives us defenses against a bunch of different kinds of attackers so we we consider both in malicious relays and malicious service description hosts slash gateway slash target as as i was discussing earlier the draft also tries to acknowledge the possibility of malicious clients who are colluding with the service description host to for example try to"
  },
  {
    "startTime": "00:52:01",
    "text": "overflow the cache of the relay in order to reset its state in order to serve different service descriptions to every user for linkability and the draft also talks about the performance considerations you might think that fetching the fetching this service description twice before you can use it is a big performance penalty uh i actually think it's pretty manageable my in my analysis through the in the draft i think it adds up to about two round trips basically the same as a fresh quick setup one one round trip to set up quick one round trip to fetch the uh to fetch the resource but uh i think that for most of the use cases we're talking about once you get that service description it's good for hours two days so two round trips once a day uh or something like that i think is is pretty manageable uh okay last slide so uh i my current thought is that this could be a good document to fit into ojai uh and uh i i think it's it'll probably evolve quite a bit but uh i would like to see it see it move forward here to try to unlock some of those broader use cases where you're discovering your uh your gateway uh as you move about the internet cool um martin i think you were first no hi ben thank you for sharing this um i originally was going to come up with just kind of about a nit for where you're listing like oh the"
  },
  {
    "startTime": "00:54:00",
    "text": "other check would be connect udp i you know that works if your target server is doing quick um it obviously could just be uh another h2 server so like you know connect connect udp some variant of that and i think really rather than talking about that it would be useful to structure this in terms of the like the tls context in which you are fetching the key config right so like you want one tls con like a tls connection to the actual service description that's like um authoritative for this target and then another one so to a different context which in this case is the one on the relay so like you have essentially two tls handshakes to two different entities and they both agree and then really at that point i imagine like that other one doesn't even need to be the relay that's caching it could just be anyone else so i think this sounds like it generalizes to check with the person who says they own the key config and check with someone else in two different tls handshake contexts and then that gives you a bit more trust is that right i i think that's that's probably mostly right i do think there are some reasons to focus on this on on this assignment of roles one of them is if um if if you're the rule is that you just have to check with some independent party and there are 10 well-known independent parties that people like to use right and then all the people on your relay choose one of them at random then you've partitioned yourself into 10 buckets on that relay so it helps a lot if everybody on the relay is using the same cash so well it doesn't have to be physically on the relay it does help to connect it right but that seems like it's like a you know maybe it should be on your relay but you could have alternate setups in which everyone talks to a different cache that doesn't have to be the same box as"
  },
  {
    "startTime": "00:56:00",
    "text": "your relay yes i think it just helps if it's affiliated in a sort of one-to-one way cool yeah so i think the um the way that you structure this is quite good i like the idea of using a double check sort of technique i don't think the connect aspect to this is necessarily important here as much as the the point that you just made about the the relay being involved in caching the information so concretely what what you're describing is you're going to talk directly to the authoritative source because that's necessary for correctness um the relay can't give you any assurances about correctness if you ask for its cash copy of it but the relay does give you the ability to get some amount of consistency uh out of that and so that's the structure that i would look for i don't know that i like the connect stuff that you've put in this document i particularly don't like the fact that you've added a requirement for connect udp which means that you've got connect not only connect udp but a requirement to use http 3 and a bunch of other things as well which i think is somewhat more onerous than what we concretely need in order to obtain the properties that you're looking for so i i would prefer to to maybe step back a little bit and look at the abstract thing and talk about those those two things that i talked about before and then um talk about why you might choose to do things like connect tunnels and other things as optimizations or so on and so forth as as enhancements rather than than being part of the core solution that you've described sure uh i would be interested to know whether you think in general for ohtttp you know do you feel it's important that the gateway not learn the client ip addresses as a as a whole the pool of client ap addresses"
  },
  {
    "startTime": "00:58:00",
    "text": "uh the gateway i i don't think that in general that's that's a problem i think it may become a problem depending on certain deployments and contexts yes particularly when you consider the possibility that clients might also be connecting to the server that operates the gateway for other purposes outside of the this particular usage so um it's something to think about and we should probably document the consequences of taking the direct route as opposed to a proxy drought but um concentrating on the core which is we want correctness and consistency and and how we achieve that is probably where i would like to see this go first okay thank you last question eric google a couple comments first i really like this overall i've been saying for a while that practice and consistency is something we really need to solve and this is you've taken a pretty good approach here i think and i i want us to work on and fine-tune this um next comment those are the correspond comment what i said earlier in discovery and the config distribution i see that one focusing more on being the payload and this the draft you have here currently does have a payload listed in it and it's okay we're just being redundant and this is doesn't mean that so this should be point of that and that should be pointing to this just strip the payload stuff out of this um third comment though once we've removed the specific payload from this draft this just becomes a generic draft for receiving a shared payload with proven correct and or validate correct and validated actually shared and it's not even using oblivious itself so this stops feeling like an oblivious specific thing other than the fact that we really need it so at the cost of potentially slowing down a draft that i want yesterday i almost suggest that we should maybe send this to a dispatch group to see if there's a better more general place with the night you have to have this"
  },
  {
    "startTime": "01:00:01",
    "text": "and if no if we can't find a better place then yes then we actually should adopt into this group then because we do need it sure i do think that ohio is the right home for this i you know i prefer not to try to go through more processed steps there on the format point the this draft does try to lay out a fully concrete instantiation of this thing in order to do that by my logic we need a format that can convey the the target key config and gateway url as a as a unit because they need to be cached atomically and and rechecked atomically uh so uh and that format i will be talking about in the in mask because it also embeds uh it also has the ability to represent mask information and dose servers and uh you know as we were just discussing those are maybe not necessary for this um to use this draft but or to use this strategy but appear to be beneficial for privacy when using this strategy so i think ben i think we should wrap up um it's yeah we're over time yeah so i think we can take this on the list all right great thanks all for coming um i think the highlight was that we decided to do a last call for the main protocol draft and there's some great new work lined up so see you all next time take some time everybody bye um"
  },
  {
    "startTime": "01:02:23",
    "text": "you"
  }
]
