[
  {
    "startTime": "00:00:06",
    "text": "[Music] it is when he gets extra points all right Thank You life Thank You Wendy okay let\u0027s get started so this is the HTTP session this is the note well you should be familiar with this this is the terms under which we participate here especially regarding intellectual property if you\u0027re not familiar with this you can use your favorite search engine to look for IETF note well likewise this is an environment where we want to keep it professional we have an Ombuds team sorry Ombuds team I always get that wrong if you feel that you have an issue where someone\u0027s behaving unprofessionally harassing you you can contact them and they are the three people at the bottom of the slide the blue sheets are going about we have a scribe and Gabriel thank you once again can someone act as a job or a relay for any questions that come up there anyone I have a hand in the back thank you that was Ted and agenda Bash today our session we\u0027re gonna have about thirty seconds talking about the contribution policy to make sure that everybody understands what we did there we have a session of proposed work so Mike\u0027s going to talk about secondary certs Patrick\u0027s gonna talk about WebSockets and h2 and I\u0027m going to talk about HTTP Terr or a business or primer or whatever we decide to call it and then depending on time of variable available we\u0027ll talk about some related work that might eventually be proposed work I\u0027m gonna talk about variants we have Siobhan talking about four or five one new protocol elements and finally Adrianne talking about HTTP payments any bashing on that okay yeah Friday is is is the session where we\u0027ll talk about all over active drafts and we\u0027ll go over those then so first of all the contribution policy I just wanted to take a very quick moment and make sure everybody understood oh great the screen blocks the other screen so we talked a little bit on the mailing list about revising this slightly to align better with what\u0027s happening over it quick and the big change here is is that we now don\u0027t go through a formal process of saying that all closed issues are have working group consensus though issue status in terms of open closed more reflects the editors feelings about where the issue is so we use it as an internal tracking mechanism when we need to declare consensus on an issue and say that this issue truly has working group consensus "
  },
  {
    "startTime": "00:03:06",
    "text": "we have a special tag for that has consensus but the general process is you know we gather consensus as the director progresses and we confirm final consensus in working group last call is that understood I think it\u0027s fairly uncontroversial we talked about it on lists I just wanted to make sure it was in front of everyone okay great so let\u0027s move on secondary certificates Mike you want to come on up and I\u0027ll get your presentation up oh they make the the pink box rather tiny this year this only goes up so far okay so the slides coming up here secondary search is something we\u0027ve talked about a bit in the past we have been kind of quiet about it for the last couple IT ups it was on time permitting for Prague this is an idea that grew out of some limitations that we were struggling with between TLS and HCV - I will very briefly recap it because I\u0027m assuming most of you\u0027ve heard the discussion in the past and then I\u0027ll talk about where we are and where we had from here so next slide so as we\u0027re probably all familiar with TLS gives you one server certificate and at most one client certificate so if you have a case where a server possesses multiple server certificates too bad you got to pick one for the connection and you get a client certificate tell us one point three limits your ability to present the client certificate later in the connection TLS implementations existing fridge for TLS 1.2 don\u0027t play well with trying to continue passing data which we want to do on a multiplex protocol while you are renegotiating to present the cert and then there\u0027s a more fundamental problem when you\u0027re trying to do hg p2 with that next slide we prohibit renegotiation and http2 anyway so you effectively can\u0027t present a clan certificate so this work grew out of number one we have enterprise cases that still use client certificates that we really would like to move to http - we don\u0027t want to stick them on HTTP 1-1 or even worse run them over HTTP 2 and then fire on HTTP one one required error at them as soon as you need a certificate so they start the connection over and then we negotiate and present the serve and the work that led into this was once we had a mechanism to present a client cert at the HTTP layer you could just as "
  },
  {
    "startTime": "00:06:07",
    "text": "easily present a server cert at the HD view layer so next slide the extension relies on a draft that\u0027s been adopted in TLS now that it\u0027s called exported authenticators it says once you have a TLS session established you can export a blob that proves that you have a certain other certificate than what you negotiate and TLS and then we use HTTP frames pass these around and say I would like to see your cert for example calm and then the server can send back the example.com search and vice-versa if you want to do client certificates the server can be very precise about for this request i need a client certificate that looks like this and the client can return him so if you want to look at the flows next slide when you\u0027re dealing with servers the server might send you an Origin frame that asserts it is authoritative for more domains than is and then are in its TLS certificate in which case the client would say I would like to see the certificates for these domains they\u0027re interesting to me and the server proves that it has a certificate chain that maps up to that dummy and at that point the client would be willing to make requests and coalesce more broadly onto a connection than they could with a single certificate and next slide if you look at the client-side clients make a request and what happened the nunchi p11 over TLS is that at this point the server would renegotiate and say I\u0027d like to see your client certificate before I answer that and so in TN HCP - or it should be over quick for that matter we would be able to do effectively the same thing without relying on we negotiation that TLS the server can say well here\u0027s the definition of a certificate I like to see and I\u0027m requiring it on this request the client proves it has that certificate links to it from the request and then the request actually get to response so next slide that has a couple of advantages that we\u0027ve talked about before for one thing being able to cool s more broadly you can take advantage of larger TCP windows and all the other good reasons why we like to call us across domain names and HUD - and in a lot of cases it\u0027s just not feasible or not preferred to have all of the domains that a server is authoritative for on the same certificate whether that\u0027s for being able to manage your certificates the more granular level or your receipt where you have the certificates from different properties but they don\u0027t mutually trust each other and want to be on the same certificate this also gives you a way to do encrypted S\u0026I that you can open the TLS connection asking for one certificate and then in your 0tt "
  },
  {
    "startTime": "00:09:09",
    "text": "data say and i would also like to see your certificate for sensitive info comm on the client side client certificates are a real thing it\u0027s kind of a pain not having them in HTTP too and at Microsoft that was and that had not been a problem until we shipped the version of Windows Server that supported htv-2 but couldn\u0027t do client certificates over that and then suddenly people start complaining or they start getting kicked back to one one and trying to figure out why they\u0027re spending more RT T\u0027s so next slide like I mentioned this uses the exported Authenticator straps that Nick Sullivan has done and that has been adopted in the TLS working group in Chicago because we were asking for it and this draft has basically been on hold while that makes some progress it is now moving forward in the TLS working group at Nick are we close to last call at this plant or yes okay we\u0027ve had some discussion over the weekend at the hackathon there are probably some properties that we need to change and exported authenticators and take advantage of here to get a few better bindings between requests and responses but in general that is moving forward and I think that means it is time to ask the question on the HTTP side are we ready to adopt this because it now no longer depends on an individual draft it depends on a working group draft until us and that\u0027s what I got right thanks Mike so fairly quick Mike line questions statements of support implementation interests that sort of thing Ted Hardy clarifying question one of the use cases that you actually described in the draft is the use case that common in TLS where you wish to present a generic certificate or or similar and then negotiate to a more specific or different certificate so that you don\u0027t reveal what you\u0027re looking for in the s and I I understand that there\u0027s also work on similar discussions going on inside the TLS working group is it anticipated that you would continue to describe it here or rely on it coming from a more generic mechanism I think going to my client is probably the better person the internet yeah oh great let\u0027s gonna model Thompson I think the idea is this would be complementary to whatever TLS does so tell us who are looking more for a generic solution or is this I think would present a path for HTTP and could present a path for other protocols that decide to adopt a similar sort of scheme but I don\u0027t and I think we\u0027re attempting to address the general problem here with this okay I think that that\u0027s a fine clarification thank you very much I would suggest at that point then if this is gonna continue to be in this that that particular use case get "
  },
  {
    "startTime": "00:12:10",
    "text": "could been more discussion in the draft especially around how it interacts with the HTTP origin because I I think you you treat that in some other aspects that draft much more completely than it currently does but I\u0027m fine with adopting it and doing the work in the working group to do that but I would suggest that we put it early on in in the work program for this truck okay can we see a show of hands who\u0027s read the draft ok good spattering of the room yeah that\u0027s that\u0027s fairly good we\u0027re gonna do some hums yeah to do a Norton Martin first Mountain Thompson I just wanted to point out that um I think Nick has some implementation experience with this in a sort of form that was slightly removed from what we have in the current draft because we\u0027re making few tweaks but evidence suggests that it\u0027s implementable I won\u0027t comment along those lines that not proving the certificate but Akamai has done some experiments as well in just basically telling the client believed the server if it sends you a broader origin frame and then testing the resulting performance and those are beneficial okay lastly I think that this draft is ready for adoption I\u0027m interested in implementing it on the other hand I have a technical question and I wonder if it would be possible to let the client always specify the such that is associated to the request instead of letting the server choose one I asked this because CGI or Fosse I expect the client space by just one such it for every request and it is awfully impossible for HTTP server to determine which certificate is associated to each request I don\u0027t think there is any barrier to adding that other than the client not knowing what certificate the server\u0027s can be looking for until it tells it if the client has a way to know out-of-band then it hypothetically could send you a certificate right away yeah so some of the changes that we\u0027ve been discussing the hackathon probably are going to mean we no longer support the client spontaneously sending certificate and saying you\u0027re going to want this trust me which is probably okay but once the certificate has been sent on the connection then saying request by request end yes please use certificate numbers in number one for this request without the server having first ask for that request and saving a round-trip that should be doable so we\u0027ve been discussing this in various ways in the background for quite some time and it sounds like what we\u0027re coming to is we think it\u0027s time to adopt this formally does anybody have any reservations about doing so or object I doing so what they "
  },
  {
    "startTime": "00:15:11",
    "text": "want to bring up now okay I think well we\u0027ll take that to the list then yeah won\u0027t confirm that on the list thank you Mike okay next up we\u0027re going to talk about WebSockets yay good morning good morning and this is not hai bhai this is HTTP this next slide okay as we\u0027ve heard for a number of years 64 55 which describes the WebSocket protocol as it likes to call it in all capital letters uses a bunch of HTTP one specific mechanisms to bootstrap itself so it uses connections host headers and upgrade all of which were removed from HTTP 2 because they have connection wide scope and conflicted with the multiplexing is fundamental to 7540 in HTTP 2 so you know we\u0027ve been hearing about this this for a number of years about this mismatch and the website community was very interested in having native h2 support and I have from time to time put a bunch of energy into trying to determine you know what the real what the real needs are there so I had a hypothesis for quite a while that you know the multiplexing and therefore the priority that has to go with the multiplexing features of HTTP 2 could really benefit WebSockets but it turns out really you know the the desire from that community by far the top-level goal that was stated was they didn\u0027t want to maintain a separate HTTP one stack just to bootstrap WebSockets those other features of HTTP 2 might maybe be a bonus but the real problem was an administrative one in many respects maintaining HP one stack just for the purpose of running their WebSockets stack ok so next slide with that in mind we talked about this at a non IETF event and the HTTP workshop in London last June and we talked through some of the native htv-2 proposals that have failed to gain traction you know in this space and I suggested we could do the absolute minimal Viable Product here which was just to take 64 45 or 60 for 55 rather and tunnel it on an HTTP 2 string stream so you would still have other HTTP 2 streams they could run other copies of WebSockets this is run normal HTTP data they could do whatever they want and those would be multiplexed with each other but within the individual stream just like on a connect tunnel when you\u0027re connecting through a proxy for instance on that individual stream it would run another protocol in this case 64 55 so the scope of what I\u0027m proposing here is limited to http choose initiation of 64 55 and I think that\u0027s a suitable topic rate to be this to talk about you know changes to the WebSocket protocol including things like masking which is everyone\u0027s favorite you know I don\u0027t think are best done you know in this room like hi bye was the group that "
  },
  {
    "startTime": "00:18:12",
    "text": "originally developed WebSockets and I think would be great if someone wanted to build some extensions to the WebSocket protocol would continue to do that through someone who is chartered to work on that kind of problem okay so there\u0027s a draft up there and individual draft there\u0027s a no - we\u0027ve been circling the list for a little bit but actually got technically published this morning when data tracker reopened and what it does is it uses an h2 opt-in extension to create an extended connect so the extension mechanism of 7540 lets you do pretty much anything you want with negotiated extensions and this makes a change to what Connect does so connect fundamentally already builds tunnels which is why I find it really interesting for this work you know but it is defined to make them you know in proxies using TCP to tell them to a different host and port and this really extends connect to apply to the origin server instead of proxy it doesn\u0027t require the external connection okay Connect as I like to say is already a special snowflake in our documents it works hop - hop really unlike other methods it builds bi-directional tunnels it doesn\u0027t you know anticipate that the request needs to finish before the request starts and all that kind of thing in that kind of way it\u0027s a pretty good match for what we\u0027re trying to accomplish the other option that folks love to you know to debate here is whether the old h1 semantics of a method like GATT with an upgrade header is a is a better fit the way I kind of look at those things is that\u0027s really an option opportunistic version upgrade you know over a real requests transaction as opposed to connect which is a real tunnel and WebSockets is estab is looking to establish a rather than any numbered version of a resource next slide so from the document here\u0027s an example of of what it would look like so you see we\u0027re going to preserve much of the way 64 55 works so you you initially have you know an opt-in setting the server has to tell you that you can do this and then the client puts together connect requests with an authority which now means this is the origin rather than where I\u0027m trying to tell through to and a bunch of the things defined by 64 55 various headers of what you need to negotiate there\u0027s a little bit in the WebSocket protocol this is designed fund alone and fundamentally to make sure that JavaScript content can\u0027t create something that looks like a WebSockets handshake that isn\u0027t really WebSockets that is not needed in this case because one of the key aspects of this of this proposal is a new pseudo header called protocol which is something that a xhr or a JavaScript basic application can\u0027t can\u0027t create and so he accomplishes the same thing a little bit easier my early drafts had a pure tunnelling application where you actually essentially just created a blind pipe and you did a one "
  },
  {
    "startTime": "00:21:14",
    "text": "like or actually use the h1 syntax within the tunnel that was connected here people preferred to move that metadata things like the protocol version the sub protocols the extensions etc you know outside that the way it\u0027s traditionally been done so this draft reflects this so that\u0027s basically what we got for an overview there\u0027s been a whole lot of discussion on this for an individual draft um thank you that\u0027s always you know motivating right and so I think if we keep if we keep this narrow just on the bootstrapping mechanism rather than trying to read them at the ocean I think we\u0027ve got a potential answer here to a long-standing nagging problem so I would like to suggest we you know we adopt this okay like you thank you bedroom let\u0027s go to queue let the queue for Martin Thompson I like some of the properties of this I like the fact that you\u0027ve essentially taken the bootstrapping part of 64 55 and said well we don\u0027t any of that and taking the bits that you actually need and put it in the in the head of fields but that\u0027s a more natural translation I like the fact that you signal that that you support the particular thing obviously if someone puts a : protocol in an HTTP 2 header block the explosions will happen and that\u0027s actually kind of a property that I like as well is that this is not going to happen by accident and if it does happen by accident connections will die so it\u0027s self-correcting fairly quickly I think this is probably the right way to do things and yeah as you say let\u0027s keep the translation as simple as possible this seems as simple as I can imagine oh I also had to have to point out that I was convinced by your arguments about connect over the other of the other methods the fact that people actually have rules on their service that block connect kind of has the right effect on on this right I sort of took Marc\u0027s comments on a list about that that to sort of imply that connect might not work but that is actually an outcome that I kind of like so now that I thought it I\u0027ll inject myself from the cue after Mike with a without a hat on Mike Bishop Akamai so I will point out that I\u0027ve seen a lot of requests for WebSockets over at GP too recently I kind of feel like these two presentations go together kind of well as these are features we left out of h2 and now we regret it yeah so I mostly like this design I will point out that the original definition of Connect says that if you send a connect to an end server it can respond with 200 and say yes you are connected to me please continue so you\u0027re not doing anything invalid here let\u0027s let\u0027s move forward with it and so mark Nottingham no hats my discomfort is mostly around you know Martin says it\u0027s it\u0027s virtuous if the "
  },
  {
    "startTime": "00:24:15",
    "text": "server refuses the connects I think I you know servers are deployed by many parties and often by multiple parties at the same time in different layers and without a lot of coordination and I\u0027m a little concerned here that you know connect suddenly tripping laughs rules when people try negotiate WebSockets may be a scenario that causes people\u0027s nightmares so I\u0027ve gone out and started talking to a few people who do that to figure out how much of a problem that really is and I\u0027m gonna reserve further comment I\u0027ll hear back from them but it\u0027s not quite as simple I know that from the browser side you all maintain the code base you\u0027ve got tight control over that servers are often not like that and I want to see how much pain is gonna cause I think also that the pseudo pseudo header my only concern there is around our we do we really want to set the precedent of extending the protocol of new pseudo headers and that\u0027s maybe a little side discussion to have I\u0027m not sure I\u0027m quite there yet are you suggesting there are limitations to what an opt-in extension can negotiate 7540 suggests you can realize there are no limit you can arbitrarily rearrange a headers frame which I think would be a far more exciting thing to do right the question is what do we want to promote as good practice so I mean I think here what we\u0027ve got specifically or the student pseudo headers apply to hop-by-hop transport oriented headers and I think that\u0027s applicable here uh-huh method is not hop by hop generally speaking path is not hop but it\u0027s the it is the version of the transport encoding of the method right which is done differently okay if now that is not to be meant to be part of the request headers of short sections so it\u0027s a property the high order bit for me is is that I think we should adopt this as long as we can continue to have these discussions of course we\u0027ve data if we adopt this change control belongs to the working group awesome but until then I write down anything I like all right I\u0027m also gonna cut with my chair head back on I\u0027m gonna cut the cubes I\u0027m looking at the clock hawk let me know I know support using Connect that\u0027s the missile because otherwise we\u0027d need to be required to introduce a new training that distinguishes end of request and end of stream and we don\u0027t want to do that Thanks yeah mom Thompson just a responder marks thing it depends on whether you\u0027re considered having WebSockets succeed as a special goal like what what extent you you consider the successive WebSockets to be to be a goal and I think to the extent that there are hurdles to using this that\u0027s not necessarily a bad thing wolf Facebook so can you go back once one slide so yeah for a new coach Nick ocean path so that\u0027s climb needed to waiting for the setting freeing comes "
  },
  {
    "startTime": "00:27:15",
    "text": "from server or not yes so that\u0027s the mean we need waiting for one one two three time to set up the connection or finish negotiation yes all right depending on who sends first it has a lot to do with how your handshake happens but from the highest hypothetical point of view yeah so can we move this aside into first a client request as a client initiate hey I wonder if negotiation is setting with well this would be included I mean the way I would implement this in my server would be this option would be included in this first flight of the server settings anyhow this isn\u0027t a different flight than there are other settings you can include this in the opening you know the opening setting preamble essentially yeah Martin Thompson at that point I did some analysis on on this and yes in TLS one to this does introduce a round trip over over WebSockets previously the fact that you actually have a user on HTTP two connection that\u0027s still usable prior to that point actually means that it\u0027s not as much of a problem as as people like to think until s13 this is not a problem because the server will be able to speak first and so you will have no worse performance with WebSockets the the only cost there is that because you\u0027re waiting on the settings you won\u0027t be able to use WebSockets in zero ICT but I think we can live with them I should point out if you want to use WebSockets in 0 RTT you\u0027ve got a whole host of other problems that you might want to take a good hard look at the whole replay thing is that don\u0027t it just basically just don\u0027t do that yeah any other comments specifically about adopting this draft Patrick I\u0027m going to ask you to come back over here and put your chair hat on thank you I think we\u0027ve heard fair amount I think yeah so we\u0027ll take it to the list I think I think we\u0027ve heard enough next all right next up Mark\u0027s gonna get up there and he\u0027s gonna talk to us about his plans are on HC beater or business or prime or whatever you know the case may be we\u0027re still calling that turn mark I think that\u0027s a bike shed so yes it\u0027s a very small pink box hello I and Julian and a few other folks have been talking about what we do with the RFC 7230 X document sets for a little while and since we\u0027ve had HTTP 2 it\u0027s become more noticeable that the the factoring of the documents is is not particularly great we\u0027ve had some discussions in the past about you know describing HTTP more "
  },
  {
    "startTime": "00:30:18",
    "text": "abstractly and saying this is HTTP the protocol as we know it and then there we have different wire serialization Xin 1 and 2 and eventually in quick as well whatever we call that and so it seems like a good opportunity to refactor the document set by opening up incorporating a rata and kind of talking a little bit about that abstract model and so we put a mailing list message out a while back trying to describe the goals of such an effort and to constrain it so full disclosure I\u0027ve expressed interest in acting as an editor on this as has Julian and so if we did that Patrick would be the acting chair for the effort and he expressed I think a little bit of discomfort about it turning into a large effort let\u0027s face it the last time we did this we took a good eight years at him yeah so we don\u0027t want to do that again and so we want to keep it fairly tight and and this was the shape that we put together so I just wanted to make sure people were aware of this and to get any comment as to how people felt about this shape of work and whether it gave Patrick some amount of comfort about embarking on such an effort so I will make the comment before that my client opens that you know I think the most valuable piece of this work is really to clearly separate the semantic layer that we somewhat casually refer to it as you know from the other aspects of the protocol and to write those down of what we can what we can depend on because that\u0027s become you know with h2 and there were only sort of two versions of this we were able to kind of muddle through but this clearly becomes a bigger problem you know over time yeah and I\u0027ll leave it at that all right also I was remiss I need to point out the intent here would also be to take things to internet standard which seems like it\u0027s probably overdue Ted already speaking I do have a bit of a question about timing here obviously there\u0027s work going on in a different working group to attempt to create an HTTP over a new transport and having this work going on at the same time seems like you both lose the opportunity to take on board the problems which are surfaced by the attempt to do it over new transport and the the the natural questioning of assumptions that goes on when you\u0027re engaged in that effort and it also potentially means that the target for that work gets a little muddier than it needs to be so I I\u0027d like have you potentially explored for me what or for the groom how you would see this work interacting this is that work because it strikes me there are a couple of different ways it could go pear-shaped and one in which it might go well but only might so today all the "
  },
  {
    "startTime": "00:33:22",
    "text": "discussions we\u0027ve had about that other work is that it would not change the semantic footprint of htdp without significant involvement from this working group and I think to date the discussions have been such that we don\u0027t proceed making any huge changes that that might change in the future and so far when this has come up I think I\u0027ve heard this work betrayed as being quite helpful to that in that we have a more well-defined target for that other work to look at whereas right now it\u0027s spread across a bunch of documents in a somewhat haphazard way and so I guess I was a little surprised to hear you say that because for at least from my perspective you know wearing a bunch of different hats I think this is good provided we can do it in a reasonable amount of time and I think that\u0027s the whole point here is we do not want this to drag out yeah I mean I HB chair I\u0027ve received questions about it essentially what is what is implicit in what is explicit right and right if there is examine only difference between those things it would be nice to and then and maybe we should have that more explicitly in the goals is to make that model much more explicit tardy again with the kind accession of the people in the line I appreciate your comments and I do see that if if this had been done before that work started it would clearly have some some opportunities to to have exactly the the impact you described with the other work already underway and it\u0027s chair telling me as as far as you can crack that whip I do worry both about taking some of the energy from a fairly small group of people who understand both HTTP and quick and for forcing them to double focus and I do just also believe that we are continuing surface new things as we go through the quick exercise about what a valuable way of expressing this in a transport neutral way would be and I I think there\u0027s gonna be either a little bit of incurred delay as a result of doing this at the same time or a little bit of missed opportunity as a result of doing it at the same time so I\u0027m happy that you\u0027re considering the matter carefully but I I do have some remaining caution I can understand that certainly I think manure seeing it now is gonna be a fairly focused effort by just a few people that\u0027s gonna be validated by the rest of the working group and I I suspect that this is going to have to happen anyway for a quick to really be able to map well to http but let\u0027s go through the key part yeah so some on Tom\u0027s and I think that a good part of the motivation for this is is actually helping quick get its work done that said to Ted two comments I would I\u0027d be "
  },
  {
    "startTime": "00:36:23",
    "text": "a little leery of publishing this before quick was done oh yes just because we\u0027re learning things the one thing that bothers me most about the work program that you\u0027ve outlined here is is the one point on number four there and that\u0027s the versioning thing well I think we\u0027re still learning about that and that may be that may be a little bit risky here and I\u0027m so sorry I want to make sure that we we understand it before we write it down and saying that we\u0027re gonna tackle it here is the only thing in this program that that published me and it but it does so just to contextualise that we had the those words are lifted verbatim from the Charter for the original diss effort we attempted to do that then as well and we did a lot and this is not the be-all and end-all of HTTP extensibility it\u0027s we need to continue to document best practice there knowing that is going to evolve the the the interesting observation from the previous attempt was that things were written down that did not match reality when we came to when we did HTTP 2 we did something different to what was envisaged in in 26 16 right I think it\u0027s more your 21:45 we went we went way off track from 21:45 and how many dog sleep that no I\u0027m speaking more about header extensibility and method extensibility although that sort of stuff all of those things I think we have a reasonably good understanding of I think it\u0027s the well ok let\u0027s go for it that\u0027s what I proved you can improve but it that\u0027s just work and I think that the people involved here are capable of doing that I don\u0027t think to the same extent we\u0027re capable of saying anything definitive about how we do versioning because we got it wrong before we did it differently for age - we\u0027re doing it differently again for quick and I\u0027m not sure that we\u0027re doing it right either and so I\u0027d like a I\u0027d like a little more confidence in that before I pick that out and so maybe striking and versioned from this thing and simply saying well you know it is what it is well document what we have is is what we need I hear you and I think I\u0027d be happy to change that to just documenting how it\u0027s been versioned so far rather than trying to lay down principles your text just say clarifying which may be mostly documenting right so a mark I\u0027ve been hesitant to ask but um since most of these questions have been about timeline do you have any thoughts on timeline I\u0027m happy to be as aggressive as the working group wants us to be I need to talk to Julian of course and we\u0027ll have to come Feb but I would hope that we could do this and certainly less than a year which would put us on on you know we I agree with Martin statement I think it was that we don\u0027t want to ship this before quick HTTP ships but I\u0027d like to have it ready to go at the same time so yeah "
  },
  {
    "startTime": "00:39:25",
    "text": "like Mike Bishop Akamai and speaking ear as both author of a draft that talked non talked about how we decompose the semantic layer from the mapping and now is the editor of HTTP over quick I think this is a separation that would be really helpful as we start to define quick and as we look toward the future I think the end versioned piece is interesting because as you observe we\u0027ve kind of gotten it wrong all the versioning that we have talked about has wound up being versioning of the mapping and I don\u0027t know that we understand how we version the semantic layer because we\u0027ve never seen them as separate entities until we kind of we\u0027re doing h2 and now that we\u0027re doing quick and so that we don\u0027t have a defined way to version them and if we were to if we were to create one that would be a change to http which I don\u0027t think is in the appropriate charter for this but I think the the work is useful but I share a little bit of the concern around exactly how we weasel word our version [Music] Jeff hodges\u0027s so how does this possibly or at all relate to HTTP to the HTTP to document is written as a fairly standalone thing I don\u0027t think we\u0027re going to need to modify it at all except perhaps to file a writer updating its references for the next revision or whatever so it yeah from a process point of view yes but it incorporates logically a lot of 7230 by reference right but not all of it and that is actually I think one of the things you set out to clarify right right so I think if the question is about if this is work or interested in taking on I\u0027m curious if alexei has any comments you know he would like to make before we we ask the room if they think this is appropriate I don\u0027t have any objections let\u0027s put it this way and I think yeah I think that there was a good set of concerns about timeline of related efforts but I think it probably will help quick HTTP or quick so and my only other comment is I\u0027m would be curious you know how well you can stick to your proposed timeline so we shall see well I the only thing that that has caused real concern I think in our discussions has been there have been a number of cases where folks from from browsers especially doing other specifications that relate to this have brought interoperability issues up or very fine error handling issues up and I "
  },
  {
    "startTime": "00:42:26",
    "text": "think we\u0027ve come to a place where we\u0027ve agreed we don\u0027t want to address that level of interoperability certainly for HTTP 1 and unless there is a really critical security or a severe interoperability issue and frankly if it\u0027s a severe interoperability issue we\u0027ve probably already seen it so I think we that would be the only thing that would really blow out our timeline as we went through and talked about how to pars every header from scratch and to find algorithms and all that and I don\u0027t think there\u0027s a will here to do that okay so let\u0027s just maybe first start with a show of hands interested in the number of people in the room that feel that this work would be a valuable contribution to the space mmm when II maybe then we take a hum about whether or not this is if we were to pursue this work if people feel like this is the right timeframe to do this work given what\u0027s going on with quick and the other the other work sits in front of the working group so if you think this would be the right time to initiate that work go hum yester the first time and if you think this is simply not the right time either because you\u0027re opposed to the work or you just think it\u0027s not the right time then you\u0027ll hum to the second question so question one this is the right time if you believe that please come down question two if you think this is not the right time to do this work please hum that now all right it\u0027s a tough room for me to really hear but I heard maybe twice as much hum one the first one is the second is that kind of what we heard through the room seemed to have verification from DK genius okay thank you and we\u0027ll take that input and figure out where to go from here right thank you got 15 minutes left so we\u0027re gonna get to a little bit of our as time allows hello again I\u0027m gonna talk briefly about variance a relatively new draft that I\u0027ve put up I\u0027ll go ahead and press space so ya in HTTP we have this notion of secondary cache keys where the primary use case is you know we want to be able to cache something that we\u0027ve used proactive content negotiation where you use you know a request header to indicate the clients preferences and the server selects response based upon that request header so content codings content language is content formats also we have a new working group draft we\u0027re not new now anymore it\u0027s been around for a while "
  },
  {
    "startTime": "00:45:26",
    "text": "but new to implementations planes to do this on we\u0027re calling client hints which is really just a collection of new content negotiation axes for things like the device pixel ratio or the window widths that the browser currently has mark I\u0027m sorry you may need to come back and fix your split screen display what\u0027s wrong with it oh okay I can\u0027t advance it oh yes now I did my apologies I there you go okay and sometimes you know we we have used this in the negotiating for things like user agents and cookies and stuff like that too next slide so the the currently specified way to do this is the very header in RFC 7230 for and it is very coarse-grained it can only consider an entire request as a string effectively as that secondary cache key you can do some canonicalization but that isn\u0027t really well-defined and so we have drifting the implementation their correct implementation where you actually correctly applied is quite expensive because it requires you to kind of touch a lot of different things in your cache and/or keep a lot of things in memory and and a lot of implementations as a result take shortcuts in implementing this so Interop isn\u0027t great and the functionality because it\u0027s so coarse-grained is quite limited we hope we can do better next slide we\u0027ve had a working group draft for a while that Roy and I put together called key and this is basically you you specify in a response header a rest recipe for how to figure out the secondary cache key that\u0027s appropriate for any given request and so you say okay you know this key incorporates the user agent and there\u0027s a sub screen it string in it and if the sub string includes msie then you go into one bucket and then you also can have a substring for mobile and that goes into a different bucket and then incorporate cookies and there\u0027s kind of a way you combine these things into a logical key for for that particular request and so that\u0027s much finer grained you can target different parts of the header for your secondary cache key it\u0027s also deterministic you you know you have an algorithm you go through and that\u0027s how you use but identify this in your cache key and hopefully that means that the implementations will be much more aligned but you know we\u0027ve had it out there for a while it\u0027s sat there we\u0027ve been asking for implementation feedback for quite some time and and the general feeling that I get is is that it\u0027s got a couple of really significant downsides one is is that it puts a lot of complexity on the authoring side on the person generating that header to get that recipe exactly right and if they don\u0027t get it exactly right bad things may happen and also there are a lot of trade-offs you know we\u0027re creating a little miniature language here for describing the secondary cache key and there are a lot of trade-offs that you need to make it in in the creation of that language to make sure it\u0027s compact and relatively flexible and we\u0027re not still certain that we\u0027ve made the right trade-offs we\u0027re just not there and so thinking about it and talking to prism "
  },
  {
    "startTime": "00:48:27",
    "text": "folks slide we have a new proposal which is actually informed when I recently joined a lovely new employer they have been doing this kind of in their own internal systems where you specify a list of all the possible variants in in one axis that are available on the origin server so you just list them out and then the intermediary can they apply an algorithm to figure out which the appropriate one to use is for a given request and so what variance does is just generalize that and it says uh you know variance on the accept-encoding plane here for example there\u0027s gzipped and broadly available and on the language to accept language plan there\u0027s english and french available and so what happens is is that you specify an algorithm for each of these content negotiation axes how do I select given a set of these how do I select the appropriate one given the clients preferences so the client\u0027s expressing their preference in a request header and then you identify on the response which ones of those were actually used in the variant key and between those two bits of information now the intermediary has the ability to select any you know the appropriate response for any given request and that works really well for four axes of negotiation where things are known well for example language or format or content coding because all those expressed you know the capabilities and the preferences of the client in the request tenders which is kind of what content negotiation is all about it\u0027s not as suitable for request headers with opaque semantics which was one of the key sorry one of the primary usage scenarios for key people wanted to negotiate on things like cookies and and so one way to view variant is is it\u0027s a supplement to key where it\u0027s not trying to target cookies and it\u0027s not trying to target a user agent it\u0027s going for well understood axes of content negotiation I myself wonder if maybe once we do this it might be good enough to get rid of key altogether and it could be possible to maybe retrofit this onto cookies but I don\u0027t want to explore that what yet um and the other plus is it\u0027s it\u0027s simple and intuitive to author it\u0027s it\u0027s much easier than key I don\u0027t know if there\u0027s a next slide no okay so um that\u0027s about it like I said my current employer does have a form of deployment experience with this and it works really well this is a much bigger generalization of that no I don\u0027t have IPR to declare on that and I\u0027ve checked into that you can also view it as something that is very similar to transparent content negotiation not sorry not TCN no TCN where you list all the different variants available the difference here is this is a much simpler more straightforward HTTP specific way to do it and so I\u0027m asking for feedback I don\u0027t know if I\u0027m asking for adoption yet but I I\u0027ve talked to so "
  },
  {
    "startTime": "00:51:27",
    "text": "a lot of folks about so far and people seem to be cautiously optimistic so model Thompson oh you don\u0027t require a fully populated matrix you just establish the matrix with the response and say which which bucket it fills into falls into and and that allows the the cache to identify the the fact that a particular request falls outside of that bucket exactly and and um yeah that\u0027s exactly right the first version of variance actually conflated that so that it was conflated the the key selection with existing response headers and for that reason that you put out that there might be a partial matrix that seemed to be a bad idea so that\u0027s why we have a separate variant key head yeah this is fun yeah and and and I think the next step for this is to be able to allow there and key to identify multiple possible values you can you be used so that you can fill in that matrix if you want with other responses yeah yeah Brian call I\u0027m Rancher sadness I\u0027m definitely interested in actually implementing it this solves a problem that we have is knowing what kind of content encoding the origins have thanks I don\u0027t all this term this is not something I understand but if server sends back this stuff will it\u0027s done said say there are no more access or variation so that for instance it if it sends back variants it will say that I will not create variants based on their yeah based on user user agent um so there are a couple of answers to that when the cache evaluates a request it uses ideally the most recent variants header for that resource that it has received and of course if it doesn\u0027t have anything cache they\u0027ll have to go back to the origin you still send the vary header with this because you still have to interoperate with caches that don\u0027t understand variants and it might be that you list more things in the vary header than you do in variants if you\u0027re varying on cookie and variants chooses not to address cookies then you need to be able to fall back to the very behavior for cookies but only for cookies thank you and that\u0027s a little tricky but I think we can do that I\u0027ll take off my chair hat and express some skepticism about that but I would like to say that this has come up this is actually sells a sweet spot that has come up with um h2 push and push cache interactions this is I think exactly the kinds of things that get pushed that may not be able to be used because of often like image negotiation and format so that kind of things is is is clearly becoming a problem and so yeah if anybody is interested in in doing some experimentation or experimental implementation I\u0027d love to chat I don\u0027t think I\u0027m asking for adoption yet but I\u0027m I think the discussion that would be nice to have is "
  },
  {
    "startTime": "00:54:27",
    "text": "if we adopt this do we replace key with it or not because I\u0027m still not detecting I mean all the interests that I detecting key is this is an important space to be working in but not this particular solution so I think this might be a better solution yeah I would want to pursue that line of discussion because key has just been parked with no activity for a while and certainly if we wanted to adopt this I would do this serve as a wholesale replacement I don\u0027t much care whether this becomes you know and plus one of key or you know we swap the documents whatever logically speaking it and we can always resurrect key down the road if we suddenly decide we need it sure so we\u0027ve got five minutes left thank you mark Siobhan do you want to try and say a little bit about 451 in the four and a half minutes that\u0027s available all right um hello my name is Siobhan and I\u0027ve been working with the HR PC research group on things related to HTTP status code 451 for the past few months and the purpose of this talk is to put forth what we have and get comments and feedback on what would be the right way to move forward next slide please next slide there\u0027s no time for outlines so the purpose of HDTV 451 is to make censorship more transparent next slide please and it should include an explanation in the response body so the the the work would be read it to see what like these status codes look like in the wild we didn\u0027t really see any of these explanations ever and it should also include a header field that has the block by information this was a source of confusion in most of the the instances we saw because some of them some people interpreted this to mean the organization that\u0027s blocking as in who\u0027s actually implementing the block so an ISP for example and others took this to mean the organization that mandated the block and this may be this is because of the example which was kind of confusing in the RFC 7 725 our next slide please so at IIT 899 hackathon we wrote some plugins client-side plugins that would report instances instances of 51 and report those back to a back-end collector and we also wrote some drafts next slide please and so one of them was the implementation report draft where we examined current usage patterns and we also made some recommendations which were captured in another draft next slide so the recommendations that we\u0027re making are having a blocking Authority link here are similar to blur by so you can make clear distinction between these two things and also because we feel it\u0027s important information and we also also having a provisional header for the geographical scope God so that we because blocks were often that we saw were often scope to countries so this would be extremely useful information so what the form that "
  },
  {
    "startTime": "00:57:29",
    "text": "this would take we\u0027re still talking about that but I guess we\u0027ll be thinking right now is having alpha-2 country codes so there\u0027s a couple of things that we had not in the slide are there was an errata that was published by stefan related to the example given in RFC seven seven to five and we also have a huge R for Human Rights considerations guidelines on sale on IFC 775 that\u0027s also a thing relevant next slide so I guess the main question we\u0027re asking is what is the right way to move forward on this and should we be looking at an RFC seven seven to five base which combines the Human Rights protocol considerations plus the new protocol elements and so and as I mentioned we are also looking for more definition of the geographical scope block that\u0027s it so my question was if you\u0027re talking about restricting the geographical area to a country code that sort of implies that you\u0027re narrowing the set of options for blocking authorities to the same extent is there is there any sense in having both fields if you have the blocking Authority so say I identify a particular government that is a government of a particular country is there any sense you know also identifying the country at that point so for one we would not make that mandatory you would not have to include the country code so it could be like if it\u0027s wider than the country then you could just be that but yeah that\u0027s a good point so my point being is if you\u0027re going to keep both of the fields I think you you might want to have a little more detail in the in the geographical area of course as soon as you get into that then we\u0027re getting into a huge mess and we\u0027ve got some experience we\u0027re doing geolocation stuff in this organization and it\u0027s unpleasant to say the least coming up with a with a format that will actually describe where something is linked relations is probably the best path forward for that provider pointer to a document that describes where it is and then that may solve the problem the extender that the extent of the block yes so that the geographical region in which the block is supposed to be applied anyway well somebody think about right where at times I\u0027m going to cut the line and if we can make this really brief please sander Bremen Texas A\u0026M University three points one is that by using the word censorship it\u0027s a very broad meaning it could be fraud it could be any kind in a number of things that we would not typically treat a censorship but are legitimate reasons for shedding something down second gia geography is interesting but if you\u0027re talking about the law you\u0027re talking about legal jurisdiction geography and legal jurisdiction are two separate questions it\u0027s worth including them both because of course many countries try to exercise jurisdiction extraterritorially and do so successfully and of course as long "
  },
  {
    "startTime": "01:00:29",
    "text": "history of that complexity in the Internet the second thing about jurisdiction is it allows you to go below the national level it could be state law could be municipal ordinance and so forth and the third thing is that you\u0027ve got should for the reason but just as technical people legitimately criticize those in the legal world for trying to assert something about technical design that has nothing to do with how it run works so in the technical world if you want to engage with the law you want to think about how the law works anytime something is shut down for legal reasons the justification must be given and so I would change the should to muscle there alright thank you lovely ok we\u0027ll chat with you a bit more perhaps and Adrian had a presentation about payments which in Port when we don\u0027t have time to get to what I might ask is is that if he and Patrick and I and Alexei and maybe Wendy can meet right afterwards to have a quick chat we might be able to give you the feedback you want so that\u0027s for today we\u0027ll see everyone on Friday hopefully thank you anyone said he can\u0027t make it on if you can\u0027t yeah "
  }
]