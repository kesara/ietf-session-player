[
  {
    "startTime": "00:00:43",
    "text": "Hello, everybody good morning. Hope that the jet lag is being lenient on you. Welcome to Apply Network and Research Works of 2024. My name is Ignathe castro from Quimery University of London and on my side is Hayeser, St. Gupta, from BIT, Mesra in India. And our other chair is Simon Perlin from Red Hat that they couldn't make it and probably some of you know her well so let's get started with the note well from the IRTF Just to note that the IRTF intellectual property rights on this disclosure rules do not apply to contributions to apply net networking research workshop All the session is being recorded and if you participate in person and are not wearing a red thingy you are agreeing to be photographed. If you participate online and turn on your camera or microphone, then you are consenting to appear in the recordings As a participant or attendee, you acknowledge that the writing audio, video, photo records might be made public Personal information that you provide will be handling a attendee, you acknowledge that the writing audio video photo records might be made public. Personal information that you provide will be handled in accordance with the privacy policy and this and other details are recorded in the RFC saw scenes in the screen. And this information is in the slides"
  },
  {
    "startTime": "00:02:01",
    "text": "that you can find in the meeting materials. Would you have any question would you have any doubt about it And moving on to the things first of all, this is only possible thanks to those who submit the paper and those who review the papers, so we have to give a big thanks to all the program committee which included many people, probably some of them among you, are both from industry both from academia and many of them are regular IT efforts so big thanks to you all. Big thanks also to all the people who have helped us in putting this together That includes AMI, Alexa, and definitely colin perkins whose big boots will be hard to feel once he left the IRTF. So thank you to them all And what we have for you is a very packed set of sessions We will start with the welcome that we are finishing. And now we will follow up with the keynote from Sharata Gargwal from Mike Microsoft with lessons he learned in leveraging AI ML for 5G and 6G systems then we will have a measurement section with two papers and then the break. After the break, we will have the second session about routine and congestion, which will be chaired by Matthias Wallis from T.U. Dresden after the lunch no after that break, we will have session number three on security and energy, which will be chaired from Juan Camilo Cardone from NTT And finally, we will have the last session with the lightning papers which will be a chaired by Thomas Smich from HAAWU Hamburg in terms of logistics, you can find the program and the paper PDFs in the Pline Network and Research Workshop 24, oops website. If you want to ask a question, please join the QMITECO. Doesn't matter whether you are Remo or in person. Please do join MeTeco. You also"
  },
  {
    "startTime": "00:04:01",
    "text": "have the meeting links and the slides in the session in the agenda. And you soon be able to access all the relevant materials And that's all from our side Thank you very much So if Sharad can come to the front I will stop sharing my slides Okay Thank you very much to Sharata Garwalf for being our keynote. Sharad is a senior print researcher at Microsoft. He works on white area networking and distributed systems and his research has deployed to Windows 10 research has been deployed to Windows 10, Windows Phone 8, Azure networking, and Assur for operators. He's also an ACM distinguished engineer and with that i pass on the microphone to him Thank you very much. Thank you PC chairs, for inviting me, and thank you all for being here. I hope you've had your coffee. This is going to be pretty fast-paced. So my goal is going to be to try and make this educational for you I want to tell you about a growing area of networking research that may be, you know, a large chunk of this audience is perhaps not working on and give you some observation I've had from building multiple networks systems for this space that involve learning algorithms Okay, so in a nutshell, these are the three main lessons that I am going to do learning algorithm. Okay, so in a nutshell, these are the three main lessons that I am going to try and convey to you in the context of systems that I've built As applied networking researchers, you will invariably encounter the limitations of deployed protocols and building improvements to those or designing new ones"
  },
  {
    "startTime": "00:06:01",
    "text": "is certainly a worthwhile academic endeavor But it takes a really long time to deploy those and in the meantime, your customers suffer What I found is that in many cases, not all, but in many cases, you can leverage cloud scale to overcome the limitations of deployed network protocols and then to manage that massive scale, you can use learning our algorithms. But in the process, of using those learning algorithms, what I have done is I have invariably ended up designing custom learning algorithms because I think I'm smart and I can do something that's more efficient And really what I found is that that's the wrong way to go about it. As often as you can, you want to use off-the-shelf well-known learning algorithms because that reduces the barrier to deployment. And then finally, you are probably going to be thinking about using generative AI or large language models in your research and you've heard about the risk of hallucinations. And I will tell you that yes, it's a real concern, but there are ways in which you can mitigate those concerns. And I will then talk about, oh, this slides went away should I reshare? So let's stop it"
  },
  {
    "startTime": "00:08:19",
    "text": "In this case, you can actually blame the network Here the network did crap out on us. So, now before I get to telling you about those lessons in the context of systems that I've built, I need to give you a little bit of context. So you may have heard about the cloudification of telecom infrastructure. It's a important for us to understand why it's happening and what is actually happening. And I will highlight some of the interesting research challenge in the space. I will then focus on three of the hardest challenges that I see One is improving high throughput of these new radios that I'll tell you about. The other support low latency end to end, and then finally improve the reliability of network functions that are used in Cloudified Telecom infrastructure Okay, now this being a short keynote, I will not go into a lot of detail about each of these systems but hopefully enough for you to appreciate some of the learnings that I've had Okay, so I will start by telling you what I see is happening in the telecom infrastructure industry From my point of view, I just want to point out that these are just my opinions, not necessarily reflective of my company or my business or the business that I work in Okay, so this part you guys know very well, right? The traffic per user and in aggregate has been going up for quite a long time Average revenue per user has been sort of either"
  },
  {
    "startTime": "00:10:01",
    "text": "dwindling or largely flat. And market growth is primarily coming from new humans being born And there's a significant lack of differentiation between operators so that allows users to to move from operator to operator. None of this isn't used to you But two things have changed now that may this a very exciting area for us to work on. Okay, the first is the latest seller specification is delayed wildly radical, radically new kid capabilities than previous generations of cellular For example, new radios, they support 10 to 20 gigabit per second throughput per device Okay, that's pretty significant. And also, roughly one millisecond over the air latency As well as new capabilities to deploy private solar networks for mission-critical applications such as robotic automation and factory and other types of enterprises And now, we all know that telecom industry moves very slowly and there are reasons for that Everything has to get standardized, new frequencies have to open up, new radios have to be designed, new qu- equipment from equipment vendors has to be made available but all of that that moving train has now finally arrived. You can look at the recency of these articles The one on the right is from November 23, the one of the left is from this year And so, you know, these technologies and capabilities are now finally arriving I said there are two things that have changed The other thing that has changed is there's now the ability to see significantly decrease cost through a reduction in infrastructure spend. Traditionally, if you run a telecom network, you buy these boxes. These are OPEG boxes of monolithic software on proprietary hardware. You don't really know exactly what's going on, and you have to deploy these boxes to"
  },
  {
    "startTime": "00:12:01",
    "text": "scale to the peak of your network And over the past decade, what has happened is that there's been this push to virtualize as much of this as possible. And now we're finally at this point on the right-hand side where each of these network functions in almost all cases is a piece of software it's containerized, you can pack multiple containers onto virtualized commodity hardware just like we do in the cloud okay again, you know, this industry moves slowly and it has taken a decade from this being written in a standard's body for this technology to be made available now but now it is available So to summarize what's happening in the wireless operator, industry, there's been a combination of new frequencies and new radio technologies that are now coming to market, and it's allowing for performance that is wildly different than previous generations along with capabilities to do private network deployments for mission critical applications And then at the same time, there are these technological headwinds that we've enjoyed in other industries for quite a long time that are now coming here, which includes software-defined networking, cloud-native functions and service-based architectures So what does this mean for us networking? people? Let's talk specifically about what a deployment like this looks like. On the left, you've got an operator network. On the right, you've got a hyperscaler network Obviously, you're going to have a bunch of cell towers and radios on the left. And then you've got places where compute runs For example, you may have applications on your device, or if in the case, of a factory, for example, you may have on-prem servers that are running applications And then you've got the virtualized radio access network that is running on what we call the far edge, the 5G user plane on what may be called the near edge You've got carrier fiber that is connecting all of this together"
  },
  {
    "startTime": "00:14:01",
    "text": "And then you have peering into the hyperscale network. And in the hyperskiller network, you will have other parts of the 5G core running. You will have a voice applications, end-user applications a bunch of things. Now, this is just one example of a deployment in other examples more of the boxes on the right, maybe on the left, or an other examples, more of the box on the left, maybe on the right But you know you are now starting to see real evidence of this actually happening For example, you will see articles from Microsoft of AT&T running its mobility network on our cloud stack, as well as you'll see it from the operators' websites as well And you will even see YouTube videos, for example this one from Nokia on how to run Nokia core on AWS data centers So that picture that I showed you is pretty complicated. For us, we can abstract it to this simple picture, which is you've got users you've got cell towers, you've got far edges where it's typically the virtualized radio access network runs near edges, and then peering into the hyperscalor network where you've got massive amounts of compute in the data centers So what are the interesting research? challenges in the space? These are the three that I worry the most about. What I've heard the most from CTOs of large telecom operators when they talk to me. One is bandwidth Like I said, these new radios allow a massive amount of bandwidth And if that 10 to 20 gigabit per second per use, is hitting the cloud, what does that mean? For us networking people, how do we maintain? such high performance? Same with latency If you've got order one millisecond over the air, what's the point of that? if the rest of your wired backbone is going to have so much inefficiency that it's going to eat it all up? And then reliability. Typically for enterprise applications, two and a half nine's reliability is sufficient, but for many telecom"
  },
  {
    "startTime": "00:16:01",
    "text": "deployments, you need to get to five nine's availability sometimes due to regulation. How do we achieve that? So I'm going to now talk about these three problems in the context of systems that I've built but hopefully trying to impart upon you, you know, some of the lessons that I've learned and hopefully get you excited about this new area of research So first I will talk about a network system we built called Tipsy, which is to help support massive amounts of throughput coming from end users into the cloud. Many details are in our sitcom 22 paper, but what the paper doesn't go into is the customer impact examples and my lessons from using learning algorithms here, so I will focus on those now Okay, so as I've described before, we are now in an era where end users have significant higher bandwidth, either from fiber to the home or in many cases, you know, 10 to 20 gig per second new radios. So this causes interest problems. Imagine the simple topology over here on the bottom right. You've got a cloud service the red dot at the bottom, that wants to be reachable to all users. Let's say they're seller users, the red dot at the top What this cloud service is going to do is going to add advertise reachability to the prefix that covers its IP addresses on all the pairing links because it wants to be reachable from everywhere. Then what happened We don't know. Routers foreign to our network are made decisions about what to do with all these routes that I have been heard, and we don't know exactly how users are going to reach us. Then those users start sending traffic, and at some point in time, maybe one of those pairing links now suddenly gets over overloaded. What do we do now? Okay is this a real problem many pairing links tend to be 10 gigabit per second or multiples of 10, and the fatest pairing links are 100 or 400 gig 400 gig. And that is actually not that big compared to the capabilities"
  },
  {
    "startTime": "00:18:01",
    "text": "that these new users, new radios are allowing users to have and we have many examples of this actually happening in practice such problems For example, at one point in time, our sales team did a deal where the mobile, where the mobile company's users could use our cloud service for photo and video services And when that deal went into effect at a certain point in time, boom, all of a sudden all of these mobile users were just sending massive amounts of traffic to us and have overwhelmed a 100 gig link in Europe Okay. And then there was a mad dash to try and figure out what to do So what can we do, right? The core problem, I think this community understands you know, BGP is not symmetric There are many ASSs out there that play games with routing advertising and we really don't know what are the routing policy on routers that are far into our network Now, rather than wait for a new protocol to be deployed or tweaks to an existing protocol to be deployed, the opportunity that we can let leverage here is that their spare capacity, at other pairing links that we have, and we've got a very large number of other peering links, the challenge is how do we show? some of that traffic over without causing some of these other peering links to then cascade and get overwhelmed Now to press upon you the type of skill that we can work with, traffic can enter our global WAN almost anywhere We have 10,000 peering links with over 4,000 peers and we peer with them in almost 200 locations So there's considerable uncertainty, even under normal circumstances, as to where a package is going to enter our network So essentially what we have is a learning problem and here's how the system works. There's the internet, there's the Azure wider network, there's puring, you've got 10,000 peering links, order 10,000 And all of that is happening at border routers. We have"
  },
  {
    "startTime": "00:20:01",
    "text": "flow information that is going into a distributed database What we do is we do a whole bunch of big data processes and then we do some machine learning in data bricks. And then that is the tip that is going into a distributed database. What we do is we do a whole bunch of big data processing and then we do some machine learning in data bricks. And then that is the TIPC prediction system So when a congestion management system detects that there is ingress congestion it is going to make a hyper hypothesis. Let's say, if I were to withdraw one of these prefixes, maybe enough traffic will go away, what will happen? It's going to go ask our prediction system. Our prediction system is going to tell it, here's what I think is going to happen. If you were to make this withdrawal. This is where traffic is going to land and then we can make a decision as to whether that is a safe operation to make. Do those other links where traffic is going to arrive, have enough headroom? to swallow the amount of flows that are going to be shown? over and if it's safe then it's going to go ahead and issue the withdrawal. If it's not safe, it's going to pick a different prefix or multiple withdrawals to make at the same time That was grossly simplified but at the core of the system is learning. And the learning problem is straightforward. Given order 10,000 peering links and then given a traffic flow, where is it? going to arrive either under normal circumstances or when appearing link is down or when you've made a withdrawal. And to try to, that, we rely on flow data Now, so this is like one of the lessons that we learned, which is that we can actually do this. We can actually leverage this massive scale that we have of massive number of peering links to try and shift traffic away from an overloaded peering link. But in order to do that, it's really hard to write a determinist algorithm that is going to do that over such a massive peering surface area. And it's, we actually can use learning to manage this scale Now, to do that, what we did was we built multiple learning"
  },
  {
    "startTime": "00:22:01",
    "text": "models and we constructed them into an ensemble And we have at the heart of it too different models with different feature sets that are then combined. Now what we did in this particular case, so what made this problem hard was the size of this problem The cardinality of one of our features is 10 million and the size of data that we're learning over is about a petabyte. And so when we designed this, we over-indexed for efficiency. We designed the system to train on one passive data to work across clusters of CPUs instead of GPUs and scale easily. In retrospect, that was actually not the right thing for us to do Today, there are GPU clusters that are far more readily available, far more capable and I would actually use an off-the-shelf algorithm, even if it's less efficient and maybe even less actually because what I've done is I've traded off against explainability, deployability implementation, complexity, and maintainability And those actually ended up being the harder barriers to cross in getting this to production So in summary, we can actually learn our way out of bandwidth bottlenecks The business of operating wide area network backbones has survived because of statistics multiplexing. You run fat pipes in the middle of the network that are a thousand times fatter than where the end user are, but now that's no longer the case and that's rapidly changing. Now you can have a small number of users randomly or not randomly synchronized in time and pummel a core link Okay. So we built a learning system. The accuracy is actually more than what we need. It's more than sufficient the details are in our paper but really we"
  },
  {
    "startTime": "00:24:01",
    "text": "had a couple of takeaways that are important. One is that yes, you can actually leverage cloud scale in situations like this and solve the problem You can use learning, but really, you know, trying to mistake that I did, which was trying to be too smart use an off-the-shelf algorithm you know, maybe a library such as pie torch, because that is going to significantly ease an engineering burden of deploying this and maintaining this in production In the end, you know, we spend a quarter of a million in computer on this, and that was really not even a barrier So if we had spent even more on GPU clusters, it wouldn't have been a problem So now, let me tell you about a network, another network system we built called Painter. And what the system is, wouldn't have been a problem. So now, let me tell you about a network, another network system we built called Painter. And what the system does is it tackles a problem of latency and to a end, particularly when you've got to these new radios with one millisecond over the air Again, the technical details are in our sitcom 23 paper but I'll focus a little bit more on the customer scenario and my learnings from this So, as I said, one of the interesting things about the next generation of cellular is the ability to depend private cellar networks And there are multiple capabilities in the specifications for this for things like factories and industrial buildings and enterprises in general. And you'll find many articles on this. For example, from articles like this, from professional services firms that specialize in trying to deploy these sorts of things to even public telecom operators who see value in helping private companies deploy private cellular And when you look at the detailed case studies of why there's so much interest in these sorts of things some of the things that pop out are network performance, speed, and application performance. Typically, what we hear is that you've got a factory with robots that are automated and laying Ethernet everywhere is simply"
  },
  {
    "startTime": "00:26:01",
    "text": "too expensive and cumbersome and Wi-Fi does give you the guarantee of performance and congestion avoidance that you really need. That's the latest generation of cell gives you. So let's make this real with an actual customer complaint So now, you know, this is an actual example of a customer that has multiple factories and branch offices across the planet. They've got a pretty complicated network to policy but I'm going to show you a sliver of it that is relevant in the particular issue at hand So they've got a branch in South America and they have deployed a bunch of network functions in the nearest Azure region. These network functions are things like virtual wider networks that allows you to control how traffic flows applied network security policies, also have various other services in that Azure region And then you've got another branch in Europe, and again, you've got another Azure region next to it, where you've deployed other network functions. And what you expect as a customer, is that when you send traffic from branch one to branch two, it's going to go from branch one to the nearest Azure region And from there, it's going to go over our backbone over to the other Azure region and then on to branch two. But the customer complained that their performance sucked What was going on? After a bunch of debugging we found that the customer and us shared an ISP That ISP, we peered with them in many locations. The customer had direct connectivity with that ISP in both of these locations But for some reason, the ISP in the middle was sending traffic from brand 1 to our cloud all the way over their backbone into North America and then handing it over to us in North America. And then what our backbone will, of course do is send it over to the Azure region where those networks functions are hosted. And then it's got to go over to Europe So it's going to go back up to the US to go over our transit line"
  },
  {
    "startTime": "00:28:01",
    "text": "links over to Europe okay so this took a long time to debug because there are three parties involved and you got you got a this over emails and phone calls and whatnot But for those of you who work on wider network routing, you know what the problem is. Okay Like in this picture, we don't really know what's happening in the middle of the network when we announced availability of our prefixes on all of our peers is, okay? Like in this picture, we don't really know what's happening in the middle of the network when we announce availability of our prefixes on all of our appearing connections. So what we do is that we built a system called Painter and again it leverages learning Here, again, we leverage the fact that we've got large numbers of peering connections and there's many alternatives paths that we can potentially expose to a customer The challenge is, how do we do that? So we continue to use anycast like we do for all of our traffic today, and let's say this enterprise customer they get, you know, not very good performance on the red path because this blob in the middle that we don't really have any insight into has picked a particular path So then what we do is we leverage this observation that many of our customers have network functions that are dependent in tandem with the cloud. So for example, they may have virtual SD-WAN sitting on their premises or V-NETs peering, private V-NET peering VPN gateways. All of these you can configure and manage through your single cloud portal on Azure where it'll going to configure not only your on-prem devices, but also all of them deployments on the cloud. So we designed our system to also operate in a similar fashion. A central orchestrator in the cloud, as well as a small piece of network function that's running on the premises What it's going to do is it's going to detect that, hey, the customer is having poor performance, and then the orchestrator is going to make a hypothesis It's going to say, maybe the second link, I can advertise a Unicast prefix and see if that is"
  },
  {
    "startTime": "00:30:01",
    "text": "better performance. It's going to advertise the We're going to measure it. And no, it's not very good then it's going to go with its second hypothesis which is you know let's go use this other peering link And then we do that and yes, there's good performance And so now we can have the customer use an IP address from that other Unicast prefix as opposed to the broad any caste prefix. Okay so seems straightforward enough The challenge is how do we scale this to the massive surface area that we have? We can't go deploy 10,000 unicast prefixes that would be very expensive and it would bloat the writing table out there. So we're going to use a small number of prefixes and do prefix reuse. Well, that opens up a whole can of worms. How will an advertisement reach a customer? What advertisements overlap? you know, which path is lower latency. And so we did what we do, which is that we designed a load learning algorithm. Now it's it's it looks complicated and we dedicated far too much space in the paper on this, but in reality, it's actually a real straightforward algorithm At the heart of it, what's going on is that we are essentially doing Epsilon greedy strategy in reinforcement learning sorry it's it's of it, what's going on is that we are essentially doing Epsilon greedy strategy in reinforcement learning. Sorry, it's a bit fuzzy, but that's okay So, you know, what we have is we have an agent that represents the actions that the algorithm is taking, and then it is impacting the environment by making routing changes And then it observes the environment, calculates a reward, which is how good the performance is, and then decides whether to use that or not But we thought in designing this, that would be clever. And the clever thing we did was like, ooh, we can get to a smaller number of iterations of the algorithm by using some quirks of routing which is that, you know, writing announces that are made very far away"
  },
  {
    "startTime": "00:32:01",
    "text": "from each other tend not to overlap. So we'll assume that and we'll use a large enough distance between them and, you know, that way we'll significantly reduce the number of learning iterations So in the end, yes this ended up being far more efficient than epsilon greedy reinforcement learning because of that but it also ended up being far more complicated to explain and to write an implementation for And so this again exemplifies both of the learnings that I've had, which is that you can leverage cloud scale to overcome in many situations the limitations of deployed network protocols but then, you know, when you end up using learning algorithms avoid what I try to do, which is try to be too smart use an off-the-shelf learning algorithm as often as you can So in some summary, you know, when latencies are not because, a problem because of the new capabilities that end you, as you can. So in summary, you know, when latencies are not becoming a problem because of the new capabilities that end users have, and our protocols have not evolved at least for now, we can work around them. You will end up having to use learning algorithms You can look for this graph in our paper that we were so proud of. Oh, look, only four iterations to get almost to optimal. But in reality, yeah, that's the so great. We added complexity for efficiency and would have been far simpler to just have more learning iterations and still get, you know, a large number of latencies savings across many customers So now what I am going to do is I am going to very briefly talk about a third system we built called Lexus And again, details are in our paper that is coming out this month And what this system does is it improves the reliability of deployment network systems by automating repair and recovery So this picture is the software architecture of a typical 5G deployment"
  },
  {
    "startTime": "00:34:01",
    "text": "from the point of view of network functions and protocols It's beautiful, isn't it? There are a lot of boxes Every box is a network function. Every line is a protocol that two boxes are using to talk to each other And every single box may be scaled up across multiple instances. And remember that picture I showed you earlier. This thing is going to be deployed across far edges, near edges, and cloud data centers. Okay, so what happens? when something breaks? Okay, what do you do? Okay, debugging a failure is really, really hard. And you have to do this while you're wondering, can you're using still call 911? Okay So when a 5G network function has a failure, what happens is that you've got SREs site reliability engineers, and they will follow what is called a TSG, a troubleshooting guide, also known as a mob or a playbook or run book, okay? What it is, it's an English language document this is one picture you start from the top left all the way down. These are just screenshots and then to the second column And the third column, this is one TSG for the issue of when a link goes down So when a link goes down, there's lots of things that you've got to touch okay could it be the switch that's gone down is it just the inner issue of when a link goes down. So when a link goes down, there's lots of things that you've got to touch. Okay, could it be the switch that's gone down? Is it just the interface? Is it the server? Or maybe the link is up? but the metrics are not coming through. You know, is the power dirty? Has the optics burnt out? Does the cable? need to be replaced? So many things. And so you've got to touch lots of things. And what's worse is that the troubleshooting guys are continually evolving as you're productive evolves, as you discover new behavior And so you're going through this while you're under immense pressure to try and maintain five-nines availability Five nine's availability means five minutes of downtime per year. So what do we do about this? We are automating troubleshooting guide execution using AI agents. Broadly what we have is we"
  },
  {
    "startTime": "00:36:01",
    "text": "have a agent Lexis planner It uses LLMs hosted on the cloud And when a human SRU writes, a troubleshooting guide or updates one, it calls our agent. What that agent does is it produces a plan The plan you can, is a long JSON document. Conceptually, you can think of it as a flow chart. Step one, identify the customer ID Step two, is there a deployment active? Step three go-fetched sys logs, and so on And what we use also is a set of tools that are already available with the team These are tools that will, for example, fetch assist logs or will do show interface status or reboot a switch Okay, very targeted, actionable tools Then when an incident happens, our second agent the Lexus incident handler, is going to go look at that incident pull the relevant plan that has already been pre-jointed and then start running through it. And it's going to go annotate a log with what are the actions it took and what it found. And then a human always has a luxury of being able to inspect what is going on. Now, when we started this effort, we had a lot of naysayers tell us that, look, you know, LLM's hallucin this is super risky, especially when you're talking about, you know, dealing with customer deployments and it's going to give you wrong answers and it'll never work And in fact, in our early investigations that actually was true. More often than not, it gave us bad answers, bad plans and did bad actions. But what we did was we did a bunch of things that actually helped mitigate the risk of hallucinations One of the things that we did was instead of generating a plan in one shot, you know, make a call to an alum saying, here's this long document, go make a plan from it we actually do iterative plan generation What we do is we break it down into lots of little steps"
  },
  {
    "startTime": "00:38:01",
    "text": "First, give me a high level plan. Now focus on step one. Tell me what you're going to do in step one. Now tell me what you're going to do in step one plan generation. What we do is we break it down into lots of little steps. First, give me a high-level plan. Now, focus on step one. Tell me what you're going to do in step one. Now tell me what you're going to do in step two. As a result, each call to the generative AI model is a smaller task with much more limited scope of what you're asking it to do. And you can also give it a lot more precise instructions. And so now it's got far more limited scope for hallucinations In addition, we have validation rules that check the output of every single execution And that also reduces the scope for hallucinations. The other thing that we do is we pre-generate a plan instead of doing it at runtime when an incident happens Because when we pre-generated, we're generating it when a human has written a troubleshooting guide. So they also at that point, have the luxury of being able to inspect that plan and say hey you know is this the right plan or did the LLM hallucinate? In fact, we're now at the point where more often, than not, it is catching problems with the troubleshooting guide itself, where the humans set something ambiguous or wrote something that is actually incorrect and it's helping them improve the troubleshooting guide rather than actually catching hallucinations And we also use existing tools rather than give an AI unfi unfettered access to the entire deployment, so here's SSH, go to town, super risky, you know, we are actually using these pre-existing tools that help engineer speed up their own tasks and that's significantly reduces what what can be done and there there's many more and i'm happy to talk in in more detail about this. So basically, in summary, what we do is we are talking about done. And there's many more, and I'm happy to talk in more detail about this. So basically, in summary, what we do is we are targeting automatic mitigation of life site incidents Surprising to us, it can actually make sense of long often poorly written technical documents and create methodical plans And there's a bunch of careful systems designed that I think many of us can think of"
  },
  {
    "startTime": "00:40:01",
    "text": "about using to mitigate the risk of hallucinations So I'll now wrap up my talk. So in conclusion, there are many avenues for impactful research in this open new space, carrier-grade reliability is a big challenge. It's a hard challenge because now you've got many brand new written software network functions that are being run from multiple different vendors and actually running that across a variety of information you know across new edges, far edges, and the cloud is an interesting challenge And you've got end to end quality of service. Of course, security and privacy is a big challenge as well as cost The interesting thing here is that you've got the stat that manages all of this hardware and virtualized software It's all coming from one place. It's all cloud stack that's being deployed. So you've got a single stack conceptually that's running across all of these locations and so you've got hope that you can actually make a significant impact without an oversized effort So thank you very much for listening to me for Sil long. I hope this was useful to you. I'm going to be around all day, so happy to talk more Thank you very much And thank you open for questions Hesham is the first one in the queue. So please go ahead Yeah, a very good presentation Thank you very much. But it sounds like you took into consideration several factors like bandwidth, latency, reliability privacy, security, but have you considered energy efficiency? Yes, yes, good one, good one, energy efficiency is a really, really important challenge, especially when you go far to the left of the"
  },
  {
    "startTime": "00:42:01",
    "text": "of the picture that had shown the topology here, where you've got the version the left of the picture that had shown the topology here, where you've got the virtualized radio access network. So where you've got the virtualized radio access network in some cases, it's big basically a BBU cabinet that is sitting at the base of the cell tower. And in some cases, that can be a 1U or a 2U ruggedized outdoor cab cabinet. And the challenge there is that because it's such a small space, you've got a limited number of cores 16 to 32 CPU cores And worse, as an operator, you are subject to power metering there from the local energy provider Because it's not a big data center, you can't buy power at bulk and you can't do long-term contracts or do, you know, all of the things that you do, you're just subject to local power metering. So over there, power is the most biggest premium, in part because of space and because of where it is and so there energy efficiency is one of the biggest challenge in fact, quite often ends up being the most pressing thing that you're designed for. And then as you go towards the right, it becomes less and less of a concern for an individual deployment, but in aggregate it does become a big concern. In fact, you know, you will probably, you know, see in the news that, you know, one of the bigger challenges now with new data centers being brought up is energy efficiency Thank you I think the next person in the queue is Curtis Hello, Curtis Hammerel University Washington I have a bunch of questions so you're probably going to see me multiple times up here. But the first one was on the troubleshooting guide work, which I found really interesting in the sense that it seems like we're going from kind of machine to human readable to machine readable to human readable, and sort of back and forth over there. Is there any sort of thought towards having the vendors produce like"
  },
  {
    "startTime": "00:44:01",
    "text": "to human readable, and sort of back and forth over there. Is there any sort of thought towards having the vendors produce machine readable troubleshooting guide that feels like if they just generated the JSON themselves that like cuts out a whole bunch of risk? Yeah, yeah, great great question in fact we've had many discussions about that and and you know many engineering teams they jump to that, like, okay, what if we were to do that, okay? and in fact, that is absolutely the right approach for a mature product where you product isn't really evolving, the behavior of the product is well known and so you can spend the engineering effort to write either a JSON document or actual code that will automate troubleshooting rather than have a English document. The reason we have an English document you know, in this space is because this product is rapidly evolving And so you need to have speed. You need to have speed to, to write down, okay, here's what I found here's how to go fix it, and you're rapidly iterating over those. In fact, we have some troubleshooting guides that have had many updates within a one-month period. And so having engineers, sit alongside and write new code each time or update code each time that change happens is quite an expensive endeavor So what's interesting is that we can short circuit some of that effort using AI Hi, wes hardaker University of South California. Thanks for the presentation. I loved watching you solve three different things to come back the larger problem of, you know, your network's performance I think that was a great triple combination With respect to painter, I had one question of you're optimizing routes according to, you know, sort of specific needs Did you study, you know, after making changes? to how much did it adversely affect other people? when you're changing routes in one location to improve? latency with one location where, you know,"
  },
  {
    "startTime": "00:46:01",
    "text": "the neighboring network may actually be have a completely different path that could have significantly degraded them Yeah, great, great question. So you know, a couple of ways to think about it. One is that we we don't make changes to our any cast announcements. So the vast majority of end users still continue to use those NECAST announcements and, you know, quote unquote default writing to reach us, right? And so we use this in a targeted way to go after specific customers who have very poor performance. And so only traffic that is that is super latency sensitive that needs that better penalty is being changed. So, you know, in the majority of cases, you know, we expect this to impact small numbers of users rather than the vast majority of users. You know, I wouldn't recommend this as a solution to serve all internet users, you know, that would be not a great great idea and probably, you know, we're better off, you know, deploying a new protocol. Do you have to use? regional DNS to get them to shift to a union address? Ah, great So a couple of points there. One is that when you use regional DNS to make these sorts of changes the challenge that we find is that it takes a long time for those updates to propagate and still records to actually not be used. Turns out scale records are still used for a very long amount of time So in our deployments, we are talking about enterprise customers which are almost always using either SD-WAN appliances or VP gateways into the cloud and are doing, you know, essentially private v-net peering on top of those VPN gateways So there are those edge boxes that are configured to use an IP address where that endpoint is in the cloud of, you know, this is the other end of this VPN gateway. Well, we can control that, right? Because all of that is being deployed from the cloud control panel Great. Thank you very much"
  },
  {
    "startTime": "00:48:02",
    "text": "Thank you very much. Do we have more questions? Otherwise, while people think of questions, I will take the chart's privilege to ask one myself So, it's very interesting. I mean, from what I can see, you saw that the is a lot of opportunities for AI, ML to contribute to networking however at the same time, it looks like most of the things that you explore are optimizations. So in a way, not disruptive. So my question is, do you see a scope for disruptive implications of AIML in networking Wow, that's a that's a tough one you know the hope is that maybe, maybe yes you would, but I think we're right now in an era where, we, there's all this low-hanging fruit that we can go after, right? There's all the slow hanging fruit. Like, you know, there's even stuff that I didn't talk about, which is, you know, being able to look at things like standardization specs and being able to help engineers understand that or produce, you know, validate or verification from those as to whether an implementation of a network function is accurate or whether it's going to interoperate properly So there's so much space for improving our existence systems. I personally feel like it behooed us to first go after all of that and improve all of our existing systems. And then, you know, if we have the luxury of actually having systems that are complete AI dependent from the ground up, that's a fascinating area to explore I think it. Well, I really hope you were not saying that you were going for the low-hanging fruits No, I mean, it's important for us for the community to also go after the long-hanging fruit. It's very important And actually, like, you know, it's not straightforward to go after that. It is low-hanging but it does require a fair bit of thought and design to go after it. Do you think that it increases the barrier?"
  },
  {
    "startTime": "00:50:01",
    "text": "of entry for small competitors that do not have the ability? to compete with a large enterprise such as Microsoft that can have? a lot of ML engineers to refi and improve these optimizations? That's not a criticism. Yeah, no, no, I don't think so Like, if anything, like I'm saying, I'm seeing that don't go off and design custom algorithms as much as possible use off the shelf ones and those are so readily available. And you can host them on your own infra, you can host them on cloud infra. You know, it's your choice. So in fact, yes, you know, I, I highly agree do not try and avoid designing your own custom algorithms as much as possible. Thank you, that's a very good point. So I think we have Laurent in the queue Yeah, hi. Great work. Thanks a lot. Two questions One is what areas will you see in subject to standardization in based on your experience what areas we could actually try to say, okay, there? if we work on standardization or interoperability, we use a experience? What areas we could actually try to say, okay, there, if we work on standardization or interoperability, reusability of some of the things that you have done, could be pursuing IETF or other SDOs And my second question is, do you intend to make any part of your work, maybe some data sets, maybe some of the code of your work available? open source for order to reproduce or to experiment with you? Thank you Thank you for both questions. For the first one, I would actually ask you, I'm not a standardization expert I'm here. This is IETF, so you know, I would hope that they're far better experts in the community than me to tell me, to tell us, you know, what would be interesting new areas that we actually have hope of standardizing and bringing to market As for your second question, you know, come talk to me. Like, you know, if there's strong interest in a particular system where it's worth for us to go through the effort of going through an open source effort on it and documenting it and making it available, we'll look into that"
  },
  {
    "startTime": "00:52:01",
    "text": "So yeah, just come find me and let's have a chat Thanks Heather. On the next person in the queue is Jerry, please go ahead Yariarko Erickson Research, so I wanted to return to this hallucination problem a little bit, which is what the queue is Jari, please go ahead. Yari Arirko Erickson Research. So I wanted to return to this hallucination problem a little bit, which is always interesting. And I really like your approach there, breaking things down, having a plan and smaller steps and less room for error That's also what our teams have found to be a working approach. But I did want to ask a little bit more. You talked about the use of existing tools. Where do you see the role? of sort of human in the loop in this situation? So one would assume perhaps that when you just want to observe more things like, you know, is this thing broken? Is this thing broken and so on, that's maybe okay for the AI to go ahead and do it by itself But when it comes to actions they might require some kind of user interaction before things are performed at least more drastic actions may be if it's something related to some single user, then you can go and do that immediately but if it requires a reboot in the core network or some such then you would, you know, maybe want to wake somebody up to make sure that that's correct. Is that, do you, do you, do feature the user interaction in this model in your mind? or? Yes, in fact, like we, we heavily encourage user interaction, but we want to limit that as much as possible so in our situation what we do is we design for human auditing at critical choke points So one choke point is the production of a plant, which is infrequent So, you know, for a product that maybe, let's say, has a hundred the production of a plant, which is infrequent. So, you know, for a product that maybe, let's say, has 100 TSGs, that means, you know, when each one of those is written or updated, then you also go look at a plan Now, we also try and reduce the effort that is involved in having a human look at it by doing automatic checks"
  },
  {
    "startTime": "00:54:01",
    "text": "For example, you know, here's a step that has an input but, oh, we don't know where that input is coming from That's a problem. So we can automatically flag that, right? So there's a bunch of verification that we do of the plan that is generated to reduce the amount of work that we're asking a human to do now when it comes to actual execution of a plan, that's where things get interesting Every tool in our system has a, this was actually there before we even design our system, where every tool has an indication of whether it's a read-only or read-write tool. Read-only tool is things like show interface status, read-write tool is reboot the switch, okay, and so we can operate in a hitless manner where we say, okay, all the read-only tools, yeah, go to town, go run all of those and annotate the log with it. But anytime you want to go run a read-write tool, you got to go ask a human for approval, yes or no, you know, can you go run it, right? So we can do that until the human team has gained the confidence that yes, you know, this plan is out accurate. We've seen it run 10 times. It's the same plan that gets run in every incident because we're not generated a new plan on each incident. So then you can cross a certain conference threshold and say, yeah, go to town you know, go go ahead and automate the rest Thanks. Makes sense Thank you, Jerry. Next person in the QI is all tonight. Please go ahead. Yeah, hi uh i'm althana i'm sasko menaki i have a question on Tipsi. So the biggest problem with predicting ingress traffic is how to differentiate between short time scale burst and persistent burst So I'm curious as to understand how did you decide that when do you decide that it is time? to shift and not be, not be causing too much disturbance in the network all the time Yeah that's a, that's a good question. So, you know, ultimately, you know, that is those are just a set of parameters in our system. And the parameters that come into play are really"
  },
  {
    "startTime": "00:56:01",
    "text": "you know, the, the window of time that you're looking at for link utilization and the threshold. So if the threshold for link utilization has crossed some arbitrary threshold, let's say 70% in the last five minutes, I'm just picking these at random but not too far off the mark. And it's been persistent for some amount of time And you can pick that amount of time. Let's say, you know, 10 minutes then you might want to consider actually doing a withdrawal because your customers have been suffering for a decent amount of time. The other factor that, you know, as you well, know, that you want to consider is when you make a routing chain it's going to take some time for those route announcements to propagate in the order of minutes. So you definitely don't want to be making these sorts of twitchy decisions at sub, you know, multi-minute time skills. So, you know, typically we're looking at situations where, you know, that congestion has been happening for a long period of time, like, you know, 10 minutes or so Okay, thanks Thank you. Thank you. And I, next part in the queue is Edwin. Please go ahead edwin please go ahead a great presentation i just wanted to ask uh regards Tipsy, when you make changes, have you looked at it? implications of potential polarizations? and bottlenecks in the network downstream from you ah yes excellent, excellent point. Yes, indeed, we, we don't know there's a potential for it causing bottlenecks elsewhere in the network that are outside of our network and causing performance degradations. And yes, we don't elsewhere in the network that are outside outside of our network and cause you know performance degradations and yes you know we don't have great visibility into what is the available capacity on those other links outside of our network on an alternate path where traffic would come in. In fact, we don't even know what that alternate path is We can only predict here's the other Ingress link that you know, with 90% accuracy we think it's In fact, we don't even know what that alternate path is. We can only predict, here's the other Ingress link that, you know, with 90 percent, you know, accuracy we think it's going to come in at. But, you know, the"
  },
  {
    "startTime": "00:58:01",
    "text": "are other interesting effects that along that vein that we haven't studied, but are really interesting to go look at, for example we looked at those corner cases where our accuracy prediction wasn't fantastic. You know, like a few percent, and then we started looking at those manually and we found some fascinating examples. For example, we saw traffic coming from a U.S. national lab from an exchange in South Africa And, you know, our prediction models like, no, that, no, we shouldn't be seeing traffic from there. And yeah, that was probably right. We shouldn't be seeing traffic from there. And that was probably, I would guess attack traffic or spoof traffic. So you know, something like this could be used to detect, you know, very unusual behavior and try and go out was probably, I would guess, attack traffic or spoof traffic. So, you know, something like this could be used to detect, you know, very unusual behavior and try and go after that. Thank you. That's amazing spoof traffic. So, you know, something like this could be used to detect, you know, very unusual behavior and try and go after that. Thank you. Thank you, Edwin. Do we have more questions? Maybe another question from my side. So this quite interesting. I mean, you saw that with pretty much off-the-shelf ML AI tools you can do quite a lot. So what I'm wondering is, well this is a state-of-the-art AI ML tools but it looks like we're still have quite a bit of opportunity for pretty large improvement in all these tools. Do you think that they think I don't know, like five years down the line, AI is not just an amazing black box, but a super amazing black box. Same with ML. Do you think it will open? up an uncharted territory, new opportunities that they cannot be thought of yet or we will start hitting decreasing marginal returns on the potential optimization that can be done? Oh, another time question. You know, there's you know, every, it seems like every couple of weeks you know our eyes are opens by yet new kipps capabilities that we're able to leverage from these new models. You know, the one that I haven't started leveraging yet is the multimodal nature"
  },
  {
    "startTime": "01:00:01",
    "text": "of some of the latest models. So imagine where, you know, if you are trying to automate some some network action, but that action is not through an API or command line, it actually requires a Google Well, you know, you can use a multimodal AI to actually look at a screenshot, understand what's going on where all the buttons are, and actually then go automate mouse clicks and keyboard commands and actually go make that change and go look at that difference in the screenshot. So, you know, that's a new capability that can potentially be super useful in, in automating network deployments or update You know, many, many of our interface we need to really rethink those, like to today, if you wanted to go deploy a complex network to policy, on a cloud, you had to spend a lot of time thinking about how to design that, what are the you know that the templates that I need to write in Terraform or by Bicep or any other language, go write that and go deploy that. But we're getting to the point where no, that shouldn't be the interface. The interface should be here's a description of the topology that I want to deploy, or like a napkin math or diagram Here's a picture, a screenshot of this napkin diagram that I've drawn. Go deploy this for me and I think we're at the point where yes, that can be done so we really should start to rethink all of our interfaces and think about whether it makes sense for it to still be that way or for it to be a completely different interface Thank you. Very interesting. We have a question from doug montgomery. Please go ahead Something of a follow-up to the question about tipsy downstream effects. Do you reason about at least, your view, of the AS-Pathlink? to the source? And even if it doesn't factor in your reasoning, do you measure your correctness, whatever your efficiency with respect to that? Yeah"
  },
  {
    "startTime": "01:02:01",
    "text": "so it turns out we, if we look at it from the point of view of traffic and, you know, weighted by the number of bytes, we are directly peered with the source AS for the vast majority of bytes that enter our network, right? And that's obvious. That's what everyone large wider network back on would do And our initial thought when we started looking at this problem was that, well, that should be a straightforward problem Like if we were to look at, for example, any other cloud or any other ISP that we peer with, you know, we paired with them in maybe 10 20, order 10 locations, right? Shouldn't be a hard problem to predict which one of those locations traffic is going to arrive on. Well, it turns out in we see all sorts of unexpected behavior Like, for example, one large cloud is that we peer with, we peer with them in about a dozen locations, we see traffic from them arriving in about a hundred different peering links. Why? What is going? on? We directly peer with them in 12th locations. Why would it come this other way? And so we've got hypotheses like one hypothesis is that maybe this other cloud doesn't have a continuous wider network backbone Or maybe, you know, they've got islands, or maybe at various times they, you know, their network gets segregated, you know, because of a cut We don't know. So, you know, there's a really interesting, unusual effects that we see out there that we you know would otherwise think that direct peering would, you know, remove the need for Thank you, Doc We have a question from Cortez? Yep, I'm back So I just continue on this discussion, because I think it's a very interesting point. We've been working with sort of large-scale CDNs that similarly have come back about this particular issue of just kind of the internals of the network of the network being the internet like the traffic flow into their interconnects being really hard to"
  },
  {
    "startTime": "01:04:01",
    "text": "predict. And so what they've been doing is actually deep hearing at many of the IxPs in order to gain a little bit more control over those flows. And I was reminded because that was a, you know, you're pulling routes, and so it's not exactly the same thing. But it's not not the same thing And so I'm curious what you think about the I guess, efficacy of that as a solution space. Does it feel hacky to you? Is there more that we can do there? just pulling routes? as a way to kind of load balance and do traffic? engineering from your perspective? So it's interesting that you bring that up. I've been in some discussions there as well around deep puring and in many cases, you know, those discussions are driven by security risk. For example, you know, maybe there's a peer that doesn't have good routing hygiene or router configuration and they can leak routes And so, you know, one way to combat that is to do a much better job of enforcing things like RPKI or other route attestation technology But when it comes to, you know, deep hearing for better performance, I don't know, like I have mixed feelings about that. I think ultimately we want to get to the point where, we have no choice but to fat our biggest peering links. I'm not ready 400 gigs seems like it's small, but it's like some of our fattest peering links. And to upgrade that is a massive undertaking Like, not only is it just about the line cards on both ends but the router back plane has to support that, but then there are all these downstream effects like all of our long-haul lengths that connect that peering point into the rest of the network has to be upgraded, all of the caching servers sitting there have to be able to support that much more traffic. There's just so many effects that you have to account for that it takes a very, very"
  },
  {
    "startTime": "01:06:01",
    "text": "long time to go after those So in some sense, like, you know, my answer is that it's going to take us some time. I think it's going to take the community some time to get to the point where we can now have much, much fatter pairing lanes to reduce the frequency of these types of effects happening because those end-use connections have just out of the blue have just maybe not out of the blue, it's taken a long time, but if suddenly, you know, now at the point where they've gotten a lot fatter and that's, that's hard, that's hard on the core of the network network Thank you. We have time for one or two more questions i will ask one from my side uh so people can think of a question if they still have one so coming back to a previous question that I can't recall who asked about opportunities for standardization let me reverse that question. As you are integrating AIML in networking systems, could there be space, would there be standardization would help you to do that in an easier way or in a safer way? or in a less buggy way? You always ask the hard questions. Yes, yeah Well, I mean, absolutely I think, you know, one of the things that I think is still hard at least I don't know, you know, how to solve is how can we how can we evolve our protocols so that you know, let's say we decide that we want to deploy an update a significant update or a new protocol, how can we deploy it? in such a way that we can start to see benefits? with peers that also deploy it, but continue to participate in existing deployed protocols? It's a very, very hard pill to swallow to say that, oh, we're not going to get benefit until we cross, you know, 50% participation or some large threshold because it's a, it's hard"
  },
  {
    "startTime": "01:08:01",
    "text": "to convince a deployment team that they should, they should spend the time, effort, and money to go deploy something new that's that's unproven and so you know we we need to think about that and think about better ways for being able to do this in a space like network routing where, in most cases, you see benefit when you've got a large deployment of the protocol Thank you very much. That's a very interesting answer and looks like there are no more questions. So let's speak looks like there are no more questions. So let's give a big round of applause to Sharad. Thank you very much Thank you So thank you very much and after this very interesting presentation about the leveraging AI and machine learning for 5.6 systems, we are going to move to our first session of the morning on measurements So if you can come to the stage, schedule get you set up Thank you"
  },
  {
    "startTime": "01:10:07",
    "text": "Thank you for the slides needs something to control I plan. I'm going to use her so it's connected and we avoid the basis with the wireless that we had before No, it's working Well, so we caught forward first paper of the morning, HTP3's extensive prairie precisiness came on the while by your Herbert. So I will apologize in advance for any name battering that I do, but it's due to my accent, not to your writing. Thank you very much and the room is yours. That's fine. Thank you. So good morning everybody, my name is Joris, Herbots, I'm a PhD student over at Hustl University in Belgium. And well, obviously I'm here to present something and this is the results on HG3's extensible prioritization scheme in the wild. Maybe let's first start with HCTP Right now, we have three versions of HDP deployed in the wild going from HTTP 1 to 3 with the main difference being the way that resources us we have three versions of HTTP deployed in the wild, going from HTTP 1 to 3, with the main difference being the way that resources are scheduled. Like HTTP 1 was a simpler came from a simple time, the web was simple, we had not a lot of resources that need to be scheduled. So the protocol only did one resource for connection and as the web's needs evolved, so did the protocol and with HTTP 2 and also 3, we have a way to schedule multiple resources per connection. Now, if you're talking about scheduling multiple resources, we are talking about multiplexing And if you talk about multiplexing, we should also be talking about the relationships these resources have to each other"
  },
  {
    "startTime": "01:12:01",
    "text": "How can we indicate this? And the way we do this with HTTP is by using HTTP privacy multiplexing, we should also be talking about the relationships these resources have to each other. How can we indicate this? And the way we do this with HTTP is by using HTTP priorities. And I'm showing here a example of HTTP 2 priorities from a block from Cloudflare, where you can see HTTP 2 in action And why am I showing this? Well, it's clear that if you use HTTP priorities in the right way, you can actually have web pages that load way faster and you can have way more interactivity at the sooner time, in a sooner way As you can see, for example, here, Edge Safari are not loading or not showing anything and Firefox in Chrome are already showing something so um this underlines the fact that priorities are rather important to web performance Right, so I've been talking about HTTP priorities. You've seen the example of HTTP 2 priorities, but HTTP 2 priorities is actually deprecated as of now. It was released together with the RFC of HDP2 2, but it was way too complex, and it's so suffered from limited deployability and interoperability meaning that nowadays, well, it's still there in practice, but it's deprecated officially In its void came the extensible prioritization scheme which was released as a separate RFC so not together with HDP3 The fun thing about the extensible prioritization scheme as well, it's simpler than HDP2's priorities. It's accessible as the name suggests, and it can also be backboard to HTTP 2, which is nice So in essence, what I'm saying is the extensible priorities scheme is a good thing. It's simple So, of course, immediately everybody deployed it and everything was well in the landscape of priorities right? Well, real is a little bit more confusing, however, when we try to use this in practice, we encountered a lot of chaotic elements and an interplay that was not"
  },
  {
    "startTime": "01:14:01",
    "text": "doing the things we expected them to be doing Which brings me to why we did this whole work in the first place, the whole crux of this So we looked at EPS support in the wild. We tested both Brouser and so the clients and server setups. And not only because we encountered this issues, but also because EPS and HCP3 are at this point two years and a month, I think, old And also because we see a lot of traffic actually using HDP3 as we speak. These results are from Cluidverleg Radar, which shows that around 30% of traffic now passing Cloudverleg is already being or already using HTTP 3 Right So I said we checked browsers and servers. Let's start with the browser site. The way we did our experiment is by setting up multiple HTML page which load the variety of resources. So everything from CSS to images to fonts, JavaScript, you need it. We had a custom A.O. Quick server, the deployed that serve these pages, so it could lock everything that the clients were actually sending over, and we did this over a period of 1.5 years Now, I've been talking about EPS, but what actually is EPS. To get an idea of it, I said this two simple parameters where we have the urgency parameter and we have the incremental parameter. The urgency parameter as the name indicates, is the actual urgency, the priority of it resource, divided into eight discrete buckets, with the lowest number being the highest priority in practice. And then we also have the incremental parameter, which is a bullion, a flag, you can say which indicates whether or not a resource can actually share bandwidth with all the resources. A good example of the is for images If you have 10% of an image, you can show 10% of an image If you have 10% of a JavaScript file, you can do anything with that yet which is why we need this incremental behavior for some time of resources"
  },
  {
    "startTime": "01:16:01",
    "text": "The way we signal these resources is a do anything with that yet, which is why we need this incremental behavior for some types of resources. The way we signal these resources is via two ways, either through an HTTP priority header, which is the most simple element to use, or the most simple way to signal priority. And the second way is through a binary frame also called the priority update frame, which is sent over-the-control stream of HTTP 2 or HTTP 3 What did we see? Well, a lot of heterogeneity So broadly we can actually classify the browsers into three distinct categories according to their approach We noticed that Chrome has a very fine range approach. Most resources have their own heuristics being applied to them. And they also use the incremental parameters to signify whether or not resources need the incremental behavior. Safari falls in the middle with a medium-grained approach and always applying the incremental parameter which doesn't make a lot of sense because as I just said, not all resources need this is actually a bad approach in the wild and Firefox uses a very coarse grain approach broadly categorized for example, all images in the same priority or using the same priority rather. And never using the incremental parameter, which isn't horrible but not good either we also checked the signaling methods as you can see Chrome is using both HTTP headers and HTTP binary frames which is nice. Only problem there is if you want to manually override something using the fetch API it only overwrite the HTTP header and not the binary frames meaning that depending on what's happening on the wire, you could actually have confusing information arriving at the server Safari allows overriding and only use the HTTP priority header and Firefox only uses HTTP priority headers and doesn't allow manual overriding So we generally see a lot of heterogeneity in like parameters and usage of it"
  },
  {
    "startTime": "01:18:01",
    "text": "A good example of this is fonts Fons discovered through the font phase directory in directive in CSS get a very different priority applied to them than, for example, fonts that are preloaded. A good example, also of an inconsistent juristic is Firefox here It actually applies a low priority to a custom font, which could indicate a later arrival and also trigger a cumulative layout shift, which is to be generally regardless quite bad in practice Slides are not advantage there we go we also saw similar inconsistent statistics being applied with JavaScript JavaScript we defined in the head as just normal JavaScript and async and defer JavaScript get very much levels of priorities applied to them which is quite weird in practice. Safari being the weird here, in that it actually shifts one of the two to a medium priority We also, of course, check the fetch priority API, which is like currently the only way we have as web developer to indicate whether or not we should change something to the default priority being applied by browsers. In a nutshell, what fetch priority allows you to do is like bump or decrease It's a hint given to the browser that it should do something with the priority. And also here the results are a little bit all over the place Chrome actually tends to ignore 50% of all hints given which is quite ineffective as a result. Safari is actually quite deterministic in that if you increase the priority, it bumps the priority. If you lower it, it lowers it So that's nice. And Firefox actually doesn't even have support for it yet at this point, which is, well as a conclusion quite sad So I hope it clear that with these examples, that browser actually have quite a misaline behavior when it comes to like priorities and heistics being applied to them, which in"
  },
  {
    "startTime": "01:20:01",
    "text": "essence isn't a good thing at this point. In fact, it's quite bad, but it's not horrible, at least if servers are doing what they should be doing Spoiler, they don't We checked servers in a very similar way in that we had a modified a quick client which could signal EPS priorities towards the server And the way we did this is by using a wide variety basically permutation of all possibilities that aspect did this is by using a wide variety, basically permutation of all possibilities that the spec writes up and even some extras to see what server actually do in the wild. And we did this on 12 server stacks we manually picked based on popularity going from popular deployments such as CDA like Akamai, Fastly, Cloudflare, but also of the off-the-shelf software such as Caddy and EngineX Same here. We did a lot of repetitions over a couple of weeks which produced around 27 gigabytes of logs, which we all manually analyzed with the Cuvus tool suite excuse me, as the logs were actually Q-locks And we summarized all those findings in this table that you can also find back in the paper. What we basically check is the following behaviors, like default scheduling What is the default scheduling that a server applies, which is very important because if incremental support is there or not, it might mean that you're stuck with something good or bad We also check the ways that servers accept these signaling, similar as browser cells it might mean that you're stuck with something good or bad. We also checked the ways that servers accept these signaling, similar as browser sending them out. We checked whether or not priority headers are supported and the update frames are supported. We also checked a feature of the specification called reprioritization which is basically, as the name suggests, a way to reprioritize a resource that you already requested mid-flight Whether or not the urgency and incremental parameters are supported, and also the basic incremental chunk-sizing behavior of these servers. Same with browsers servers can be categorized into four"
  },
  {
    "startTime": "01:22:01",
    "text": "distinct categories. Let's start with one side of the spectrum being the no support side, which speaks for itself. Amazon Cloudfront, EngineX, Caddy did not show any support for EPS, which is an necessarily bad as we spoke to EngineX and Caddy developers and they gave us an indication that it's definitely on the roadmap which is good. On the other side, we have the full support category in which we find Fastly in QuickCloud, which is also awesome basically they responded in a good way to everything we sent. They responded in a, according to a what the specification says, which is great. With only a minor difference in like the incremental chunk sizing. We noticed that fastly round robins every packet on every stream and QuickCloud basically chunks a couple of packets going from one to 90 is what we saw in practice and then switches streams to do its incremental behavior More interestingly is the partial support category where we find varying levels of support. Akamai, Kloidflare, and most of Google services all under this A good indication, or a good example here is the priority request header field being ignored by both Akamai and Google services which is quite bad in practice. Because if you remember, from the first slides with browsers, Firefox and Safari only use this header, meaning that you have pretty much browser supporting priority. You have the servers partially supporting priorities and the communication is pretty much lost in the wild as the priority request header field is basically ignored by these services Another good example of something going bad is the incremental parameter not being supported. So we have the two basic parameters and one is basically ignored which isn't necessarily bad in Akamai's case because it has a default scheduling behavior that is sequential So pretty much we cannot have any incremental behavior, which isn't the worst. Worst behavior is seen at the Google site where we have default scheduling behavior that is actually incremental, and we cannot swap this out for sequential behavior because the parameter is not support"
  },
  {
    "startTime": "01:24:01",
    "text": "And this is really interesting or funny even because Chrome actively requests sequential loads but it's Google servers themselves actually always reply incrementally. So we have an obvious indication that we have two teams developing Chrome and like the Google services that have diametrically opposed approaches when it comes to like web performance optimization, which is quite interesting And then finally we also have the indirect support category. We check J's Deliver and Shopify here, which are basically hosted on top of Cloudflare and fastly and what we noticed is that um services hosted on Fastly actually adopt the parents' behavior So everything EPS related is also seen in like stuff hosted on top of Fastly. But when it comes to Cloudflare, we actually do not see any support for EPS at all anymore meaning that Cloudflare is probably, and I hope there's some Cloudflare engineer in the room that can maybe give an indication of what's happening here, but to us, it's an indication that CloudFair is actually running multiple stacks of making different choices in them stacks, having a configuration disabled or something like that. Also, interestingly, in J.S. Delvers case, which uses Cloudflare and Fastly, you have some very inconsistent behavior. The whole goal of J.S. Deliver is to have optimized delivery of JavaScript files and depending on what kind of backend you hit, or even if you hit them both, you have basically very misaligned behavior once again which basically undermines the whole couple at that point Right. So say, with service, considerable heterogeneity We have chaotic behavior at the client side. We have chaos behavior at the server side, combine them and the picture doesn't get that much better. It gets even worse when we look at stuff like fetch priority, because if we even want to override this behavior or do some well, yeah, basically override the behavior, it's not possible because fetch priority at this point is quite in effect um even worse if we want to optimize with fetch priority, we could work"
  },
  {
    "startTime": "01:26:01",
    "text": "the experience in other browsers, which is basically a worse experience, throwing us back 20 years into the past, where we had these little images in the footers of our world worsen the experience in other browsers, which is basically a worst case experience, throwing us back 20 years into the past where we had these like little images in the footers of our website saying, this is optimized for Internet Explorer, let's say I think we can all agree that we do not want to go back there um once again why is this important? Priorities impact web performance And if there's one thing we care a lot about as web developers website, maintainers, webmasters, if you want to use the old-school terms is that, well, this is important, right? Which brings me to the recommendations that we bring forward, which are actually quite straightforward if you were listening to this talk. First of all, full support We have a chicken and egg problem. We need full support by EPA by major deployments. If we do not even have support, for the basic features browsers will not be using them and we are basically stuck in this vicious cycle Behavior at this point is very inconsistent when it comes to like the basic parameters being supported. Not only that, but also the extent extensibility, which is in the title of EPS, is basically being thrown out of the window at this point So the whole specification defines a space for future extensions if we don't have these basic features yet, well, we can forget about extensibility Then another recommendation is better manual control through developer API Once again, we have a chicken and egg problem Currently, we do not have a lot of manual control. And we need this if we want to have some workarounds for like the basic heistics being applied at this point. A good example of this is allow us to change the incremental behavior. At this point, we can only hint for a priority increase or decrease but we cannot change for example the incremental behavior being a applied on resources not only that but it would also enable more complex web applications, such as, for example, videos, streams, which might want to make use of priorities, especially, for example, on low latency lines streaming scenarios. And final,"
  },
  {
    "startTime": "01:28:01",
    "text": "the last two recommendations, we need further research in, like, loading heuristics and prioritization strategies Browsers are clearly misaligned. We even see differences when we look at priorities in HTTP2 stacks and HTTP 3 stacks within the same browsers I think we need to combat this heterogeneity simply because this will improve long-term end user experience And final but not least, major deployment should probably also be looking at offering realistic testing resources, the whole point of quick, the whole point of HTTP3 is to combat ossification and at this point, we are, I think, and with results we have shown here, we need some way to do a thorough development of these stacks and especially also the future extensions And with that, I come to the end of my slide set. Feel free to scan this. This is a table that shows all the browser findings, nicely compiled. It's a simpler version than the one presented in the paper. It might be interesting And I am happy to take any questions. Thank you Thank you very much And we have a question from matt mathis, please go ahead Yes, in your recommendation for full support an incremental approach to that would be a recommended order to implement features. It kind of appalled me that Google seemed to have implemented features in different orders or seems to be implementing features in different orders And it might be useful to be able to head that off in the future Okay Yeah. Well, okay i agree Thank you, Matt. And we have a question from Mark Munizaga Okay, Marco, webmaster enthusiast So would it be possible to me? a website that's like are we EPS yet? where like browsers hit it and the server can return like all the stats on the browser?"
  },
  {
    "startTime": "01:30:01",
    "text": "Good question I don't think we have an easy way to do this at this point The specification also clearly indicates right now that communication back towards the client about whatever is being applied at the server is not mandatory. But there are services doing it right now. For example, Cloudflare actually returns, I think it's debugging for a big reason at this point actually returns what priority was being applied on a resource and actually if incremental behavior was enabled yes or no. But there is no easy way to see what was actually happening. So I agree that it's fun if we could do that, but according to the specification it's not possible right now and we don't even see support for that in the wild. So yeah, thank you Thank you, Marco. We have time for one or two more questions maybe one from my side. It's quite interesting to see all these uh diversity across uh browsers and servers. And I was wondering do you have an intuition of why such diversity and do you think that diversity will reduce over time as how more things are implemented, more time is devoted to tackling decisions yeah good question. It's quite philosophical also in some way um it's difficult to answer because we have we have been seeing this since htp2 priorities right We have seen a lot of research going into this like the whole extensible prioritization scheme is actually also backed by previous papers in this field The thing is, at least that's my opinion I don't think browsers or browsers implementers right now are clear on what they are doing. They're just trying stuff. And we have seen this with a HTTP 2 and 3, like I said, like if you look at Chrome, for example, it has a very coarse-grained approach when we look at HTTP 2 priorities and now has very fine-grained"
  },
  {
    "startTime": "01:32:01",
    "text": "approach meaning that depending on what you use you have even very different behavior depending on HTTP 2 or 3, and vice versa with Firefox. So I think, well, browsers are currently just experimenting a lot I think it's a good opportunity to maybe come together and like discuss what are good ideas the web performance community at this point is quite aligned on what are good practices For example, do not schedule everything incrementally. Maybe we should start like having a roundtable discussion and get that going, right? Hi, I also want to add to what something similar to what Ignacio asked So we all know that H3 supported both the browsers like Firefox and Chrome. So do you think that there's variation in the results that you see could be also because of the OS? that supports this kind of browser, something to do with that? No, I think the full behavior is browser-related, so OSS doesn't really have anything to do with that. I have no indication at least that's not, we didn't test it, if, like, the the implementations being the deployed on mobile cell phones are different, but I think it's quite deeply embedded in the core of the whole products, so it might be the same might not be the same. I think it's the same, but I haven't checked that. But for differences between like main, main OSs like Linux Macintosh, Windows, I don't think we will see any differences. In fact, we retested on Windows and Linux We know there are no differences Brilliant. Thank you very much. So let's thank you very much Windows. I don't think we will see any differences. In fact, we tested on Windows and Linux. We know there are no differences. Brilliant. Thank you very much. So let's thank the speaker again And next we have Talmi Sarahi who is going to be presenting the observer effect in computer networks. And Tal, we can see you Let me hand over slides. Can you hear me?"
  },
  {
    "startTime": "01:34:01",
    "text": "Yes, we can hear you. Okay, great Just one second All right, and the slide are up and you should be able to control them so the floor is yours. Okay, thank you So my name is tal mizrahi, and this page is The Observer Effect in Computer Networks it is joint work with Michael Shapira and Jura Moses Yeah, I'm not sure I can control the slides at least not that I can see Then maybe just say next slide and I will click for you. Okay, next please Okay, great. So what? of the most well-known principles in physics, is the uncertainty principle by Heisenberg And basically it presents a trade-off between how accurately we know the position of a particle and how accurately we know its momentum of the velocity and this answer uncertainty principle is also formally represented by the uncertainty relation, which we momentum or velocity. And this uncertainty principle is also formally represented by the uncertainty relation, which we've seen this inequality on the slide But probably the best way to understand this in intuitively is by considering the well-known joke about Heisenberg. This is a joke So Heisenberg is driving his car and he gets pulled over by a policeman And the policeman asks him, do you know how fast to her? going? And Heisenberg says, I have no idea but I know exactly where I am So that's just a joke This is the uncertainty principle Next slide, please"
  },
  {
    "startTime": "01:36:01",
    "text": "Another way of looking at the same uncertainty relation is related to the way Heisenberg can conducted his experiments. What he did was in order to measure the location of a particle use the gamma ray And by using that gamma ray, he noticed that he was affecting the momentum of the particle. So this was more generally called a few years later the observer effect which basically says that when you measure a system, the actual measurement effect the system you measure Next, please So in this paper, we're presenting the observer effect in networks and the idea is very similar. The idea is that when you measure the performance of a network, the action the measurement actually affects the performance of the same network And we also present the uncertainty relationship again, very similar to Heisenberg's uncertainty relation and the idea in the uncertainty relation is that when you measure a performance metric M, you actually affect different performance metric p metric M, you actually affect a different performance metric P. So this kind of, again, presents a trade-off between how accurately you can measure M and what is the impact on the network which is reflected in P Next slide, please So where is this? coming from? Obviously, when we do a measurement on the network, it causes some overhead And the overhead may have some impact on the performance of the network. Just a very simple example let's say we have A and B, and we're"
  },
  {
    "startTime": "01:38:01",
    "text": "doing an active measurement between A and B that means we're sending control plane messages between A and B. So obviously that's some overhead If we want the measurements to be more accurate, we want less uncertainty in the measurement That means we're going to send more control plane messages between these two nodes. So we're going to have more overhead Next please Okay, so why do we care about this overhead? So if the net Okay, so why do we care about this overhead? So if the network is already loaded with data playing traffic and then we add some measurement overhead, obviously when we add that over if the network is already loaded with data plane traffic and then we add some measurement overhead, obviously when we add that overhead, it can potentially cause some packet loss as a result of adding more loads to the network. Now, obviously we don't want more packet loss. One way to avoid packet loss Next slide, please One way to avoid this kind of packet loss is to over provision the network So we're going to use more resources than we need That way, there is no packet loss even when we add the network overhead But obviously if we're going to over-provision the network just for the sake of measuring that has a cost So we don't necessarily want to do that Next slide, please So at the end of the day, what it comes down to is asking ourselves, how do we quantify the impact? of the measurement overhead on the network? And in order to answer that question, we can look at various different metrics We can look at packet loss. We can look at the power consumption, which may be affected by some of the overhead we can look at the over-provisioning"
  },
  {
    "startTime": "01:40:01",
    "text": "cost, if there is over-provisioning Or we can look at the access traffic charges if, for example, we are billed based on the amount of traffic we're sending and receiving so these are various different approaches of how to look at the impact but what we chose to do in this work is we quantify the impact by the overhead traffic rate the number of bits per second caused by the measurement over chose to do in this work is we quantify the impact by the overhead traffic rate, the number of bits per second caused by the measurement overhead. Next slide, please Okay, so obviously for talking about measurements, very generally, there are different kinds of measurements which are completely different So just a few very basic examples in active measurement, which is what we see on the left side if we talk about the impact, since active measurement is performed by control plane messages, the impact can simply be measured by the number of bits per second consumed by these control plane messages And if we look at passive measurement in the middle part of the slide, in this case, each of the measurement points performs its own measurements internally independently. But if we want to observe these measurements, we'll need to be able to export this information to some kind of external analysis So in this case, passive measures the impact is going to be affected by the rate of these management plane messages which are exported to the analyzer And finally, a third example in-situ measurement, like for example, I IOM. In this case, the measurement is performed by adding some overheads to some of the data plane packets And the impact in this case can be measured by"
  },
  {
    "startTime": "01:42:01",
    "text": "the average rate of this data plane overhead that we're adding to some of the packets So these are a few different examples and like I said in each of these cases, the impact may be measured in slightly a different way, but at the end of the day, the common thread here is that the impact is always the number of bits per second caused by the measurement overhead Next please So some of the theoretical analysis we did here, what we did was assume that we're doing periodic measurements so that the measurement inter or the measurement period determines the uncertainty in the measurement. So that the more frequently we do the measurements the less uncertainty we're going to have And regarding the impact, like we said earlier, the impact depends on the overhead traffic rates. Next, please Okay, so basically we talked to about the uncertainty relation. We talked about the blue part, the uncertainty, the red part the impact, but we didn't talk about the green part the observer factor And it turns out that the observer factor, this constant, given the settings of the previous slide, it's very simply the number of overhead bits per measurement interval And this is something that is very easy to compute for every given measurement method of protocol. Once we know the measurement protocol, we can very simply compute the observer factor Next please So let's see what we can do with the observer factor So what we did in this work is in our evaluation, we took three measurement protocols and we used three open source code repositories to"
  },
  {
    "startTime": "01:44:01",
    "text": "be able to experiment with them So for each of these measurement protocols, again, since we know the product, we can very easily compute the observer factor It's shown in green here So we have a number for each protocol representing the observer factor But now what we do with this number? Next please So just a very simple example, let's say we have A and B and we want to measure the link from A to B and specifically we want to be able to measure when the link fail the exact time of failure So that's what we're measuring. We're measuring the time at which the link failed So in this case, the uncertainty is directly related to the measurement interval. It's equal to the measurement interval. So what we want to do is we want to be able to determine a given level of uncertainty. That's the requirement And for that given level of uncertainty, we want to compare the three different measures methods in order to understand what is the impact on each of these three methods on the network. So we have the observer factor for each of them The level of uncertainty is given So next please So based on the observer factor and uncertainty, we can estimate the impact of these three methods and actually since the level of uncertainty is something that is required, it's the desired uncertainty, that means that the observer factor directly determines the impact So in other words, when we look at the observer factors of each of these products, we already have a very clear picture of the impact on each of each of them on the network Next, please"
  },
  {
    "startTime": "01:46:01",
    "text": "So what do we do here with the observer factor? Basically what thing that is important to understand, it's very easy to compute and it allows us to do an apples to comparison between different measurement methods and protocols. We take any measure protocol, either an existing one or future one we compute the observer factor and then this gives us a tool for comparing the different measurement methods in terms of how they impact the network when the measurement is performed. Next please Just a few more words about the experimental evaluation. Like I said, we use three separate environments, three open source code repositories. And one of the things, we did was we measured the impact of each measurement method and we compared it to the theoretical curve So the theoretical curve is determined by the uncertainty relation In that way, we could verify the uncertainty relation compared to the results we got in practice in the experimental evaluation Next please So in conclusion, what did we do here? Basically, we presented the observer affecting networks, which means the the act of measuring the performance of an network, actually affects the performance of the network We also presented the uncertainty relation, this inequality which presents formally or mathematically the trade-off between the uncertain in the measurement and the impact on the network and these two components are basically based on Heisenberg's analysis of the uncertainty principle and observer effect"
  },
  {
    "startTime": "01:48:01",
    "text": "So this is kind of the theoretical part of our work. The practical part is the observer factor, because this is something that can be very practically used It's just a number that gives us a way of evaluating the amount of over consumed by a measurement protocol So it's very easy to compute for every measurement protocol and it can be, like I said, it can be computed for existing protocols, for existing methods or for future ones, and gives us a way of comparing different measurement methods in terms of how they affect the network and the network's performance Next That's it, thank you Thank you very much, Tal. Do we have questions for the speaker? Maybe a question from my side on the meantime. So you made some theoretical evaluation. I was wondering, how would you approach to calculate the observer effect? on the while? Have you thought? about that? Yeah, well, again the observer effect when you look at the uncertainty relation it has three components. The uncertainty the impact, and the observer factor And what we did basically in the lab can also be done in the wild you know the observation factor because that's given by the protocol itself and you can measure the impact. That's something that is measurable So for a given level of uncertainty, which is basically based on how you design the system you can measure the impact, okay, so that you know what is the impact and the impact theoretically is given by the uncertainty relation, but in practice it can be less or more"
  },
  {
    "startTime": "01:50:01",
    "text": "depending on how accurately or theoretical analysis was Thank you. Yeah, that makes sense I was wondering that to some extent probably the fact that many networks drop ICMP packets or struttle them or any other thing is in a way a reference of the costs that it implies to have measurements going through you either in terms of overhead or in terms of revealing something that you don't want to you think that you could use that or that would be correlated with the effect that you are trying to measure or to many other component factors? And I know that this is a little bit of a far far-fetched question yeah there are many components like you said since measurement has over in many cases ISPs operators may throttle some of that traffic may rate limit it and we know that speed tests may have dedicated handling by specific ISPs so that we don't necessarily get the same measurement result that we would get for the year tests may have dedicated handling by specific ISPs so that we don't necessarily get the same measurement result that we would get for the normal traffic So yes, in some cases, the way operators and ISPs treat measurement traffic may change the measurement result but this is the way the system is designed On the other hand, the observer factor or the observer effect is a principle that describes a case where you perform a measure it affects the network regardless of how the network is designed it's not related to a specific behavior of what the ISP or operator has imposed Thank you And we have a question from Juan Camino. Please go ahead Yeah, hello. Thank you. Camillo from NTT. Thank you for your work. It relates a lot of"
  },
  {
    "startTime": "01:52:01",
    "text": "monitoring protocols in a interesting way. I will ask you, so here we have many practical network operators doing monitoring. Do you have any, I can say no, but you have any practical advice? of how this could be used, maybe in the future? for designing networks for i mean any practical day-to-day engineering i think one of our one of the things that we're trying to see, here is that the observer factor is a very practical thing What we can already do in the IETF is based the things that we're trying to say here is that the observer factor is a very practical thing. What we can already do in the IETF is basically each time we're in defining a new measurement protocol we can compute its observer factor and basically we can compare the observer factors of each of the protocols we're defining it the IETF. And then we can have a kind of a apples to apples comparison of the different protocols you know ICMP versus trace rod versus T1 and so on. So this is a starting point for us designing the protocols to understand how much overhead each protocol consumes and that way we know how each of them can impact the network Very well. Thank you very much Tal, Juan Camilo, and let's thank the speaker Thank you And this concludes the first session of the morning on network measurements. Hope everybody enjoyed, hope everybody enjoys their lunch and I hope to see you later for the second session on Routing and Congestion. See later"
  },
  {
    "startTime": "01:54:07",
    "text": "There's a freeze in Thank you and five"
  }
]
