[
  {
    "startTime": "00:00:15",
    "text": "I think we have a wrong at our appointed start time Thank you all for joining us at this net our appointed start time. Thank you all for joining us at this NetMod session at IETF 120 in Vancouver. I am lou berger, kent watsen is here next to me and our we have a new secretary james cumming, James is here next to me. And our, uh, uh, uh, we have a new secretary, uh, James, uh, James. And there you end up over there um we thank our uh outgoing No, I was going to So Jason is going to be away from the IETF for a little while. It was that I wasn't sure what we were saying uh there but jason's um uh away from the IETF for a little while and we really appreciate all his help and contribution to the working group and to us sharing the sessions and we also appreciate that he helped find a replacement for himself So welcome James. Next Next oh, thank you. I did draw in chat the link to the note-taking tool Please join that link and help us capture what discussions we have here, and as a reminder, you don't need to capture what's on the slides This is our Notewell slide being an IETF. We have certain policies governing our disclosure of our ideas our technical work. Those are covered through a series of best common practices"
  },
  {
    "startTime": "00:02:00",
    "text": "these BCPs. If you're not familiar with this, it's really important that you go and become familiar with it Basically, anything you say here, becomes a contribution to the IETF and becomes part of our permanent record We also have guidelines about how we treat each other We do sometimes get a little anime in our discussions and our opinion but we should keep in mind to always treat each other with respect and professionally and keep it technical. It is perfectly okay to have a technical disagreement, but we still have to conduct ourselves professionally and we have guidelines on that and we also have escalation procedures if you feel that you have not been treated appropriately So for our actually aimed at you, because those who are remote who are listening, they've already been successful in this. So if you're in the room, please make sure to scan in. That helps us keep track of the number of attendees, which gets us the right size room It's also how we participate in queuing up for comments We'd like to be fair between those who are in the room and those who are outside the room so we will be using that tool also if we have any polls, they will take place using the tool. So please make sure to scan in I think I've actually covered these points, but it's a great reminder to joining us, join us for joint minute taking. This is really important if you have a comment at the mic and you want to to make sure we got it right, go check and make sure it's capped properly. If we have an action, that you hear us talk about, that's"
  },
  {
    "startTime": "00:04:00",
    "text": "really important to be captured and any all our help excuse me, everyone's help in that is appreciated Additionally, the URL for the note-taking James pasted it to the chat window Our agenda is a slightly modified from what was originally posted. We haven't renumbered the slots, but we've sort of done some reordering. Uh, the first change is that we have two working groups documents that have been proceeding at a very slow pace, and I think I'm not, I think I'm even being generous with that And the current editor have said they apologize for not getting out an update but they will get an update before the next meeting and they are number item number six and they've been scratched The other thing is, is that we have a new document that actually sort of in our opinion we could have started as a working group document because it's a spin out of existing working group document and we had it at the end. It was a little silently done So at the time of we put this agenda together, we didn't realize it was a spin out of the existing version work. So we'll hear about that all together Uh, this is a little bit in micro font So we have a number of post last call Actually, before I go there we have a common Yang data types that has been going through the process the publication process, and the current author, editor, doesn't seem to be overly responsive, so we would asking the working group for a little help here to help bring this one over the line, to bring it to completion And if you are interested in"
  },
  {
    "startTime": "00:06:00",
    "text": "helping out on this document, as editor, please contact us. It should be a pretty small amount of work and you'll get your name on an RFC your name in shiny lengths Mahesh, you're in Q I guess he didn't expect me to mahesh jethanandani. So yes, I want to support Lou's comment. We this particular document 6991 biz, has been sitting on my queue for 400 plus days, and I would really like to get my staff under control, and I appreciate any help from this group to pick up an editor for the document Are you going to volunteer? Maybe, you know, we'll shift the document shepherding to someone else All I'll say is I think a lot of the comments that were probably getting this document before seemed to have been resolved. So it should be a fairly easy process to get this over the line So I would really appreciate some help I also had a question on the previous previous So the common interface extension and sub-interface I know those two, both the drafts are expired, I think last week, and I'm wondering what is holding progress on this two drafts. Rob, I don't know if you been tracking this, but if you would like to jump in So Rob was one an author of these, and then it became AD, and then so. I know author of these and then it became AD and then so yes so author AD back to an author but I mean scott rose been editing is mostly so"
  },
  {
    "startTime": "00:08:00",
    "text": "we did and then Scott is in Q if you want to defer to him Oh yes, brilliant, I'll defer to Scott. That's better choice So Scott, you're up Oh, thank you. Can you hear me all right? Yes So I didn't think they had expired yet. I think they expire next week If they expired this week or last week, I apologize So the plan is to get them to reach them. They're in that funky state, which is probably not unlike the state of the one we just talked about, the types draft is that there's almost no comments. The issue tracker has been tracked, and it's just a matter of doing the final editing and getting the request to push it along in the in the process so it shouldn't be that much work just on dislike the last one we just talked about So I'm hoping to find, to find more time over the next month to get that done and out to the mailing list Thanks. That's great, Scott And if you are successful at the end of the site, maybe in September, we can have last call on this again after, what, four years? Did we do it last call four years ago? I think so. All right Yeah, that would be, that would be great. That would be really a pre- call on these again after what four years did we do what last call four years ago I think so all right yeah that would be that would be great that would be really appreciated so thank you so much yeah thanks and if I get that one done then maybe I'll do the other one too I've got to get these two done first Thank you. Thank you. So we're running a little bit behind, so I'm going to go a little quickly on these We have a list of post-last call documents the I'll highlight one, the very first one, because this is me not getting my job done. I have a document that wrapped up about a couple of weeks ago that's now ready for publication"
  },
  {
    "startTime": "00:10:00",
    "text": "So sometime this week, I'm going to submit that one for publication. I don't think we have any open issues We have a couple of others that are waiting on the authors When we get those revisions, we will, based on the change, we'll see whether or not we have to do another last call. I don't think so, but we'll see. We have a couple on the agenda We'll hear from those And then one of our favorites is the syslog model. I don't know if you want to say anything about that, Ken The dependency has been resolved, right? TLS, it's, I think it's RFC Editor Q right now So we're close No, no, I know the dependency is RFC Editor Q I know. The CISISLGF needs to be updated to reflect it Yeah. And you have the task You're going to update it. Update it. It's just a matter of regenerating the examples in tree diagram uh yeah drew clerk i we up updated it right after you made the last change to the TLS client server back in March so it should be ready to go Okay. All right. That's great. Okay. Unless anyone has anything else they'd like to hit on this slide I'm going to go to the next slide slide We do have one incoming liaison There's a document available I think I read it as the document differs slightly from the slides, but so it might be worth reviewing, but we're also going to hear about that on the agenda, so there's the opportunity to ask questions later later The I think we're pretty familiar with working with that on the agenda, so there's the opportunity to ask questions later. I think we're pretty familiar with working remote at this point. Just keep in mind, we have resources available to the working group that include informal meetings as well as formal meetings"
  },
  {
    "startTime": "00:12:00",
    "text": "and we have resources that we can make available to the working group members if they would like them and a final note we had a process change where we are now asking that for every meeting at the time of the IED cutoff, and that's important at the time of the ID cutoff, we'd like updates sent to the list from all authors or a request for a meeting slot. Those are the choices but we'd like not to wait until the actual meeting for that update so we give time for the working group to consider the cost Those are the choices, but we'd like not to wait until the actual meeting for that update. So we give time for the working group to consider the status and decide if they want to contribute anything during this meeting or before this meeting In the past, we've done updates right before and there's not really enough time to appropriately react for discussion. And we don't want to leave that opportunity With that said, does that have anyone have anything they'd like to bring up on an existing document that is not? on the agenda? Lou, this is Tim Carey I was just curious about two things that were on your status One was on the no tags that you said it was park because it failed last call and the other was on the best practices biz Could you give us a status update or could we get a status update on those two? Sure. The best practice I don't remember off the top of my head, maybe you do, but the don't believe that one is solved, but I just don't remember it off the top of my head. I have to go back to the slides. What? Best practices. Yes On node tags. No, I'm sorry, I didn't hear what you're response to the best practices. My response is I don't have that off the top of my head I apologize sorry um i will try to look back on it and come back to you, maybe even during this session No tags. We went to this document had"
  },
  {
    "startTime": "00:14:00",
    "text": "a tepid acceptance. You know, there was enough for us to say we'll work on it, and we were really hoping for there to be more interest generated And then we went to last call and we just heard crickets And so our read is, is there's not really adequate support beyond the authors know the authors to to progress this okay and if for some reason we, you know, the group thinks we got it wrong the document's there. We can take it off the out of the park All right, we're going to move on And Joe, are you next? Robin and Joe. I'm not sure who's coming up first Clicker I'm sharing it for 15 minutes I hope this will be quick Hi, my name is joe clarke with Cisco. On behalf of the authors and contributors who get on a call every Tuesday or so to talk about Yang module versioning. This is our update. We're hoping we've converged around a lot of the working group comments that have that have happened around this and that we're making some good progress towards a new last call Why may? It's you have to select? Oh, okay, sorry now so where are we we we're in Vancouver we collected the feedback from the working group. We presented this last time at 119, and we got some feedback not only from the working group from the chairs, specifically we'll get through one of these bullet points. Lou made a comment based on what we said there. So we consolidate all that feedback we went back and we started to make edits and we discussed the edits and and we answered some emails on the list and we came up with the two versions I'm gonna talk about now. Not a lot has changed So we published those two new revisions just ahead of this meeting. We sent a brief summary to the"
  },
  {
    "startTime": "00:16:00",
    "text": "list in what we changed and we asked for, we asked the chairs to call a new since these have already gone through one working group last call to call a new working group last call. Now the one thing that came up that we had decided not to address and we mentioned this last time of 119, was this idea of file naming. So you may recall that, and I know Per will discuss this, we have this text in there about recommended file naming with respect to Yang Simver and we said, you know what, we're not getting a lot of consensus around that, let's pull it out. And Lucy Moore, or maybe it was both of us. Why, whoa, whoa, why are you dodging this issue? We don't want to create an ad hoc standard So Per opted to take this on and adapt some of that text and I won't steal his thunder, but he is presenting that footnoted module there today. So we are not dodging the work. It's just going to be done in a separate draft, potentially Now, what did we change? So in Yang module versioning, in the latest revision, which is dash 12, we just did some minor text clarification, some typo fixes and we explicitly stated that the work applies to both Yang 1 and 1.1 So that was the sole set of changes between what we presented in 119 and what is currently in Datatracker today Okay With respect to Yang Simver, there was a big more changes in here. The reviewers, the authors, contributors went back and forth and said, you know, there are some things that could be clarified a little bit better, especially with respect to how you might change the versioning in a submodule with respect to the main module. So we added some clear clarification around that. And then we could have done a better job at explaining why one might want to skip version numbers. So remember"
  },
  {
    "startTime": "00:18:00",
    "text": "we had text in there that said you could go from a 1.0, 1.1 and then come up with a 2.0 and then a 5.0 Why would you skip numbers between, say, 2.0 and 5? So we added some text and an example of why, say, a vendor might want to do that if they're making a lot of internal changes. They're not released those modules, but then they're going to come out with a module that will be publicly consumable and they still want to signal the non-backback or backwards compatibility there. There was some ambiguity around normative language so we saw soften some of the language to make the normative bits a little bit clearer. And there was one thing that as we migrated text from Yang module versioning to yang simvert that we talked about in the last meeting, because we were changing some of the scope here and there, some of the text in the Yang module itself, the Yang Simver module itself, got a little long in the tooth it was no longer valid so we sync that with the text that's actually in the draft. It's always a good idea to read and make sure everything matches and is consistent So it's that's just consistency. So these were a lot of really editorial changes around around document for the most part, but we think it adds a lot of clarity and again addresses everything that we've heard thus far so click in window please Thanks. I think this is the last slide. There we are so we want to get this next and hope think this is the last slide. There we are. So we want to get this next and hopefully last working group last call kicked off and then digest the comments that we get back Questions, comments And that was fast Thank you. All right. So before we talk about your next steps, we're going to actually go over to Per out at sort of out of original order"
  },
  {
    "startTime": "00:20:03",
    "text": "So we're going to jump to what's labeled as slide deck alone 11 from Cisco. On the behalf of the modular versioning authors present this work, which Joe did an excellent job in introducing. So this was work that we removed from the drafts that Joe said, and we're bringing it back in a separate draft as an experimental draft and to investigate if it's a good standard to have also would documenting current industry usage because this is used in some places already in proprietary tools the solution excuse me, the solution overview is to follow the current schema with an at and an date but also allow this new schema with this yang semantic version hash sign as a delimiter, and you can see an example This is the ABN for it details The motivation for this work is that Working Group requested DOS to well not dodge this issue but to address it. But why do we want this at all to simplify for? module consumers to be able to at a glance see the module and see how do i need to look at this to form my compatibility issues or not And also to what, since this is"
  },
  {
    "startTime": "00:22:00",
    "text": "actually prevalent in some tools preparatory tools, to standardize it now before several solutions emerged Yeah, so there are no own implementation I did a hackathon in IT 119 hackathon to add the support Pyang as you probably can understand, it's more or less trivial for all tools to add this and then next steps is to then adopt this draft and to finalize the to guide the industry in showing showing finally, yeah, and finally conversion can be. I believe that stuff to guide the industry in showing, yeah, and finally conversion can be. I believe that's the, that's nice. Yeah, so Yeah, so a couple of things. Can you go back one? Maybe not Okay, great. Thank you. Our reading of the document is that this is a spin out of the Sember document. Is that a correct reading? So that was a spin out of a working group document. So to become a working group document, I think if the authors had said, hey, can we make this a working group document, we the chairs would have said, you're taking part of a working document, it's appropriate to make it a working group document. So we don't believe adoption is necessary Okay, we think we should consider it adoption and would like to republish as is. The more substantive question, if we can go back to, I think it's your second or third slide, you've mentioned that you want to go experimental Can you tell us what you why you want to do this and what you think you're going to get out of being experimental versus standards track? So that was what was discussed in the group to show"
  },
  {
    "startTime": "00:24:00",
    "text": "that this can be used because there was some contention changing the Yang file naming as it's said from rc 7950 and then it would update that document and that hits some obstacles. So this is a negotiated extension correct? Is it, it's an extension? it's not used without without it won't cause a compatibility issue because of a negotiated, it's being negotiated as an extension. Is that correct? or? It's up to the server to read the file. Okay Or to tools. So the thing that big issue is to evolve all the tools in the industry So if I, for instance, start to publish with this filing conversion, maybe half the industry can't consume those models with their tooling Right. So that's a big issue, I believe Okay. So I think it's good to hear from the list, but I don't, the last, from the queue, excuse me, but the, um, one thing to keep in mind is an experiment has very specific meaning in current, as currently interpreted, um, in the process, you have to have a defined period that you are conducting an experiment and you want to have specific results. I think by the definition of how experiments are defined today, this does not mean It's not a candidate for an experiment draft. So experimental process is new to me. Yeah, so I think- I tried reading up on it and I thought it fit the bill and that was also what was the discussed in version The group, yeah. So I think the um the document now isn't always so clear the documentation my personal view is, or view as one"
  },
  {
    "startTime": "00:26:00",
    "text": "co-chair, so I haven't asked to get this, but my view would be to take this to propose standard and let last call it and see where the chips fall. But that would be my approach to the document but we have people at queue so let's hear just to clarify so action points now are Action point is wait for the end of the discussion. And then we'll summarize But if before the discussion the experimental isn't the right place Let's have a discussion to see where we end up mahes jay tanandani i had a very similar comment to Lou when I got on the queue same question, why experimental? why not a proposed standard? And they met a point under is also to try to address, I think a comment that Andy made on the list and I'm surprised he's not here in the queue He's not in the queue as yet The whole question of naming of the file and its compatibility with exist Yang 1.1 specification So if you can try to see, we can address that question it'll be nice Do you want to repeat your answer? I think that someone had answered it on lists, or maybe it was from the last meeting so so is it the name of the file or is it another versioning? scheme inside the file? I don't remember maybe it's the final name it is the final name And can you address compatibility? backward compatibility also? Sorry Can you address the, is it backward compatible? Depends on the tooling, right? No, it is backwards compatible because it maintains the existing file naming strategy. That doesn't change. It's full supported right yeah yeah it maintains the old yeah so it doesn't deprecate the app So Rob Wilson, Cisco so um yeah i remember correctly"
  },
  {
    "startTime": "00:28:00",
    "text": "the reason we spun this out was because there was reticence when we're doing last, the record last call of the other documents as to whether this was acceptable or not. And there's some opinions as to whether this is backwards confirmed or not. I can see two views of that The one that's being expressed up there is that we keep in the old format and we're introducing a new one. So no existing tools break. But by introducing this new naming form naming convention, it means that tooling that's using versioning, might start to export files and provide those to clients in this using this name format for the file name, rather using the revision data that they're using before. So at that point is such, there is a minor, you know, that could break tools, it would be a trivial script to fix that and change that. So that's the sort of change. I think that's what drove us to take this this work out into a separate document first and that was the reason why we're trying to do that was because the thought was maybe they should be addressed as part of Yang next My concern is Yang Next could be a very long time away can we discuss this a bit later on and so I guess the experimental flag was trying to I don't know where that came from, but that was trying to say, look, we think, this is what where the industry is going to go, but I'm not sure it's ready to get there yet. I do take your point that experimental has this very strict rules. And also to lose point of wanting to last call and see what happens, I think that's a good idea Thank you connect the question to the chair I mean, you mentioned that the document would be adopted automatically. Does that mean we're going to do last call on all three of them together? and then, yep, can proceed together? Okay I also in favor of the experimental because they have two names, two names in rules can be a source of confusion How can I say the two files which different names? are exactly the same model? So having a"
  },
  {
    "startTime": "00:30:00",
    "text": "an experimental helps understanding which one is the main naming rules rather than which one we are experimenting And about the bill of the experiment can be an experiment because this is a very good naming scheme, maybe for the young next so we can we can we can we can we can experiment is up to the time where we have it adopted as the as the as the naming rule for the new young that's my opinion that maps to coexist in the meanwhile and that and provides the success story at the end do you want to respond yeah yeah so it's recommended to not have the same model with different filenames. So either you use the old at-date schema or the new yeah but you have different repositories different implement That's where you get confused andy bierman and I was the person who suggested that maybe this is should be experimental because the Yang 1.1 RFCs is maybe this should be experimental because the Yang 1.1 RFCs say that this must be the way the file name looks So I'm concerned about putting new standards out there that say forget what that's standard says, now you do it this way. And when as soon as you say, you may do it this way, you're forcing every other tool to must accept that And not ready for that, yang 1.2 tools are done this certain way and there are a lot of complexities with now mixing all these file names together in the search path and, you know, there's issues there, so I thought this would find for the next version of Yang or experimental where it's definitely not overriding anything from Yang 1.1 So Kent is the chair, I am actually unfamiliar with the experimental rules, but is there a way for this document to conform to the experimental rules?"
  },
  {
    "startTime": "00:32:00",
    "text": "I think from a practice standpoint, if we go experiment, we might as well just say, let's abandon this I don't think experimental is really a viable path forward Sorry, can I get the answer? Are we able to make this document conform to? the rules of an experimental? So I think, I have i'm looking to the current and x a to make this document conform to the rules of an experimental? So I think I have to, I'm looking to the current and XADs in the room, but I'd have to go refer my memory also, but it is experimental is supposed to be defined for particular experiment. So we'd have to design what the experiment is and as people that are building tooling and infrastructure, sorry, technology I think it'll be hard for us to say this is an experiment that will be successful or successfully getting information as to do what to do next. I want to go yeah maybe the experiment was already successful last idea Yeah, I think it's right to tips. I think you'll struggle to get this through as an experiment with LARC. I think the IESG wins they are evaluating, say, it's not an experiment You could potentially go informational as another choice, but it don't know. I think it's sort of tricky in a way. I do get Andy's point about existing tooling by tricky in a way. I do get Andy's point about existing tooling, but I don't really know. I think the choice is either we do this and we do it standard track or we wait until Yang next and then he gets defer to then. I think that's the two real choices here. I think anything else is just mudding the waters Yeah, the other thing that occurred to me when looking at the AB and F, and I haven't thought, about it enough to think of whether it's a good or ridiculous idea, is to instead of making the revision date optional, make it required So you would actually have a date plus a version"
  },
  {
    "startTime": "00:34:00",
    "text": "always and yes you would still change the date when you change the version and that would allow you to be backward compatible with tooling but allows you, now you're saying no. As I said, I have thought about this is this happens this is on the fly but i think the tools will still do a reg X match on the name and it still fail on combined one. Or it is end up treating the version as part of the module name string So I think the tool has to change. It's a trivial tweak, but it had to change change Right. So I think the way forward is let's try, change it tweak, but it had to change. Right. So I think the way forward is let's try, change the proposed standard. We'll publish it as a working group document let's go to last call, see what happens Thank you. Thank you And with that, we're going to move to slide number three Shafin person Oh, sorry. I don't have the control Yes, yes, thank you So hello everyone my name is Tufan, and so this presentation is about the system defined configuration update. And the working group last call was initiated on version 4 about the system-defined configuration update. And the working group last call was initiated on version 5, 3 or 4 months ago, which is after IETF And 9. And a lot of excellent comments were received up to then, and we are now at version 8 which tries to incorporate a lot of working group classical comments and the young doctors that's called review comments as well So a lot of changes were made in recent revisions and generally the authors think that all issues should have been resolved now but this might be highly subject to fitness from reviewers"
  },
  {
    "startTime": "00:36:00",
    "text": "So for this presentation, the main focus would be to highlight some working group, let's call issues that we think are worth discussion and as well as our proposals and see if there is any other concerns or objections. So the first one is about what needs to be copied from system into running and is a question for both clients' explicit declaration and servers auto-configuring triggered by results system parameter. So if you have read the previous version of the draft, we used to set that only the parts that are required to make running well need to be copied For example, the list entry with at least the key if it's reference and then the entry with at least the key needs to be copied But the recent discussion reviews that for the uncopy parts, there is concern that Lexi clients are unclear whether they are not set versus not copied So the proposal, the current documents that asks to copy the entire reference system nodes, for example the entire list entry. So this is not only to not confirm the lexic lines, but also to save the energy and efforts for the client or server to calculate the minimum. And assume that the space is not a big deal, we think that it is might be a better choice for the client or server to copy the entire instead of the minimum And then the second issue is about the merging behavior of system and running. And the proposed architecture proposed to a lab system and running system is more with running to create the contents of internalization the"
  },
  {
    "startTime": "00:38:00",
    "text": "question is whether we should specify the mortgage behavior of system and running. And I think it is more specific to the question how ordered by user lists and leave lists are merged. Do the running values go? before or after or if this is a case? where a full replacement is needed? So after thinking about it, we think that this dropped should not define what merge means as this is not really specific to system configuration and to this draft, but this won't affect the behavior of modifying and overriding system configuration. I think this is the case which is more related to change the values of system defined nodes like a leaf, the value of the leaf node So the proposal from the authors would be to leave it on the unsprosified, and examples avoiding implicitly defining merge logic But suppose we do have some examples of system-defined entries and user user provided at least entries being merged together and show the results of intended. But suppose lists when not ordered by user, suffer at examples than leave lists So we think it might be okay if there is some list examples And then the last one I will go through all the working group last call issues and then went through the comments on the Q queue. I will be quick to finish So the last one is about the impact of results system parameter on the candidate of private candidates data store. So we used to have a lot of discussion about the impact on the running data store when it refers to the candidate or private candidate"
  },
  {
    "startTime": "00:40:00",
    "text": "a client may edit the candidate or private candidate data without expecting it to be valid until a commit or validate operation tax place So the draft now states that the resolve system parameter may be used in three cases The client makes an added to the candidate or private candidate and use this parameter to ask the configuration to be valid. This might be possible, though, may not be needed. All the client issues are valid at or commit operations and with this parameter being carried and the current document has augmented the validate and commit operations with the result system parameter And so, more specific for the private candidate document, the draft specified the concept of configuration conflict and the resolution of conflict. So configuration copied by the server met conflict with the conflict of running, but really the resolution is identical to resolution of conflict caused by the configuration explicitly provided by the client so there is not that different difference. And for the next step, the authors would like to request the working group to review the update. We have the fielding that a lot of times, even the general, the basic ideas were reached upon the potentially inappropriate wording due to confusion or misunderstandings. So please help review the update. And even better proposed text And given a lot of changes, the authors are unsure whether this would need another working group last call Okay, I think that's it from my side"
  },
  {
    "startTime": "00:42:00",
    "text": "I see Rob in the queue So maybe you are referring to the margin issue. So a couple of comments. First one is yes I gave you some review comments at the last call. I will go back and check the resolution of those. But yes, in the merge I don't know whether or not this document needs to say what the merged behavior is. I think what is required here is the merge behavior has to be deterministically known. We can't leave it sort of vague way document needs to say what the merged behavior is. I think what is required here is the merger behavior has to be deterministically known. We can't leave it sort of vague where different implementations will choose what a different, choose different merged behaviors. It has to be well specified So it may be that this picks up the behavior from NetConf and it's already well defined or it may need to be defined here but we can't leave any ambiguity So I don't know which way that is, but this needs to it may be that this picks up the behavior from NetConf, and it's already well defined, or it may need to be defined here, but we can't leave any ambiguity. So I don't know which way that is, but this needs some resolution Okay so it was our intent to do a second last call on this document. Just to make it just so we can clean it cleanly close it out okay sounds good to me All right, thank you. We'll move on to the next slide It's Shafan, John. Yes it's me Okay, I'm sorry, just getting a second to bring it up A little bit slow Then I have to. Okay, so this is a presentation about a common young data model for scheduling And I will give a document status since last IETF meeting So during the last IETF meeting week, we had another site meeting with authors of TVR Schedule Young to discuss their process requirements. So the TVR working group is chartered to define that model that address time-based and scheduled"
  },
  {
    "startTime": "00:44:00",
    "text": "changes to a network So the intention of our job really is to be served as a common building block so that they can use and then define their own specific schedule YomTet module. And then this draft is adopted in NetMod Working Group after IETF119. And please feel free to report issues or propose change on our GitHub report And so now we have some drafts that use this Common Schedule Yang in other working groups. We have the schedule OIM tests in the office area working group, which is designed to perform a schedule network diagnosis procedure And then we have the UCL document to enable the scheduled activation of access control policies And then we have the TVR schedule young work to manage the network devices and topology with technology variant attributes. And so since this is designed to be common and generic, the key design rationale would be better modular and ease of reuse So Maharsha in the queue do want to comment on this slide? I think he wants to wait until the end. Okay Or until the next slide Okay. So the major updates since IETF119 are have addressed the working group adopt comments, which I think is mainly from DeRue, we improve the en route text and enrich examples and fixed needs. And we also incorporate comments rest during IETF119 TVR sessions And they have a requirement for a machine-friendly recurrence grouping, which is formatted using the UTC. So with please"
  },
  {
    "startTime": "00:46:00",
    "text": "the definition into UTC and time zones types to accommodate different needs And we also have the parameters naming in improvement. So for the UTC, specific recurrence, we rename the start time of the first recurrence to UTC start instead of that time start And there are some other updates that authors identified to be needed. So we had examples of using Schedule Young module in the context of RFC 84 and 13, which is about the framework for scheduled use of T resources We show how that framework can be used in our can use our scheduling young groupings, and we also add relations to the Disman Schedule MIP defined in RFC 3231 So this slide shows the mapping between Schedule Yonge and the MIP And generally, a majority of the MIP object are supported by the Schedule Yon And some objects that are not supported are shown on the left side of the slide. So for the schedule owner, we currently don't have the owner defined, but if the working group has a preference we may need to add one. And other objects like the context name, this might be I think, should not be included in the common scheduling young definition as we should not clear the using context of scheduling and the schedulerless failure error code could highly depend on is invoked action and also other objects like the storage type and scheduled variable and value, this is the one we think would be"
  },
  {
    "startTime": "00:48:00",
    "text": "SMP specific so current so not supported in Yang Yang And for the next steps, again, we would like to request working group review and also not only in NetMod and also other working groups. So the document update will keep them informed as well And we will also continue to collaborate with authors of our consumer drafts And as we think this draft is stable now, we would like to request young doctors early review after this IETF meeting. And the final object would be to target the working group that's called before the next IETF meeting So as we wish to move forward fast to not block a lot of consumers jobs, that's a general intention okay that's it the chair's requested the Yang doctor review this morning Oh, thank you Mahesh Jeta Nandani Nandani. And this might be just a process question I don't know what happened in the side meeting between TVR and NetMod the authors of this draft um was uh I'm wondering if TVR working group is just chartered to define the Yang model for time time-based or scheduling and what I understand that this draft does is essentially define groupings. Yes that is why the two drafts are not being merged Is there a reason to keep them? separate? Yeah. So the TVR working group is chartered to define the scheduled change of the network attributes So they are specific to the change of network properties"
  },
  {
    "startTime": "00:50:00",
    "text": "But we also have other use cases like the schedule oim test to schedule a network diagnosis action doing some OIM test based on a scheduling. Or we also have other documents in Officerial working Group that is designed to enable the space scheduled activation of SL policy So there are different use cases of scheduling not only the single scheduled netto attributes So that's the reason why we would like to split this out into common grouping and be used as common building blocks And then other use cases can build on top of this groupings groupings Mahesh is walking back to his chair, so I think your response was satisfied him. And we're going to move on to the next Okay Immute for flag not this one. Oh, sorry sorry Okay, so this presentation is going to be quick. And the documents data be quick. And the document status, this draft was discussed as a fabric net model virtual meeting, and the authors would like to show our sign was discussed as a February net model virtual meeting, and the authors would like to show our thanks to a lot of active participants and their great comments and then the document was adopted just before the IETF 1-1-9, and before this IETF meeting we published a new revision to"
  },
  {
    "startTime": "00:52:00",
    "text": "incorporate inputs received as an interim as well as some other issues identified by authors. So this presentation is going to be a report some of the main change since that's IETF meeting So actually, generally a lot of clarifications were met on the immutable flag. We are clear on the following bullying points shown on this slide. So the first is about that servers may suppress a notation if it's inherent from its parent node or uses the default values as the top level nodes but are not precluded from returning the annotations on every single element So currently every each case is allowed without preference to not to add too many restrictions on the server's response. And immutable flag has no bearing on the list or leave list entry ordering and addition of new entries So currently immutable flag is defined as a metadata annotation, which is attached to the individual list or leaf list entries So we think it might not be a good idea to use this annotation to have bearing on the ordering and addition thing. And immutable data can always be copied into or deleted from running as immutable configuration can only be created by the third one be copied into or deleted from running as immutable configuration can only be created by the server and that's present in system. So client can always copy a same value as found in in system and also deleted from running But this just means making a copy of system configuration visible or invisible in running And server must ignore any immutable annotations sent from the client"
  },
  {
    "startTime": "00:54:00",
    "text": "And finally, it's about the immutable ability and value of immutable data must only change where software upgrade hardware resources change, or license change. Because so we are locking in these three cases that allow the immutability to change because generally we don't think it's a good idea that if server can dynamically decide what it considers immune So that's, so we only allow these three cases that in can dynamically decide what it considers immutable. So that's, so we only allow these three cases that the immutability and its value can change And other changes, these are identified by authors We believe these are needed. So we currently update the existing netcon and RESConf specifications as this draft extends the existing protocol operations with an additional input parameter with immutable to add the annotation to be a responded from the server-signed and related sessions are added to clarifying update details and we also add RESCOF support of immutable flag as really is not should not be netconf specific Okay, Mahash in the queue There was a joint coordination meeting between 3GPP and ATF earlier today and this particular draft was cited as an interest from 3GPP they would want to know if and when the draft has reached some level of maturity that a liaison statement be sent"
  },
  {
    "startTime": "00:56:00",
    "text": "from the working group towards 3GPP Are you asking or stating? I'm asking maybe the chairs could once you reach, once you feel that the dog document has reached some level of maturity, that issue lays on statement to 3GPP so we have asked for a liaison statement to be sent to them. So we certainly can issue a liaison immediately that says this work is underway So that is easy. Saying this work is done, I think takes us to at least doing a last call. Yeah, I would say maybe. So if you're saying you want to do it now, we could say, sure, please propose some texts you'd like to see since and then we can get, you know, socialize it and get agreement and we can move forward with that immediately it can't say more than we're working on it. True. I was I was, so that's one option. The other option is wait for last call. And then we can say, this has been it. This has been for public by the working group So which one from an inter-SDO process stands? do you think is more valuable Based on my understanding of what they discussed, they're not particularly interested in providing any comments and feedback to the current document as is They're just interested in the status. So I think what would make sense is that you when you do reach last call consensus that would be a good time to let them Charles? Yeah, hi. Yeah, so kind of on the same subject. The reason this came by in the coordination call was that"
  },
  {
    "startTime": "00:58:00",
    "text": "the LS was received back in March of 2023, I believe And so if this you know, the one option is, I think, as a result already covered, once we think this work is essentially done, or even that it, we could even wait till it has published as an RFC, then then let VDP know but the thought was that um you know, 3GP provided some requirements and uh if we're sure that we're a addressing their requirements with this draft, that as it as currently exists, well, then great, maybe this is and if we're sure that we're addressing their requirements with this draft, as it currently exists, well, then great, maybe this isn't needed. But the thought was, well it might be good in parallel with us, perhaps going to working group last call to say, this is what the work group is thinking. And we want to run it by you and let us know hey this is really meeting your use case and your needs before it gets public as an RFC So that's an interesting approach Typically, you know, Typically, we have not taken requirements and lia liaisons or taken specific action on liaisons in the working groups I've participated in. We would expect that contributions would be made in inside our process that say whether or not the requirement is being addressed or to bring in mechanism to address those requirements I don't know, I mean, this is really an IAB question of whether or not we want to send out a liaison saying please tell us with your met with your requirements. That's, you know, that's definitely different than any group I've operated in Again, I don't know if Mahesh or XAD Rob wants to say anything, but to me this seems a little different than our normal process Mahesh is coming to the mic"
  },
  {
    "startTime": "01:00:00",
    "text": "You can take the short one if you want I would agree that I think this is rather undefined but based on our processes, if they need to provide comments to the draft itself, they should do it now rather than wait My understanding in Charles you're probably closer to this, so you know better If they're looking for looking to provide comments, let them come to ITA or provide the comments on the mailing list my idea was that we would give them and send them a liaison giving them a status update when the draft is mature I would say if we're really looking to have their input, we should send it now and say, that if they would like to provide input, please do so through standard IE contributions and participation I agree Yeah, and that would meet Michael too Yeah, I was going to agree So I was like, well, an idea. I had a similar example with something that went to ICAF and think, where we wanted them to comment on what we were doing, and effectively for that one, when we reached IETF last call we had a liaison ready to go to send to them saying the IETF last call was started it's going to end on this date and you need to provide comments using the normal IETF mechanism Here's the point to the main list. I mean, you could do it to the working group last call But I think for that, the key was to get, they need to be provide the comments into the IETF process in the same way as everything else any other the other participant and all you're doing is advertising them to say, this is happening now so, so come along. Okay Is anyone interested in drafting a liaison statement?"
  },
  {
    "startTime": "01:02:00",
    "text": "for review on the list looking for a volunteer to help? No, I'm not volunteering for there But whereas I thought the subtlety was Rob saying, do it when we should the working group last call. You're saying, do it now send a... He said we had a liaison ready to go. Oh, okay. So whether we decide to do it now or when we last call we need that liaison text ready to go So I would expect that when we draft that liaison text, we make the decision at that time whether we send it immediately or wait for working group last call I don't think we need... Either way, we need the text text So Rob, are you volunteering? So Rob is definitely going to volunteer so appreciate it. Thank you, Rob, and we'll work off are you volunteering? So Rob is definitely going to volunteer, so appreciate it. Thank you, Rob, and we'll work offline with you All right, thank you. Absolutely capture that in the minute I'm sorry, I cut you off. Go ahead It was the same, thank you, Shafan, we're moving on. Okay, okay just want to say the authors might have as well. Okay you Thank you So hello, I'm Jean. So I'm going to present the updates on the young full update full embed or fully include oh thank you very much. So, oh, sorry Great. So yeah, just to recall the goal of this is to reuse the the modules that have been defined at the device level for instance the IETF interface to reuse it at the network level so basically put it in a list with device ID and if you want to do that in the end today it's very difficult So basically, you can do copy pasting. You can do"
  },
  {
    "startTime": "01:04:00",
    "text": "you can rewrite the modules so that they have a grouping that you can reuse or you can use the schema mount So this is basically the goal of this of this draft and just to say the use case that was triggered is the data manifest where we want to read the we want to reuse the young push information to have it pair device in the in the data manifest So this is basically filling the game that was in the young scheme Schimamund. So they said, in this draft they covered only the implementation time and runtime So in this draft we want to cover the design time So other the implementation time and runtime, so in this draft we want to cover the design time. Otherwise, it should be the same semantics except that it's not the same time, but the same kind of behavior that we want and so this is the this is the example so it's a little bit garbled here, but basically the idea is that if you want to reuse the model, first you need to import it. So here we import IETF interfaces and IETF IP IP being the augmentation of the IETF interfaces And then we have this any data node that is the same as our moonpoint let say in the schema mount and inside we will say the list of modules that we want to import and that would be it to define a module that includes other modules basically So for the semantic of what I happens within contents is the same as"
  },
  {
    "startTime": "01:06:00",
    "text": "what is already defined in the schema mount basically, if you have a RFF, you cannot escape the moon point So the updates on this rafts were basically, that we need some kind of play to store the information about what is supported in the embedding point So basically a way to do that would be to add some include in the Young Library and to say for this data store and this path to the embedding so here the embedding path would be the absolute path to the any data node that contains the included module we want to say this is the schema that is available here. And with this schema we can specify the feature the deviations and so on But the main idea is that we only need that for the implementation at design time we don't have any implementation so we basically just need the young modules that we want to have in the moonpoint There is another part about the recursive embedding, so there is a risk when you do that, that you include modules and you have a kind of a set of modules that can repeat themselves and actually in the draft we forbid a module to include itself And then since you need to import other modules, there is a kind of argument that this rule is enough to prevent this kind of infinite recursion. So you cannot create with the basic young rules plus the rule that you cannot embed a module inside himself. You cannot create a fully recursion schema. At some point, it will stop"
  },
  {
    "startTime": "01:08:00",
    "text": "And so I think that's it So last time, I had some feedback from 3GPP and BBL that they needed this kind of module. So I would like to have a little bit of details about these use cases to make sure that it fits and that that that would be great there is a question whether this can be done like right now or whether we should wait for your next. So I have at least one draft that is the depending on this So there is another question about the parent node mechanism so whether we need to copy that from Schimamount Schimamund And there is also the possibility to do some finer image so instead of importing the whole module starts importing only parts of the module I think that's a nice idea I would like to wait for the for the implement of the first part to be done before going into the second part. And of course, we need to do the implementation, so I would like to start myself a little Titan time But if anybody is interested in working on this kind of implementation do not hesitate to contact me and yeah and also maybe if the interest about the free from free GPP and BBF is still there maybe we could consider adopting this document so i see rob yeah yeah you have an ice document. So I see Rob. Yeah, you have an ICQ. So thank you"
  },
  {
    "startTime": "01:10:00",
    "text": "for this work I think it's interesting I'm concerned on a few different things, there are a few points. So I think the first one is this feels like it's quite a major change of the Yang land think it's interesting. I'm concerned on a few different things, a few points. So I think the first one is this feels like it's quite a major change of the Yang language to do this. And I'm concerned about doing this now as an extension as opposed to going to the next version of Yang. Ideally, that's where I would like to see if we're to do this. I think I have concerns more generally as to whether we're making the Yang language more complex and whether this complexity is worth it I do see use cases where this is a useful thing to do The other thing I want to say is when we were doing the yang packages work, when that sort of got put on holders of trying to finish the other drafts, we were looking at a somewhat similar problem here of specifying scheme amounts within the Yang package definition. And it's not quite the same as exactly putting in the module itself but it is sort of quite close to potentially being designed time because those packages can be used offline and in particular, I think that one of the complexities here that is being lost over is those modules that you're sort of including or embedding in that particular points is if they have augmentations and deviations and maybe different features being enabled that sort of being glossed over here, whereas I think some complexities there And if you had a yang packages solution it might be you could define a package for that sub tree which fully was resolves to a schema and then you embed the package at that point, and hence it sort of then resolves those issues um so that might be something that's worth looking at. And the last comment is, I think, this is like using a subtree of the scheme again I think is something that's probably a good idea so in the, like the Yang push case, that's, I think something case where that would be helpful so so it's interesting work I'm not sure this helped you Okay, yeah, yeah. So I can answer on the augmentation and deviation part uh yeah basically"
  },
  {
    "startTime": "01:12:00",
    "text": "you would need to list the augmenting module as well so for instance for the IETF IP, that augments the IETF interfaces, you need to list both in the mounting point if you want to have both So package would be a simplification And in the case of like feature statements and you uh, would you be allowed to have different augmentations and deviations for it mounted below as to where that module turns? up elsewhere? So that's the bit, yeah, yeah, so busy basically you have your young context, which is never different anywhere. It's just a set of modules that are at the root So it would be your root young library if you want and then for each module that has embedding, you include the modules that you need you can you can even use a different revision than the one in the route. It's allowed by it young and you would have these modules then in the mountain point. So you have a different completely different young library for the embedded part but that's only for the, that's only for the runtime, for the for the design time it just you have this set this exact set of modules that you are specifying is the one you would have your mounting point okay okay how well away, I think it's quite useful and I think for your use case, I think not having the final granularity is great, but I can see some use cases there having the subtree is really beneficial For our hackathon, we are looking at what to do. We are copying paste but it's not so simple mapping that you can just use the module. So I think having the parts is really Okay, thank you. Thanks Osharo Deepak. Oh, sorry. Deepak. Yeah Oh, hi Interesting presentation. I just wanted to highlight"
  },
  {
    "startTime": "01:14:00",
    "text": "that the use cases are to highlight that the use cases that would be required by BBF would be covered as part of the upcoming presentation One more question was in the previous session in IETF119, there was a question about having more granularity in embedding certain modules, right, instead of using print about having more granularity in embedding certain modules, instead of using prefixes, is that still being pursued? Also, is it just part of the module or can be customize that? Meaning can we can we refine certain data nodes yes so I think it's yeah it's still considered and Olga just asked for it again so i think it's definitely a nice to have feature and I would still first do the implementation with the whole module because it would be simpler. And then when that works, try to see if we can go into the finer granularity but definitely I see that it's needed as well including the customization of i mean allowing refinement of certain notes or is it just sub sub or sub-nodes? Yeah I think we maybe we should separate the features at some point, but yeah I can see use for that as well yeah. Okay Okay you. Rishad, Equinex So plus one to what Rob said, very useful worried about having that in the current Yang. Yang next intuitively seems to be the right spot You mentioned augments have to be specified explicitly. What about deviations? Would that be automatic or? i i would say the same uh deviation have to be included. No, usually when you have a deviation"
  },
  {
    "startTime": "01:16:00",
    "text": "it's not on the official module So maybe deviation would show up only in the young library part at runtime But otherwise, you could technically put a deviation in your list set of modules, but that's a little bit weird because you're designing something with a deviation in it and that's a little bit counterintuitive, I think. Yeah, I just found it odd that you would have the deviation automa, I mean, automatic in the normal path but in your ambit path Anyway, it's a minor issue we can discuss offline if needed thank you so before you go i'd like to go back to a comment that Rob said, is that it may be possible to solve the using the same mechanisms that are being defined for Yang packages. So Yang packages is work that's been taken by the group and has broader utility. So if there's any way to leverage that and combine the solutions so that we have one set of mechanisms that we can use for two applications, that would, I it's my opinion and I think Kent doesn't object it's a chair it would be the interest of the group to combine those. So I'd like to ask that the before you present this again, and before you next meeting, to work offline with the authors of packages and see whether or not you can solve it using that same mechanism or a slot modification of it Packages has been on the shelf, we're hoping it'll take it off the shelf Now that we're getting lost caliber versioning, you would really help the group if you could help move that base mechanism forward and also perhaps solve your problem as well Okay, yeah, I look into it, yeah. Thank you so much Did you walk away with the flicker? Yeah. It went behind the screen"
  },
  {
    "startTime": "01:18:03",
    "text": "Okay, this is Oscar Gonzalez from Telefonica So now I'm going to present an approach and a solution for a use case which is related to the previous one is not the same thing that what we are aiming to do here Goop ahead. Now it should work So here, I guess you are familiar with the device models and network models In IETF, there is a huge amount of work in defining models targeted at the device so they model part of that configuration of the device. On the other hand, what we have, the current trend is to have a lot the device. So they model part of that configuration of the device. On the other hand, the current trend is to have network management systems, or now all the CDM control that are the entry points to the devices, so they offer the capability of the network towards other layers. So typically we are exposing network services. Sometimes they are, for example, the VPN layer to VPNs but there are some cases where the service is one part of the device configuration, so it's equal, it's the same, it's the same but there are some cases where the service is one part of the device configuration. So it's equal, it's the same thing. So for example, an access control list okay, an access control list is something that you can manage and you can precise in one single network element so then in that case okay, the model, the ICA, model that was saying that device is perfectly usable for that for also routing policy is something also that you can manage. So there are few cases, okay? does not apply for everything in the device, but there are few cases where it is very useful to use this device model. So we can use this slide. Ah, I can"
  },
  {
    "startTime": "01:20:00",
    "text": "use this slide So the use cases that we are targeting is used this device configuration as a service or device model, okay, two manage it through the SDM controller okay, I have this ACL put it in this device or in multiple devices and also the use case of protocol profile. So what we have observed is many times these entities are the same across multiple devices for example the access control list for the security of the box In Telefonica, they are similar network devices have the same set of ACS. And then they even have some particular ones, but we have some of them that are very common. So, okay, you define them in the control? and then you apply them to all the group of devices at the same time so it's very useful so both use cases we can apply to either one or two multiple network elements at the end the group devices at the same time so it's very useful so both use cases we can apply to either one or to multiple network elements at the same time okay so what is the approach We try to have a very light to multiple network elements at the same time. So what is the approach? We try to have a very lightweight approach. So here, first of the the approach? We try to have a very lightweight approach. So here, first of all, is import the device model. How? Okay, this is something that we need to decide which is the best way because one we can solve this by augmentation, we could solve this by other by other means but this idea is to add to your device module a deployment container you say, hey, I have my deployment container and it tells you okay, which are the network elements in which you target to deploy that particular piece of that particular service of this of configuration and areas. For example, the thing is the name that you have in your controller and one different thing could be the name that you have in the device. So we allow that"
  },
  {
    "startTime": "01:22:00",
    "text": "So you want to have it different it's possible You have a way to identify the network element or you can look have a list of groups of network elements okay so you can as an network operator, decide, okay, these are all the same devices doing the same function, okay, and then I want to once I apply, or I update my ACL, go to all of them. Once I apply, this updated routing policy, go to all of them set of devices. So here same thing is just this group of network elements What we, it will have the list of network elements and an email So here, this group, you know, network elements is just a we define this document, this group that provides this list of an error, this list of network elements so it's very very easy so if it's facilitates the network analysis All these things also are, let's say, solved to the in many different implementations in different ways so here the reason to come also to IETF here is to see, hey, can we solve this? And can we agree on a common structure between us and to have a common solution? between us? Because I think the use case is quite a lot of times in the network operation. So here one of the open questions that we have also is, okay, as we need to define this, network element ID, is if we can also align with the inventory, because we were working okay network element ID that we are using here. So here, let's try to harmonize also, as we are in IETF, let's try to harmonize the common way to refer in this one one possibility is to okay, as I is the finding and the element ID, okay, to point to the invention"
  },
  {
    "startTime": "01:24:00",
    "text": "or just leave it free and keep it for every operation I would prefer a common approach across the industry so we can have it similar approach So here, the next step, so here is just to understand it. First, if this use case is also common to other people okay to other operators so here, all the feedback is appreciated because here, I mean, for us in telephone, it is a very common use common use case. It's not for all the configuration of the database, it's for useful so it's the work interesting to be carried out here network network. The boat seems to be the right place, but I confirm, so here the also, we want to collect his feedback, refine the draft things and also look at this, for example, the full embedding want to collect this fishback, refine the draft things, and also look at this, for example, the full and bed jam that you presented also to see if it's applicable for this use case I think it's complementary. I think the use case might be slightly different Here, it's not neural elements centric is the model cent to be ACL centric and not device centric and the receive feedback from you and to see specialist if you see if you other people also see for us, it's something that we need in the Okay, so move with the queue and tell us. One question, and I'll see that us. One question, Oscar, have you thought about the how to manage a potential? conflicts between the configuration? done through the network model and the configuration down to the device? model? Because now these two configurations are coexisted on the same interface, and you may configure two things which are incompatible to each other which one wins no i i"
  },
  {
    "startTime": "01:26:00",
    "text": "don't i don't care how the is the controller who will be responsible to configure in the device so even the device even might not be implementing any any device model, it might implement the same, it's the controller who needs to take care of senesop here I'm not exposing the model that is in the device outside no are you exposing a device model i am exposed a device model i am just take care of Senesok here. I'm not exposing the model that is in the device outside, no. Are you exposing a device model? I am just, I'm using that this is a device model, okay, I use it here and then the control is responsible to top to the device, and if he needs to configure BESB V.S.E.L. B S&MP. No, yeah use it here, and then the controller is responsible to talk to the device, and if he needs to configure BSI, B as an MP. I understand, but what happens if the configuration that you request on the device is incompatible with a configuration? that you request on the network? It would say it Which, oh, okay, so you reject both configurations at the same time. You will reject I mean, you try, it's like, it's your intent, it's like in any model. I pointed, I have two intent and... No, you will have one intent. You don't, you will not have two intents okay you are managing through the controller that is your configuration will be entered, but it is one intent. There will be no other intent and if something changes in the in the device it will let's say let you change that in the device later by other means, okay, it will be out of sync fail of course But that's common to any any network device model that question no your point is that here you are on the same interface you have two ways to configure the same thing And you can have a conflict. For example, let me an example you can create a tunnel at a network level and say this is my part the tunnel is implementing a statelessp and then you go to the device and you create you change the the path of the LSP, which is the part of the LSP, the one calculated on the tunnel or the one that you put on the device can we take this comment on to the list please Thank you. Yeah, we're running out of time Alex yes no yeah"
  },
  {
    "startTime": "01:28:00",
    "text": "put on the device? Can we take this comment on to the list, please? Thank you. Yeah, we're running out of time, Alex. Yes, hello. Yeah, you mentioned basically alignment with network input or and I agree. And actually, one thing that is not quite clear to me from your presentation is, why is this not part of network inventory? Isn't it already covered there? Can you explain that? This is not taking for network inventory So why not? I mean, it seems basically the use case is very related right? You want to group the devices which are in your network. This is pretty much what network inventory does no? Well, that could be part of the inventory. I don't care if the group of network elements would be part of the inventory. The main point of the draft is to be able to configure something in a set of group of device and this something is today defining a device model. That's the main point of the draft. So it's not an inventory thing could be the list of the group of devices That could be part of an inventory that's okay all right I I'll reread it. It seems to me if you're talking about a operating on a set of devices, that would be a slightly different from what I'm saw from that. Anyway, just back feedback. Thanks. Thank you. Yeah, so Joe Euro, and we have two more comments to try to wrap up in the next minute. It's clear that the you. Yeah, so Joe, Euro, and we have two more comments to try to wrap up in the next minute. It's clear that there's a good opportunity for discussion on the list on the draft no matter where we end up Yeah, I might take this, joe clarke, I may take this to the list because I didn't really get your use case. And when you're talking to Atalo, I think I understand You have a controller and there's a group of devices that all implement ACS and they all should get the same ACL how that's configured southbound doesn't matter I wonder if that's the case and I'll follow up on the list. I wonder why you even need this. Just let the controller fit that's configured southbound doesn't matter. I wonder if that's the case, and I'll follow up on the list, I wonder why you even need this. Just let the controller figure out what the device supports and say configure ACL this way. No, no, yeah, right, but what I am just saying is that you don't have in the controller, you need some"
  },
  {
    "startTime": "01:30:00",
    "text": "structure to indicate the ACL where should it go, so this is just that in the northbound of the control you expose the ACL Young model, which is already defined, and you add this young, this deployment structure next to it to say, hey, deploy it here, there or there It's the purpose. I think there's a role. I'll follow up on this Okay, no, we can discuss out of line I'll just mention this, but maybe we'll have a chat afterwards I'm just wondering, is it just any idea? up on the list. Okay, no, we can discuss out of line. I'll just mention this, but maybe we'll have a chat afterwards. I'm just wondering, is it just any ID or are there any other keys and mismatch between the keys? Northbound and Southbound, and how to address that problem? as I mentioned Southbound I don't care in this it's just design, yeah, but the design time still there are kind of different ideas and keys so you don't need it. Okay Yeah, I think it'd be great to continue this discussion on list. This clearly I don't know if there's interest but there's at least confusion So making it clearer on the list and getting the question would be great thank you and now off to Ken for probably another good discussion. Thank you So this is ROC 7950 biz and friends, which means related drafts Of course, you are already my friends Sorry Yang's been very successful RFC 7950 was published almost a decade ago in 2015. Sorry, 16, my glasses are aligned here. The Yang next issue track has captured and cataloged 105 issues in eight years so far. It's time to start, Yang Next The current focus of this work is to factor out the obvious part that should not be present in 795 including the sections that are entitled to Ex-Mone coding rules and the sections entitled NetConf Operations sections"
  },
  {
    "startTime": "01:32:00",
    "text": "Also, to rewrite other two other parts to not be XMO only including the sections noted as usage examples, and the current strategy is to simply add matching JSON examples to match along with the current XML examples So what does it mean to factor? out the obvious parts? So first off, of course, there's the draft itself, draft RFC 795BIS, and then there's the factoring out of the XML encoding, which would go to another draft called Yang XML. That name is picked at the it was the same name that Lauda chose when he created RFC 7951, which is the JSON encoding rules for X, Yang model data. And then also a document called Yang Protocol Requirements, or Yang Proto But that has some concerns and we'll be talking about those in a moment All right, first dragon So the goal is to factor out the NECOP operations section that should not be present in the draft. The observation is that this should lead to an RFC's 6241 biz, right? And that work should be done in NEComph working group, not at MOT. And yet, there should also exist a document that defines generic requirements for all protocols, NetConf, RestConf, CoreConf For example, it must like such a doc document might say, list pagination has to be supported private Canada has to be supported. It'd be a way of consolidation the last decades of effort into a new protocol definition document Hence the idea of a Yang protocol requirements document. Does this make sense? The current status is that the Yang XML document is done I did start with Yel Laude's table"
  },
  {
    "startTime": "01:34:00",
    "text": "of contents and convert reported all the text from 7950 into it and it's probably ready for adoption The Gang Protocol Requirements document, I didn't start because it got complex and of course the actual document itself, 790 Biz, is a working progress some details about 7905 biz what was the work that was done so far? First, I asked the RFC editor for the XML source. Then I add a make file and cleared all the errors and warnings reformatted it using tidy, rewrote the front map matter, added production note to be removed by the editor, added a special thanks section rewrote the introduction section, removed all the netcom confusage sections, and removed all the exome coding sections. There are some links You can link to the GitHub commit history, and see exactly that history there, as well as a link to the diff of the current document against RFC 790. Sorry, I mean, 790 Okay, so the other dragon It's not actually my goal to publish a gang 1.1 or to republish it but that is what the current work is about. It just simply, uh, reproduces the existing, which is why it's called Abyss. But my actual goal is to publish Yangt 2.0, a non-batholic compatible version of Yang, which would not obsolete 795, just like how 70950 did not obsolete 60 60-20. To this end, among suitable ID name might be Gang 2. The only reason this wasn't done now was to start the conversation Also, technically speaking, the current focus doesn't change ARPS 790"
  },
  {
    "startTime": "01:36:00",
    "text": "So what is the conversation? How to proceed? First, there might be the question should we proceed? Respect if there's no intention to proceed, I feel like not much to shut down. We would have complete our charter Next, with the assumption that this is a recently knowing that this is a reasonably large project, how to distribute the work, how to distribute the load to avoid burnout, how to best utilize scarce resource how to incentivize involvement When would it make sense to adopt? Wait until the document is ready, which might be a while or nowish. So the working group can start revealing right away Should this be a done through a design team or as a GitHub project? If we use a design team, this scope would be set up front, members would be known up front and I think we all know how this plays out, right? So currently the versioning design team is working in the versioning work. If it were a GitHub project, the scope would be driven by individual interest. Members would be whomever submit poll requests How this plays out is not well understood in the IETF. So just a couple more thoughts about how it might play out. The idea would be used GitHub workflows to automate adequate internal reviews amongst the authors or the contributors, followed by the editor bringing the result of each full request to the work group before merging it to me Another idea is that the a dozen each full request to the work group before merging it to me. Another idea is that a designated set of experts would do the reviews thus reducing their load And that's the end of the piece presentation. Questions?"
  },
  {
    "startTime": "01:38:00",
    "text": "comments, concerns Sorry, not in the queue jeffrey haas. For your design team question, I think maybe a sort of a middle model is the working group and or design team driven by the working group is there to basically say this is the work here's the space that we're going to go in and you effectively are delegating out implementations of the agreed upon pieces of the work to whoever is willing to contribute Mahesh J. Tanandani you clearly indicated your interest was more in Yang 2.0 but I think at least some part of the work seemed to belong to something Yang 1.2, if I want to call it where you just stripping out the draft of all the XML examples And I didn't come across, I thought I would just highlight that maybe there is the sub-task that could also be identified. That's one comment The other comment was I love GitHub. I love the process Yes, it hasn't been tried before, but maybe this is as good a time to try to see that works for this working group It actually was tried in a couple working groups before, I think quick in particular used it, so it wouldn't be a first for the IT to see that works for this working group. It actually was tried in a couple of working groups before, I think Quick in particular used it. So it wouldn't be a first for the IETF. It's just not, we've never tried it before okay good to know that and uh positive negative feedback from Quick. I think it was positive Rob raising his hand I think he has a response to that is yeah one minor comment on your 1.2 for cleaning up a document, you don't need to change the revision number And that's commonly done as you're going towards full standard is you would go back and clean uh clean the document make editorial changes but not make any"
  },
  {
    "startTime": "01:40:00",
    "text": "uh on the wire protocol changes and I think there's room for that. There's also maybe room for one the document, make editorial changes, but not make any on-the-wire protocol changes. And I think there's room for that. There's also maybe room for 1.2. So it's just your example was not one that required a 1.2 you're right so just to comment on the GitHub process for quick. So that document when it hit the IST I think, was one of those polished drafts I've ever written because they had a large number of people collaborating and the ability to put in small changes very easily and get them reviewed meant that the quality of the document was very high So it might be because there's lots of other people, but I think from the output of the document, from using that process, it went very well I can't speak to us to the sort of engagement of the community in that process and whether that was everyone was happy with that For my comments, I first of all I want to say thank you for starting this work, Kent, because actually it's a lot of efforts, a lot of work. Some of it's not the most glamorous thing to get stuff going, but I actually think it's important that we a try and sort of sort of sort of sort of sort of document documentation set and get to the point where Yang has a stable base that we can extend and do new revisions and sort of cleanups on the technical debt we have and lose some of the baggage. So I definitely think the step of trying to at least publish a new version of Yang 1 do new revisions and sort of cleanups on the technical debt we have and lose some of the baggage. So I definitely think the step of trying to at least publish a new version of Yang 1.1 is a notable goal in itself I think that's a good thing to do Lou made a comment, which I also agreed to, is it might be that we want to do a yang 1.2 and a Yang 2 together. And actually, I can imagine that some parts of the industry don't want to go to a yang 2.0 but there are smaller enhancements that they would like to pick up pick up and put into yang and publish a Yang 1 or 2. It's different from a massive step change to a much bigger language The last comment I have here is in terms of it feels to me like we need to have more discussion as to what the scope of what these two versions, if those two versions, would look like. So there needs to be more discussion. We had a list of features and issues and things to try and actually work out a top level which ones"
  },
  {
    "startTime": "01:42:00",
    "text": "could go into one of those and what the new language would look like because that might sort of people say, no, this is too big or this is too complex it's too far away or or so you're having some sort of vision as to where we're heading might be helpful, both for either Yang 1.2 or Yang 2.0 Okay, so for 1.2, I don't know because that's, I hadn't thought about that but I think that's the middle path and and uh Yang2.0. Okay so for for 1.2 I don't know because that's a I hadn't thought about that but I think that's the middle path and sort of compliments what Jeff thought of as well For 2.0, again, my thinking is that it would be driven by individual interest like who has the energy if this were a group of all in volunteers, who is willing to volunteer to you know, write up a poll request and submit it and see it? through is those who are having that energy to do that would do that effort. When all the volunteers have put down their pens because they no longer have energy or interest in any of the remaining next issues on the issue tracker then at least as far as a volunteer perspective, we'd be done We could bring it to the working group, but I mean, of course, each full request would be brought to the working group, but we would bring it to the working group that the work is completed at least from a volunteer perspective, and see if it's a adequate So if it were the case that 25% of the Yang next issue tractor issues didn't resolve then the working group might say, we want 10% more done that might issue tractor issues didn't resolve, then the working group might say, we want 10% more done, that they might select specific issues. But then the question would be who's volunteering to do the work? So it feels to me like those are like design level changes and what I'm wondering or think we might need is like an architect agreement as to what yang 2.0 is trying to achieve. So what is, what its goal of where it's meant to go to? Is it just a set of enhancements or is it trying to say, I want to open? up new markets or address problems that Yang currently does? address and having that sort of definition"
  },
  {
    "startTime": "01:44:00",
    "text": "statement of where we're aiming for to then build a value and say, yes, this should go in and this shouldn't because otherwise I fear that if anyone could bring things to the language it could go in all sorts of directions and lose its cohesion and consistency and again a lot of complexity at the same time Okay, I think that's a good comment. Certainly, you know, if we were to move forward with this effort, we can make an attempt to put together a paragraph that described what we've thought was the vision for the overall effort, the motivation for it. Okay, thank you Rashad, so the first question is I'm assuming the yang versioning stuff would be part of Yang next Yes. So does that mean we would need to wait until? No, I don't wait, wait, that you say that again and make sure you're hearing the question Say your question again, I think he answered a different question than you asked. Okay, my name is Rashad, no. No, no, no no, sorry, you say the question again. Would the Yang versioning, would be part of Yang next effort? That was the question I heard before and why I said yes. On the slide I mentioned, it would be an attempt to consolidate Remember that Yang protocol requirements document? I mentioned? The idea is that we would put together a document that specified requirements for NECOPF next ErestConf next, CoreConf next. Okay it would include the version of work. An important process point. He's not saying we stop the documents that we said we're about to last call earlier. Okay. It would roll that work into, you know, that would work. An important process point. He's not saying we stopped the documents that we said we're about to last call earlier. It would roll that work into, that work would be rolled forward as well. It's not an alternative thank you okay and the That's the part that I wanted to clarify question on this is, this seems to be either or, but you know, if we look at the version and design team, we started with the design team. I mean, can you go back to that slide, please? We started on the last and then I mean I know I mean we use GitHub"
  },
  {
    "startTime": "01:46:00",
    "text": "and then people who are not part of the design team join There was Jan, Per, Italo, depending on various i mean so to me i don't feel get the point of why is it one? versus the other one as opposed to a combination of of the two but you know I think, I mean, perhaps, I mean, certainly the time team could use GitHub and and pull requests and workflows and what I think the difference is perhaps the computer versus the bazaar are we going to architect and you know, everything up front and try to figure it out, and then go down requirements in a waterfall fashion? or is it going to be a very agile effort where we don't actually know where we're going to end up until you know we get started and people start using the energy to submit full requests? OK Okay. Thank you thomas graf. Thanks for this great work. I think this is really a good preparation work and especially also that you have dividing the XML and the definition of Yang into two separate documents. I want to follow up on the comment from Rob and I think it's a good idea or a good proposal, one or two having like small changes and 2 to follow up on the comment from Rob and I think it's a good idea or a good proposal, one or two having like small changes and 2.0 more the bigger changes and one questions on the third documents the requirement where would be the requirements? coming from and is they somewhat related to the IAB workshop? Oh, great question So, well, first off, we might need to talk about which working group does that belong? Yang is not the protocol working group it should be NEP CONF working group that would take that work on to define a protocol requirements document Would they involve IAB or? to what extent, I don't know? But that's a great comment and perhaps they would have a thought about that Good, thanks. No, okay"
  },
  {
    "startTime": "01:48:00",
    "text": "Jeff has again It's partially a response to what Rob sort of raised has there been a triage effort to go through the list and say, here are rough buckets things that? are in? Yes. Okay. I didn't see that like the GitHub tags. It was about six years ago, I think There were side meetings at an IETF or forget which one But we did, and you can go to the GitHub and look for, I think it's called a project. And they're actually very nicely labeled and please take a look at that We didn't get through them all, though. We only, after even, I think a whole four or five hours with 20 people in the room, we only got through about 60% of issues that's great common and if that sort of effort has been done don't take a look at the existing stuff there Part of the architecture, you know, front loading of the project, if you can come up with common look at the existing stuff there. Part of the architecture, you know, front loading of the project, if you can come up with, like, common rules of what a given piece needs. So this is example, I care about data types. If I want to add a data type, what do I need to include? You know, it's like what does the data type do? How it behaves? What are the representation impacts? known like if it's rendered in XML, JSON, etc. If we have sort of the work list for a given type of thing, if it deeply falls into that, that's another way to ease the workflow andy bierman Charner couldn't join the queue. I don't know why my app isn't working right. Actually, I don't see a lot of end user value in re- republishing Yangua.1. I haven't heard any interest in customers or any problems reading RFC 7950. In fact, I've heard it's wax actually one of the best documents the network management has ever produced. I would like to see some energy going to fix to finishing the gang next list. We couldn't even get a design team going there was going to be a design team and then it never happened. There was people willing to go through the list of 105 issues And if we can't even get any consensus on what"
  },
  {
    "startTime": "01:50:00",
    "text": "new features were adding, then we shouldn't even bother. But I don't think a new version of Yang that's just a rehab of the current documents serves anyone except the IETF. It doesn't serve the community at large, in my opinion A new version of Yang with consensus for new features, that's something else, whether it's 1.2 or 2.0, I don't know You have to go through the list and see where the consensus is. And I don't really like the idea of changing the working group consensus project to a open source pull request model I'd rather see things worked out by the working group and added because there's consensus along the way But, you know, so I'm fully support going through the Yang next list There's not a lot there that I think is that interesting but, you know, there's maybe not, maybe there's 30 things or something. I don't know There hasn't even been enough energy to go through that list And so that's really a concern of mine Right, so I was the I I guess volunteered myself to be the, instigator or the promoter of the whole Yang Next effort. I created the Yang Next GitHub repo long ago to start tracking the catalog I was the one that organized that design on side meeting session to do what categorization would create I lost energy. And I also didn't, you know, I just volunteer work It's literally my free time. I choose to spend on it About five years ago, I raised the issue again I forget which meeting I was, but there was pushback and concerned that any change would disrupt the industry at large and would be very detrimental to Yang"
  },
  {
    "startTime": "01:52:00",
    "text": "being published But now I think with all the issues that we're currently facing Yang versioning, it's a great time to revisit that I have the energy now to do this and so why I'm bringing it to work through Go ahead Mahesh, I came up just because Kent, you prompted me to for a comment and I was trying to get the context of the statement I I think it's people are missing this list of issues that Annie just referred to and you have very well tagged under the project. So maybe at reference to the GitHub location where these list of 100 plus issues that have been documented would be helped to the, if I'm surprised that people haven't been able to see that and instead of going through a formal process of trying to collect any more requirements I think we have a fairly decent set of requirements already in place I don't know if we need any another work or get together to really get any more requirements So sorry. Agreed that we have a good list and there's probably no need to create more to it but I guess that's the distinction of no that we have a good list and there's probably no need to create more to it. But I guess that's the distinction of the two approaches with the other approach, we don't even have to complete the list. It's just yes it's there. And if people want to submit a full request for it, I know that's in the list, whether I'm being categorized or you know. The whole intent back then was to categorize things specifically on three axes, backwards compatible complexity, and importance But if you go to the bizarre it's actually doesn't matter it's actually up to the individual and what they want to self-priority So if, you know, whether or not"
  },
  {
    "startTime": "01:54:00",
    "text": "we actually complete the categorization would be probably dependent on the choice. Right, and I need can tag any poll requests to the particular issue that you are addressing, whereby closing it if you have if you feel you have addressed the issue So to close on this discussion, we're out of time So to close on it, I think this has been a really good discussion I think there is clearly interest in talking about a Yang next I think there's a little bit of unclarity of what the group would like to achieve with that So I'd like to suggest, Kent if you could put together some just discussion on motivation and objectives that if we can get agreement on that that will allow us to go talk about mechanisms and then we get to mechanisms, we can say, is this something that belongs? in 2.0, 1.2? maybe even an extension. It doesn't even need to go to, you know, for perhaps it's 1.1 plus an extension. But we can have that conversation in context so if we can start out with that motivation objectives, completely separately is how we work with Git Personally, you know, I do a lot of open source work and we use Git all the time. I think that's a great thing We do not need to change our consensus process to do that We can work on a more agile, you know, that's the Vogue term right now. We can be more agile and then bring it back to the working group and say, this resulting document, do we agree or not? So we don't even need to change our processes. We should just go forth and start doing these, you know, the contributions that you're talking about and get, that would be awesome But we're out of time on yours, so we really have to go to the very last presentation. You have about five minutes. But thank you, Ken, for getting this started And more importantly, thank you for help shepherding it in the future. Everyone Yeah, thank you Lou. Thank you, Kent"
  },
  {
    "startTime": "01:56:00",
    "text": "SGA and the BBI leader officer has talked about the BBF liaison And this leads, I introduced large-scale manager issue. This is fine has been, you know, a calm recruitment issue in the type of trade and VUF has provided some analysis about how this is a much of BF site We would like to receive the suggestions from our the NAP to resolve this issue And Deepak will introduce this slides Okay, please Deepak Deepak Thank you. So, yeah, let me in the interest of time, let me just, that's go, though time let me just that we go to the yeah and i'm sorry you don't you're not going to have a lot of time I understand. I understand. Let me just yeah, quickly walk through the exit executive summary slide wherein now we just uh highlight the use cases and the issues that is faced right? So, yeah, so currently what we have is, we have a problem at scaling up certain systems which in the magnitude of, let's say, 30 30,000 plus interfaces, which currently is built upon standard modules such as IETF, right? The network we are talking about is a typical PON network which includes an OLT and OING news hundreds and thousands of OIN news together so at the current standard models do not scale at that size, and it becomes typically difficult to deploy for such use cases. And the problem that we are talking about is not tomorrow's problem it's it's already in the running code you know as more"
  },
  {
    "startTime": "01:58:00",
    "text": "and more people are on board with NetConFand Jan as management systems we are seeing this as a real world problem So what was done in BBF is to take an example of OANU management But okay, the context is an OANU management of this slide, but it is not restricted to OANU management alone. It is applicable to any large product right? So, I context is a venue management of this slide, but it is not restricted to any management alone. It is applicable to any large product, right? So as a study, we conduct a study and we found out few salient points there, which is basically we can define a list of OA news or we call it clustering where related nodes could be clustered instead of interleaving between the OLTs and OAN news and second point that was that being configured at an OLT level which is basically outside the cluster list of OANU News, create a list of profile, shared profile that each on you can refer, thereby reduce the data source size. And the third point is something called the template which is basically an identity configuration you know many of the OAN News would be referring to identical configurations and they don't have to be configured at an instance level. Instead, a template could be created which could further reduce the data store size And more importantly, the validation time so making the performance much better than having it individually under each instance so what these study points translate as requirements would be"
  },
  {
    "startTime": "02:00:00",
    "text": "the data nodes, which is originally defined at the root of the standard models should be a able to be moved deeper into the yank tree Example, the interfaces slash interface is typically translated into Owen News and OEN which is the plastered content It can be moved under that X mark. So it can be referred that. The second requirement is a very important one about which we have further information in the upcoming slides The only instance data nodes can have the mandatory and default statements removed to avoid interference with the template The more explanation about this point or this requirement is in the upcoming slide The third one being OU instance and the template data nodes can refer to the data nodes located at the root of the tree shared profile So we did have a look at the existing schema mount and the newly proposed draft So definitely it has its own use cases and it serves its purpose, but when it comes to scalability it doesn't seem to add to the second and third requirements as such such So we're really out of time, we're actually over time Thank you for sending the liaison and thank you for the presentation I invite all those in the working group to take a look Going back to your previous slide, it sounds like you have some more recommendations. I'll point out that we would very much welcome your contribution in the IET and through the normal process. That would be through a working group, sorry, through a document or draft submitted to the working group for discussion here. So if you have recommendations, on how we should be structuring your Yang models, the right thing would be to put that into a document that we can then"
  },
  {
    "startTime": "02:02:00",
    "text": "run through the process and say, yes, we agree with it. Yes, the whole group agrees. Then it can become even a consensus document in the IETF. So we think that the right next step here is to bring this work in the IETF through an IETF document That's the best way to get us to make comments You know, we're not, we don't really can conduct a business through liaisons, it's really through contributions I understand. But I would highly encourage people of this group to go over these slides and provide their comments over the mailing list. At the same time, I do agree that maybe we can create a separate draft explaining more in detail about these proposals and maybe if people are interested, they could also collaborate with us too make the contribution. Yeah, that would be great because if you have a specific proposal we can run that through the working group process and that would be really helpful and allow your issues to be addressed thank you thank you very much and thank you to all who contributed to this meeting it's early in the week but you know see you at the next meeting and online Okay, thank you so please send comments to the list to continue the discussion. Thank you you you"
  }
]
