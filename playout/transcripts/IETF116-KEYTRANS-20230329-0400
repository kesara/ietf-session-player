[
  {
    "startTime": "00:00:10",
    "text": "Good afternoon, everyone. So this is key tran. I'm Alex alex Golf. And ron my sitting next to me, where your c chairs for key transparency today? Let's get started. We have quite a busy agenda. So we want to leave enough time at the end for various questions and discussions. So this is a non working group forming both. So we're Not going to discuss Charter, but we hoping to get as much done pull the steps before that. Okay. And as a reminder, as should be obvious this session is being recorded. And a few housekeeping details. By now everyone who has been here person should know what statement is? But if for some reason you are just arriving and have never been to an Before or if you're attending remotely and this is your first Atf. Please read carefully this statement basically, what you say here, is being recorded and could be can be used. And we must all use best practices in terms of decor and not abusing each other and all of the details are on this lovely slide."
  },
  {
    "startTime": "00:02:02",
    "text": "For those of you in the room, please wear your masks. Unless you would briefly remove them to either drink something? And unless you were actively speaking out the microphone or if we've had presenters in person up here at the microphone, which we do know. And Please join the on site meeting tool from the agenda That's the little icon you see there, the on side tool. For those of you who are remote, please make sure that your audio and video are turned off unless you are unless you were presenting or unless you have been called for your place at the at the microphone. Yeah. And both remote and on people use the same tool to add you to the queue so that we are fair to everybody. Alright. This is available from the list of materials on the on the Website, but the may with the mailing list for key trans information is at the bottom of the slide. And the agenda and general meeting information is here. And here is our proposed agenda for the next two hours. Anyone like to say anything propose a a bash to this agenda. Okay. Hearing no comments? We will invite Brendan to I'm gonna stop sharing this and start sharing me slides for the problem statement."
  },
  {
    "startTime": "00:04:18",
    "text": "Okay. Brendan, you have the control. Please take it away. Cool. Thank you. Hello. My name is Brandon. And did David talk about? Transparency. So for contacts, right now, when people build into an encrypted services, they have a ton of options for tools and libraries to securely encrypt data. Like you can choose between Ml s or the signal protocol the or t open Could. And all of these are really good options and they all have really good implementations. But one thing that's kind of thing thing missing from this ecosystem is that while you have all of these options for how to encrypt data? There's really not a good way to distribute the public keys for that encryption. If you look at almost any secure messaging now? They usually have some internal directory that store. A mapping between user identities and each users public key. And that directory is not secured in any way. Users kinda just have to trust the server to provide them with the right public key. And what's unfortunate is that a user doesn't have that trust for the server two behave honestly, then the encryption protocol kind doesn't matter. Because the english server can just give you the wrong public key. And while apps do you use, like an internal certificate authority? Similar to the way that a distribution works in the web P I. Use. This particular scenario that doesn't tend to change much in terms of the trust model, you're still kind of just trusting this order to be honest. If an app is very security conscious, they'll usually, at least have the screen. Like, the one that you see on the right that allows two users to"
  },
  {
    "startTime": "00:06:03",
    "text": "manually verify that they see the same public keys for each other. But people rarely actually do that because it's manual and it's inconvenient and you have to could talk to the person in person I see that Richard Branson hand up so you wanna question? Yeah. Hey, Brent. Just a brief clarifying question. I just wanna confirm wait, when you say distribute long term identity keys. It seems like the problem you're trying to address here is not merely the mechanics of delivering a key from point eight to point b. But the association of a public key with an end user identity. So it seems like the problem we're trying to tackle here is assuring the fidelity of that bind. Is that the right way to understand what you mean by distribute distribution here? Yeah. That's is the right way. Okay. Thank you. Yep. The technical solution to this problem in the literature is something called key transparency. From the buffer request. Key transparency is a safe publicly editable way to distribute crypto sensitive data like public keys functionally, It works kind of, like a key value database. And you have two crypto assured properties. About the consistency of the data in the database. The first and the most important is number one there, which is the Analysis kia seen by alice. Equals Alice kia by everybody else. Or another way to put that is that everyone has the same view of all of the data and the database. And that's really powerful because it lets us go from the situation we're currently in where users manually verify the public key belongs to a specific real life person like Named Dallas. To a world where Analysis devices can monitor it her account for unexpected changes. So to think about this in terms of, like, like a comparison."
  },
  {
    "startTime": "00:08:02",
    "text": "Think about what happens when you log into gmail or Facebook. Or any sort like that. You usually would get an email saying that someone logged in zero. And if it was really you, you just ignore the email. And you can imagine if instead of that, every time you log in to one of the services, all of your friends got an email saying that someone logged in. That would make no sense because your friends are not prepared. Do anything with that information. They don't know. If that login was legitimate or not. But really that's kind of the world that we're in with within encryption right now because if I'm someone's contact, and I see that their key changes have no way to know if that's legitimate matter or not. But the power of K is that it gives you the ability to say, you know, even if this is a malicious actor trained to access Alice account. Alice already has a way to be aware of that. So it's not my job too. Then you're out of this was legitimate or not. And the second property is more technical. So analysis this is key to date equals this key yesterday plus anything new. It's kind of an only property and the purpose of that is just so of that Ellis can go offline or, like, a one vacation for a week. And when she comes to back can check that, nothing I nefarious happened. She was going. So what's interesting is that Yeah. I just wanted to interject that this is this is a way of solving of solving the problem, but the the transparency part is the the the salient the only part of this this particular approach there, of course, their authority based approaches, but this is this is the the transparency providing the visibility into what has happened part of of identity management were."
  },
  {
    "startTime": "00:10:01",
    "text": "Yeah. It's a slightly different approach. So instead of having and authority cert. A painting, then you trust the authority to be behave correctly. This is a transparency approach where everybody can see the same data and users are responsible for making sure their own finding is correct. But what's interesting is that The Atf already has a lot of experience, standardizing transparency log type technology So for example, you've got this working group which focuses on supply chain integrity or the Ti working group which focuses on digital credentials or in particular the trans group which published an irc c hunt certificate take transparency. And all of these projects rely in some way on the idea of transparency, which is provided by a crypto append lock. In particular they use a mer tree and the mer tree is just a tree where each sleeve contains the hash of some data. And then every other node contains the hash of its children. So it kind of christmas is up until you get to the single root note, which is a commitment to the entire tree. An important difference between what all of those groups have previously built where are building is that those logs are fully public and it's intentional of that someone could go in and see everything that's logged in check. Whatever they wanna check for. Q builds on top of the of an independently log to provide two additional features. The first is that it has a search protocol where a user can request all of the entries related to some accounts and the server can provide those entries and it can also prove that it executed the search correctly. So the user notes that it actually got all of the entries they were looking for, and then nothing was omitted. And Importantly, they'd know this without having to download the entire log. Second picture is that it provides better privacy. So you have the search protocol, that"
  },
  {
    "startTime": "00:12:00",
    "text": "let's the server prove to a client that it's actually showing the client everything that they asked for kind of the inverse implication of that is that you don't have to show the client, anything in the log, but it doesn't need to see Like, the client doesn't need to see every entry or even any entry other than what it would be allowed to search for. And this actually ends up being a lot more appropriate for the use case out into twenty encryption. Because users one half to download the entire log of every time anyone has ever changed their key. Just to find the key of the couple of users that they wanna talk to. They wouldn't be able just to search for the specific keys they want. And also for pregnancy reasons, a service provider probably doesn't want to provide the public log of every user they have. Much sure keypad that on an no basis. Eric chris? You have the question? Yeah. Sorry Mean keep tire does not involved transparency one. That was my impression from. Beating it up. Okay. Right. I was in the group yesterday, so I'm I'm pretty confident. Okay. And or Or still transmit I'm one of the contributors the the Skip work item, and I just wanted to comment on the sort of mentioned that a lot of these existing systems like certificate transparency, the entire log is public and to be clear Skip does not sort require the entire log be public. The model there is each transparency service can maintain a log and that service can choose to disclose either the entire thing in a public format or only certain parts based on an authorization policy. So it's... The model there is is not up, you know, fully public you know, in the sense, that, you know, certificate trans transparency has a sort of very public facing sort of intention behind the Merkel, the marco Tree. Proofs in the log. Well the other comment is"
  },
  {
    "startTime": "00:14:03",
    "text": "about the the identity dependency within the certificate transparency and identity dependency within skit. Because of the the need to think about digital identity associated with the log entries, a lot of them end up automatically including some form primitive form or related concepts to some kind of key transparency and there are other sort of error scenarios where as you know, for example, as part of securing a software artifact in skit, you might secure some of the key material used to authenticate the issuer of claims about that software artifacts. So really excited about, you know, the work that's that you're doing here. And I think there is a lot of synergy between some of these these other work items that and agree with E comment about Ti. Thanks. Started for getting that wrong. Thank you. So Next slide. I mean, all sounds great, but why are you telling me because the like kitty being seem a perfect fit for the problem of Thank this for maintaining this user identity to use public keep finding? And the fact that it's been around for about ten years at this point, said to a little serious adoption and the question is why is that? So if from working on this myself and talking to lots of other people, my sense is that it's because Kt tends to be very technically complicated sort of in its own. Right? There's also a large amount of academic literature on key. So The design space is fairly wide and there's not much guidance on what the right choices in the design space are versus what is even possible. And also, there's terms of actual implementations that exists there aren't many and what does exist stopped and is missing important parts. So like, they implement the server side but not the client side. Has no documentation or no active containers."
  },
  {
    "startTime": "00:16:02",
    "text": "And just overall the technical difficulty combined to it. Much work needs to be time to deploy something like this combined with? To lack of any outside help validation makes this something that people tend to just be very likely to give up on. Like, a company you might recognize that this would hypothetically be a valuable security improvement. Not able to justify the amount of engineering time would take to actually accomplish. Hi. Thanks for this analysis. I think this is pretty important to think through. I think it's missing one of the other pieces for why it's been difficult to get this deployed, which is a question of incentives. And I'm reminded a little bit of Dns sec. Here. Apologies for that. But people often see Dns an opportunity to break their domain. Because when you screw it up, just looks bad for you and people things don't work. And I think we have to ask ourselves with key transparency. What happens when you screw it up? But also what happens when it effectively does uncover that someone's key has been modified. And what are the implications? What are they reputation costs for the service that's running it. I think the service should run it. I'd love to see reputation cost for services that don't run it. And still distribute keys. But the folks who are distributing keys may see this as only a way that they can get with the with the P negative P r. Stick. And don't see how they're going to get an improvement from system improvement for their users, but not for the distributor themselves. So I I don't mean to be discouraging because I actually want to see this happen. But I I do think that we need to grapple with the incentives here, and that's not on your list. Yeah. That's totally valid. Thank you. And we're going to we're gonna hold questions until the end of this presentation. Just so that"
  },
  {
    "startTime": "00:18:01",
    "text": "we're sure that run can get through this material and then we'll have a robust discussion on the problem statement. Okay. Cool. So Like I said, this is something that is tech difficult. You like a lot about outside help validation, something that people tend to just kind of give up on some. I deal and go here or is a place where you think that a standard could have a really positive impact because the goal is to reduce the barriers to deployment that I was just talking about so that using Kt is actually just and not for me the people just give up on. And I think that the standards process tends to target most of those issues pretty perfectly. So the process of actually building industry consensus around what Kt is supposed to look like and how it should work. Helps zero in on the right choices in the design space that would satisfy a wide range of use cases. Whatever protocol transcription comes out of that receive a decent level of scrutiny from security researchers in the general public. Which would create confidence that's actually secure we'd have more trustworthy and complete open source implementations because people will actually wanna use it. They feel like they can trust it and they don't have to start from scratch with figuring out what to even implement in first place. And then wider adoption leads to having better documentation somewhat natural link because There's more people that need to understand that then they get better explaining that. So proposal for actually getting to that end goal at having a standard is what I think make sense. We will start by trying to understand the broader state of what's been deployed in what's possible in the world of Katie. After that, we would try to align a community on a set of common achievable requirements that be the basis for a standard. And if we can do that, then actually write the standard. Seems like the easy part This meeting is meant to focus more on the first step by"
  },
  {
    "startTime": "00:20:03",
    "text": "introducing Kt and, like, what sorts of things are possible with within the world of Kt. Ends. Towards the end, hopefully, we can start to move towards step two of talking about consensus. But That only and now we will take questions and comments. Seeing no one in the queue do Do we want to k. Echo? Yeah. And I think I wanted to go back to this point D dk was making my incentives. The reason that Ct is a thing? Is because about two browsers maybe three to decide that we're gonna require it. And everyone else had to follow along. And, you know, is expensive opera Cg logs and the logs impulse quite a few you know, a long up quite badly. Katie I has like similar problems on exactly same problems. I think would be... We we do... We'll we'll talk about these problems of like, who's gonna actually operate this? Who's gonna make a bigger thing. Right? And And Just just a preview light the question I'm gonna ask you later is like, who else is who... Which if it has messaging service is actually wanna do this. if the answer is, like, the no set and like this is not doing. So Because Hi am Ka from Phoenix R and d. And well, prior to this meeting reading up a bit on the apparently, literature. I've been wondering each approach seems to rely on both the distribution and or seems go aim for the both the distribution and provision of transparency for key material. And I was wondering why we have to combine these two, So do we really have to upload keys or"
  },
  {
    "startTime": "00:22:00",
    "text": "wouldn't it be enough to store commitments to key material or to other data say if you have want to provide transparency not just for a key, but for more data like a user account. So why not just upload or store commitment commitments to whatever you want provide transparency on. Yeah. Do you have any thoughts on this? Yeah. I think that's totally be valid. And that's something that you can do with the current trapped I'm gonna present at the end of this meeting. It's just... It follows, like, basically the key value database abstraction. So you have a key, which is gonna be username. And then the value can be whatever you want. It can be a public heap, but it can also be any kind of information about your account or whatever. Yep. Alright. Thanks. Thank you. We have worry in the queue. If you're... If you don't see your name there, please use the on participant tool So Okay. I tried to use that. can add you? Or sealed transmit... Just regarding I guess some stuff that I've seen that's related to key transparency in open source community Like I mentioned before, and in skit and in skip like services you outside there is a lot of people are starting to put keys in these transparency services that were you know, designed to store artifacts of other types because they wanna be able to sort of generate know, receipts for offline verification, not just for the artifact, but for be issuing identity around some of those components. And so I wonder, you know, how do we do we know coordinate that that identity problem across the different transparency ecosystems because"
  },
  {
    "startTime": "00:24:04",
    "text": "all transparency ecosystems have some need to handle identity and keys building block for identity. So again, I I don't have a good answer there. I just... I'm seeing hints of key transparency already showing up inside of sci and of the work we've been doing there, and I wanna make sure that it all goes well. And... Yeah. There there there can be issues, you know, around long term identifier that that have keys associated with them when they interact with several different transparency like ecosystems. So It's Yep. Then can't gilmore. So I wanted to ask about the why are we not storing commitments instead of the content? So one thing is that when there's a mismatch, you may be interested in knowing if you are the account holder. What the distributor has served about you, which is different than actually just knowing that is there's something different. Don't know what the semantic Trade off star there, but that might be one thing. Second thing I wanted to observe was that putting just the commitment seems like a bit of privacy advantage because maybe you're not putting don't know, details that might be more identifiable, but the real thing that the privacy concern is I think is with the name with the account account name, not with the content that is the key of the key value store is the thing that we have a special privacy concern with things like Ct do not handle. About this we are actually right now deploying key transparency at present. And it... And it it it is indeed. As hard as you say, So building it It's it has been a challenge building the tree and billing everything."
  },
  {
    "startTime": "00:26:02",
    "text": "Using a very version to what's in described in the Rf. And we would actually be interested into seeing this work to be standardized more. On the other hand, I do... I wanna say that even if you don't put the commitment, even if you put just the full string. The server can anyway highly leaf. So we can we not real the information about the. So whatever is gonna happen with the commitment I think it is important to remember that the server can just omit any part of the Aaron. Yeah. Thank you. One international I think actually certificate transparency is a very interesting topic. My pressure is that in your plan, you have any potential yeah, potential implementation message. Like, I in my idea, maybe, like, broker sharing is. So do have any other considerations? For implementation. Brendan then would you like to answer that? So we don't currently plan to I think straight to you far away from the problem that we're talking about right now, which is more like, instant messaging focused of attaching the usernames to public user trees for Instant messaging encryption. Do you have a follow question or"
  },
  {
    "startTime": "00:28:00",
    "text": "I don't have. It's. Conrad? Okay. So... Sorry cannot go again, links twenty. So thanks for the kind of responses to the question regarding commitments versus material. Just to clarify a bit where I'm coming from. So first of all, I share that the privacy concerns of of course, and I agree that the identifier is is is some more, you know, important to protect all way, that's somewhat. I mean, you can have commitments and still try to protect the end fire Where I'm coming from is while we're Also, I mean, at the idea with the mini working group trying to standardized around identifier and and authentication. Who knows where that goes. But kind of thinking separately from that it would be great to have some sort of flexibility because There's a lot of movement in the in some messaging space right now. And kind of fixing a certain format or you know, whatever we put in the in the actual tree or or transparency structure might be a bad idea and to focusing on commitments would give us a lot more flexibility. So that was kind of where I'm coming from. Thanks. Antonio I'm I'm going to present later, but I just wanted to someone asked about, like, industry interest in in building different transparency and Zoom it is public published a white website a couple years ago saying that we were going to build kitchen bank, and that effort put is going and I'm here so There is some of on."
  },
  {
    "startTime": "00:30:02",
    "text": "Okay. So please excuse this. We're gonna try to do a bit of a take the temperature of the room here. How to we wanna figure out how people feel about the problem statement in general. And not necessarily the specifics of whether this is a commitment or the actual content. And then we can get more specific with our with our questions shortly thereafter. So does the problem statement. Accurately express. The sense of the problem. What was that is the Okay. Okay. So First question is the problem statement was specified so far. So if you have not used the show hands tool, in the same interface where you would add yourself to the queue you would see this this question, and you can say Raise hand for Yes, the problem statement is well specified. Or by raising hand or No. Do not raise hand. You don't think the problem statement is well specified. K. Give this thirty more seconds here."
  },
  {
    "startTime": "00:32:08",
    "text": "Okay. So for the record, that's forty one people who said yes. And forty two who said yes. And one who said no. Forty three. Okay. Next question. Do we want to go into level of detail about do we want to we wanna solve Do you want to do think the problem is specified. Curious while you guys are working with sun might be good a chance to give folks who are in the minority on that last twenty chance to see why they. Okay. There's there was one person who did not raise hand. If they wanna identify themselves. And make a comment. But the floor is yours for the moment? Okay. Melinda Shore said, I think it was the only one in the minority. I'm not clear and whether they want proofs of inclusion or on distribution mechanism and. This is this is let's say this is a a question that we would like to answer later in this. Yep. Okay. At this point, I think we're probably gonna proceed with the the presentations unless anyone has a burning burning issue that they would like to discuss. a So and the plan is will run through three presentations"
  },
  {
    "startTime": "00:34:04",
    "text": "only clarifying questions during them, and then all these discussion at the end of this whole three presentation. So basically, we just we did a quick checkpoint to make sure that people understood what was discussed so far, and we will do another bigger checkpoint after the next few presentations. Alright. And that one more thing about this is that While you're watching the presentations, please watch them with an eye towards this problem statement these does answer change based on seeing these presentations. Okay. Jocelyn? The floor is yours. Thank you. Hi everyone today. I'm going to be talking about Para, which stands for a practical key transfer transparency for end encrypted messaging. And this is joining work with Left bordeaux who are both in Labs, Asia ago, she will be presenting after me who that Msr our general stu and Kevin La, all med net. So Just so recap the problem. End turn encrypted messaging I'll send bob to message each other through some encrypted messaging service. And this encrypted messaging service also holds database of their numbers mapping to their public keys, for example. And in order to be able to send messages they need to retrieve each other's public keys from this server. So Alice bob can look up each other on the server, let's say they just use usernames now. But the server cannot... Is not bound to return the correct public keys in fact can return something malicious."
  },
  {
    "startTime": "00:36:00",
    "text": "And mount a Medal in the middle attack and what's worse, it can do this undetected. So the solution And and also the setting that that we're talking about is there's an identity provider who holds addiction with the username public key pair such that new users can join the system. And once users of join, they basically own their usernames and can update these public keys. They want privacy, so they want the server to restrict queries to their username. So For example, the blocked someone one, they shouldn't be able to query this user, or learn really anything about the metadata of this user. And importantly that identity provider could cheat. So if this... And what does this mean is the same username is que at the same time? The actual value return could diver in the in the plain setting. So this is what we're trying to address. So again. Threat model, identity provider holds a dictionary made sheet by showing diver views. And I we wanna prevent this together. But this ends up leading to assumptions on the clients such as having the clients store secrets. But we all know how notoriously bad. Clients can be at store secrets. So This is undesirable. So instead we go with non active location as our security guarantee that we're targeting. Meaning, The server can actually show different keys to different kinds without getting caught. So at any given time, If Allison was sir keys peak, The server cannot get away with telling bob her keys Bad. So this side is a little bit done. So bear with me Let's just talk about the parties involved there's an identity provider who's trusted for privacy and authentication holds this database. This is the case even in current regular"
  },
  {
    "startTime": "00:38:00",
    "text": "messaging systems where the server holds a database is trusted for dealing with blocks blocked lists and so on. As well as authenticating users, for example, what if you wanna to join what's if you use your phone number. But you wanna eliminate trust in the server for serving these correct these public keys correctly. And the updates on the server basically batch and take effect in discrete time steps that we call. There's users who may update their public keys once they've joined the system, they may look up each other's, public keys if they're permitted. They can check each their own keys history up until the present App, And what they want is no changes to their keys without their finding out. And that their friend should receive matching keys for them. Finally, there's auditors where parties that are literally there to share some of the computational burden of the users. And they basically just check global pre kits about whatever changes the servers making. So For example, I could check that the servers is in destroying any records. And this could be users or smart contracts even or designated machines or some sort of secure computing hardware. And because this can be anybody, what we want is that they should not learn data about particular users by doing this global checks. So with that model in mind, Even with that simple model, we can come up with a few components. So basically, what we want is a mechanism for committing to a mutating state on the server. A mechanism to allow users to monitor their own keys. And some source of ground truth that is a way to share a small commitment And in particular for our system, what we wanted was to be able to support billions of users, billions would be. Of and this would include for a global sales system."
  },
  {
    "startTime": "00:40:00",
    "text": "Users and all kinds of cases with bandwidth constrained or battery constrained or compute computationally constrained devices. Okay. So Again, Tl r there's an identity provider hold the table, mapping to public keys, we need a way to commit to this this changing table. And a way to serve commitments as they get changed basically over time. So the problem basically, the way that that we model it breaks down into commitment and verification for mutating database problem and a dis small commit problem. So let's talk about this first part. Commitment and verification for a small mutating or database? So... Yep. There's a database. Sir. Committing committing or mutating potentially large mutating database. So if there's a database, you're committing to this, So Here's the first two interesting problems that showed up and there's several role that that showed up that I can refer you to our our paper for basically, the first problem is take machine replication. Storage separation, basically in academic work. This was mostly abstract away. And experiments just use single most... Single machines to run run their tests But the problem is you can't just load entire large data structures into memory. And operate on them. You're at some point in the compute cost is just going to be too much. And you also need state machine replication, You can just have one of. Holding all of your data because that might go down. Right. So basically, we introduced to flexible storage there Api. That is modular and plugs into existing database solutions. Which"
  },
  {
    "startTime": "00:42:00",
    "text": "By the way, I think this this might be an interesting topic for standard having some sort of standard interface introduced. Then there's data structure for actually committing to these states, which think Brandon referred to this in talking about the Mer tree. And we basically wanted to talk about use Marco tree based data structures because those are constructed with hash function. So post quantum and And and also easily slash already standardized. Turns out previous work, in the tens of millions type of category seemed to find, but then when you're start to scale to the scale that we wanted. Even over five years, you'll be add more than a hundred terabytes of storage. So it's this a storage caused blow up. So we basically replace this under blind data structure got orders of magnitude better as you can see in this side basically, the work that is most comparable in privacy properties to us is what is word called Seamless, which was if you had ten million updates a day, which is reasonable to assume for for something like the scale of whatsapp messaging would would end up at more than a hundred and ten terabytes over five years. Versus our work, which is barely five. So with that, I wanna mention the last problem that I have time to discuss, which is users checking their own keys. And previous work basically talked about this using zero knowledge either zero knowledge proofs? Having the user be always online or do the equivalent amount of work consuming the equivalent amount of bandwidth. Or something called a pen only data structure. So basically nothing ever gets deleted. So"
  },
  {
    "startTime": "00:44:03",
    "text": "Let's just go through this one by when. Zero knowledge proofs? These are impractical for the server to do at scale. The client doing linear near work So basically being always online is impractical for clients, especially the kinds of clients we want to support. Data structures lead to ever growing storage costs which Yeah. I guess try convincing somebody in Corporation to let you implement something that has no way of reducing storage cost so we basically found a middle ground which we call secure compact. Which basically doesn't require users to be always online, but also doesn't totally require a pen data structures. Okay. So that is all I have time to talk about on the commitment and occasion for the mutating database side. I do wanna talk a little bit about the dis of small commitments. So This design space is also interesting. You've got Two minutes. Okay. So so this is basically the problem of taking this commitment and serving it to users. As it gets updated. Thanks. By the way. So one option is to use which is basically users have some out of fan communication mechanism which they message these commit through. Essentially the problem with this is it can be too slow, lead to partitions, and all guarantees can be are are basically retroactive. So damage may be done by the time you see any notification. Another option is blockchain, so using a smart contract, for example, but these are one to have you on the client to you might even just flood the blockchain. So what if we just, like, had a custom version of something like blockchain that ends up meeting consensus. Which is also an efficient complex to implement and analyze I had a montage of papers to show you which the animation isn't showing up just yet. Right now, but"
  },
  {
    "startTime": "00:46:02",
    "text": "Basically, consensus is not good. We basically opted for something called consensus less strong consistency. Which you can basically say, let's say there's some independent witnesses of that can sign these updates, and then you can use existing server infrastructure for hiding all these signatures and serving them to clients and responding to requests and stuff. And The observation here is based the inside here is basically, the server already trusted for comp the updates and updating the underlying database. So why not just use that for other things? And I guess here's little schematic but let's not go over that the point I wanna make is that... Doing this is basically as good as byzantine and fall tolerant consensus protocols, except you trade liven for getting something much faster. And it can be used in addition to other mechanisms. Easier to implement users existing server infrastructure. Users get certified commitments every time they query and it's also actually very good. It's it's very fast. The latency is is under five seconds even if you have a ridiculously high number of updates per second, which you don't expect. And Yep. So I guess here If it's air, you have you have a couple you of three more minutes. Oh, We can just slow down just a little bit. This is actually the last slide. So guess thank you. Our goal our goal is to scale of billions of users And This had two components, scaling the underlying crypto photographic primitive. Using easy to standardize crypto traffic tools and scaling distribution of small commitments"
  },
  {
    "startTime": "00:48:00",
    "text": "for all kinds of users in all kinds of places. And we basically explored in address both problems while ensuring privacy, and there's also other things that show up. Other details that show up when you start considering the type of setting. And for that, I defer to our paper. So thank you for coming to the talk. And thanks to my collaborators. All all of our code is open source. And The links are in this paper. And Jo, do you wanna comment on the problem statement briefly? Yeah. I guess, I mean, This is basically what I covered in the first couple of slides. Right? So encrypted messaging service, there's a database on the service users basically wanna make sure that they have consistent views of this. And and be able to detect if they are getting inconsistent views at some point. So for me for the less the folks with less domain knowledge that may be attending This is a good match for the problem statement in your opinion. Yep. Right. Thank you. Thank you. Antonio. I'm pressing to you. Alright. Everyone thanks to brandon and the chairs for the... For the indication. A new around here a couple words about myself"
  },
  {
    "startTime": "00:50:00",
    "text": "I finished my Phd in crypto photography in twenty nineteen from for now. And then I joined the key as a engineer. In may of twenty twenty, this was acquired by june, and that's how I got to my current role. So in this presentation, I want to give you another view of two different fancy systems mind the one that is been in production since two thousand fourteen. And the other one is the one that Zoom is planning to the point. And in in addition to in the details of different system, we will look at out the concept of a user identity is different between space in June. And now that informs the aircraft to to pay trans find systems. And then we're gonna compare contrast and I'll comment on the on the statement. A couple of bigger disclaimers. I'm gonna like, mean, some important details, they won't always be a hundred percent accurate for the sake of priority. This display information on purpose only. You can read the rest the. Okay. Let's get three key base. Key a starts as with the with the mission of giving people way to map their online identity to their public keys in a way that is how to forget and that's figure it possible. So the is like, people know you through, like, keep a a twitter, Facebook, whatever, and they went on a water and key ebay is trying. To to to build, like, a publicly directory that allows like everybody to go check the public east connected today. I of the people that you're not online. And we were trying to do this in like a barrier. Simple. And if it use, so users don't even need to actually in terms of public keys, they be just things in terms of flight. What devices they have and need device of own team And on top of this factory, we have built like a lot berry interesting application that that's"
  },
  {
    "startTime": "00:52:02",
    "text": "chat or tried sharing at etcetera right. And key bases is the only keeps system deployed in production to the best to the best of my knowledge. And it's been running for quite a while since two thousand fourteen. So what does an identity add based look like? So we have an immutable username. That that issues actually as a team is that directory. And this username is connected to, like, a set of devices in keys, so people can like add devices remove devices and so on. And then also, as part of this identity, we have, like, what we call the social proof. So in this case, max, the the former the opt is if it's declaring publicly that it is user maxed tag on twitter, and he can also like automatically cost tweet containing a hash of its identity based. So when clients... When give his clients show max profile, They actually go to sleep and track. That that these statement that the hash matches what the... What what the february circuit. And on top of that, we have, like, the ability for users to follow each other and sign over each other state entity which you know, build some sort of, like, web. System and are like, public, so you can you can look up the identity of any key issues user just by going on the website. The way that crypto drastically we store and we start this user identity is that are least I can depend on the list of statements with this strike the changes of this identity over time. So in this case, maybe Alice start using key ebay Like a first device which and"
  },
  {
    "startTime": "00:54:02",
    "text": "of this statement, which is signed by the public of first device. When she wants to add a new device, the statement that says here is my second device is both going to have like to like, a hash reference the to the previous statement, and it's gonna be signed by both their new device and their whole device. The way, it works is that in the app, you actually need an existing device in order to organize a new device to use say app and you would, like, scan a codes or something like that. There are other kinds of statements that going the identity as I was saying, like, you know, social proof and then, you know, you can also not the disturb, but battery devices. And what what happened here is that all of the statements then get get the in the trans that we have, as I will explain later. So one point we started having a key base with with this with the system is that since you need like, new devices and existing the device in order to authorize a new device users would like just lose all of their devices and then be upset that they can't. That they would they they get to lose their use name. Of course, we can't recover their data, but we could do something about recovering the user name. So a few later that we introduced this ability for users to reset their account. Which is essentially amounts to put another statement on this chain that says I lost on my devices I wanna start from scratch. And since this is supposed to be very rare when this happens offense like we can show to that users to the conversation partners of these people very scary message with, like, an actual scrolling and there that says, you know, the keys changed Please like, confirm with them this is legit before letting them in. In contrast to when your keith and what change your gave some notification and says, your security got has changed and people down three layers. Right. At them that. They just ignore."
  },
  {
    "startTime": "00:56:03",
    "text": "And so, yeah, we're gonna like, content. And after after given we actually include previous conversations for the for the new so that users don't need lose necessarily boost. All of their history. This feature can also be, like, disabled. We have worked called lockdown mode where where the the these don't work and also all other stated changes from the website that this allow? You just need the device to be able to do anything. This is something that from the server. We could potentially let users add... The... To this change the says, please never ever accept my account The way that the Metro three works, it's again, like I'm meant three, so it's like, the specific three, which essentially allows you to prove that, like, value... He's has is associated together with the specific label. And in our case, as we each user on the system correspond corresponds to listing. So the label is just the hash of the username, and the value is is the hash of the of the of the heat. One thing that's important about our system is that like, for example, it's a therapeutic transparency the app actually blocks Whenever the user is updating their keys or set of devices or whatever to this update need to be very. The Metal three itself is publicly out of. We even have an the e Api that you can go and play with. You can look at the miracle rules. You can look at a they we now can do the hash stuff. Etcetera. We post the root either to the tele before we used to a bitcoin, but we're trying to make sure that guaranteed people that we don't change this. After the fact. So that was. Now let's talk about another scientist, if you send the one that would be"
  },
  {
    "startTime": "00:58:02",
    "text": "for zoom. So I don't need to tell it with manage Communication platform. The important dates that in May of twenty twenty, we published white favor where we were describing a plan to bring the kitchen to our users and are not of identity, that does include like, a different finance system. And currently, we use and an on just for meetings, but also for other stuff, The I identity that we use a zoom is different from the one that we had the base. So this of two components. The first component is the effect of like user identifier. And we used to view at the domain name to identify the account, which a user is spark off such as a company or a school and we believe that identifying the organization that someone works off what for it often the most important piece of our user entity. And in case that many administrators of the account, we have select improve ownership or this domain name before it can be used to represent the account. And then individual users, we believe account would be identified by their email address. And note that is identifier the my can ebay they. So users can change email address this they can move between account and so on and forth. The second part of the user identity, like key based it's the list of devices and this leads can change over a time, you can add them the moments on. We also use c that at at tone but with some differences. So first, like, you know, we we the user change is now indexed by like Id. Which is not anymore the has of a username, but we have a least additional that late the in the statement. And Another important difference is that when we allow users to add devices without adding to have an all device available to do the addition."
  },
  {
    "startTime": "01:00:00",
    "text": "So the... In this case, the second the addition of the second device can just be a self sign statement. And then the the the ba, like, the old device has came vouch for new devices by approving them in a second link that come and the Deepgram come afterwards. Another important difference is that since these identifier are usable, we we need to keep track of which user correspond corresponds which identifier and now that changes over time. So we have additional change. One the users and one for the identify in case this know. And then, you know, another important feature that we have that we just launched yesterday today is that that's related to transparency and though it's not actually in scope for for for sake for the for the for this task, is that we allow, like, experimental identity providers to pouch for the identity of, like, members of, like, an account. So many businesses is, you know, delegate their authentication needs to this external identity providers such as After, that offered the centralized decentralized service that manages access control to all of like, company resources, and they also allow users to use like, that's the same set of credentials everywhere. And the idea is that partnering with without that, but we have add more identity providers so that they can issue signed station validating that the user belongs to a specific company's account and validating that user public in a way that the zoom server cannot. Cannot tamper with. Now for any purposes, I don't think I'm going to go other this. How it works, but but you're gonna read more about it in our white paper from from the point of view of the actual transparency three, we are using, like, a data structure which we analyze our favor, which was published been last year"
  },
  {
    "startTime": "01:02:03",
    "text": "The main differences is from what we were doing at ebay, is that instead of using a single lease that gets updated? That contains the hash of of a t, we we store each statement off the chain in a separate the. And this is because that way, we need to less information about when when our chain is updated. Instead of using like, a simple hash to compute which the position of the state of the in the three instead of hash, we use a very high random function, which essentially is the way to add privacy. With the system because you can't just verify. You be in the only I where label, you located one that server gives you proof, but you can compute the value yourself. And then as the ask some people where where we're anticipating before we for the value we actually use commitment. And we don't post. Directly again for increased privacy. We respect the the back of the system now this that file slight chain contains multiple statements, we need to do more than one inclusion proof. In edmonton advanced twenty three. So if you wanna compare the two systems, at key base, we have been immutable user that whom me immutable identifier In both cases, we have ways to add like to connect like, their the identity within the system with identity that that the users holds outside of the system. On the ip base, we have a stronger understand I being a device to required for from an existing device. And Zoom, we decided to relax this a little bit and for devices can be approved after they've been handed, At the Based user is public a while at zoom we can"
  },
  {
    "startTime": "01:04:00",
    "text": "we can more about making them private and not leaking information about the sea change when we on have too. And for that reason, we used, like, a different data structure or different three design, and which allows us to, like less leakage. And we pay for the additional privacy with, like a slightly less efficient vital application. Construction. That's all I had for you. Thank you for listening. Okay. And Antonio, I'm gonna the same question. Yeah. Sorry. For forgot mention. Yes. I think that that the problem statements would be like a good match. For what we're trying to do, I think as I presented, like there's is like, So to more stuff beyond what the what the problem statement is capturing that we are are doing some of which I have presented here. So I would I would see it as a good can. Like, I would want put for what we build to be, like, extend in a way that we can also do, like, in a way that we can like allow for this additional obligations as part of the end integration start with the spectrum summer. Thanks. Thank you. Okay. How shall. You have the floor. Thank you. Thank you for sharing this, and thank you very much. To Brandon for inviting me to give this talk. I'm also you to this. So I'll do a quick introduction My name is Es go from Microsoft Research. And I have graduate from Brown university as a in thousand eighteen and I've been in Microsoft then. And I've been working on strong privacy preserving key assistance since the last five years."
  },
  {
    "startTime": "01:06:01",
    "text": "Many of the proposals discussed today. I have been quarter on those course. Of his seamless and para rc. And this is very exciting that there is a proposal of us coming together as a minute in building key transparency specifications. So Kevin with Kevin from Meta, I was trying to understand what sort of security and privacy properties would make sense for a key systems when we go first standardization and many of those since already already came up in today's discussion, so that's great. So is just an attempt to bring some discussion points to the table and see if we can go from here. And agree on a set of requirements for key transfers transparency. Okay. So this slide is a quick recap of what the problem statement of transparency system is, and this has already been discussed by Brandon Y and you I'm not going to go into too much detail here. But the mood point here is that there is a service directories service provider who maintains a username to mapping public key directory service. And gives the key out on the client's behalf. They also costs, tree heads, macro heads, or commitments periodically on a public bulletin board, and I'm going to talk about this in a moment too. And when a client gets public key from this directory service, it also gets a crypto proof along with it, which it can verify against the publicly posted tree hats. So in the system, the service provider basically commits to this directory of username key mapping, this Key value store and publishes it on above bulletin board. And the users the clients of the system interact with the service provider in three. So the first is they can register with an account or update their public key."
  },
  {
    "startTime": "01:08:02",
    "text": "The second is they can look up their contacts keys. For example, talk can ask for Alice most recent public because he wants to connect with Alice. So server will return a proof along with it, which book and verify with respect the latest tree here. And Bob's device can also monitor. Its own key history, which has also been alluded to Brand problem statement, which is the transparent aspect of it, and it can verify that his went and correctly. So the goal of this talk today is trying to understand what correctness consistency and privacy prop might be achievable and my be important for a key transparency systems. So So before diving to that one quick comment about the dis destination of the free heads or commitments, in the slide, I mentioned a public bullet in board. So that's one way of dis the three heads. And the idea here is that all participants of the system meaning all the users should be able to see the same tree head for a given e epoch. Otherwise, fourteen attack possible. So the currently deployed our proposals for p transparency systems either bar or work with either of these two assumptions. Either there is a third party public bulletin in board back this street heads are posted, or it's assumed that there is a gossip channel between the different in the system so that they can compare the tree heads directly with each other. So with this with this... So I'm just trying to follow the chat, but I probably come back to later. So with this in mind, we are now ready to look at some of the properties that we think might be important for key transparency systems. So the first property I'll actually first talk about miss, So what does it mean for a key transparency system to be correct? Is basically the service provider is honest and certain users say Alice is honest"
  },
  {
    "startTime": "01:10:00",
    "text": "then another user box should always receive the correct public key for atlas. So that should be the correctness, we think should be the preparedness for key transparency. And then the more interesting properties I've consistency and privacy. So for the consistency with property, the that we want is to follow and say Bob's latest key is due, but the server sent when Alice is query for box latest publicly, the server center red key, which is a fake key. So the consistency are property required in key transparency this will be detectable. And the properties can be sort of separated in two parts depending on who and when this can be detected So the first thing to note here is that Only the owner, which is bob, will be able to relatively decide if this was a fake key or not in the system. So it seems that at least two checks would need to happen for such a fake key distribution to be detectable. So one is Alex needs to ensure that the key she got for bob is in in fact committed by the server in the latest Is she's not she's a tail key for Bob. And then bob, the next time becomes online and she checks his own key history should see that this fake key in that history and should be able to detect it. So based on that, we think for consistency, right make sense to separate two different flavors of consistency properties. And Also, there are existing systems key transparency academic literature proposals out there that achieve some of this... Some of them achieved strong and some much if consistency So my strong consistency remain we end the strongest case where Bob detects such an inconsistency the first time they come online since the distribution of the fake key, and does the monitoring of their own key history true. In the week consistency property, it's... We need additional checks for that. So Let's say, He was distributed to Alice bob game online after"
  },
  {
    "startTime": "01:12:00",
    "text": "that and run his key history check, it's this fake detection fake distribution may still not be detectable. So additional checks might we need to be perform with Alice or other parties in the system for this to be detectable. And in consistency, say, either Alice, or Box should be able to detect it. It's not necessarily that only bob will be able to detect it. And there are existing proposals out there that sort of fall in one of these two categories. The second, property that we want... It's it's not exactly a consistency property, but it's a proper that you may need achieve consistency is what we call contact state. So if each client has to remember the last keys and the version numbers or any other auxiliary information for it contacts. Not for its own key, but for the context keys that he get fetched in the past. And if this is crucial, for the client to be to achieve consistency of the system. Then we say that the system is contacted full other we say Otherwise, we see that this is stateless. And yet another property, which also came up in the discussion before is owner signing. So that gives stronger than consistency properties. So what does owners sign mean, it means whenever Owner, say Alice changes her. Her key change is signed by one of our existing keys. So in that case, at hold he's are not compromised, then the server or any other mel malicious party will not be able to inject a key on Analysis account. But of course, you can do other device which will lead to a full reset. To her account. But even in this case, we can achieve a strong property which says that if a malicious server publishes a tree at a certain,"
  },
  {
    "startTime": "01:14:02",
    "text": "And after that... The user's device was compromised. The server still should not be able to have clients who hold this tree except any keys that the user's device did not authorize before the corruption happened. And this property is stronger and somewhat ortho gone to the consistency. A property. I mentioned before. And then I'll talk about the privacy properties which also came up this discussion about commitments and what privacy we achieve in the key transparency systems? So Broadly speaking, I think he transfers the systems so we can say have you can think of aim for two kinds of privacy. So one is content hiding, which is what we were discussing earlier today in the meeting, which is it hides the public key and the user usernames from the trees. So basically, instead of putting the raw name, a very verifiable random function is computed on the username and the random string is the position in the tree in the micro tree. And then again, instead of committing to the rock of the key, a commitment is posted it to the tree. But there's also stronger privacy notion with some systems such as seamless para and Rc case achieve, which is metadata hiding. Which means it's not only the content itself. But also when the users are registering how when they're updating their keys, this information are also hidden from the public sheet. And there is a yet another stronger property, which was proposed in the Rcs case paper in asia of last year. Which is healing from a server state compromise. If the... Because very verifiable random function requires the server to maintain a secret key to retain this privacy, there is a possibility of that key getting compromised So if the key gets compromised, how can the system heal from it? Once the server rotates the key, that is called post compromise security and that has been recently proposed to"
  },
  {
    "startTime": "01:16:04",
    "text": "So those are some of the interest properties that might be interesting to aim for for a key transparency system. And finally, one more comment I would make about the deployment loans are we I talked about the bulletin board and the gossip support already, but there are two other ways we can think of the deployment. Mode one is the third party management mode and others third party or mode. So the third party management mode is you sort of think of that the tree are through a third party or of parties. But the audits are happening preemptively empty. So if audit it fails, then this doesn't get published. As compared to the third party audit mode, which is similar, but the audit can happen with the lad. Which will lead to... After the fact. Detection. And with that, I will conclude my talk here, and I'll be happy to take questions. Thank you. Alright. So I'm gonna ask Ash for you again to give pay answer the same question that I asked Justine and Antonio. Which is about the problem statement, how do you feel the problem statement accurately reflects The problem and then I have a personal question that I entered the queue for. Okay. Yes. Absolutely. So I I do agree. I think the problem statement that you he reflects the problem and I think that that's the starting point of where wires is added writing this. Slides who are actually talking about importance early privacy properties when we have problem statement. Okay. Roll from the from the floor. Asha, how many systems did you evaluate in total? Did you"
  },
  {
    "startTime": "01:18:00",
    "text": "and specifically, did you evaluate Para and key and the Zoom proposal. In your analysis? In this room, I evaluated in more than that. So whatever existing literature is out there, I evaluate based on those, but yes, most specifically Evaluator perk and case. I haven't evaluated The ex Zoom proposal. Hours the case paper that was in issue last, I did evaluate back. Okay. And and approximately how many tokens? Key transparency sort of proposal algorithms or proposals. Did you look at? So that would be around ten. Great. Thank you. Richard? Yeah. Thanks For for presentation. I was I have been thinking in the last few presentations. It would be great. Someone had a synthesis of all these these variations. So think this is it's a great great analysis and I think will be a good starting point for further refinement working group. This is a comment not another question. Sorry. But I I just think as we look forward to hopefully eventually triggering and working group in this area. Think this this analysis that it shows done should be a guide and that we are gonna have the working group till up a single thing. And so wherever there are choices here about what we get property and property be willing to make choices and this would be good. So degree, we can make those choices upfront and turning stage that's obviously better. You know, if first cases where need to figure out how hard something is and defer we should do that deliberately. But I I think this this is, you know, a nice framework for for kind making decision. So probably. A follow call to to figure out what the right set of properties is for the thing that is working? So do want So I see a question in the chat from Daniel. Should I respond to that?"
  },
  {
    "startTime": "01:20:03",
    "text": "It confusing the interaction between the V and the user identity can the user know that the only keep published associated with their identity is their actual key. So that is an great question, and that's why the abstraction which differs from the thirty certificate transparency. Is here this is an authenticated dictionary obstruction. It's actually very important to have uniqueness. So basically, you cannot proof membership and non membership of a certain point at the same time. By the correctness of the system. So, basically, on a username, if you compute and you can prove the v was completed correctly and you prove some that you you open the commitment to that path in that tree and prove something. You cannot prove another statement there. I don't know if that answers your question daniel. It sounds like you have answered for it don't understand it yet, but I probably need to read more. Thank you. Okay. Any further questions on the whole set of presentation so far. Okay. So this Yeah. For listening comments. I I I would do the overall impression I'm getting here as a you come of the space is that we're probably gonna need to identify a subset of the overall functionality that is in systems like para like the zoom system. We're going to to standardize. So we'll need to find a cut point team. The thing we're gonna standardize and, you know, which which parts are in that and which are, you know, special to the Yep. Things like like the gym system are repair."
  },
  {
    "startTime": "01:22:04",
    "text": "Okay. So There's a poll here. We're just checking in making sure that we we think that the problem statement is still on the right track based on the feet based on seeing is presentations. So in ideal world, all the presentations have clarified the bigger picture as opposed to getting you more confused. That's basically the high level question. Question we're asking. Okay. We'll give it thirty more seconds here, but this is looking very good. Okay. I'm gonna go ahead and end this thirty four to zero so thank you. And thirty seven. Great. Okay. Okay. Okay. We'll queue up brendan slides here. Wait. Yeah. Let's do. Yeah. So we have somebody in the queue here. Okay. So quick question from Okay. Bit. Alright. Chairs are feeling slightly optimistic. So we'll ask a question about do you think that should this work be done in?"
  },
  {
    "startTime": "01:24:13",
    "text": "Okay. We're at we were at thirty five Zero. I'm gonna call that strong. Thirty six to zero I'm when call that strong consensus. In the richard do comment. The. Okay. Alright. So with that will go to the last presentation from Brandon where It's basically a straw man on a starting point for addressing the proposed problem. And two parts. Yeah. And this presentation is sort of split into two parts. They're the first two slides which are more general. About kind of talking about the problem. And then this then the second half is is a specific way to address that. As was addressed in Brendan draft. Okay. You've got the floor printed. Okay. Well, thank you. So yes, this presentation is on traffic and key transparency which is the individual trap that I wrote. This has meant to be My best has that with a middle ground and protocol for key transparency. Would be. So keep that in mind but especially saying presenting team, I at least in my head, everybody is agreeing with me and not even along. So if you tone agree with me. That is something which is"
  },
  {
    "startTime": "01:26:00",
    "text": "valuable to share either here or potentially on the key trans us because I kind of do expect this conversation to spin out. But Yeah. To start by introducing the basic model that I'm it makes sense. What we have in mind is a between a client and the server, essentially pretty similar to a key value database. Where the keys are potentially user identifier and values are essentially arbitrary information about users account. Mean, ideally, there's a public key in there, but it can be any by string that you want. Can send submit search requests to look up the value of the key. Or complete requests to change the value of the key. I can also do something called monitoring, which is basically a search, but it's optimized so that users can repeatedly look their own account with the understanding that pay or not. Actually looking up their own account. They're just trying to check the nothing has changed that their permission. And importantly, something that's not mentioned on here is a transport layer. Traps night. Specify a transport layer. That although it does that's an eight four hundred four protocol messages so they can be encoded. But we generally assume that operations are happening within a broader application layer protocols. So we can let the application layer handle things like user authentication and limits and access control and all of that stuff. And we can just assume that if we send a request, and we don't get a response. That the application layer are blocked it and ideally also told the user why it was blocked, you know, like, maybe an application only lets users look up keys for people that they are friends with. So if user for to look at the key for a stranger, the service provider can just drop that Kt request until the user, like, hey, stop that."
  },
  {
    "startTime": "01:28:00",
    "text": "I also made a choice to try to avoid out to communication if it's really necessary. So says the user generally only needs direct communication with the service provider. The reason for that is because it can be pretty hard to get strong security guarantees from things like out of band communication. Like, if you think back to the qr code scanning screen. That I mentioned from my first presentation. If nobody does the qr code scanning, then you don't actually get anything from having it. Yep. So you can have maybe the scene you from, like, client declaring Whisper or like, gossip that silver like Wi f or Blue shoes. What you're not on the same wifi? Has anyone else these step. You can't gossip it with them. So because this would be a standard. I think that you would want the security to be robust in a wide range of scenarios and trying to kind of avoid how to bank communication does help with that. So that's the model p design. But I think makes sense to stick to our grouped into some different categories keep boring non controversial design goals are Number one, we want efficient verification processes in small state like this should not be something which is a drain on users devices. Also, we don't want also we want to avoid country geographic algorithms that don't have a straightforward path to be posted one. I'm secure because we don't want to have to read you all of this work in a couple of years. On the maybe interesting side? I would like new entries. To be added to the log immediately. Normally in systems like this, it is typical to do patching. So a user would submit a request to change their key and then the server waits to patch it with a bunch of other changes to the tree at the same time. This internally make some things easier for the server, but from the user's perspective, every time they change their key, they have to wait an hour."
  },
  {
    "startTime": "01:30:00",
    "text": "Before the change takes effect, which is super annoying. It's much simpler user can request to change to the database and have it published immediately. That does affect the architecture of the system though, like, whatever database the service provider uses needs to prioritize consistency over availability, which means that it can be harder outages because you need to come to consensus tree very quickly if you need to add new things to it. Immediately. Put in my opinion that's worth that. On the more interesting side, I think it would be really important for a standard Kt protocol to be able to operate securely without a third party, most Kt constructions in the literature assume that there is like, a big powerful third party out there that can download the entire log and double check everything to assure users that the service operator. Is behaving honestly. But from talking to people who would be actual candidates to deploy Kt in production I've heard a lot of reluctance to actually create a third party dependency in something which is pretty court to their service because this is interfacing with their user management system. So there's reasonable worries that if you still a third party in this that the third party could go down and cause an outage for you or you might have to pay the third party and you don't wanna do that or it's just overall too much of a headache to manage. This new relationship. So of course, on the other hand, the reason that there is so much academic literature assuming trusted third party be is because having trusted third party, is really compelling in theory because you can get a lot of efficiency and security benefit So overall people tend to fall on one side or another of this trade off where either they're willing to support a third party auditor and exchange for those security efficiency benefits? For their users."
  },
  {
    "startTime": "01:32:00",
    "text": "Or they don't wanna do with a third party, and they are more so fine with using a protocol that is maybe less efficient or has some rope edges security lines. And I will talk any few sites about how I think we can manage that trade off. But something else that I wanted to say first is that this draft doesn't cover or doesn't consider metadata privacy, which is the second part of the interesting design gold well, design non calls because it's not considered. So because of that, it can potentially leak the approximate number of users in the system. And can also leak how often the specific user updates their key. So it doesn't make like, the content of the update. Nobody that's allowed to nobody that's not allowed to see an update we'll be able to see it but they will know that the update happened. So that's what you were leaking there. My sense is that maybe we can live without the extra complexity of metadata privacy, but that's not a super opinion. That's just... I didn't consider it in the structure. Yeah. So those are the design goals. Brandon, there there's there's house discussion going on in the chat. Would you like to have discussion as we go here? Or would you like to fix the whole things for? So that's we actually just got two inter information because I know where that this is already a lot of controversial content okay. And I'm gonna now give you the opportunity tl at me about it. So, Brandon, if you could go back to the previous slide during the discussion, I think that'd be useful for everybody to have that as reference. Alright. Don't know jump up at once folks. Have let me big game in the chat wants coming away. So as I good chat. Like, I think the secure with that third party audited is interesting in the sense of being"
  },
  {
    "startTime": "01:34:04",
    "text": "impossible. Like, I don't think there's really any plausible system where you don't have that some sort of third party. Checking that there's no publication by No. That's said. I think that that checking can be fairly lightweight. And if you look at Ct, you're checking consistency approach to verify there's a single linear street is a very cheap operations, and I think we could do some things some more here. But I think you have to have some external source of truth other than log. In order to prevent. Like from communicating. So I Am comfortable accepting that constraint okay. You're comfortable accepting can be secure without third party. No. I'm comfortable accepting the constraints. There has to be a third party auditor. Gotcha. I I add some some demonstrations that there's some some magic that know causes that not to necessary. Which as far as I'm know as far as I know there's Rafael? Yeah. Hi. Rafael Robert from Phoenix R d. You know, thank you for putting that together. One thing that I suddenly remembered little closer to the mic, please. Okay. Sorry. Yeah. Thank you for putting it together. One thing that I remembered when I saw that on the slide now is that really long time ago I was still working at wire, there was some discussion between wire and Google one. Transparency was sort of new. And so the... Regarding the metadata privacy. The person from Google back then told me that there would be a way to sort of prevent that? Or preventing king the the number the exact number of users wire would have had by creating"
  },
  {
    "startTime": "01:36:00",
    "text": "like fake entries essentially. So but you could only infer a theoretical maximum number. Yeah. Just putting that out there. I don't remember all of the details, but that might still be relevant. And another aspect that's probably doesn't need to be part of any future standardization. But that would be good to talk about is the the gossip that was mentioned earlier. Because in terms of security, that makes a huge difference if such a mechanism exists. Of course, it's very specific to application design choices, I guess, it depends on on the protocol you use. But since we have a now as another proposal that you have standard, they're there's an interesting dynamic between the guarantees that Already give you because there is this Yeah Guarantee on who's in a group already? And you can if you combine that between different groups, user sees. For free, you already get pretty good guarantees. So this is kind of the missing piece of the puzzle in a way. So that you can interconnect groups you're not really part of. So, yeah, I would just want to put that out there that it might be interesting to discuss that what kind of security guarantees you really get in the end when you use this system in a specific messenger. It's Daniel gilmore. So I wanted to highlight... I think maybe people are talking pass each other about third party auditing?"
  },
  {
    "startTime": "01:38:00",
    "text": "There's two ways to think about this, and I'm not sure which way each person was talking about it. And some systems they're designed with specific designated trusted third party. Ensures the security. And other systems are designed where anyone can act as the auditor. Meaning, there a third party they're not the key holder. They're not distributor, but anyone can step in and identify when there are problems. And I think what Richard was saying was doesn't believe it's possible to do this without there being somebody outside, but I'm not sure whether brandon your your slides here talking about designing system with a designated trusted third party everyone has to depend on. So I just wanted to highlight that that there's there's some confusion about have we talk about it. I do think that it's also worth us thinking about how this is and interacts with other forms of identity verification. I don't know whether we need to think about it specifically here. But Like if this existed would the peer appear, either identity any verification go away? Would there be no more clarification between peers, via Qr codes or bluetooth or whatever. And if it doesn't go away, how would a system like this or a failure in a system like this? Or failure in in the other form, interact with each other. Like, what if they're... If they're gonna disagree about what's the right key what is the actual consequence? I think we need to think a little bit about what happens when any of the system's flag of failure. If I could just add one thing to Daniel's comment, we already have this problem where we have to the extent that if you have manual verification and an authority pace verification that those can disagree already. So we've already kind of"
  },
  {
    "startTime": "01:40:01",
    "text": "going through some of the user interface cases for that in in a few systems. Conrad again from Phoenix R So while we're talking about architectural choices in terms of auditing, I was wondering if it might be worth to consider since and speculating here, but mimi might... The mini working group might end up in a space where we have federation of messaging providers in a place where we don't have one big deployments like, certificate transparency but instead, we have maybe multiple key transparency deployments for individual messaging providers or identity providers can host their own instance and then we can have a big big instance that connects them by again, return with the commitment stuff. But uploading the tree hash and kind of have another tree hierarchy on top of everything. Yeah. So how people feel about that? Okay. Okay. And listen, anyone has any more burning Urgent questions will let run continuous his presentation with the sort of detailed the details of his proposal. And we'll leave some time at the end for us to ask the big questions. Cool. Thank you for that That was good complete back by the way. So as I was talking about earlier, there is a trade between efficiency involving a third party in Kt. And the kind of operational simplicity of having a single party deployment the way that I think that we can manage this is with something called deployment notes in the draft. And they core view here is you can take a kt construction from the literature that works for single party deployments and then to find a way that you can optimize it in the event that you have trusted third"
  },
  {
    "startTime": "01:42:00",
    "text": "So this is the way they kind everyone can be happy. You can either use the base construction which works scores single parties or a you you know, have a third party you can get the optimization benefits as well. The actual construction that the draft is based on is from a paper called. Merkel squared, which was just published in twenty twenty one, I believe. And it chose it because it was one of only two constructions I was able to find that actually supports single party. And this is the one that was more formally analyzed. The good news is that it is pretty amenable to this idea because you can kind of you strip away different mechanisms from inside of Merkel square that the security that that mechanism provide isn't necessary in some use case. And the deployments that are described in the draft are first contact monitoring, which is the single party one and then you have third party auditing and third party management. Which both reflect different ways that the service provider can choose to integrate to third party into their their operation So to talk about the first one which is contact monitoring. This is what it looks like. Because it's a single party mode. You just have the one service provider that users interact with. And because there is nobody in the system to make sure that every change the service provider makes to the database is being done correctly. This responsibility ends up pulling sort of partially on users. So whenever a user looks up a key for someone that they want to talk to. They have to remember some information about what they were shown by the server. Then in the future on a recurring basis, they continue checking in with the server and verifying that what they were shown previously is still present. So this is how we verify that nothing has ever secretly added and then removed from the database really quickly. Service provider maybe"
  },
  {
    "startTime": "01:44:00",
    "text": "malicious adds some some entry to some users account. And shows that malicious entry to one of the users contacts. And neither the service provider will try to remove it at some point in which case the contact the god shown the entry we'll see it was removed, and they will be upset. Or it will stay on the database and the user who owns the key, will eventually see that it we'll potentially see that there and will be upset. And of course, the thing to keep in mind here is that if people are looking up a lot of random keys with this deployment and they're gonna have a lot of auditing to because the auditing typical view skills linearly with the number of keys that you look out. So that's the catch here, essentially. The second who it is. Third party auditing? This is one that More people are familiar with with this note to service provider does all the actual work of hosting and running the Kt server and it regularly checkpoints with a third party auditor. It's part of that ship. It will show the auditor, all of the changes that have made to the database. And the auditor will check if the changes were done correctly. And if they were auditor produces a little signature basically saying like good job. A service provider can show that signature to its users is evidence that it's continuing to behave correctly. In the event that the service provider ever does do something malicious. For example, by trained to hide something that was previously committed. And the auditor will refuse to provide a signature and without that signature users will eventually stop trusting a service provider. And what you really get here is efficiency because now users don't have to do all of this work of making sure that nothing is getting removed from the database themselves. Like I talked to about in the last slide because the auditor is doing that checking for them, so they can kind of press a little bit easier. The third mode. Described as third party management. This has meant to fit a little bit more into, like, a software as a service pattern."
  },
  {
    "startTime": "01:46:00",
    "text": "You have the manager on the right who is now doing all of the work of hosting and running the Kt t server And the service provider is really just forwarding requests from the user to the manager. But importantly, because it's in the middle of this interaction. It is still able to enforce its own access control policies. It can control it can control when new entries are added to the database because it has to assign them. So this it's a kind of division responsibility. So if you think about what you would do if you were trained to launch an attack, the manager can potentially construct the tree incorrectly because the manager is just responsible for holding the tree and building at you can actually accomplish much with that without being able to sign new entries to be added to the train. So you can, like, move things around, but you can't actually add any new malicious entries. On the other hand, the service provider can add a malicious entry. It can do that without the user permission. But it's not gonna be able to later hide that from the user. So to actually succeed in adding something malicious from adding something malicious to the database. And then hiding it from the user. These two have to include to actually succeed. And what's interesting is that you get the improved efficiency of the last deployment note because the manager this kind of acting as an auditor. So users yeah. Can know that the tree is being constructed correctly. And you'll also get a security benefit from the fact that this auditing is happening proactively and continuously. If some party in the system is behaved. It's not like you find out it in a day or a week or something you find out. Relatively immediately. One thing which is notably, missing? Is is an anonymous third party auditors. And I wanted to clear us the idea that you could have anonymous third party auditors, sort of, like, how"
  },
  {
    "startTime": "01:48:00",
    "text": "certain of taking transparency works. With this approach, the service provider doesn't have a strict dependency on a third party, they just kind of publish an Api. Let's anyone that wants to perform an audit. I actually intentionally just Decided did not to do that here because first of all, it doesn't fly out of pain communication, which like I said, before I am trying to avoid because the security didn't you get from it? Can end up being a little bit fluffy. And second, auditing operating endpoints tend to be very expensive because they produce a lot of outbound bandwidth. And also the fact that they produce a lot of outbound bandwidth in response to small request payloads. Also makes them really easy targets for users. So it's easier two bunch of Dos tech against season points and also just take advantage of the prostate. I've been taking the log or of it. Costing the log a lot more to respond to a request than it does for you to send a request. So that is why I decided to omit this? But the idea is that between these three deployment nodes. That you know, there's always something where someone can be happy. Again. That is... All that I have. Thank you. Yeah. Just to clarify that we're not asking in the room to accept this as this initial graph. This was just more existing proof that the problem is sol. One possible approach for this. So... Yeah. Thank you, Brandon. Okay. So it sounds like we didn't have that that there were two of the design goals where there were"
  },
  {
    "startTime": "01:50:00",
    "text": "there was a disagreement and The first was what the role of third party auditors would be, whether it's, you know, required not not not there nice to have. And the second was to what extent whether metadata privacy protection is sort of an extension you can add an add on later or whether it's something that has to happen. So Modular those two those two things that are being debated The people feel generally good about the rest of these design goals. I'm gonna go ahead and put up a if anybody wants to jump up at the Can ask a question or clarifying question or rephrase it or whatever go ahead. But I don't hear anything in a couple of minutes, I'm just gonna put it up on the. So Yeah. I was just gonna clarify my earlier go go ahead. Thanks. not third party auditing and light what get she said, I I think because caught captured my comments more and more accurate than I I did I was presuming that there was some scheme for you know, by way more or less Ct like auditing where any any third party could act as an auditor entrepreneur. You know, performing a standard set of computations. Not there needed to be some third party trusted by all people. So I think with with that flavor of third party auditing is when I was envision we would need here. And while I got my makeup available see I think this are probably a non exhaustive service design we'll probably need a few more for example, making some design decision issues. Presentation."
  },
  {
    "startTime": "01:52:37",
    "text": "K. Twenty seconds. Okay. Ten more seconds. Okay. Would the person who who voted do not raise hand, wanna make a quick a quick summary of their objection. Okay. Feel free to make a comment on the list but that's shows quite good quite good interest. I think we we're on the right track here. So Alright. So Obviously, we need to work on the chart and we'll do this on the mailing list. The question we would like to ask now is who's going to participate in working on the problem. In the working group of it is formed like editing documents commenting on the mailing list through reviewing documents. Participation and the broad sense of the word? Yeah. He's stepping."
  },
  {
    "startTime": "01:54:45",
    "text": "Okay. Twenty more seconds. Okay. That shows some strong strong willingness to participate. I'm gonna close this here. Anyone go ahead read it? So I think Alicia posted to comment in regards to said that her audio wasn't working. It seems to me in the critical dependency on this auditing, which remains open is a concern. So yeah we know. We know we need to get consensus on on this point. Okay. We're gonna invite Roman at the microphone."
  },
  {
    "startTime": "01:56:04",
    "text": "Hi, everyone. So first, I wanna say kind of thank you for this conversation. And I wanna say I think we have something very novel here. To my knowledge, this is the first time we've run a above where all of the proponents are remote. We have folks on a room and others participating. So I think that's great that we have energy to bring kind of new things into the. With a lot of different with a lot of different dynamics. Thank you to Thank you to Brendan Jazz Antonio and asia for for bringing this material to us having this conversation. Really, Rohan, thanks for grinding in and polishing it, making facilitating our conversation. I think we've had a great chat here. So top line top line as as the chairs we're saying. I think we have a strong signal to do work here. There appears to be interest around kinda of q. We have volunteers to be to be working on these. I think we have a sense of some of the design goals we wanna hit. It's clear we got a polish a little bit more. So to me, that means kind of next steps, we're gonna go to the list. We should probably create a a charter which tries to be very very very much more concrete about some of the things we talked about and we're gonna have iterate from there to make sure that we we have it right. But the the strong signal coming from this meeting is that we have interest in this and we really should figure out a plan of how to do work with that in the Idea. So please join the mail list if you haven't been there. And in I would assume in the coming weeks be proponents, the chairs in the and then I will kinda work to get you something to look at. Thank you so much for coming and thank you for your feedback. Thank you everybody enjoy your cookies."
  }
]
