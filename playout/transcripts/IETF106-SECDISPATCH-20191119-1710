[
  {
    "startTime": "00:00:05",
    "text": "you must have liked that so I\u0027ve uninstall spyware Oh they\u0027ve marked me as untrusted hey maybe maybe Amy just doesn\u0027t care [Music] maybe over here so you can please take your seats everyone this is sec dispatch we\u0027re in dispatch some stuff securely you may notice that there\u0027s some different faces on the stage here Kathleen was unfortunately unable to make it so Nancy is filling in her place and we have one brand new co-chair Francesca pollen beneath can we have a round of applause for her please all right so note well is the same as usual please note it well including your obligations with regard to a PR and disclosures as a reminder this is our process we are not here to adopt documents if you\u0027re not here even really to develop technologies we are here to figure out where work goes so should it be done in an existing working group dispatched to AV sponsorship or you know should we not work on this at all we have this range of possible outcomes so keep those in mind our goal for each of the presentations today is going to be to come to one of these conclusions so as you\u0027re watching the presentations think about which of these conclusions might be appropriate here\u0027s our agenda for the day we\u0027re in the first slot right now we have five topics looking for dispatch we have a bit of an overflow slot because we are a little short on time I\u0027ve been I think has opted out so we have one there Brian Campbell who didn\u0027t have a draft so we got put an overflow and is kind of looking for interest there so any agenda bashes before we launch into "
  },
  {
    "startTime": "00:03:07",
    "text": "this agenda all right dr. Paula okay everybody welcome to sec dispatch I\u0027m max Farah I work with Kaiba labs and I\u0027m going to present them about addressing public key algorithms uncertainties with composite crypto this work has started a couple of years ago is in collaboration with other companies I can trust in trust other cards Cisco Systems I Zahra and desert so what is the problem here well you know with announcement about quantum computing and lots of investment in this technology we leaving it here of uncertainty specifically in cryptography we suffer a problem where algorithm that we use today might fall apart right but this is a very uncertain period we don\u0027t know if that happens and we don\u0027t know if that is for example schemes are strong enough so possible workaround would be to use hybrid solutions where you have multiple algorithms that can be used together to secure some data like certificates some minutes and some initial experiments for the Poynting some quantum resistant algorithm have been published I sent an email before in dispatch meaning list so just keep in mind this these results is not for all the algorithms these are algorithm that have quantum keys that are relatively small but still it seems that the situation might not be dead that tragic so why we are here well I work in in cable and we use a lot of certificates for many different things and it\u0027s use is going to be just increase with the new platform that we\u0027re going to deploy for a 10 gig and one of the questions that we\u0027re facing today is is it possible to protect our infrastructure infrastructure in a transition period right so what applying what could be could be said as the further algorithm agility so are your peaky eyes going to be secure in next 20 years or 30 so we have this problem we have to protect ourselves in a transition period in with that\u0027s full of uncertainty right there are cool currently different solutions for this and we\u0027re going to go through through them these solutions being discussed on in the ministers and some consideration are useful to make so multi-chain so using using multiple "
  },
  {
    "startTime": "00:06:08",
    "text": "certificates using extensions in certificates to carry additional keys and signatures or using composite crypto the one that we work on with all these other companies all these are have some merits and some drawbacks and let\u0027s go through them so using multiple certificates seems a very easy solution great for negotiated protocol I can select which one of the certificates traditional one or post point one I send to the client depending on these capabilities so I don\u0027t have to transfer the keys all the time right and this is a problem because these keys are big and if you put in certificates then for example for TLS this the the amount of data in the first flight will require multiple round trips but in this case you can design your protocols and the decide where to transfer these big keys waste it down they downsize well now you have multiple certificates so if you want to protect the same data you have to change the protocol to allow for multiple signatures to be used and for non negotiated protocol might be a little bit harder you know the example the user example for as mine where you don\u0027t know if the client supports or not the new algorithms and however the other problem would be you know when you have multiple certificate you apply multiple to the same data how to link these identities in multiple certificates especially if your PC is distributed might be a problem and definitely complicates that the operation size of PK is a second solution I was adopted by ITU and uses extensions in the certificate I was also discussed here names and basically what they do they use an extension to put additional public keys and or signatures so that the certificate is backward compatible there\u0027s no critical tension so it can be ignored by clients that don\u0027t know how to process it however is very backward compatible so clients don\u0027t even know that they are missing something so it could be a false sense of security requires change to to the protocols to validate multiple signatures and of course in this case the problem of transferring the keys is present because the large keys are tied to the traditional ones so you cannot separate them probably it is something that can be done there but it would complicate a lot the schema and so a third solution is the one that we\u0027ve been working on in the past couple of years actually and we try to leverage the beauty the beauty mechanism for a greater agility that is in certificates and all pica-x data structures and how we do that so we define a new public key algorithm so a new ID define the encoding encoding "
  },
  {
    "startTime": "00:09:09",
    "text": "rules and processing rules so the trick here is that instead of using a data strategy the data structure that contains the generic key and then we say now this is a sequence of generic data structures and this case allows you to extend the use of public keys and signatures in all the pkx data structures I said before and and therefore provides compatibility with existing certificate processing rule in the sense that one composite key generates one composite signature and this buys well with protocols for example what are the pros of this solution well you can drop in any of the algorithm that I already defined so you can imagine a composite key using RSA you see the SI n a post quantum and you have different classes of devices that will use the different algorithms they support for example can be extended to combine not only just two but three or four depending on what you use cases and it\u0027s not just related to quantum think about this as a tool that can be used anytime you have this type of uncertainty you don\u0027t know if how much you can rely on the old algorithm you don\u0027t know if the new algorithms are ready for you so you can try to combine them and of course by using one signature one public key setter is compatible with also revocation information so you can do OCSP you can do CR else you don\u0027t have to define anything else the downside backward compatibility requires the support of a new algorithm identifier this is not new we do that all the time when we deploy a new algorithm so it actually goes into the PKI operations very well the downside here is the large keys are sent every time because they are part of the certificate so you cannot really excite them from there one note that the ITU just published or was was published on the meaning is the X 5x by 10 this that use a similar approach so we hope that if some work has been will be adopted we can try to limit the in competitive incompatibilities there I hope that we can do a good job so what\u0027s the current status of the discussion of course messages have been a same thing with many different lists dispatch lamps and pica-x to try to gather some some feedback of course mix the reaction as usual so however one of the things that came out fairly clearly is that this is a problem that needs to be solved many people noticed that because of the time frame that we\u0027re looking into the sooner we start to work on this is better logic I providers I work in an industry where we leverage "
  },
  {
    "startTime": "00:12:09",
    "text": "a lot of certificates in the billions and other suppose like desert and others VSPs they actually want to work on this because they want to be able to have at least one solution that they can deploy other proposal may emerge that that more towards let\u0027s reinvent the wheel I\u0027m not saying it\u0027s not possible it\u0027s always possible I would like to have one solution that is easy like the one that we propose right away and then we can look and how we can optimize ok we can have more optimized solutions in space largely we not heard from the sales community about around this idea mostly because we didn\u0027t engage with the community but if you guys want to start engaging and telling us what what you think of course we are aware of the fact that the large large key is and the problem for for performances here however and this could be one one tool that doesn\u0027t require many changes in protocols today so I mean ok conclusions does mean discussion is a problem that is we should try to solve within that composite crypto is a possible tool not the only one but one simple tool that we can standardize and we have to two IDs one is for the problem statement and overview of the solution space and the other is the solution that we try to propose question yeah well I question are we in the discussion phase now Richard so I can\u0027t speak for other applications but it\u0027s a little hard to understand how this brings a lot of value to at least like the web PGI story and the reason for that is that on basically we have two choices so somet right right imagine you have like a situation where we are now we know there\u0027s not a valid upon a computer and then someday that we evolve a common computer perhaps and we\u0027re trying to get past that transition point and so on now we can either accept like non compositing signatures or we cannot that is that standard or assisted insurers and easy signatures or we cannot if we if we do then the vast majority of servers in the world will only have those signatures and when there\u0027s a chronic computer what we squirt conversely if we don\u0027t then we\u0027re basically forcing everybody in the world to get Capas integers which doesn\u0027t seem super likely and so as a contract achill matter I don\u0027t see how to like use this in like a web PKI environment um so it\u0027s like not like I\u0027m tal I said like telecine used everywhere so like that I\u0027m sort of some cos environments was useful but it\u0027s like hard understand like in the web environment this works there\u0027s been some experimentation in the TLS web context with hybrid key exchanges could you maybe and make sure "
  },
  {
    "startTime": "00:15:10",
    "text": "you Benjamin has some things to say about this as well yeah concern that situation would be helpful right so as you say jealous husband working at hybrid key exchanges on the avange the hyper key exchange right is that it\u0027s is it it doesn\u0027t require the client enforcing anything it\u0027s just like mutual negotiation and it is that its defense now against quantum computers in the future um but like like the general my general concern about about anything along these lines is is that in order for it to work properly in like real-time environments you have to actually enforce it\u0027s a requirement that post constants are all time so the whole thing falls apart and so like I don\u0027t see anybody doing that like I\u0027m in the mass environments now in non real-time environments like not saying it\u0027s not reasonable put it like a real high environments like a well I respectfully disagree with you I think that this solution is very important for specifically protecting keys that may be pulled remove to factorization so not not so much the server sides but you think about CAS route the route CAS that we need to protect so by by using this this approach usually you can be verifying this type of algorithm is a lot easier than signing so with software updates you can actually verify and protect the chain I don\u0027t think there\u0027s gonna be that much of impact or you could think about solution where you deploy CAS level type of multi algorithm and and entity just using the the crypto that you want to use at that time because at that point you can is easy to revoke one CA and whenever the the algorithms aren\u0027t gonna be broken and you know that you can actually if you want to revoke a CA and then spin up anyone I think I misunderstood my ecosystem point which is yeah which is that either the browser accepts classical only injured or does not and if either yes supports a new I\u0027m seeing it signing algorithm or not no no it\u0027s the same situation that we have if you support RSA or you know no it\u0027s not because sitting here is that someday in the future all classical algorithms are broken and now I cannot trust any signature make a nice neutral a the classical algorithm and so now the date so like if you want me to flip that switch or you want me to turn off all class of algorithms and I haven\u0027t already preceded the environment with everybody having non class of integers and I just destroyed the web which is exactly what happened we try to search over Mashal one - ah - and so and so so in order to actually make this work or we have to do is we have to go forward by requiring everybody to have post quantum signatures on every certificate or and then only once that is done then are we like well we\u0027re gonna stop trusting classical always integers and so I don\u0027t see like I don\u0027t see us doing that I don\u0027t see in the be ours requiring that and therefore like I\u0027m saying back partners right so I think the point is taken the in real time situations like the web this is there are challenges "
  },
  {
    "startTime": "00:18:10",
    "text": "that might so this might be more suitable to things like software update or yes absolutely yeah I\u0027m just understanding answer the question that tell us I think that for software update clutch applications like this this kind of thing make sense um although I do wonder in those cases why bother with hybrid why not just use basically why not use hashing interest which you all grier find you so we have two minutes left line is closed after deke after Sean so please be brief David Benjamin so similar to the like also on the telus side of things when we were doing the the there was some talk of the hybrid key exchange stuff and I think one of the things that came up was how to do the encoding do you add this like generic Combinator thing or you just allocate code points for some pairs and move on with life and the preference I well my preference at least was overwhelmingly for it just allocate some code points for pairs or triples or whatever you want and move on with life and I think this is in the wrong direction here where if you want to do a hybrid thing building these combinators and saying oh if you have subsets and it\u0027s okay and all this stuff just adds like a whole lot of complexity which bleeds throughout the entire system we went through a lot of trouble until s13 to simplify the signature algorithm negotiation and it\u0027s not clear to me this generality actually gives you any it does anything useful for you because at the end of the day if you\u0027re if you\u0027re trying to if you if your goal is to do something where like a client that doesn\u0027t understand C can still accept an ABC like only understands a and B will still accept an ABC signature like it\u0027s going to go up to some trust anchor and if that if the clients like either the client if the client has an ABC root in its trust anchor set if the I could but if the client trusts an ABC trust anchor like presumably it knows what C is so that scenario seems kind of bizarre and the cost of all of this stuff is that we need to like be able to express the Combinator isn\u0027t like the the verifiers need this like complicated matching thing as you know in the slides we have to move the policy into the crypto libraries which is actually the wrong direction because the crypto libraries are fairly low-level and don\u0027t really know what\u0027s being used like I don\u0027t see the benefit of this read carefully the draft I think that it will answer most of your questions pushing in the crypto library actually I think is a very good idea in a sense that operationally wise for PK eyes you\u0027re talking about TLS but we I\u0027m correcting my PKI I need to protect my clients and I need to protect my infrastructure so my consideration for now is I need to protect against factorization all this consideration for TLS they are very important and they have their place I think that there might be some other solution that we can come up with that are optimized for these use cases like for TLS for example specific algorithms like some experiments I\u0027d try to do I think we should have a generic solution doesn\u0027t complicate the operation of actually for "
  },
  {
    "startTime": "00:21:12",
    "text": "application layer is easier compared to multiple certificates or multiple keys as I show before protocols don\u0027t need to be changed this could be a tool that you can deploy whenever other tools are not available or don\u0027t fit your use case because it\u0027s very generic so you can deploy it easily other optimized solution that would address the problem that you that you mentioned for TLS of course it\u0027s possible and it\u0027s part of the proposal here let\u0027s try to work on a solution composite crypto could be one others can be come out from above for example or for a workgroup or other things but it\u0027s a problem that we need to address okay I\u0027m gonna cut it right here because we\u0027re more than close to three minutes over so I think this work seems to be more appropriate to lamps so max I suggest you keep this lamp senseless here and if you sent light back the lamps with back legs okay yeah I think we\u0027ve gone through this with some other stuff in the past where lamps wasn\u0027t sure if other folks if there was a broader applicability and they\u0027ve bumped it up this Petrus I don\u0027t seem scoped to that and I think that the conclusion we have here based on the comments from the floor is that this doesn\u0027t it\u0027s not really appropriate to you know broader situations like TLS I\u0027m so Supriya to consider in that narrow scope does that seem like generally okay two people will confirm this I\u0027ll tell you what let\u0027s not have further discussion we will confirm this on the list the draft resolution to be confirmed on the list is to dispatch this two lamps thank you well max you\u0027re the next presenter okay I\u0027m max steel with CableLabs so this is another another presentation about the cost of relocation information delivery for public infrastructure where do we where do we come from so one important step in my reading certificates is check for the availability of replication information so if there\u0027s compromised or something that you shouldn\u0027t trust and it simply period now the deployment of infrastructure comes with some prices attached to it mostly because OCSP doesn\u0027t scale for very large PK eyes and costs are directly proportional to the size of the certificate population and you know we worked in the past with different techniques to try to optimize the deployment of a CSP responder especially for high frequency environments where we pre computed responses and we deploy and deliver their responses with through CD ends and "
  },
  {
    "startTime": "00:24:12",
    "text": "I want to write three considerations that that sparked this this work and the first one is the larger the PK I said before large apki they higher the cost of providing good difficulty for section is in general at best practices today we preside a once posed for assertive that is in period and in particular what we notice is that what we sign over and over again is here there\u0027s no replication information the only difference is the serial number but it\u0027s the same type of signature and think about the situation for CSP large CSP is where they manage hundreds of thousands of different CAS each of which can have millions of certificates especially when we when we think about one of the last consideration can we do something to optimize for the most common case where the certificate is valid so there\u0027s no additional information that we actually want to provide the second consideration is about when you ask the status of certificate usually what you really want to know is this certificate they all chain is valid to something that I trust can we limit the number of needed round trips so some discussion went on the meaningless about this and you know some people pointed out that the OCSP since the 2560 allows the responder to attach multiple responses even if the client doesn\u0027t ask for multiple for multiple requests but this is never been used to convey and this the full saddle of the chain because of I think some some trust issues that we\u0027re going to to look into a little later but one of the point that I\u0027ve tried to make is that maybe we can do something to provide the full chain information to the client in such a way that the client can really trust that information this the third and last consideration is that in the AEF we focus on you know the internet PGI where the trust model uses mostly certificate on server side and other techniques to authenticate the client side but you know recently we\u0027ve seen the born of new environments for example IOT is but industrial and the industry that I work with cable where we have huge big eyes or PK eyes tend to grow in size and in this in this environment sky insider vocation is even more costly and can drive up the cost of certificates now what how do we address the distribution of location information today mostly through CR ELLs or OCSP and other proprietary metals but I\u0027m not going through that because this would be infinite so how do we do with CR else well er else is a list of authenticated and serial numbers that\u0027s signed by the CA or delegated a CA and says that these "
  },
  {
    "startTime": "00:27:13",
    "text": "certificates should not be trusted anymore for different reasons and there\u0027s a sentience for that the program is CR else and this is why we actually shift mostly towards P is that the size of the CRL is fairly unpredictable tend to grow beyond acceptable sizes and you know it grows with replication event and shrinks with exploration events so it\u0027s very unpredictable it was not it on the main list that we can use the issuer distribution point to to bound the worst case scenario however this is a study partition as we noticed so maybe you know some approach to ranges could fix this problem so others be responses we have to calculate every single SSP response there\u0027s a problem in conveying the full chain here because you know CSP response today could be signed by the CA and if you try to say that CA says this certificate is not revoked I\u0027m not revoke and my parents√≠ is not revoke probably is not the great trust model but we could potentially attach SSP responses signed by by a responder wrapped in the chain and so limiting the round trips just to give you an example of the proposal the proposal here is to do range queries in in a PTI this is a extreme example by an API that you have 11.5 million certificates and only 3-year vacations you know with doing range queries you have to sign the three different certification plus they intermediate between them so with two x+ 1 signatures you can provide the same information then instead of signing 11.5 million certificates it\u0027s an extremely simple but this is the type of optimization that we\u0027re looking for so a discussion on the list there\u0027s been agreement that we have these limitations today there\u0027s no really way to go around that we have a mixed approach to do the propose right not not everybody agrees on the proposals and this is perfectly fine we\u0027re looking to spark the discussion and maybe to see if there\u0027s some work a bit can be done there - - less comments some requests for some figures how can we save in costs right probably the real dollar costs will be difficult to provide because this is usually secret sauce but we can provide the ratio of revolt against population because this this solution actually changing changes one property they the costs are not related to the Pope active population in this case but I related to the revoked entries in the population so far we received very strong feedback from major csps did you cert and committed to say well we really like we "
  },
  {
    "startTime": "00:30:15",
    "text": "really think that we should work on this we like the idea but and we will deploy the area in our industry as well we really need to find a practical solution okay so the kickoff discussion here and again keep this focused on this dispatch outcomes I think the chairs would propose that this piece of work looks about like this the right size for something like a small focused working group that seems not not like something that fits as an existing working group and probably too big to be something ad sponsored um so that\u0027s that\u0027s our initial proposal with that please discuss sure it\u0027s a little part of the discussion metric any protocol engineering because like it seems that is really obvious solution this problem doesn\u0027t require much protocol engineering which is do merkel signatures myrtle trees and then you would like have you basically no one\u0027s integer and then solution and then and all you need ISM is that way to panel that so I\u0027m not gonna need working group um um but um so I guess III liked it I liked the season where evidence is actually for her problem before like spam for working before it well yeah yeah just queue up the rest of the folks you might comments on this the important question here is is there work to do and if so is it right I guess I get right so I think before I would sign on for the work to do I get to see some evidence that actually was a computational cost this seems like actually a pretty low cost based on I knew how CAS operate so I\u0027m a little surprised that this is considered to be a big deal filmmaker I this is I support this work and I actually proposed this exact solution in 98 when we had the issuing patent distribution point patent dispute issue to respond to worker yes lambda the Macaulay revocation trees or coastal revocation trees another approach I\u0027m not sure I think we\u0027d have to consider which one but the other thing that you might want to consider is the work that I did with Rob straddling which was on crl compression you can actually compress CR ELLs and if we\u0027re going to change the format maybe what we should do is to do one change and so that might be worth thinking as well if we\u0027re going to do it I think the natural place to dispatch it to would be lamps you\u0027re ammonium Qualcomm I\u0027m at since you\u0027re coming from cable labs I\u0027ll mention what we did for ATSC which is the over-the-air television broadcast and it\u0027s commonly used in North America and other countries we actually used OCSP as is but we staple the OCSP with possible responses to brought to specifically broadcast emissions so if you\u0027re interested in for instance of "
  },
  {
    "startTime": "00:33:15",
    "text": "channel a you set your tuner on channel a the client only received only receives the OCSP responses that are related to the certificates associate with channel B if you want channel B sir - responses you go to tune to channel B we were able to use OCSP as is just use it in the staple in the way was intended to be for OCSP stapling I think I don\u0027t think that you necessarily have to change OCSP for that I think it\u0027s more a question of how do you actually narrow the amount of responses that the client is actually interested in and allow the client to discover places to obtain those responses rather than coming up with new signalling all right Sean Leonard Penang go Inc so having read this I do support this work and I think bless your heart for trying to continue to improve OCSP multiple times I guess and coming back to ITF for for this kind of work what I think is different and is very valuable is for those who are skeptical of this work to be convinced otherwise is to see the data right in practice the telemetry of how much time resources energy whatever round trips can be saved from you know the different techniques that are being proposed especially whether its web PK or other PKI deployments you know that that will help I think motivate a lot more support for different use cases and different kinds of data structures so I\u0027d love to see that data you know from what we\u0027ve seen in the field from what other from what practicing providers can give as part of this work yeah we have like less than 90 seconds so be quick we work at authority and we make some IOT system also and we really want to kind of investigate concerns like we did he wanted kind system because like current to chef is not Scarab righto and we having very big problem so I really support that one it\u0027s that just next Nick Sullivan CloudFlare we cash a lot of the webs OCSP responses I don\u0027t see a need for this this work I\u0027d like to see more data to justify doing work like this i OCSP seems to be working fine Daniel Kahn Gilmore I\u0027m curious to know whether you thought about how this interacts with OCSP stapling are you expecting to ship the range in the stapled region during the TLS handshake and if so what does the client going to do who doesn\u0027t understand this when they see a range are they\u0027re gonna is it going to break the stapling I\u0027m not sure you need to answer that question right now since you have negative 60 seconds but it seems like a potentially problematic situation this is potential work for a work group or you know collaborating on finding "
  },
  {
    "startTime": "00:36:16",
    "text": "solution so yeah I think it sounds like nobody objected at least to this idea that if if we\u0027re gonna do any work here then it should be in a new small working group I think we can have some discussion almost to confirm that there\u0027s energy to do work here at all so thanks max I\u0027m gonna call it Nick Sullivan next if you that\u0027s alright we\u0027ve had a last-minute agenda - propose to the chairs directly I\u0027m just gonna swap the next two proposals so we\u0027re gonna do a nick and then Justin that\u0027s alright okay yeah the conclusion on that last one is that if we\u0027re gonna do anything it\u0027s going to be new working group material and we\u0027re gonna confirm whether there\u0027s to be a new working group on the mailing list please Roman and I would add there was interested kind of additional evidence if it could be provided to help with the discussion yeah thank you okay so privacy posts this is a technology that was presented previously at perigee and I\u0027m gonna go into what it is and what the interest is in it so it privacy pass is a lightweight zero knowledge protocol for the web the motivation here is wouldn\u0027t it be nice to have some online equivalent to cache something like talking to one service and being issued some sort of credit that you could spend at another service or such that it\u0027s unlikeable but the person who issued the credit to you is unable to know where you spent it and this would be something that be nice to have and to work an internet scale there\u0027s a specific problem that this solved for us and I\u0027m gonna go into this so I\u0027m just some sort of physical motivation here to to how this could potentially work imagine having an envelope writing serial number on it adding a piece of carbon paper in there sealing it up and sending it to an issuer that would sign the envelope with saying this is legal tender without knowing what the serial number is you\u0027d open it up and then you have legal tender that you could spend somewhere else so the issuer does not know the serial number and it\u0027s something that you could use use somewhere else so privacy pass is essentially the digital version of this this idea has been around since the 80s but this is something that we found more recently have updated to use I guess more efficient cryptography this is a paper from pets that was published by myself and a couple co-authors the solution here or the problem space here was for solving CAPTCHAs specifically solving CAPTCHAs on multiple different websites so that your experience of solving CAPTCHAs is is that you see fewer CAPTCHAs so you can imagine if there\u0027s a hundred different websites they all have the same CAPTCHA provider and if you "
  },
  {
    "startTime": "00:39:16",
    "text": "solve a CAPTCHA on one website you get a cookie that proves that you solve that CAPTCHA this cookie is not transferable from one website to the other without leaking your identity so what would be nice is to be able to get some anonymous proof that you solve this CAPTCHA and be able to redeem it to bypass another CAPTCHA so this is this is the flow then this is how Club privacy pass works so you take a token you blind it up you issue you send it to the capture provider they sign the blinded token send it back to you and then the next time that you encounter a CAPTCHA you unblind the token and you send it to the capture provider and it\u0027s able to verify that this was a valid token but not know which site it was that issued it or who the issuer was and so there\u0027s two constructions underneath that make this possible blinded RSA this is the original ecash scheme this has the feature that it the these tokens are publicly verifiable so one party can issue and any party can verify the version that we came up with for privacy pass is called vo PRF this is some this this is actually currently being looked at at the C FRG that\u0027s been adopted as a working group item to define how this works it\u0027s a oblivious pseudo-random function with verifiability essentially the only difference with blinded RSA is that it uses the looked at curves it\u0027s more efficient and it\u0027s verifiable by only the issuer which is a slight constraint that gets you the performance now privacy pass itself has running code we have the codes open source it\u0027s oh I have one mint okay great um so this is there\u0027s a firefox in chrome extension this is actively used by over a hundred and one hundred and thirty thousand people per day per week half a million redemptions or so this numbers probably gone up quite quite a bit and we recently released a new version and so the reason I\u0027m coming here is this technology seems to be useful more generally and there\u0027s been a number of different applications to this that have popped up specifically with within the brave router browser doing ad confirmations the privacy sandbox proposal from chromium is interested in using this specific technology there\u0027s Facebook\u0027s also proposed something similar and the Tahoe L AFS project has has committed to using basically the exact same construction so the idea here is that we would standardize this and go forward and it would be useful in multiple view of these applications okay so I know I\u0027m sort of a little bit over or not okay okay great um so I\u0027m almost done here um so what does the scope of work to be done what am I asking well "
  },
  {
    "startTime": "00:42:16",
    "text": "defining the basic privacy protocol in terms of HTTP headers how do you integrate the crypto and if there\u0027s specific features to the use cases listed can we support those and so perhaps this is a mini working group sized amount of work maybe a full working group sized amount of work it\u0027s not clear this is why we\u0027re here at dispatch if we were to do a working group there\u0027s this is sort of the proposed charter essentially tokens are we shooting groups these groups form an anonymity set any issue token can be confirmed to be part of a group and can be submitted to be verified and the verifier can only prove that this was one of the tokens of the group not link it to the specific issuance and so what we\u0027d like to do and what is defined in this in this draft which is posted on the list is to specify protocol that provides this mechanism with the security properties and how to use this in an HTTP client server setting it\u0027s not a goal to build an interoperable federated system with multiple token issuers this is a basic protocol and there is one additional request to define a way to embed a small amount of metadata say one bit into the token so with that our students so I remember talking to you about this and one of the differences is the fact that the original proposal could be verified offline and this can\u0027t right that\u0027s correct so I was wondering whether that could be brought is there a is there an like a way to bring that back I\u0027ve got use cases which this would be perfect for but offline verification would be really really useful yeah I I believe that should be in scope having a publicly verifiable and a online issuer verifiable version I think those those are two very solid use cases and we\u0027ve had requests of both perfect thank you state your name for the minute sorry late for wants one Eric rola thanks for bringing this is cool stuff um I think you know I think you\u0027re right to think of me working for the right thing there\u0027s enough there\u0027s enough stuff here that probably it can\u0027t just be like like an HTTP extension I agree with Leif it would be good to have offline use cases part of the as part of those part of the the Charter um which I think actually brings us to the point about were the majority in this as like I\u0027m certainly I assume he\u0027s not using his performance and and and precise yeah RSA there was the reason we searched from RSA to vo prfs was performance and the fact that we didn\u0027t need offline right I I don\u0027t see why you wouldn\u0027t be like support both right well so he wants to do BLS um what\u0027s the trick lighting um so um I think the I would I would "
  },
  {
    "startTime": "00:45:17",
    "text": "caution against BLS until until sure yet I didn\u0027t foresee FRG but again so I guess the question the question I do have is is there any new crypto engineering here that we\u0027re gonna need to run trip for CFR G my understanding is V up here ups are already being done and that we understand how to do the there one or two bits of metadata with scheme without having to like and then a bunch of these are knowledge proofs and stuff like that right yeah so the hope is that this would run in parallel with the CF RG process for the OPR F\u0027s and if there was a requirement for public verifiability then maybe a new work item to to bring Charmian and blinded RSA in 2 CFR g could be useful so this seems like quite appropriate is interesting i think including in the charter the ability to have further extensions like that private metadata additional bits of data would be useful I think there is still crypto work to be done we had a scheme for they like private metadata but there was an issue with that that you were able to discover whether or not two users had the same bit there and I think we probably want to get more is both from CFR G and like people looking at these protocols specifically before we call anything working and not needing work Tomica C let\u0027s make Matt Miller the last commenter please sorry mark quickly um I just want to express that I like your sponsor use cases for this work as you showed um a couple slides ago so I\u0027m interested in where I could like to see him move forward and I hope that was that Iran Sheva I support this group I think it\u0027s well was the working group in a in of itself I am worried about the working group were caught in it is that interoperability is out of scope so I urge you to find the areas where you do require interoperability yeah that\u0027s a good that\u0027s a good point maybe maybe it\u0027s just a federation that\u0027s out of scope but interoperability is in scope that\u0027s a very good comment echoing for Coby gherkin I support this work I\u0027d like to see this point signature based protocol moving forward would be willing to participate in a working group just from an HTTP perspective I think a separate group is probably the right answer here there\u0027s enough meaty stuff to do but please coordinate because I think there\u0027s things like cache interactions and you know intermediary interactions you want to take care of thanks mark noting him could you please state your name for the record my name is Richard barn "
  },
  {
    "startTime": "00:48:17",
    "text": "or mark Nottingham I\u0027m not sure right because we\u0027re bad at estimating time up here I\u0027m gonna go ahead and let our remote speaker go hi this is Roger notify mutation machine I support this one we already have interrupts with the existing implementation compiler and we\u0027d like to see go forward in the working group thank you thank you yeah so that\u0027s that\u0027s a clarified clarifying point on the in drop point of view the recent release that we did is interoperable with multiple CAPTCHA providers rather than just CloudFlare and the closer extension so it\u0027s one extension multiple providers but the mechanism for federate Federation is is not in scope cool all right so it sounds like there\u0027s I think you\u0027re probably about right this is about micro working group size and it sounds like there\u0027s several expressions of interest from the floor so I think let\u0027s work workshops the Charter on the list and eighties willing we can probably just charter this directly without further Bafa tude a chair so that chairs the mic please or a decent mic please continue yeah Roman do you so continue talking the list for architects is great I think we want to buff it but let\u0027s put some let\u0027s put the text in the list let\u0027s chat cut a little more and we\u0027ll make some some plans since that what we\u0027re talking about is three four months from now okay okay thank you all right Justin you\u0027re up [Music] all right so for any of you who are at dispatch yesterday and saw the same presentation this is the slightly slower version of it slightly yes I\u0027m running it probably about 2/3 Eckerd\u0027s right now so anyway I wanted to talk about HTTP signing specifically what I\u0027m talking about is a message level signature over an HTTP request and that\u0027s a signature that would cover some subset of the headers the body other requests I learned elements like the URL and verb and all of that other stuff and in particular we\u0027re interested in talking about detached signatures and not encapsulated signatures more on that in just a bit the reason that there\u0027s a lot of people out there interested in solving this is pretty varied as it turns out people have been approaching this in order to prove possession of a specific key there are security protocols extensions to OAuth and and the like that are you know you want to have some way to say that I have a particular application level key you want to be able to authenticate a piece "
  },
  {
    "startTime": "00:51:18",
    "text": "of software which is a slightly different but related problem to keep roofing possession you want to have sometimes message level integrity this goes beyond the TLS transport layer integrity and also non-repudiation and audit kind of you know I\u0027ve got a signature over the request itself that might last in logs and things you know going forward so the reason that this is a hard problem and we don\u0027t already have something built in is actually not the signature part the reason that this is hard is because of HTTP HTTP gets transformed and you know terminated and repo and parsed and reconstituted and replayed all over the place it\u0027s designed to be able to do that and we kind of expect it to be able to do that in our systems today however we we don\u0027t want to just encapsulate the entire HTTP message to prevent it from being modified because we want our terminating proxies to be able to look at something and parse it and figure out and then hand that back to our back-end systems and add in their own headers and all sorts of stuff like that we need to have those kinds of capabilities in our apps today and it\u0027s really really common especially with things at the application level to parse and re serialize stuff so things like query parameters tend to get handed down at the application layer as a map of some type and not as the query string things like a JSON body is gonna be handed to you as an object and not as the series of bits of the JSON the HTTP message entity payload itself right parsing and re serialization is really really super common all of this makes signing any of that really really really difficult you inevitably need to have some type of canonicalization and normalization process in order to make this thing work so first question why aren\u0027t we solving this using other existing technologies so why can\u0027t we just use TLS for everything well TLS stops at the TLS terminator thus the name and in a lot of cases in a lot of applications you need both the integrity protection and the key proofing to go beyond the TLS terminator additionally there are a lot of applications where mutual TLS doesn\u0027t really fly anything that\u0027s being generated inside of a web browser so in in s.p.a or something like that doing M TLS from inside there really doesn\u0027t work it it is a horrible user experience people get prompted for personal certificates because of assumptions that we have made on the "
  },
  {
    "startTime": "00:54:19",
    "text": "Internet about what a certificate in a browser means and stands for that don\u0027t really map to the way that we\u0027d like to potentially use the technology all right what about s HTTP this got brought up I believe is on dispatch list not on sec dispatcher I forget but there\u0027s and no I don\u0027t mean HTTPS I mean s HTTP this is an old RFC that wraps up HTTP in a in an encapsulated message and it duplicates and hides a bunch of HTTP functionality in order to do the encapsulation but the biggest problem is that it exists but nobody\u0027s ever heard of it great yes sometimes a correction here I think that as HTTP was raised as an example of how this is being done in the past and perhaps there were some lessons to be learned from it not to say just use this HTTP because there\u0027s an RFC right and I did not in intend to imply that that was what was claimed and which is a good thing because we shouldn\u0027t just use that s HTTP for lots of reasons not the least of which is that it\u0027s an encapsulation protocol are we taking questions in the middle here or should we tell Phil that okay awesome thank you all right so what about using Jose a lot of people love this for lots of things the thing about Jose is that it\u0027s really really good at signing its payload that it carries along with it and again if you\u0027re doing some type of detached signature you need a way to get that payload into the Jose world and then get it back out so that you can carry the signature along it\u0027s not really not really set up to do this kind of thing and if we were to encapsulate all of the HTTP stuff so put the the verbs and the actions and the URLs and queries and everything inside a Jose object and just stuff that inside of an HTTP request you end up with soap with curly braces and let\u0027s really not go there all right so looking around there and the reason I wanted to bring this into sec dispatch is that there are at least five options out there there are actually now seven thanks to Annabel publishing two more this week but be fair that\u0027s a it\u0027s those are a remix of one of the ones up here so I didn\u0027t update the slides and I am personally responsible for two of these which are different from each other because reasons and all of these exist today and are incompatible with each other and solve slightly different slices of the overall problem so cabbage signatures which is probably one of the yes so Mountain Thompson I can add at least two more to that list yeah I\u0027m sure that\u0027s I said I said at least there\u0027s there\u0027s all "
  },
  {
    "startTime": "00:57:19",
    "text": "people have been hashing this in different ways so and I should add these are specifically the detached non encapsulated versions if you want to go encapsulated mess signed HTTP request there\u0027s it\u0027s like you you can\u0027t throw a dead rat around here without running into one there\u0027s a lot so I\u0027m talking about specifically detached stuff here Cavett signatures are probably one of the most widely used ones out there they\u0027re a little bit limited about what they can canonicalize and sign but kind of works one of the the worst things about this particular draft though is that it is entirely detached from the IETF process it is in ID that people outside the IETF have been working on and updating and changing more on that in a moment and it\u0027s just kind of there but people are using it Oh auth depop and OAuth pop which yes those are two completely different things they and as you can see they attack different parts of the problem deep hop is all about key proof of possession whereas auth pop is about token presentation and a message integrity component with a key proof of that presentation that kind of comes along for the ride and that is that latter one is also an expired working group draft because you know it never really kind of caught on the new XYZ project that I\u0027ve been working on which we talked about the TX off off the other day all that that does is it signs the body it doesn\u0027t touch anything else so that is extremely limited but it has its uses as well and then there\u0027s the proprietary ad of AWS v4 which predates pretty much all of these which has its own really really major limitations even though it manages to cover a lot of the columns here its major limitations is that it\u0027s very tightly fit to AWS is keying infrastructure with its key derivation functions and stuff like that that you have to do in order to make this work right yes less than a minute okay well so the cabbage signature drafter that I mentioned before started way back in 2013 as an individual draft it got picked up by a bunch of people and then earlier this year including a couple of financial groups and earlier this year the editors of that draft made a bunch of edits which included the text do not use this draft and that freaked everybody out that was depending on this and there was a scramble to peg against a particular version and then there\u0027s been more updates and stuff like that and all of this kind of led me to realize that you know enough people are "
  },
  {
    "startTime": "01:00:20",
    "text": "using this stuff enough people are trying to reinvent this stuff I think it\u0027s time that we brought this into the fold and make this a real thing that people can depend on for you know stability and all of the iti process and whatnot so where do we go from here I don\u0027t actually know should we combine all of these drafts in all of these different use cases should we find a working group where this makes sense we talked about potentially targeting this at the HTTP working group at the dispatch thing should we start a new working group to do just this one thing I don\u0027t actually know so with that we\u0027ll do comments and questions so what about bringing these to http working group mark maybe you want to yeah does mark want to jump the queue for that maybe and and also keep these short mark them so this has been I think as I mentioned before this has been an item that the working group has HTP working group has been had its eyes on for a while especially cabbage but other things and the confusion in this space is one reason we\u0027ve been a little bit resident to start work from what you\u0027re saying and obviously you\u0027re more engaged in those communities than we\u0027ve been it sounds like it might be time to start some work so I would support some work in this area as you kind of alluded to yeah I think this the the three different groups of folks who need to be involved here one is the users of potential users of this technology another is the security folks of course another is the HP community to make sure that it\u0027s being integrated into the protocol well and as you mentioned that\u0027s kind of the the tricky part of all of this right so I had a quick chat with my co-chair just now and I think we\u0027d be happy to consider a call for adoption if you\u0027re interested if if you want to dispatch the south where that\u0027s fine too but I\u0027d one West that you ADEs talk to our ID so we can do some coordination and figure out the best place for it to land if that\u0027s gonna happen yes I would I would consider this in scope of our Charter that that honestly would be fantastic we\u0027ll figure it out with the ADEs when I initially brought this up with with the SEC ADEs the the thought was that this really is on the line between the two areas and we do need people from both sides yeah but yes thank you I feel them Baker actually I was gonna say that I don\u0027t seem to be online I think it\u0027s and your work is gonna be entirely HTTP okay I act I it wasn\u0027t just Eric who try to do this stuff back in the day I did it as well but I catch relation is actually the way to go you\u0027re on to lose here you can optimization always loses otoscope thank you may be a silly question iran chef have you actually talked to the cabbage authors yes and they asked me to present this yeah so I talked to my nurse morning specifically about this and he is keen on getting this targeted to an actual place now so here we are so we\u0027re cutting the line here I spoke "
  },
  {
    "startTime": "01:03:22",
    "text": "to cabbage about this one probably five years ago now and he was quite keen to have it go here but wasn\u0027t really able to invest the effort required to get it over the line I learnt that someone\u0027s willing to do that this is really tricky from an integration perspective though and I caution that you know comments like pH B\u0027s just now are quite valid and I think that we we have to think about that in this context very carefully I realize that people are using this but though there\u0027s there\u0027s attention is that this creates between end points and intermediaries and and protocol actors within HTTP that make it look very tricky Oh my suggestion would be that the primary venue for this one would be the HTTP side of things and we were bringing in expertise the the crypto expertise that you need in order to do something like this is a little sophisticated so we will definitely need some help there but it\u0027s still fairly basic stuff but the tricky part is getting in the protocol so I would get encouraged there we go there yeah I\u0027m absolutely with you Annabel Bachman Amazon a couple of quick points first of all you know since we\u0027ve been operating signature version four as our main request authentication mechanism for years now we can attest to the viability of a detached signature protocol at scale across a wide variety of services with a wide variety of API formats we encapsulation is not the only way that this can be done in addition to that Justin mentioned me putting forward two other drafts what I\u0027ve done is taken the expired draft that Justin wrote the OAuth pop spec and split it out into two different layers pulling the HTTP message signing pieces out into its own piece independent from all of the OAuth specific details of how you attach them how you put that message into the request what do you to sign whatnot I really think that\u0027s that kind of layered approach is the right strategy here the all of the work related specifically to signing elements of an HTTP message that belongs in HTTP how you apply that in specific context for example to do proof of possession for OS is something that the OAuth working group can handle and other working groups can can leverage that that signing work as well as as appropriate to their use case yeah I agree everything that we\u0027ve had so far has been very packed together I think we might see multiple drafts out of this and I\u0027d be happy to put forward the message signing draft in HTTP working group submitted there and hold depend on that if if we need people to pick that "
  },
  {
    "startTime": "01:06:23",
    "text": "work up okay so it seems pretty clear that this is going to HTTP so we can I mean move on yeah pending pending coordination with chairs it seems like this is probably going to be an age to be work item that sounds fair okay cool thank you this worked out that I will present has been planned for a researching group I rkf research group that unfortunately has not been charted so I\u0027m here to ask for feedback whether it is research or engineering or if you have suggestions where to go so the background of this work is the concept of systems as has been defined by the ITF so the past incidents have proven that systems can no longer be considered secure we have fallen abilities at all layers starting with spectrum Eltham from hardware and then going up to upper layers so vulnerabilities do exist in these systems and it is question of matter and time and resources to exploit this this varner abilities system complexity is not no longer manageable all of these vulnerabilities they are packed in one module that is reused by someone else you purchase hardware designs integrated into your design so it is this this concept of having or improving the security of a system is somehow outdated moreover we are focusing on the area of critical infrastructures where monocultures are developing so operators have incentives to have just one single hardware design to operate one single firmware and have one single software and hundreds of thousands or tens of thousands of devices thing about smart meters and so on in RFC 3550 2 it is stated that protecting against an attack when one of the end systems has been compromised is extraordinarily difficult and we have asked ourselves what doesn\u0027t mean what what does compromise mean in this context so it is obvious this isn\u0027t required statement it is it is very important to have this chain of trust between systems because otherwise we can\u0027t do anything but the systems are vulnerable that\u0027s a fact so and malware intends to exploit these vulnerabilities we need some solutions we need to better than than saying we give up whenever one system in this chain of 1000 systems is infected so we need to isolate we need "
  },
  {
    "startTime": "01:09:24",
    "text": "to contain all of these devices as an example and and the challenge here is that these devices are low cost that we\u0027re talking about and they have adversaries have physical access to these devices electrical vehicle charging stations now are updated to 350 kilowatts which corresponds to more than 500 households of energy consumption and it\u0027s a matter of loosening some screws and accessing the device to compromise it good in parallel security protocols are deployed at large scale now and in the lowest line you have a a reference that points out that this security might also create a platform for malware to propagate and do subliminal channels and secret communications or hidden communications which might be very difficult to detect so what we\u0027ve done here is just to implement the command and control structure for botnets using Bitcoin in the blockchain and the signature being bedded some-some commands that were then taken and and adopted by clients good the motivation of this work is that malware has incentives to communicate we want to discover this communication between malware in instances the more communication we argue the more important it is and and the more the higher the threat that is malware can can cause in overall in the larger system the challenges are high because malware has started recently so can\u0027t while mother variants already monitor the traffic\u0027s the benign traffic on the network and try to to obfuscate within this traffic to use the same protocols to encrypt data and so on and so on what we propose is to complement existing security measures that is we do not want to say we replace them but we want to - to provide additional means of security as a proactive measures we want to inhibit malware communication by design meaning we have shown in signatures of the bot chain it is possible to in to include command and control structures how is it with other protocols that is to evaluate the potential of hidden communication in these protocols that are used in critical infrastructures and but my talk now is about reactive man and that\u0027s a draft also about we want to detect this hidden communication and what we did is and the question research question is here can we detect and "
  },
  {
    "startTime": "01:12:26",
    "text": "capture malware behavior in these networks what we did was to design a generic malware lifecycle model which basically captures the behavior of known malware variant in the wild and if you look carefully this diagram here mean equals the concept of compromised in the current IDF security concept so what does compromised really mean does it mean we have infections does it mean we have gained access to system does it mean we have control over the system so it is much finer granularity and we believe that and and the essence is that we have various states and these states are subject to communication to change so we have transitions between these states that you see cyclic one we have scans that also originate traffic we want to capture this traffic as a monitoring part and to infer on the existence of malware to detect anomalies in the network two minutes thank you I\u0027ll do fine good so and now the question is how can we use this lifecycle model to improve the security of systems as a future research question we discussed it before in a society meeting and the conclusion was it\u0027s challenging it\u0027s very challenging so can we quantify can we define metrics to quantify the behavior and and the support for subliminal channels within existing security protocols good as an Outlook so this generic malware life cycle is something that we perceive could help to improve future evolution of security to give an additional potential and and additional security for in particular for critical in stress infrastructures now the question is is this the home for this work is it IRT F is it IETF are there specific groups where this fits in we have a funded research project now that combines various stakeholders so we have a ministry we have two utilities or three research institutions and antivirus company that all team up together to research on the challenges in the can\u0027t evict infrastructure we start at a very low level if you know how the current state of electrical vehicle charging is with respect to security but we hope to get some good results and yes we believe that the results are of relevance and if there is any feedback and any any any opinion where this should go to I\u0027ll be "
  },
  {
    "startTime": "01:15:27",
    "text": "happy to get feedback hello okay so it\u0027s not clear to me exactly what you\u0027re trying to propose I\u0027m not sure that the generic working on malware is appropriate for the IETF there are nuggets in here that talk about proactive measurements rates and protocols perhaps that could go into like the map RG as they\u0027ve done so in in this session for example there was a presentations on different measurements for detection of anomalies if you will but as a whole I guess I\u0027m kind of struggling to figure out how to dispatch because it\u0027s somewhat broad so with that I\u0027m gonna do the quick discussion before we figure out how to help provide guidance good so right it is also about measurements it is about anomaly detection mainly because the challenge will not be the measurement itself but that the focus will be the anomaly detection of of these anomalies in encrypted traffic finally so it is it spans several areas that are yeah so so let\u0027s have our our ad comment hi Roman didn\u0027t you I was just hoping can you talk a little bit more about that first bullet no I\u0027m that\u0027s lie it was so can you talk a little bit more about the specifics of that lifecycle model there and how you see that manifesting in ITF work this lifecycle model is supposed to be mapped to the security model that we have in RFC 3550 - so about a compromised point here right now we when when do we consider a system being compromised is it so when do we stop can\u0027t ITF activities basically if you take it this way saying that the system has been compromised so it is extremely extremely difficult to defend against we believe that we can do better by adding additional functionality to do all of these mechanisms so it\u0027s a source of resilience thing we\u0027re talking it is a resilience yeah resilience it is it is an additional feature is this supposed to be a monitoring device that monitors a critical infrastructure the packet packet level traces so this is related to measurements then but it is related also how can we process all of this data it will be in no enormous amount of data all of this data and it is about finally about malware behavior how does malware behave how can I all of these transitions are "
  },
  {
    "startTime": "01:18:27",
    "text": "characterized by specific features so for instance triggering a scan or a discovery might cause a lot of traffic my cause less traffic depending on the topple and on the on the kind of activity whether I trigger a blind scan a trigger topological scan or a passive scan or a control message will be small and I have no quorum I have a causal dependence between a message arriving at the malware and an affected instance and causing an attack but I have no temper or not chronological dependence so I do not know I have received a message in the past and in the future it will trigger an action okay I\u0027m gonna cut the line at URI cool so and there\u0027s some interesting stuff in here as we discussed previously I think that the focuses of little channels kind of destruction we die TF decide if two kind of caught through they decided not to like really make an effort to release subliminal channels in current protocols and there\u0027s like an enormous amount of like literature on that like probably he\u0027s not worth the capitulating so uh by certainly like you know malware\u0027s real thin um but I do have a suggestion for you which is there\u0027s currently a I ABO Graham I think it\u0027s called Model T so they\u0027re calling it about looking at the threat model for for the ITF and discussing potentially we\u0027re visiting 3552 on since this isn\u0027t really a protocol specification um but his work a threat model on about on malware I was just that you take it there um I don\u0027t know Steven Farrell\u0027s in the room he\u0027s leading that program but in any case it\u0027s not hard to find okay thank you yeah I just wonder about why you think there\u0027s value there\u0027s value in forming a malware lifecycle model when a lot of a lot of network equipment today already come equipped with uh with the with intrusion detection systems based on adaptive technology such as machine on board machine learning engines and jury money I\u0027m Qualcomm I know my company I all makes access point processors with uh with onboard machine learning engines I wouldn\u0027t really try to solve this problem y\u0027all forming a life cycle model more than I would actually try to train an engine based on traffic characteristics that I expect to be normal within the private network so why do you think this is a better approach versus something more adaptive this is a better approach because we have a finer granularity on these attacks we can detect when we want to amplitude detect when a specific malware is in a specific stage of its evolution so we want it\u0027s it\u0027s what ideas are doing however most ideas are still pattern based they\u0027re trying now to do machine learn based that\u0027s what we do too but however this disk granularity having intelligence that adds on on specific tasks and activities of a malware in "
  },
  {
    "startTime": "01:21:28",
    "text": "critical infrastructures and we have also architecture I didn\u0027t mention this but we have architectural topics there to isolate and part of this architecture part of the subsystems from the rest of the systems trying to maintain the functionality of the rest of the system so it is a kind of resilience yeah yeah I mean I would say that I would say it\u0027s hard to measure success of an approach like this if you if you cannot say well I can easily deploy this model and keep the false alarm we got to wrap this up in quick last comment just a clarification to a point that echo is making Model T is not yet a program there\u0027s a mailing list and some active discussion and certainly if you talk to Steven he\u0027d be happy to add you to mailing list and you can during that discussion but if you\u0027re scrambling to go to the iba website and go where is this program there\u0027s nothing here that\u0027s why okay thank you yeah I think you the chair has been talking back charities I think that\u0027s probably the best next step for you to talk those Model T folks all right thanks and finally Brian Campbell we got five minutes left for you to chat to talk to the IAB Model T proposed program it\u0027s the threat model evolution all right try to do this in a few minutes I want to talk about conveying clients certificate information a lot of words here from TLS terminating reverse proxies to back in HTTP applications quick kind of overview of the problem statement is that in a lot of HT a HTTP application deployments oftentimes TOS is is terminated by some reverse proxy that sits in front of the actual application somewhere this is true in a lot of different architectures in the kind of old-fashioned sort of interior reverse proxy and back in origin server architecture it\u0027s true now with things like you see with CD and as the service type offerings or application load balancing type offering services and you also seen it even in micro service type deployments where you have this sidecar proxy pattern so even though things are changing this this it\u0027s a recurring pattern of TLS has terminated somewhere up front and the the backend application isn\u0027t isn\u0027t talking to us with the clients but but terminated by this other component but and TLS client certificate authentication is in fact sometimes used and a lot of times when it\u0027s use the actual application in the backend needs to know something about the certificate make authorizations decisions to bind tokens to or whatever it needs to know more than just was the connection successfully established or not and these access to the actual content of their certificate and in the absence of some standardized method of conveying "
  },
  {
    "startTime": "01:24:28",
    "text": "the client certificate information from the proxy to the back-end different implement implementations have done this differently or in some cases haven\u0027t done it at all I want to give a quick idea I know there\u0027s a lot of words here of how I got here in front of dispatch in the OAuth working group where I spent a lot of time there\u0027s a draft about doing mutual TLS for client authentication and binding access tokens and in an unrelated discussion the draft came up as we were talking about some other things and one working list group participant basically said that this some sort of protocol for conveying this information should have been defined by the MTL s document I took that kind of hard but luckily Ben stepped in and said that it was seemed like it was something a little more general and probably would have been defined in a more general fashion and not specific to here feeling a little bit better about less insulted by that I agreed with them and said it would be nice if such a thing existed but it definitely you know has a wider applicability than just some narrow Roth profile this stuff a couple other people piled on saying they also agree and specifically said would it be possible to get this pushed off the HD HTTP or the TLS working group would be more appropriate there but it would be helpful to have something like that thank you said that Ben and said you know somebody has to write a draft this was right before the draft deadline and said barring that howdy heart hot RFC or sec dispatch might be a way to take this I wouldn\u0027t be here in time for hot RFC so I landed here in front of you all and I did do some conceptually similar work awhile back around token binding which is kind of died out for different reasons but did some things really similarly and thought that maybe some of the concepts that were applied in that draft could be applied here and basically this is sort of a simple proposal for how to do this which would be and which could potentially enable sort of turnkey simple and interoperable integration for conveying this information between independently developed components or services which would largely just be the you know normal HTTP connection between a client and a server that\u0027s the reverse proxy proxy terminating TLS that proxy sanitizes relative headers and passes the client certificate information back to the back-end application as a new header with a defined name and encoding this is sort of all that\u0027s needed to solve this problem for different components to speak to each other in different ways and that would be sort of the I guess the the proposed solution to this is to develop some kind of draft that just defines that header name as well as the encoding sort of certificates and the rule around header sanitization to keep things secure and not injectable from the front end clients having said that I "
  },
  {
    "startTime": "01:27:30",
    "text": "wonder if maybe the ship has already sailed there\u0027s lots of disparate solutions out there already and they\u0027re all doing it in slightly different ways exposing or as configuration options different ways to pass different parts of the certificate and it\u0027s not clear that you know retroactive adoption of a late standard like this would actually happen and while I stumbled over the words and said it quickly I try to present one simple prospective solution to this I actually think the consensus here might be might prove really difficult to achieve the thread that started this discussion on the OAuth fed after even after the mention I might come here and talk about it degenerated into a lot of really strong opinions and even even some borderline personal attacks and questions of people\u0027s motives which was fun I when discussing a tie a TF 99 that particular draft around token binding so it\u0027s hard there\u0027s other ways to do it there\u0027s the forwarded extension I don\u0027t know thanks for your time I don\u0027t know if this is something we want to dispatch or not or where the relevant work would be done but sorry we don\u0027t have time for discussion here to answer your question we are not going to dispatch this because we don\u0027t have draft look forward to get sick getting some discussion on the list and we can hopefully get this discussion thank you I know it was a time constraint thing would it make sense then at this point to write something up and and work it through dispatch for discussion yeah I think you if you get a draft going you can post it on the psycho specialist and we can have some discussion there as to what make what might make sense alright so Roman yeah I would just wanted to kind of remind meta we can use the sec dispatch mailing lists all the time to talk and have proposals and ya know we can make we can help with dispatching there all year round by all means we don\u0027t need to isolate our activity to these meetings we can even have a virtual enter virtual meetings to dispatch things in between physical meetings so let\u0027s get that energy going if you are interested in this stuff please chat with Brian so just to quickly recap our outcomes today with Max\u0027s first proposal on post quantum combination signatures I think the feeling here was that if this is gonna get this work is gonna get done we\u0027re gonna dispatch it so lamps that\u0027s to be discussed and confirmed on the list will the chairs will start a thread on that for max the second one about OCSP revisions again I think the feeling was if there\u0027s going to be work this should be in a new working group there\u0027s enough work there\u0027s a merit that it if there\u0027s energy to do that work so we\u0027re gonna confirm that and see if there\u0027s data to support the need for this back on the mailing list and again curiously start yeah for privacy test um there was pretty good energy in the room seems like there\u0027s probably energy for a working group the little hat well we\u0027ll see let\u0027s see so we\u0027re gonna we\u0027re gonna hash out charter text in the list and each adsr going to advise on what process we will follow to decide whether "
  },
  {
    "startTime": "01:30:32",
    "text": "to form to form working group or not and if privacy passed once a mailing list we can also make a mailing list fair enough all right the HTTP signing stuff has been dispatched to the HTTP working group and the malware lifecycle work to Model T over at the IAB so we have successfully spread our influence over multiple areas and the IAB good job SEC dispatch and finally if you\u0027re interested in the work those presented last by Brian please talk to Brian so that is suck dispatch thank you for your time today [Music] blue sheets where is the second blue sheet [Music] "
  }
]