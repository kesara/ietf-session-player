[
  {
    "startTime": "00:00:18",
    "text": "all right it\u0027s 11:20 let\u0027s get started so this is any wig if you are not in this room 4l wig you may leave the room unfortunately then could not join us either physically or virtually so this is more that I\u0027ll be handling all the administrative issues and we have Serratia ready here to help this along it\u0027s already wet nice day so I hope by now you know the note well if you have some questions come to the mic now or leave the room so we had some time I thought we could do a little bit more spend some more time on on the working group and how it has been progressing in the last since the last IETF so we had updates to the neighbor management policy document where which Rahul will present today then we had an update to the TCP constraint node network draft which was also presented in TCP M we were hoping to issue a joint working group last call with TCP M but there were some issues raised which Carles would put present today so I guess we need another revision for this document before we do do the working group last call then we had a new working group document adopted and Rene will present more on this remotely during the meeting there no updates to working group documents on lightweight co-op implementation so I had some feedback for the author since we have all these new options and extensions in coop like hop limit and too many responses maybe it would make sense that at least some document tells me which one should i implement for which scenarios so if it\u0027s very small sensor do I need to implement too many requests do I need to implement hop limit for example so I\u0027m hoping Ola 4 or Matias can can use this feedback and and bring update of the document to the next meeting we had no updates to their weak security protocol comparison I guess they are waiting for DTLS 1.3 to stabilize before they come up with the numbers then we had the class the device classes draft which is not yet a working group draft but there has been some interest we will have a last minute addition to our agenda so we we will have a presentation from Oscar Pascal who who will talk about device classes for for software updates then we had "
  },
  {
    "startTime": "00:03:20",
    "text": "this draft IETF velvet cellular which is now in mr. F for more than 1,000 days which is a bit sad so I discussed with one of the authors yari whether it makes sense and this is Suresh also question to you to move all the normative references to informational this is an informational document I don\u0027t see any reason why we should be stuck on resourcedirectory people to to finish their things and it\u0027s not like we can wait one more IETF and and it would be done I think it would be another couple of years before resourcedirectory moves forward so so maybe the maybe the authors and ad can say something on this suresh krisshnan so as eddie so the one thing i can do is like kind of pull it out of the ROC editor queue and push it back to the working group do their changes and bring it back right like there\u0027s really I don\u0027t want to make this change in outside the working group process okay so that\u0027s if that\u0027s something you would like like we can probably just like pull it back and do this and I can talk to the iesg about it and so one thing I want to talk about is really the normative reference and informational documents I think it\u0027s not that straightforward right like you know just saying this informational document and we don\u0027t need normative but if you think like somebody can follow this document without reading that then we can seriously push it to informational right that\u0027s really the question so that\u0027s a different question than saying this in information assurance sure totally agree my only concern is that if it\u0027s more than 1,000 days most of the content in the document anyways is getting outdated so so most many recommendations would change with you know other things it\u0027s better to ship the document like that\u0027s fine so I\u0027m willing to pull it out right like it\u0027s not a problem pulling it out and but this like this existence proof for this kind of thing this like stuff in there that\u0027s like more like close to thousand days old like there\u0027s like this cluster 238 I think if you look at it there\u0027s like you know this intertangled thing of like about 40 documents I would say they\u0027ve been stuck in there like for a very long time right and unfortunately that\u0027s how it is right like you know if it\u0027s anomaly reference it\u0027s not a reference but if you don\u0027t mind pulling it out I can pull it out like from there I guess I\u0027ll leave it to the authors to decide I reckon as one of the authors yeah I guess that they\u0027re referenced were missing whereas in Salem Ellen Rd and we did think back in the days that those wouldn\u0027t be RFC\u0027s way earlier if you would have known its chromatic thousand days probably would have taken another look on as informative or no many references so that is an option of course but I guess it\u0027s matter having that cloak have a chat with already if you can make the change on it\u0027s okay but already should be ready different assistant system to fajitas for now should be going for last call in any day now so also that that is an option so "
  },
  {
    "startTime": "00:06:21",
    "text": "your recommendation is to keep it and then just wait well we can we can see what now happens in the RT I mean that\u0027s open let\u0027s say open issue that weather is closed to be closed and I can see an already common coming beautiful much talk I\u0027m not so pessimistic about our D as of a thousand days ago but ya know in interrupts which have passed very nicely there are two modifications we have exchanged in to expect to be accordingly and I think we can have good interrupts according to the specifications and the last call will not be very far back and then there\u0027ll be very quick because there\u0027s so many comments before so either way it should not be another thousand days it should be either way we go fair so I guess it remains in the editors queue for now I think it makes sense to see how this final question on whether already last call is started in the next few weeks we\u0027ll know that you know in a few weeks okay and if it looks it\u0027s gonna go longer then let\u0027s have a look whether we should pull off that normative reference I think that makes sense okay then the last thing on the status in society of 102 well we had this presentation from Daniel be called on doing IPSec on non small devices and I think we have done to call for adoptions in to IETF meetings and then we try to confirm it on the list there were some comments from from Tarot from Paul routers and Henrik but we never closed the last the adoption call for a for this document so there there is not going to be any more updates or or presentations at this IETF but I think this is for the group to see if they have comments and you or if they think it makes sense to it of this please comment on the list otherwise this craft I mean it\u0027s people come and say oh they have this concern and then the document authors address those concerns and then you update but those people then never reply if they are okay so I guess and I will discuss this and then see how to take it forward but so far our thinking is that if if people don\u0027t comment on the new version then then we adopted all right so this is the agenda for today Carlos will present TCP user guidance in the internet of things this was presented in DC p.m. on Monday and we will see what what feedback he got then it\u0027s Rahul presenting two things so the neighbor management policy update and then performance report for six low fragments forwarding which was also "
  },
  {
    "startTime": "00:09:21",
    "text": "presented in in the six low working group RNA will do a remote presentation on alternative curve representations and then we had last minute update to the agenda and Pascal will present these security classes for software updates does anyone want to do agenda bashing is are we missing something if not let\u0027s move on blue sheets good Rahul is the JavaScript and re are taking the notes together so you had to leave so he\u0027ll start with the notes and then Ari will take over [Music] Carlos hello everyone my name is Carlos Gomez I\u0027m going to present the current status and the last update of the draft entitled TCP uses guidance in the Internet of Things so first of all let\u0027s take a look at the status of the document since the last ITF the draft has been updated once the last revision is - 0 4 and this last date intends to incorporate to the document the feedback received in the room in the last IDF and also it addresses the last remaining editorial - those from the authors also we received the review of - 0 4 by Yoshi foam in Ishida who\u0027s the CDM co-chair later referred to the review and also in the same idea as Mohit explained I already gave a presentation in TCM that was a longer presentation with the goal of providing an overview of the main contents in the draft in preparation for requesting a working Robles call then we also in that session in this idiom we received few comments by Gorion David black that later I\u0027ll also present I have also read this true and I will give quite long list of comments but it will take some time to write them down to an email so could you state your name again for the Europa - ok thank thank you ok so now let\u0027s take a look at the updates in the last revision of the draft so a first set of a date is in Section 4 - 3 which discusses used of "
  },
  {
    "startTime": "00:12:21",
    "text": "delay that noise means for single MSS windows here we have added that the pier that the constraint device communicates with may be a general-purpose system that means a system which may not be specifically talking only to constrain devices and it may be quite typical that such system in such a system related management\u0027s maybe configure through system-wide parameters and a typical setting for this mechanism will be enabled meaning that in some cases it may not actually be possible to disable delayed acknowledgments which is what we would like to in order to avoid incurring some unnecessary additional delay in communication I promise to do the review as well but that\u0027s the least I\u0027d heard about late that the medium a few days but relax the there are other things also that should be taken into account so unfortunately when using single MSS advertised in dog then the it doesn\u0027t play very nicely with it if you turned on the dead axe off because now when the message or the data packet arrives you immediately ack and that goes with this Jeremy advertisement and now when the application reads the gate on the from the buffer don\u0027t receive buffer that triggers and window update are so so as as a return you get two acts and that\u0027s the kind of a not something that people want to have so in general it\u0027s not that clear and another thing is that tiem when you have a read with response kind of for traffic and now when the request comes you immediately act and soon after that you send the response and if you are using the latex in most cases the I could call together a key back or the piggyback with your response once again you kind of send an unnecessary ACK in that case so this is not that clear whether it\u0027s advisable to turn it off okay thank you so well it would be great if you can provide your comments also thank you so much so yes so okay we have also another set of a date in Section five first we have reorganized the content in this section so sections five two and five three have been swapped in order and also they have been mostly editorial updates in the current section 5.3 which discusses the city connection lifetime previously it was split in two specific parts one discussing short lifetime and another "
  },
  {
    "startTime": "00:15:22",
    "text": "one for long lifetime however now the content is mostly the same but it\u0027s been presented in a more natural way possibly better for for the reader and on the other hand we have in section 5 the tool which provides guidance on the number of concurrent connections used we have added some actual new content we have explained now that in order to well using several concurrent connections between the two applications may help avoid head-of-line blocking problems for the application however it also may be harmful in congested networks so considering what we already explained in the previous version of the draft that each additional TCP connection will consume potentially scarce Ram resources the overall recommendation is being conservative with regard to the number of concurrent connections to be used then finally we have also an update in the annex of the document you may recall this is the section where we collect details on a number of TCP implementations for constrained devices and basically the update is that we have removed the section on open VM since it appears that that implementation was actually mostly based on micro-p so it was actually quite redundant with that so we have removed that section from the text and also the corresponding column from this table nice to see you Joe from Ave so nice to see the socket row getting added here and it\u0027s good that we have removed open WS one thing that I wanted to check is regarding the riot Dane\u0027s interface inspired by POSIX have seen the latest ApS and they are indeed POSIX compliant there are certain options that are not available but I what I\u0027m trying to say is is it possible for you to actually push we work on four of these operating systems at least okay and it is very difficult for me to convince my team that lwp 2.0 takes less than 40 KB or it could approximate your 40k be so will it be possible for you to push the open source with the configuration that you are checking to l wig github or something I don\u0027t know whether which you what is the right place but I want to check I want to cross check whether 40 KB whether L WI B 2.0 can 1440 KB of course flash yes so that the sources for this information or different or heterogeneous in some of the cases we do have some actual references that indicate which is the source for some of these details in some cases it could be academic papers or in other examples it\u0027s more related with information available in some webpages "
  },
  {
    "startTime": "00:18:23",
    "text": "so what we can do I guess is double check again all the sources and make sure that we have the right references in place and hopefully fresh yeah the reason why esteem this is because people have started using this to compare things you know and if there has to be a fair comparison the code size has to be checked on the same platform maybe we can do a cross compilation for I mean there ways to do it get it done I don\u0027t know whether they\u0027ll with github is the right place to keep this information so Mohit when we have done this crypto sensors document which is no RFC 83 87 we you know did experiments with a bunch of libraries and we got actually a lot of people offline asking us how do you compile this library on this platform that platform what settings you use so what I did was I made the configuration we had three or four different contribution configurations one was for no least amount of execution time irrespective of how much memory it consumes one was for least amount of memory consumption irrespective of how much execution time it takes and I put it on my person we get help so that people could use the same configuration file to build the libraries and what I guess Rahul wants is something similar because he is using this OS for his products or for some of his experiments so if we do say that this is 40 kilobytes is there some way to reproduce these results whether you put it on your personal github or whether we use Hellwig github is is another question yes so in fact well some of the details here in the caption are related with the fact that some of these data correspond to having these implementations on different platforms so in some cases it may be actually difficult to really have a fair comparison what what we can do is make sure that the references and the sources for this information are really reflecting what is intended so the data here that the numbers for code size are really not measured by ourselves so they have obtained some cases from academic papers in some cases for example for riot we have the details provided by the main developer of the TCP implementation of riot so yeah we have this problem with heterogeneity here so I don\u0027t know sure so for every bit is the whole protocol stack on embed so if this embed folks who reported this number or because now I see the annex that it says for l-l week to dotto it says the whole protocol stack on embed so is it the embed folks who said that this is some how much space it takes or did you do "
  },
  {
    "startTime": "00:21:25",
    "text": "some we didn\u0027t do any actual measurements okay so this was based on results that were found by other those measurements but is it someone\u0027s blog or sorry is it someone\u0027s blog or is it more reliable reference oh well I hope they are reliable references but anyway we can double check and make sure that we can trust the details okay so then we have a number of comments received after the internet draft submission cutoff date one one set of commands was provided by Yoshi for me Nishida TC TM culture he sent a review on the mailing list by the way things a lot for the review and well his general assessment was that the draft looks fine and mostly ready although he gave a number of detailed comments the first one was a suggestion to cite TC TM document which discusses the trade-offs and and requirements around RT algorithm design so it is useful we believe it\u0027s a good idea to add this reference in a section where we explained that devices that use a single MSS window size or very small window sizes mostly will detect losses after the expression of the RTO therefore the RTO algorithm in that case will have a significant impact then the second comment was request to provide some additional clarification and why we may need a window size of five MSS to get three duplicate acknowledgement then also he pointed out a typo in Section five two three and also in the same section he mentioned the problem with the fact that TCP first opened DFO may sometimes deviate from TCP semantics in the sense that a packet may be repeated at the application so this is something we need to to discuss here also if we want to handle this problem we\u0027ll need to consider the use of additional mechanisms such as TLS and finally he requested also to add some discussion on reducing that TCP keepalive interval that in order to avoid the issues that appear when in between the two TCP endpoints there\u0027s a middle box like a firewall that performs some kind of early deletion of filter records for example after 5-10 minutes of inactivity and they would be to set the keepalive interval low enough in order to avoid this deletion of filter records however "
  },
  {
    "startTime": "00:24:28",
    "text": "this has a cost in terms of some increased consumption of energy and memory sorry energy and bandwidth resources by the way we already gave responses to these comments on the mailing list and the idea would be to incorporate those into the next version of the draft which will be 0 5 then on Monday in the TC p.m. session we received also some comments david black explained that mentioning this be md5 we just mentioned in the security consideration section is not a good idea since it\u0027s no longer considered a secure option so the proposed action for this is actually removing the related part and the gory Fairhurst explained that he had read some part of the document he said that he would provide more comments and anyway his general assessment so far was that it was more or less in good shape for a working group last call so finally you Shifu me the co-chair of the decision session suggested that once we have this 0-5 incorporating all the feedback received we might want to request a working Robles call so finally well since I also made this question in Indy CPM I\u0027d like to ask to the a week members and also the the chairs whether it would be a good moment for a working group Moscow I guess it will make sense to address the comments from Marco and from Rahul and then all the other comments you got from DC p.m. submit another version and then we see the comments on the list we don\u0027t have to necessarily wait until Prague to issue a last call so we wait for the next version great any more comments I\u0027m Rahul Jadhav basically this this this this presentation is about an update for neighbor back a neighbor management policy what it deals you with is you have neighbor cash entries and how do you manage those neighbor cash entails well with the star networks star topology it was much easier to manage the neighbor cash entries with bus like topology it is slightly more complicated with mesh topology it is extremely complicated and with with additional constraints with additional resource constraints as much it becomes much difficult to handle there is the the NC "
  },
  {
    "startTime": "00:27:30",
    "text": "entries so this draft talks about how do you manage this neighbor cash entries in a mesh topology like 6lowpan with a limited neighbor cache size navigation table so we have received a good substantial review from more health we have updated the document and pushed the next version we have clarified a lot of terminology that was used we dependent upon we have given examples about ripple signaling Panna signaling which we make user for network access that the there was one thought that came to our mind whether we should be cripple ripple and Panna from this document and make it more generic it is possible to do that but then it is very difficult to give a concrete examples in the document so I would like to have I would like to check if there is any specific feedback from this working group on this point if not we can go to the next point so the points to discuss so there while going through the document and while discussing with several other people and while implementation ourselves there was one more key thing that came to our mind whether whether we should do two things the document tries to do two things one is the reservation policy for the neighbor cache entries and the other thing is the signaling recommendations there are no signaling changes that we say but there are some signaling recommendations that the documents are added so we feel now that maybe it is difficult to have all the signaling recommendation or maybe it is not a good idea to give all the recommendation for in this draft it\u0027s better to concentrate only on the reservation policy like is mentioned here there is a fixed table there is a reason entry that is added by I mean you need to know what is the reason for the entry into the neighbor cash and then you can have a reservation based policy with this you can have a stable Network even if the node density where is across the deployments so we intend to remove the signaling recommendations because it\u0027s very difficult to get it generally applied across all the deployment scenarios in some cases we might cite some examples but we are trying to remove the signaling recommendations from the draft in the subsequent version if the working group has any comments about this then I would like to know Mohit so I\u0027m not a 6lo expert but like don\u0027t you have the neighbor cache entry entry it\u0027s based on the signaling that you receive right you put something in the entry based on some signal you receive so even if it\u0027s for your specific scenario at least that\u0027s a scenario that you are deploying and you actually actually have products that you are deploying so you could write this is "
  },
  {
    "startTime": "00:30:30",
    "text": "our specific deployment model and these are the signals we use when putting things into the cache these are the signals we use when we remove things from the cache and it may not be applicable to all scenarios right so let me give a specific example in this case yes we have a deployment in place which makes use of the implicit signaling basically we make use of ripple signaling to add interest to the neighbor cache the problem is even with ripple as a signaling mechanism if we specify that you can add neighbor cash entries based on triple signaling it it may be interpreted that you can do that across all the deployment scenarios when one problem is in in case of NS na or NDB signaling there is lot other things that are happening for example now we have CG is we have ap nd we have six 67 75 update which is doing lot of stuff all this is not applicable with this implicit signaling mechanism so that was what I mean we can cite a deeper moment we can cite a specific example but yeah that would be too limited in scope eiffel so so if I move it so if I understand your concern is that you are using something on the ripple layer and you know making changes on the 6lo layer in the in the neighbor cache and this is somehow like you\u0027re mixing things between layers yeah yeah yeah so one might an implementation go might one implementation can do something like this based on the d io message it has decided that the preferred parent is selected based on the DR message you also add up with neighbor cache entry based on it other another implementation can you decide to do explicit nsns signaling before adding an invocation tree this is also possible and SNS signaling gives you some additional control over other stuff which people sitting alone cannot give so some one other idea said I guess some long time ago that if you do it it Slayer violation if I do it it\u0027s cross layer optimization I think if it works for your scenario put it there and you know make it clear that this is this is how we are deploying and this is how we intend to do it may not be generally applicable and you need to do some of these things if you are running you know devices which have hundreds of not thousands of kilobytes of memory and flash thank you thank you for the feedback then I\u0027ll take into consideration this thing and maybe I will discuss with other authors on this point as well which are canta key developers as well okay the implementation progress we have an implementation which is almost finished one of the things that we found during implementation is we are unable to handle and see increase authentication related insane reason "
  },
  {
    "startTime": "00:33:30",
    "text": "with quantity because quantity doesn\u0027t support any network access protocol one way is to do is to the injuries by the way we have a private implementation which does all this but but we don\u0027t have an open source what we are trying to do here is we are trying to push an open source implementation as part of quantity and this is the this is the issue that we have faced so I hope it is okay to do this way yeah it definitely stabilizes the network to what extent we will be able to report the data by the next meeting good question so this network taxes in quantity I guess it doesn\u0027t do Panna and yes yes it it doesn\u0027t do a panel or there is an equivalent stuff I mean equivalent but a call to do that\u0027s all for so I have another presentation right okay so this is about fragment forwarding graph I have presented this previously in a day before in 6lo working group well when we presented this in six law working group please let me clarify before I go into the details of this draft that this is specific to the deployment that we are doing so consider the numbers consider all the figures that I am quoting here only in the context of what we are trying to achieve these are specific I will be quoting specifically two characteristics the numbers are relevant only with those specific two characteristics so for people who don\u0027t know about fragment forwarding they\u0027re the existing four nine four four allows you to do per hop reassembly you can every node sends a packet it\u0027s at every or immediate 6lr it is reassemble and then subsequently fragmented again and then since sent upstream or downstream whatever in case of fragment forwarding it is possible to have a train of fragments such that the the fragment as it is is forwarded to the next stop there is the table that has to be managed by every individual 6lr node but then the overall memory requirement the memory utilization for doing forwarding is much less this has been proved previously by another experiment from but yeah so our motivation our we we were really excited about this particular work we are really excited about this particular work we wanted to check whether it can improve our fragment forwarding in our scenario our primary motivation was to check latency and PDR implication not the memory utilization on the bottleneck node and we have been using a paper on signaling for the network access and EAP panel signaling is relatively bulky which causes fragmentation in the network so we were hoping that if fragment forwarding can solve that issue it will improve our network convergence time "
  },
  {
    "startTime": "00:36:32",
    "text": "okay the test that we started this implementation even before the drafts were adopted so we were really excited about this work we are really excited about this so the test configuration that that we used is we use eight know - or 15.4 in unsorted single channel mode of operation it had carry on sensing it has clear general assessment enabled but no RTC TS I don\u0027t know if anyone here use this lo pan with RTS CTS it has a high control overhead and no I I don\u0027t know of any implementation or any deployment which uses RT CTS with six lo with lo pan the node the the network configuration here is 50 nodes not a very big network it\u0027s a grid topology the the distance is specified here we use M Rho F with ETX as the routing metric trigger parameters and M Rho thresholds were all similar for all the test okay the data transmission frequency we had a sparse data transmission we send data every 40 seconds or 80 seconds or 160 seconds the data payload varies from 256 bytes Phi 1 2 bytes to 1 0 to 4 bytes respectively the reason why we did like this was so that we wanted to have equal amount of data traffic on the in the air but more or less fragments in there for example 160 160 seconds scenario will generate more number of Eggman\u0027s or payload than 40 seconds but the amount of fragments in there at in water time should remain same the data traffic in there should remain same please note that there was a random delay between 0.5 seconds to 5 seconds before transmitting each of this payload not the fragment and all the data here is distinct to the water router I think that\u0027s that\u0027s ok so the packet delivery rate that that that we found with with fragment forwarding it actually yeah the question that random delay is that in addition to the channel excess delay this is the delay that is added by the application there yes so the packet delivery rate that we found was surprising actually in case of per hop reassembly we found that where of reassembly is performing much better well if it turned out that fragment forwarding is is better or is almost equal or better then piranhas presumably when there is some sort of pacing in water what it means is you and I\u0027ll come to this point what if what is pacing so before every fragment is forwarded on the sender side we would add some fixed delay it\u0027s a fixed delay of 50 milliseconds 100 millisecond because it is much easier or trivial to implement this kind of delay mechanism on the sender side it\u0027s very difficult "
  },
  {
    "startTime": "00:39:33",
    "text": "to implement such delay on intermediate hops because on intermediate hops you might have multiple fragments coming from multiple streams so it\u0027s it\u0027s non-trivial to implement it so on the synth aside this delay was implemented and I we had a great discussion on the design team mailing list to implement this it improved the pacing improved the PDR drastically for fragment forwarding but also naturally it induced some sort of latency and it was a big factor the latency was a big factor you know so the reasoning part the Mac transferred failures if you see the macro transmit failures were relative were very high in case of fragment forwarding without any pacing it uses if you add some pacing with pre-assembly it\u0027s much better but one one one more point that I so the observations here is this all the observations here are quoted are in context to the setup that we have and it\u0027s not a very general setup it\u0027s very specific to our deployment fragment forwarding seems to depend on pacing if you add pacing the read latency and if you add pacing the real latency is negatively impacted naturally at least in this case Ferrari is simply seems to be doing better both in terms of PDR as well as latency the L - but clearly LT primitives have a bigger impact than anything else on this whole scheme so one of the key takeaway from from this experiment was that if you are going to implement fragment forwarding without I mean without considering any l2 primitives I mean without considering what your l2 is you might have some surprises so it\u0027s better to have it\u0027s better to get your l2 characteristics in place before thinking about such a scheme fragment for a drop due to memoral unavailability in our case at least at least it was nil and the reasoning was that we had a great topology it was a sufficiently balanced network and the traffic patterns were sparse so not much of a memory issue for us but if you have a constant fragment constant payloads going out of the node then you might run into memory or an ability issues and fragment forwarding in that case might perform much better secondly secondly one more important thing is fragment recovery might actually help in this case because we found that as the number of fragments per payload increased it resulted in exponential decrease in PDR or R or Layton exponential decrease in PDR so if you have fragment recovery of some sort which is another draft in six slow it might actually improve the performance the simulation tool that the simulation tool that we used was Whitefoot framework basically it\u0027s an MS 3 a larger loop and in the back end and there are some implementation quotes that we mentioned we needed some slack to be added in first fragment yeah clearly more "
  },
  {
    "startTime": "00:42:34",
    "text": "experiments are needed there are different ahrefs that have to be tried out more optimal pacing algorithms that have to be thought about and we are hoping to do the same experiment on the actual hardware setup Thank You Carson customer a quick question if I understand your parameters right the packet takes about four milliseconds to be transmitted and then we add a little bit of inter frame spacing so we have something like like a five millisecond wait of a package and it\u0027s interesting that 50 millisecond is kind of a key and 100 millisecond is perfect so what\u0027s the relationship between those five milliseconds and the 50 and 100 to avange which five milliseconds you\u0027re talking about III know about the actual propagation delay or no I\u0027m talking about the serialization time of the packet I guess in the air for about five milliseconds time so that means it arrives at the next stop the next hop tensage so if it were able to do this immediately then the channel would be clear again after five more milliseconds right but you have to wait fifteen milliseconds or even better 100 seconds so do you have a hunch but the relationship between this theoretical 5 milliseconds and the real 50 or 100 might be so what we think is that the train that the fragment train we use you are trying to send as well as receive at the same time on the intermediate LR that might be causing the issue so you the downstream node is trying to send as well as the upstream 6lr is also trying to send at the same yeah I know what causes the issue the question is what what causes these numbers and maybe it\u0027s worth actually looking at other numbers and trying to come up with a characteristic there right right so one of the things that we looked at was the mac transmitted failures now here only the mac transfer failures are mentioned even the second and third attempt so we have a macro macro try of three the second and third items were also relatively much higher in case of fragment forwarding so what this tells me is and we had clear channel assessment in this cement enabled CC was enabled we had carrier sensing in place even then this had there were a lot of failures with record forwarding so in case I think yeah what you said is we need to check what caused that failure on at a much granular level yeah what is ready to finish this what I\u0027m trying to say is this is an interesting result and it requires some diagnostic work to find out why it is that yes thank you thank you we\u0027ll have a presentation next time hopefully you are up next so it\u0027s it\u0027s "
  },
  {
    "startTime": "00:45:45",
    "text": "still today why are you going to join I guess then we can move to the next presentation and come back to Rene a day at the end gotta go ahead occur in France so what about these drafts the goal of this draft its target date for device and let\u0027s say Internet of Things device so the idea is to evaluate the security of the device itself by reduced number of attribute let\u0027s say five billion attributes the ephemeral odour one time for my programmable memory secure my on loader tamper resistant key and diversify a key one question should be is it necessary to add more attribute but if you had more attribute its mean we will define a lot of subclass of device so from this classification you get eighteen device class let\u0027s say two classes without bootloader and sixteen classes with bootloader so the class of the device is a set of five billion tributes the FDC OTP FLD sec trt second and eve key so what is the goal of of these of this draft when you talk about sick software updates one guy in from France and National Security Agency say if you don\u0027t have update for IOT it\u0027s "
  },
  {
    "startTime": "00:48:46",
    "text": "not serious it\u0027s mean nothing\u0027s will works and your plan to deploy IOT system will completely fail so update is needed but if your update can be crooked easily then it\u0027s more than having no update it means what you are going to deploy is put on shore a kid named networks so it\u0027s in this draft we want to provide a creative estimation of risk induced by remote firmware updates according to the device logical and other security resources so the device architecture so you have a mind processor and in the main processor on the processor you are non-volatile memory it means it\u0027s a memory and usually it\u0027s fresh or square problem and it\u0027s mean you can erase this memory or write this memory and okay it\u0027s non-volatile memory but it\u0027s mean it can be erased and this is quite fundamental because taking a look at what society today you will find simply that a lot of device can be completely erased so it\u0027s menu believe you you have a book order and in the device but it\u0027s very easy to simply erase the bootloader and to refresh with another bootloader that\u0027s why the only insurance karoke huge or security is from insurance you may have device is the use of one-time programmable memory and I prefer this OTP term rather than one term because Renaud me memory doesn\u0027t really mean that you can only read the memory and usually it\u0027s mean you can write the memory with as a mean and in normal operating condition you cannot erase the memory and so when you use one time program memory memories damn it\u0027s mean you have something like refused I don\u0027t say that refuses perfects you can reconnect the fuse for example but it\u0027s let\u0027s say you have given insurance that you cannot erase this OTP and another way to to put software in a device is to use physical protocols you have many physical protocols your parallel and so on and this protocol used to put code and data in the non-volatile pasta sauce and because anyway you need a communication at least for for the update you have a communication process so in all IOT device you have a communication processor same time the "
  },
  {
    "startTime": "00:51:47",
    "text": "communication processor in fact is much in the mind pop up a cell say it\u0027s the same thing you have a system on earth on shaggy device by the communal processor two as the same the same structures so to go further you have a device with two main features you have a family let\u0027s say you call oh you are not first thing is to identify why is the bootloader only needed if you are no bootloader it\u0027s me you are going you need to use physical processor in order to put the code in in your ddddd device it\u0027s mean so you have a lot of physical protocol available for for the chip and it\u0027s been film where loader is not some things than that you may use the device without somewhere Loden and this will give you for example other security products the existence of physical protocols for flashing ddd device quite a suppression attack and suppose shannon attack today is a very sensitive issue for all the device including the networking the device the IOT device and so on it\u0027s been if you have no permanent memory in the device you can reflash the code you want to flash in the device and this is very easy to do during the suppression supply chain process because it\u0027s mean your device could be undone by many people and these people will have the ability to for example to erase your original boo-boo-boo-boo Triodos and to a fashion another inside so yeah basically these two kind of device with and not boot if you have no shame where it\u0027s mean you may have not no TV which means in that case you have no minimum the device behavior you cannot you don\u0027t know if your device is simply your device or not and there\u0027s a kind of devices you have OTP me memory which usually is is used to stop battle of the few moi so you will have a minimum device via a guarantee on just part on the left you have device that include VMware lalala - monkey Corbeau Trudel and so you have to kind of devices all you have no permanent memory no TP it\u0027s been in fact you have a bootloader but you just you "
  },
  {
    "startTime": "00:54:48",
    "text": "will never know if the bootloader the right boot and screw Sebastian attack your device could be more device and this mean all you want to do for update software would likely completely fail and as a generality it has the option on your an OTP in the device and then in spin you you will have minimum guarantee about your device BBP behavior so that says is this draft is not content with device that include bootloader with and without OTP okay so we start with this device with a familiar FML attributes set to true you have a bootloader and as so the second attribute OTP will give used insurance that is it possible or not to erase the bootloader for example in th you have an OTP and part of the loader usually the ash of the public key is in fact in this memory so part of the security attribute for T came from the fact that you have this kind of one-time programmable memory and if you google for example microprocessors and an run you will find what will you likely which are going to get is the datasheet of a secure amount with which the data sheets that you could not have and without a known without in the agreement because the specification of this kind of device are not perfect so let\u0027s say most of processor have not OTP today only flash memory and so they use physical protocols to be flashy and the first code which is fresh it is is the bootloader then the next attribute is a use of sexual my Allah Allah does that\u0027s to say man we are running out of time could you okay wrap it up so do you have security you not and some would have no security for example and it\u0027s very common to do to have no security or not since I am and I like that and even if you put security in your boot reserve the issue is your device tamper resistant or not that to say that all symmetric cryptography may be broken by side channel attack an isometric - so it\u0027s mean even if you have a secure boot "
  },
  {
    "startTime": "00:57:49",
    "text": "order if you have not this tamper resistant key attribute it\u0027s mean all the key could be recovered by you well no attack boss for symmetric and asymmetric cryptography there was a competition last year and the goal was to to write a program with AES key inside and it\u0027s it has been skipped six months and also program must be broken let\u0027s say between a few seconds and three weeks so it means there is no way to this today to securely compute a symmetric or asymmetric algorithm by software and the lastest tribute is a diversified key it\u0027s mean because you know that you have side channel attack if you use hardware without temper resistant key if you put for example one is key for all the device it\u0027s mean the recovery of one is giving key will break all your update architectures that we need to do a hard stop here thank you so we look forward to more updates will give one more try to Renee and see if it works we are running out of time Renee can you give it one more try [Music] do I need to press anything hello hello oh okay okay now under you so what I will do is I probably will go to this slide number four because I think I have two minutes or so yes long no not notice from the the piece on yeah they fill me up so I I presented the this document in Montreal and since then I think it became a document and there\u0027s a missing pieces at a time because I had to run some computations it\u0027s actually good to quite some while but the results are included now in the document version zero that I posted by the cutoff date but since then I\u0027ve also provided a few examples and the examples have to do with essentially how can we deal this different elliptic curve flavors in small device I devised Oscars it\u0027s our own is curves or one of the C over D curves which is either the one used for the film key agreement or for signatures and the main crux of the drafts is really to try to morph them into something that decreases the code size requirement and also makes it easier to specify new things so I provided too "
  },
  {
    "startTime": "01:00:54",
    "text": "many examples one of us if you have a small device and you run for example in agreement on it like in the co-state protocol then maybe you can also implement the so-called efforts signature scheme in which also has been a use in the same coast a scheme and also in Hawkeye I saw using the same implementation and let\u0027s go to the last slide so basically I show that you can use all these different flavors of course by ripping em them into the same shape and so that you can use the NIST implementations and reuse them to also implement the co fatty curves but also to use single implementation for both the after signature scheme and the Montgomery letter that\u0027s you still saying the Kosei scheme the main question I have is the draw for you looks quite technical and the first five pages are really about the main content is and everything else is essentially a huge tutorial into all kind of transformations so I would really like to have a little bit more feedback and I already got some good feedback from Nicholas Reznor who I think he did a thesis all this project and I also would like to have some implementation inside so I got some information I see nxp as a some technical notes about how to implement the CV curves using their kind of alternate hardware is affected then speed up but the good it would be useful to see if the road if it has some other uses as well and maybe also the drawbacks that puts you in a draft so mainly main question for me is when you have a chance have a look at mostly the normal appendix part of the draft which is only like five six pages and includes it\u0027s a back page and let\u0027s have some feedback and see how we can move this forward and maybe fill some gaps that you might may discover Renee we are already three minutes over times I think it\u0027s enough time to close the meeting but it\u0027s for the group to provide more feedback on this draft I think it\u0027s provide some useful information gosh quick comment Thank You Unni Thank You custard okay so I guess we need few more reviews before before we progress on this document that\u0027s it for Elle "
  },
  {
    "startTime": "01:03:55",
    "text": "McPherson where are the blue shades we are done for today thanks Randi and thank you all thank you "
  }
]