[
  {
    "startTime": "00:00:30",
    "text": "[Music] all right um okay welcome it\u0027s that time it\u0027s Singapore and what Tuesday so I guess it must be time for token mining let\u0027s start with our usual note well we\u0027re pretty far into this but for newcomers it\u0027s worth to note the IP or rules of the ITF and how to relate to them and from now on I\u0027m going to assume that you won\u0027t understand this stuff so we have a you know fairly light agenda today we\u0027re gonna get updates on two of the documents that are still being sort of processed by the working group and but before that John\u0027s gonna sort of give an update on where we are with our core documents are currently in ISC a review I did they screenshot of of the data tracker to help y\u0027all of course I can\u0027t see it from here buddy this one has a switch okay so the three specs HTTP token binding negotiation and token binding protocol so we\u0027ve been through with the with our responsible ad both of those documents and he\u0027s pulled the plug on the two-week review period we met with him this morning he had a couple of issues or questions around the HTTP around the redirect Federation stuff so we agreed to add some xsplit Ori texts saying essentially this is intended to be used with existing Federation protocols that actually have audiences and and other things that if you were to invent a completely new Federation protocol and just tried to use token binding your mileage may vary it\u0027s probably not a good thing to invent a new Federation protocol without appropriate security reviews I mean God knows what somebody might attempt to do just using token binding in a cookie so "
  },
  {
    "startTime": "00:03:30",
    "text": "with a bit of explanation so he\u0027s going to also pull the submit that suggested today based on our agreement to update some security and implementation concerns Mike Jones clarification question so he is asking for clarifications of the exposition no normative changes no normative changes thank you it\u0027s basically to clarify the underlying assumptions that were go into the term Federation right fair enough right so he was concerned that a bad party could do an HTTP redirect ask for a token bound something and then be able to do something with that and in our discussion we attempted to explain that there is nothing more that you could do than what you could already do with a bearer token at which point you\u0027re completely screwed you would have to even if you got every single security thing wrong you would have to get a bunch of security things wrong to be able to exploit it with token bindings so it you know work I think we\u0027re in a good good shape he seemed to accept our explanation so that\u0027s that\u0027s essentially it hopefully we can force this through the iesg and get it done by the end of the year right so for the rest of our agenda unless anybody has you know questions or comments about the status of core documents but it does look like we\u0027re sort of seeing the end of the tunnel there yeah it\u0027s it\u0027s good work all right and I think we leave the floor up to Nick come talk about let\u0027s see if I can bring that up so I\u0027m actually not talking about zero RTT as is listed on this agenda I\u0027m talking about TLS 1.2 combining negotiation for TLS 1.3 as in like 1 RTT so yeah this is a short four-page internet draft to describe how to update a tea bean ago for TLS 1.3 next slide please there are really only two changes that this draft covers the first change is to the token binding TLS extension so in the client flow in both TLS 1.2 and 1.3 we send the token binding TLS extension in the client hello in 1.2 the server if it\u0027s negotiating token binding puts the extension in the server hello "
  },
  {
    "startTime": "00:06:31",
    "text": "this draft updates that to say that in TLS 1.3 that extension goes in encrypted extensions instead TLS 1.3 also requires that all new extensions describe their interaction with cor TT this draft says that you cannot have both token binding in too early data in encrypted extensions ie you cannot have both token binding Zorc and the same thing this leaves it up for these 0 RT t draft which I had previously started work on to update this draft to say how you can do that and just as a note it is allowed to have both token binding in the early data in the client hello this means that a client which is can do 0 RT T to a particular server but has not done token binding is saying that I also support token binding and I\u0027m willing to do tow combining instead of 0 RT T on the connection of server sports that next slide so yeah as section 4 is just an update of the token binding signature definition in TB proto it describes that in terms of the RFC 57 o5e km value TLS 1.3 provides a new definition of an exporter but we keep all of the same parameters there might need to be some word smithing here but essentially I tried to make this v8 non-normative section to say by the way here\u0027s what this looks like but it\u0027s just the same as the previous draft so yeah that\u0027s basically all that is in this draft yeah right so um I guess the question this begs the question open that\u0027s next steps that is right where do we go what do we take this right yeah so what we can do with this is my suggestion would be that the working group adopt this as a work item and this would be a separate draft from these new RCT draft another option could be that we just merge both of them into one draft for doing it\u0027s one drafter updating token binding for TLS 1.3 right so that\u0027s a good question for the working group what do you guys want to do it is all in one or separate drafts or what yes now is the time for a run for the Mike Mike Jones Microsoft to the question of whether to merge them is it ever meaningful to implement one without the other yes I think it\u0027s very meaningful to implement this draft without the 0rt draft a an implementer could decide that they don\u0027t like the security properties of zero RTT token binding and she was just to implement this one thank you under a pop of Microsoft just you know my take on this is that token binding with one or two G makes a lot of sense and token binding with one RCT TLS 1.3 has about the same security properties as it does with previous versions of TLS "
  },
  {
    "startTime": "00:09:32",
    "text": "whereas token binding with zero eg has weaker security properties and you know to me it\u0027s actually questionable whether that\u0027s worth implementing so I would like to see those drafts separate and go their separate ways in the working group right and this is sort of this situation now anyway right so the I guess this if nobody else has an opinion stronger opinion about this I think the question on the table is whether to adopt this work as a working group item and move forward with with it anybody if there are no nobody else who wants to express consent opinions about that we can do a great consensus colander in the group so for the for our our first couple of hums the first one is support adopting this as a working to fight them the second would we oppose and the third is you know need more information slash don\u0027t care all right so on maybe you if you like if you like the idea of adopting this as a working group document all right opposed don\u0027t know don\u0027t care need more information okay so that\u0027s fairly clear consensus on adopting this is work about them so I go ahead and post our addition as a zero zero we can communicate a separate dollar name right but yeah now will confirm it on the list but this was fairly strong comes in con salsa so you know okay thank you we can talk about the name while we wait for the list all right and that means we\u0027re - Brian is this the right slide all right someone talk about HTTP still combining in conjunction with TLS terminating reverse proxies tied a slide which has document identifiers and everything so I\u0027m gonna repeat a lot of what I\u0027ve said in in previous meetings but kind of give an overview of the problem statement is that HTTP applications are very commonly deployed behind some kind of TLS terminating reverse proxy and it\u0027s a that sits between the client and it\u0027s a very common application deployment pattern not the only one but it comes up quite a bit and this is true sort of across all spectrums of deployment there\u0027s products "
  },
  {
    "startTime": "00:12:33",
    "text": "that do this like an f5 there\u0027s open source solutions that do this your engine X or your Apache and increasing their services that do this sort of thing like a cloud flare or application load balancer from Amazon or a variety of them so it\u0027s sort of applicable to both the old deployment patterns and the new and the issue here is that in order for applications that sit behind one of these terminating reverse proxies to actually take full advantage of token binding some kind of information needs to be passed from the the component that\u0027s terminating TLS back to the application at least in the general case I know there\u0027s there\u0027s a you know an example of the engine X plug-in that sort of automatically binds cookies for you and and sort of makes that transparent to the application but in order to do more general things all you would need might want to do with token bonding including some of the Federation in these cases you really need to expose more information to the backend application and let it do some how do the binding and the verification in the absence of some kind of standardized documented way to do this different deployments are gonna do it differently and that\u0027s obviously really bad for interoperability ideally we\u0027d have something here that is is documented and standardized enough that can be a turnkey solution so if I\u0027m running my location behind CloudFlare I can flick a configuration switch and CloudFlare and and code to the standard a flip of switch in my application and things just work that\u0027s a goal that\u0027s the problem statement next slide please just a little bit of history on all this so I first brought this up in Seoul and we got a rough consensus to work on the problem from the working group there are two general approaches discussed at that time they\u0027re still valid today you can kind of do it one of one of two ways one is to expose the token binding IDs to the backend application somehow and the other is to expose the ekm and a few other things to the backend coming out of that meeting I got the sense that people were liking the ekm version of the idea so I wrote a draft Campbell took behind TLS term zero zero and that exposed the ekm to the backend and a few other items but mostly the APM to the backend as a header thankfully along lines are somewhere Jeff coined the turn T TRP which has saved me a lot of typing in the meantime thank you and huh but there was some pushback on that approach from a number of people largely from people actually implementing the the some work in Apache and nginx about sort of the the complexity of doing it more so for the backend applications negotiating the types and sort of simplifying making it simple to adopt it from the backend application approach wanted to talk about that draft in Chicago and I did a little bit but we were a little rushed I was at the end and the meeting was cut short in the "
  },
  {
    "startTime": "00:15:33",
    "text": "main session due to time working on more important things like the core drafts so what it did was announced a an open side meeting that week and in them I don\u0027t what we call it the ad hoc room which another number of people came to announce it on the list a number of people came to it and talking through some of the issues there there was a clear preference within that room to that favored the approach of passing the the validated tow combining ID to the back-end application so in between that and Prague I wrote a new draft and it does exactly that exposes the token binding IDs to the backend there was an editorial update to that and then into Prague next slide at Prague or shortly after we got consensus to adopt that version of the document as a working group draft and the only real concrete feedback at that time that I was able to act on was to add the SEC prefix to the headers that I was working with I\u0027m not sure it really adds much but there was there was a desire to do so at least limits those being able to be set from JavaScript within the browser so we did that and that\u0027s in draft o1 and next slide so just kind of getting in the the nitty-gritty details of how it works the draft defines HTTP headers and this enables the the TT RP in the backend application to function as a single logical unit implementing token binding and it works by the TTT RP negotiating tow combining with the client and validating the token binding message from the sec tow combining ID header and then removing that header from the dispatch request to the backend what it does then is add a sec provided token binding ID header with the base64 URL encoded provided token a binding ID adds that to the dispatched request and then if applicable if there\u0027s a refer to combining it does the same thing with the referred to combining with a different name predictably nameless SEC referred to combining ID this requires some level of trust between the TT RP in the backend which is very very common for these kind of deployments more or less required in all of them and it requires the TCRP to sanitize the header so if the client tries to inject the sec provided token binding ID header the the TT RP has to strip that and remove it so that the there can\u0027t be sort of a impersonation isn\u0027t the right word but basically in personally in the toe combining like ID key from the client the TRP needs to prevent that from happening by sanitizing any of the headers that come through and just deciding out the original toe combining an ID message or sorry the original full token binding message is not provided the back end because it\u0027s dropped from the original request next slide and it\u0027s pretty simple pattern but sometimes pictures a little bit helpful so I tried to draw it up here from the client and we\u0027re doing old fashioned "
  },
  {
    "startTime": "00:18:35",
    "text": "token bonding over HTTP and that includes the TT RP negotiating obviously it validates the token binding messages those headers as a sanitization and then if all is good with that it removes what came in the original request and this is a very much in line with what\u0027s suggested in the token binding draft which is the token binding protocol draft which is to make available to the application the raw tow combining ID for for doing the binding and it passes that to the backend and then so if the backend application is issuing a cookie it combined to that if it\u0027s verifying a cookie you can verify against it but the actual work of validating the message is done in the reverse proxy and next slide please so the elephant in the room or at least what I thought would be in the other four in the room but I don\u0027t see Eric here um even in Prague I was there was some concern expressed about this this approach largely about header injection using sanitization as the means to prevent that and the concern that was raised was that it doesn\u0027t failsafe so if it\u0027s not properly implemented or it\u0027s you know partially deployed or not properly deployed it doesn\u0027t feel safe in that there there\u0027s no way for the backend application to detect that a client\u0027s injected the header it has to sort of blindly rely on the T TRP to strip those but in my humble opinion client header injection through reverse proxies is not at all a unique problem to this particular application of token binding or the functionality of this draft and I think it would be wildly inappropriate for this draft try to define some one-off additional mechanism for preventing this and the reality is that stripping or sanitizing headers right now is the de facto means of dealing with a sort of thing in practices a in practice a day and it\u0027s sufficient when properly implemented and it\u0027s normatively required by the text in the draft let me get through this slide maybe and I further wanted to say that the the unsafe failure mode which it is if the failures there but it\u0027s sort of not exactly fully catastrophic if the the the proxy isn\u0027t correctly sanitizing headers if it\u0027s implemented improperly or if it\u0027s somehow sort of half deployed half not deployed the failure mode isn\u0027t exactly catastrophic you lose the if you potentially lose the protections afforded by token binding which isn\u0027t great but it\u0027s basically the current state of just about everything on the web today so the the failure mode is is is just sort of falling back to where we are today so in my view the I guess the "
  },
  {
    "startTime": "00:21:38",
    "text": "summary here is my view that the the current functionality draft requiring the TT ERP to sanitize the headers as appropriate is is sufficient and appropriate for the security mechanism of the draft and yeah please yeah just a question yeah the one way just state your name everybody state their name at the offense of the zone so one way of making this failsafe I think would be for example offer a mechanism with a shared secret to H max this the data from the server to to to the back-end application from the proxy have you considered that as an optional mechanism so there\u0027s a lot of ways all variants of maybe H marking the data may be placing some sort of shared secret just in a header indicating that the the processing has occurred listing out the the various headers that have been processed by the reverse proxy there\u0027s a wide variety of way - to try to address the problem what I\u0027m what I\u0027m saying is that it\u0027s it\u0027s it\u0027s a broader problem than just this particular draft and I don\u0027t think it makes sense or is appropriate for this draft to define a single sort of one-off solution for this it would be nice if a broader solution existed that maybe we could point to but in the absence of that I don\u0027t want to try to solve the bigger problem here I don\u0027t want to take a one-off approach to solving it for just this particular set of headers and would prefer to rely on what what\u0027s what\u0027s currently in the draft so you\u0027ve probably spent way more time than me and the problem and but it feels still to me that you\u0027re making the wrong conclusion because you\u0027re you are defining in header ID which carries some data and you have the opportunity to specify the syntax and and and their conventions for that data to be passed so it\u0027s your opportunity also to specify how I could have security data like H Mac dealing with it if I if I could share have a pre shared key if it\u0027s important for me to make sure fail safely that this data actually originates from the for the reverse box establishing shared secrets between the systems is is one thing that I\u0027m looking to avoid so I guess it could be optional I I would prefer simplicity in the draft and in deployment and hopefully adoption versus on top of security that I believe is sufficient today versus adding optionality or additional complexity or additional sort of key management "
  },
  {
    "startTime": "00:24:38",
    "text": "requirements between systems Mike Jones Microsoft another thing we discussed at the previous ITF it\u0027s on the next slide is this I\u0027ll wait till the next slide then I think if you\u0027re gonna say what yes do your slide then I\u0027ll speak well just going back to so I sense there are a few people that that would like something more I I\u0027m I think pretty clearly against adding an additional functionality to try to so one thing we did actually have this discussion I can\u0027t remember which meinen list this was it don\u0027t sag it was sort of this it was yeah and and there was actually some people expressed appetite for doing something general right yes and but nobody suggested that that toe combining was sufficiently different to warrant a special mechanism for this right so so so in fact um they actually don\u0027t bear you out step on I mean at least that was the consensus in in the discussion that happened when this was brought up by Eric Ries Cora after after after Prague right you know so we\u0027ve basically covered this and you know I\u0027m I\u0027d be totally excited about they and and support like a general mechanism just that nobody stood up to do that yeah somebody should offered to help doing it but I don\u0027t want it to hold this up and and there wasn\u0027t and nobody a lot of different right ideas but no one\u0027s really right and nobody suggested that this be held up no I mean even Necker hasn\u0027t suggested that okay I was feeling like he\u0027s sorted so I was trying to address it I think he\u0027s sort of backed down from that okay so I I don\u0027t I I don\u0027t I\u0027d be surprised if we land there all right then we can move from there Thanks next slide then elephants supposed to be cute though it\u0027s so the other issue that was raised in Prague was support for other token binding types in the current draft oh one there\u0027s only explicit support provide for provided for the provided and referred to combining IDs via these two headers we talked about before from the 99 minutes I went back and looked at that that someone has used cases that require more than two token my name\u0027s and a use case description of that was requested and I\u0027ve not been seen because I gave it verbally at ITF 99 or do it again here well a more detailed description was requested because I\u0027m I guess I\u0027m looking to understand the case and whether really warrants Standardization for something like this "
  },
  {
    "startTime": "00:27:38",
    "text": "and and beyond that looking for a little bit of input and consensus from the from the working group whether it it makes it make sense here because at least the way that I understood your use case was that you had Microsoft develop clients talking to Microsoft develop backends doing something with a proprietary Microsoft toe combining type and that is valid and reasonable use case but I don\u0027t think makes sense in the context of this kind of standardization let me this is Mike Jones at Microsoft I\u0027m going to turn the question on its head if I may the token binding protocol document and the token binding HTTP document can communicate token binding IDs and security information associated with them for 256 token binding IDs if token binding IDs other than 0 \u0026 1 are used in this document that information is thrown away that\u0027s not good protocol design it\u0027s a presumption of extensibility and application here that you\u0027re right if there\u0027s if there\u0027s another program binding ID that comes up in the web context you\u0027re gonna pass it yeah yes and it\u0027s great protocol design if it keeps it simple and that case never arises and so the request for it that\u0027s an assumption that isn\u0027t borne out in the token binding protocol document or the token binding HTTP document well and I can write this on the list but the short description is if you have something with multiple audiences and those audiences are well-known if you\u0027re following good token hygiene you\u0027re gonna have to have different token bindings for one audience than the other and you know you can use the proprietary word all you want but these features would be available to Microsoft customers as well as Microsoft I guess I would I would be interested in actually seeing what it is having written down what it is and and getting some some input and consensus as to whether this is in fact a an extension point that we want to allow for in the standard it\u0027s not an extension point it\u0027s not throwing information away it\u0027s not you should have to justify tossing information that\u0027s present in the underlying protocol it\u0027s an extension point in the underlying protocol because there\u0027s two defined and there\u0027s 254 extension points available and so it\u0027s a it\u0027s a you shouldn\u0027t presume they won\u0027t be used I\u0027m presuming they will not be used in I think that\u0027s bad protocol and I think it\u0027s simplifying the protocol where "
  },
  {
    "startTime": "00:30:38",
    "text": "appropriate it\u0027s cutting off use cases and so I\u0027m asking for an actual description of the use case so Nick Harper I was going to point out that the token binding protocol also defines extensions which is a separate space than these two hundred fifty six types of token bindings and right now a tt RP doesn\u0027t describe anything to do with the extension so my Jordans this point that\u0027s throwing away information but I think that\u0027s acceptable in this case I think that TT RP is designing a protocol for the majority of use cases not all of these cases of token binding and I think that\u0027s acceptable to have a protocol that is covering the majority of use cases if they\u0027re yeah well and in the future there might be extensions that are defined to extend it it\u0027s not going to support it and I think that\u0027s okay today we don\u0027t know all the ways that\u0027s going to be used let\u0027s make something that is generic enough for what\u0027s going to be used but we don\u0027t need to worry about every single possible edge case in it so can I just ask a question to Mike would you be more happy if there was support to extensibility that match in ttrt that matched what the extensibility and the core protocols yeah I want it to be defined how this additional information that may be present in the underlying protocol is passed through I recognize that most of the initial use cases won\u0027t have that header or headers whatever they are but I do think they should be defined so that if you say after my ears want to clarify so there\u0027s a difference between sort of making one-to-one representation and making a representation with for the majority case but with extensibility that optionally covers all the other cases if and when you need them right so sure right I agree yeah and I want to sort of I want I want to ask a question about the second case I did would you be more happy if yes it is everything isn\u0027t carried through today but here\u0027s how you would if you wanted that\u0027s exactly what I\u0027m asking I\u0027m just trying to find consensus well I think you\u0027re asking for a defined mechanism here and and Lafe I believe was saying would it be sufficient to have some wording that said here would be the extension thereof if you wanted to pass that in the future the goal of your draft as stated in your introduction is enabling Interop among such terminating servers then you have to actually define the mechanism yes for for things that are defined and I keep coming back to that there\u0027s no other current definition of other token binding types so yes there are it\u0027s 2 through 255 just because I don\u0027t "
  },
  {
    "startTime": "00:33:40",
    "text": "have a name doesn\u0027t mean that they don\u0027t have identifiers so I have a question do we since we don\u0027t know what these other token binding types are are there specific processing rules that the reverse proxy would need to know to actually be able to extract the appropriate information from the token binding types or are they or is every token binding ID exactly the same with a different number yes that\u0027s what we have so far Google I\u0027m getting what Mike is saying is if the names of the headers were SEC token binding ID zero take token buy any ID one blah blah blah you covered for all the cases but then in the interest of usability of the spec sure it\u0027s much clearer if you\u0027re saying the photo combining versus provided token mind you so Mikey the question that come up with a way of allowing the the undefined ones to be passed through as well I think so that was what was requested and I\u0027m kind of pretty agnostic as to the syntax I mean I would be ok with an other token binding IDs syntax where there\u0027s pairs of numbers and IDs all encoded in some string I would be ok with SEC token binding ID to sect took and binding ID 255 being defined I you know use whatever syntax you think you want I recognize that most initial implementations won\u0027t have it but I think we shouldn\u0027t be throwing away information which is present in the underlying protocol especially when we know that there are multi audience use cases which are real anyway that\u0027s my request do you think that you guys could sit down and sort of come up with I mean it\u0027s always easier for the working group to you know have a opinions about stuff like this if there is concrete text I\u0027m if you guys could you know come up with a few lines right defining this right it shouldn\u0027t be that difficult yeah I don\u0027t think technically it\u0027s particularly difficult to solve it\u0027s an additional header with or multiple headers although that that that makes the sanitization process significantly more difficult because you have to look for all 256 headers which is a bit awkward I\u0027m not saying we have consensus I\u0027m trying to figure out a way for us to determine whether we have consensus and it\u0027s always easier to have some I guess my request is an engineer defining one other took and binding IDs header which may or may not be present is fine my "
  },
  {
    "startTime": "00:36:44",
    "text": "request here is to actually understand and maybe it\u0027s just my lack of understanding the use case behind this not just that the underlying protocol has 256 but what\u0027s the use case that that you\u0027ve stated you currently have for it it\u0027s because we have what would be a auth resources which themselves then become authorization servers to other things that are logically resource servers in particular this this thing called the Microsoft graph boom where a client is the resource but then it gets a token which it wants to play to the graph and it\u0027s on a different TLS session and if you don\u0027t have it token bound all the reasons we\u0027re doing token binding go away so it\u0027s not very hard so it may be useful to actually document that because given that the token binding message needs to be signed by somebody that has the private key over the ekm there may be actual things that prohibit having it make sense to send right those token binding so it would be be useful to actually sketch out who\u0027s signing what and what does it mean so that we have a as engineers if it\u0027s concrete in our mind what\u0027s going on then maybe it\u0027ll be easier to make progress right and I may be able to do this with Tony I may have to go back to I tried in our conservation home Tony but that I may have to go back to our enterprise architects next week to actually get it but I can work on a syntax proposal with Brian this week all right done right so but did I hear an agreement that you guys actually try to come up without propo I mean you know at least Mike come up with a right you will offer concrete proposal right on the list working group says have it say about it and we\u0027ll take it from there yeah I would I would ask that the problem statement also be described concretely in there so that we can see whether the the proposed solution actually addresses the problem because if we\u0027re passing through multiple components then I\u0027m not sure it actually works just to expose the other IDs to to the backend so yeah we\u0027ll work on it right all right and the last one is that\u0027s okay it\u0027s just that it\u0027s yeah until next time which is in London that\u0027s London any other comments or questions so can I ask who has read the "
  },
  {
    "startTime": "00:39:46",
    "text": "latest version handsome thank you people all right and I mean other than the discussion we just had do you have like open issues you know that you are need to address the sanitization piece but it sounds less open than I thought it was all right so no that\u0027s that\u0027s the only open issue I mean it\u0027s sanitization could crop up in in um is you review or something just them but I guess the other question I was going to ask about what do you know about the implementation status might are you talking to implementers who are sort of signing on today\u0027s saying yes this is how we want to implement it there\u0027s there\u0027s not a lot out there but I I\u0027m been working with well there\u0027s one in engine X can you can you speak to it I know your original approach was similar but somewhat different in parsing a hash rather than the full ID sakura google yes it was a little different but I don\u0027t have any issues with updating it to the current draft and I think it\u0027s fine also since I\u0027m already up the question regarding token binding types is it fair to block this on unregistered talking binding types if the original protocol doesn\u0027t define any like presumably if we want to add new token binding types we would need to add them to the original protocol anyway right and the finder moon I think you or it could be I mean it it\u0027s not the ability between them it\u0027s not the point right find that the reverse terminating proxy level but all the reverse terminating proxy has to do to enable offer interoperation is to faithfully pass the information between the protocol endpoints yes particular Federation protocols or authorization protocols etc would have to define how these things are used and why but that\u0027s not the job of this document the job of the document is just to do faithful information transmission from the ternary terminating proxy to its client yes my point was about the fact that you there is now defined interval between client and server "
  },
  {
    "startTime": "00:42:47",
    "text": "anyway regardless of reverse proxy right if you are using some internal versions of the speak of the command right and I\u0027ll just say on top of that the there\u0027s a Apache module for token bonding that already implements those all right well and it implements the old way too but it\u0027s yeah it\u0027s dari so there are some implementations there are some yes all right yeah Rosanna from Google in fact our implementation in the TRP is exactly but we\u0027re not using sec we are headed there but roughly the same thing someone easily changed to using the standard headers again in your case it\u0027s maybe less important since you own the infrastructure top to bottom but we like having standard folk Alliant implemented and maybe if you were going to enable you know if you had your terminators in front and we\u0027re exposing this stuff to you know App Engine deployments or something like that then it would make a lot of sense under a pop of Microsoft so without taking sides in this debate I think it\u0027s it\u0027s totally possible that you know a future specification will define different types of token bindings I think such a specification could also define new ways of processing those new types of token bindings at which point the currently proposed design of TT RPE seems to have an issue because it looks like the the smart the smart proxy that actually implements token binding needs to know how to process those new things correctly so so I think there is a tension there and there\u0027s also no negotiation per se well I mean I guess I guess you negotiate the version of token binding but with the with the TT RP at that point but anyway so I think that if you have a new type of token binding and it has different processing rules then the TRP has to be intimately familiar with with that because it does all the work and only passes the result to the back end in this specification so I think I think there is some complexity if if we were to go with the other way where where the actual end point server does the validation and the TT RP just passes along the you know the information I think it would\u0027ve been easier to accommodate new token binding IDs in that other design that\u0027s just how it feels to me thinks it depends on the processing rules I guess and there are certain set of processing rules that are defined and turned currently in terms of what the signature verification is that could happen in the other place and my understanding of the ask is is to presume that new types would follow those rules and those rules only and then to to pass the validated binding onto the back will we\u0027ll work on it and get to a point where we can at least I guess put the question in front of the larger group as to whether it\u0027s something won\u0027t include oh yeah that\u0027s "
  },
  {
    "startTime": "00:45:49",
    "text": "the only there is some implementation I\u0027m hoping they\u0027ll be broader implementation interest once things roll but there\u0027s some already and that\u0027s that\u0027s the only open issue that I\u0027m aware so I\u0027m in terms of rough timelines we\u0027ve been asked to update our milestones they are somewhat temporarily challenged at at present so are we talking like at least to London you think before we can expect to have like see a working with law school here like all things being equal no no I wasn\u0027t knowing that these were outstanding I wasn\u0027t expecting that I think being realistic probably around London might be a reasonable expectation to go into or at least start talking about working group last call right I mean we do have like one sort of one serious open issue here that we\u0027re talking about right and doesn\u0027t there doesn\u0027t seem to be a lot of other things so okay and just to bring back Nick into the discussion did the same question for 41.3 where would you how much time do you expect to have to spend before you\u0027re sort of for one RTT 1.3 I think that will be it\u0027s a really short draft so I I wouldn\u0027t be surprised if that\u0027s ready for last call in London for 0rt T or I that one might need a little more time probably just waiting for implementations to see that people have actually implemented it right so London ish for 1.3 and later for 0 today was that yep all right that means open mic we have at the station I need a USBC oh you need to USB soon "
  },
  {
    "startTime": "00:49:08",
    "text": "if I can figure out the right command [Music] okay so last week ger Hadar whose name I probably just butchered here Gary asked me to remind people about this spec that koala calm bunch of you koala calm have submitted so this is our actual first token binding extension which of course Brian\u0027s reverse proxy would eat but this does actually this is an example of an extension that doesn\u0027t have you know it\u0027s going to have to be added in specifically because they have each extension is likely going to have different processing rules that that the reverse proxy is going to need to take care of so the general idea as near as I can make out is that koala com thinks it would be a good idea if we could have attestations at the token binding layer so that you know how the key is stored and other sort of network based information so they\u0027re imagining in one case that you would have protocol analyzers looking at your your traffic and raise flags based on attestations from traffic coming from devices at the HTTP layer has anybody in the room actually looked at this specification Tony you looked at an old version of it so they would like us to adopt this as a working group document but it would be a good idea before we do that for some more people other than Tony and Brian to have a look at it I think this probably needs to be fleshed out yeah the notion of having an attestation at touken binding layer isn\u0027t may be useful it may be useful for web authentication which is one of the things that they\u0027re they\u0027re thinking of knowing how the token binding key that underlies the token binding that web off signs over could provide some additional context "
  },
  {
    "startTime": "00:52:08",
    "text": "not that attestations for web authentication aren\u0027t controversial enough laughs this would be yet another one and they proposed Microsoft so there is great interest from a number of teams actually at Microsoft and using at the station with token binding because the security of token binding is the degree to which it improves the security of the token depends on the the strengths of the key storage solution that is being used so there is great interest in this I have not read the latest version of the draft yet but I\u0027ve read the previous one which was more exploratory so I would like to read this draft right before I made judgement on whether we wanted obvious or not but I think the actual area is very interesting to explore all right so the general the general idea there is has some support but we have to figure out the whether or not this is the right way to approach it I believe that yeah there\u0027s there\u0027s also we\u0027ll talk in the hawk meeting about device posture stuff that we\u0027re looking at for OAuth and you know the Microsoft team at the w3c meeting last week was quite interested in some of the new attestation stuff that you guys have been working on might be useful for for both of these things so we won\u0027t call for adoption right now but people can provide some feedback to the list maybe we can call for adoption as a working group document if there\u0027s general positive feedback okay other open mic issues anyone wanting to do show tunes [Music] we can send it to the list it\u0027s in the it\u0027s in the list of working group documents no it\u0027s never been it\u0027s never actually been presented at a write so the the authors haven\u0027t managed to come to an IETF meeting yet perhaps the next one I think they were saying all right anything else anybody with open issues on their mind pressing pressing needs to do show tombs no but they will be minuted and recorded including your show tunes hydrogenase there you go I got here late I\u0027m sorry so what did you guys say anything about the HTTP draft relative to last call yes we did and "
  },
  {
    "startTime": "00:55:09",
    "text": "what did you say I said that we discussed it with the area director and there was confusion in his mind about what constraints we were actually assuming so we discussed that this was intended to work with Federation protocols as opposed to just random stuff being passed around the the internet so we agreed that we would add some explanation of this is anticipated to be used in Federation protocols that have audiences and write check redirect URI zorse have signed messages etc and needs to be used in combination of with those things to have it be secure okay so what that in he\u0027s not ready to push it into law oh why do I do that he was planning on doing that today okay stun our agreement to add some language okay so I replied to that at lunch right before this meeting that\u0027s why I was late and I haven\u0027t seen that yeah and on ice in my message I\u0027m suggesting you know he really should have sent it to the list his comment I think that stuff should go to the list so I think he was mostly sort of not sure whether there his comments were were were legit yeah it or not I hate to bring it up with there with the authors and they are legit within a if you\u0027re not making certain assumptions which most seem to be yeah anyway especially be if we\u0027re gonna make changes suspect in regards these comments they need to be on the list so he should he or somebody needs to send his comments to the list and John\u0027s reply and Andres in mind need to go to the list please one way or the other I think that\u0027s excellent feedback for the ad if if he was here right and I will I excellent right I think you\u0027re right there\u0027s nothing in there that sort of anybody needs to hide about or be shy about it\u0027s just sort of comments and he could have he could have easily sort of made them today\u0027s I think there was just sort of hesitation whether he had understood the issues correctly that\u0027s fine hi Jeff again uh so also if there\u0027s any notes on the discussion because I missed the discussion because I didn\u0027t see the messages until during the first session this morning so there\u0027s any notes from the discussion please forward them to the list noted anyone else so in otherwise you get a full hour back of your time hey not bad alright see you in London oh by the way if anybody was came in "
  },
  {
    "startTime": "00:58:16",
    "text": "late and forgot to sign the blue shit it\u0027s up front you "
  }
]