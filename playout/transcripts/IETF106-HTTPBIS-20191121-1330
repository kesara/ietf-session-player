[
  {
    "startTime": "00:00:06",
    "text": "and could you possibly close those doors thank you so much they\u0027re very noisy crowd out there it\u0027s those 5g people thank you okay so I can talk through some these results again to them okay all right so this is HTTP this is the note well once again if you\u0027re not familiar with this you can find this by going to your preferred search engine on the internet and searching for ITF note well and it will tell you about our expectations regarding intellectual property and people\u0027s behavior and handling of things like harassment so please do be aware of this these are all policies which we do take seriously and apply the blue sheets are circulating did we get a volunteer prescribing we did not oh dear would anyone like to volunteer for note-taking as and then also have someone else on jabber scribing you can do jabber scribe we still need a scribe so note-taking please anyone we\u0027ll be going through the various extension drafts will be a lot of fun you didn\u0027t say no Oh Mike thank you you\u0027re you\u0027re you\u0027re a gentleman that\u0027s fine agenda bash so um I wanted to do a quick reprise of stuff that had happened in other groups if someone would be willing I\u0027ll talk briefly about what happened in sac dispatch because I was there if someone else could talk about what happened in DNS op regarding the new record type very briefly that would be really appreciated anybody wanted to do that I mean I can talk about you can talk about okay okay then we have a short update on what happened to continue to happen in the priorities discussion it\u0027s been the bulk of our time talking about our in-flight extension drafts and then we have a presentation proposal for new workaround compression dictionaries which we talked about before this is just a further step in that discussion and finally as time permits there\u0027s a proposal for a transport info header that we might get to any other agenda bession okay let\u0027s get right into it then so insect dispatch there were two interesting discussions one was regarding request signing we\u0027ve had on our agenda rather on our watch list of things that were keep an eye on ahead of the draft cabbage request signing for some time HT a draft cabbage HTTP request signing I think and there was discussion insect dispatch I think the information we got there was that there is a fairly large community people with with requirements in this space and interest and there\u0027s some forward "
  },
  {
    "startTime": "00:03:07",
    "text": "impetus and so the discussion there recommended that they bring that draft here so we can expect probably a revised draft to appear sometime soon and then we\u0027ll look at doing a call for adoption or talking about it more if need be the other discussion there was around identifying the credentials in a forward hop from a proxy and there wasn\u0027t any certainty around whether that was going to be at TLS layer or the HTTP layer but it did come up a little bit so just keep an eye on that today something might happen do you know stop all right so in DNS up we had a presentation from the team working on the HTTP service record or the service binding record or whatever it\u0027s going to be an ending up being called that document has been presented here but now it has been adopted in the DNS op group it seems to be progressing well there\u0027s good discussion on a lot of the details there there\u0027s going to be a bike shedding on the names so if people have particular opinions on that you can chime in on that list and it looks like that\u0027s going to be on track to kind of start finalizing that format and the trying to get it like an early allocation for some of the points there so if you I would encourage this group to look at the way it\u0027s going to be encoding ALP n values and other things make sure that is in line with what we expect because that may be being locked down around now okay relaying an agenda bash yo ah vice asks if the client hints can run a little bit early sure thanks thanks for that he asked about that earlier offline I think we\u0027ll do client hints first when we do the extensions and that should hopefully address his needs since he\u0027s remote thank you so priorities Ian are you going to cover that and did you send updated slides is it this one priorities did you send it as a pull request okay hold on a second oh yeah apple magic is now happening we\u0027ll see about I don\u0027t know how do I turn this thing one Oh on that thing so this is exciting I could have put anything in these all right no yeah excuse me well my computer\u0027s taken over by anyone in the room awesome yeah so we had some continued discussions and then lunch after the last priorities discussion that ended up I think being quite productive and then "
  },
  {
    "startTime": "00:06:08",
    "text": "the authors and contributors the sign team kind of tried to make as many updates through the draft as possible and because you have kindly pushed out a date last night which we already got some good feedback on a slide it\u0027s the same scheme we discussed before we did a little bit of renaming we made a little bit tercer with the expectation that you don\u0027t actually need to spell out incremental and urgency or progressive to save bytes in the wire I think Martin Thomson has a suggestion we can make it Taurus you\u0027re still but you know that\u0027s for for later that\u0027s kind of a TTL issue but the overall skein has not changed since earlier in the week next slide so I think we the gold that I draft update really was trying to clarify this fact so there\u0027s one scheme it\u0027s the same format but there\u0027s two ways to convey it if you want and end you should use a header and if you want hop-by-hop you should use a frame and those are your two options if you headers are slightly more suited to initial prioritization they can Betty send by either side and they allow you to I think I lost some text on that one sorry it served it over I does not make sense just ignore that frames are designed for reprioritization they can only be sent by the client or the intermediary so for example in these case we discussed before where you want and then signal what the client priority is but only given hop you want to say like you know on this hop I want a different priority you can use a frame to reprioritize the request and this fits exactly with the end end versus hop by out this diction next slide so just to be clear when you say sent by Clara intermediary you mean sent by clients including as an intermediary yes just in that one direction yeah yeah cannot it cannot be sent corresponding to our response at least as the draft is currently written I\u0027m not sure if that restriction needs to stay but I think no one\u0027s come up with a killer use case for it so I think we\u0027ll keep it well until someone does so we simplified the negotiation using settings the current goal this went back to the original goal of the draft that was at the last IETF which is if it\u0027s one HTTP two priorities are deprecated and urgency is supported therefore don\u0027t send those frames anymore that\u0027s pretty much all the functionality you\u0027re getting at this moment future values could be defined for the setting if we wanted to you know do other things with it but for now it\u0027s really just there to say like I support the new thing I don\u0027t support the old thing stop sending the old thing and it could be sent by either side and that\u0027s it so I think the plan going forward then is we can expect a revised draft in the very near future correct or is that is that it was revived bust last night right and so that\u0027s as far as you\u0027re concerned that\u0027s done that encompasses all the changes I\u0027ve talked about "
  },
  {
    "startTime": "00:09:08",
    "text": "they\u0027re in there and it\u0027s it clarifies a variety of issues I think it\u0027s not done I mean of course but yeah in terms of reflecting the state of the discussion to date yes I think at least the technical aspects yeah okay then I think the plan going forward is we do a call for adoption on that pretty much now yeah and once we adopt it we start the discussion on oh yeah that sounds good Martin Thompson I think kazoo who answered my questions about the structure of the they had a field reasonably well I think there remains a little bit of question about the frame and the value of that I raised that issue on the list I saw some feedback on that point but I don\u0027t think that should stop us from adopting this work I think that\u0027s enough of a separable piece that we can ex eyesore enhancers as needed to clarify learn if you could so is your concern about the frame just kind of the nature of the frame or is it more that they\u0027re just like two mechanisms to communicate the same thing so that there are two mechanisms that that exist here and we\u0027ve kind of know a lot about the first one on robben point of the research that you did all those wonderful things but the other one we\u0027ve had for the longest time and we never had any any anything to back that in the first place and we still don\u0027t have anything to back that and it\u0027s extra complexity so so I\u0027m coming which which the second way where they\u0027re wanting to frame the wreath the idea that you might send a hop by hop signal sorry I\u0027m gonna cut the cue we do not have a lot of time to discuss that\u0027s not I don\u0027t wanna I wanna I don\u0027t want to go to get this length but I want to say that there is there\u0027s a question about that one but I don\u0027t think it should stop us from adopting it mozilla i just wanted to mention that so using the word deprecated that usually means that the whole thing is still okay it\u0027s just not preferred whereas i think you want to say it\u0027s like obsoleted or something oh cool they think the text is clear about what that means but yeah more clarity maybe you did briefly please reppin ya roller marks I just want to clarify that we now also use the frame for the whole by hope semantics so it\u0027s no longer just for reprioritization it\u0027s also used for other things that we spent a long time discussing in the design team and if you remove the frame we would have to go back and figure out that which yes if anyone wants to do so agreed I want to stress that this is a proposal from a design team I know a lot of the folks who are very active were involved in that which is great but it doesn\u0027t mean there\u0027s any kind of consensus reflected in that and when we do a call for adoption that\u0027s a significant affine that the working group is working on this item now not necessarily that we have consensus on the contents of the document so that\u0027s the frame of one we should go into this of course we\u0027re gonna discuss the issues we talked before about the possibility of an interim meeting to hammer this out had I had a few hallway chats and we talked "
  },
  {
    "startTime": "00:12:09",
    "text": "about that I don\u0027t know that that\u0027s gonna be necessary at this time and we\u0027ve talked about if we do you know I think everyone once gets us up pretty quickly yes a quick and for other reasons but if we\u0027re talking that if we do need to have some sort of meeting we might try one or a series of virtual interims where we do this in the phone and I think we can maybe exploit the fact that a lot of these folks do know each other to try that out so if you have any feedback on that talk to Tommy myself but that\u0027s the plan going is is if it\u0027s needed that\u0027s probably what we will do all right thank you very much you so don\u0027t poke those tickets to Zurich if you do if this is all you\u0027re interested in okay my computer\u0027s still open for attack so I mean just yeah there we go next up extension drafts so we said we would go with yo first yo are you with us can you requests to be seen let\u0027s do it here paging your voice let\u0027s see if he\u0027s huh oh this computer is or maybe frozen although it\u0027s still reflecting video it is so has he requested yet or okay all right why don\u0027t we move to another one while he figures that out then so if we go to the listing let me just go straight down digest headers that\u0027s another remote presentation from Roberto Roberto are you with us sorry oh it\u0027s you oh okay sorry come join us the of will do you right after digest okay so I realize five minutes ago there\u0027s a slight slight ordering error in this so here\u0027s the slides finished way before they do so I fix out with the PR but I can just do this just to be aware of it so this is yeah I just had is which was called resource digest which used to be RFC 30 to 30 next slide please so just just a brief recap if you have not yet read the draft or forgotten it this is just a way to provide a hash on a request for a response header so I got "
  },
  {
    "startTime": "00:15:09",
    "text": "this digest had a in there you would signal that I just algorithm that you\u0027re using and then the encoded digest output what that is is the application of that algorithm over a the representation say or some part of body of the or the payload of the request or response but the format of that thing is dependent upon the digest algorithm that you view so it\u0027s typically based 64 or some other thing just something to keep in mind as we go through next slide please so last time around when we presented in Montreal Roy asked for some use cases we haven\u0027t put them explicitly in the draft we\u0027ve put in like broad ideas of how it could be used and that\u0027s something I\u0027ll come on to later but today as far as we\u0027re aware these are the kinds of things that are using digest mice signatures which is an issue that will it\u0027s all a little bit more and things like banking api\u0027s next slide please so we had drafted o0 and in since Montreal we\u0027ve been working on some updates we had some open issues that we presented last time we\u0027ve been trying to address those we not fix them all but we have this draft I took a stubborn editorial sweep before we cut draft oh one we\u0027re aware there\u0027s still some editorial issues we\u0027d like to resolve the readability of the document could be improved so I really appreciate any feedback on that but if people don\u0027t want to take a full read of this document that\u0027s fine because it\u0027s difficult but if you\u0027ve got an opinion on some of the issues we present I\u0027d really appreciate feedback on that because we can resolve those and then then figure out how best to reword this document or make things better so I just wanted to deal with that first the steps of the changes we\u0027ve made very quickly so one the first is clarifying state changing methods and the second was a reboot of the digest algorithm I on a table and then the third one was a consideration section effectively for the relationship between digest and s RI which stands for sub resource integrity this was opened by MA and basically during the Montreal thing I don\u0027t know if what we have there is everything we need but it is about the best I could do given the discussion and the information available next slide please so to go through these what does clarifying state changing methods mean at issue 853 and basically what we\u0027ve said is post and patch requests convey actions not partial representations so a digest header on a post or patch request is calculated or computed over the representation data of the actions there and in response is it\u0027s called deleted on the selected representation of the referenced resource this might be the enclosed one or the selected representation for example in the case "
  },
  {
    "startTime": "00:18:11",
    "text": "of no content what does any of that mean if you go to the next slide we have a post example so we\u0027re basing some stuff that some Jason and we we tell the civil what we would accept but we were posting this thing title a new title and that request sorry that I just had a is calculated on the enclosed representation of the request the response that comes back as a different ash because it\u0027s calculated on the enclosed representation in the response which is a completely different thing if you go to the next one this is patch this is very similar we\u0027re submitting a Jason patch which is RFC seven three nine six we want a similar kind of response but the thing we\u0027re sending is the same same payload as the post but we\u0027re given the instruction to patch document and therefore the response we get back in this case is different than both the patch document and the representation from the post example clarification julian Raschke says we should be clear that post and patch are not special cases this should be true for all methods that\u0027s that\u0027s good you beat me by two slides so if we go on to the final example here this is with the 204 so what this is trying to show is it\u0027s exactly the same digest header as as the previous patch example in the wrist but we didn\u0027t have any payload we didn\u0027t need one so this is one of the advantages of digresses you can inside this thing so that said haven\u0027t gone to the FO given some examples for posting patch we gone to the next slide Julian said I don\u0027t think that we it would be a good idea to vary the semantics based on the request method and so we can\u0027t address this with some rewording but should we yeah and yeah this is Roberto\u0027s comment does it present I guess is it present on sorry methods exist today or maybe invented in the future convey a partial representation and if so the digest should always be competed on the complete representation that\u0027s probably some form of the text we might put in there so we we can come back to this but if you go to the next slide ha no next like the discussion doesn\u0027t end there as you all see so they changed to this is is really simple stuff we have basically as part of the changes in this document compared to the URF see that we\u0027re updating we want to obsolete or deprecated some algorithm so we just update the table to have a new column that can contain this status and we\u0027re deprecating md5 and obsoleting Sean "
  },
  {
    "startTime": "00:21:12",
    "text": "adlet 32 this is something we actually considered when getting the document adopted and changing from the well anyway we didn\u0027t because Mark told us don\u0027t do that and then to try and address it as as part of 0 1 2 0 0 0 2 0 1 update so that actually we could incorporate the feedback of the working group and all that stuff so that was fine we\u0027ve done some of this stuff I think it\u0027s all pretty straightforward change 3 the next slide oh well you skip a slide okay well we\u0027ll go onto the open issues that we we need input on I can go through them all I don\u0027t know how we\u0027re doing at the time we probably don\u0027t need to discuss all of them today I just want to give people some awareness of the challenges were facing if you got any strong inspiration on helping us get to that answer it\u0027d be fantastic so if you go to the next slide this is cash digest and cash validators you\u0027ve got RC 3213 stating that the instance is specified by the request URI and any cash valid data contained in the message but we\u0027ve updated digests to use the more recent ins in 7230 X so rather than cash validator we say just validator but how do validate to specify a resource and is specify their corrective mark so um you know listening to the issues you haven\u0027t here it seems to me that part of the mismatch here might be that this document is 32 30 was partly instant status work and that was based upon a terminology and and an architecture of HTTP that was very specific to instance digests and we did a lot of work in HP Biss to move further away from that and I\u0027m wondering if Roy and and Julian and maybe myself but more Roy can help align the terminology in kearney HP this with what\u0027s happening here because I think that would resolve actually a lot of these issues does that make sense to you Roy because like for example here this seems like left selected representation it shouldn\u0027t be about the cache fellow there ah geez I mean it would it depends on what we were talking about so we\u0027re talking about what would be on the back end of the server that you\u0027re doing a cache or digest on the back end of what the selected representation is then yes you used like the representation if you\u0027re talking about what you\u0027re sending in the payload then you would talk about something else yeah I suspect that a lot of terminology you\u0027re looking for might already be buried in HTTP this and core okay and be clear that that\u0027s the the whole intention of this document update is to get us a line so people aren\u0027t questioning this and we can just get it "
  },
  {
    "startTime": "00:24:12",
    "text": "and get it done and not need to revisit I think we need to help yeah so I\u0027d be greatly appreciated yeah so next slide is using digestion signatures so one of the main uses for digests is with signatures we provide very minimal guidance saying that you know use some transport integrity signed data and metadata avoid the broken algorithms when you\u0027re generating the digest but that\u0027s it some people are saying maybe we we could provide further guidance on signatures especially related to representation metadata that effects the selected representation so what this means is if you\u0027re going to calculate a signature over some metadata fields to protect them you should and that includes the digest you should include the other headers that relate to that digest but I don\u0027t feel strongly on if we really need to do this in this document itself yeah none Thompson said that the signature works gonna be hard enough already and they\u0027re gonna have to grapple with all those problems content lengths by the way is a really bad example because that\u0027s typically included in the hash in other ways so you don\u0027t worry about thank you next slide please somebody asks could we add a threat model this might be in Jeffery I\u0027m not sure is that useful should we put it in the ID we\u0027ve got some kind of their texts on a PR somewhere so it\u0027s really just trying to understand can we just close it not needed or maybe the text designer issue we could move on to your PR and then put it out for review or consider some broader thing which is relate to the signatures which we just said we didn\u0027t want to do yeah on Thompson again this is going to be a little bit tricky to do there is sort of one level where you simply say that I want to make sure that this hasn\u0027t been modified in transit but if you start getting to the threat model proper then you have to worry about the signature and the and the downstream uses of all of this so I would prefer not to do anything on this particular one it\u0027s yes concentrate on building the building block and then we\u0027ll worry about how that\u0027s composed into various weapons later on okay thank you our next slide please this one is more of a stylistic thing I guess digests have an empty representation it sounds simple but you know we\u0027re trying to add some examples into this document like my lower them so who were to do that just because you\u0027ve got an empty representation doesn\u0027t mean that the thing that sent on the wire is empty and that affects the digestive al you as is calculated so here\u0027s two examples that you know we were taking an empty string this is an empty string that\u0027s compressed with something and they come out as two different digests so that this can happen but should we basically create a I don\u0027t know the "
  },
  {
    "startTime": "00:27:15",
    "text": "canonical and encoding of this thing that people can use when they\u0027re trying to figure this out or do we just don\u0027t care leave it Thompson again it is what it is if the selected representation or what representing rent owed better payload is is a certain number of bytes then it\u0027s a certain number of bytes and in the compressed case when you compress the empty string you get something so obviously that\u0027s otherwise you wouldn\u0027t have this problem so I don\u0027t think we need to worry about it okay I know that we have something in the in the mice draft that specifically addresses the empty case but that\u0027s because that has specific requirements around that yeah and I\u0027m like I\u0027m not super familiar with this issue if you go on there we do link to the discussion that happened between I think you jeffrey and david benjamin and some of those things so i think that\u0027s a different problem yeah yeah so next slide please the this is a fun one the RSC 3230 the one we\u0027re updating states are following and and we just import that text verbatim into the updates first so for some algorithms one or more parameters may be supplied here\u0027s an example of the digest algorithm and it says the BNF for parameter is as using blah but that document doesn\u0027t drive any example anywhere and the reference to the BNF there needs updating anyway so we should have something free to reference in court we\u0027ve recently I think closed an issue on that okay that\u0027s cool next slide please there is no next slide Oh with them that\u0027s it Oh hold on yeah yeah thanks all right thank you very much keep it up I think this the spec I\u0027ve seen a lot of activity the editors have been very busy it\u0027s great I think it\u0027s gonna get to a stage scene where it\u0027s gonna need what a review is I think people get engaged on the issues now wants to do a bit more editorial work we need better review from folks Jabar really I think Roberto Puli would like to jump the queue to speak if possible before you have presents if we can do it quickly we\u0027re running behind time I don\u0027t know how to do that on your just let them through them yeah you know if we\u0027re gonna get rid of you but we\u0027ll get you right back honest okay can you pick up can you oh yeah I try depressing again innit oh wait sorry okay Oh Roberto queue up again please it\u0027s all about latency Roberto okay "
  },
  {
    "startTime": "00:30:15",
    "text": "give it a try then okay he won let\u0027s go ahead and let y\u0027all talk about client Hansen and we can a few changes to the draft that has happened between 0-7 which I think was published in back in March we clarified the define that the define header the response headers key references the key references with bangerang and replace the Aidan F pressured hundred none of that was particularly controversial as a result of feedback that we got at the ITF 105 we remove the explicit except CH lifetime header and replaced it with implicit registration that is tied to the life of session cookies next slide another PR that has just landed as a result of feedback is to add the basic outline the bite-size cost of adding hints and therefore cautioning implementers as well as servers that you know hence have a cog and therefore they should be used in moderation next slide and we have a couple of and the key ours but I believe recruit to being done but I would love the group\u0027s opinion on them and what more is needed there one is detailed I mentioned of information exposure this is a PR that outlines exactly what categories of information can be exposed in client hints what categories of information must not be exposed as a client hint and define what implementers and feature that we\u0027ll be using this infrastructure and I shouldn\u0027t take into account when doing that um so I believe this is close to being done but I\u0027d love opinions from "
  },
  {
    "startTime": "00:33:17",
    "text": "from the group and particularly Martin Thompson I know like you\u0027ve been active on this issue I\u0027d love to know if there is anything else that needs to be done there so that we can wrap it up the discussion essentially we think that 20 and you make sure that those headers be used and we are aware of the fact this prevents [Music] sorry got ya 1 Thomson yeah thanks thanks for summarizing that this is a difficult one and I I think it\u0027s probably I can probably try to explain where I\u0027m at to up to on on the thinking here the sec prefix prevents sites from setting this value themselves only the browser can do it that\u0027s really the property that we\u0027re looking for and part of part of the the concern that we have is that if we allow sites to set arbitrary headers particularly in cross-origin requests then the server at the other end may be unprepared to receive those particular header fields it may do something that maybe we are uncomfortable with the consequences of it might be a security vulnerability who knows and that is coupled here with the desire to have these header fields available on the very first cross origin request made to any given origin is that a reasonable summary of where you\u0027re at so you were trying to load an image from a cross origin source and you want to make sure that they get for instance the DPR hint so that they can make the right choice of representation yes so we want to avoid pre flights as that would negate a lot of the performance benefits that this will the client hence will have as well as introduced a significant performance regression for hints that "
  },
  {
    "startTime": "00:36:17",
    "text": "don\u0027t well performance such as user agent hit client hints right so um I guess this is a bit unfortunate but I\u0027ve been having a bunch of discussions with Alabama Karen and and others about what it is that we do with origin policy other ways of signaling origin policy potentially using things like a flag and that in the taillights handshake that indicates that this service willing to willing to accept the consequences of dealing with things like the pre flights itself those are where I would prefer to put my effort into acknowledging the fact that if we allowed these header fields to go that means that currently we\u0027d be in the situation of having to decide whether they\u0027re preflighted at for the ones that we have in here even though it might be just for a short time period of time because what I don\u0027t want to lose here is the utility that we get out of being able to have applications set them in those contexts where it is indeed valuable to have that information available to the server and through a couple of examples in the in the thread there and they\u0027re just strong man examples but I think that that having that capability is something that I would prefer to keep even if it means maybe in the short term having this exposure to the necessity of pre-flight until we have a better understanding of how this works I realized that\u0027s kind of springing on you love but that\u0027s all discussions I\u0027ve had in the past week or to try to try to chase this particular problem down it\u0027s really quite a funny one okay do you have any specific cases in mind regarding the like user land based grant hints is there the example that I gave was the case where you have essentially a service worker that\u0027s pre loading content available for offline and it wants to be able to explicitly say that it wants the smaller or the saved data representations because it\u0027s worried about that the time that it\u0027s going to take or the amount of space is going to gonna need that sort of thing or maybe it wants to prepare for a situation where it\u0027s in a more limited context or maybe it wants to move that that data elsewhere and give it to a more constrained device I don\u0027t know but it has these constraints on on the data and it wants to express that and use the client hints and hit the cache in the right way and all those sorts of other wonderful things so that was the example I had I think I probably come up with some more of them if you really like but that was the example I had okay would a solution we\u0027re browser-based clients have a sack prefix and then new zealand-based client ends that are "
  },
  {
    "startTime": "00:39:17",
    "text": "willing to take the preflight cost don\u0027t have the secretary fix but they have the same semantics with something like long those lines work and so that\u0027s one reluctant to do because that means that now you have two things that essentially mean the same thing but they\u0027re distinguished based on where they came from and we have to carry that baggage forever I I realized that this is unfortunate but I would I would rather try to solve the problem than have to have to deal with it in this in this kind of ugly way the sec prefix is kind of horrific and it\u0027s a blunt instrument unfortunately and that\u0027s what I\u0027m trying to avoid okay thank you any more um yes so next slide is basically I would love to see that infrastructure draft move further along I am planning to ship user agent client hints in chromium very shortly based on the new infrastructure that\u0027s outlined in this draft as well as the feature policy really the infrastructure of cross-origin delegation um so I would love to see this move further not in Thompson if I might offer a potential out you don\u0027t actually define any clients client instant here and I confess I was unable to find any of them when I went looking the other day so you\u0027ve done a great job of removing them they seem to have disappeared from the internet but we [Music] that means that we probably can not concentrate on whether the sec prefix is something that we use and simply say that we have to when you define a client hint you need to ensure that the server is not going to fall over as a result of receiving one of these things in the web context and we can be very lightweight about this because this is an infrastructure document and that makes this primarily a problem for the fetch back or whatever document ends up defining the individual hints I realize that\u0027s kind of kicking the can down the road but I think it might be kicking it exactly into the right location so do you have enough to make a modify the pull request to make a new pull request based on that to kind of scope that ah I believe so what for the for the sac PR and for the other one it looks like mainly the comments on there were seeming to be about the fact that we are "
  },
  {
    "startTime": "00:42:17",
    "text": "adding kind of normative text in you should avoid these various fingerprinting surfaces without really giving you mechanisms to do that and so it seems like it\u0027s problematic to add normative text to tell you something that\u0027s under specified do we have comments here or do we know how to progress on this issue make sure we can wrap it up I reviewed it I was I was happy with the conclusion I I think if we\u0027re gonna publish this document we need to publish it and basically the current form that\u0027s hard from that to exist at the second thing do we want to because I mean ecers comments in here or saying I\u0027ve talked about this one look will never be completely happy with this situation because we there\u0027s there\u0027s some fundamental agreement disagreements about policy but those are policy disagreements and no I don\u0027t think that disagreements about what\u0027s what\u0027s in the draft it\u0027s sounding to me of like you of you can produce in the new draft fairly soon and we can go to working group last call and see if we can make it stick yep okay thank you thank you so much thank you thank you so so not much further Papa Smurf do it you can do it thank you thanks okay what is next so that was digest and client hints using TLS 1 3 with h2 we\u0027ve already sent that to the ESG I go ah Roberto you had a comment yeah can you hear me somewhat yes ok it was well about the discussion for about given given consideration young guidance in using digests with signatures all this digests draft started from me noting bad implementation of draft cabbage using digests in the wrong way for sending content so the first thing I did was to better define which fields should be signed together with digest with metadata should be signed together with digest and then started working and rewriting that I just had I think that it\u0027s worth when specifying the digests raft to give guidance about using digest with signatures because actually there is an issue by for the implementers about all the contest and all the the metadata that are part of the of the the essential to decode the epilogue because "
  },
  {
    "startTime": "00:45:18",
    "text": "the payload is not the representation that that\u0027s it thank you problem okay so next up we have proxy status but I think it would be better to briefly talk about cash header first because there\u0027s some changes there that might have impact on proxy status if you look at the latest draft which I published pretty recently we talked last time about refactoring this because if you\u0027ll remember the previous approach was very much paving the cow path of the cash the X cash header and so it had the very familiar cache hit cache miss and all the other tags and and the feeling was that that wasn\u0027t terribly extensible and adaptable to changes in cache semantics and also if implementations are already implemented X cache they could just try and change the header name and or not make any changes to where their code actually calls this and maybe get the semantics wrong and so that was a bit of a moral hazard and so we decided to refactor it and I\u0027d like folks to look when they have a chance maybe not right now at this reformulations and I think there are some examples down here and and I think this still needs some work I want to make sure that it\u0027s usable both for the implementations that are produced in the header as well as people consuming it to do things with it and I think we need to probably do at least one more revision for that latter class of people but one thing I want to highlight here is is that we made a pretty fundamental change last time there was a tag that kind of held the semantics of what happened and then there was a parameters on that that were identifying various parameters including the name of the node so what the name of the cache was that is claiming that this action has taken place we flipped that and the the primary token here that you\u0027re putting parameters on is the identity of the the party taking the action so in this case it\u0027s example cache and then you know here it\u0027s a fresh response and so forth and so on and so I wanted to highlight that to folks to make sure that we\u0027re comfortable with that because I think we should probably do the same thing in the proxy draft who\u0027s read the latest draft of this was put out a couple weeks ago okay few more people could read it and give feedback that would be really helpful I don\u0027t think I\u0027m not even sure they\u0027re open issues in this one yet so there is one issue open for me factor which is using that is close by this commit um where was it\u0027s just I\u0027m not sure that it\u0027s sticking yet I think we need to continue to refine refactoring I didn\u0027t that\u0027s why I didn\u0027t close it so please take a look and review and I\u0027m gonna probably noodle on it a bit more and we\u0027ll have another draft sometime soon any comments on the cache draft we aren\u0027t we changed the name by the way we did close that issue its cache status now there was a old pull request open for that so maybe that should be cleaned up I think I did let\u0027s under getting "
  },
  {
    "startTime": "00:48:19",
    "text": "caught Fleur you can also close my PR about renaming other and there it is yes thank you okay and that takes us to proxy status Peter and I have been working on this in the background and having a chat we have two issues left we haven\u0027t we did not publish a new draft before this ITF because we wanted to get to conclusion on this first and assuming that we can make the change we just talked about I think this issue we went to a place where we were talking about splitting into two different headers proxy status to reflect the the terminal you know this is an error generated by a proxy and then proxy info to capture information that the proxies observed on the way through and I think that if we make that change that we made with cache status we\u0027re not going to need to split it up into I suspect we\u0027re to be able to leave it within two one header which I think makes everyone happy sorry is this about this draft fish about cash oh please go ahead Chris lemon says I\u0027ve read it I really like the reformulation I don\u0027t see the extensible case in there I\u0027d like to see a place to put some data about what kind of a hit it was for example a hit on disk RAM or some other place I\u0027d like to see proxy status to follow suit okay that\u0027s good information thank you so if if that\u0027s the case and we\u0027ll do that refactoring again on this spec and then hopefully we\u0027ll be able to close 8:21 without much that leads us to 808 and there\u0027s a back and forth here in piano field please feel free to come to the mic to represent your view we\u0027ve been talking the background a lot and then there\u0027s there\u0027s attention here I think you know one of the comments was that that being able to identify requests errors and different kinds of requests errors that are currently identified by H to be status codes you know whether it\u0027s forbidden or URI too long or whatever is useful to do here into a court here and so we started to walk down a path where we had a code for each of those states and you can see I did a I started to do this in the draft itself and so we have all these new things associated with oh sorry yeah here we go all these new HTTP requests ones from here down one code for each existing HTTP status code and I\u0027m not done with that yet so I\u0027m having this givings about that I don\u0027t want to represent theaters position too much but I\u0027m having misgivings we aren\u0027t able to come to agreement yet so we wanted to talk about it briefly here James crusing BBC so what are you gonna "
  },
  {
    "startTime": "00:51:21",
    "text": "do when another HTTP status code comes along I think the idea is is that it would be registered in both the status code registry and here so do you wanna I don\u0027t wanna it might depend on that so I think this was more of an issue in current state when we have dedicated types that are a primary object if we do the refactoring and switch to the proxy name being the primary identifier and switch this to us to being key values right like status and status price we don\u0027t we can just piggyback okay on an existing service kasam don\u0027t need to read the find so I think then it\u0027s fine okay so um that would I think we talked about this briefly so that would take us to a design where we originally had one of these codes that was HTTP request issue or whatever and then it had additional parameters that convey the status code and the status phrase so that you can you can find out but you know it\u0027s just look at the status code of course I know one of your big concerns was that if there\u0027s another condition which isn\u0027t captured by a status code yet you want to be able to convey that as well but I think that\u0027s probably just registering a new one of these error I forget what we call them but the proxy they\u0027re our status things yeah okay so I think we can kind of write that down and see what it looks like it make sure everybody\u0027s comfortable with it and then before but it if we can solve these two issues I think we\u0027re in agreement that we\u0027re pretty much ready to go right it will be good to read everything from the room whether everybody\u0027s against you know duplicating status codes you\u0027re gonna run a hammer sure I mean this is I guess there\u0027s anyone I mean does anyone want to speak up for duplicating them just so you can kind of hear a argument in that favor or Roberto says I commented on the issue the status message eg bad requests may change in time okay so the status message could change but the code wouldn\u0027t okay all right so mum Thompson I I think if you\u0027re making requests then it makes perfect sense to just record the status code that you\u0027ve got if that\u0027s all the information that you have if there\u0027s other error conditions that might be generated then you have them other values that you can have but I think having a having I made a request and the and the status was X as part of the information that you provide which may even be in addition to the other errors that you might stick in there is much "
  },
  {
    "startTime": "00:54:21",
    "text": "cleaner I\u0027d saw the table of contents as it scrolled down and just kept going and going and going this is just unmaintainable so let\u0027s let\u0027s just pretend the status code so you see you\u0027re arguing for just status code not what we originally had of both the status code and the other signals that you need to provide it in addition to that because of the processing that happened locally by simply just have the number but but just the number with you as a value of as the parameter yeah good do you want to take a home on that er I\u0027m happy to Peter\u0027s happy you happy we have a waiver pad for it I think we have call for it okay I\u0027ll note that in there yes no no service in this place okay good that takes us home thank you very much that takes us unto variants I think also again a very brief update here I don\u0027t know that we have any oh we have one open issue and variants I believe so oh no we have a few that\u0027s right so in the last of this set for a long time and we weren\u0027t sure we we weren\u0027t getting a lot of implementation experience although we do see other specs depending upon it the last time around I posited that we might get a little more engagement from folks if it also addressed one of the most common cases that isn\u0027t met by the very Keter today which is cookie variance so I in the last draft I sketched in what that might look like I don\u0027t think it\u0027s seen a lot of review who\u0027s read the latest draft of variance yeah I don\u0027t think it\u0027s seen a lot of review so if people could please take a look at that that would be fantastic there are a couple of issues here which i think are pretty manageable so my anticipation is I want to play when I have an old implementation of this that I want to refresh make sure it works properly make sure that the draft is reasonable and then I\u0027m thinking we should probably publish this as experimental and see how that goes we did have some implement or interest but for a lot of reasons it\u0027s not really getting that and I don\u0027t hang around too long I\u0027d be interested to hear if people feel differently about it if they want to just keep it hang grandma\u0027s draft or oh I have an implementation or I\u0027ll do one honest or whatever nan Thompson I realized this is probably drawing too long about it but W Peck work was more or less depending on this one I know would it would it seems like the outcome of that work would be - ideally would be a standard track document and having that standard take document and not an experiment is a little awkward I think we must we might need to be prepared to revise this in a fairly short timespan if it gets more serious over that way I\u0027m that that\u0027s assuming about a whole bunch of things that that haven\u0027t "
  },
  {
    "startTime": "00:57:22",
    "text": "happened yet of course I\u0027m thinking that publishing his experimental might encourage the implementation I know that sounds very hook based but if it need be it can be flipped from experimental distinguish track down the road with some process stuff yeah yeah I\u0027m just highlighting that as a as a potential problem sure no that that\u0027s very much in my mind this is Jeffrey askin um in the W Peck kind of experimental implementations we are suffixing variance with the draft number which seems like a good way to proof kind of the experiment if it gets published as an experimental RFC and then needs changes before it goes to standards track is there we need to come up with a migration plan for the kind of what Evers whatever is released sure we\u0027d have to come up with different header names if it needs changes yeah and that\u0027s not terribly Pleasant yeah I mean to be clear I\u0027m perfectly fine parking it for a while if that lines things up a bit better I just want to make sure that everybody is comfortable with a Marc document for that long because if this is the negging out there for a little while I couldn\u0027t live with that I think we can we can keep it around internet Dras don\u0027t expire do they should they expire question I think it was in this very room okay well I certainly I have issues to address it has a dependency on core so it\u0027s not gonna ship anytime soon anyway I\u0027ll do a revision I\u0027ll do some some prototype implementation to make sure that everything still works properly but I will there on the Shelf after that and wait for feedback I think and if there is implementation experience from the packaging stuff I mean that may provide enough basis to make it not experimental by the time we publish sure I mean personally I\u0027m not doing this for webpack sorry Jeffrey I know that\u0027s a huge shock I\u0027d like to see this used in anger by caches I think it makes them more powerful yeah Mumtaz and I don\u0027t agree with that any anything we might learn and we\u0027re packaging would be helpful but I don\u0027t think it\u0027s gonna be dispositive in any of this because this is targeted at intermediaries and if intermediaries don\u0027t prove that they can use this then we still don\u0027t know anything okay I think that\u0027s all we need to really cover them um PCB 306 yes we did get a comment yes I got a comment yes I\u0027ve had a chat with fluffy and I think there\u0027s some editorial finessing there that might need to happen but and I need to take another pass the draft as well because we left it up indeed thank goodness wise chairs indeed eventually he\u0027ll start rolling yeah I did a fairly large revision of this draft recently probably bigger than I intended to and that\u0027s based upon the feedback we got in the "
  },
  {
    "startTime": "01:00:24",
    "text": "process of putting RFC 7320 bits out which is the revision of the URI ownership stuff and the feedback we got from the larger community and that was that it\u0027s fine to state some principles and states and practices and say this is you know what happens if you do this and this is why you probably don\u0027t want to do this but using must sand must not to convey that is a whole nother level and it\u0027s not usually appropriate for these kind of architectural considerations and so I did a pretty big pass to the document to remove a lot of the what is probably going to be considered inappropriate requirements language tone it down and make it more you know this is is why we do things the way we do them in HTTP so it encouraged people to review that I probably do want to take one more editorial pass through it and it still has this dependency upon Gore yeah has anyone looked at the more recent revisions of this anyone okay I did take a look and it looked reasonable but I think once we get the any modifications from Fluffy\u0027s review in there we should ask everyone to take a look again well definitely need to do another worker blast calmness and and you know I after I did I had misgivings about all these changes but as after I did I looked and I was happy with the documents resolved that\u0027s yeah I think it\u0027s the right thing to do random access is not our problem anymore and it should be out the door as an actual RFC very very soon it has secondary certificates I think we\u0027re a little ahead on time we had ten minutes allocated for this but you can probably do fifteen actually I don\u0027t think we\u0027ll take that long so there\u0027s not a whole lot that\u0027s happened in the document itself last time around we finally came to a compromise on what we want to do for the DNS pieces and really the outstanding piece right now is implementations I\u0027m aware of all of one implementation of this and it\u0027s server-side almight I have two other possible interest in implementing that don\u0027t have a specific timeline also server-side only I\u0027d really like to see at least one client implementation before we progress this anywhere and I don\u0027t feel like we can responsibly do that until someone does okay mom Thomson I\u0027d really like to be able to implement this one but it has remained below the the floor of various other higher priority things for for a long time I think like the variants work I\u0027m comfortable parking this one I don\u0027t want to publish this one as experimental I don\u0027t want to I don\u0027t to publish anything that hasn\u0027t been tested in the field in particularly in this area and there\u0027s there\u0027s a number of things in "
  },
  {
    "startTime": "01:03:25",
    "text": "here that I think will require some care in order to get right and we may want to make some sort of minor tweaks as we as we go through deployments so my preference here is to just say okay fine it sits there and it can sit there at the bottom of this list for the next three years if you really like we don\u0027t have any open issues do we we have an editorial issue and we need some we need the text for the compromise we worked out last time which is more or less do what you would do anyway yeah yeah so I I\u0027m comfortable with that I\u0027d want to make sure that the rest of the working group was comfortable as well because it these things tend to be a bit of a liability when they\u0027re hanging around so we need to acknowledge that kyle nekritz i think i might have mentioned this last site if we have a like half completed client and server implementation but um yeah there hasn\u0027t really been any movement on that in the past year so and i\u0027m not sure there\u0027s going to be any any any time and then a very near future but i have no problem with what the plan Martin suggested from what we did get done we didn\u0027t find any kind of real issues in effect though yeah I think not publishing and not killing is the sorry Pat McManus I think not publishing in killing is probably the right path here I there are a number of use cases being sort of explored on this but it\u0027s a delicate thing to deploy even at a test level so I certainly don\u0027t want to see it deprecated so we have something to work off of but yet publishing it without the experiences probably yeah and ego okay so it sounds like keep on going and we\u0027ll just see where it takes us thank you yeah it\u0027s like okay expect CT uh that\u0027s not see now isn\u0027t it no what\u0027s happened to that one not yet still in the RC editor Q I think it didn\u0027t okay missus mr. F oh that makes sense I\u0027ve got structured headers so we have been chucking away at this our issues list we\u0027re just doing some some I\u0027ve done an editorial pass through it and there are a couple of knits left over the only real discussion we have left is around floats we still have a little bit of discomfort around exactly what floats are and especially since you know the on wire representation and the model for "
  },
  {
    "startTime": "01:06:25",
    "text": "that is somewhat different from what people are using implementations and making sure we get those mappings correct so that discussion continues I don\u0027t know that it makes sense to go too deep into that here but we do have a pretty active discussion there I think we\u0027re gonna probably rename float to decimal it seems to be that\u0027s that\u0027s the the sense if folks have thoughts about that I\u0027d love to hear it we do have multiple implementations we have our test suite with almost 1500 tests in it now I recently got my implementation doing both the pars again serialization parts uh uh half of that working which is great and I think it\u0027s being implemented at least in the civilization side in chrome by in income so that\u0027s good Martin yeah yeah I\u0027m fully supportive of the move from float to decimal I think dealing with floating point numbers in here is has revealed a whole lot of complexity that in implementations that really isn\u0027t warranted for this I had a question though where we going to put the decimal point well so to be clear the current proposal is just to change the name from float to decimal oh that\u0027s terrible we discussed this at the last meeting and it seemed fairly clear that people were happy with the effectively a fixed point decimal right but what came up in discussion was that that would result in being unable to express certain types of information such as for instance the number of nanoseconds since the UNIX epoch milliseconds would be equally bad I think maybe maybe there\u0027s microseconds I don\u0027t know but that seemed to be the the thing that motivated the change to go to a floating-point number I think that\u0027s a bad decision yeah that\u0027s how I want I want to talk about that a little bit I don\u0027t think that that really happened that just sort of happened and and Ryan it hit the rails and and three people went off and charged away with it and I\u0027d like to have a discussion about right well it\u0027s also interesting because the the people have been most active on this spec aren\u0027t in the room here and don\u0027t generally come here so we only know where that to we have to be aware of that yeah personally for me the high order bit in this is that if we have a flow to our decimal type or whatever it needs to be able to represent what\u0027s in carnage to be headers if we want to map them to structured headers which is I know not completely in scope for this but it\u0027s an Intendant future and that means mostly Q values I think I don\u0027t know of any other big places where where decimals are used in HTTP headers and Royce getting up the correct thing so so I\u0027m getting them from Q values give values Q values yeah so I\u0027m not getting from from that that we need a huge "
  },
  {
    "startTime": "01:09:26",
    "text": "dynamic range on these values which suggests that we could go with something a whole lot simpler but it seems like the discussion that went on on the list was quite quite firmly down the path of well we need we need this bespoke floating-point format Chris lemons asks does anybody use more than two digits of precision for Q values I think you guys are specified as three if I remember correctly right yeah this is Roy fielding yes it\u0027s a three digit fixed point so I guess I I guess the real question here is if we\u0027re going to express times as as numbers what are we what do we think we might want to do in the future about that and is that sufficiently different to the use cases we have for say Q values that we can worry about that problem at that future time right well so to be clear if we\u0027re talking about back there two cases four times one is backporting existing time-based values in HTTP like the date header yes modified nixing iris no those are all at one second resolutions that are all gonna be integers so that is fine hazy until someday far far far in the future because we\u0027ve got 15 digits to work with yep in integers in structured and then there\u0027s if I want to introduce a new field that has something like millisecond time in it hey there\u0027s a question of whether that\u0027s a good idea which has always been a contentious issue in HTTP assuming that it is a good idea you don\u0027t have to start with floating-point you could start with an integer and say this is the integer number oh you\u0027re making my arguments for me thank you yep that\u0027s why I\u0027m here Martin Thompson so all right so I think the proposal is to go to fixed point how do people feel noted Chris lemon says I observed that quite recently we defined some high resolution times as integer milliseconds see the cash status header and he is +1 on fixed point and this isn\u0027t going to be a fixed point at what I think three three digits three or six and we cannot listed him for three if we want to make it backwards compatible [Music] so this has been contentious and I think it brought we can make a proposal and list it\u0027s gonna come up on last or on the issue I\u0027d like to get a better sense of the room personally I think the precise number of digits is a bike shed agreed no I mean about it being becoming a fixed point so could we get a sense of the room yeah I think you might want to want to do a Hammond on fixed point first floating point on this one sure all right so we\u0027re gonna take a home we\u0027re gonna meet two options first we\u0027ll "
  },
  {
    "startTime": "01:12:30",
    "text": "ask if people would like to switch to used fixed point for anything that is a fractional number and then the second question will be if you prefer to use floating point as we do today and try to figure out that world alright so please hum now if you prefer to switch to fixed point and please hum now if you would prefer to use floating point okay so for the minutes it was stronger for fixed point there was some humming for floating but if anyone who hum for flooding will be willing to come up and say why I thought it\u0027d be really good information mm-hmm this is not a slam dunk obviously or on jabber thank you for fixed for free yeah well the home was for fixed but we\u0027re asking if there\u0027s feedback as to why people hum for Flair Chris observes it\u0027s worth noting that the floating point proponents are mostly out of the room that\u0027s so for me I think I have an action to go and engage with the other people who aren\u0027t here and who have been active on the spec as well as the communities that have started to adopt structured headers because there are they are out there I don\u0027t think any of them are using floating yet but I want to double check and make sure that this doesn\u0027t cause concern those communities so we\u0027ll see but from a interoperability standpoint personally I feel better about fixed repair to pay on Facebook a lot of well there\u0027s a fair bit of hardware out there that doesn\u0027t even have floating-point units so it would make floating-point even more challenging it would get converted to fixed point on most of those platforms there is a really fun hardware restriction for this so I in addition to all the other stuff julian comments an alternative solution would be to get rid of it and define an extension later if needed yeah I\u0027ve thought of that I think having it around for backporting things like Q value makes it valuable and for other a couple of other simple use cases but I\u0027m much more happy or I\u0027m becoming more happy without kind of a limited value thing rather than making it so flexible yeah I guess the argument against doing something like that is that this is fairly tightly coupled into the into the numeric serialization and parsing routines that that you have in the spec and so having it integrated into the spec makes it a lot easier to be sure that people get that distinction "
  },
  {
    "startTime": "01:15:32",
    "text": "between the two of them correct whereas in an extension we might have to think about having a different flag to go at the front of it in order to properly distinguish it from other types of fields and that sort of thing that\u0027s actually a very good point yeah we we are this is one of the few places works where we\u0027re exploiting that yeah Julian says Q value can be sent as four-digit end of course it can but but it you know so I have a separate draft which is not in scope for this working group now which is how do you back port existing headers on to structured headers and a lot of value a lot of headers use key values would be nice to be able to not require different serialization of them gothics I\u0027m wondering if it would if the only use case for this is Q value is I\u0027m wondering if a much tighter drier structure that can only represent values between 0 \u0026 1 rather than arbitrary floating point would be it would be the right data type here I\u0027m seeing shaking heads and I\u0027m wondering why I think if we\u0027re gonna go to the point of describing something decimal you know saying okay well fixed point decimal numbers that has utility still without a lot of work and older and again the interoperability profile is still pretty tight so or just as tight I want to check this HTH real quick I think everything here is done except for like oh yeah that was the decimal thing yeah so uh please do have a look at the spec Delta that issue I think it\u0027s pretty much ready to go we\u0027re gonna have a couple more editorial passes through it just to make sure because it\u0027s hyper important that this one gets it right the first time out mhm Julian says what Mark just said is interesting as the goals for this spec seem to change from time to time smiley face so is backporting existing header fields now a goal as I said it\u0027s not a goal for this spec but it is not terrier motive for a document to come okay it\u0027s so schedule wise when do you think we want to go to I am I would love to get a working group last call in 2019 okay the clock is ticking indeed it is especially since I have a holiday scheduled rear took am I\u0027ll I\u0027ll note that the priorities scuf wants to depend on this so yay sooner yes that\u0027s there are now a number of respects queued up for this and so we\u0027re under a certain amount of pressure okay client hints where he discussed 66-65 Biss oh I think I need to close their feet because we said this is still Julian because Julius Villa Julian because we said last time that the URI type is not needed because backporting was not a goal that\u0027s not we said that the yarra type was not needed because we couldn\u0027t define it "
  },
  {
    "startTime": "01:18:33",
    "text": "with good a good interoperability profile and now I\u0027m waiting for Julian\u0027s response we did close that issue previously I don\u0027t really want to open that one again you so sixty to sixty-five this is still an open document um we still have a number of open issues on it I believe there we have 1818 so I think we\u0027re gonna have a chat with the editors again about that and figure out yeah how we can move that forward I don\u0027t think we have anything to report at this meeting because there hasn\u0027t been any activity but we need to see a way to get that to conclusion somehow any other comments on our open extension drafts I think that covers everything okay so we\u0027re doing pretty well on time actually compression dictionaries hi my name is Felix anta and I\u0027ve written a draft that talks about the security properties of compression with dictionaries next slide so why am i standing up here why is this interesting for HTTP piss compression is a crucial feature of http low in may be a controversial one as long as the web is made out of text and particularly JSON compression will continue to provide a great deal of value and next slide so in pursuing achieving the best compression ratio the choice of algorithm plays an important role but once you\u0027ve done that I believe that compression dictionaries are the next frontier and as you can see we\u0027ve seen pretty significant way in deploying our own content coding at Facebook next slide for those unfamiliar for those unfamiliar dictionary based compression is this technique where you provide some external state to the compressor and it can use that to produce a more compact representation of the message when we\u0027re talking about a response body compression we\u0027re usually talking about an LZ compressor so the dictionary is basically content that you can make string matches against so rather than having to represent some string in the compressed message you can just omit a reference to the dictionary there are other kinds of dictionary "
  },
  {
    "startTime": "01:21:34",
    "text": "based compression algorithms H pack and Q pack are examples that may be familiar next slide this technique does have drawbacks and in particular the blocking problem in previous attempts has been concerns about introducing new security vulnerabilities next slide nonetheless I think this is something we should do we should standardize and deploy a dictionary based content coding I hope to work with you all to do that in the future but it\u0027s become clear that first in order to do that we need to better understand the security properties of the domain X slide so I have written a draft that attempts to do that that involves a few different things it starts by looking at dictionary based compression as well as the machinery and choices that surround it that you have to make when you integrate it into an internet protocol it lists the security questions that arise as a result of both that compression and the surrounding mechanisms and finally it lists mitigations where they\u0027re known so in investigating the security properties in this domain I think there are two categories that are worth talking about next slide the first is this existing class of attacks against compression you know which is the crime breach heist series in which as an attacker if you can introduce data under your control into the same compression window as user secrets that you\u0027re trying to discover when they\u0027re compressed together you can look at the size of the compressed message and use that as a channel to extract information about that secret next slide so this attack applies just as well to dictionary based compression which is a concern and actually possibly even more so because dictionary based compression is precisely the process of taking two different pieces of content and putting them in the same compression window so it potentially creates new avenues towards mixing attacker and user data so that requires careful consideration next slide the other category sort of broad category that\u0027s worth talking about is the security questions that arise from all of the other things "
  },
  {
    "startTime": "01:24:35",
    "text": "you need to do to do dictionary based compression dictionaries are pieces of state so somewhere you have to create them you have to distribute them you have to agree with your calendar party which one you\u0027re going to use or if you\u0027re going to use one at all then you have to actually use it and eventually at some point you want to learn whether it\u0027s safe to delete it or whether you still have to retain it and so the draft looks at whether there are security implications in those activities as well next slide so this is the list of kinds of attacks that the document currently discusses I tried to figure out how I could say more meaningful things about these without using vastly more than my allotted time so instead I will just refer you to the document which discusses them in some detail next slide and so that leaves me with the question is this work does this work belong in HTTP this and if so what is the path towards adoption from here so thanks next slide I look forward to hearing your thoughts questions comments thank you very much so for folks who have been here for a while you know that we\u0027ve had this discussion in several ways over the years there\u0027s a lot of folks interested in you know doing dictionary based compression in HTTP there was always this roadblock of what are the security properties of it and so thank you so much for for doing such a fantastic job and trying to write that down and document that so we can continue that discussion I don\u0027t know that we can come to any answers today but I\u0027d love to hear what people are thinking you know who we see if show henan who\u0027s read the document so far okay so it\u0027s mattering across the room I\u0027m hoping we\u0027ll have more people read it so we can continue that discussion go ahead right so I was interested in using it as well for a different protocol but yeah sure great I think it should be adopted yeah and so one of the questions about the home for this is I think it\u0027s motivated largely by work that will happen in this group but I did try to write the document generically so it could apply to any internet protocol so there might be a question of at least coordination with the security area there to see if they want to take first pass at it or yeah we can talk to where a director and talk to the security area directors and see what they think you didn\u0027t talk about this that\u0027s act dispatch at any point did you okay any other thoughts for folks okay I see thumbs up thank you again for doing that and we\u0027ll have some background discussions to figure out what the next steps in that discussion are but thanks again so I think we have we definitely "
  },
  {
    "startTime": "01:27:38",
    "text": "have time permitting we have one more presentation scheduled James did you want to talk to about the night anyway extension things yeah thank you for reminding me we\u0027ll do that after this we do have time so I\u0027m James Christian from the BBC uh I would like to introduce a new header to represent transport information next slide please so including various states like you know at each of the connections RTT are the sender\u0027s congestion window and I want to do this for a couple of reasons it\u0027s for clients that can\u0027t get this directly particularly for JavaScript inside of web browsers or perhaps revealing information about the connectivity between CDN and origin there is already a w3 standard called net info but for a bunch of reasons it doesn\u0027t expose a lot of this information and it\u0027s not it\u0027s not extensible we don\u0027t want to do this exclusively for TCP we could do it for quick or anything else and we also allow for multiple samples so that are all time and time based next slide please a couple of examples here really quickly if you don\u0027t understand what I\u0027m saying that\u0027s roughly what they\u0027re looking like next slide there is a couple of issues in a 0-0 draft that were already aware of such as how to deal with connect proxies a LPN might be problematic because for non h2 or h2 and lower the it\u0027s not clear it won\u0027t be clear to the receiving and whether or not TLS is being involved our current represent a of time is probably over-engineered and there maybe it\u0027s not clear whether or not we\u0027re being clear enough about which fields are exhaustive or in exhaustive are you aerial time I wonder what you can\u0027t I\u0027m pretty much done okay thanks in sweat Google I had two questions one is whether you considered using this as a request header as well because there are use cases where you\u0027re an intermediary going back to a back end and you want to actually supply a different response to the original client based on the client properties and at least that\u0027s a plausible use case worth considering the other question of course is trying to think of I mean this is this is presumably the last hop right so like you wouldn\u0027t want like if there was an interview area you wouldn\u0027t want the origin sending this back and then having the intermediary proxy it like I "
  },
  {
    "startTime": "01:30:38",
    "text": "don\u0027t know that\u0027s all they also haven\u0027t defined you know yeah well caching to you but like let\u0027s like assume caching isn\u0027t I just want to make sure like this is kind of this is really only the very like last hop of the or I don\u0027t know you might want to figure out like what hop it is I guess really is what I\u0027m saying [Laughter] Chris lemons asks this information is mostly information that the browser already has access to right is this motivated mostly as an end run around the browser choosing not to provide this information to the client ah so going back to two of the motivations the browser does have it but the api\u0027s that are currently defined so the net w3c net info doesn\u0027t expose all of the values and it\u0027s more focused around exposing some estimation of what the bandwidth or connectivity for the thing might be and I think there\u0027s some privacy implications of exposing other values like RTT and friends because it\u0027s a basically figure print okay and he and I do assume this header would be listed in the connection header untrue that doesn\u0027t help in h2 it\u0027s that hard a clarifying question about what API surface is you\u0027re planning to have access to in particular I\u0027m assuming from the discussion so far that you never plan to pass this out of the browser as additional information into something like an OS congestion controller or something like that you\u0027re just going to use this or the information that browser needs for making decisions it\u0027s not going any lower is that right no I don\u0027t think so you think it\u0027s not right or you think it\u0027s not going any lower I don\u0027t think it\u0027s going any lower okay thank you on the client side at least yeah my remarks this seems like a very coarse crane signal you\u0027re getting this response so you get a seventh update every time we do a request which seems not very useful what okay so it\u0027s it\u0027s not completely course the time value that we put in has millisecond resolution however that doesn\u0027t guarantee millisecond accuracy although there\u0027s some questions and concerns about whether or not that\u0027s the right thing I mean did the rate at which you get new values oh yeah yeah it\u0027s it\u0027s it\u0027s coarse-grain right it\u0027s not how useful can there be ah for some of the use cases that we want to use it for accurate or not useful enough can\u0027t give an example such as controlling how much data is being downloaded at a given point in time remember Seawind is just one of the values and that we would also look at using the rtt martyt var for example I\u0027m "
  },
  {
    "startTime": "01:33:41",
    "text": "gonna let you of go next hey um so regarding that info it is currently as exposed the RTT and downlink like in download speeds as the client perceives them but that is likely to be something that will go away due to privacy considerations but I\u0027m not clear on the youths case here are you aiming for the proud to use that information or the client use that information in order to optimize something or is this something that will be web exposed as a JavaScript API to the actual application so JavaScript can already see headers through fetch and xhr right okay script running in the browser can then go look at those look at the results that it gets back from the server and then make decisions based off of that such as optimization of what it\u0027s downloading so if you see a huge fluctuation in our TT for example you see it go tenfold then you know you should probably back off from downloading the next thing in line okay probably want to look at the privacy implications of that oh yeah and the other thing about this is that this is the server will only reveal what it\u0027s configured to reveal so if though if there\u0027s a particular concern over one of those values well then just don\u0027t transmit it I\u0027m going to cut the cue in a moment so if you want to get it please do it but go ahead all right Tommy Paulie no hats so I would echo the privacy concerned I mean this is not surprising and I think I mean looking at that I think it was a very serious thing to think about and maybe it kind of calls into question if this is exactly the mechanism you want and maybe would be good to like look at what is what is really the problem we\u0027re trying to solve and are there other ways of signaling we can do to get that effect that\u0027s already been brought up a little bit because for example giving the RTT that RTT is going to be an estimate based on previous connectivity which particularly is not going to be very rich at the beginning of a set of connections and then later on will indicate the past and not necessarily what is going to be coming up hmmm perhaps what we could do and I\u0027d love to understand the use case more is have indications from the server saying hey it looks like I\u0027m having trouble getting stuff back to you at the rates I would like to and if you as the client are not adapting to that it\u0027s a hint almost from the server to the client say maybe you should back off or something so if maybe find a way to make this explicit rather than relying on lower level measurements that may not really "
  },
  {
    "startTime": "01:36:42",
    "text": "map well onto the semantics of HTTP would be more effective in this case we can talk offline about that all right yeah at Google I want to comment that yet see when do you cannot actually get obviously locally because it\u0027s the peers congestion window so that didn\u0027t get totally reasonable it\u0027s not just doing an end run around the browser um I do wonder I also be curious why you want to standardize this is I think you can just do this now and not standardize it so that\u0027s because I\u0027ve seen lots of different implementations do this in very different ways that\u0027s all the cues cut go ahead um this is just an observation this seems like the kind of thing that would fit in well with I\u0027m sending headers any point within a request for response so what do you expect to be able to send multiple of these response if that was technically possible yeah assumes oh yeah and on that note the the issue that Roy created Piatra provided a link to something called a metadata frame that could also refer to the connection but carry a header like that so you could get connection level statistics rather than just connection level statistics related specifically to a request a response right Chris lemon says it sounds like the browser has explicitly decided that this information isn\u0027t data that it wants to provide an API to I\u0027m not sure an end-run around that decision is advisable without fully understanding the reason browsers are making that decision um Patrick so I mean I think some of this stuff the browser isn\u0027t providing but some of its also information that\u0027s really only on the server that it\u0027s sharing through this and that\u0027s your interesting what\u0027s the relationship between this and like server timings sorry I\u0027m not familiar with a a it\u0027s an API to provide server timing information not terribly unlike this so you might look at that see wind is probably not what you want that\u0027s gonna vary between congestion control algorithms like how to interpret that like that means maybe a slightly different thing like in bbr than it does in Reno and that kind of thing you might be more interested in delivery rate and that kind of thing is a bandwidth metric might be much more actionable and have a semantic value rather than just a number and I had another what I didn\u0027t read this back I\u0027m sorry so there\u0027s other values in there that might be might be helpful for this like we also include so all of the fields were the exception of are the the first the first value so the the name of where this is coming from and the time everything else is completely optional and some of the other values include what congestion control algorithms are you using PBR using something else if you have a look at most of the values "
  },
  {
    "startTime": "01:39:44",
    "text": "inside of one of these we\u0027ve learned like in HTTP is you want to concentrate on the semantics rather than the the really instance of that right so you don\u0027t want to say it\u0027s PBR and it\u0027s Seawind and you figure that I don\u0027t you want that what\u0027s this what\u0027s the Mantic of how much bandwidth do I have that\u0027s like kind of the usual way what is TS mean it\u0027s the timestamp but what is it time sniffing ah that\u0027s supposed to be UNIX epoch SEC milliseconds of what what\u0027s the event of the time that those values were sampled okay and just selfishly you only need two digits precision there I think it should be three all right so so so this was a last-minute addition thank you very much I think from what I\u0027m hearing folks want to understand more about your use cases so maybe focus on that a little bit okay mailing list sounds like the next step thank you very much okay so one more our last minute addition Roy wants to talk about an issue that we opened on core as a result of other discussions it\u0027s 986 on extensions yeah I figured that\u0027s where you\u0027d want so this is the idea of defining an extension to htv-2 and eventually quick that would allow us to send metadata midstream in a request to a response and so I describe what I meant by that in the issue which I\u0027ll skip ahead and and we look down below use cases there\u0027s a number of different things that we could use this for that I just went through my list of history stuff from over the years and progress meter midstream timings like server timing just like we just saw priority updates like we\u0027re talking about in the priority draft except we\u0027re doing a different way in the priority draft non-critical path metadata which is basically it\u0027s metadata that you you would like to send but you don\u0027t want to set it in front of the body because you don\u0027t want to you don\u0027t want the time we don\u0027t want the user performance to suffer because of all the metadata you\u0027re sending in front so you send it after you sent most of the body that\u0027s very it was a critical problem with the alternates header field when it was defined for reactive content negotiation it was just too big and it\u0027s also useful things like link preload we\u0027d send that information after you figured out oh hey this is the pattern like if you\u0027re using algorithms to figure out what the client is actually performing against your site you can use those algorithms to anticipate you might want to push to the client or what they might want to pull ahead of time and these are our algorithms that "
  },
  {
    "startTime": "01:42:45",
    "text": "aren\u0027t necessarily going to complete before you send the header fields so you might want to send the result of that in the in body things like that and long pole things that aren\u0027t related to a separate channel those are all use cases so as it turns out we I I put this on the list last night and Pyotr pointed out a it\u0027s already been implemented well no the other direction oh the other up there is the one called down so in the Envoy proxy there is apparently already HTTP two extension called metadata using the frame type 0 XD already which is just a Google Doc about how to do this exact same thing yes there just can\u0027t be on it it\u0027s not but I won\u0027t be mean to them because they just save me a lot of work anyway this is almost exactly where we want with the exception of you know describing what it is what do you do with this metadata when you receive it so once we hopefully I\u0027ll get in touch with the authors of this document and we can put together a draft to define this for real might as well use that your 0 XD value but you know what it\u0027s the next one available anyways and we can put this together as an internet draft and get it done about two months and we\u0027re gonna last call the next idea so Roy just one clarification when I set up in an issue I did mean encore oh you did yeah because I think the important thing to clarify is right now in core we say that the the abstract model of HTTP is you have headers and then you have body and then you have trailers and we need a clarification that trailers might come early it\u0027s already in the spec we should talk about that okay good hmm Ian sweat Google I\u0027m fairly sure I know the authors of this extremely well also I think it turns out that in our implementation we support this already well in the in the moat if we support trailers we support it I think the people who implemented our hb2 implementation actually thought this was allowed even though they thought it was completely bizarre and then the last thing was a they I would recommend we call these Midler\u0027s because the bats are so much fun that was what they were introduced me as when this was talked about a year ago internally when we\u0027re like you can do this and I\u0027m like please so first a clarifying question Roberta pan is this meant for HTTP to HTTPS GP one this one is is HV two given the "
  },
  {
    "startTime": "01:45:47",
    "text": "progress they\u0027ve made it I\u0027m this this particular issue is for h-e-b two there\u0027s another one for quick which doesn\u0027t have any of this discussion on it but as referenced from this issue so so it\u0027s but not for h1 because I tried to do that in h1 and it\u0027s too painful I and I\u0027m very sad that we still don\u0027t have chunky extensions but anyway there are some very fun questions around the semantics of some of these things that I think are gonna take longer than two months to answer like are these placeholders within the entity body that\u0027s being conveyed or whatever we call these days do they when they are forwarded do they have to be forwarded do they have to be in the same location when they are for it when we\u0027re doing HTTP 3 or a quick version to this doing partial reliability are these about the stream or within this dream becomes a really interesting fun question so these are the things that I\u0027m a little worried about with with regards to this because it could be fantastically under spective we don\u0027t think about that so do you want to be a co-editor do you want to co edit it I can try but good luck yeah Robin yeah Robin marks a same question about hp3 and I want to say that this looks very interesting in terms of priority updates indeed I can we were talking a bit about ranged priority priority changes per range of resources and the thing this could be used to do you don\u0027t fly interesting stuff Hawk lastly I think this is very useful for service training traders mid response on the other hand I actually wonder if this would be useful for sending priority updates will be calls priority updates I expect it to be sent after the client closes their quest and it could arrive after the server has completely sent a response so if we are going to use that it means that the server needs to retain the connection assets dream state forever so I\u0027m not sure to be clear my intent for these is is only form editor that can be dropped silently so I\u0027m sure the optional metadata yeah mum times and I think that\u0027s fine and priority would be would fall into that class but I think because always point in and particularly applies to something like quick is if you put this in the middle of the request stream the request stream is long gone by the time that you need to have that information updated so it\u0027s not going to be useful for priority I gotta play my h2 because h2 of words the stream goes away because the stream sort of store is there but in in quick it wouldn\u0027t I got to basically say camping a new frame "
  },
  {
    "startTime": "01:48:51",
    "text": "type and HVAC know is so there\u0027s gonna be a different spelling of this I think if we if we want to pursue this at least that would be my preference I can see how this had helped the decisions that led to this are all rational and perfectly reasonable but I think there\u0027s a different spelling of this that would be a little better particularly the the compression thing I think we should be compressing these because it that will allow us to do some much more powerful things I believe they don\u0027t did not do that because it would interfere with the the compression algorithm possibly without either end knowing it there\u0027s because this doesn\u0027t negotiate the use of this frame type it means that you cannot change the HP state but if you negotiate it with the setting you can and so that would be that would be superior I think Roberto points out that you can still reference the the compression state worth considering nh-2 at least yeah julien asks should we talk about assignment of frame type numbers I believe Julian it\u0027s it\u0027s under I under restricted to IETF review so basically the the actual assignment would have to be a completed document from the IETF I\u0027m just it\u0027s I mentioned that just because I think it\u0027s kind of funny whenever somebody just ignores the actual process it goes ahead and assigns the next unassigned standard number because it happens all the time no matter what the idea says it happens all the time we should give away chocolate that might help we should make them give away chocolate mark Nottingham I don\u0027t have strong feelings about how they should be spelled on the wire I do think it\u0027s interesting and I do think it\u0027s useful but I look at the history of trailers and the trail of trailers and it\u0027s a Trail of Tears it is it is really painful it is you know we I think we\u0027re in core we are now just getting to the point where we understand how trailers work and have some recommendations of how to make them really useful and interoperable and implementation is still really trailing I keep on doing this that was the Ted stop I\u0027m not that good I am really scared if we introduce a new thing that is not like trailers it\u0027s gonna destroy both the new thing and the old thing because most developers aren\u0027t going to get it and it\u0027s gonna get miss implemented and it\u0027s not going to be available in a backwards compatible fashion so I\u0027m fine if this is just basically trailers that happen to arrive "
  },
  {
    "startTime": "01:51:51",
    "text": "early and as long as you can treat them like that and they work within those constraints that\u0027s I think pretty tractable if it\u0027s some new extra thing above on the model of the abstract model the HD messaging I just think we\u0027re over designing and it\u0027s gonna fail yeah I agree with that I mean it\u0027s it\u0027s painful enough to get to the point where we are in draft zero six in in HP core which does incorporate that for trailers and so I would like to stick with that and no further pachuco to Google it\u0027s worth pointing out that this was originally designed us basically internal home by hob headers or trailers right whereas I\u0027m not sure if the case you\u0027re after is end to end trailers right yes and this is worth pointing out like those have some different properties yes one one of the first things we would have to work around has how how to self describe the header fields that are sent such that somewhere connection based and some are Indian that\u0027s all that\u0027s but that\u0027s a very old HTV problem yeah but is there any reason not to use headers or like note trailers for end-to-end do we need new frame for end-to-end trailers I don\u0027t think we would need a new frame I think we just need to identify which ones you want to drop immediately on receipt no I\u0027m saying for end-to-end right it\u0027s one of the reasons why it\u0027s it\u0027s defined currently in their document as a as a literal non-indexed header field so it doesn\u0027t mess up the and we\u0027re cutting the lines right for this Mike Bishop I will I will say that I don\u0027t really have a problem with trailers that arrive or early I think the more challenging thing is going to be the fact that you then might also have trailers that arrive at the normal time and what do you do with more than one set of trailers or potentially lots of sets of trailers over the course of an issue be message firstly I thought they did combine that\u0027s the whole idea they just keep going there are trailers just one big set yeah Lucas party I think how\u0027s it related to that and and there\u0027s probably already an answer to this but I really wonder how this gets exposed to something like fetch in in like if I don\u0027t know when when that set will be bounded and finished like how how much time do I keep waiting to process a headers object and the implications of that so I think we should think about that while we Transpac something that because user "
  },
  {
    "startTime": "01:54:54",
    "text": "agents are all the same but they have different api\u0027s yeah I I agree with that Lucas and that one of the reasons why we were why we went through all of the trailer specs moved into semantics and and and just defined it the way we did was to correspond to some of the feedback that we got from Anna about from fetch that he actually wanted it to be in separate trailers separate trailers from header fields so you have you have header fields that you know up front then you have trailer fields that you don\u0027t know up front and to not mix those two the way we had described before for HB one and as painful as it is to go back and just revisit that decision the reality is the way he described as it\u0027s easier for people to implement now and less security issues so we actually went ahead and made that change and I think hopefully the same way Anna will look at this and and be able to come up with a reasonable design or someone to do that I\u0027m certainly not gonna try to design the browser side for them okay um I\u0027d say the reason I ask is because fetch isn\u0027t just within the browser context but is used in in other places it\u0027s it\u0027s you need the api\u0027s right I know it\u0027s supposed to be cut but yeah if there is not a demarcation of the end of the body of sets of key values then in the case where there are multiple header values repeated they may be misinterpreted so I think that there\u0027s a problem there we have to resolve yeah can we just ask show hands who\u0027s interested in in this discussion in general good portion of the room so when you don\u0027t figure out a way to keep it going I think the country yeah and do we think this work but I think Zoo we want an issue on core just to clarify things I it\u0027s not where the work is I want to check well I think we can be more clear in core but yeah okay good yeah and then in that but it would be an H to an extension maybe niche three extension blah blah yeah okay okay um I think that\u0027s all we have I think so I mean it sorry one thing I in when I was up at the mic I used the phrase Trail of Tears and I did that unintentionally that is a historical event that I wasn\u0027t trying to refer to and so all these for any offence caused it was just the words that came to mind at the moment I think we\u0027re done for the moment yeah yeah thanks everyone okay we will see you in Vancouver "
  },
  {
    "startTime": "01:57:56",
    "text": "funny you are Friday before sir I\u0027m just sending up covered on right now if anyone wants HTTP three stickers we have plenty you "
  }
]