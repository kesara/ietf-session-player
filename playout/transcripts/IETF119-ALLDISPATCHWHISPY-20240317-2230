[
  {
    "startTime": "00:00:03",
    "text": "[silence] [silence] Okay. So good morning. It's time [silence] Okay, so welcome to our first session of this ITF week and it's out dispatch. Actually, it's a buff, and it is an experiment and trying to see how it works if we dispatch across areas So it would be good if you could share your feedback to our IES and let them know what you think about this session. Thank you So first we got this no well, and you must be familiar with it. If this is your first time, please do raise the rate and there are some precise and policies you need to follow and the IPR issues you need to be aware of and also some guidance here you could refer to And we also got this note really well. It's more about the behavior and we have this idea anti-harassment procedures If you, it's more about you, we need to be friendly and respectful to other people's work And if you do have any concerns, please resolve [silence] and there is some meeting tips, things were the first session and you could get yourself familiar with it And please do sign into this session where the data track of the QR code and so you will have"
  },
  {
    "startTime": "00:02:03",
    "text": "And please use the onset tool and when you join the queue For the remote participants, we do have a few in this session and please make sure you all audio and video are off unless you are present presenting And your headset is strongly recommended to use And here are some resources for this meeting, you could refer to Okay, so this is a dispatch session So please, for all the presenters and all the people who come to the Mac, please focus on the dispatch questions. And there are few answers to this dispatch questions I'll direct the work to an existing working group if you think there is any. I'll propose a new focused working group and that might require a both. And maybe the draft is small, so that may require a job sponsored and further if it's not clear yet, so more discussions will be required in the meeting list All the work is not appropriate for IETF Please, because we have limited time, please keep this email next That's it So to add to that, we've had a number of people that have the impression that the dispatch session is for publicizing their proposal that is not the focus here We really want to focus on the dispatch question and just kind of describe the work that you're doing to the extent needed in order to try and answer that question but we want to try and avoid having a lot of back and forth or discussion on the"
  },
  {
    "startTime": "00:04:03",
    "text": "[silence] [silence] Yep, we got nine items and so now we can start. Welcome our first presenter, so remote presenter presenter Hey. Yeah, please start. Yeah I'll ask the slides [silence] So could you give me control of the slides or? Sure [silence] [silence] [silence] [silence] Yes I think now he has control. Which is the [silence] If you drop he can blow it right, I can work with the next slide list, it works as well right? Okay, thank you, I'm little slow on this. No, no problem. Okay, so, yeah, so hi, everyone. My name is Franco Michel I'm researcher at you, C. Louvain And the topic of the talk here is running SSH connection over HTTP 3. So the idea is to rethink the design of the design of this and run it over border transport protocols such as Quick TLS and HDP So SSH is quite famous so you may know it already The idea of SSH is to provide a set of secure services on top of an insecure network So the set of services is like having a remote interactive shell access You can send also as you could see comments and you can do, for instance, TCP"
  },
  {
    "startTime": "00:06:03",
    "text": "Next slide [silence] So if we look at the SSH architecture, so the current version is version 2 SSH V2, the architecture is divided into three main protocols, so three main documents The first one is the SSH transport protocol which is handling the security channel establishment, so key exchange and that kind of stuff and it provides encryption. Then you have the SSH user authentication protocol, which allows you to authenticate users on top of us using passwords or public keys And then you have the SSH connection protocol which is doing the actual SSH work of spawning processes and communicating with them next slide and so if you want to implement this you have to implement the three protocols and multiplex it over a single TCP connection. Next slide and let's say you want to you want to extend the crypto agorisms, like adding a new one then you typically extend the transport protocol and add new code points for new crypto algorithms, and so you update the document and then you update the implementation Next slide so SSH V2 is widely used but it still has some limitations. For instance, it cannot forward UDP packets, so that means that you cannot forward quick connections and you cannot forward some real-time protocols that are based on UDP, for instance. It can also be easily detected and blocked so SSH typically runs on 422 22, so you can simply block port 22, and if you're also server is running on another port, then you can simply inspect the payload of TCP packets If you see clear text SSH version string, then it's an"
  },
  {
    "startTime": "00:08:03",
    "text": "It runs over TCP, which works well, but it's subject to some smaller tags like packet ingestion attacks or manipulations of the secondum. For instance, the recent therapy attack was about that it was missing around with the sequence number of TCP to be able to skip some parts of the algorithms negotiation it's also not really well integrated with modern web infrastructures So if you look at modern web infrastructures, you have many ways to authenticate your users. You can use SAML2 you can use Open ID Connect, for instance or WebOthen and Pass Keys and if you want to integrate it with SSH, it can work but you have, for instance, to deploy middlewares that keep mapping between users and public key or generate open SSH certificate to do so. So it's doable, but there is a deployment burden And also it evolves in parallel to the web protocols such as TLS, Quick and HTTP these protocols also propose a secure channel and encryption and you authentication but it evolves in parallel with SSH. And so you have some features that are similar between the two protocols, such as certificates, but for instance, SSH certificates are not widely used, but SSA certificates are used everywhere And so you can have cases where, for instance, you have users that deploy their VM with an HTTP server and simply the HTTP server works well. It has a public service but the maintainer connects to the VM using SSH and it's not using any certificate it relies on the first and first use pattern It could use open SSH certificates but it has not access to the ecosystem of X509, and so it's"
  },
  {
    "startTime": "00:10:03",
    "text": "slide so that leads us to the idea here of the proposal so the idea is to replace the transport protocol and the user authentication protocol of SSH by HTTP QNCLS. And TLS and run the SSH connection protocol on top of it, so that next slide you can focus on implementing the SSH connection protocol and HTTP and HTTP and QQ and TLS can evolve independently and be updated next slide also you have access to the modern features of this protocol, so you can have a your round multiplexing, but also streams multiplexing datagrams, and connection migration. Next slide So let's see how it works in our proposal to establish a new SSH So the proposal is called SSH 3 I'll be happy to discuss renaming later So now let's focus on the idea of the protocol itself but how to start up an SSH 2 connections. First, you do the quick hand shake Next slide. Once the handshake is a step established, you use HTTP. You send the HTTP extended connect method, where you can set a protocol. Here is SSH3 and to authenticate the user you use the authorization header of HTTP and so basically here you can use any kind of authentication schemes that you want with HTTP. Next slide. If it works for if you choose a good scheme and if the user really authentications then you will have a 200 status code and the conversation is established, and you can use quick strings and stuff. Next slide If it does not work, then you have an authorized status code and then yeah you do not succeed authenticate Next slide So what are the opportunities of using HTTP here? first you have access to the quick API so that"
  },
  {
    "startTime": "00:12:03",
    "text": "on different streams, and you avoid head-of-line blocking here upon packet losses. Next slide and next slide. You also have access to data grants, so you can do UDP port forwarding. Next slide and you can also have connection migration so that if you change your IP address, if your user is mobile then you can reattach the quick connection with disrupting the SSH connection which is quite nice. Next slide You also have quick that encrypts and authenticate all the control headers. Next slide You have access with low effort to do X509 ecosystem quite easily So here on the screenshot is just to show that without prototype, we just rented an Azure VM, run the server and using Axx generates the certificates as a classical HD server, and you can access it right away without the tofu pattern. Next slide You also have your multiplexing, so let's say you have several VMs or content on the same physical host. You could put a reverse proxy on front of it and do multiplexing based on the URL or based on the user or based on the SNI, for instance. Next slide. You have a sheet authentication so with that you can simply implement password or publicly key authentication that are used with SSH2, next slide you can also do a certificate based client authentication, but you can also do more. You can use, for instance, open ID connect without any middleware and stuff, which is widely used And you can also think of maybe a or next slide, maybe web author or Pass Keys. Next slide And finally, it fits well"
  },
  {
    "startTime": "00:14:03",
    "text": "It allows SSH to benefit from the effort of the ITF has put during the previous years to deploy to develop the protocols such as Quicken TLS and so it can use all these modern features. Next slide So what about the threat? So there is one here, TCP only networks so sashv2 runs on top of TCP port 22. It's quite well supported on the internet. HTTP 3 runs on UDP Port 443. It's less well supported so it might be blocked by default in many networks So there are ways to mitigate the problem we could use TCP as well in addition to UD by running SSH over HTTP 2 There is also the recent quick-ound streams proposal, which is proposing to run quick over TCP That might be interesting as well And we could also run SSH over web transport that supports both quick and TCP so it uses both for us and so we don't have to bother too much about that next slide And so yeah, that's that's it's it for me. So now I have a couple of questions for you So is that work interesting? Does it? ring a bell um it's interesting, what would be the best? outcome for the proposal? Would it be an act? SSHV3 candidate in the future? Of course, we need implementation that worked well before thinking of any of that but still, should we integrate it to another? existing protocol? I know that mask is already doing the whole UDP-IP forwarding stuff, so we might think of an mask method such as Connect Shell or Connect process, or maybe we could think of other designs is anyone interested to collaborate on the draft I'd be happy to have any person that wants to"
  },
  {
    "startTime": "00:16:03",
    "text": "to make it better And is it interesting enough to integrate a existing working group or start discussions on the list? or anything? So let me know If anyone wants to implement and interpret, let me know as well. It's quite easy to implement because it's only the connection protocol to implement on top of HTTP 3 so if you have access to an h3 lib with TLS or quick, it would work well It's interesting enough that we have a bit of a queue to discuss So maybe we should move on to that. Sure Mike Bishop is first Mike Bishop I'mai editor for age three Bishop, Akamai, editor for H3. So I'm, I like the general direction. I'm a little caution about trying to do an something on top of HTTP and then reach down into quick I think web transport might be the better path forward there if you're going that direction. I also kind of wonder if you still need the TCP connections when you doing something that might already have mask on it. Okay well... But that's stuff that can be worked out later. As far as the dispatch question, yes. I do think that this is squarely in the ITFs remit I don't think there's an existing working group that would contain this, so this is probably something to have a bough on, see if there's enough impetus to spend up a working group Thank you, Mark Nottingham Hi, Mark Nottingham. Longtime user of SSH very happy to see more being put into it I question what the utility of putting it on top of H here is, of the list of advantages that you said you were getting, almost all of them are just from using quick not from HTTP, and especially if things are downgraded to H2 or H2 or H2, which can happen because remember, HTTP is a hop-by-hot protocol"
  },
  {
    "startTime": "00:18:03",
    "text": "and so I think like Mike I would be looking at other things like web transport or other things I don't think that's a reason not to do this on the Dispast question Yes, yes, this sounds great. But really, question the need to go over HTTP And just at a higher level, maybe for this community, we see to be more and more knee-jerk, oh, let's put that over HTTP And while that's great for my job security, I think we should really think about that architecturally. So to the dispatch question, you would point to a boff also? I think Abaf would be fine. Okay, thank you. I don't have strong opinions on the particular path. Great. Tommy Pauley? Heather, thank you for sharing this Yeah, definitely interesting work I think we should consider this. I think as people have been leaning towards, Boff, would make sense just to figure out what shape would be right. If you are doing it over HTTP, as you've suggested, you're right that it's very similar to mask. It doesn't really fit in the charter of mask because it's not really proxying in the same way But, you know, if you're doing that, we should have definitely review from the community in there. We also have other things going on in the HDP BIS working group of, like, Connect TCP, of like, modern versions of also doing the similar thing. So we want review there if we're going in that direction, but I think also the point about web transport are interesting so let's have a boff and try to maybe talk about all the different ways you could spell this and figure out which one makes most sense Sounds good. We're going to need to close the queue if I can figure out how to do that, but David Skunazi is next Hi, David Skarnazi, putting stuff over HG enthusiast I'm really excited by this work. I actually see good reasons to put it over HTTP personally. We run SSH through our load balancer internally with Connect and this could be much better, but specifically to the Disp"
  },
  {
    "startTime": "00:20:03",
    "text": "to warrant its own working group, so I would be very supportive of a boff Thank you. Christopher Allen Yeah, so I share some of the questions of, you know, everything over H.T although I think that's it's not unreasonable, but I also feel like you know, we've kind of waved our hands at the SSP off side of things, and I just have a lot of questions about using the same keys for SSH developer use in some of the peer to peer things that are natural and easy with SSH that are hard with HTTP So I'm hope, I'd like to see this as a boff, but I would like to also either know that this is only going to be focusing on transport and, you know, you know, sort of make a better layering for authentication, or that they're also going to be looking at the larger problems of auth and khaki usage and all of that Thank you Great, thank you. Ecker, next [silence] Hi, Erica Skorla. So, you know, you definitely sing my song about having one transport that's good, and I think if we were designing us from scratch, this would, like, clearly be something along this angle would clearly be right The problem is we're not designing a session or scratch. There's a huge deployed base of SSH And so I think the threshold question, and so I agree with people who said that there should be a boss on to, um, going to do this. But I think threshold question for that box, ought to be, are any people who are currently deploying SSH? at scale, including the, like, big SSH clients in terms of in doing this? Because they're not an ITF producing something that says you do SSH for quick is kind of like not going to make it very well So I think that the ISG should determine prior to proving this BOP, whether or not that is, in fact, the case because having a boff when like no one wants to do it as silly. So if if like you don't want to do it then fantastic, people don't do it, we probably should not"
  },
  {
    "startTime": "00:22:03",
    "text": "thank thank you i mean this seems to be pointing pretty clearly toward a boff we do have three more people in the queues so and we're about out of time, but please go very quickly. Alex Hi, I'm Alex Schenhovsky, Google. I'm also one of the maintainers of Mosh, which is, I think the first use of an SSH-like thing over UDP And I want to say that I'm very excited in having this work move forward. There's a bunch of feature requests in Mosh that would be solved by this work by people basically wanting the benefits of UDP transport along with the reliable streams of TCP So I think definitely we need to move forward on this I have lots of evidence that users want this and would deploy this including Google internally users of Mosh So I definitely want to see if this move forward. I think Abaf is fine. I also think mask is fine, but we definitely would need to do a recharter I think that the question of why not quick is absolutely answer by the Mosh precedent. We need the TCP callback. We need all these things to work well. Okay, thank you Richard Burns Hi, Richard Barnes. Just a quick medical question. I think both is the obvious answer a plus one on that. I just hate it every time we dispatch something to a buff that takes another three months and we waste all that time. So let's, I'm looking over at the very ADs, like, let's please keep this moving and have a virtual boff in between the ITS Sounds good, thank you. Martin Thompson. Yeah Martin Thompson. I think Christopher mentioned this, but I think the question of do we do transport? or do we do transport and all the various authentication? options might turn into a bit of an attractive nuisance. So I suggest that some work be done ahead of any boff on refining the scope a little bit. So it's very clear what any working group might be working on because I think the plethora of options that were presented to us is likely to cause failure more than success. Okay, thank you So I think the strong consensus here is"
  },
  {
    "startTime": "00:24:03",
    "text": "And we'll move on to the next presentation I neglected to acknowledge our third chair that's remote, Rafat, who is here also and contributed a lot to this and also to our other chairs that aren't listed, which are Daniel Gilmore and martin vigoureux So thank you to all of them So the next presentation is Andrea Vesco Yes, do you hear me? Yes, we can Hello, everybody So, I'm going to present preliminary work I prepare with my colleague Leonardo Perugini on the use of the very fiber credential as a new credential type for authentication and transport layer security Next slide, please Okay, just to set the graph verifiable credential is one of the components of the cells of the entity that is a decentralized model for digital identity in which, of course, the entities have control over the information they use to prove who they are and the identity in this model consists of three main components Of course, a key pair are decentralized identity that is a URI to essentially an address to DLT where the public keys is for, and at least a verifiable credential that also contain a link to the DAD of the identity and both these and DAD are have their full specification in W3C and of course they are evolving Next slides, please"
  },
  {
    "startTime": "00:26:03",
    "text": "an entity that want to build his hope self-surreign entity started with creating his public key and secret key, the keeper then he's going to store the public key or the public key [silence] [silence] Uh-oh, he froze [silence] froze out here Yeah, Fresno [silence] Andrea, are you [silence] We don't have any audio from you now [silence] [silence] [silence] [silence] [silence] [silence] [silence] [silence] [silence] [silence] click the presenter. He's off Okay, well I think we're going to move on then, and hopefully Andre can get his connectivity issues resolved, and we'll come back to that. Okay. Do you hear me now? We hear you now. We hear you now. Okay, sorry for that. Okay, good Please continue, then Yeah, sorry for that. So, we are at the point, an entity saw the public key on the deity and then at that point, can request a very fiber credential to one of the issuer in the system"
  },
  {
    "startTime": "00:28:03",
    "text": "with a verifier to get access to service and resources Next slide, please please And how this authentication works today Essentially, this authentication occurred at application layer for the client side [silence] [silence] Uh-oh Again It's unfortunate [silence] In any case, while we're waiting, Christopher Allen, why don't you go ahead and Yeah, so, this hits a lot of keywords. Go ahead, is he back? No okay. Anyhow, you know, there is a Spice Charter being circulated for a Boff, which talking about verifiable credentialsals There's a lot of stuff going on in the DID, verified credentials world in the W3C that doesn't map to the ITF very well You know, I really want to see some stuff here to resolve some of these things. I'll even admit even though I'm an invited expert and co-auth of the DID spec and W3C verifiable credential spec, that, you know, doesn't work with HP, doesn't work with some other IETF patterns, etc that this is, you know, this is the beginning of a big important pile to untangle it. So I just wanted to throw that out as a as a, so this is an important topic but don't know how to do it. So toward the dispatch question, what, how would you presume that IETF should take this up?"
  },
  {
    "startTime": "00:30:03",
    "text": "I'm not sure. It just feels like Boff usually has more of a charter before you do a boff, and this feels like this may be, maybe really needs to be multiple boffs. I don't know. I don't know what project boff. Yeah, there are different sorts of boffs. Okay, thank you Andrea, you're back? Yes Okay, did you want to continue, or we've got several people in the QW? I can, we can, we can just to the next slide, and we can arrive to the next slides, and we can arrive to the point have the specific domain, like the IOT domain, the use of X509 certificate is not straightforward and in these scenarios use SSI can be a very good idea. For many, there are many pro just as some example the endpoint can update, rotate its keeper without the need or refreshing the VC The endpoint can also revoke immediately its the idea and the identity. So in this domain, the idea of using SSI can be a good idea, and so if we have this kind of identity, why not to authentication data? at the TLS layer? And this is exactly of our of our ID. Next slides And what's exactly the topic of our ID. Next slides to add a new certificate type called VC, in addition to X509 and row public key in the existing client certificate type and server certificate type extension add just a new extension called DADD methods that the endpoint used to transmit the list of DAD methods to transmit the list of DED methods resolve"
  },
  {
    "startTime": "00:32:03",
    "text": "case, and in case certificate type is selected in this case, the certificate message will carry, of course, the content of the inside the message. Next slides, please This is just an example of a full election and shake with the verifiable credential where the client proposed to use verified credential of X5 or 9 in server certificate type and client's certificate type and then in form the server data match that he can use to resolve the DAD match that he can use to resolve the DID of the server and the server can then say select in this example, for example, the verifiable credential to proceed with the authentication with this very simple extension, with this very simple use of the server certificate type and client certificate type, we can also have hybrid and shake. Next slide, please Okay, I think we're getting enough detail here that we have several people in the queue with opinions about dispatching this. So can you wrap up? You can go to the last slide Sorry, the previous one So what we have already learned during the previous ITF, first of all, the tier working group said that application or domain specific extension to TLS are out of scope and we perfect understand the reason behind this The WG, the working group usually only consider extension to protocol that are widely applicable while at the same in this. In this case, we are targeting the IOT domain"
  },
  {
    "startTime": "00:34:03",
    "text": "There is a possible interest there, but course, the extension are out of scope. And so we are here just to listen to your suggestion If, first of all, you are interested in this kind of work and what are the possible venue to continue this discussing the idea. And thank you very much and sorry for the disconnections Okay, thank you. We're going to close the queue pretty quickly so if you have something to say about it, please join the queue. Hanas, go ahead. Hi for defining or add a new value to this registry that defines these certificate types, which this proposal does, it's you only need a specification. And ideally, that specification should be done in an organization that actually works on these verifiable credentials so I would just do that in the W3C, right, the specification alongside of the group who I'm not a W3C expert who already works on these verifiable credentials and does the work there. If someone does something similar for things like CWD and J.W.D as it would be, for, for example, in Spice then clearly there, there potential home there, but it was not proposed there and was not discussed, so purely speculation It looks pretty straightforward to me, just add a red to that registry and done Okay, thank you, Ecker Ecker I changed microphone, so we'll see if this one's any less terrible. Sounds good Okay, so as a hottest indicates, if all you need is a code point, then we don't need that you don't need to do anything in TLS because all you need to do is"
  },
  {
    "startTime": "00:36:03",
    "text": "Well, I can't help too loud someone has to fix that separately However, there really is only one place in ITF right now this could go to, which is TLS, which is the only places, like, really empowered, like, making new code points for TLS, other than just doing it yourself So, I think probably the answer here is to bring and I'm also somewhat concerned, do some questions in the chat about whether or not the binding to TLS is actually straightforward as people seem to think it is and so I think this really does have to go to TLS, and then if there's no interest, then you should just register yourself. Okay, thank you Richard Burns. I am Richard Barnes I would like to dispatch this to the future I think that, like Eric and Hahn is are totally right, that the places should ultimately end up is in TLS or as a private registration, but I think the VC space is just too unsettled right now to do things in the ITF. There's a bunch of you know, multiple defined non-interoperable stuff, and we just need some time for the space to settle down and get some deployment first before we start defining these code points. Once that, settling down has happened, I think it'll be straightforward as Eckron Hunas pointed out, and we'll just do it in TLS, and it'll go. So if we're going to dispatch it somewhere today, I'll send it to TLS, but I think we should hold off a little bit before we do that. Okay, thank you Wes. Thanks, Wes Hartaker, I say. I'm not quite sure exactly where did she? go. I kind of like the future idea, and specifically wherever it ends up, I think that there are multiple sort of spaces that are working on this now as one of the chairs of the dance working group It's an example of there is some overlap in the solution space so it would be good to see a comparison of why you're not following any of the existing work in various places and you know how can it be married in what is different and things like that in order to get a decent evaluation Okay, thank you"
  },
  {
    "startTime": "00:38:03",
    "text": "is roughly that this goes to TLS if it's in fact ready to come to IETF at all Okay, thank you. Next presentation is Happy Eyeballs Version 3 with Tommy Polly [silence] Can I get to my permission? Yeah, if we can figure out how to grant. If you can do that Can I do it? it? [silence] Thank you. Thank you [silence] [silence] Grant pre-load. That's it [silence] Got it? Yep [silence] [silence] Okay, well. You need to join there I am. Yeah. All right I'll just say next slide. Hi, I'm Tommy Pauley from Apple, and I'm going to be co-presenting with Nidu who is on the Google Chrome team, and she's remote. So I'll just give brief introduction to Happy Eyeballs as it exists and then Nitty will take us through why we need to do first and the questions about where they should go. Next slide [silence] All right, so happy eyeballs. It's a funny name if you haven't heard of it before. This is an algorithm on the client that the reason for the name is that is trying to make the user's eyeballs happy when they're loading a web page in a browser or doing some other type of interaction by making the connections work quickly and get to servers that are actually working. Next slide, please [silence] So the context here is this came from handling"
  },
  {
    "startTime": "00:40:03",
    "text": "on various networks, and it's based on the assumption that IPV6 is the more desirable option that you want to use and it's a way of racing different options you have One of the main reasons to prefer IPV6 actually is that it does perform better for clients So, next slide There are a couple different reasons here It's not necessarily intuitive, but because are going through fewer Nats on various networks that ends up being a better experience for clients. We also have we see a strong correlation between a routes and having more optimized servers and better server location and so it actually makes the experience better routing but also v6 is you know the future that has been coming for a very long time So we want to use it. Next slide, please But, of course, we can't always use IPV6 even if it's available because sometimes it's broken, and that was the whole reason for motivating happen eyeballs in the first place. Next slide, please So there are various things that can go wrong Servers can essentially be available on V6, but be broken or slow. Networks can offer you V6 connectivity, but they may have middle boxes that slow things down or actually break connectivity. But one of the insights that we get from Happy Eyeballs overall is that choosing just one address and trying to make a connection to that and waiting before you ever try anything else that you have as an option is a bad idea. You're more likely to run into an issue. And this actually extends to things beyond just which IP address you want to connect to of a server but all of the other options you have. Banking on just one option working doesn't work very well. Next slide So I'm briefly going to go over what the V2 algorithm is. So it essentially has three stages We do DNS queries, asynchronous we sort the addresses, and then we erase connections Next slide"
  },
  {
    "startTime": "00:42:03",
    "text": "will do DNS queries to figure out what available addresses they have. In Quad, and they do this all in parallel, and they have an algorithm for how to wait for the answers to come back. Next slide The next step is that we do sorting their existing RFCs on this but we also use historical information and add a preference for IPV6 at the front. Next slide And then finally, this is one of the key parts Happy Eyeballs, is about racing connections, and so there are different connection attempts going on in parallel, but they're not all at the exact same time. They are a staggered parallel race where you choose your most preferred option, then you choose the next preferred option after a delay that's based on the round trip time of the network. Next slide You can look at this in detail These are some numbers that we've shared before in MapRG and other venues, but overall we find that Happy Eyeballs does a great job of helping us use V6 when it is a very available and when you have networks and when you have dual stack hosts available, but we also see that even when all the stars otherwise align a stack that's doing Happy Outwows v will end up using V4 around like 7 of the time globally, so we do still see brokenness out there So it still matters to do this. Next slide, please As a sidebar, there's some discussion that's happened around happy eyeballs that doing this type of racing can hide brokenness in middle boxes, etc. We believe that's something that doesn't belong in the core algorithm document, but is something that should be addressed and discussed somewhere within the IATF about how can we do better reporting for errors Next slide. All right, so that takes us to why do we need a new version So Nidie, go ahead. Yeah, so I'll talk about version three of the algorithm. Next slide, please So why do we need a new version? So there have been lots of changes to DNS"
  },
  {
    "startTime": "00:44:03",
    "text": "published in 2017, including this new program that you might have heard about called Quick, which was standardized three years ago, and more widespread use of it increasing deployment of IPV6 only networks, standard of new types of DNS responses in the form of this and HGPS resource records last year that provided information like addressants service priorities, and supportive protocols, and encrypted client Hello or ECH, which is being worked on in the TLS working group. Next slide, please please So the updated algorithm follow the same overall phases as the previous version as Tommy talked about earlier. Next slide [silence] However, there are slight tweaks to incorporate the new addition which are bolded. So when we asynchronously core DNS, we now query for SCCB records in addition to the quad ANA records, placing SVCB responses first, since they provide better hints about addressed families, ECH, priority, and protocol support There are some additional considerations to incorporate and prioritize SVCB-based responses in the rest of those sections as well. Next slide [silence] So the sorting algorithm for the addresses stays mostly the same except with the addition with the addition of ECH key SVCP priorities, and ALPNs, if they're present and we prioritize these ahead of the other criteria to maintain security while respecting priority signals and protocol preferences. Next slide And finally, when making our connection, the previous version raised attempts until the TCP handshake completed but this meant that we might have ended up with a broken or slow TLS handshake where another attempt might have succeeded sooner. In the updated algorithm, we raised connection attempts until the full handshake completes, whether that's TLS over TCP or quick. Next slide [silence] There's a lot more detail on this slide, which I won't get into now, but as you"
  },
  {
    "startTime": "00:46:03",
    "text": "endpoints due to the benefits that Quick provides including improved delivery, congestion control, and connection migration migration. Next slide We also included several considerations based on ECH to maintain security. We still have some open questions regarding what's reasonable in this area based on clients being SVCB optional or reliant, and when it's okay to start a TCP handshake or send a client hello Next slide so this brings us to the dispatch question where does this work belong we started with B6 ops at the last ITF, as that's where the first two versions of Happy Ads Eyeballs were developed. However, as you've seen there may many areas that are involved in this version of the algorithm, which we'd like review from, including IPV6, DNS Quick, HTTP, MTLS Some options that have been suggested are continuing in B6 ops with reviews from other groups moving to TSPWG as it's a more general trend group or forming a new working group in W area, focusing on client algorithms and operations So we'd love any feedback about the best place for this work. Thank you okay thank you and we have a queue starting, Bob Hinden first [silence] [silence] Hi, Bob Hinden I support this work. I think it's important I don't have a strong preference, whether it's in V6 office TSVE Working Group, but I think we should do it, and it should get dispatch somewhere. Thank you [silence] Lorenzo Khalidi, I also support this work. I think it should not go to V6 ops. I think while it's grew out of V6 ops, it's all solves, it solves a plethora of other problems and has a variety of hard to predict implications"
  },
  {
    "startTime": "00:48:03",
    "text": "is something that V6 ops is really not qualified to talk about, right? And, you know, racing quick against a what are the consequences for, I mean, I feel that it belongs in some sort of transport working group So yeah, not in V6 ops That working group should also carry consider, again, these consequences, and I would also caution us to keep in mind that the performance advice is obtained by this protocol, and the fact, for example, that it uses IP4 some percentage of the time may not be because it chooses the best path it may be because it's just reacting to random packet loss, which could cause, you know, the second backup attempts to be preferred just because, right? So I think that is something that really sort of the transport folks are, I think, most qualified to talk about And yeah, this isn't you know, not, I think the position of saying, oh, yeah, you know, this is, you know, this is, to race is a bit simplistic The other, the other position of saying, oh, yeah, well, V6 were you can only try one address is also simplistic, but again, transport is the working group that is most qualified, I think Thank you Okay, Jen. Yeah, Jen Rinkova. Thank you very much I just read the draft again. I really like the changes you've made. I even sent you some comments because got confused with your GitHub process So I sent you just in the mail. Anyway, I think this definitely should be done, right? Regarding groups, I understand Lorenza concerns, but I also see a lot of things which do belong to this So maybe you really need a different working group or like, oh place when all interested people come together and work, and I do not see it really matter which rooms those people are sitting but for example one very important thing I think we need to discuss, is what happens when"
  },
  {
    "startTime": "00:50:03",
    "text": "DNS 64. Do you want that to prefer? synthesized records and go through the not 64 or you want them to prefer native? IP4, right? This is something it's a fundamental question, right? Do we want those dual-stack devices? still use V4 natively? or fake V6, right? I don't know the answer, I think it's something we shall discuss All right, Ted Ted, Reney, I think the dispatch question here is best answered by a new working group. It seems that there's a good bit of overlap, but it's overlap in different working groups and in different areas, and the only way to really bring that together is to get a new working group and assign advisors from the appropriate areas and encourage people to join it. Thanks very much Thank you. Okay, Ralph Hey, Ralph. Ralph. Ralph, you're back on my I certainly would like to work on that and I think it is belong somewhere in the ITF. I'm don't have a particularly strong preference, but as Ted said, there are multiple kind of evidence that are pursued here, so maybe a new working group is a good idea [silence] And Pete. Uh, Pete, Pete to voice what was discussed in the chat room, a short recharter for Taps might be interesting You know, I think the comment that transport people need to be in on this discussion is exactly right somewhere in that area would be fine Doesn't matter whose charter you added to, or as Ted said, a new working group may be one of these short, you know, quick working groups with single topic is fine. But something that gets this done quick would be good be good And since we've got time, Warren, go ahead Thanks, it's not actually related to this, Warren knock monkey. Could whoever's got the action?"
  },
  {
    "startTime": "00:52:03",
    "text": "please turn it off. It's using a megahertz and it's over there somewhere and it's killing the way wireless. Okay Thank you Okay, so we lock the queue and we hear support and interest for sure for this work and some clear comments is not V6 off and we hear more about the support to have a new working group that working group might cross areas so we need experts for sure the transport area needs to be there. Yeah The wait to hear. Yeah, cool. Thank you Thank you. So our next speaker speaker speaker [silence] David Weekly is next. Warren wasn't joking Lars Lagerd. Warren wasn't joking. So somebody here has a travel Wi-Fi access point that is screaming louder than all the ITF access points, and which is why the whole section of the room has no Wi-Fi. So if you have a CTE travel Wi-Fi box, please do turn it off off [silence] [silence] [silence] [silence] People can hear me all right? Yes, yes, please Sweet. All right. So, hey, everybody. This is my very first IETF. I'm really excited to be here, or at least here online. I wish I could be with you there in Australia While I've worked at places like Google Facebook, and now Capital One, I'm here presenting without affiliation to any of those institutions. My personal opinion is that email missed is an actual and not hypothetical problem It unintentionally happens nearly all of us"
  },
  {
    "startTime": "00:54:03",
    "text": "There's a clear analogy to postal mail handling and all all-involved parties benefit from having a standards-based approach to resolving the problem. Next slide, please So, here is a real non-theater problem. What can recipients do about misdirected email? What you see on the right is an actual email? I got in late December. I get maybe one of these a week sometimes for a Diane Weekly, sometimes for a Jeffrey sometimes for a Doug. Some would argue that I should just mark the email as spam because it's the sender's responsibility to ensure that emails are sent to the intended party and should be double opt-ining a user to make sure that they only send email to the intended recipient for a given account. While there's a great of truth to that, there's also flows that make it much more challenging to verify an account holder's correct email address, such as if a user wrote an email address on a sheet of paper for sign-up or faxed it in, and yes, that's still a thing or representative took the email address over the form. Now, in this situation, the sender is legitimate and otherwise has proper mail sending hygiene with correct ARC D mark SBF and dek but what it doesn't have is either an unsubs link or one-click unsubscribe because it's not a sub-subscribed list. I have no standard way to tell the sender that they've got the wrong person for this account, and I really would rather not spend an hour on the phone with the sender to try and get them to update the records. It would be nice if there were, like one click on unsubscribe, a simple way to just tell my mail client to tell the sender that they got the wrong guy Next slide, please So postal mail solve this about a hundred years ago you probably get misdirected postal mail all the time. The post office knows this as part of the definition of first-class mail that they'll transit the letter back to the center if there was an issue with delivery. And one of the issues with delivery is there's no such person at the address. So you bounce the letter back to the sender, and hopefully that kicks off a process, whereby the sender can attempt to find a better address for the recipient or no another way to get in touch with them, like a phone number. Next slide, please"
  },
  {
    "startTime": "00:56:03",
    "text": "what if email had a wrong recipient notification It would need to be user-initiated via the U.S This wasn't meant for me. It would probably need to only show this if the UI was conf- that it wasn't spam, that the message wasn't spam This is mostly for a B2C where you often see email addresses of the sender as no reply at. The human rights to you, and it's misdirected you can just write back to them like, hey, you sent this to the wrong person What I like about a proposal that gives a wrong recipient notification is that this benefits the wrong recipient who will, in theory, no longer get the emails not intended for them. It'll benefit the sender because they might accidentally be transmitting PII to a third party, and it benefits the correct recipient because they finally actually get the email that was intended for them Next slide, please So let's say we craft some sort of a return path for misdirected email We could call this a wrong recipient flow. So what? What is this option, what options does the sender have if they get? one of these notifications? The first is that it's likely that they have the wrong email address for the user, so they should make a best effort to try and connect with the user via some other channel to very a correct email address. They could use a phone call, a text message postal mail, email to prior addresses used send a push notification if the user has their app installed or even show a message in the app or web experience that they need to update and confirm their new email address. And they may want to stop sending emails to that known bad address for the account Note that this is different than a do not email indication. The user may have a separate relationship with the sender for a different account that is correct. Of course, and does note earlier, if the sender validates the email address mapping to an account this will mostly be avoided. Next slide, please Cool So if we think that email should have the same, no such recipient capability, as postal mail has had for centuries, what are some ways that we could implement? this? My thought was to mirror the wild success that has been seen in RFC 8058 deployment"
  },
  {
    "startTime": "00:58:03",
    "text": "major mailers this quarter are going to stop carrying non-eating compliant bulk email. Just like 8050 my proposal has a simple post to a sender provided and sender validated URI with the client never sending any cookies with the request. For offline use, so SMTP only MUAs, the standard could support using a mail to URI. Much in the standard is been drafted with an explicit intent of being a close cousin to 8058. Indeed, one of the 8058 authors has been helping me with the proposal. Next slide slide So here is the proposal. It's actually, in its essence, completely contained in this page. There's a header that senders include for wrong recipient notifications, and there's a post to the address by a mail client when the user indicates that an email has been misdelivered. That's it. You'll notice here a assigned URL, but there's explicitly not included in the standard a strict recommendation on how to sign the URL since it's only the sender who needs to be able to validate it The client just blindly posts to the provided URL after the user action with the fixed post body and nothing else. Next slide That's it Thank you so much. I really appreciate your attention I'd love to know how we can dispatch this best Okay, Tobias first [silence] [silence] [silence] Okay, Tobias Flag, are you here? So, Tobias, Hivich, Max Plan Institute for Informatics. So I personally am not sure whether this draft is just adding another version of NDR. I mean, you mentioned NDRs, but technically it's just encoding a user interfacing based on NDRs because technically we just send an NDR to the return path, and people would just be required to actually do some kind of handling for return path emails, which I mean if operators like ESPs would pick that up that much"
  },
  {
    "startTime": "01:00:03",
    "text": "So your answer to the dispatch? I'm actually not sure what we have something for that at the moment Okay, thank you Joan? Thanks. Does my audio work? Yes, I got you. I'm the author of me that he referred to, and indeed, the one click on unsubscribe, has been successful enough excuse me, that many large mail systems now mandated for bulk mail. And having talked to some of them at Vaugh, I think they're interested in this, too So I think we should do it. I think the obvious place to dispatch it is assuming the mail maintenance working group gets spun up in the next month or two, which seems likely you should go there Thank you, Brong Sorry, busy taking notes Yes, I definitely think mailmate is the right place to just this. I think it is one of many things. There's been discussion of a more general trust and safety response, say, this, this message is something I subscribe to and don't want, which is the list unsubscribe version, but also this is something I didn't subscribe to is something that you might want to say back or say there's something else wrong with this message And so a more general feedback than just adding a new header for each new case we come up with and having a general feedback and then a defined set of things you can say with the problem with this message in the post body is we probably want to solve more than just this one problem at once with this and extend list unsubscribe just a the previous dispatch as well there was a thing in the chat that said that we should dispatch it to every working group and see which one take the work for happy eyeballs I just wanted to throw that out there. Happy Dress Christopher Yeah, I just, so I like this. I think you know, having it go to mail maintenance is"
  },
  {
    "startTime": "01:02:03",
    "text": "extent, this is following a successful path with 8058. Can we just send it? to an area director to basically, you know, do one of the expedited RFC things? or at least an information graph, so that people can start saying, yeah, that's good enough, Will? you know, we're already implementing 8058 we'll implement this as well, rather than waiting six, nine months a year or whatever for this to go through a working group that doesn't exist. Funny, you should mention the area director. This is Murray the area director you're talking to I think that the right way to do this is to send it to Mailmate, which is currently in the process of hacking out its charter before, it should hit the next television 4-4. So it's probably going to that way. I have no interest in sponsoring another document, especially since there's a working group coming that is in which this falls very clearly Scott Fleur. Scott Fleur is Cisco system I would not want to give, have it rush forward because there may be some security implications about allowing somebody to send this arbitrarily unauthenticated wrong email address needs to be thought through I was, a working group would be fine I don't, I wouldn't go through an area director directly. Thank you Okay, thank you So, and we hear support. And so, maybe more discussions in the mail maintenance working group to have more feedback and also we have suggestions to like share it in more areas and to get more feedback. Okay so next it's a remote presenter"
  },
  {
    "startTime": "01:04:03",
    "text": "Thank you very much the? call? Yep, right here And Christopher Allen will be joining for any comments, questions, except So my name is Shannon Applecline. I'm with Blockchain Commons We're working on creating infrastructure that's open, interoperable, secure, and compassionate. Next slide So data is the heart of the internet, but still the Wild West. There's few controls on how it's shared or re-shared data privacy is all or nothing. Once data is breached, it's out there It's being shared with a little concern for human rights. We need to make the internet more humane next slide so we have three challenges. The first issue is that data is not minimized. Most interactions involve more data than it needs even in the face of regulations such as the G Next slide That becomes even more problematic when data gets out there You can combine one batch of excessive data with another and suddenly you know a lot about the data subject Next slide Worse, when you have lots of data, you can use it in ways totally orthogonal to what was originally intended. You might have given your address to receive a shipment of vinyl records, but when that gets correlated with the financial data, you provided it to your bank as KYC, suddenly the burglars are knocking at your door, or rather pry-barring your window. Next slide. These challenges are all cumulative More data disclosed means more data correlated means more secondary use, means more problems. Next slide Where's the amount? of data being collected? It's growing every year It's more sensitive and it's more often placed online We show some activity trackers here. I have one on my wrist They're a great example. They can record where you are and to a certain extent, what you're doing. How can we protect data that? sensitive? Next slide"
  },
  {
    "startTime": "01:06:03",
    "text": "big frontier. It's really coming of age right now with DIDs MDLs, Idis, but it's been around for a while I shockingly discovered I have 410 online accounts that contain a lot of personally identifiable information If that's all correlated, everything about me is out there. Next slide Honestly, though, identity credentials, healthcare, they're just the tip of the digital iceberg How much information could a competitor gain if they accessed shipping records? How much espionage could a foreign country commit if they tracked the executive offices fit? How much trouble could hackers cause if they broke? the chain of identity and software releases? We need to get in front of this now. Next slide So, IETF has some solution RFC 6973 and 8280 which talk about privacy and human rights considerations Next slide 6973 talks about privacy in the design of internet protocols. Next slide [silence] 828 expands that with a look at human rights considerations such as open secure, and reliable connectivity. Next slide Unfortunately, these RCs are not enough because they're not concrete and more importantly, because they're just considerations they're not required, they're not being used Even if they were new privacy innovations and requirements have appeared in the last decade, the RFCs are dated. Next slide For example, take a look at 6973. Its first three recommendations for privacy are to incorporate anonymity, pseudonymity, and data minimization. Next slide [silence] Shannon, excuse me, and you got a lot of slides, and so please focus on this best question Yep, yep, we're going to get to what we're doing, and then my request very quickly here. So, Bitcoin's an example of why pseudonymity isn't enough. I mean, we've seen"
  },
  {
    "startTime": "01:08:03",
    "text": "Meanwhile, data minimization, though it's definitely a foundational requirement, it causes problems with some of the human rights needs in RFC-280 Next slide. So there are some cutting edge technologies like zero knowledge proofs, for instance BBS proofs, which can deal with this. Next slide but we need privacy tech that's simple, well understood, and in production but still more advanced than 2013. Next slide we need a middle ground. Next slide. So that's where we come to our solution, which is deterministic hash data illusion. It's that middle ground. Next slide Deterministic means the data is always stored in the same way. Next slide Hashed means that a cryptographic hash is created for each element of data. Next slide And Illision means that the data can be removed, and in particular one, the data to be removable by any holder of the data, not just the subject or the issuer. Next slide So the format we've been using for this with working code is a Merkel tree. There's other options Next slide. In a Merkel, tree, leaves hash the date of their branch, nodes, hash the has beneath them, and a root hash, which is what you see seeing at the top here, verifies the entire structure. Next slide When you lead data, you remove one or more branches, but the has remained valid the integrity of the data. Next slide So what you do is you sign the root hash and then you can have authenticity, even when material is elite Next slide. So here's some of the core advantages. Any holder of the data can choose to ally data at any time that supports deamamization because it's suddenly easy to exclude information, but the signatures, as I said, remain valid"
  },
  {
    "startTime": "01:10:03",
    "text": "A hash data elation system can go much further Inclusion proofs mean that you can align parts of a tree and then give proofs leading to the alighted hashes, which allows for the verification of data, even when it's not there Heard privacy takes the next step. You can publish only a root hash and give out inclusion proofs to data blocks allowing individuals to reveal that data are not, as they see fit Next slide I spoke earlier of the dangers of correlation, but it's actually not all blocks and white. Sometimes you want to correlate, sometimes not An advantage of deterministic cache data elision is that allows you to match the requirements of your data set by choosing a hashed method that either supports or hinders correlation as you prefer Next slide For the IETF, the advantages are it supports these two RFCs, and in particular, it supports the authenticity, decentralization, and integrity from the human rights RFC that we're kind of left out if you do core data minimization. Next [silence] we think it's important because it can cover a whole different, a whole lot of areas, credentials, data, provenance, etc. Next slide So, we'd love to see the support for any version of deterministic cache data lesion but we have one called Guardian envelope It includes all of the fundamentals that we discussed already. It's built on a Merkel tree, and it also does additional things like encryption operational functions other cryptographic data, and lots more. We have a full work prototype of it in a reference CLI. Next slide. Okay, here's our questions. Next slide [silence] Most generally, how can we advance the search? of issue? It feels like there's not a good venue, but we have three specific things. Next slide First, we feel like these two F.R have been largely ignored"
  },
  {
    "startTime": "01:12:03",
    "text": "working group charter, we heard there just wasn't a lot of support for these RFCs. How do we improve respect? for what we've heard called Core IETF value? Next slide specifically on data minimization how should we create a group for it? Should it be CFRG? Should we run above? Should we join a boff? Should we join another group? And next slide another group? And next slide. More specifically, for Guardian envelope, our specific, our specific implementation of this, we did great work with the Seabor Group on it, but they ultimately said they weren't the right venue Some say we should try and work with Coz, but they do have legacy constraints. So we farm a working group here. Do we take it? to an area director, or do we do a boff here? Next slide. If you want more info these are our two drafts AppleKline hash delision is this problem state and McNally envelope is the right of our envelope. Next slide Next slide. Thank you And this is contact info for myself and Christopher Okay, thank you. Paul Hoffman I, you gave a list of the chairs gave a list of possible dispatches at the beginning of the meeting. I think this goes into a different place, which is the IRSG. There is I've read, or I've skimmed over carefully the two drafts, there's a lot of statements in there about this will cause that, that you'll get certain features and such like that, that I are far outside the protocol space I would propose this would be something of that is very strongly research and it's not just cryptography. So I would say it would be somewhere in the IRSG and I don't"
  },
  {
    "startTime": "01:14:03",
    "text": "and would interact with CFR but not be in CFRG. Thank you Tobias. Yes Tobias Sviwich, MPI, and I would actually second said, so HRPC, maybe might actually be the most fitting place [silence] Okay, thank you. Ecker [silence] Yeah, so I think you've asked a number of dispatch questions You know, I guess, to answer the initial one, those documents you're citing were not produced by the ITF and so the fact that they're being not, like, widely implemented ITF might be partly due to that The, you know, there are a number of places that discuss things like this, as people suggested, perhaps somewhere IRTF, though I don't think HRPC is probably right place, and it's not really doing anything meaningful for this protocol specification The, you know, this is a, uh, uh, uh, uh, other people might use, and so in terms of dispatching it in terms of IETF work, I think the threshold question, as I sort of said earlier, is it anybody in ITF want to use? this or something? And if the answer is no, then it gets kind of this dispatched the dev null. So, you know, I certainly don't think should be dispatched to any ITF work right now, and I think that the next time you present this, you should be, what you should be asking is, to demonstrate desire for people in IETF to want to use this technology Okay, thank you. We're going to need to close the queue. We just did. And so Michael. Yeah, thanks so much. Yeah, I appreciate this I will strongly concur with maybe IRTF for some of this. I'm not 100% sure exactly what was being proposed there. It seemed like a whole bunch of different relations things. Maybe there were some technical drafts as well that I know have bounced to Cozay and Seabor and feedback's been given back on that, right?"
  },
  {
    "startTime": "01:16:03",
    "text": "at Cozay and Seabor that has some relation, and then go from there and see, once again, to Eckers point, if there's follow-on tech that someone at IETF wants to use, maybe we can those pieces into IETF very explicitly with one or two slides, not 41 related to a broad problem statement. So thanks David Skunazi David Skonazi, Internet Architecture Board I was kind of confused by this presentation in that it started off explaining how what we have in terms of abstract properties that we want was insufficient in terms of our human rights documents or our privacy considerations documents and then proceeded to say, and we have a technical solution to me that was a lead that I, you kind of lost me there. So I would say, if the goal is to move forward, with this technology, then I don't see a need for it at this time I don't see any protocol that could use it. And then if that's wrong, please come back with those implementers in mind. But if the goal is to say, well, maybe we need another human rights document that has these properties that we want then yeah, that should go to HRBC, but that's not what these documents And just like saying, you know, these privacy documents aren't doing anything well, if you look at the decades since the privacy one was published, we've done quite a few improvements to the protocols that the ITF owns in terms of privacy So in terms of dispatch, I would say dispatch to nowhere for now until we have clear interest on what protocols should be improved specifically and what problem this solves. Thank you Alyssa Yeah, thanks. Hopefully you can hear me Can someone confirm that you can hear me? Okay"
  },
  {
    "startTime": "01:18:03",
    "text": "comments of basically everybody who came before me about the dispatch question. I didn't see anything here that seemed ready to be dispatched to someplace inside the IETF. And just wanted to note as an author of 6973, the point of 6970, was, in fact, to just provide guidance, like it wasn't specifying any protocol and it was not meant to be mandatory and that was a conscious decision. Could you be a little bit loud? Alyssa? Sure What I was saying was that it was a conscious decision to make 6973 advisory and not mandatory because we thought that making it mandatory would just cause it to become a check-the-box exercise that nobody wouldn't pay attention to. And instead, I think if you look, there's actually like a good amount of evidence of how it has been used in certain cases There's also been discussion about updating it so that's something that you're interested in, definitely would be interested in talking about that because there's lots of things that have changed in the times since it was published, but it's meant to be advisory and guide and not protocol. And I think this it seems like the authors are after something different here So I think the, using that as the motivator doesn't really doesn't really work Great insight. Thank you Thank you. Colin Perkins. Hi Colin Perkins, IATF chair So we are always, of course, happy to discuss proposals for new work in the IRF, either in the particular research groups or directly come to myself or the IRSG to talk about that As a process issue, though, I do want remind the room that this group can dispatch things to the IRF IRF Noted, thank you Andrew Campbell Hi, Andrew Campbelling Yeah, as Alyssa just said, 6973 and in fact, also 8280 are both informational"
  },
  {
    "startTime": "01:20:03",
    "text": "so maybe the authors hadn't understood what the purpose of those was but it would be surprising if they were applied to all protocols given their informational So maybe that's a misunderstanding by the two authors here. On the dispatch question, noting what Colin just said, I was about to say, perhaps they are appropriate place to discuss the topic, should the esteemed chair of the IRF be minded to take that up afterwards Ted Hardy. Ted Hardy Ted Hardy, thanks very much. I think the basic problem here is there are three different things, yoke together and the fastest way to get progress here is probably to unyoke them So if you have small-scale things that relate to the work that's already going on in Cozay, unyoke them from the larger scale question and go to Cozay with it If you have large-scale questions of theta minimization and how it affects human rights, you can talk to Cullen or to the working group chairs for HRPC but those people can't do protocol work in the ITF, just like we can dispatch things to the IRF so I think you've got multiple different things kind of all put together into a vision here, but the actual work needs to be taken back out and sent to the right places, and there's no single dispatch for the whole. Some of it's just, frankly, out of scope for the ITF as a whole. So I just encourage you to go back and break this into the chunks of work that needs to get done and then ask again with the individual chunks separated out, and I think the answers will be much easier. Thank you [silence] Okay, so for this work and it seems currently it's not clear where it should go, no, I mean, in IET so in probably in IRT, and so, so in, probably in IRTF, and so"
  },
  {
    "startTime": "01:22:03",
    "text": "more specific pieces and go to the related related working groups to have more discussion and feedback there and then maybe come back to here and have more to here and have more and then maybe come back to here and have more specific feedback here you [silence] So next speaker Dragana [silence] [silence] [silence] [silence] [silence] [silence] [silence] You cannot control. I think I figured out do slide control, so. So maybe Jam can have this. You cannot. So, do you want to control the slide? I have it. I asked to do anything. I just start [silence] [silence] [silence] Good morning. I'm Dragan Mianovich. I'm going to talk about Webstock and the station to disable masking Next slide First, I'm going to explain what it is is Oh, sorry. Thank you So first I'm going to talk about what it is why it was added, and why I think it was added, and why I think we can disable it and how to do it So WebSocket enables bi-direction communication between the client and service It starts with a handshake that is using HTTP upgrades mechanism and after the handshake, the client and server can send messages. Sorry, one question Is it possible that the left side of the room also gets"
  },
  {
    "startTime": "01:24:03",
    "text": "No? No No? No? control. I don't have a way of control one Out of control Go to chairs. Yeah, please No luck And so, mask is, the web socket user frames to send the data that are sent by the application and all the data sent from the client to the server are masked with masking key that original payload is exhort with a masking key so to change how it looks on the wire And masking key is sent into inside the frame header so it's not for privacy it's just for changing how the packets look on the wire how the data looks on the wire. This adds extra bytes that needs to send for each frame, and also adds this additional processing It's not very expensive operation, but on the server side, where there is a lot of requests This is multiplied by a lot By masking was added. Next slide, please This was to protect against the attack that was describing this paper, and this picture is the original picture from the paper Sorry for the IP addresses that are there That was not intentional, that's from the paper paper um so uh to for attack to succeed uh special kind of proxies, transport caching proxies are needed that are routing the data according to the IP others, but caching the data according to the host name And the target of the attack is actually the server who is behind these kind of proxies"
  },
  {
    "startTime": "01:26:03",
    "text": "website with a web resource that is controlled by attacker, this web resource can open a web socket connection to the attacker.com and after that can send arbitrary messages to the attacker. It can also construct a message that looks like HTTP request This message will be routed to the attacker because the routing is under by IP address, and the attacker can receive with a message that looks like HTTP response which is WebSocket message, but it looks like very response. And in this case, this moment, proxy will cache this according to the host name, which is target.com and when the next users try to get resources from target.com, it will, it needs to be access using the insecure HTTP it will hit the cache and get resources out of the cache [silence] Next slide So, so, so masks was added to change how the data looks on the wire, so that client cannot construct the data that looks like HTTP request So Android encryption does the same thing, but it doesn't help in this case because the attacker controls the client and the server, so it has a key and can construct the message in the way that up to encrypt it looks like plain text HTTP can be potentially cached by the caching process. Next slide please. Do we still need masking? This study that I mentioned was done in 2011, and they found eight out of 47,000 pads that were affected with its proxies Also, it's worth mentioning that at that at that time,"
  },
  {
    "startTime": "01:28:03",
    "text": "It existed theoretically, but not on the internet. So this proxies didn't know how to deal with this mechanism. Now it's different Web sockets are present everywhere, so probably more of these proxies already learn how to deal with it upgrade mechanism also at that time a lot more traffic for plain text and now they are not So how useful this kind of catching proxies are at this moment is also the question, and how many of them are still left. Next slide slide If we look at a secure version of app sockets that are usually sent on the port 443, or we can look at any other port than port 8 which sends them usually gets the plain text HTTP that will be mean that this transparency proxy will listen to the connection that are usually encrypted and cache them as the plain text HTTP which is considering that this caching proxies were actually caching the clear text at HTTP, it's most probably they were all only listening to the port 18 It's unlikely they were listening to the other ports Next slide Also for this attack to succeed clients will need to access the website in the website before, target.com using insecurity HTTP, considering that there is less traffic that it's insecure now on the internet or less content that is insecure on the internet on the also it is unlikely that client will access with insecure HTTP content that is available using HTTPS, especially considering that there is a text"
  },
  {
    "startTime": "01:30:03",
    "text": "and efforts like HTTP first It is also less likely that the clients are going to use an insecure HTTP and hit Poison Cash. Next Therefore, I said I propose a website extension to disable masks This extension, it's using WebSocket extension mechanism that this already exists, so it's just adding the new token. This is then using the HTTP extension mechanism. This is then using the HTTP propose adding this only to secure connections because and excluding the port 80 because it's highly unlikely that these caching boxes are going to catch content on the on the on the port 443 Next slide. And when the extension is negotiated the frame sent from the client to the server will not have masking key, so there will be less four bytes less in the header, and payload will not be mask frames from the server to the client will stay on change Next slide So, I'm seeing in interest for this work and also the working group. I started this discussion on HDP's email mailing list because I thought that the audience is right but it doesn't belong to their chat so that's why I'm here Also, I have implementation of this and Mozilla is also having done a prototype for this draft. Thank you. Mark Nottingham Hi, Mark Nottingham. So just the trade-offs here I think something to keep in mind is that whilst, yes, most traffic is now encrypted"
  },
  {
    "startTime": "01:32:03",
    "text": "proxies that, you know, are interstaping proxies enterprises, for example And so they can still be poisoned by these techniques Also, I think one of the other I mentioned made was that most proxies have been upgraded. They've had time to, you know, learn about web WebSockets upgrade My experience in operations of networks is that proxies often are not upgraded very often. And I mean, you know, scale of decades sometimes. So you know, I agree that those factors do make it less likely that these attacks will succeed I think the thing to do is to wait against a the costs of the changes, you know, the cost of doing the encoding are, and as has been discussed on list, the cost is maybe not great For the dispatch question, we asked, we asked, bring it here because it's, as you said, it's not in our charge although it does interact with HTTP in the sense that it's an attack on HTTP from another protocol But if the dispatch is to take it to HTTP, I think we could talk to the ADEs, perhaps, and I don't know where the aides are, but talk about maybe doing it there, because it does seem like, work like this new working group. Unless we decide to spin up a, you know, Web Sockets maintenance group yay. That might be this sensible thing to do Haran. All right for the introduction And based on the scenario, you describe where clients need to access well, website using Azure HTTP to trigger points in cash and and considering the challenge posed by the website threat adoption of HTTP and security measures like HTS and a relevant question might be how can an organization ensure its website remains accessible"
  },
  {
    "startTime": "01:34:03",
    "text": "without compromising security, especially in environments where points to cache attack is concerned. And considering the prevalent use of HTTP and security, enhancement at HTS, by the way, this is my first time attending ITF and I've learned a lot. Thank you Very good, Ecker [silence] Hi, yeah, we should discuss us in the list a little bit. You know, I think this needs more motivation, frankly before we should be thinking of doing it That motivation would come in the form of two things, one of demonstrating there's substantial cost associated with the padding with the masking, given that you're already encrypting the data and having to do AES or cha-cha So I think, like, the measurements will be helpful The other four measures to be helpful would be demonstrating this is no longer an issue And, you know, I think you work for a company that has a browser, so you could take those measurements if you wanted You could replicate the work that was done, you know, back in 2011 But I think, you know, saying we don't think it's an issue, but we don't know, the way we got into the hole was we didn't think it was an issue and somebody checked And so, I think at minimum before you move of security, feature, which you actually verify there's no longer an issue I do want to make one small technical point, which is, that the fact that you think implementations are only stooping on AD does not necessarily help, because the attacker controls the website server, and therefore they can simply do, they can simply do the cash poisoning on 80 themselves with TLS As far as I can tell browsers, we'll do HGPS on 80 just fine so that doesn't actually help you [silence] Okay, David Skunazi David Skinazzi, Masking enthusiast. So first, plus one to Ecker, where I think would like to see more motivation on this, on why is masking bad"
  },
  {
    "startTime": "01:36:03",
    "text": "Mnott's point of sending the, I would recommend to send this to the WebSocket Maintenance Working Group which is currently called HTTP Biss The charter of HTTP BIS seems, from my read, to allow this so I think we should toss this can to the ADs to interpret the charter of weather webbis is maintained by HTTP Biss or not As WebTransport Chair, I don't think we should have a WebSocket maintenance group, because it's not like we're doing a lot of work in WebSocket, so I would recommend taking that to HTTP even if it might not, I would expect more motivation before I would make any progress in HTTP business Thank you Alessandra. Alessandro Gadini, Cloudflare I think an additional problem to the mid- box cash poisoning thing is that there are some middle boxes that actually try to actively look at the WebSocket data and sometimes even try to inject like close frames. And I suspect that because the sort of the negotiation mechanism for the extension would be end to end, and because these kind of proxies tend to not be updated as often as, you know, we would like as Mark was saying, I suspect a lot of those would probably break. How much that is a problem in practice is, I guess, to be seen but it would be good to try and maybe some experiments, if possible, before we decide to actually do this. And I also agree that it's with the other comments that it's not entirely clear what the benefit of not doing the masking is, but okay can you summarize it? Okay, so maybe more"
  },
  {
    "startTime": "01:38:03",
    "text": "to show the necessary work and also maybe go to HTTP base first to get more feedback. Okay, thank you. Next [silence] Ginger, please [silence] [silence] [silence] [silence] [silence] [silence] Okay, good morning everyone, this is Ling Jo from John Gunwanson Laboratory. Next slide, please This title is about the extended young data model for Deng and here is the outline of this presentation Let's start with the DDoS attack trends and problems Next slide, please Thank you Nowadays, the Deduza attacks happens more frequently, about 8 million didazate tax happens more frequently year of 2003 which has 31% increased year over year. Next slide, please And also, the deductible attack shows the feature of hypervolumetric the largest attack in 2023 as 200 million required per second, almost eight times larger than 2022s strike cut. To counter this kind of randomly occur, and large large scale, did us attack attack long-term purchase and the operation of large-scale data defense resources come at a very high cost. Next slide, please And also, the did also the DDoS attacks becomes more intelligent, more than half of the DDoS attacks in 2009-23 is more than two vectors. And also, this is a typical"
  },
  {
    "startTime": "01:40:03",
    "text": "disaster attack. The fossil flooding attack can suddenly expect to a high level for a shot duration, which is hard to detect and also hard to defense And also, there are many new types of attacks are emerging which are also challenges for the Dada's defense. Next slide, please So we want to use a specific example to illustrate why we need collaborative mitigation. In this case, if there is a fossil flooding attack is ongoing, and the attack is transferred from the network of the operation to the enterprise, for the enterprise it can detect the attacks in seconds, but because of the limited resources, it can mitigate the large-scale deducts attack So it need the help of the operator. Before the operator, although it has the enough resources but because of the sample-based, detect method, it can only detect a text in minutes, which is very slow. So we think the emperor, and the operator should exchange the information to do the collaborative mitigation Actually, we already have Dots Open Threat signaling to do the exchange of the information. The enterprise can initiate mitigation requests to the operator, and the operator can acknowledge that text in time, in minutes, and the device the mitigation strategies, and then give the response to the enterprise, and then the collaborative mitigation can start Next slide, please. But we use the dots and the some of the problems that the data more of the dots is not enough enough example, we want to expand the operators"
  },
  {
    "startTime": "01:42:03",
    "text": "The information, the visibility means all the useful information they can be the attack features or the network telemetry message or some intelligence. All those information will help the operator to do better mitigation strategy and the they can use the resources their scrubbing device, or BGBGB full specs were something others to do the mitigation. So we think in Dots, we need a structured attack feature data model. Next slide, please And this is the other case. If there is a slow HTTP attack is ongoing and the target needs the code communication, it can, there may be many servers that can offer the co-mitigation, but which one should the Zosklan choice and this is a problem. So we think, um, we think we needs to know the mitigation capabilities that the server can provide in advance in order to make the right decision In this case, in this case, because of the slow HDV attack is complex It cannot be mitigated by a rural with BGB flow spec. It must be mitigated by a scrubbing device. So in this case, the DOS client should choose the DotsR1 server one. So the client need to know the mitigation type capabilities in advance to do this choice So what we need is the mitigation capability in advance to do this choice so what we need is the mitigation capability data model including the strategy and the capacity. Next slide, please So here is our requirement about the extended data model. Here is the main function of the dots signaling, including the"
  },
  {
    "startTime": "01:44:03",
    "text": "requests in others, and in the three parts of it, when think there are, they need data model. Next slide, please And we also do some work about the implement Here is the topology diagram of our experiment We built and test by it to verify the mitigation effects of didast attacks, and also developed a simple DDoClan and a server. So in this, scenario is just the same as the probe one. And in this case, we add the attack features such as the attack type and the average packet lines or the duplicate message This kind of message can help the operator fans the attack attack seconds with matching with matching with flow data. Next slide, please And here is the experiment of the experiment with the experiment with the experiment with the time to start the communication was reduced by 43% And because of in this simulate, test bed, the simulated devices in have a data forwarding delay of three minutes. So hopefully in the real network, the communication start time can be ready from minimal to second level. Next slide slide So, this is our work we're applying doubt to our collaborative team did us mitigation framework, but found some important data models that were not yet defined So, because DDoS has concluded we want to find an approach working group to advance our ID. That's all, thank you Okay, thank you"
  },
  {
    "startTime": "01:46:03",
    "text": "Thank you Liu. Hi, Zhuo, all from Qinghua University. Thank you very much for your talk I'm very interested in this part. So, about 20 about maybe 20 years ago the uh the academic community has proposed a concept called a network capability, which is a side form of cryptography, side form of Routty English to express how the network should be forwarded And the network researchers, including myself, has published a lot of works on using this stuff to prevent the loss attacks But in 2018, I talked with a bunch of cloud providers like Cloudflare, like Akamai, and they what they said is like, okay, we should, the large providers they should only care about large things So I'm very happy to see that the, you know, from IETF that people are talking about, okay, only watching the large attacks is not enough to help the downstream customers So I'm looking forward how this can be unfolded in IETF in the industry Thank you very much. So your answer to the dispatch question? Sorry, what you see? suggestion? So what is your suggestion? My comments is like, I really like to say how this thing can be unfolded in IETF, because I like this feedback stuff, like from the downstream, from the victim to tell the abstract filters how they should handle their network traffic Yeah, thank you. Thank you. Thank you very much. Peng Liu [silence] Point from China Mobile about this topic is always important for both the operator and the enterprise network And for China Mobile, we also have some related products in both for the public network and public cloud I think that the purpose requires is reasonable in your slides"
  },
  {
    "startTime": "01:48:03",
    "text": "the work, including extending the related protocol, considering some pre-configure and as well as collaboration with mitigation strategy and routing strategy since those WJ is concluded is concluded, it is better to find somewhere to promote this work. Thank you Okay, so next to Paul Hoffman. To try to answer your actual question about dispatch, I believe that this should be a boff Dots concluded a year ago, had law of documents, had lots of interest, that's all being deployed. I don't think that we needed dots BIS yet. I don't think that much has been proposed that would do that. I would say possibly a one boff for this specific draft or for the top of what, you know, now that we know the dots is established, how do we deal with the data? that we're getting for it, would be sufficient and then hopefully an AD with the result of the box would be able to AD sponsor it or to say no we you know not AD sponsored we really need a working group, but I think a boff would be sufficient for this. Just I haven't seen much else posted dots in the last, I think it was like last April or whatever that it was concluded. Thank you, Paul you, Paul. Kent Kent Watson chair of NetMod Working Group. We have a standing agreement to publish any Yang modules that don't fall into any other existing working groups but we're not domain experts with dots so it'd be best if you had domain experts to look at it but for publishing the Yang module itself, we could do it Thank you Arnold Yes, Arnold today he brought come"
  },
  {
    "startTime": "01:50:03",
    "text": "dispatch perspective On the content, I really don't know how you are going to have the list of the mitigations from the search because I don't know they are normalized So if they are not normalized, I really don't know how it's going to work That's it [silence] Okay, so the summary of dispatch would be above and maybe not for this draft so maybe more related topics so you could get more feedback and during this IATF week Thank you Next Tim, are you ready? Hello, can you hear me? Yes please start. Well, hi, everybody Tim Bray here, not representing anybody [silence] There we go. So this work came out of the IATI JSON Path Working Group, which is just shut down I was co-chair, and we shipped two RFCs, one for IRA which is a small interoperable regas dialect, should work the same across popular libraries and Jason Pass, which has been around for ages, and in both cases, we insisted that the text be unicode and utf a and then had to consider whether that meant all of Unicode And that question turned out to be harder to answer than we thought and thus these drafts next slide, please [silence] So most protocols and structures have text and Unicode is good and then the question arises, do you want to use all the characters? And the answer is no, you don't The term code point's going to come up through this discussion and those are just the integers that are used to identify Unicode characters, and you can see the number of them. There's a lot of them"
  },
  {
    "startTime": "01:52:03",
    "text": "what we call problematic. Next slide, please [silence] So this is the worst thing that can happen to you And so that is perfectly legal JSON per RFC 80259 So if you write a protocol and just say, well, we accept our input data in JSON, somebody could throw this at you You can read what those things are, but in the value of the example field, there is nothing that can usefully be shown to a human and something that are going to cause real parsing problems [silence] What's going to happen is unpredictable. Some implementations of JSON parsers will return you a helpful error others will crash, others will actually generate ill-formed UTF8. Others will read the ill-formed stuff with a little Unicode replacement character, which is the little diamond-shaped thing with the broken. Java will replace it with a question mark it's a mess so that's because these characters are all problematic. Let us walk through and sort them into three baskets. Next slide, please So the first two are control codes. The old people in the room will remember what these are. These go back into Asky days, and they are the first, they're the first starting at 0 and 128 and they were used in sort of disgusting ways in ISO 88 59 and even worse iso 2022 But you can't wholesale condemn them because they include New Line, Carriage, Return, and Tab, which we refer to useful control codes, and the rest as legacy control codes but the ones here like zero null and some weird format control thing are no longer useful Next slide Then that DEAD there is a surrogate. Surrogates are an artifact of UTF16, which is an artifact of a period when people believed Unicode could be expressed in 60"
  },
  {
    "startTime": "01:54:03",
    "text": "And UTF16 provides these surrogates to allow you to express high value characters by pairs of surrogates, and they're only for use in UTF 16, and UTF 16 is normally not sent over the wire So if you see these, almost certainly something has broken. This should never happen, but it's does, and one of the reasons it does is because in Java, the native char data type is actually a UTF 16 code point, and if you prefix in a range by taking the first 10 characters, it's real easy to end up with one of these things. So these are really problems They break in all sorts of ways and just should never appear. Next slide, please Then there are some other code points that are not characters, and they are called non-characters The history is complicated and boring, but Unicodes specifically that don't use these except internal applications. They don't define what they mean by internal applications, but I'm pretty sure they mean not over the internet And they can't be displayed. They have no use So what we want to do is offer three subsets that in part are in whole avoid these problematic characters, and thus aren't safer and better So the first one, next slide, please is called Unicode Scalers And this is all the code points that aren't surrogates and it's actually pretty widely used, not just in Seabor and IJson, but over in the W3C, you know, the White Working Group and things like that, they use Unicode Scalers quite a lot and they're much better than all the Unicode points because they exclude the surrogates, which are the most problematic but they include all the control codes and non-characters and so on Having said that, you know, you may end up having to have to use this if you are wanting to handle seabor messages Next slide, please Then, in 1998, XML picked this set of characters to bless"
  },
  {
    "startTime": "01:56:03",
    "text": "controls were useful, but not the rest And it gets all the surrogates, it does not get all the non-characterials non-characteries And so, you know, XML may not be popular these days, but it's been around a long time and been used for a whole lot of text. And people just have not had problems that I'm aware of with character repertoires And if you're in something like Yang, it is required to exist in both XM and JSON you're probably stuck with this repertoire next slide please And then this is a new subset we invented for the purpose of this draft, and this is all the non-problematic code points So it removes everything, and it's got AB&A The ABNF here is taken straight out of the draft The idea is that should this draft be become referenceable, it would be really easy for somebody writing another draft to specify what subsist they want to take up. So next slide, please So this is not the first thing that IATF has ever thought about this is not the first time IATF has thought about code point subset so there's IDNA out there, and that's about domain names and if your text field is a domain name, we're not adding any value with Unicharis, just, you know, use IDNA Next slide, please Then there's Pracey So there's nothing wrong with Pracey, but it doesn't see to get much visibility, and the weird thing is that in, I've been involved in a lot of the IATN discussions around IATF over the past years and I'd never heard of it. So I'm not even sure how that could happen and then in all the discussion we had with hundreds of emails on this particular draft nobody brought it up so it not much, I'm not sure why I've looked at it. I don't see anything wrong with it but it's pretty big and complicated. Maybe people are just saying, oh, I just don't need all that stuff. I'm not sure"
  },
  {
    "startTime": "01:58:03",
    "text": "that you could use Prissy and Unicharis together just fine Next and the last slide So after we were pretty well finished with the JSON path work, we decided to write a draft that cover what we'd learned, and REDs AEDs told us to take it to those two mailing lists, and we had really a good discussion with some really passionate and deep Unicode people and went through seven drafts and it's way, way, way, way better than what we came up with in August. So, big thanks to all those people who pitched in This has received, you know, as much as discussion as some working groups give drafts of this size. It's already been referenced out there in a couple of places. I don't know, I believe that having this around to reference would be handy to creators of new drafts that have to handle text fields. They certainly would have been handled for us, handy for us in Jason Paths And I think it would be useful to have this exist as a stand track document in the ITF So thank you, and we look forward to hearing suggestions just to how that might be achieved [silence] So, I'm co-author, Tim was remote, I'm local, so I figured I would be the one standing here. Okay thanks. John Clenson [silence] [silence] Hi. Tim, Mike biggest concern is that if we and up with a large number of different profiles and ways of talking about unique characters, and limits on them, we basically end up confusing everybody and end up a lot of incompatibility and interoperability problems I see your problematic characters list, but I also see"
  },
  {
    "startTime": "02:00:03",
    "text": "are okay, which are probably problematic. And I understand your comment about precede that be widely publicized, but it's not clear to me to making yet another competitive document would be much more widely publicized or much more widely used So the question is, can start with Tracy? and if necessary, create a new profile, or just what the deficiencies are there, and if not why not? So your advice? on dispatching this, John? My advice on dispatching this, John? My advice on dispatching this is that I would like to hear from the authors why this can't be built on a precede foundation and it cannot be built on a precinct foundation then we should be discussing boss for working groups if it requires modification for Precy, we may need to start that working group up again, but I don't see this as an independent effort. Okay, thank you Pete Pete Resnick, my dispatch recommendation is ditch this document The reason Pracey exists is for folks like you to read through the record requirements and register a profile do that put what you have in this document into a Pracey profile. Explain why it needs to be different than the existing Pracey profiles. But if you need one, make one But we don't need a working group. Pracey gives you all of the instruction for how to build this Build one. Implementers don't need to look at all the Prasee documents you do. Implementers get to look at the profile and use it. Do that Pete, so I follow-up question on that"
  },
  {
    "startTime": "02:02:03",
    "text": "because it's our belief that Pracey profile have not been well used and are barely known would that change your mind or would you say you know, like you say, ditch this and you know as we still won't have any focus on Tracy, and therefore other groups might do things without knowing, would you, you know, how? do we get Pracey profiles to be better? known? If we've ditched this. This as as an RFC, will have some focus Pracey profiles won't. I think it's in particular, go the JSON community, which is what this is aimed at and say, one of them, yeah, right, here's the document that describes which things to use Pracey profile such and so I mean, you're saying Pracey profiles don't have visibility, therefore we should publish in this form that has higher visibility Give Pracey profiles visibility. Create one point to it. Say, this is what we need to do announce it on lots of mailing lists okay thank you All right, thank you. Kirsten [silence] Thank you. I agree with Pete's dispatch verdict but not for the same reason A document like this should give advice I think this gives really bad advice It's really useful in information about the history of things so that's a good read for people who really care about this subject and with a seventh or eighth review it no longer contains a lot of incorrect statements. So that already makes it a useful document in some way. But I think it's really should be useful And the episode that Tim related to was in Jason Parth, we had this"
  },
  {
    "startTime": "02:04:03",
    "text": "language and jason accepts toxic waste. Toxic waste is something that is not Unicode, but something that adjacent parser is going to ingest and then get terrible stomach cake And then Tim even had an example where one of his systems broke when that happened. So that's one thing Then there is this weird term problematic character and every character is problematic is problematic, and lowercase A is problematic What you need to understand is what is your application and what do you want to do with these characters and so on So I think we really need a document that gives useful advice to people who want to define new protocol If you want to use an old protocol that already tells you how to do that So SMTP tells you exactly how to operate in this space. We don't need a document for that but you need a document for new implementers And I think we should find some way to have such a document I thought I might just write it quietly somewhere but now that this document is out there as well, it's going to be the next subject in this meeting, so I'm going to shut up now Okay, thank you. Harold Haral Alastram Unicode offers many opportunities to shoot yourself in the foot This document well, I like the presentation better than the document because the document seems to say that as long as you're only handling code points and don't care what the code points mean you can get away with only doing this, etc of rules"
  },
  {
    "startTime": "02:06:03",
    "text": "acknowledge the fact that if you tried to assign any kind of meaning to those code points you get the a world of other troubles I mean, IDNA 2008 Presees, all the string prep, name prep, we've been in this wasteland of horrors for many years And with a significant applicability statement statement and a forward point to saying if you try to do more than just slip around the camera, trap around the code points you want to look at these other places. This could be a use document But I'm not sure where we should take it to get to that useful document. That was my next question [silence] Ory Steele. All right Orsteel, incoming Art AD The, back to the disc patch question, I heard folks saying we will this was a Pracey profile, Precy is a working group that's not currently active Has there been, is there a giant pool of work? that needs more Pracey work in the chat? I can hear folks saying they looked at Pracey and they decided not to use it in recent documents for various reasons. So I'm bit concerned that we're sort of pinning Pracey on this while we can also see evidence that folks don't want to use Pracey To the dispatch question, regarding this, it seems like it's headed either for an AD sponsor or for a new Pracey working group with a whole bunch of other challenges associated with that process And I don't like either of those options personally. Thanks [silence]"
  },
  {
    "startTime": "02:08:03",
    "text": "was closed, so I didn't want to do jump up. Pete Resnick no, the nice thing about Precy is that it has this whole framework It becomes effectively like an Ianna registration We have this framework where you can register one of these profiles If these guys go follow it and do it, they might need some advice from the internationalization list in order to get it right But for the most part, it's follow the directions in the document and create the profile. So no working group needed Do you want to summarize that? Okay, so for this draft, presentation is a good brief and provide useful advice, at least a good starting point And for the work, so people maybe more prefer to precise, although it's not popular yet, so and the some suggestions to work more on the prices and make it more visible and yeah. Good, thank you. Thank you [silence] [silence] [silence] Thank you [silence] [silence] Wow [silence] No, you, yeah estimated closeness stuff okay Now, this is a really unfortunate estimated Okay, thank you. Now, this is a really unfortunate slot because I had to pick on this other draft that you"
  },
  {
    "startTime": "02:10:03",
    "text": "So I apologize for the A while ago in 2019 I wrote a document which I think was useful at the time because I could point protocol developers to it and explain these are kind of the choices you're going to have when you are using Unicode And this has been around for a while, and Tim and Paul's draft kind of prompt me to dust this off a bit. Next slide, please So obviously, this is not happening in a vacuum We had this draft in 1936 which was called an RFC at the time, RFC 20, which we actually turned up into a IATF standard some decades later, which is ASC And Esky was an externally was an externally defined document that we imported and started to use a lot in the Internet, I think we can say it's built on ASCII and well an interesting document here for instance is RFC4, which is the telnet protocol specification some of you may remember telnet and that defined a network virtue charmnet. And that's pretty much what has, uh, um, added the specification to asky as a foundational document, how we actually use it in the IT and then 15 years later, it became clear that ASC is not enough We had to do something about the cover more characters, and we got an ITF policy on character sets and languages, and Harald is one of the"
  },
  {
    "startTime": "02:12:03",
    "text": "is this is BZP 18, and nobody has since questioned BCP 18. I think we all agree that UTF is the way we are going to interchange a document and the underlying Unicode is going to be our character model And actually, five years later, we got another internet standards which defined YouTube which defined UTF 8 more precisely. This came as a sequence of several documents until it was completed And finally, in March 2008 John, who has also been on the microphone already, co-authored document that essentially replaced NVT the old network virtual terminal, with one that is based on unique code and answer a few questions that came up when you do this So this is essentially the platform on which we stand and the question is is there anything left open here? Next slide The problem really is, or not the problem, the problem, the opportunity the nice thing, is that we don't need a network virtual terminal very much anymore So we're not using Telnet that much that much We are using SSH, but today we are defining protocols that have their own structure. We have XML, we have JSON we have C ball, we have whatever And these already provide this structure that we use to have to derive from ASC. And ASCII, you have something called record separators and unit separators. I don't know if you remember those. We actually used them in JSON sequence but normally the structure is coming from something else like XMAR JSON, CBOI representation format. So the protocol designers today use XML"
  },
  {
    "startTime": "02:14:03",
    "text": "technology and then have to decide what kind of Unicode strings go into these little fields what goes into an attribute, what goes into an element and so on. And, well, at the end of, at the start of the previous decade, I was helping in designing a protocol, and ran into the problem, we needed some more text So we actually referenced 5198 but it wasn't that useful I mean, it still works, but it was a compromise. And as some people have said, unique code is more complex than ASCi was. So protocol designers really need help. Next slide So, given the this came up again in the context of another development that I'm going into called Coswit I started writing a document and trying to get feedback on the art mailing list with some excurs to internationalization directorate and also got lots of good feedback and learned a lot beautiful the approach the approach here is to have a relatively simple menu of choices that a protocol design can make Unfortunately, these need options because applications are different But this is about eight pages of documents And then I have some more 10 pages of appendices about terminology, which is really important in this way about the history legacy issues and how we got that toxic waste into our system sometimes Unicode Normalization, which relevant to many people who think it isn't relevant to them and finally relationship to 51, 90 next slide so the objective for this document was supposed to be used for protocol developers"
  },
  {
    "startTime": "02:16:03",
    "text": "can read and don't need an afternoon for that. But also maybe as a reference that the new specific can point to and say, we are using this particular subset of unique Of course, this subject could be expanded. A lot should become long document, then it would become less use for developers. So really, the guide aspect is quite useful as it is. The reference aspect, is. The reference aspect might require a downref in a document that uses this or might require some standardization. So I don't have a strong opinion on this, but I think that would be used to have as a reference mechanism I'm not thinking so much about formal mechanisms like presi profile and so on, but simply as something that can be pointed to and, for instance, the difference between one dimension and two-dimensional is pretty important in many other cases so this is something that this document can be pointed to So I could just continue, develop it in quiet on my own or we could set up something that looks at this in a more consensus-oriented way I'm not proposing anything specific, but given the previously discussed document, I would like to hear you Okay does anyone have any opinions on dispatching this? Karsten, what in the absence of a queue, what would be your preference about how you would like to see us dispatch this? Well, I thought I got pretty good feedback on art So there is a certain kind of consensus that is wavering through the room, but it's not captured. And I'm mainly interested in getting in"
  },
  {
    "startTime": "02:18:03",
    "text": "people have looked at this, and it kind of seems to be a good choice, such of choices. Good, well ask for a cue and one shall appear. Go ahead, Colin I'm not an expert in this space, Colin Jennings. I've seen an incredible amount of time and energy spent into these problems, and my read of your document car is that it comes to slightly different conclusions on some of the things than some of the other mini working groups that have looked at this area deeply. And having yet another set of conflicting advice on this stuff will probably make the situation worse than better. So I think if we do something on this, we need to do it in a you know, fairly serious working group type way. This is not something that an AD can just, you know, sponsor or that we can just do slow in some area like that. We'd need to get, we need to be very serious about it and be willing to deprecate some, you know, say some of the stuff we did in the past was wrong and we're going to do this instead. Sorry don't agree with that part of your statement because I mean, we have legacy and we will always have this legacy Of course. We will still have Jason with all that toxic waste in it we are not going to change this. This is for new designs, useful points that people can congregate I understand, but it's advice for new design might be a little bit different than what some of our previous published documents would say about new design, and that's why I think this will be complicated Thank you. John Clenson [silence] First of all, I agree with Colin about the complicated part Our general internationalization work is in a bit of disarray a situation which has been discussed at length with some of the relevant ADs, and we may be on track to getting some forward progress, which we have, in my opinion, been less last couple of years"
  },
  {
    "startTime": "02:20:03",
    "text": "Carson dismissed as NVT only that was not the intent, but that document at this point is clearly showing its age and needs some rethinking And I wish Mike Petlipsky were here because he was able to get far more articulate on some of these things than I can as those of you who knew him or knew of him would know But I think the solution for this problem this document from a dispatching standpoint is to look at the existing work, talk much more clearly than the drafts do now about how it relates to existing work integrate it with whatever the deuce we're doing with internationalization more generally and see if it can become part of the picture rather than yet another conflicting picture even if only partially conflicting Because I'm very, very worried about our ending up and the situation where we've got multiple specs, which are not the same, although they overlap give people too much of a choice about where they should go and what they should look at without understanding choices and that's a recipe for interoperability problems as I said before. I'm not opposed to this draft, but I think it needs to be part of a larger picture Thanks Thank you, Ted Hardy Ted Hardy, I believe again, you have two different things you're trying to do, and that the answer may be different from the two different things. From the guide perspective, I don't think that needs to be a standards track RFC and in fact, it might be a better guide if it were not an RFC at all but one where it could iterate more rapidly as experience with trying to use it for different protocols situations was learned. So I think for the guide side I would suggest to take it out of the RFC stream entirely"
  },
  {
    "startTime": "02:22:03",
    "text": "reference as a new specification that is not itself also something? that you could write up as a Precy profile? And if there's an answer to that, then I think we go back to what we just said. If there's a reference that people need that can't be a Pracey profile, maybe we need to fix Pracey and then make that work If we find that, you know, we absolutely can't do that and we need a different thing, then I think this would need a working group. But I think if you split these into two pieces again, the answer sort of fall out naturally. Thank you. Thank you Harold. How to all this, John again? have some of the same objections to this draft as to the other drafts meaning that the amount of trouble you can get into is much larger than the draft seems to indicate But comparing this one to the other draft, [silence] to come to... They are frankly incompatible. Publishing both would be a disaster So, if we want to specify something that says here a reasonably sane set of unico to use in these particular situations we need to get one. We can't dispatch both [silence] Okay, that's the end of the queue Can you summarize that? Try. Yep, so, and then this work is, Gerald are a lot of existing work, and so be careful about this overlap with existing work. And this is, and this is also complicated new design So probably for this work and the first"
  },
  {
    "startTime": "02:24:03",
    "text": "and figure out what is the new specs will be needed and then start from there So more feedback, more discussions So the venue would be the arch mailing list Or I-18 in Yeah, this is not really an internationalization document. I mean, it's trying to be not too wrong on internationalization, but it really is about what you call these Yeah. Okay, thank you Thank you Can I just interject? Because Carson just said one thing that I think is unclear. It was taking to the art mailing list. We have two mailing lists as we both, as both Carson and Tim and I have pointed out There's the art mailing list, and there's the art mailing list, and there's the I 18N internationalization directorate mailing list so if it's going to be dispatched to um mailing list, it would be good to know which one to dispatch it to. Thanks yeah i think kirsten said that since it's more of a protocol matter than internationalization per se, it should be dispatched to art [silence] Okay, we're at the end of the agenda Thank you all for your participation and have a good week We're about 35 minutes early. This is great Okay, so the summary of the dispatch outcomes will be sent after session in the meeting list, the all dispatch meeting list Thank you [silence] Hi, very quickly. So, Lars Egert, AD, for this session, for this boff. We would also like to hear feedback on how this went for you as a participant. Do you like this all dispatch model? of talking about potentially broad new work? in this broad new group, or would you prefer something else? So please send that feedback to the ISG. Thank you"
  },
  {
    "startTime": "02:26:03",
    "text": "[silence] I think that looked pretty well Time management is special. Yeah, you see, the exact Yeah Perfect. Yeah timer on the screen, I think it really helps give this [silence] [silence] [silence] [silence] Yeah, but I do take some [silence] It sounds great Oh, yeah, I don't know some, on, maybe, some limited number of slides Yeah, maybe some limited number of slides. Yeah, there's some there was a style thing different people have different styles for putting together slides. Yes, yeah style that they used was a little crime to the have. It's pretty hard to say that you have to, you have to, you know, format your slides. Yeah, but gave them suggestions But we do give them suggestions you know, and also IR and what if we have maybe, maybe talk with Holly what if we have, you know, maybe talk with Holly. Well, you know, I think, kind of we would handle this case. It's fine, you know, I think kind of we would handle this case. It's fine, we can't really formally dispatch dispatch You didn't suggest that you can't talk about you. Yes I think that was an okay out [silence] Thank you very [silence] [silence] [silence] [silence]"
  },
  {
    "startTime": "02:28:03",
    "text": "Martin. But, I mean, honestly, the fact that we were able to get the discussions in 15 minutes each, I mean, that's really what thing. That's really the thing into way too much into it useful, but the I mean, I think people are respectful with people respectful of people's time by having all of the presentations Jim and Chu Ping, are you aware that your mic is hot? [silence] Are you aware that mic is hot? [silence] [silence] [silence] [silence] [silence] [silence] [silence] and so I should that look at it [silence] [silence]"
  }
]
