[
  {
    "startTime": "00:00:07",
    "text": "excellent hi everyone uh let's get started no that's fine there's nobody here okay perfect good okay uh let's quickly wave at the remote participants they can all see us that's excellent wave over there so roman can you see us roman folks are perfect i i can see you it's not some kind of deep speak good good okay okay welcome everyone um great to see you um in person finally um lots of uh familiar faces some new faces too which is great and um hopefully this is just a beginning of uh better days hopefully more more face-to-face meetings so welcome to that oauth working group and let's get going uh this is not not well so um if you're not familiar with this especially for those new faces here"
  },
  {
    "startTime": "00:02:02",
    "text": "please make sure to get familiar with this this governs everything that we do at the ietf and it's important that you may know this stuff right so take your time and and spend some time looking at this um again because this is our first time doing um kind of a hybrid model a type of um um conference so if you are in person um make sure that use you use a meet echo um and this is the on-site tool please so um and um you will use that to join the queue even if you are in person here um and you keep the audio and video obvious obviously off and for remote participants again you can make sure that audio and video are off unless you wanna present or um or say something and we highly encourage you that to you to use a a headset so now we have um a few sessions uh so this this our first session for this week a another the other official session is on thursday at the same time we have also two um side meetings um one on tuesday tomorrow at two and one on wednesday at six pm um everyone is welcome to attend um again it's it's public meetings so anyone um can attend those too a quick work group updates first um rfc 9207 was published uh"
  },
  {
    "startTime": "00:04:00",
    "text": "congratulations to danielle um and um i think creston i don't think he's here right congratulations uh guys and thanks for everyone who contributed to that document and reviewed and provide feedback so awesome work thank you a rfc edit queue we have a one jot response for or tokens introspection um i think we're just waiting for this to go through we can't do much about this a worker consensus we have um the first one is a christina's and mike's document is a simple document we're progressed very very well very quickly so we have consensus on this one and we will make progress on this one soon the security bcp has been languishing for a long time and you can blame the chairs for this so we started doing more work around this so we did review it myself and harnesses in the process of doing it is halfway through this um do you wanna okay we have to oh so yeah now i'm filled uh so harness is halfway through this document but hopefully we will make progress on this one soon eh on the right document we kind of drop the ball in this one and we will pick it up pretty soon so um we will start working on this one too thanks daniel for doing an update of the document following the previews that we did so the next step is the shepherd write up the ipr"
  },
  {
    "startTime": "00:06:02",
    "text": "i think so if i correctly memorize it for the raw document yeah no it was thorsten you're right okay not daniel okay that's fine but it's the same status thanks to austin i don't know if he's online i didn't see him okay um so that's the update that we have any any questions any comments about this okay hey so here is our agenda beside the chairs update um mike uh sorry brian will start oh go ahead um mike so all the last three this is mike jones from microsoft all the last three documents are awaiting shepard reviews yes okay so um brian will start with uh d-pop um after that um i'll be talking about three direction attacks and aaron will will finish with the oauth 2.1 so that's for today and for thursday we have a device flow um and peter we'll talk about this um victoria will talk about step up authentication uh um brian will be in supporting role and daniel will be talking about libraries there on on thursday so yeah i have lots of interesting stuff to to to discuss um any questions or comments suggestions personal attacks on the chairs okay get brian"
  },
  {
    "startTime": "00:08:00",
    "text": "okay um are you gonna have i don't know how to do that hold on i don't know how to do this either do you want to advance or i think you have to choose the fan stuff yeah yeah like he wanted to control it from his okay then let's let's let's just yeah just just let me know and progress it all right very cool yep all right uh welcome nice to see everybody in person again ah here we go this is weird this is really weird uh so bear with me uh so depop oauth2 demonstrating proof of possession at the application layer uh doing a picture up here for iatf this is on the other side of austria though so close but not quite uh so sorry it is it is it just what if i speak a little louder okay i will try to speak louder all right next slide man this is awkward all right little expectation setting here i got 45 minutes hopefully not going to use it all got a little jet lag so again bear with me um i'm going to do a full overview of the depop protocol um trying to note particular places explicitly where changes have occurred recently i know some of you have seen this before so i apologize for any repetition but i find it a lot easier to talk about things in context of the overall change and then i'll wrap things up next slide please so depop the objectives of depop really quickly and in general providing a pragmatic application level proof of possession mechanism for oauth 2 access tokens and refresh tokens when they're issued to public clients the pragmatic was a little bit qualified prayer it is still pretty pragmatic but it's maybe not as simple as it once was and it's not terribly efficient because it uses public key cryptography on basically every request but that is uh sort of the price of admission and where we've ended up with things but i wanted to point that out and just head it off right at the beginning uh next"
  },
  {
    "startTime": "00:10:00",
    "text": "so it has been a while uh last time we were all together was ietf 106 in singapore um lots happened since that time we presented i believe was draft three of uh defect individual draft sometime later uh around the beginning of the following year got a call for adoption actually got it adopted we've had several drafts since uh really this was just an opportunity to to say hello again to everyone in person and throw another photo up here of a nice ietf city uh it's nice to be back this is weird but it's really nice to be back in front of everyone and see some faces inside and out the meetings but since that time give me the next slide we've published a few things so into the overview of d-pop in general d-pop is this proof-of-possession mechanism it's achieved by sending something we call a d-pop proof jwt is sent as an http header what this does is it demonstrates a reasonable level of proof of possession in the context of the given http request this header is sent the same way with mostly the same syntax and semantics on both requests to the token endpoint at the authorization server and on protected resource requests the as uses it to bind tokens that it issues to the the public key contained in the proof and the rs uses the proof um to verify bound tokens um just an example at the bottom there it's just a d-pop header and a jot and a fairly simple illustration of the token request includes the proof bound tokens are issued following that the bound tokens are used for resource access sent in conjunction with the proof and assuming that all validates access is granted next slide please sorry i'm nervous this is strange the general anatomy of a deep prop proof here's the jot exploded they're explicitly typed because that's one of"
  },
  {
    "startTime": "00:12:01",
    "text": "the best practices these days uh d-pop plus jot using that structured um structured suffix syntax um we the ad part of the normal job there we only it only supports uh asymmetric signatures part of just the way that it works because these keys are sort of established almost like on a trust on first use basis you present the key and proof that you control the associated private key um so it only really works with asymmetric signatures the actual key itself has included the jwk header um and this is the key both the signature over this jot will verify from and that including the content of the jaw and the request is what proves possession of the associated private key um we've got a jti just for a unique identifier for following replay some minimal information about the http request this is what binds it to the request it's not a an integrity mechanism over the whole request or anything like that it's a it's a minimal amount of http information that just associates with this proof with that particular request or a subset of information about that request there's an iat an issue that time and these proofs are then only accepted for a reasonable window around the iit when receiving it in oh three draft of three we introduced a hash of the access token that's included there only on protected resource access in draft 04 we introduced the server provided nonce so if the server challenges with the nonce the client has to follow up by including the nonce and a claim in the proof um what did i miss something i think we got it all there next slide please so an access token request when actually uh requesting tokens it's a normal request of the token endpoint at the authorization server but a depop proof header is included in the request shown here in purple it's just a jot as a header um you'll see otherwise this is a normal"
  },
  {
    "startTime": "00:14:01",
    "text": "authorization code um request next i don't know what to do with my hands the access token response looks familiar um access token is issued normal stuff here refresh token but the response types indicates that this access token has been depop bound by the inclusion of the depop value and header for public clients clients that don't have credentials associated with this authorization server the refresh token is also bound to the uh the public key and the depop proof next slide uh just following up with that it looks the same a refresh token request is the same kind of thing requested the token endpoint normal refresh token stuff but the default proof um header is also included here the result of this would be since this is a public client there's no other credentials this refresh token was bound to that so on checking this the authorization server makes sure that the key in here matches the key to which this was bound and then also subsequently issues new access tokens that are that are in turn bound to this request or bound to the public key in this uh request next and what an actual depop bound access token looks like either for job-based access tokens or tokens uh that are introspected it's just the cnf claim um and in turn that includes uh a sha-256 hash of the jwk thumb print of the public key that was in the proof so basically it's binding this token to that public key through a hash of the public key included in the token using the cnf the confirmation clam syntax uh with a jkt for json webkey thumbprint i think was a little short for tried to keep it's relatively compact next resource requests no surprise here they look really fun similar as a normal request it includes the access token"
  },
  {
    "startTime": "00:16:02",
    "text": "with d-pop as the scheme and also includes d-pop uh proof in the in the header and what this allows is this token then is bound to the public key in here and part of the validation includes then validating the proof signature accepted and then in turn validating that the hash associate of the public key in the access token matches up to the hash in the in um excuse me matches up to the public key in the proof itself that's a bad explanation but i hope you get the idea next so for protected resource access we have a 401 with the wa authenticate challenge to indicate that depop is needed in the case that there's a protected resource request without any token at all again it can respond with a 401 and depop is the scheme and here it can also indicate the algorithms it accepts for the proof itself so these are signature algorithms that are acceptable in the depop proof so the types of algorithms that it can sign and for um a request this is very similar to the bearer scheme but a little bit information additional information is necessary for like the signing algorithms a response to a protected resource request with an invalid token for whatever reason in this case it was invalid because the confirmation didn't match the public key in the in the proof so again it's just a 401 uh the dub dub there's something missing and that's how that got in the other spot copy paste anyway there would be a uh debuff here what is the scheme and then the normal error parameters invalid token and their description just saying what's wrong as well as the out can be specified here as well um and this is the abs in the the challenge are the way that the resource server is able to signal what proof signing"
  },
  {
    "startTime": "00:18:00",
    "text": "algorithms it it accepts so that it can be a little bit more dynamic with the client next slide um so in draft 4 we added the option for the server to provide a nonce um that will the option for a server provided nonce to be included in the deprop proof while drafts five and six hopefully refine and clarify this in a way that makes it really comprehensible and implementable some examples of how this works is the authorization server errors provides uh this error code use depop nonce and the nonce itself is always included in a header of depop nods so basically this is just saying uh try again and include this nonce in that element of the proof when you send it it's a little bit different on a protected resource challenge because we have the www authenticate um in play there and in that case it's uh the same error code but delivered as a parameter on wwe authenticate and the nonce though is again delivered in the header so no matter where it is the nonce comes back as a loan header and that's useful particularly in the case that you can provide a new nonce even for successful requests which just tells the client on the next one use this nonce this allows a more efficient means of the server providing new nonces without constant back and forth the challenges that just looks like this whatever it is it's an okay but a new nonce is provided and so in the subsequent request the client would use that nonsense proof rather than whatever the last one it had was so brian this is roman i'm sorry to kind of cut in from the uh from the jabber when you it's really helpful for you to point to the screen but you're not by the microphone so some folks are having a hard time to hear so either reach over if you could or pull the mic out so you can travel i was afraid you were going to say that because i realized what i was doing right as you started talking will do especially since we're almost done thanks for the tip"
  },
  {
    "startTime": "00:20:01",
    "text": "next slide uh some metadata uh the authorization server so we talked a little bit about how the resource server can signal the alg proof algorithms that it supports the authorization server can provide the algorithms it supports through the use of metadata it's just one new uh metadata um parameter depop signing out value supported and this just signals support for depop in general at the as uh by its presence as well as the particular algorithms that it supports it's a array of strings in drafts five and six we added uh client registration metadata both for client registration and for the general sort of model of client metadata is useful as a as a way of sort of providing a common data model for clients in general we had a depop bound access tokens and it's just a boolean value that indicates whether this client will always use depop or not when requesting tokens from the authorization server this felt like a fairly common switch that might be needed to enforce particular policy around one client so say this client is always going to use depop if it doesn't something's wrong and reject it next slide please thank you refund so binding an authorization code to a depop key in draft05 which is relatively recent the optional depop jkt authorization request parameter was added this is a parameter on the authorization request it's the sha 256 jbuk thumbprint of the proof of possession key of the depop key this comes in the authorization request the as binds the authorization code it issues as a result of that request after the whole dance to that thumb print and then on code rejection it checks that thumb print against the depop proof provided in the token request otherwise rejects it this enables a more end-to-end binding of the whole authorization flow to a"
  },
  {
    "startTime": "00:22:01",
    "text": "particular depop key that was lacking in prior versions it can be used in conjunction with pixi with no changes required to pixi and when using par you have that initial pushed authorization request that provides the opportunity to bind early so when you're using power you can bind either from the depop proof presented in the par request itself the normal header presented in the header or in the request or can also bind using the same parameter depop jkt if they're both provided they need to be the same uh quick example of what that looks like no scary surprise but it's just an additional header and a get request that would be sent through the browser includes the thumbprint of the key by that parameter name next slide please so looking ahead next steps ietf 114 is scheduled to be in philadelphia uh we'll see if that happens or not but a couple of things that are kind of open right now that i'm aware of one is whether or not the application depop jkt media type registration is really necessary this is the pattern that's been followed by a number of of other documents but as i look at it it feels like a bit overkill to actually go out and register a whole new media type for this one type of jot that's only ever going to be sent in an http header so there's some words in there that kind of ask that question no one's actually answered them registering it's not a big deal we can put it in there but it just seems really excessive so i don't know if some higher ups chairs or ads have some advice along those lines i would certainly be interested in hearing it we also have six authors on the document which according to the rfc styled guide is considered excessive and gritty's down here um helping me with that statement so those are two sort of administrative problems that that i think need to be fixed for sure but they are basically just"
  },
  {
    "startTime": "00:24:00",
    "text": "minor administrative issues so that in terms of the protocol definition and functionality itself i feel like we're approaching a place where working group last call is a reasonable thing to start considering um so i'll put that out there are we closing in on working working group last call and yes that is philadelphia and gritty's from philadelphia i thought roman was trying to join the um yeah mike if you can join the queue please roman jumping in to help with some of the administrative things okay go ahead please uh so jumping in on the middle one is six authors excessive for the style yes that is the letter of the law of the style guide uh if the working group really feels that it's important to to have all of those authors i will support them in that we just need to document that appropriately in the shepherd write-up and i will carry and support the group in that decision through the isg do you think that's possible roman the the style guide was was very um harsh about it so i was assuming we would need to cut down but if you think it's something we can push through with a little bit of explanation that would be great yeah i mean we could talk about this offline but it's my understanding that all the authors there have very much kind of contributed there and there's a very tight story as to why we why we have that list and that seems important to the working group unless someone kind of disagrees with me so i will help through the process to make sure that the document stays as it is with that author wonderful thank you mike did you join the uh the queue i i did you can see it on the yellow screen there good it's a beautiful thing nice um this is mike jones from microsoft um my memory of the description of the jot type claim is that"
  },
  {
    "startTime": "00:26:01",
    "text": "those are intended to be media types with a special syntax edition that you're allowed to leave off application slash but for my earlier statement those are supposed to be media types media types are things registered in the iana media type registry therefore i think we should just register it even if it's never used as a media type per se that field is for media types your memory i believe is correct i think that's right it's just every time i sit down to do it it seems kind of crazy but maybe we should just go ahead there's also a structured suffix for plus jwt registered um but i suppose that it's i wanted to think about that sort of as like a wild card for you could just go ahead and use this as a media type but it sounds like from what you're saying we should just go ahead and bite the bullet and do the registration right the structured suffix was registered by a different rfc and is already in the iana registries and i couldn't remember whether we've done the registration or not if we've not i will create a pull request while we sit here if i get bored we have not done it there's some some rambling words to the effect of what i just said in the area where it would be so pr pending wonderful thank you okay so has yeah yes we can hi um i i on the registration i would say we should go ahead and do it on the working group last call i would support uh to go go to the last call uh within cisco uh we are planning to use uh this kind of this this solution for webex uh in order to mitigate theft risk for the"
  },
  {
    "startTime": "00:28:00",
    "text": "tokens we use for internal services and we've been following this draft pretty closely and the refinements uh in the five and six and over has been uh at the point where the returns are dimension diminishing um i think it's good enough i i we think we should go ahead with the last last call for this draft okay thank you anybody else put your hand down yeah okay so um do you wanna maybe then kind of update the the document based on that discussion with mike and and then we can probably start our group last call okay okay awesome anything else thank you thank you thank you all there you go okay okay can you hear me okay let's get going so i'm gonna be talking about three direction attacks next slide please so this um there was an article that prompted the whole discussion here uh the the article was talking about some specific vendors and and issues around implementation of a free directions and just to be clear those same problems and issues that we will discuss right now not specific for those vendors it's just"
  },
  {
    "startTime": "00:30:02",
    "text": "much much wider than that so next slide please um so let's talk about that how the whole thing starts with the attacker setup um initially the the attacker creates an account on the victim's platform um creates an application of that platform and it crafts an authorization request with the goal of redirecting that user to an application that controls by controlled by by the attacker and then send that request to a the victim through sms or email or whatever right next slide please also take the microphone and put it in is that better can you hear me better okay um okay so this is a typical a authorization request you have a the get request with a response type a redirect uri a scope and a client id and obviously the host that hosts that endpoint we're showing a host name that is shared between all tenants some other deployments will show the tenant itself also in the url the issues applicable to either deployment right next slide please okay so let's talk about um what the rfc is talking about today like what's how to handle those error cases so the first part is talking about a redirection uri if there is a problem with redirection uri or a client identifier then the authorization server should inform the resource owner and must not automatically redirect the user right which is good that's what we want right the second part is that it says"
  },
  {
    "startTime": "00:32:01",
    "text": "if the resource only denies that request or if the request fails for any other reason then the authorization server informs the client by adding some other parameters and redirecting the user right so that's the rfc today um and notice that it says authorization server informs the client it doesn't say must should it's a that's the way it is today so next slide so we will talk about four different issues that that was cast actually the first one is um if there is a problem with the request there is an invalid response type or a scope so after the user authenticates and if there is a one one of those parameters are invalid and the and the client id and redirect uri is controlled by the attacker then the user will be redirected to that specific website controlled by by that attacker so that's the the first use case next place so the second one is after the user authenticates typically you will get the consent you have to either confirm or decline so in this case it doesn't matter what you do whether you accept it or decline it you'll still be redirected to that attacker a controlled application next slide please uh this issue is talking about event redirection even before the authentication so this is an example of a uh a crafted message um it's just the only thing that there is is a client id every other parameter is missing and that and the user redirected automatically to a specific"
  },
  {
    "startTime": "00:34:00",
    "text": "application next one okay so this one is the the most challenging challenging issue probably that that we'll face here so this is um around silence a solid authentication and this is an oidc a kind of specification which which allows um allows that that allow you to check if um a user is still authenticated or the consent is still valid without really prompting the user right and again in this case the user will be redirected to um that um application controlled by the the attacker next slide so the question is do we need a rethinking here around uh how to handle um error error error handling right so do we want to say hey the server should always be responsible for handling those error cases should there be an explicit text about you have first to authenticate the user before attempting to redirect the user how to handle solid authentication which is probably the most challenging part of this story how to handle that that declined a consent um use case regardless of what we do i think we at least want to document all of this and explain it like try to improve their current situation and we could do that and there are a few options here about documenting the the status either update the current security bcp which is trying to ship soon but we'll see if that's the right path if not maybe maybe a a new dedicated document just to talk about this those issues that we've we've seen in"
  },
  {
    "startTime": "00:36:00",
    "text": "the field right so what i'm looking for here is that really thoughts discussions and see what what should be done here so that's that's my last slide and um looking for people to line up and have some discussion here any thoughts i didn't know if i i didn't know if i should just like talk through meat echo or since we're in the room or what no that was a joke that was fine anyway um so everything you're describing here is kind of like this is the known trade-off uh the well-known trade-off of doing anything in the front channel you know it's kind of an inherently fishable space and um you know the the documents especially the you know the updated bcps and stuff like that do a pretty good job of describing that not going into exactly the specificity of these particular attacks i agree um so to me i i realize that we're trying to ship as much as fast as we can um adding a few additional paragraphs to the bcp to describe the specifics of these attacks to me that makes the most sense i don't think that this makes sense as its own document just talking about one little description thing if that's what you're going to do you may as well write it in a blog post and call it a day because more people would actually read it there and um i don't think that this really needs to hold up the bcp because i don't think that this this is really a new attack this is really just a description of how bad this attack surface really is that we've all already know about right with just more specifics yeah thank you justin any other thoughts mike"
  },
  {
    "startTime": "00:38:02",
    "text": "mike jones microsoft uh justin i like your characterization of adding descriptions of things we already know i think that is an appropriate kind of response to the thinking that the working group has done around this and it's good thinking i do not think we should be proposing normative changes to any of our specifications i think we should be in particular asking authorization server and open id provider implementers to think about the security implications of doing the redirect back under certain circumstances and i'd be glad to review such a text and i bet justin would too awesome thank you thank you mike daniel yeah um i agree that this is probably so the security bcp is probably the right place for this um but probably the next version of the security bcp so i think at some point we agreed that we don't want to add any future attacks to the security vcp we're not we're not like we're still reviewing the document like why do you want to wait for a new version of bcp like because it usually um entails a lot of discussion um and probably delay in the already quite late document so i i think as as justin mentioned like we these are well-known things right it's nothing nothing really new if we just capture this just make sure implementers understand this it's just waiting for a completely new bcp it's it's uh i mean"
  },
  {
    "startTime": "00:40:00",
    "text": "if we can really quickly agree on attacks to add then it would probably be fine but we shouldn't be waiting with the bcp for this change okay okay thank you daniel anybody else any comments good day mike mike jones microsoft speaking to daniel's remark um we still have to go through itf review we still have to go through isg review there's a lot of opportunity to add a couple paragraphs prudently i think those who care should find a room write two paragraphs and leave this week with mission accomplished yeah we have those side meetings too right we can you can see if we can discuss those during that time okay any other comments questions okay thank you all that that was that was good feedback appreciate it okay apparently i'm the shortest one here okay um hi aaron peraki from octa um slides there i don't get a clicker right no no yeah okay fantastic what about you so uh thank you i'm gonna give an update on oauth 2.1 and talk about um some of the things that have changed since the last time we've talked about it some of the"
  },
  {
    "startTime": "00:42:01",
    "text": "plan changes and then i've identified a couple of issues to discuss either here since apparently we have quite a lot of time left or during the side meetings for more faster paced discussion if needed so um since last time we met which was virtually and i believe october or november or so uh we've gone we've we identified some things there and have done many of those updates so uh thanks to several people who have contributed to the document to help make all that possible um the tls has is now mandatory for redirect urls except for loopback interfaces so that was a nice update to see we've talked about that before hopefully not a surprise there was a big re-org in the language used to talk about tls because it was scattered through many different parts referencing kept referencing that tls was like a good idea and a new thing that maybe we should do and so that's all now consolidated and it's kind of just assumed uh right at the beginning and then instead of repeated all the way throughout there's been a lot more editorial clarification clarifications um based on vittorio and justin's extensive feedback as well as some additional pull requests that were submitted by other people in the community so that's wonderful another big reorg that happened is or is ongoing it's not finished yet we've been pulling out from the security considerations it turns out there was a lot of things in there that was actually normative and that's not really a good place for normative text so we've been pulling that into the appropriate spot in the main document and that counts both texts from the security considerations of 6749 as well as other drafts that were extensions so that's"
  },
  {
    "startTime": "00:44:01",
    "text": "hopefully easier to see now as well uh the another change was the refresh token guidance so that now matches the security bcp which has had already updated its guidance previously so we're trying to keep that in sync and i guess that's going to go for the discussion we'll have this week as well about these redirection issues so i'll have to roll that up too i do i do think that it makes the most sense to essentially wait on the security bcp until that's more or less final and anything that goes into that gets pulled pulled into 2.1 um and then a there is a new section which is now in there which explicitly mentions the implicit flow because there have previously been no reference to it at all there's a new section in there talking specifically about it explicitly in relation to openid connect it is essentially saying that the implicit flow the the oauth issuing tokens from the authorization endpoint is what is being removed from the spec rather than something called the implicit flow and uh that leaves the room open for opendconnect to still define the response type id token which is a form of an implicit flow in openid connect so hopefully that is now clear for people who are wondering why is there no implicit flow is because specifically it's the oauth one that we don't want um next slide please so um this is a lot of work there's still more to do and i have been going through victoria and justin's feedback have made it through about sections part way through section eight now we're getting into 9 10 11 12 and 13. so there's still a few more sections left um some of that is started some of that is still remaining and uh that is hopefully we'll go through that um"
  },
  {
    "startTime": "00:46:00",
    "text": "there's still more normative text in the security considerations which still needs to get pulled in in line again i've just been sort of doing that slowly as i've been going through the doc um there's the issue we identified at the last meeting which is expanding the uh there's a section in there called differences from oauth 2 and as we discussed at the last session we intend to be more explicit about the changes that are causing certain roles to do things differently and documenting exactly what is breaking for who since a lot of the later extensions do modify behavior of uh compared to 6749 by itself there are a handful of open issues that is the link to them so please go there and read them essentially what i've been doing is as i've been going through the reviews from mainly from justin vittorio um i have been making a lot of the suggested changes that are relatively straightforward and what i believe are not controversial at all mostly it's been editorial stuff anytime there's been something in there that is something that is there is not a clear resolution to i've been pulling it out as an issue so that we can actually uh track it better and and make sure we get around to talking about it so there there are a handful of those in the github right now which we still need to process um some of that can happen here in the room something that can happen during the site sessions some of it is probably better for the mailing list so or the github thread um so please feel free to jump in on those uh next slide so uh for the i guess i should i guess i should pause since what i have left for this is a couple of i think it's three issues i identified as things that would probably be a good good issues to talk about in a larger setting synchronously"
  },
  {
    "startTime": "00:48:02",
    "text": "now um but before i go and describe those and actually get dig into this do we have any comments or questions about the progress so far hey aaron uh justin richard uh first off great work it is no small task pulling all of this text together and making it make sense um uh i just wanted to um uh if we could go back a slide i just wanted to bring to light a very very important point here on number 97 that that might have been elighted a little bit and that's that uh the notion of what is backwards compatibility um in the tech in the in the context of oauth 2.1 is going to vary depending on whether you're talking about compatible for a client for an as whether you've got a 2o client talking to a 208 or to a 2 1 as or vice versa or something like that and so i'm i'm very very glad that that is a focus that is also something i'm going to i wanted to point this out so that when people are reviewing this text especially the bits that say don't do this thing anymore keep in mind what that means to all of the different parties in the ecosystem because there are some types of breaking backwards compatibility that we're actually okay with because certain combinations of those versions were okay with that actually not working anymore okay um then let's go ahead and move on to number five yes so um at the last meeting we had brought up this issue which is"
  },
  {
    "startTime": "00:50:01",
    "text": "this new mechanism the iss response parameter that was a fledgling idea at the time and the consensus at the time during the last session was let's not touch it until it's reached rfc status because we're supposed to be rolling up best practices surprise it is now an rfc as of like three days ago i think so congrats um so now we have to have the discussion again so the idea with this is it is a security fix for clients that talk to multiple authorization servers it is a pretty straightforward mechanism which is i believe why it it breezed right through the whole process and moved through pretty quickly um it and it only applies to clients that talk to multiple as's so if you are only talking to one as then you can pretty much ignore this draft completely and don't worry about it uh so the question now is now that it is an rfc is it considered best practice and if so do we bring it into 2.1 or at the very least reference it from 2.1 as either a requirement or a possibility or um etc etc there are now these these questions to have so um that is the first first issue any thoughts from the room mike jones microsoft out of fairness i was one of the people who said wait um it's now an rfc i'm fine folding in guidance at least"
  },
  {
    "startTime": "00:52:00",
    "text": "saying if you're going to talk to multiple authorization servers do yourself a favor and present them prevent the mix-up attack i'd be glad to review text um so along those lines is it a better idea to incorporate the text of the rfc into 2.1 or in the appropriate place reference out to it saying here are some conditions go read the mechanism over there as a sometimes editor i'll say include an example of using it in the normative text but i'd be fine referencing it rather than pulling it all in i realize there's attention but because you're you and the co-authors are correctly trying to create something that's more readable and i've gotten some additional feedback that it is more readable so you know good for you and good for us but it's a judgment call i'm not in the queue because i'm now i am there you go okay you can't figure it out okay so daniel here from yes.com um [Music] yeah so i would um also support what mike said so um including very brief guidance uh that you should do that and maybe also the like the most common case which is pretty easy right you at the issuer there but in the rc we also have um some guidance around what you do when you don't um have this"
  },
  {
    "startTime": "00:54:02",
    "text": "idea of an issuer in your oauth um deployment and so on so there's there's a lot more guidance around some corner cases there or like combination with jam or something like that um so therefore it would probably make sense to to describe the common case and then refer to the rfc for the other cases okay i'm happy with that um for my own sake later did that get captured in the notes brian brian has a comment okay sort of more of a question of brian campbell from paying identity um as you mentioned it's it doesn't apply to most clients that are just talking to 1as but the actual mechanism of doing it is something the as has to do so i'm i'm a little i was maybe wondering if you could clarify or start thinking about how you portray that in a document like this where you it's the optionality sort of condition on something the client's doing whereas the as is the one that has to support it or not or at least be on that side of it how are you going to resolve that that is a very good point um it seems like probably the right way to handle it is to describe the situation as if your as is likely to be used by clients that will support other asses then then you need to do this because you're right it is something that the ais has to build support for in order for in order for a client to use it okay but i i also think that's actually pretty realistic because i think realistically um or actually sorry there's another condition or another call out in the iss draft which is using"
  },
  {
    "startTime": "00:56:00",
    "text": "separate redirect uis per client is that correct or per as client can use multiple redirect uris per aes not a recommendation but it does solve the problem and in the my mike mike yeah daniel here um if i remember correctly we mentioned that this could be used in theory but um there's i'm not sure if we even discuss this in detail in the rfc it's in a security bcp there's an example so there's more discussion on uh why you could use that to defend against mix-up attacks um but also why it's maybe not a good idea so there's some some subtle details there that you need to take care of okay sorry so the iss uh parameters really the only thing that i would consider a robust defense against up the text sure sorry it was a little bit of a tangent i was just thinking in realistically deployments are going to likely either like they tend to work as a whole there's there tends to be nas that someone is going to be using and then a bunch of clients so i think realistically it's not really a problem uh in in saying the sort of like if your ass is likely to be one of many that a client works with in practice then that's i i think it will cover it realistically uh mike again uh just thinking out loud i would eventually get to this anyway um the iss parameter was kind of motivated by the openid connect issuer in the first place and it's one of these cases if you're doing pure oauth and you're not doing connect all of the supplies if you're already doing connect you already have an issuer"
  },
  {
    "startTime": "00:58:00",
    "text": "and so the parameter would be duplicative i'm not looking to make special cases but i'm also not looking to add stuff that you already have mike can you repeat that if you're doing pure or not open id connect volster if you're doing pure oauth you don't have an issuer without this parameter whereas if what you're doing is always open id connect and not pure oauth or open id connect on top of oauth 2 you always already have an issuer in the id in the id token so there's no need to also included in the response i believe that's mentioned in the draft as well right yeah getting nods okay it could be i'm just talking out loud about where this is really needed and where it isn't this is all definitely making me think it's much better plan to mention some simple examples and reference out for the details since the draft mentions all the details oh good yeah great i'm very excited uh i seem to remember that the part of the discussion was that um you want to have a effort in the request without having to dig inside the id token and there was some reason for that because like there are situations in which really talk and it might you might have to wait until you decrypt it and instead having the issue in the request even in the case of open id was useful because then you were able for example to know what key you need to use for um actually going inside ready talking i don't remember the details but i remember the part that there was specifically the desire to have these in the request without ready"
  },
  {
    "startTime": "01:00:01",
    "text": "talking just wanted to modify what mike said benefit um so you mentioned that in pure auth there's no issue um right but i'm also that's probably a separate topic but i'm also strongly advocating for always having metadata in auth 2.1 which would mean that you would also have an issuer so that might make things easier again because you can rely on that issue so maybe some corner cases that are discussed in the rfc are not relevant just saying got it yeah philips kokan octa echoing vittorio's comment about asking to have the iss in the response one of the reasons to use that before relying on open id connect is that it is actually available in the response i don't have to make the code call to get my id token because even that code call if i make it it's part of the mix-up attack surface yeah okay well it sounds like yeah sounds like we more or less agree on that so i will work on that and report back so yes next uh okay number 101 on github um this is something i discovered as i was reading through the text i was copying and editing um technically rfc 6750 requires but it's in the security considerations section"
  },
  {
    "startTime": "01:02:03",
    "text": "lifetime that is uh not ambiguous however i know for a fact that many deployments do not expire access tokens for various reasons which means they're technically not following oauth 2.0 right now so this is uh the reality today and the question is what do we do to reconcile that because it seems kind of weird to publish a new document that is going to even more clearly state that this is not allowed because essentially what the reason i found this was i was going through the security considerations pulling out normative text in line into the higher up in the docs so people actually read it and this is one of those things which i think people didn't read and then have just ignored because it was was in security considerations so maybe the question is um [Music] was this in security security considerations because it was not intended to be a real must or is this was this always intended to be a real must and people have just ignored it which means maybe we should just not enforce it because people ignored it anyway so i don't know what to do here thoughts are welcome so as the primary editor of 6750 mike jones speaking i'll say that i inherited a bunch of text from another aaron and i did with it what seemed best at the time but i remember no intent to have a normative must even be in security considerations in fact stuff i've edited since that i've tried to avoid ever doing that but the isg didn't call me out on it so take that for what you will but there's nothing conscious about this"
  },
  {
    "startTime": "01:04:01",
    "text": "justin richard um to me this really like the paragraph is still decent advice and it should be phrased as advice if you have bearer tokens which is what this whole section is about then it's a good idea to not have them live forever and um that can be reasonably interpreted in a number of ways um including having a time-based expiration but also as you mentioned down at the bottom lifetime doesn't need to necessarily mean that it's time-based uh like you know you can expire based on in or you can be revoked based on an event or on suspicion or on client deregistration or any number of other things that's not clear from this text and so i agree in expanding that i don't think that this should have any normative weight at all though because this is this is security advice about you know this is the thing about bearer tokens and one way to to limit the attack surface is to limit the lifetime and so i say get rid of this don't don't call it a must or a should or anything this is just contextual advice for how to deal with some of the inherent problems of bearer tokens george wow will it work you guys hear me yeah yes wow kind of fun um i guess the thing you know a little bit to dustin's point that i'm sort of struggling with here is half of what we're trying to do in oauth 2.1 is remove things that are security you know bad practice right i mean otherwise we could say put don't use implicit flow in the security considerations and leave it there so"
  },
  {
    "startTime": "01:06:01",
    "text": "if we think that um allowing forever access tokens is a bad idea then it seems relevant to me that we put some normative language around that in the the text i mean as justin pointed out it does you know you could limit it to end uses or any number of other things um it doesn't have to be time based but i worry about just leaving it open and allowing you know bad practice to continue go ahead justin oh justin richard uh just to victoria i think you were yeah okay fine uh i was just gonna say if this does remain a normative requirement i guarantee that i am not going to follow it um because i have active i i mike says that i am a bad person that's irrelevant to this part of the conversation um no so uh i have a number of um sort of you know larger system use cases where access tokens are taking the place of what we would have traditionally called api keys right we're not issuing them in the same type of you know oauth going to a client type of thing but from the 6750 perspective they are oauth tokens and they're being configured in software and those get rotated when software gets redeployed or somebody just needs to you know re-bump their configuration or something like that but they're not being requested in the sort of dynamic fashion that we normally think of we're okay with this because of the way that we have a very sort of very very limited space in which these tokens get uh that get issued they're not issued using 6749 tooling at all right and so that's a case where we looked at"
  },
  {
    "startTime": "01:08:02",
    "text": "this and we actually decided to implement these quote-unquote forever access tokens for use in this system because within our security model it actually makes sense for that very very limited case so that's that's one of the reasons why to me this needs to be contextual advice and non-normative requirement i absolutely understand where george is coming from this should be giving all of the best advice and that is good default advice but you should be able to read and understand that and say i'm pretty sure i know why this doesn't apply that's fair i may also say that if you are not using any of the 6749 tooling to get the access token then really it is an api key not a no auth bearer token in which case n a so a largely a victorio octa i largely agree with the spirit that has been expressed so far i think that the intent there is good but the way in which it's expressed is uh anachronistic and a bit simplistic in today's world in which it's fashionable to do continuous authentication as long as you are on top of a reason for which you are still okay with that particular token the token can technically live forever let's say that again they want to use fashionable stuff like zero trust and similar but if you are using uh introspection for example or any other mechanism in which you can deal with a revocation of tokens one circumstances allow or circumstances suggest that it's time to do it as long as those circumstances never arise and you are still okay with the security posture of the color that stuff technically can live forever i do agree with george but i think about it well i don't know if we can have a"
  },
  {
    "startTime": "01:10:00",
    "text": "normative text because of the nature of what i just described it might be difficult to describe in formal terms what that means but i do think that we need to help people understand that they do need to do the work that we shouldn't just like do a fire and forget like here is the talk and use it forever it's more of a make sure that you have a sensible criteria to decide whether this thing should still be allowed to operate or if instead circumstances has changed but i do agree that that sentence is just not applicable in a variety of scenarios like the one that justin just mentioned it sounds like what you're saying is the as must have a way to revoke a token if it wants to under its own criteria that was one example of a token that lives forever because somehow uh like you don't know what you maybe your user has done something that suggests that the circumstances are still yeah i'm still trusting this thing but uh it's just one example like the the example that justin brought up is different but just as valid so that's why i'm saying it's going to be difficult to find a normative language that will encompass all of this stuff well i was i was trying to find something normative that is also least less specific to particular cases so that like what you're asking for is don't don't hard code these keys such that they're just hard-coded everywhere like make sure that you're building a way to revoke them but the particular reason for revocation is not something we can normatively require like say or the mechanism that you use to perform the thing is kind of like maybe we can enumerate a couple to give people ideas but we can't enforce and like for example introspection is a good way of saying you must call home or if you don't want to do introspection but you want to have i don't know uh"
  },
  {
    "startTime": "01:12:00",
    "text": "um allow lists or block lists for your their tokens like ultimately i don't feel that we can be in a position of imposing to people what's best for their architecture it's more of a matter of like make sure that you don't paint yourself in a corner and give tokens that once out they are out of your control and they can be used forever seeing some nodding from george okay george yeah so i think my biggest concern is sort of what you stumbled across aaron which is this is in the security considerations and probably nobody ready so i i i i'm you know i'm hearing the the difficulty of coming up with normative texts to sort of imply the correct security behavior but somehow i think we have to make it more clear in the default section of 2.1 here are all these you know here's some examples effectively you need to protect the access tokens as vittorio just said and here's some you know different ways that you can do that right there isn't you know just a reference to go read the section in the security considerations um so that we hopefully do a little bit better education even if it's non-normative okay peter peter castleman microsoft so i i don't have a particular problem with this idea that the lifetime of the token must be limited i actually think it's good because if you don't have the notion of an end state you have no way to get there so to vittorio's point uh by defining an end state you have to define mechanisms to get there right so it's revocation mechanisms it's events uh it may be expiration times right there may be a number of those ways you may want to consider giving guidance on what limit it means right so that could be"
  },
  {
    "startTime": "01:14:00",
    "text": "defined or enacted in a number of ways but i think if you omit it forever is an incredibly long time right and and often doesn't last more than say a year or five years or something like that right so um so i think i actually don't have problem with that statement it's more about how you define limited and giving guidance to the implementers around how they construct policies but having the ability to revoke in case something goes wrong if you don't have that you're going to find yourself in a really nasty place okay that's it again good yeah okay i think i think that's i think that's enough on that um that was helpful i will add that to my list and get back to report back on the mailing list i guess awesome yeah absolutely okay i think we have one more ah yes uh this was identified opened as an issue on github so this may be the first time people are aware of this um the from the native apps bcp which has now been pulled into uh oauth 2.1 it actually has a requirement that authorization servers that support the native apps bcp all support support all three of these redirect uri methods for native apps which is private ui schemes so that's claiming uh or defining your own url scheme and it gives some examples of ideally using like reverse dns based ones but that's not a requirement either um claiming https urls which is a feature that ios and android platforms support and also the loopback interface of just opening up a port on the device and authorization servers must offer at least these three"
  },
  {
    "startTime": "01:16:01",
    "text": "and then it was pointed out that there are many times that a for a particular deployment you actually don't want to allow any one of these in particular for various reasons for example fabi actually goes and prohibits prohibits private url ui schemes because they are not nearly as secure as registered https urls so technically if you follow fappy you also are not following the native apps pcp so that is the current that is currently the way that it is written um so now that this gets brought into oauth 2.1 it seems a little bit weird again to say that if you're following tapi's rules which are meant to be more secure that you're then also not able to follow 2.1 so again we have the sort of conflict that needs to get reconciled somehow daniel danielfatiers.com i'm not sure if there's actually conflict there because it hinges on whether you want to support native apps at all um and i know a couple of deployments that don't intend so that intentionally don't support native apps i think the same applies to floppy so one could say that if you want to support native apps then you have to offer some of these options at least but you can also just say not to support native apps but fappy native apps can also use fappy so right yeah that's where the conflict happens yes um so i'm i'm not sure what the exact wording is in puppy right now but yeah so probably it's a good idea to leave the door for not supporting this"
  },
  {
    "startTime": "01:18:02",
    "text": "i know for sure that there are customers that want to get caught dead supporting the loopback interface so having a mask that includes the finger will automatically means that those people will be out of compliance so i'm strongly in favor on not having a must in there we could get rid of a loopback that would be fantastic but i know it would be too good so at the very least i would not force people to implement it if they want to do a native client brian i'm not sure what i was going to say now i get closer to the mic i don't think there's neces it's not uncommon for profiles like fappy or otherwise to further narrow what's allowed based on other things i mean for example fappy disallows client secret authentication which is required by the base so i don't know that there's inherently a contradiction that said though i i think the way that this text is being pulled from a bcp about a very narrow context and over it would probably be better to somehow qualify it with not must or under the conditions that you're supporting native apps you should do these things yeah so it's both it's both okay and i think you should change it great if that makes if that makes sense um yeah dave tong money hub um yeah i i kind of agree with what brian's saying i definitely think the wording needs to be changed i mean if i understand compliance you know it's only if i fully support native apps i need to rough all three so maybe if i want to support not fully native apps i get a new support too so i think it definitely needs the wording is a bit strange i also i think it's highly unlikely that"
  },
  {
    "startTime": "01:20:00",
    "text": "any authorization servers you know many of them will just not be compliant with the security bcp because i don't i don't think that's the intention surely it must be that these are three different ways of doing it which you could support so yeah that would just be my suggestion and i but also if we're trying to make things more secure um unless there are is a good reason to support the the pri uh private uri scheme then maybe that that should be excluded because you know the reason we exclude it in fappy was because of you know the fact that in you know many the mobile systems you know different apps could claim the same private uri scheme so i mean my the starting point i would say is to remove that unless there's a good reason to keep it in yeah that's another option is to to require claimed url schemes and loopback and make the private uri scheme optional just mention that it's a possibility or just not require not require any of them i'm i i'm kind of curious what the reason actually was for the requirement of offering all three of them in the first place and i kind of suspect it was a optimistic attempt at interoperability which kind of seems like maybe that wasn't the right goal for that feature george yeah so i'm uh i think i'm in favor of not explicitly forcing authorization servers to support all these mechanisms and i am in favor sorry i am in favor of ordering them by best security practices right so we should be telling people use the claimed http https urls um"
  },
  {
    "startTime": "01:22:01",
    "text": "and unless you have a really good reason to do something else just don't right um you know if you have to support some you know legacy version of os that maybe doesn't support it or whatever well then you know maybe you have to right and you have a really good reason for it but otherwise i think we should be pushing people toward the secure options which at this point is you know claim https urls um and you know whether we want to put other you know guidance in here around other ways you know that the os's are now supporting you know to get app at the stations that's probably a different topic but in this particular case i would much prefer we sort of push people toward the secure solution okay any other comments any okay so let's try to summarize this one it sounds like sounds like we're going to in the draft reorder the the list uh claimed https urls first loop back second private private url schemes third just at least make sure they're ordered that way [Music] um and then just remove the sentence that says that they must the as must support the three um because nobody cares about that requirement apparently is what i'm hearing um and then maybe some fiddling about explaining why they're in a certain order or whatever but i'm seeing some just removing the the"
  },
  {
    "startTime": "01:24:04",
    "text": "url first loopback second private ui scheme at the bottom um maybe even adding in some text about why you would want to support it at all just to better set the context um yeah i'm happy with that okay good i believe that's the last slide no one more oh just okay um yes so those are the three that i want to talk about today i felt like they were more complicated than a lot of the other ones and requires more joint thinking power so there are however a lot more things to talk about this is not done um and i would very much appreciate more of the discussion happening um asynchronously on those so the list i'm keeping track of is here that is where anything that's open is still i'm going to close it at some point one way or another but before this is considered done um if you want to to chat on github that makes it very easy for the editors to keep track of the discussion i appreciate that if you are would rather discuss it on the mailing list that's fine too we'll pull it in but yes please we would all appreciate some help with this there's still quite a bit more to go so yeah typically we want to have those discussions on the mailing list just for the records right and and that's a idf process but yeah you can send those also to to the mailing list just so for people can go and take a look at the github and see what's going on there okay yeah i'm happy to uh sort of post the state of the state of the draft to the mailing list um to let people know what's going on and call out some of those issues i do feel like some of the issues are relatively minor so i'm less concerned about about the the whole"
  },
  {
    "startTime": "01:26:02",
    "text": "mailing list record for some of them uh obviously some of them are a little bit more substantive okay brian sort of following along not and i only sent an email this morning about it but the the idea closer to michael damn it sorry yeah only just followed up this morning but back at the end of last year there was a threat on the mailing list about the credentialed client type and kind of nothing ever happened and it was not nothing was done in the latest draft about it and so i wasn't sure if that was a forgotten about or a um i'm most i'm mostly just wondering if should i put an issue so it's followed were you gonna tell me to screw off did it just get forgotten yeah how should i proceed in general i guess um no they want to talk about it now i had completely forgotten about that issue um i guess my recollection of that thread was that there was some discussion and no real resolution to the mailing list thread either uh so i think that's why it sort of died out was it just got lost right having an issue uh wouldn't hurt right yeah you have to avoid uh if you sort of like yeah yeah definitely definitely um it's so hard to go back to the mailing list and find all of the threads that are relevant to this draft so yeah if you want to file it as an issue then we'll it'll make sure that it's tracked it's tracked okay um and then we can pick up the mailing list site again too if you want to talk about it there um or we can talk about it now because we i think we still have yeah like if you guys uh when i go ahead all right no problem for what it's worth my recollection is that the issue was put up on the screen it was more or less closed so i i was expecting some action but that could bias me because that's what i wanted to happen so it doesn't mean that it really"
  },
  {
    "startTime": "01:28:01",
    "text": "was resolved that way but okay um so where would that issue be brian sent an email today yesterday so to check the archives and it should be pretty recent at the top and hopefully that's in reply to the original one or not no of course not oh okay why would you use a mailing list with it but i think that i did link it so you could follow through so is it in the mailing list yeah yeah it would be at the top of the mail unless i just quickly to summarize there's there have been some i think confusion about what the term credential client really meant um and then on further inspection the actual normative requirements around it outside of the section that it was defined qualifies every single usage of it is confidential or credentialed client must do this confidential or credential client has to authenticate so they are treated uh as synonymous throughout the document just with more words um so i the suggestion from me and i think others sort of backed it up was to get rid of the distinction entirely and provide some somewhere any discussion around the various levels of trust and establishment and pre-registration and so forth in that i forget what it is 2.4 section describe the the nature of it but keep the two types as they are um so okay i remember this i remember this thread now um yeah because we need to we're gonna try to try to find it for the for the screen because otherwise everyone is lost oh right no he did a good summary of it though um yeah um"
  },
  {
    "startTime": "01:30:08",
    "text": "oh um oh you have to restart your browser for that one no kidding okay um well okay that's not gonna work um the brian did a very good summary of the of the state of the issue anyway that was um that was a good recap of it um my so the original text that's in there every time you see the or credentialed and the new text previously said confidential clients or clients with credentials which i i personally thought was more confusing because elsewhere it says confidential clients have credentials otherwise a public client doesn't so that was what it was trying to reconcile was there is like there is something between the two because apparently we can have confidential clients or clients that have credentials that are not confidential clients and that's already in the original draft so that's what it was trying to do so if i agree that maybe the like it could"
  },
  {
    "startTime": "01:32:00",
    "text": "use some more clarification around the conditions under which a client may have credentials that are not it's not a confidential client that clearly needs to be explained better because that is not obvious in either draft at the moment but i don't think just reverting back is going to solve the actual problem justin justin richards so um brian's not entirely wrong um the the term is a is definitely a bit confusing that said uh aaron is 100 correct that we have more than just confidential client which in the 67 49 days was statically configured you know hand registered somebody called a sysadmin to go set up a config file somewhere type of client and then public client which was just you get a client id by calling the sysadmin and having them set that up without a client id and that's it we don't live in that world anymore and i think it is very very important for oauth 2.1 to not only acknowledge that but also to like embrace that i personally kind of like the direction of credentialed client as sort of being situated in between that said i think we may want to approach this um in a slightly different way in that if the definition of confidential client is simply a client that has a secret that it can keep right so a a client secret or a key set or something like that and public client does not so it's a bit of an expansion and"
  },
  {
    "startTime": "01:34:01",
    "text": "clarification of the original definitions without all the assumptions then there is an orthogonal dimension of how that confidential client making sure i'm using the right terms how that confidential client came into possession of its secrets and under what circumstances that's what i think credential client was trying to capture but by putting it on that same dimension i think may have been a little confusing so i think we might actually be able to have a better and more thorough discussion by sort of expanding the the reach of what confidential client actually means and making sure that when we're talking about condo financial clients if we mean one specific sub category of that then we name that subcategory because there are different security considerations that you have for statically pre-registered web servers versus a um a mobile app that gets a secret provisioned on install as part of you know an install framework versus something that does a full off-the-street dynamic registration versus the whatever the you know moderna ecosystem does and open banking and stuff with the they're basically they reinvented cas anyway all of these are very different takes on how to get to that state with the goal still being to get to the state where an individual instance of a piece of client software has access to a secret that can authenticate that instance of client software and so i think what we might be able to do is to back off in all of the places that say um you know confidential or credentialed"
  },
  {
    "startTime": "01:36:00",
    "text": "or whatever just say confidential in all of those places and then in our definition and discussion of what confidential means and how you get there we expand that discussion significantly i i like that for sure um one of the other implications of that is there are also many places to talk about considerations for confidential clients that would need to get qualified further yes because it would no longer apply to all confidential clients yes absolutely and bike shedding all of those categories is going to be a mess there i don't think there's any way around that um i think that uh having named categories is going to be very helpful for all of those and credentialed client was it was a good stab at that um to help some of that differentiation okay i see where you're going with that for sure um i think that's i think that's doable brian i i think justin proposed more or less the same thing that i was proposing which is strange because i thought he was going to disagree with me but i do think i think the names are pretty bad public and confidential but we're sort of stuck with them and i know personally i've used them in other documents that will still be applicable to 2.1 so i would unfortunately for what they are i'd prefer them not to be changed and then it comes down to just better explaining them and i think that orthogonal access of trust that that justin described um works and gives people the knowledge that they need but it's not like you wouldn't authenticate a client with credentials just because of the way it was initially established you're still going to check those credentials you're still going to um so it doesn't back to what i said before it doesn't"
  },
  {
    "startTime": "01:38:00",
    "text": "change sort of the functional places where you refer both of them and say they have to authenticate but just a description of how sort of the provenance or the trust and the application or client comes to be um as that orthogonal access of of yeah words that you'll come up with that are better than what i'm saying one of the one of the other attributes is around whether or not the user gets prompted for consent there's an explicit mention that says public clients should be should always be prompted even if it's like a first party client if there's something around those lines um or was the other way around of confidential clients might want to skip the consent phase i don't know which one it was and now uh but it's it's not just about the authentication of the client it's about other implications of how much that client is essentially trusted by the as based on various things one of which is it's how was how that credential was established so but i think you're saying more i think we're saying the same thing and i the areas i looked at were the credentialed not for the other scope so yeah there's probably more touch points for clarity but but the same thing applies i think you know a client that's registered through an open portal anybody can is no different than a client that's registered via open dynamic client registration versus dynamic client registration that's done through some sort of um you know bespoke access token issuance to get in there in the first place is more trusted maybe then absolutely so there's yeah and that kind of touches on the redirect issue it does really right as well it does um so yeah i think i'm agreeing yeah okay thanks um yeah dave song money hub yeah i'm basically just just to agree we we had a few issues and people asking okay what what is this credential client and trying to look through the current draft to see what you actually have to do differently and and apart from that initial do you trust the identity that seemed to be only the only thing as far as i could see so yeah i just very much agree i think if we can keep it"
  },
  {
    "startTime": "01:40:01",
    "text": "simple and then just call out this you know i think brian made a really good point it's not all confidential clients are are equal either in terms of you know how much trust there is whether they're just yeah registering so yeah very much agree with what's said before great george i'll just add i i'm in agreement um the dynamic client registration's back um 57-91 no sorry 75-91 i'm dyslexic this morning um basically implies that when you go through dynamic client registration you have a confidential client that uses the word confidential client in a few places based on the response so um you know i think potentially to brian's point keeping those words to represent those class of clients makes sense so that we don't introduce a new term but all of the other points are super valid right just because you have a confidential client doesn't mean that it's trusted it just means that it can you know accurately authenticate itself um and you know the other things like you know should you show consent or not um you know probably could apply even to some kind of confidential clients if they're not trusted in the sense of an open you know dcr kind of a model so there's a lot of implications there okay david uh i just wanted to remark that it could be that it's better to find the mutant can you can you speak up david can you speak up please get closer to the mind maybe i just wanted to say that it may be better to find new terms possibly in axes we can barely hear you that's funny i hear myself and feedback pretty loudly actually"
  },
  {
    "startTime": "01:42:03",
    "text": "better keep going david keep going i just wanted to say that it might be better to define new terms possibly multiple terms to define different facets because otherwise everywhere we use public and confidential we're going to have to revisit those such as registration to make sure the older term breaking anything to work on them i didn't get that um david can you send that in in a message to to them in the chat or did you get i think i got it i was going to okay go ahead brian and then argue against it at the same time i believe that dw was saying that it would be better to introduce completely new terms because the existing terms are used throughout different documents and possibly multiple access these terms to to cover these things i speak up now maybe if i'm wrong about that david um and i would i would flip it the other way because these terms are used throughout a number of documents that are not touched directly by oauth 2.1 but will still be compatible with 2.1 and it's all of its framework um as bad as the names are i think they should remain the same so that they don't introduce further breakage or confusion with with those documents david do you have any comment okay i don't see david and mike again okay vitoria um i am a bit concerned about uh post-hoc uh redefining some of those terms um although it would be handy to say"
  },
  {
    "startTime": "01:44:00",
    "text": "anything that has a credential is confidential in a practical user many systems are predicated on the idea that a confidential client is a singleton and the infrastructure and the service and the programming model which is offered to the developers is based on that and in fact the confusion tied to that uh is also observable when people try to use such systems for iot or similar in which they try to distribute the credential to clients but to a scale which wasn't designed for so long story short i think that uh if we decide to uh generalize the term of confidential client to anything that has a credential with no regard with whoever is singleton or not however the assignment of this credential was done in a circumstance in which you would have some i'd say extra insurance that you knew something about the registrar then i think that um we we needed to like convince ourselves that we will not break or that we will not create even further confusion and uh potentially uh contradict ourselves because like although we never said i believe anywhere that this thing represents a single tone originally this thing was websites which were naturally and then everything else was somewhat derived from that so long story short i guess i'm saying uh i'm a bit worried about making that sweeping uh generalization because of the potential side effects and given that have a mic i'll also say that to me it's odd that we might uh say excuse confidential clients from showing consent but instead asking to uh public clients to do so because uh public clients today unless you use the tricks like urls uh claim the urls and similar very travesty like you can use whatever client id you"
  },
  {
    "startTime": "01:46:00",
    "text": "want and pretend to be someone else so asking for a consent in that particular case in which you have very little confidence that the bits that are running are actually representing the thing that was registered as a client seems somewhat contradictory but that was an aside the tldr is uh let's be careful about generalizing what the confidential client is brian i understand what was just said but the generalization matches the reality of i i believe what was written in 6749 some of those cases you discussed are due to some of the prior weirdness of the various editors and taking over and so forth i think it's it's pretty widely accepted that confidential clients are those with credentials regardless of how they've gotten them and again i've certainly written a number of documents that say that and rely specifically on that so i don't think we're redefining anything and provenance of trust and chris like the reason right or wrong the reason that lack of consent has allowed for confidential clients is because the picking up of the actual what's consented the access tokens is restricted to that client yes the initial authorization request can be anything but because they have to authenticate because the callback only goes to a registered url that's why they're allowing for that that part to be skipped at least in the text i believe is what it said so it's not quite the right comparison unless i'm missing something but yeah go ahead thank you um so on the whether it matches the reality i'm not sure let's say that that's what we might have a place on the specs but if you look at practical usage"
  },
  {
    "startTime": "01:48:01",
    "text": "for example if you look at what some of the twitter clients do when you install it on windows that's a public client as in it has the same id in every installation but then in the moment in which you install this thing you get a key so you still have one entry but and it behaves like a public kind it is a public client is a native uh thing running on the desktop but you do get a key so although we might not have uh to say formalize that particular flow but that thing behaves just like the credentialed client that you attempted to place into that one so i think it's a bit more advanced than the reality is um like that anything that has a credential is a confidential client in reality in fact like i think there are a number of practical example in which that is not the case only the other one about the consent i don't want her at home so we can discuss offline i think the uh i think what you just said was actually relevant to the thing that justin mentioned which is that the the other factors of what the system is doing with this client is what's dependent on how that that secret was obtained and the fact is that it has a secret and most of the things in the spec are things like if you have a secret use it things like that so uh i was i who's who's left on the queue george george go ahead okay so i i guess um i don't want public clients and maybe i'm misunderstanding what you were saying victorio but i don't want public client definition to me a native app right because if my client on the native app can basically create a public private key pair where the private key isn't stored in the tpm of the device right"
  },
  {
    "startTime": "01:50:00",
    "text": "and and then it can use that for proving its identity when it makes calls i don't think that should be considered a public client um in in that context right it's something different and i worry about labeling that as a public client um so if if we're basically just saying public clients are i always for me in going through this over the last bunch of years right i always looked at public clients as those clients that can't protect a secret and a confidential client is a client that can protect a secret so if the client can protect a secret and when we were talking about dynamic client registration you know the expectation was the secret is instant specific and therefore it can kind of protect it because it's the secret itself is not embedded in the binary someone to get it would have to jailbreak the device itself to get access to the instant specific piece then that would be considered a confidential client so you know maybe the problem we have here is that we have a bunch of you know different interpretations of what these terms mean and you know we're trying to sort that out and it has ripple effects as brian's pointed out against existing specs but i you know that has been my interpretation confidential clients are ones that can successfully protect the secret public clients are ones who can't regardless of where they're running go advertor great so i think that this this discussion is really an excellent example of clearly we have different uh points of view and different interpretation of how this thing went because for me being very pragmatic and having to deal from the developer side the main difference is that there is only one twitter website but there are millions of twitter installations like everyone on the phone"
  },
  {
    "startTime": "01:52:00",
    "text": "everyone instance and then whoever tweeter decides that they want to identify a particular instance or not it's up to them so i can model the twitter client using a public client and then if i want some extra guarantee i can find a way of also assigning a key so that although i still have the same client id and the current id is the thing that deals with the nature of a client i have those extra guarantees in which i can recognize the instance now i can't claim that this is a normative because this stuff is not covered all i'm saying is this is the way in which i've been operating and helping customers model things or observing others modeling their own system to me this just points to the fact that if we go in the direction of saying no now we formally want to say that anything that has a credential is a confidential client then we need to be explicit and saying okay if you were doing the thing that i just described in which you have those enhanced public clients in which you can recognize the instances of a client but we all have the same client id you need to distinguish these from singletons in which when you have a website then uh it's just one and so let's use it a different way let's call it the confidential client plus plus or max or 365 depending on the company but like yeah perfect so yeah just wanted to qualify active client no mike um oh the microsoft jokes in this room um uh justin richard once again uh i think victoria uh that sorry you were saying all lunch about how everybody gets your name wrong and i've known you for years i think vittorio and i actually do agree violently in different directions um"
  },
  {
    "startTime": "01:54:00",
    "text": "so everything that he just described about how you have the special class of a public client that's not acting like a public client i would call that a confidential client that's not acting like a statically registered confidential client and that's why i really think we do need this this different dimension in order to talk about these things um i'm with george and with the the language that we have in dynamic registration that said once you get the credential then you are a confidential client like that was that was one of the the selling points of dynamic registration was it was take your public client and turn it into a confidential client in a way that oauth could actually think about it being a confidential client with all the security caveats that this is not the same as a statically registered one and then with software statements and registration jots and all of that other stuff people have bootstrapped a lot of other layers of trust on on top of that as well to have even more gradients here of trust however at the end of the day it is presenting a credential of some type be it a client secret or something else now i do think that it is interesting if you vary the client id per instance or not and what that actually means that should be part of this discussion that should however not be part i would argue of the definition of what makes a public or confidential client right because if i decide to give everybody the same client id everybody in the world the exact same client id and differentiate them based on their keys instead i could write that system it's kind of a dumb idea in oauth world because so much is leveraged on the client id that public identifier what's that yeah that's what twitter did that's what"
  },
  {
    "startTime": "01:56:00",
    "text": "that's what a bunch of other uh things out there have done and um google did google did that back in the oauth one days as well with their weird ex-off extension thing whatever that was called uh regardless the point being that i don't think that this should be wrapped around the client identifier at all um i do think that it does make sense to collapse down to these two categories if we can then have this larger discussion about how you got into that category that is really what i'm hearing is that there's a lot of factors about clients that you want to treat differently depending on a lot of different things none of which have to do with whether or not it has a secret yes exactly and it applies to both clients with and without a secret all those factors apply to both clients so i don't know it seems like it seems like there's two different issues going on one i agree let's let's simplify the terms and then two there's a lot of stuff we need to talk about like there's more things to add about these different considerations and everything that i've heard is definitely like a good thing to to bring in as a hey if you know you have the situation and i think some of that exists in the current draft but it was more more tied to the public or confidential type which as we've seen is not actually the correct place to tie it right so yeah we should be making we should be making distinctions when there actually is a difference between things and in a lot of the discussion that i've noticed here today a lot of the decisions being made are actually decisions that are on top of the oauth protocol and not within the oauth protocol itself you know back to aaron's point of any time uh that it shows up in the text it's basically saying if you have credentials present them and verify them and then what you do from that point is a different question"
  },
  {
    "startTime": "01:58:00",
    "text": "that you answer with different information so vittorio's concern was ripple effects of redefining the term and i think that's something that's worth paying attention to but i don't necessarily think it's uh a deal breaker i don't think it's something that's good that we should stop and revert this plan so proceed with caution uh and i'm happy to keep that in mind as we work on these changes okay we have two minutes here and uh i want to allow george to get into the mic george sure i'll be real quick i think victoria your model is a really interesting one and actually surprisingly one i heard right when i think about dynamic client registration i always think about issuing each instance of a client its own client id and specifically that so that i can block that particular client instance um separated now you could do that by the key as well right so i would like you know i guess for me the question is where do we have these larger conversations about models um because i think it's super important right we probably have some best practices or some patterns for the way things are implemented and you know does that go into a spec do we pull that out into something else but i think that would be really helpful for developers to understand that there are multiple models and um and you know the pros and cons of doing you know things one way or another okay honey you wanna wrap up i'm that's it i'm happy with this discussion thank you it's very productive um i've got my homework cut out for me awesome good thanks aaron yeah great discussion thank you all uh we are done for today um but we still have three more sessions so two side meetings and we have thursday also as an official meeting okay see you there"
  },
  {
    "startTime": "02:00:01",
    "text": "go ahead mike last last minute mike jones are the side meetings on the list or if not could you do that i i sent it to the list i think i i will send it to the nest yeah that's fine okay thank you yeah as long as it doesn't say confidentially do not clear you're good you're good oh okay okay"
  },
  {
    "startTime": "02:02:29",
    "text": "one you"
  }
]
