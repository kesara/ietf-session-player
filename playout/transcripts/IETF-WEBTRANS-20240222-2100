[
  {
    "startTime": "00:01:23",
    "text": "testing Bernard can you hear me I can hear you awesome thanks I figured we'd wait till Eric gets here yeah and you until five passed uh General"
  },
  {
    "startTime": "00:03:46",
    "text": "all right I think people are filing in virtually I think maybe we'll start at five five p"
  },
  {
    "startTime": "00:04:03",
    "text": "we can probably St start the nagging a bit early uh do we have a volunteer for notaker all right folks we need a note taker for the meeting to start know the drill and with these virtual calls I can't just awkwardly stare at people but you can talk about doing it well let's see I can turn my camera on and stare into the webcam but I don't it's it's less fun if I if I could generally everyone looks down at their laptop for some really important email at that moment all right folks we don't need the minutes to be too precise remember these days have the YouTube recording just to kind of uh I mean if you're willing to do the first half Martin that would be super helpful and is someone willing to do the second half and the nice thing is with a not taking tool right anyone can do it easy apart from the fact that uh the"
  },
  {
    "startTime": "00:06:00",
    "text": "note taking tool if you're not logged in doesn't open the note taking tool that's right ah thank you Lucas uh all right thank you Lucas and Martin and all right let me see if I all right cool and just to make sure we're all there here's the link in the chat all right Bernard you want to kick us off sure uh this is the web trans working group uh we have two hours together hopefully we won't need every little bit of that uh but a few reminders this session is being recorded I think by now everyone knows how to use meet Echo but please use the Q hand tool to to get in and out of the queue and don't forget to unmute yourself or we're not going to hear you not well so ITF policies and effect on topics of IPR Etc and uh it's detailed here by participating in the ITF you agree to follow the processes and policies definitive information is at the drafts below uh please please read them and understand them and then uh we have standards of professional conduct in the ITF guidelines of conduct an the arrestment policy and procedures if you have any concerns please talk to the Ombudsman all right a little bit about the meeting we do have an notaker thankfully I guess David you'll be the zulip Scribe um and we have notes for people to take notes in so here's the agenda um we're gonna have uh yanar do a w3c update and then we're going to get into the core of the meeting which is really about Max streams and flow control um and we have a number of of drafts which um will represent potential"
  },
  {
    "startTime": "00:08:01",
    "text": "solutions to this and lots of slides to go over um on it so that's the focus of what we're going to be uh doing today and then at the end we'll try to wrap up and summarize what we've figured out okay yeah Evar hi can you hear me okay yes yep all right great hi I'm yavar from Milla I co-chair the w3c part of web transport with Will who couldn't be here today so I'm doing the update so this slide is pretty simple uh we will present a full update in Brisbane for ITF 119 but for this inter we would like to focus on uh two two well two issues one PR and one issue which we have ITF dependencies on and the F this is the first one which is issue 411 over in AR of the woods which is to expose a TLS keying material exporter unique or unique value for the TLs session you might this might sound familiar because I think it was bounced back there was some U we reached out for more uh user support and there was a bit of a delay and people come back and I think it's Li P2P the specific user who wanted to who had interest in this feature so we're bouncing it back and in short it would be useful to expose a TLS key exporter from RFC 577 or least a value that's derived from the TLs Master secret and therefore unique to the TLs session we like to extend our use of web transport to use the web PK extensions uh here being able to drive a unique value would allow us to bind the TLs session to the noise handshake similar to how we use SE certificates I don't actually what A noise I don't know what A noise Handi is but it sounds really cool so but this is apparently a useful building block for protocols running on top of TLS and there's some strong support report from uh the"
  },
  {
    "startTime": "00:10:01",
    "text": "authors of this so Victor reopened uh this in ITF which is issue 116 so um discuss any questions around this or concerns uh no concerns but um I know we've created tls1 .3 exporters uh in other working groups I'm just wondering if we're clear exactly uh what the what the function is I think we are in other working groups like emu created one um but that might be something to check Victor oh to answer the question I think the exact function of those would depend on the applications is building on top of web transport Oh you mean the label would right but the well the label and the specific use but it it's up to the protocols that R help of web transfer we're not asking uh to design the API in this working group but uh I understand there are some parts that would be needed to facilitate an API yeah I I'd say I think Victor had a PR uh written up for this so i' encourage if people have thoughts to go comment on the pr um given that we have this request from the j3c I think we'll we'll look at it more seriously there I don't believe there is a PR but there is a proposed design on okay so on the issue so please comment on the issue folks um and then ideally we can like so in a few weeks we'll all be in Brisbane so Victor if you can have a PR by then then we can uh discuss it in the room then and see if uh we can get the appr like if if we can reach consensus on a"
  },
  {
    "startTime": "00:12:06",
    "text": "design all right thanks and the second issue is issue 580 uh which tried to remove a dependency on data received and we were able to partially remove it but this line uh was proving a little difficult it's a line that Waits uh um for the data to ENT the internal stream to ENT the send stream sorry to enter the data received State um and this was discussed in ITF uh issue 103 that is actually useful for aboring a stream to create what we call partial reliable sending uh basically to abandon data that's already been sent um and we would lose that feature unless we keep a signal in HTTP 3 and maybe not an hb22 where we could add it but it wouldn't be useful probably uh so the a similar PR was so the other references to data received other than this one was removed and again Victor was supposed it says Victor to open an issue on the ITF side to update overview about the definition of streams to include some sort of omitted State Victor do you want to comment more on this one does that cover it yeah turns out that due to API issues we uh uh have to tell uh the upper layers when the stream transitions from the state where you sent fin but you can still reset it and that would result in discarding data to the state when you can't reset it anymore because the all data is been acknowledged and there's nothing to do"
  },
  {
    "startTime": "00:14:00",
    "text": "that's that's the background for this issue all right thank you I see Eric and the Q just a clarification question so the proposal here is to keep the data received state or is it to add a new state that better represents what we're actually trying to do uh kind of both the proposal is to rename the state from data received to basically all data committed I think that was the name I was going to and for H3 it would mean a data received and for H2 it means as soon as you write a fin onto TCP your thank you any other thoughts comments Martin so Victor I think the the primary concern here was that there's that um there's a distinction between that the data is gone into the network and um the the data has um so jez I'm struggling with this one a little bit because I'm trying to keep up with the notes um the the concern is that there's a difference between H2 and H3 in this Regard in in H2 once you've sent the information and and the promises have resolved it's gone it's in the buffers and it's more or less committed and there's nothing you can do about it in NH3 you can send packets and they might get lost and you might have to retransmit them and there's that window of time during which you might want to have bought the retransmissions and that's the window that we hoping to exploit with a sort of"
  },
  {
    "startTime": "00:16:00",
    "text": "partial reliability capability yeah so one thing to note is H2 also has kind of haet window so it's smaller it's like you write a bunch of data and then you hit flow control which is entirely plausible because API lets you write like 10 megabytes at once so you can still reset that and it will not write it to CCP connection so it is not entirely like meaningless in http too as well yeah I I would imagined that the the promised resolution on on rights even though people tend to ignore those sorts of things would happen once the data has been committed to the to the network yes I think this a specifically promis resolution on the close and not on right H okay I think we need a little bit more clarity about what the distinction would be on each one of these ones uh to be confident this is okay I don't want I don't want a situation where we are driving this based on um acknowledgements or something like that because we made an explicit decision not to do that I think it has to be has to be framed in terms of what what has happened locally on the on the stack so all right yeah more work required on this one yeah all right so more work needed is that um and that's there's an issue to attract that wait that's issue 103 oh no that was closed uh Victor did you open an issue for this one uh not yet okay but you'll open the issue and discussion will happen there"
  },
  {
    "startTime": "00:18:00",
    "text": "all right uh thank you everyone I need to drop at this point so thank you everyone for your time thank you for the presentation yanar all right I think Victor are you uh you're doing the intro here right uh I think I'm reading up to proposal D and then starting with proposal d it's Eric Eric is it correct yep that is correct awesome thanks Jens oh okay I assume I don't get slide controls or anything fcy like that so uh so I'm today the main purpose of this meeting is to talk about the flow control issues that we had discussed at like for over a year now and the flow control here is a very interesting issue because it is not necessarily what you would think when you say flow control it's a bit different and the difficulty Here Comes not from the usual flow control but from the fact that we have a quick connection that it has for flow control and we're trying to put flow control on Lower layers of things that we nesting in it uh next slide so uh what do exact so flow control in most General is a mechanism by which receiver can tell the sender how much uh it can send so that receiver can control the size of its buffer uh this is mostly due to the fact that in quick once you acknowledge data you basically commit to having it buffered so uh quick Wick has a model in which basically you cannot"
  },
  {
    "startTime": "00:20:01",
    "text": "send any data unless the receiver permits you to send that data first in the exact amount that receiver specifies uh so one observation here to start is that web transport is inside the quick connection so web transport is subject to all of the quick flow control mechanisms uh so to that extent you cannot actually buff for infinite data so that is not the specific issue what we're dealing here so what do we mean when we say web transfer flow control and next slide uh the problem we're having is that the web transfer sessions are kind of like virtual quick connection since I want big quick connection uh and that big quick connection has some set of resources like stream like bites data on streams and in numbers of individual streams opened uh and there is a global limit that is shared by all of those virtual connections uh but we don't really have a way to but there is nothing inherently preventing one connection just from using app all of those resources which would mean that the other streams and that connection other virtual connection sorry other web transport sessions that connection cannot send data and neither can like HTTP traffic that is not part of web transport uh and uh this is applies so I would usually talk about this like as a browser and browsers client to server but this also applies on the server to client Direction uh because if you have some application backend running on Server doesn't necessarily know what is sharing the resources with in terms of auor application"
  },
  {
    "startTime": "00:22:00",
    "text": "backends uh next slide so that is the problem and there is some argument as to why this might not be necessarily a problem so first of all the observation is that at list in browsers we generally don't share connections uh don't pull unless you're already connected to this same website and that is mostly originally was done for privacy reasons uh but that also add means that you cannot effectively dos one of the we websites that you share connection with unless you're on the same domain uh so from that perspective it is not necessarily a security issue however the counter counter point is that it's a still a robustness issue uh imagine you have a web application and like it's a chat client and you open free tabs for different chats and all of them will open web transport or even not CHS let's say video live streams or media streams uh they don't necessarily know about each other they might share the traffic uh and uh typically web applications do not actively synchronize State between tabs and they go out of their way to do that uh and this would lead like if we let one tab accidentally run out of flow control resources on this web transport connections and other suddenly will start mysteriously working uh stop will storry others will mysteriously stop working uh and now this is actually really painful to De buug because you're viewing live stream on one Tab and on that tab it's using Apple resources but"
  },
  {
    "startTime": "00:24:02",
    "text": "the tab that doesn't work nothing happens there and you don't necessarily even know it exists unless you're looking from the server perspective uh and so our second Counterpoint is even when you're connected to the same website the same domain can operate multiple products that are offered by multiple teams that do not necessarily operationally interact outside of sharing the same load balancing infrastructure uh next slide uh so and another observation is that another reason we do it is that there we provide flow control in H2 uh and it's flow control effectively per session uh so when we Bridge H2 to H3 we we end up in a weird situation where one of those is flow controlled another is not flow controlled now the proxy has to deal with it somehow uh next slide so we have four proposals uh they're named a b c and d uh the first proposal next slide is uh proposal a and proposal a is uh we go through the counter points that were just brought decide that we for some reason may choose to not care about any of them uh ignore them and just decides that we're fine with leing web transport over AG free as is with no flow control mechanism uh so the second proposal uh next slide second proposal is a proposal B also known as the hence proposal it does"
  },
  {
    "startTime": "00:26:02",
    "text": "not have a draft dedicated to itself but I outlined it before on the GitHub issue for Max streames next slide uh so the idea of The Proposal B the idea of The Proposal B is that we solve the problem where one web transfer session can exhaust Resources by making the sender somehow enforce the limits uh and this is not that farfetched we kind of do that in browsers already when we do pooling that we we can throttle requests from one origin and do things like that uh so the general idea here is well let's assume so the problem here is uh we in order to for the sender let's say a browser to enforce resource limit on every session it needs to know how much resources it has in total and it needs to know how much resources each section could get uh and the problem is that the way quick is designed is right now it doesn't really give you that information the way it works is a say something like uh Max streams uh equals 100 and that means uh I okay this it it can tell you you can open streams uh the 100 streams but that doesn't mean that if you open 100 streams and then close them back it's not guaranteed that you'll get extra 100 streams uh some implementations will do that that uh but there is nothing in"
  },
  {
    "startTime": "00:28:01",
    "text": "protocols that guarantees that and some of them might in fact decide to scale down your flow control window based on sound factors or scale it up uh so the solution here is hence uh which is the solution here is we're going to give the sender some information from the receiver that will let it figure out how many exactly streams uh per session are allowed to be opened uh and the reason they are referring to I'm referring to this as hands is that they're not really like stract limits you can choose to not enforce them but it is in your interest as a browser to enforce it because otherwise your application performance will suffer uh next slide slide uh so the overall ideas in model I'm operating here is that there is some total max number of streams and some of those streams are HTTP streams and the rest of those streams are web transport streams uh and we are going to assume that every session gets some fixed number of streams and by the way I'm saying Max streams but you can replace is with stream data limit it it's the same print approach and uh so there well roughly a for this formula with four variables Max sessions is a variable that's known to both parties already since we send it in the protocol it's something that the server decides and tells to the client uh and now the client wants to determine Max streams per session in Max HTTP streams uh so there are two ways that can do it next"
  },
  {
    "startTime": "00:30:02",
    "text": "slide one is the sender tells it that by the way I will allow you to open up to 128 streams at once and then and you're only allowed to open up to 10 sessions and then the browse the user agent can decide how it's going to allocate those between HTTP streams and web transport streams and B on that it can decide okay there are 10 sessions they get 10 streams and then 28 streams are for reserve for each for your requests uh and the alternative approach which is actually even more simpler because everything is decided completely on the on the server is basically uh you send the max streams for web transfer and Max HTTP stream so it can explicitly so you get to decide all limits on the receiver side uh that's basically both of those can be sent as HTTP settings and next slide uh the general Advantage is that it's really conceptually simple uh there are two setting one or two settings that you need to send uh it's really easy to implement you just look count your number of streams before opening and if it ATS a limit you do not allow of course there are two big disadvantages and I feel like a lot of our discussion today is going to be around whether those disadvantages matter and how much we care about them and whether there are more disadvantages that I've not thought of uh number one is the this is model only works if all of your transport for session get a fixed number of uh"
  },
  {
    "startTime": "00:32:03",
    "text": "streams uh or stream data and they're equally allocated and that is kind of on one case there are cases in which you might want to do that heterogeneously or there are cases in which you would be able to like if you're talking H2 to the back end and you know already what your limits are you can just propagate those limits directly to the pier uh and this is not something you really get to do here uh so if you have any limits Mis limit limit mismatch between the ends of the proxy you would have to buffer uh the second limit is uh basically since this is a mechanism that is advisor it means if the center decides to not what I already mentioned that the cender it is in sender interest to implement those limitations if it decides not to that means that every receiver by which I mean every potential application at the end of the receiver has to handle up to Max session times the number of resources that it has uh that it would normally expect to handle uh so that is roughly the outline of proposal B now next slide is uh uh proposal C that has also been in various forms brought up uh is that we somehow uh move this problem from web transport layer to Quick layer uh next slide and there are various similarly shaped proposals that I've seen I'm aware of there's two with"
  },
  {
    "startTime": "00:34:01",
    "text": "internet drafts and one with that is not to draft but kind of conceptually implemented as an API uh is the idea is that well what if we make quick layer aware that there are stream groups or name spaces or what you call them and they have some internal limitations and that way quick stack can do flow control for them and quick stack already does flow control control so it can do FL control for them too uh and this is gives you properties that are very similar to proposal it says SCE slay proposal B but we're a number so so it's actually proposal D that Eric is going to discuss except it's entirely implemented on transport layer uh next slide uh there are some advantages and disadvantages of this approach Advantage One is I feel like there are many uses of this and whatever work we would do in area of multiplexing quick connection to Virtual quick connection would be applicable to other applications potentially which is good uh and that we won't have to do any flow control Logic on web transport layer because it would be quick layers problem and quick layer already deals with flow control and there of course the obvious disadvantage is that this would block a quick working group because it's not in scope of web transport working group uh and uh there is a lot of things to bike shed there as I mentioned there are at least two draft there and the drafts have uh uh very different opinions on how to encode things uh and as I said it just unclear how useful while it is potentially useful outside of web transport it's not necessarily actually"
  },
  {
    "startTime": "00:36:01",
    "text": "useful outside of web transport so it's unclear how much was at work would be useful uh next slide uh is uh option D and this is the uh Eric you're muted how about now all right hear you click a few more things how about the next slide all right let's uh go to the next slide and one more interestingly both of those slides are marked as skipped in my copy of the presentation um so the general idea here uh so we we've just talked about kind of what would it take to add a a hinty kind of of thing we've talked about what would it take to change quick to make um flow control happen there uh the other option that we have is to uh bring flow control to web transport directly um the general idea here is what we did in H2 is we said hey um we've got these different layers we'll look at a diagram for that in a second um but we don't really want to bring forwards the way that H2 does flow control we we rethought that bit when we built quick and we're looking for something that is is specifically separated out to look like quick um could we use that in H3 as well so we brought a bunch of the quick frames that were necessary for flow control in as capsules for H2 next slide please what if we just used those same capsules everywhere so we've already got the logic that knows how to talk about that we've got all the text that knows how to talk about that it looks very familiar to anybody this used quick because it's the same thing um we do it over H2 there's no reason we couldn't do"
  },
  {
    "startTime": "00:38:01",
    "text": "it over H3 and that would layer nicely next slide please so this is a diagram that we've seen uh quite a few itfs ago uh it's not necessarily a perfect diagram but it's kind of trying to make the point that on H2 you have a web transport session that is on a given uh connect stream and everything happens within that single H2 stream and so you have this top level flow control for the Stream scen that becomes uh essentially the the global how many bytes can go through for web transpor but then you also want to be able to say how much data of of actual application data can go and I I don't want to block that top level allowance um for my control frames I still need to be able to get my control frames through and and be able to do that um and similarly datagrams are kind of accounted differently because we don't really Flo control them the same way we we FL control them by throwing them on the floor if we don't like them um next slide please and of course we know that this is different for ag3 because the web transport session is outside of that connect stream it's it's kind of this top level construct within H3 and so we have these native H3 streams um and that's kind of nice because we can already we actually already have flow control for every web transport stream um so we don't even need to bring over all of the stuff that that we had in H2 we really only need to bring over the things that are missing um so if we go to the next slide we had defined a entire set of capsules for web transport and some of these are H2 some of these are H3 this is a long list it's not super fun trying to read through this all and make sense of it so if we go to the next slide I categorized a bit um and then there's this giant question mark in the middle of this and we'll talk about that in a second but fundamentally H3 has drain web transport session um perhaps we should bring that to H2 as well if needed um both of them use datagram and H2 is about to start using close web transport session um H3 already does and"
  },
  {
    "startTime": "00:40:02",
    "text": "then we have the equivalent of of stream frames as WT stream we have padding which we don't need because that's natively rh3 and then we have reset stream and stop sending which of course you can just do on an H3 stream so you're in good shape um those are all kind of the the main ones that you need to have streams working and then there's flow control which is basically Max streams stream data and Max data right you have the number of streams you can have for each stream you have a certain amount of data on it and then you have the certain amount of data that you can use globally um and then there's blocked variants of that to a and boting just like we have H3 and everything else however I put a giant question mark on here because this isn't really the whole story so if we go to the next slide I've now added colors and dashes and rearranged things um but fundamentally uh what I used the the green dashed box to me is in H2 WT stream is a capsule in H3 that ends up just being the native H3 stream sending um data on that stream directly um same thing for reset stream right if you if you're in web transport Bri 3 when you want to go reset a stream you just send a reset stream frame you don't need a WT reset stream um capsule and so datagram and closed web transport session are the two that actually show up as datagrams we send HTTP datagrams um for both H3 and H2 so those are actually truly defined for both um but there's an equivalent concept for all of these um that are that are in the in the green box as well the notable one here is WT Max stream data that's what we were just talking about we have H3 streams they already have their own flow control we don't need a new way to do that we've actually already brought all of that budet in and all of that already applies to H3 we're in good shape there so what that means is that there's really only four"
  },
  {
    "startTime": "00:42:01",
    "text": "things left and that's conceptually two of them plus blocked variants for each in H2 that we don't have in H3 and that is in fact the flow control capsules and so if we wanted to um what we could do is simply move those over so if we go to the next slide we could just take those and say hey you've got a Max stream limit that allows you to limit the number of streams that each individual web transport session can uh can consume um so now I can have one session that doesn't impact other sessions or or other HTP traffic on that H3 connection and similarly I've got Max data which says within that session can I have a limit that's lower and we tend to use that to lower the memory requirements for a given session while still allowing any individual stream to use more than a very small amount so if I'm going to allow you to have 100 streams and I wanted to give you a megabyte per stream that might be fine but I don't really want to give you 100 megabytes and so I might have Max DD some lower value that is how much memory I'm actually willing to use and I'm basically saying you can use almost all of that for any individual stream if you if you should so need it so that's kind of the the main thrust of the entire proposal is take those two plus blocked variant remaining things that don't have a equivalent in ag3 where where we need to be able to say um you know please don't overwhelm me with this that or the other uh and and bring them to both the other place that this came up is when we were having some some of the conversations around uh when do you look at settings and how much does a server need to buffer before you um before you're allowed to to send things and do we need to can we handle incoming requests before we know what session they're for and things like that and one of the things that came out of that was that having some form of flow control uh makes story they much much simpler um so ideally we can take these make them look"
  },
  {
    "startTime": "00:44:01",
    "text": "the same across all the different versions of web transport we can even reuse the same capsules uh and that's essentially what the document here proposes so next slide please it's really just those four capsules this is them with fewer lines around them but it's really the same thing next slide please we wrote all this down in the thing that you can go click in the PDF that we'll eventually have for this um in case it's useful and if we go to the next slide that is happily our last option so we very much have a do nothing which I think we're we've been making a pretty strong case that that we don't want to just do nothing um but we essentially have different layers in which we could add the flow control that we need um and having explicit flow control uh rather than a hint is not a particularly huge lift over having that hint so that brings me to the end of this all I don't know David did you want to take us through the rest specifically the time P sorry I stepped into the other room at exactly the wrong time um I think let's see what is our next slide like I yeah go to the next one Bernard um 541 uh yeah uh so oh weird I thought I had put all the options on that slide weird oh I guess we oh right we didn't update the pdf version anyway this is good so pretty much what we're looking for is like the ideal outcome of this meeting is we walk away with uh one of these options that uh that we like and then kind of go from go from there um what"
  },
  {
    "startTime": "00:46:00",
    "text": "are people's thoughts just go ahead Bernard I think you're you're first yeah um I guess I'd like Victor and Eric to just talk about the differences between the two I mean I think Victor made it clear that the hints one is simple because it's only on the sender side um but I'm wondering if Eric would talk about like what additional work would be needed and maybe what the advantages he thinks there are over Victor's hints sure um so I mean fundamentally hints as a hey this is kind of what I'd like you to do and it might work and it might not be there I think is is deterministically less fun than saying this is how much I'm willing to support for you uh that's also a a bidirectional thing um so if you're sending me data as a client I need to be able to limit how much you can use and I'd like to be able to do that in the the case that I described where the the max data uh capsule is used to be less than anything for the the sum of the streams so if I'm relying on just the fact that we have uh Stream flow control in H3 that isn't actually sufficient at a at a session level um and I don't know that the hint covers that particularly well um happy to be wrong there but but yeah I think I think the the the main thrust of it is is that the hints and the the signaling necessary for it are not massively simpler than just doing the real thing with the extra two capsules um and so the value of having it be the same across different web transport versions and having it actually be a concrete"
  },
  {
    "startTime": "00:48:03",
    "text": "this is how much you can send in both directions are in my mind the the biggest advantages but there may also be others thanks uh Lucas hello um can sorry um maybe I missed it on the slide 40 but I'm not sure if if the ordering is the timeliness that we think that what we pick is going to deliver or something but I don't think that matters my comment um deferring and like saying We'll add it later doesn't seem very good to me because like people want to ship stuff now and they might deploy some apps and then they don't want to have to come back and worry about this stuff um hints just seem like a load of problems of like yeah we'll have a standard you know interoperable something or other that doesn't really work except for kind of manual like oh it works when you speak to my server or the server I developed and then I want to bring in a third party intermediation or whatever and suddenly things stop working very well um so I think I I haven't spent much time considering but having something a lot more strict and mandatory feels better even if that's going to take longer to do um and that that my question would be then of the options like the final two C and D um put it in quick or put it in web transport which of those two would be more timely I don't know and I don't know if we need to know to right now and speaking as chair with transport and since you're the chair of quick my gut feeling is that things would probably be more timely in web transport because the applicability would be just"
  },
  {
    "startTime": "00:50:03",
    "text": "to web transport we could add it to the existing drafts process-wise we'd have nothing to do whereas if we did it in quick we're talking you know a brand new Adoption call plus reasonable discussions about wait this is applicable to other things have we considered X Y and Z which kind of opens up the design space so expediency is not our only goal but it is one of our goals and I think doing in web trap sport does will get there faster yeah that would be my kind of inclination again like I said I haven't considered it as much as others but doing it here seems better and maybe you know in some Far distant future we decide okay this is something that we could kind of subsume back into the transport layer maybe and and kind of come back to the drawing board in a few years time and make web transport V2 or something awesome thanks uh Martin yeah I I think Lucas pretty much said what I was going to say I I think of the the four timeliness approaches I think we need something mandatory uh Lucas's arguments about oh I introduce a new type of intermediary and it doesn't happen to to implement something suggests that the this sort of only sometimes uh doesn't doesn't really work out very well so um I'm I'm all for the first approach here and I I think given the previous discussion I've I've been advocating for doing the work here rather than uh taking a dependency on on something more General and quick thank you uh Victor oh four approaches listed in the slide more inclined to pick either one or two"
  },
  {
    "startTime": "00:52:00",
    "text": "uh and depending on whether we pick one or two I will have the different feelings about the four proposals that are discussed so I'm not sure like I can those are completely decoupled okay that's that's a good point I'm going to let's have Eric and Bernard speak and then we'll ask questions specifically about this um thanks Victor yeah I think uh brought up a good point there as well um the the other thing that I think really I definitely think doing it here is a fine thing to do um if in the future there existed a better session or group of streams concept with him quick it would not be super hard to rev transport to to do fewer things um there is some nice niess to having it be reusing an existing mechanism that we use for H2 because I don't know that we're necessarily planning on putting a lot of energy into making groups of things in H2 and it doesn't really apply there anyway um so from that perspective having it having it shim that into what we have for age three and then if we want to go and make something happen in quick we can always go and make something happen in quick and then rev to pull it in in the next version of web transport we've already talked a lot about how we do version negotiation um exercise that version negotiation be totally fine but I I do think having it be mandatory especially for intermediaries that are trying to forward potentially in between versions um saying hey I've got this mandatory pipe Upstream where I have specific flow control requirements and then on the other side it's kind of gonna be Goosey Goosey please try to not screw it up um makes it really hard for for those people to do any kind of sane forwarding that doesn't involve them just doing a ton of offering thanks Eric Bernard yeah um so I agree"
  },
  {
    "startTime": "00:54:03",
    "text": "uh that I think it makes the most sense to do this in web transport um my personal uh preference would be of these Timeless approaches number two which is make it mandatory for pooling um I don't know if that addresses all of Eric's uh scenarios or concerns but um you know pooling has been slow to roll out anyway so you might as well Define it now rather than wait and and then have the pooling implementations uh do that when they become available thanks so let's uh I see you Martin I I'd say let's focus on the the question here the sense I'm getting from the room is I'm not hearing anyone jumping up and down to support three or four um and it's unclear one and two so if everyone could come in and like opine on whether they prefer one or two that would be be helpful Martin go ahead that was exactly what I was going to do um I don't think this works um if we if we only make it mandatory for pooling if you think about uh the potential for a connection to be used for htttp and web transport concurrently having some limits on the web transport components is still probably necessary even in the case even in that case so you only have one session on the connection but you have other HTTP requests being made now um maybe people have in their minds that poing is I want this connection exclusively for use of web transport but that's not at all the The View that I had and if you have that possibility and you have a front end that's sending some requests one way and some requests to a web transport session then um you you end up in a situation where one can starve the other and having some sort of session level control would be useful there thanks Martin"
  },
  {
    "startTime": "00:56:03",
    "text": "Eric yeah in terms of One Versus two I kind of end up in the in the same place of of doing it just for pooling ends up being almost more painful um I think there's there's enough places where the am I doing pooling do I have a weird bug do I have a different implementation I think being consistent there is is helpful um I'm trying to think of of other places where there's a capability that we'd be missing um so we can we can walk through that exercise but I think having it just be mandatory and saying hey like here's these two frames you need to be able to figure that one out um is not a huge lift thanks Eric Victor uh I'm more in support of twoos and one from General perspective it's easier for implementers especi those who don't need pulling uh and we really don't want to make them do extra work because we already make to do some a lot of work that somewhat vaguely unnecessary and I don't think pulling really helps in case when you only have one thing on connection and that's your web transport now that is from theoretical point of view from practical point of view uh I don't think number one would work because uh drafo two is already exists and it's already deployed for non-poled cases and it does not require pulling so uh if we're going to make try to get people to upgrade to something that is dramatically more complex for no value I don't think they will just do it we will be stuck with draft 22 for a long long time Victor just to clarify your last Point"
  },
  {
    "startTime": "00:58:01",
    "text": "are you saying that browsers wouldn't update to a new draft if it oh the browsers would update about the server vendors is like the problem is not with draft 2 with versus a version future version of mandatory poolings if problem is we already support a version that is easier to implement so if uh people are faced with option with supporting the verions that is easy to implement a supporting a version that is not easy to implement they will go gravitate for one that is easy to implement yes though browser have the ability to deprecate draft O2 at some point right H subject to web compatibility constraints okay thank you uh Alan uh I guess I wanted to ask a question clarifying because we we're throwing pooling around but then Martin raises this point and do do we have the right definition does pooling are we only talking about having more than one web transport session on a connection or does pooling refer to having regular HTP requests and web transport sessions and like do do we have a good understanding of what that means because I think maybe my answer if we were if it was only ever web transport uh on a session then I kind of would feel more like to in the realm of possibility but if we think that like there you can always send like get requests and stuff on the same connection as web transport then like it seems like we have a problem that we have to solve so I do I'm just not remembering if we have this written down somewhere what it means and what the requirements are so the my understanding and please jump in to correct me if anyone disagrees is that by pooling we meet anytime the web transport session has something else on the connection so and that could mean get it could be a second web transport so like the non-p pooling just means you have a onetoone mapping from your web"
  },
  {
    "startTime": "01:00:01",
    "text": "transport session to your quick connection underneath okay and then when we talk about what browsers have currently implemented nobody has implemented sharing any it's it's there's like there's one HTTP transaction which is the web transport session and that's it that's correct for from all the browsers I am aware of at this time uh but Martin or I guess Martin's gone but if someone from mozzilla or Eric from Apple wants to jump in I I believe you're correct David um okay and then I guess the other question we were just talking about server vendors and I guess I don't know how many server implementations of web transport there are out there and are there lots of sort of bespoke ones or is it like you know sort of the same set of people for example that have quick implementations and HTTP implementations um that we're talking about I guess I don't know yeah there there aren't that many alen um a lot of them are in I'd say they're very early that's certainly true of ours it's very early uh I I'll yield the floor back I'm still mulling over my answer thanks Victor uh yeah so the support pulling means different thing from the client and from server so from the client specifically browser there is a very uh specific meaning I'm not sure how clear it is in W3 back and the fetch spec that in the interaction between those two uh but when we do not allow pulling for web transports that means once you create web transport uh once you I'm sorry once you create a web transport object in a browser we will create a dedicated"
  },
  {
    "startTime": "01:02:00",
    "text": "connection for that specific JavaScript object and nothing else will interact of it uh and that has some nice properties like you can change how you do TLS certificate validation but it also means that the saying is basically in its own Universe uh away from all other web networking uh now what would happen when we allow pulling is the step one we have a generic establish HTP free connection which is like we use for all traffic that is from client to server when we've try to F HTTP free and the first step would be we will attempt to negotiate web transport support potentially web transport with pooling support and if the server supports both of those that means great now we can flag this connection as the connection in which web transer session can potentially go once uh your request once you open a web transport object that allows pulling uh from the server perspective it's a little bit different but the way you already have a way to enforce no pooling on servers the way you enforce it is you basically decline or all HTTP request and then you only allow one web transport session per connection and that's it there are still some control streams that are related to H free but those are static and uh uh they you do not need to open more of those so this don't particularly factor in flow control thanks Eric yeah I think when we're talking about kind of the the previous versions and that kind of thing like there's a huge amount that's different um since those previous versions so like people"
  },
  {
    "startTime": "01:04:00",
    "text": "are going to need to move at some point or not in which case that's frozen there's nothing we can do about it but I'm not I'm not sure that I would make huge choices about what we do for the future things in web transport based on on people who are stuck on an old version because like the diff between draft 2 and where we are now is not small but yeah I think in in terms of pooling and stuff like that uh Victor's point about the server can always decline to answer other requests or or have other streams come in so it's not like you can't prevent somebody from from doing that and in fact if you uh use your flow control to set the maximum number of sessions to one uh you're in almost pretty good shape to to have rejected ruling anyway um you just have to deal with rejecting other HTP from us so I don't think that's a I don't think that's a a huge decision Factor um in terms of whether or not they sh be mandatory Victor uh the we actually only have two backwards incompatible changes between draft two uh one of them is we re numbered a bunch of stuff and two of them it's we just allowed a frame we just allowed you to put frames before web transfer stream uh magical bite uh but as in that they're mostly the all of other changes we did were backwards compatible uh is kind of really nice because I think we actually shipped a lot of them like the goway we have code for that uh yeah even if you don't believe that this would be a practical problem in terms of deploying things which I believe because I think I'm not sure about web apis ver their long story"
  },
  {
    "startTime": "01:06:02",
    "text": "of vendors and introducing apis and then introducing a much more complex API that does things better and then never being able to deprecate the old API because complexity Gap but and just a practical situation we might find ourself in but I just even on Purely conceptual level I do not believe there is any particular reason to uh do flow control on what we in browser serer as dedicated HTTP connections for web transport because there that is literally does not do anything uh uh thanks Victor I just wanted to jump in as as individual contributors to say on the topic of servers disabling uh pooling it's pretty straightforward um to just put your server on a different host name and that way like you're not going to have any get requests or you're not supposed to and if you get anything there it's very easy to just like close those streams um though oh I'm realizing as I say this that it could take some flow control credits so anyway maybe not as easy never mind so in terms of where we go from here I've heard kind of support for one and two and it's not absolutely clear that we have a like clear clear winner right now perhaps maybe we switch gears to talk about the um the propos for for a bit and see if that conversation might be more likely to land on something Bernard can you go"
  },
  {
    "startTime": "01:08:02",
    "text": "back to the slide that has the four of them I let's see which I think it's actually a 421 oh thanks I mean that's what it is in the latest version but we forgot to update the oh PDF on on me EO yeah so so it's probably one of the early ones let's see yeah slide 16 there we go thank you all right so I haven't heard anyone speak in favor of doing nothing um but you know you still can um what are folks thoughts here do they have strong preference on one of these proposals um Victor go ahead uh as I said my position depends on whether it's mandatory or not if it's mandatory I'm in favor of B maybe even a if it's not B both B and D are fine uh okay thanks Victor anyone else have opinions Bernard yeah uh just speaking for myself I I basically agree with Victor that uh making it non-mandatory I think would uh make b or d sensible but if it's mandatory then probably I want I want a maybe okay thanks uh Victor uh I wanted to give some probably meta commentary as to explain why I feel so strongly about the complexity is a protocol so pleas which I feel might be"
  },
  {
    "startTime": "01:10:02",
    "text": "useful to some people so back in the day the only way you could use unreliable transport on uh web was RTC data Channel RTC data Channel if you wanted to use it in client or server setting required that your server ships an i server and dtls implementation and the user space s CTP on top of that uh and uh it was and this combination of a lot of stacks and parts that nominally do not do like Parts like ice ice nominally did not do anything but we still it it was still there and you still had to read the 100 page RFC to find the five pages that tells you how to not Implement Ice uh things like that uh or the major reasons people found RTC data Channel unsatisfactory and it was basically never widely adopted by web developers as much as say websockets and people even do things like conferencing over web sockets just because data channels were that bad uh uh web transport motivation for existence uh largely arose from the desire to rectify the situation and provide Solutions that is simple and for which we can uh maybe not quite at websocket level but have a similar level of diversity in terms of server side implementations and that people could usually is easily use them uh be because of that I feel like not adding layers of complexity to the protocols whereas they're not necessary I feel is an important sell is why one of the basic reasons web transport exists and if we add too many of those we're basically to the situation we found ourselves of FC"
  },
  {
    "startTime": "01:12:02",
    "text": "data Channel thanks Victor um Bernard are you getting Q or was that a straight hand H straight hand okay Eric so on one hand yes it's good to reduce complexity and I don't think any of us are trying to push to add excessive amounts of complexity um I think there's one of the reasons that people tend to use websockets is because it's there and there isn't a better alternative that that better meets their needs um and part of the reason that it's there is exactly as you say we have a diversity of of servers that can use it and a big part of the reason it's there is because there isn't really a great alternative in the web platform of today that does doesn't dive into into some of the um things that were built with a very specific purpose in mind I think that's a little bit different than just it's complex it's also complex um the main point that I'd like to make there though is is between BC and D I don't see a huge Delta in complexity um and a big part of that is that that complexity is not necessarily exposed to the web platform directly right these are things that happen under the covers that control when certain promises resolve and things like that but it's not it's not saying hey this is way more painful and so in my mind that suggests that most of the complexity is on the server that needs to implement these things um and that is also the place where flow control is uh I guess it's necessary on both sides really but it it is also important on the server um in part because you need to be significantly careful about how many clients you're willing to handle at the same time and how many resources you're willing to give to each client um so I don't think that pulling in um"
  },
  {
    "startTime": "01:14:00",
    "text": "something that we've already implemented that looks exactly like the thing that you implemented for quick that looks exactly like the thing that you implemented for H2 Etc um is actually massively complex now we know that flow control in general is complex but I think we've we've established here that me that that option A of doing nothing isn't a a option that meets our needs in other areas so if we're going to have to bite the bullet and say yes we do in fact need to offer some kind of flow control I think that to me does not say oh my God nobody's gonna want to implement this because it looks the same as the other things and I don't want to type that or I don't want to use my implementation from there over here or anything like that uh thanks Eric before you go um I think I'm reading between the line on which of these options you like but could you just say it explicitly sure um I mean somewhat unsurprisingly I think where we land is that D is the best option architecturally I kind of like C but I think for for timeliness reasons and the let's not stall out making progress on making the perfect General thing um we would probably need to yield on doing C and do D for now and we can always come back and do c again um I struggle a lot with with B because it feels like it it adds the illusion of doing the right thing and doesn't necessarily actually have the the effect that is required um and so it it feels like a solution that that gets you to a place where you feel good about what you're doing but potentially still have all the same problems you did before thanks Eric um the sense I'm starting to to get is that if the um question question from the other slide were to only require this for pooling D is starting to look like a a winner to me so if you disagree"
  },
  {
    "startTime": "01:16:02",
    "text": "with that please get in line to tell me why um okay alen okay I was in line before you said that but um I'm not going to tell you that it's I'm not in disagreeing with what you said like uh I guess I want to say okay I'll allow not disagreeing okay um I don't I don't think we should do nothing here and I I'm not hearing a lot of people advocate for C but I want to just sort of add my voice to say like I don't think C is the right thing in addition to the timeliness factor it always it might be the right thing someday but I've always had this weird feeling about web transport is trying to offer the quick API to applications and if in order to do that correctly we have to add more features to the quick API then we create this sort of like weird circular recursive thing or we have to like say like oh well yeah we created stream groups but web transport can't actually use them we created them so that we could Implement web transport um which would just be weird so I think there's lot I think it's just one more reason to like not really consider C right now um and I think in terms of like the complexity it and there was a discussion about like how much we want like this protocol to be a success and we want people to use it the way that they have used websoft but I don't necessarily see that the adding flow control or the even if it was complex I don't think that's going to be a barrier because that is going to be completely hidden to basically the 12 people on this call plus like I don't know 12 other people in the world that are like implementing this in browsers and in the like 10 most popular servers and um I think they could probably also you know if you got to even if you had to and and it was mandatory to implement flow control and you just and you weren't going to support pooling you just set everything to the max probably and like pretend like it doesn't exist um and I think Eric's voice is really"
  },
  {
    "startTime": "01:18:03",
    "text": "powerful here because I think Eric is the only person who's implemented it um and he keeps saying it's actually not that bad guys so um I think maybe one path forward might be to say that this is how we're going to go forward is with d and get interoperability on it to force the I don't know three or four other people on this call to implement it I'm looking at myself also who's like in the I don't really feel like it today Camp um and then kind of come back to it and be like oh well it really was a lot really complicated or really it wasn't but I think there's a lot of like uncertainty about like oh it might be complicated or I don't want to um and that's kind of in the way of us choosing what's probably the right option thank you all right just to the um having implemented at part uh so yeah so we we've got the stuff that's that's um prototyped and uh I don't think we've we've finished all of our H3 stuff so if you go try to turn that on right now I don't think you actually see it any anybody can see um so uh that said one of the one of the things that does come up as we talk about um how flow control gets implemented uh is very much this like hm how are we representing like the fact that these different streams are all part of this session and if you close the connect stream we'd have to go back and view them and it turns out that like a lot of the same like there's definitely challenges there but as far as I can tell a lot of those challenges the same things that you have to do to be able to handle like other errors that occur on the web transport session that comes you to have to kill all of them and things like that so there's not a huge like it's not it's not nothing like you do have to put some thought in into it but as far as I'm aware the thought that we put into it ends up being the same thought as you kind of have to do for the rest of it"
  },
  {
    "startTime": "01:20:04",
    "text": "anyway thanks Eric so this since I'm getting from the room is that everyone can live with d and some folks really prefer it so maybe that's kind of where we go of course you know we we'd confirm this on the list um but Bernard can you go back to slide 40 please all right so assuming for now that we go with option D uh let's revisit this conversation here because I heard Victor and Bernard say that they they requir M for them to be happy with d was to do two so only make it mandatory for pooling and so I'm asking is is two plus d something that people can live with um Victor uh I can live with it so I wanted to comment something about server implementation uh I feel like a lot of people seem to saying that it's okay to make like HTTP fre more complex like web transport more complex because there will be only 10 people implementing it uh websockets is implemented by like hundreds and hundreds of people and I may or may not have implemented one just when I needed one in C++ and like 300 lines when I needed a server for websockets uh you can't exactly do that for AG free even and so H3 is conceptually simple but we still have to deal with CAC uh which was a I consider"
  },
  {
    "startTime": "01:22:01",
    "text": "a major design oversight of H3 and I complained about it on issue tracker but that was too late in the process uh but to answer your first question I'm okay with uh option two plus option D It's perfectly fine thanks Victor uh Eric yeah I just wanted to uh amend prior comments there I think I had a slight preference for one but if if where we end up is is two with D I think that would be a totally fine place to go um and I don't think we've thought of any place where that leaves somebody totally screwed so yeah let's let's go for that thanks Eric um thanks for being flexible appreciate it Bernard yeah I like 2D as well um what I would say is there's a couple of server implementations that don't do pooling and it'd be nice to just kind of get them out there and then once they're out there you know and and they have some feeling for it that they would do pooling and then you could say hey this this extra thing you have to do um and they would you know take it upon themselves to do it but they'd at least get something out there so I think I think 2D is good because it doesn't slow the momentum of web transport in general um and I think we will get we will get pooling implementations you know with all the bells and whistles eventually but we don't have to make that mandatory now awesome thank you uh Victor uh yeah I wanted to comment something about the complexities that I feel like uh the complexity from my perspective does not only comes from the fact that you need to like send the frames and do accounting part of the complexity is that like now you add like your quick layer has its own buffer but like if it's blocked by web transfer layer you now need to like add a"
  },
  {
    "startTime": "01:24:02",
    "text": "buffering layer on web transfer and now you need to figure out how those interact and yeah uh there are also potentially other things yeah so that's that's like there are some complications with stream State Management are not almost might not be apparent but now that more I think about like what would it go into implementing those B I see that there are like some potential rough edges that would be nice to avoid in cases when we do not want to encounter them which is when we done to polling thank you Victor Alan yeah so I'm I am a little curious what what it would what one would look like if you weren't pooling and you really didn't want to do anything like is it just sending one or two frames that's like you get a million and then calling it a day like is that that's kind of what I'm thinking I'm thinking about in htb2 if you didn't want to do flow control like that's what you would do well you're you're talking about the receive direction in which case if you don't want to imposed receive limits you just send hey my limits are infinite the problem is when you're sending if you're uh an application like a server web transport implementation and then your application wants to write and the client says no no I support flow control and you can't write that much you have to buffer the data at that point so you need to implement it you're saying if this you're saying so the server has set a limit smaller than infinity then the client has to handle the buffering is say like if the pier has set a limit you need to manage your sending to respect the peer's limit okay you can't you can't unilaterally just just opt out but at the same time"
  },
  {
    "startTime": "01:26:00",
    "text": "like if both sides are trying to opt out then yeah they can both just set it to a pillion and it just doesn't apply and if the other side isn't setting it to a bajillion then perhaps they needed it but I think there's no like all of those things still apply you can still end up in exactly that same situation if you're not cooling it's just a different number that it's doing it to you so like there's no new like there's no new place where you where you could have avoided back pressure in the past and and can now cheerfully skip it it's just there's another place that could have caused that same back pressure to happen but it's still the same signal to to the client as it were not client server but the the person using web transport so you're not you're not far off like you could just you could just set it to a million Tech both sides could set it to a million but if you don't know for sure that your peer is going to set it to a million then you still have to handle the N that case okay and and arguably that doesn't matter right because like the pier is already potentially not going to set the lower layer flow control to a million and if you're not pooling and that flow control still affects you pretty much equally um and so like you have all the same concerns about hey I can't send at this particular moment and hey I need to make sure that I'm not offering people way to write way more than I'm willing up offering and all that fun fun stuff but yeah so like I I think I think living with living with two doesn't drastically make people's lives easier there but if it makes it easier for people to do I think the other piece is really like to VOR point if we if we discover that this is radically massively painful to implement then like great you know that's part of the point of our ITF process is to is to take that into account so like this isn't like we're here and we're done and we're never going to think about it again um this is more like we're going to take this as a direction and then go from"
  },
  {
    "startTime": "01:28:01",
    "text": "there so I uh I jumped out of the queue to like if that's what you wanted to say then I I had another thing I wanted to say so was that when you were in the CU yeah I still there at the end okay that's fine um so I get and I think it's similar I guess which is like I I my feeling is that we really shouldn't ship this without at least a few interoperable implementations of pooling even though the browsers are sort of in a place where they're like we're not shipping pooling right now and we'll think about it later and I hear Victor saying like H this may not work at all I'm not sure um so um I'm but I really think that we're probably making a mistake if we don't have like some implementation somewhere to show that like all the stuff we designed like actually works and it's interoperable and it's implementable because it would be kind of a shame if we were like ah we think pooling works on paper and then um somebody tries to implement it later and then it's actually doesn't work absolutely and speaking as chair like we're not planning on starting working with last call until we have like implemented every feature of this uh protocol because you're right otherwise you can end up with something that just never worked um Lucas hello um just just to respond to your points David about sticking stuff on different host names um uh with my cloud flare hat on my employer hat on that's not something we support for like websockets if you want to support websockets you can you can but uh we we don't provide an ability to say only support websocket requests on this host otherwise reject everything else and only support other requests on this other host um and do stuff partly because it's easier not to bother and partly because I don't think anyone's everever asked for that um that said we"
  },
  {
    "startTime": "01:30:01",
    "text": "only support HTP 1.1 websockets so some of the problems related to pooling here don't count anyway um and I think even trying to describe that to people um is difficult so yes if if you're deploying these Services yourself sure but if you're trying to sign up to something um any anything relying on multiple host names I find in my experience really rils people up um so yeah I'd like to avoid that if possible okay so I mean we need to make sure that the server has a way to disabling then that makes a lot of sense uh that said in the CDN use case like cloudflare you're probably if you're implementing web transport on your front end and you're allowing this kind of thing you're going to have to implement pooling right and their for flow control I haven't thought enough through to that yet okay or or or or actually are we saying that we need a way in the protocol such as a setting for the server to say hey don't pull on this period um actually yeah the ma web transform Max session set to one um so maybe yeah we sorry that's that's how you disable you don't need to put on a different house name you just set that setting sorry I think that's the answer all right yeah oh cool um all right we've drained the queue I like the sense I'm getting is that everyone can live with two plus d so we're going to declare I mean we're g to check the consensus on the list but sounds like that's our tentative plan moving forward and hopefully the folks who can make the meeting or the second half of the meeting today uh think that's a outcome they can live with um was there anything else that we wanted to use the time today Bernard or"
  },
  {
    "startTime": "01:32:02",
    "text": "should we just kind of wrap up here yeah I think the only uh thing would be is if there's some other action items that we need to uh just check and make sure we do um other than the check on the mailing list yep I'm not seeing anything um okay all right in Lucas Chris yeah I don't want to distract from actual working group stuff but since it's web transport I only realized we're meeting today um sorry about that but um kind of in related stuff kazuo and I published a draft about um quick on streams and hb3 on streams and I saw Victor responded to that in relation to web transport and there's a lot of overlap with H2 on web transport which is not something I paid that much attention to I fully admit um so obviously we're doing the work we are here and part of the discussions we had today related to some of that um I just wondered if there's anything we can do to keep that discussion going if we don't want to keep the discussion going I don't know like Kaz and I are going to carry on working because what we have is a solution to a set of problems that we have um and it wasn't designed specifically to address anything in web transport but if there's some upside brilliant um I just wondered if anyone wanted to comment while we're here yep just before we open the floor I'm going to declare this meeting of the web transport working group over and this is now a hallway conversation um about this draft which I think is great and feel free to use the rest of the time I'll I'll be writing up the consensus call while while you do that um so this is not officially web transport anymore it is still covered by the notwell as an ITF hallway conversation all right discuss Victor uh yeah uh so basically my"
  },
  {
    "startTime": "01:34:00",
    "text": "observation was that web transport over H2 uh is just saying that well web transport is a thing that gives you something a shape like a quick connection and web transport over H2 despite having H2 in the title uh as long as you have something to do like headers you can run anything over it including HTTP free technically web transport doesn't give you stream IDs but it's mostly an API consideration that we chose because we assumed that those things would be proxi and the the stream IDs would not be consistent you can totally get uh the stream IDs and in fact like right now I've not finished web transfer over2 implementation but you basically can take the same application in our case let's sayq and you can run it over web transport over H free you can run it over Rock quick and you can run it over uh H2 I want to say H2 but technically it's anything that lets you exchange headers and looks like a stream so it can be H1 it can be websocket it can be anything so My worry is that you we will end up with two things that basically do the same thing do the multilex streams over TCP with quick style flow control uh and I would basically prefer to avoid that so there was some discussion before in web transportal reach to in fact there is an issue of can we extend the applicability of the protocols that we defined uh to non H2 and the cons the agreement before was uh we will will not formally Define it"
  },
  {
    "startTime": "01:36:03",
    "text": "for anything as than H2 but we would describe how it could run over those protocols potentially uh as a non-normative text so we could maybe spend more time discussing that uh because outside of the facts that like like I do not see any conceptual things other than this ter might issue for that would prevent someone from running uh agree or web transport or whatever yeah I would I would second some of that and I unfortunately need to drop in a second but um yeah it'd be good to talk more about it in in in detail and kind of see what are the needs that we're trying to address because we made a couple of very conscious choices um even before um running any of this stuff over ag2 as as web transport was web transport over H2 it was a very deliberate um attempt to make it so that we could run something like quick over a TCP in the cases where you needing to um and one of the very clear goals that I think we sometimes forget a little bit as we focus mostly on web transport over H3 is web transport is not even really supposed to be H3 web transport is we think that there is a modern way that multiplexing protocols should work um and H3 is the current state-ofthe-art there but if if H4 can't also expose a similar thing or if quick V2 can't do something similar then we're going to be sad right the goal is into to just make a different websockets the goal is to say that this is how you should transport bytes from A to B and uh we are very much planning to offer the same API for quick as we offer for web transporters and the idea is that you can run just like Victor said you can run your same code on quick you can run that code on H3 via web transport and you can run that code on"
  },
  {
    "startTime": "01:38:02",
    "text": "H2 via web transport um and to Allan's comments uh yeah that is tapsy um but it is not I don't think that that concept is exclusive to Taps so uh we also when defining the current set of frames deliberately made it look very much like quick um for for web transport over H2 so one of the conversations that we had when defining that was you could run that over websockets right you could run that over literally anything as Victor said that that exchanges headers and has a b directional VI stream now anything that you can explode out to get better you know independence of different streams and less out of line blocking and stuff is great but fundamentally there's there's absolutely nothing stopping you from running that same thing anywhere that you wanted something that looked like quick over a random TLS connection or a webet or literally anything else yep a random quick stream a um literally anything Soh yeah the the that was very much a a conscious design choice we didn't bother to go write up all the stuff that you would need I know Martin RoR and some other folks have asked about and written up some some documents on how you would do that over websockets and that could be a nice way to to kind of offer a polyfill style thing there but this very was an attempt to say hey we've got quick we'd like to be able to do quick everywhere can we offer that in a way that looks the same as quick and provides you know 99% of the same benefits mod what kind of unreliability you can get under uh so to clarify some things that I I'm not sure like might be very unclear if you're not f ing web trans group originally we started our original design for web transport over H2 was we kind of did the web transfer over H3 say"
  },
  {
    "startTime": "01:40:02",
    "text": "where we took H2 and reused H2 streams as web transer streams uh and then we concluded that unlike web transfer over H2 unlike H3 we don't really get anything from reusing H2 stream since they're all linearly sent over TCP anyways and we had a problem where web transport over AG free was using the quick style flow control and web transport over H2 would be stuck with H2 style flow control so at some point the draft was uh dramatically changed to uh basically be hree or to to run uh quick over H2 but instead of uh quick it's capsules that functionally work the same as quick frames cool um I don't have much to add um just just as usual hallway chat thanks is giving me some some things to consider we will well we're we're planning to present some of this work at Brisbane um potentially between the HB working group and the quick working group I don't think we should waste any time on the web transport session hence we haven't really spoken to the chairs about that um so if anyone wants to come and chat some more um yeah do so be great all right thanks everyone then I think we can call it uh see a few of you in Brisbane I hope uh and otherwise see you on the mailing list uh I'll send out the consensus call uh later today all right bye"
  },
  {
    "startTime": "01:42:19",
    "text": "everyone"
  },
  {
    "startTime": "01:50:32",
    "text": "all"
  }
]
