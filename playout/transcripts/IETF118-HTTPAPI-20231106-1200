[
  {
    "startTime": "00:00:01",
    "text": "sit on this side of the room. Because this is where the chair is, and it's easy. It'll be easier to the flow of the meeting but action where the action is. That's right. But It's it's too early in the week to spend all your working group meeting time doing email. Some Right. Alright. We're at the top of the hour. We'll start in 60 seconds. This side in the room. Yeah. It's what's awkward is the obstructed view with the pillar, Yeah. Just like the old Boston card. Might be good to move the mic a little closer to you, Rick, is Yeah. I know. This doesn't pick up all that well. Okay. Is that better now? Oh, that's much better when you move when you lean in. Alright. I will speak Speak closer to the mic. It A suggestion folks you may wanna sit on this side of the room but if you wanna be, you know, if you got emails to do or whatever, free. I'm just suggesting Feel not a rec not requesting. I don't care where you sit. Particularly. Alright. So Welcome to the 2nd session of I"
  },
  {
    "startTime": "00:02:00",
    "text": "of the 118th IETF? This is the HTTP API working group. If this is not the flight you were expected to be on, please notify your, you know, the gates right there, get out quickly. Alright. Alright. I'm just gonna stop suggesting people move over. Okay. Welcome My name is Rich. Daryl remote is our co chair, Mark Nottingham in the front corner here is our secretary. The session is being recorded. And, we might as well get started. The note well so you will have see you will see this more times than you can count probably bytheendoftheweek. This document which is really an eye chart describes, you know, IITF Policies and procedures, for participation. Don't don't try to have any hidden patents be, responsible for all of these other, you know behave nice, be respectful, be professional, Document copy documents submitted to the IETF? And adopted are copyright by the IETF. And, because, again, just, you know, responsible, mature person, you won't have a problem. Which means I have problems. Know really well. The meetings, you know, again, reference to Dakota contact, which is an RFC 7154. No. I don't have that number memorized. We try to maintain an environment that's inclusive professional,"
  },
  {
    "startTime": "00:04:00",
    "text": "and accepts people from all sorts of different backgrounds. Do not harass anybody else you know, we keep the content and the discussion technical, you can say, you know, this idea that you proposed is not a very good one. Don't say don't say the second sentence, which is, you know, this idea is stupid in your mother dresses funny. Right? Don't not say like I'm not I don't mean to be flip. I'm just try to lighten the mood a bit. Meeting tips in person, We do try to accommodate as best as we can. In this hybrid meeting situation, which is what it's gonna be all the time. You know, there is an on-site tool will pass around. The blue sheet, if you haven't I've changed The QR code there, Sorry. The QR code on that sheet We'll get you to the lightweight browser based client, that's how we do with sign in list. That's also how we manage the queue for people who want to speak. As the chair, see the queue, recognize you. You can stand at the mic if you want, but don't start speaking when you speak. Identify, you know, name, say your name, affiliation, and so on so people know who you are. And for the note takers, Resources kind of a little late, but if you haven't already seen the meeting agenda, there's some links on how to do it information on Mead echo. If you have any problems, technical assistance, just email support at ietf.org. Alright. You wanna start, Daryl? Sure."
  },
  {
    "startTime": "00:06:01",
    "text": "First piece of administrivia here is, we need a notetaker somebody who will volunteer to record all of wondrous conversations we're about to have. Doesn't need to be in Great depths, Rich, you're gonna have to watch for hands because I can only see a small slice of the room. As I'm sure there's many people putting volunteering. Oh, look. That's scamming. We we can't proceed without a minute taker. I can do it if necessary, you only have to record. And if you go to the agenda, There's a link that says point to the ether pad headstock Sorry. CodyMD hedgedock, ether pad, whatever. Shared the the agenda is already in there. So you just have to record the occasional sentence of when we come to a conclusion. Any volunteers? Alright. In the interests of I can help Okay. Great. Okay. So mark mark between Mark and I will get it done. Excellent. Thank you very much. Thank you, Mark. And if, there are conversations that come up on, Zulip or in the chat, please feel free to also add into the the notes, any things that get missed there. Francesca. Welcome back. We also are going through a little bit of a reorganization with regards to the areas. The important thing for us If I understand correctly, It doesn't affect us. We have same chairs. We have the same area director. We just get a new name. And I believe that name is Witt. Is that correct?"
  },
  {
    "startTime": "00:08:04",
    "text": "I don't know how to come. You have to talk? Stand up in front of the room, Hello. Hi. Yes, that is correct, Whit. Web and internet transport. And I've had a a short presentation in dispatch about it. So I I wouldn't want to repeat, but Yes. HTTP API is going to width. And I'm saying the responsibility. Awesome. Thank you. My apologies. 3 AM was a little early for dispatch from me. I'll have to catch up later. Excellent. Okay. So, The agenda as we have it today, we are going to do a brief update on documents that have changed status. In the overall processing. So that will include short discussion on Yamal media types, link template header fields, and problem details. And then we have a presentation on API catalog, and we are going to have some doc discussions around the other documents that have had around them or in some cases, no activity around them. And there's a list of those fields there. We have an open conversation on, adoption of Jason Pointer. And, we have a arbitrary deadline that we set for making a decision on the debt occasions back, before we seed into the first step. Would anybody like to do any agenda of actually Okay. No signs in the room."
  },
  {
    "startTime": "00:10:01",
    "text": "Okay. And hopefully, that the slide this this this time actually fit onto the screen. It was so much challenging lasts time with over all of the large list of things to do. Okay. So when it comes to, documents that have changed status. We have, the Yamal Media type that is in the RFC editor queue. It has gone through all of the IAnA processing, the IAnAX for review. It is actually a media type that is now registered. In the iona registry, it is sitting in the you saying waiting for IESG. Upon doing some research. I'm not exactly sure What? It is waiting from the ISG 4. So, I think Rich, you and I will need to go and poke around a little bit and you can explain to me some of the additional processes as to what it might be waiting for at this point in time. Yeah. Francesca, do you have any clue Francesca's checking. We'll have an a live update during the meeting. Excellent. Link template field Yeah. Is moving quickly through the, the IRT through the process. If you go to arm github pages. I have updated the little flow charts that tell you where the thing is in the process and, the link template is moving quickly through the process. I believe there are 2 open issues, related to this particular document, I believe it there is an open issue mark created related to,"
  },
  {
    "startTime": "00:12:03",
    "text": "internationalization of strings. And so please if you have thoughts and feelings about international internationalization. There's an open question for Mark, and I believe what's holding back. Could Rich, could you look over to Mark and see if you get a non from him as to whether that is the correct problem? He nodded on cue. Excellent. Okay. So, and for folks who are not familiar with the group, we do a lot of tracking of the open issues on GitHub. So while you might see that the mailing list is fairly quiet. There's quite a bit of activity that does go on, via the GitHub repos. And you'll also find links to those get pub repos on our get help. Website, which does introduce a little bit of a circular dependency. We should find a place too. Linked to those more. Is are there links to the GitHub repos on the data tracker page should Sehampton? Yes. They are. If you go to the the the the data track sorry. Datatrekor.itif.org. /wg/httpapi. When you click on the about tab, there'll be a link a resource link to the GitHub organization which has repositories for all of our drafts. Yes, sir. Well, not all of our drafts, which is a topic for the next page. So before we move on, on from our status updates, a little accelerations since last IETF problem details. Now has a RFC number. So that is now RFC Ninety 4 7 and becomes the 2nd completed document out of this working group. Yay. Yay. Hooray for us. Thank you, Mark. Thank you, Sanjay. Eric, if you are in the room. Okay."
  },
  {
    "startTime": "00:14:00",
    "text": "That was easy. Next slide. 1st of is API catalog with Catherine. Would you like to tell us the progress on this document. Yeah. Thanks, Darwin. Hi, Rich. Hi, everyone. Yeah, so Will you be, yeah, you'll presenting the slide here? So thank you. This is a quick one. Just one slide. Can you sec? Here we go. Thank you. That's great. Thanks. So the first working group draft has been published as double 0 And for those unfamiliar, this simply proposes a well known URI APO and dash catalog. Which returns a resource representing a catalog of your API. So if the well man your eye is hosted by example.com, for example, you would expect to get a list back of the APIs that example.compublished and the aim is to facilitate machine discovery automated consumption of APIs, it can also be used by human readers as well to see what's available and how to make use of the APIs and what they're for, etcetera. So so oh, at so itf117 the the idea I think was was well, accepted. What the the the challenge was was the fact that the initial draft under my name. Actually proposed a former for the API catalog based on Linkset. And the, the challenge was to say, well, actually, there are companies out there now who do such catalogs in different formats. So to the decision to make it now up to the implementer that format of the catalog is up to you. You can roll your own. You can use some of the existing structures in this space, such as links or APIs.jason, how rest desk etcetera, ones that you can find. So, the upcoming changes for the next"
  },
  {
    "startTime": "00:16:03",
    "text": "version are, at the moment, there's an API catalog link relation. But we've since spotted that in RFC 573 as some perfectly usable relations for collections, and items which has the relationship between a catalog and the items within the catalog which we can reuse. And also, I'd hope to take any feedback from this meeting on any other ideas suggestions that anyone has. And that's smart then. Any comments, feedback, any So, quick question, is it the intent that collection relationship is used as an alternative for API catalog yes. Feels like it's less losing a little bit of semantics there. I agree. I agree. And this is actually a I had was the NRfc 6573. It talks about an item being able to be part of 1 or more collections. Now in the RFC, it doesn't Go on together, an extra layer of Symantec to say, well, this collections for this and this collections for that. So I was wondering if anyone had any experience of of those discussions and whether that was pointed out at all. Mark? Mark Donning, I'm So I wasn't thrilled about using a well known location for this. Just because, you know, intuitively, you think, okay. It's a well known location, then it it can be easily discovered. But you still have the problem of what hostname to use. And and and because there's a mismatch between the boundaries between organizations and, you know, the hopes There are most organizations have many, many host names. And even when it's the top level domain for that. You know,"
  },
  {
    "startTime": "00:18:00",
    "text": "for that company. They may not have their APIs there. So you still need to know something. It's not truly automated. So then the question is, well, what value does having a well known URI have over having a just a URL. You know, because, if if I have to be told manually, Oh, well, our API catalog is over there on that host. Yeah. You're saving a few characters, but I I don't know that it's terribly compelling. That's not to say I think we shouldn't do this. I I think, you know, it's it's harmless to the final unknown location. It's just not very web like perhaps. But but what concerns me more is the idea that that we're gonna not recommend a format just to have people, you know, do whatever's out there because, you know, the power of standards and running this down in an RFC is where encouraging convergence. We're encouraging interoperability. And so I would hope that, you know, whilst good to support different formats so that we can encompass lots of use cases would at least recommend 1 and and try and steer people towards a default. So I'd really hope that, that, that, that would see that. Sure. Thanks, Mark. So to the first point, yeah, I'll get you there and my company is probably in that same position. Really the rationale was knowing a company's top level domain, Can I query that top level domain to find out where Beth? API catalog is. And it, as you say, it might be on a completely different host. But at least, it it does involve a a guess as to what the top level domain is of a company either typically a dot com, I think, is a good, a good starting point. To the the second point, yes, that that that is fair. There was a, as I say, push back in 117 about prescribing a former in the double 0 draft. It does give a an example of links"
  },
  {
    "startTime": "00:20:00",
    "text": "isn't it doesn't go on to recommend a particular one. So that's something that we take up on the list to see that out of all the the candidate formats, whether there is one particularly recommended or not. Any other comments, questions, discussion? Have a question. It's Yes, sir. Please go ahead. So, for big companies, there may be various groups they may have videos catalogs. So it is possible that there is one catalog for private APIs, which are internal APIs. Maybe one for public APIs, consumable by customers and partners then maybe one for maybe specific partners. Is it possible to have that kind of, you know, different dispatchers from, the main catalog. Hi, Sandra. Yeah. It's a good question. I don't see why not. Certainly the the format should be flexible enough to allow that allow that level Symanti. The the question about internal and private APIs it may be that the well known URI for private APIs needs to not be on the public host. Maybe on an internet host instead, for example, but following that, the concept should be the same. If you hit that well known URI on a privately accessible host, then you should get the private APIs for that company. It's a good point at night and feel better."
  },
  {
    "startTime": "00:22:07",
    "text": "This is Farrell Mill speaking without chair hat. Mark, I just wanna clarify from your comment. Were you suggesting that you don't think there should be a well known URI, or you would thinking that having a link relation of API catalog provides an alternative, so that people don't have to use a well known URI. Okay. Tell me, you know, yeah. Yeah. I'll just, Mark again, this is a really awkward room layout. I, if I were doing this myself, I would not have a wound on your eye. I don't think it's necessary. But I don't have the energy or focus to stop it. So you are supportive I'm looking for a mostly harmless. But the but the word that the you would be supportive of there being a link relation defined in this document specifically to point to something that has the semantics of API catalog and you are not against alternatives, you just would rather there be a default. Or about what the words I'm sure about. For UDDI. So I'm very down on catalogs and role. Okay. I'm I I'm cynical. But, sure. Yeah. This is a that would be a natural fit for link relations. I think that's because then you can have a type attribute that says what the specific format is. If there are multiple possible formats, it it makes a lot of sense. You just need to discover that link relation, and you're all good. And then the question is whether, you know, we we're reusing existing link relations or whether we need a new one, and that's where you need to dig down in the details. It sounds like there was a direction on that, but I I'm not in I don't have that state pitched in Thank you."
  },
  {
    "startTime": "00:24:03",
    "text": "Okay. I think that if there's no one else who has comments that like Thank you very much, Kevin, for providing this update. We shall continue conversations on list and the one other comment that I wanted to make is that I noticed there is not a, I GitHub repo. For your particular, document, So I I have I have a couple of questions. One with being to yourself, like, do you think it would be useful to allow people to comment on GitHub issues Secondly, do you already have a GitHub repo that you were managing this in and and this is more a question to Rich. Should we point to external repos or should we ask contributors bring those repos into the HP API org. Alright. My my preference would be to migrate them over. And then I think there's a way to do it. I forget the details, right, to that preserves all the comments and issues and everything that's been closed. Right? I think even GitHub has it in their UI now. So I, Yeah. They should all be in in that one place. That's certainly the intent strongly given that in the past, it's from when this group started. We had a lot of contributions from GitHub because the warrant a lot of IETF people. Or it wasn't a high percentage of IETF people, and so we decided explicitly to use GitHub as be mean or primary. So, yeah, I would like to like to do that. If I you need help setting it up Kevin, we can talk about it offline. Right. Okay. Does that mean, yes, you'd like help setting it up offline? Yes. Gotcha. Excellent. Thank you. We'll okay."
  },
  {
    "startTime": "00:26:03",
    "text": "And and call call out to other authors of documents, that slide from Kevin with was just a one slider just had a few notes. It was absolutely wonderful and perfect. And saves me having to scramble together the night before to figure out what are the things that we're going to talk about, in documents. So next time it would be great if, you all could provide a single slide like that with updates on documents. Cool. Thanks, Kevin. Thank you. So moving on to, another of our newcomers in the group, bite range, Pat. Austin is is Austin in the room? Yes. Awesome. At Justin Dime, Yeah. I did not prepare a slide deck. It would would have had to do that on the flight here, but would be very short. Bite range patch is a media type for being able to write to a particular site offset on a document which is a normal file system operation. It just doesn't exist in be for some reason. If you want to download like a particular range of a document. Like, you know, I've already have the first gigabyte and want it to be on down the second Yeah. You can always use range requests, but there's no inverse if I'm, like, uploading a live feed and I want to resume my life feed off of the first gigabyte that have already uploaded. Oops. Like, how do I recover from it or, like, that. So the 1 major, question that I'm aware of right now is how to represent indefinitely long rights on in this document because byte range patch reuses HTTP fields and some of the semantics of,"
  },
  {
    "startTime": "00:28:04",
    "text": "multi part, the multi part media types, the problem with, content range field is that it does not support definitely long fields. While HTTP supports like, range responses where the server does not know with the length of the document at response time. It has to know where that bite offset is going to end. Due to the syntax of the content range field. So, right now, it had been right right now, the draft says special cases, a format of the content range fields that just omits that end Number, which is required, this is dubious and possibly fragments the HTTP ecosystem. So I, recently posted to do HTTP biz. Suggesting maybe we should either redo the syntax of that field. Or just introduce a new field So that is the one remaining question, I think. We we have a couple of people in the queue. Do you wanna take questions? Yes. Questions, please. Mike. So HTTP does have a draft currently a opted on resumable uploads. Yes. So But maybe not say that doesn't exist because it does exist. But there are if there are cases where this overlaps, then we should figure out how to reconcile the show. Yeah. Actually, this sort of spun out as, effort to implement reasonable uploads for other purposes that I was doing. And I sort of saw this as a first step. This"
  },
  {
    "startTime": "00:30:00",
    "text": "this doesn't intend to replace any of the functionality that the Rezumable upload draft is doing, but Resumable upload could definitely use this in order to say, for instance, I already I know I've already uploaded the first gigabytes. So here is the offset at 1 gigabyte that I'm resuming. Now there's a number of other ways that reasonable uploads could do this as well. They could just use the content range header, verbatim in the headers instead of as a field within the patch. There's various options there, but Yes. Mario's Clager from Translode. Want to bring up exactly that point that you already raised on the list about content range. I think redefining it or changing its syntax is quite problematic. You're doing it in a special situation where you say, okay. Content range actually not in the header, but, like, in the body of the request. Which is less problematic. But I think in the end, it's still gonna cause a lot of confusion. So if We can use something like content offset as you proposed on the list. I think that's definitely a better alternative than redefining content range. And that's also something, what we probably can work together with Resumable uploads to find a pretty good commonplace. Yep. To just avoid having different solutions for a very similar problem. Yeah. Fully agreed. Either solution will work. There might even be a 3rd or 4th solution that we haven't thought of yet. But Whichever one works better, I think, is gonna be up to HTB biz, like, either way, I think it should be formalized as part of the HTTP standard. And even if it's not used for anything else, like, servers wouldn't"
  },
  {
    "startTime": "00:32:02",
    "text": "be able to automatically start using content offset and and 206 responses. Unless this client syndicate some special support for it. Like, that could be future work But in an event, would have to be a standard that works, across HTTP even if it's only used in this place just for now. Yeah. Yeah. Yeah. Mark, not him. Content range is kind of an awful header. You know, it's from the prehistoric times. And and we've we've run across this problem before. We actually have an RFC that says how to do indeterminate length, content and content range if I remember correctly, and it's a horrible hack. Which we knew was a horrible hack, but it was our only because we had to be backwards compatible with the deployed web. You don't have to be backwards compatible in that sense. So I I I don't see any great advantages from reusing the header just because it looks kinda like what you want. You know, if you are reusing parsers or there was existing parts of the you know, to interoperate with Sure. But you'd don't. And and the existing parsers are mostly in browsers. And and they're so deep in that you're not gonna be reusing them. So I I'd say, yeah, define a new header, make it a structured field if it's if it's gonna be a header, that's that's a vintager. Whatever. Yeah. And and whatever, you know, figure out what you need from that and then just define it. Doesn't have to be part of the HP standard. Anybody can divine a header Tom anybody has said that. And, you know, it should be fine. Yeah. And and if you can make it reusable for other use cases, That's great, but you don't have to bend over backwards to do so. You can make it specific to your use case if you want Okay. Yeah. That's, yeah, very good advice. I do foresee many use cases in the future where this header would be"
  },
  {
    "startTime": "00:34:02",
    "text": "usable particulars in synchronization and other uses, actually in maybe this is used in 206 responses if the client indicates it needs it. I'll make an argument that that that doing, subscription updates could really benefit from this, but that's another discussion. So any other questions? You. Nobody in the queue. Okay? Thank you, Austin. Thank you. Yep. So so Mark, see your turn again. You're gonna get your steps in today. I'm staying in a much nicer hotel. So, yes, I will. Yeah. So we adopted Link hints. This is a specification. As you might recall, to define a set of pre composed, target attributes, we say, in in the language of the web linking specification. To put on to links. So you have a link relation, if you recall, and you have a link target and you have a link context, but you also have these target attributes. And so target you know, when you see a link in HTML, it might have like a type attribute on And and what this specification is trying to do is to come up with a galaxy of, or, well, small solar system of of those target attributes that are specific to HTTP links that make sense, like talking about what the resource on the other end of the, link is able to do in terms of what it accepts, what it produces, what methods are available. Type of the different representations available. That sort of thing. And and and there are hints because, of course, they're not definitive. It's not a contract."
  },
  {
    "startTime": "00:36:02",
    "text": "It's just, a hint as to what might happen if you actually interact with that resource. Using HTTP. And and so, the use cases for this are a little fuzzy. The obvious ones are probably like, API description formats and things like that. But, I I'd put a spec out there a long time ago and kinda let it sit for a while. Enough people kept on on saying, Hey, that might be useful that we decided to adopt it. I think in the last meeting, Yes. Yes. So I haven't really had a chance to to work on the spec at all. Is in the Repo now. I believe we have a I Yeah. So, I think believe it is. Yep. Yeah. I'll probably take a look at it, in the next well, before the next meeting cycle. Nick, any updates that I feel are necessary, if people can take a look at it, open some issues and then then may be shipped Has anybody had a chance to look at this? Have a question. Sure. What was the reason for using the word format to list Media types, content type, seems an unusual literally asked me about a decision I made about 6 years ago. So okay. Well, that there's a I will go in on an issue. So you can think about it while you're reviewing don't think any of it's you know, Chain changes on problematic, so we should you know, you know, feel free to and stuff. Awesome. Thank you. Okay. Okay. Thanks. So, I I'm gonna take this opportunity to make another little soapbox sides side speech in that, Mark has a talent for getting things to move fairly quickly through the process because he's written a whole lot of docs before. We have a lot of First time authors, in this group,"
  },
  {
    "startTime": "00:38:00",
    "text": "And, if there's one thing that I've learned in the last few years is that if documents are not reviewed in detail before working group last call, they will be reviewed in detail in all of the following steps that happen afterwards. And it's kind of frustrating for authors say, hey. I've made it to working group last call. Now we just have to go through this up, and then they start getting piles and piles of of comments when they go through area area directorate reviews and stuff. So it it would be very, very valuable who are current authors, and we have quite a number of docs in the process. If we can get some experienced eyes on those documents to provide feedback on that content. Before. That that that that this this goes to the next stages where they're going to get them thrown back at them. And it's harder to manage those changes as it moves further upstream. Shall get back down off my soapbox. Francesca. Sorry. I'm sitting too far from from the mic. I just wanted to mention that, chairs and ADs and the working groups can request directorate and area review teams reviews. Anytime during the process, if that helps. So if you think that there are documents that will benefit from a first read through, let's say, then it's it you can you know, talk to the chair or to the ID and then we can organize that. Awesome. Thank you. And I'm here to to advertise that we now have an GDP review directorate. So that specifically can we'd have people take a look at that. And and I can assign"
  },
  {
    "startTime": "00:40:03",
    "text": "I I'm I'm leading that director, so I assign reviews to different people. Including Daryl. So you can cause him more work. No. Because they don't just give it to me. Okay. Moving on to our, rest API media types. Now, I believe, Roberto was not able to join us today. Is that correct? Cause I think he was out sick. Yes. Exactly. He's sick. Okay. So I did I did quick review of the open issues that are there and again, if you go to the GitHub organization and you click on projects, There is a project that summarizes all of the open issues across all of the documents and that is up to date. As of late last night, The the open API the rest API media types attempts to define 2 new media type. We'll register 2 new media types. It attempts to register the open API media type. And the JSON schema may be attacked. For the open API media type, there are 2 blocking issues, really. One of them is that the open API education people need to go right to security considerations. And I won't say who's on the hook for that. And the other item is with regards to fragment identifiers for what are referred to as plain name. Fragments. And it appears I also have been the blocking person on that. So, I I think both of those issues can be resolved. Fairly soon. I am much less confident about resolving the Jason's schema issues because I I"
  },
  {
    "startTime": "00:42:00",
    "text": "don't understand them well enough. And so one of the questions that I think we need to answer is, is should we split this into 2 specifications? Is is one question so that we can deliver the open API registration once. And then secondly, the JSON schema as a separate thing, And then the Other question, which is Oh, awesome. Thank you. Awesome. Actually, let's answer that question. Let's see what Austin has to say about that. And then I have one other question primarily for Mark. Hello, Austin Wright. He's like, Yeah. All of the above documents. I think have their uses sometimes, but in this case, like, like, there's only registrations in here in Jason's schema right now. Some of our close collaborators, we've been trying to figure out like, that, venues for publishing and how to publish and how to break it up. Interoperability requirements and that sort of thing. And, Like, this document lacks and then he of the interoperability requirements where we would not be able to published revisions, and have that be backwards compatible with validators written against the version that's I've been published first. So, Yes. Let's break it up. And, Yes. Okay. Thank you for that input. The other open question relates to, the work that Mark, you're running in the media man. Which is this idea of, allowing community format"
  },
  {
    "startTime": "00:44:01",
    "text": "to be registered in the stunneders tree. I think I'm correct in saying that both of these documents both open API and Jason Skema are kind of full under the target of what your intent is for the community standards. And so my question to you is Is there value in continuing down producing these RFCs. As well as I've how do you see the relationship between the doc you're working on and us built working on? These RFCs. Sure. So, Mark, here again. Yeah, that is leave the intent is to make it easier for what are perceived is legitimate communities, working on open formats to register without jumping through the hoops of of publishing or that We're gonna talk about that document, this afternoon or this evening here. My thought feeling is is that there hasn't been a lot of feedback. Everyone seems pretty happy with it. So I think we're probably gonna last call it pretty soon. However, I think the current plan for publication there is that it will be incorporated into a larger update. Of the, master document as it were. And that's gonna take more time. So, I'm a little unclear, a about whether or not, a community registration should be done until we actually publish that RFC. We we speculated a little bit about it in the last meeting in San Francisco. If I remember correctly, but we'd need to, figure that out. I suspect it might be possible to do so. So, but, but that doesn't stop. Publishing these RFCs. You could certainly publish these RFCs and register, and that's"
  },
  {
    "startTime": "00:46:01",
    "text": "illegitimate way to go about doing it. Or or if if if whatever reason people, you know, lose, the focus to do this. We could try and use that process. Let let let let might be a little dicey. And to until the RFC is published Okay. So If we have low hanging fruit, like, if we split off the open API and we can get that off quickly. Then continue with the RFC And if there are bigger issues around Jason schemer, maybe we hold off and wait for and by the time we've resolved those issues, they community registration may be the right approach. Sure. That, that sounds reasonable. Yeah. Awesome. Thank you. Moving on to our auth Okay. link relations, guess, two questions. Is Evert in the room because I don't see Evert. On the list of attendees. I can he he don't think so. I'm gonna back up one sec. So are is the intent Is it decision to split the document into 2? And and move ahead, as circumstances allow. Is that a conclusion? I I think that there is support for that in the room We should talk to Roberta. Okay. Yep. So, with regards to offline relations, for the record, there's 2 there. One is a, it doesn't have a get a repo, and maybe that's why we're not getting a whole lot of feedback on it. And secondly, it has just"
  },
  {
    "startTime": "00:48:01",
    "text": "just as today has expired. So, we should ask ever to submit an update. Does anybody else have any other comments or feedbacks if they have read who reviewed the offlink relations. Yeah. I don't think there's been any action since we asked them to submit k. Yeah. I created the repo and told him to put it here and the spindle action. So Yes. That's right. There is a github repo. It just doesn't have anything in it. Yeah. Okay, that brings us to item potency key. I know Sanjay woke up very early to join us today. Would you like to speak to, the current state of item policy key? Hey. Good morning, folks. What the age is probably a good afternoon. I there are 2 issues there. Daryl, I think the sec second one that you have mentioned, I'm not sure where that is. The minor editorial issues, I'll do the next draft. I forgot, 4 to 2 I don't know. I thought I had done made the change. And the second one is about removing that last sentence. That's that shouldn't be a problem you are right, you know, previous one already gives that, meaning, but I'm not sure about the second point listed there. Okay. Where is it actually? Right. So if you recall from previous conversations, the proposal from David Benjamin, about the ability to use the item potency key the client could send it even if it doesn't is not aware of whether or not"
  },
  {
    "startTime": "00:50:02",
    "text": "server supports it. I did propose wording that we reviewed a few times and you merge that into the editor's draft. So at the moment, the only thing is we, that isn't actually in an official draft So, if you could do the editorial content the those who editorial issues and then push a new version of it, I think we have a document that we should look for doing working group last call on Sounds good. We'll do that. Excellent. David, have you looked at the PR that Daryl did, see if it met you were suggesting If not, could you David Benjamin. I Faguely remember skimming it a while ago, but it was a long time ago, so I don't really remember. But I assume it's reasonable. Alright. We'll happy to take another look at it, though. Yeah. That that that That'd be good. I I can paste the link in the chat to the particular words there that are are under discussion. Okay. And I see I failed to manage to fit this slide completely on this document. So you'll you'll have to I'll have to tell you what the other 2 I are on this particular, the right limiting headers. Again, this is this is a document that, I have absolve myself a chair role for this, and I'm working with Roberto, to complete the rate limiting header specification well, in IETF 17, we proposed a introduction of a policy identifier that would correlate the rate limit thing policy header with the rate limit"
  },
  {
    "startTime": "00:52:02",
    "text": "remaining or the the consumption state header? And, that there was some additional feedback in ITF17 to change both headers to start working as SF items. So that you could actually, report on consumption state of multiple policies because you'd be able to have multiple rate limit header describing the state of different policies. That PR has been dated is in the the GitHub repo. And is ready to, be reviewed and merged. The open issues are too, and they don't quite fit on the screen. One is we had a discussion around which people wanted to also have a scope parameter and the ability to be explicit about quota units. And now that we're using SF item, We have the ability to add a set of parameter So we can have an arbitrary set of parameters that you attach to either the definition of the policy or the current consumption state of the policy, those, if folks have opinions about whether or not we should formalize quota units and scopes. There are open issues on the repo discussing those things. I have not yet added any wording into the current PR to address those. The one question that I wanted to bring to the room is that in a more recent draft that was added a registry"
  },
  {
    "startTime": "00:54:03",
    "text": "a dictionary. So it was a register for keys in the rate limit header But so now that we're using SF vitamin parameters, it would become a parameter registry. So when an Ayanna registry for known. Keywords or, sorry, known parameters. You could attach to either a policy or the current state. And I'm curious if anybody has any opinions whether that is an appropriate use of a registry for extending These rate limit headers. Mark, yep, I got a So, Daryl, can you give us an idea of what's in the registry right now? On the defining the policy there is a limit and a window, which is just the letter l and the letter w as parameters. And on the Yes. Rate limit header that defines the remaining consumption, there is a remaining letter r, and reset, reset, when reset time, which is a t. So that is a number of seconds. Remaining. So at the moment, the limit the numeric value but it is there's nothing in the message that tells you what it is a number of. You don't know. Is it a number of requests assisted a number of bites, that's where the the quota units comes in. The original definition was or the the earlier versions of the spec just allowed policy to allow the user to add an arbitrary set of of"
  },
  {
    "startTime": "00:56:01",
    "text": "custom parameters, to extend the policies. But now we're using parameters for both. I'm not sure allowing an arbitrary set of extensions is a good idea in case we fall into the problem detail is problem again. Yeah. Yeah. I mean, Just noise in the hallway. Sorry. Generally, you wanna use a registry when you need relatively uncorrelated extension. So you, you, you need some degree of agreement about, you know, I'm gonna use this extension point and somebody else might wanna reuse the value I put it in the registry, and we make sure we don't have conflicts. But in this case, I think, you know, you're talking about really the core semantics of, the right limit header when you're talking about those, those parameters. And so the other model you could use here is just to say that, you know, on, recipients need to ignore on unrecognized parameters, which is part of structured fields anyway. And if you wanted to find a new parameter, that's interoperable. You you need to revise the specification. You need to do an update RFC. And so you bring it back to the working group. You know, probably and go through the process. So that that it's much more tight coordination about the extension points. The place that that I would think a registry would be more valuable would be in those units themselves. Like the units in the scope work that you're talking about. You know, if we're gonna define and say, okay, we we define units of seconds and, I don't know, kilobytes received or or whatever We you could see the need to extend that in the future in in perhaps a relatively uncoordinated way. Likewise, with the scope work, I I could"
  },
  {
    "startTime": "00:58:02",
    "text": "see us saying, okay. This is per resource or this is per server. Or whatever or, you know, per, per, you know, your authentication token is is your scope and that authentication token has this rate limit. But you probably would need to extend that in the future. And so a registry might be an interesting thing to do there, but the actual core semantics that to me feels more of like you wanna create more friction against uncoordinated. Extensions there. Not not infinite friction, but but more friction. Thank you Marris. That was quite it. So I just want a second idea of adding some measurement to communicate the units or to scope or to scope, So, like, as mentioned quite often, you know, it's helpful to know how many requests you're have left, but it's also good to know how many, like, resources you're still allowed to create per time unit. So I think don't have an opinion on how or whether a registry would be, suited here, but measurement for communicating units, or type of unit would definitely be great. Next one. Thank you for that feedback. there is If No other thoughts or feelings about right limit headers. I will I will take that conversation back to Roberto and to the list. Austin. I've just wanted to ask about how the headers interoperate with cashing. It's probably not going to be something that most APIs are worried about, but for, like, Object storage, for instance, it might become an issue. It'd be unfortunate if a client"
  },
  {
    "startTime": "01:00:03",
    "text": "like, sees a cached version of the header and it thinks, oops, I can't download any more documents when, in fact, it can redownload that from its own cache as long much as it likes. So I maybe add some treatment this or just a warning Yeah. That's an excellent call out. I know in the early days, there is a section on cashing in the doc that Roberto created, it basically says that, you should ignore rate limit headers that are included in responses that come from a cash Okay. Based on the age. There, Daryl, it's Mark again. We can double check that. There's some language in HTTP you can leverage for that. Yep. Excellent. Cool. Cool. Okay. Rich, next slide. Busy recording what Mark said. One sec. Okay. Sure. No pro no worries. We we have lots of time today. We're not going to run out of time. Yeah. Now you just cursed it. So the next, item up is adoption of relative Jason Pointer. I do not believe Henry was able to join us today. And we have had from Carson with regards to relative Jason Pointer. Who brought up some very interesting points about the challenges of, people figuring out how to go up a tree. And how to count, how many"
  },
  {
    "startTime": "01:02:00",
    "text": "levels up a tree. Things need to go. He didn't raise an objection to this being adopted, but did add that it would also be really nice to see this kind of ability to go up ancestors in the adjacent path. Specification that is currently being worked on and the Jason Path Working Group. I don't know whether there's anything else that we can really do here other than ask for opinions, in this group as to whether or not we should adopt this document. Does anybody have any opinion since reading the doc. Daryl, let's mark again. Has anybody talked to anyone in the Jason Path group about this? Especially the chairs, well, well, well, well, well, Carsten is in the JSON Path Group. Is member. Right? Yeah. Yeah. I I'm not aware of of Henry talking to them. Okay. Yeah. We will, the chairs will get together. Okay. Thank you. The civil Hampton. Okay. Okay. Moving on to the next topic. And I will I will set a little context and then I'll I'll Hello? I'll hand it over to Sanjay to give his opinion on this. We have had a working group document since basically at the beginning of this working group in order to standardize the deprecation header. There has been lots of discussion about the relative merits of"
  },
  {
    "startTime": "01:04:01",
    "text": "using structured fields in this header versus being compatible with the sunset header, which is a pier to the deprecation header. We came somewhere close to getting agreement and then there was a fork in the road and a conversation was raised about, well, maybe we should just build a more advanced header called life cycle that encapsulates both sun setting and deprecation and maybe other parts of an API life cycle. And so time past where there was hope that somebody would step up and go and write a life cycle header to replace the deprecation header. That didn't happen as of a few months ago. And so we decided in order to apply some grease to the process that we would set a deadline of this meeting to say if somebody wants to go do a life cycle ahead or go do it, And if you haven't done it by this meeting, then we will go back to doing the deprecation header, as appeared to the sunset header. And so I think that's a semi complete summary of the situation. Sanjay is one of the authors of the original deprecation header. Would you fill in your perspective. And just to add a big thing, you know, So for the life cycle header, you know, in my personal experience. I haven't yet come across use cases where we have beyond application and sunset, any event that, regarding the APA's life cycle. That needs to be"
  },
  {
    "startTime": "01:06:02",
    "text": "conveyed to the clients. We do have all of us have our own ideas. You know, this might be useful. This might be useful. So if you think from that perspective, practically, I think, these these these 2 headers which are well scoped, sunset and application. You know, there is an advantage for you know, being just a web scope. Henner that it It is just for one event in the APA's life cycle. So in that way, I I kind of like the application header as a separate header But, as you were saying, you know, we've been talking about life cycle event header for quite some time But, in my opinion, strong use cases have not appear at least in my personal experience. So I would I'm kind of leaning towards keeping the application header. As a standalone header. If, you know, working group agrees to keep it that way. To speaking without chair hat, I think the one scenario that was discussed was being able to signal that a resources in some kind of preview state. So that, do not take a production dependency on this as it is possible that there might be breaking changes in the future. But that's the only one that I recall as being a status that was flouted in addition. Mark. Not not even in the Alice meeting."
  },
  {
    "startTime": "01:08:00",
    "text": "We need to get a lot of exercise today. Mark, Mark Nottingham. I I feel a little bad, because you know, I I I pushed for this a little bit and, I I I think that, you know, in, in, in a, better world, we would be doing it, you know, as as life cycle. But I feel bad because I'd I don't have strong opinions about this, but I know that if you take a date field to IETF last call. There are gonna be people who feel strongly than I do, that things should be structured fields now. In HTTP. Gonna get that pushed back fairly strongly. So of that that's the observation I'd make. Which Yeah. Like I say, I feel bad. Sorry. I'm willing I didn't realize there was a deadline if if it helps, I'm willing to put some editorial cycles into making a proposal in if if there's interest in doing it, but if folks want to stick with the application, I'm I'm fine with that. So for what it's worth, I'd I'd, you know, if if Daryl, you think that would help? So I think the question about, you know, Mark, the the date field or, the structured field. I think that's that's okay. I mean, if it's a structured feed, I think. At least that's my personal in. But, the other question was, you know, should we have a life cycle event completely new product. Yeah, Mark. The the thread that that triggered this deadline and and I was needing to make a discussion there was a lot of interest in the deprecation header. And in general, people were okay with using the structured field for date. Okay. That's the compromise. Yeah. Okay. Well, then then maybe that solves that problem. And I certainly wouldn't have a problem with that. I"
  },
  {
    "startTime": "01:10:03",
    "text": "I kinda feel like if we had the energy to go off and really investigate and and research and document what the life cycle of an API should be that we could do some interesting work here, but but I don't know that we're capable of doing that right now. So, you know, maybe maybe the right thing to do then is to publish application get it out there and then learn from that and see if there's something next in 5 years or something. Does that make sense? Yeah. Okay. On a related note, I have a question. The working group. Is there a way we can find out Well, let's see if the application header where it's being used. When I in the past, I used to do research to find out where, you know, the application header or a project header key header are being used, which API developers have adopted it. But it's just a personal, you know, thing. If you have a way to find out that where this is used, Then it will help us, in taking steps like going from late feed to the structured field and, you know, are we breaking things or not? Any any thoughts on that? How we I believe the general sentiment in the past is, we are attempting to be forward looking, and that the concern about breaking existing dot of non standardized things. Is not a significant influence in having us choose the best option to move forward. And so"
  },
  {
    "startTime": "01:12:01",
    "text": "while understanding what people do out there is interesting. And is informative towards overall design. We don't have a mandate 2, build things that are very compatible with existing implementations. And if I said that poorly, apologies, but it was my best effort at capturing the sentiment that we heard in the past there is freedom. That's good. Thanks. So we have Alright. As I understand it, will work to get the value of the header via date structured field, And, resubmit a new draft and ready for last call. If someone down the line wants to investigate and work on full life cycle document open with open arms. Sounds like a plan. Great. Thank you. Excellent. And so, that brings us to the end of our schedule topics, Francesca. So I got an date from the RFC editor about the YAML menu type document. And they said they had missed, Zahad approval. So that's why it was stuck in ISG waiting for ASG. So now it's unstacked it's in edit again and they put it on the top of the queue and prioritize to get through. Off 48. So great. We're getting that moving. So the other lesson learned is guilt is a good motivator for the see. It"
  },
  {
    "startTime": "01:14:02",
    "text": "Thank you for following up on that franchise Thank you. Awesome. One more win on the board. Excellent. Okay. So does anybody have any other, topics that they would like to bring for today or shall we just and early. Okay. I I think No one wants to come to the mic. I think we are done. Thank you all for your attendance. We made a lot of progress, actually, on 4 or 5 documents will soon be showing up for final review. Maybe 3 or 4, whatever. Enjoy the rest of the week. And, See you Some of you online, some of you in person in Brisbane, and on the list. Thank you. Thank you. And thank you, Sanjay, for getting up really early Yes. I appreciate it. Thank you. Thank you. Thanks, Rich. You too. You too, Daryl. Yeah. Partners. Had I had I spoke in front of a life might be the last one. Luckily, they edited out Yes. Nothing. Oh, sure. I'm going to, like, get this in I usually registration"
  }
]
