[
  {
    "startTime": "00:00:18",
    "text": "Hello? My clock says that it is midnight which means it's time to start privacy preserving measurement working group session. So thanks everybody for coming. We need a Described, we need somebody to help us take notes and some brief minutes. Of the session And as a reminder, the chairs will start calling on people at random. If we if we don't have anybody who volunteer to help with that with that. So if you can help us up, please, let us know. Okay. Wonderful. We have volunteer here. Thanks a lot. Can you tell me you your your username shows as Michael will b here. Can you Can you identify yourself a little bit more specifically. Yeah. My be. Okay. Thank you. Wants to help out with minutes or"
  },
  {
    "startTime": "00:02:00",
    "text": "or make improvements of corrections along the way. We do have live collaborative note taking. So So so ben and Sam, this is Roman who just walked in the room sorry. I'm late do you need any... If you need anything in room, just kind of holler, I am here. We just gotta volunteered to do minutes. So I think we're set in the room. Tim, are you ready to go? Actually how. Then you have I still to run through. Great. So I think we're ready to get started. Let's keep moving. So again, this is the privacy preserving measurement session. I hope you're in the right place. As a reminder, especially if you're new to the It etf, all I sessions are covered by the I f note well. Please familiarize yourself with these policies that cover both our expectations of professionalism. And and communications, appropriate communication style? And also some important legal implications of participating in an Etf working group session. Just a reminder, especially since both chairs are remote. At this time? Please do use the Id half on site tool. So that we can keep track of who's in the queue. Get people their their time to to make comments during the session. Please also note the mask policy if you are on site. And if there are any technical issues or or in room problems."
  },
  {
    "startTime": "00:04:02",
    "text": "Thanks Roman for being present and being able to help out with those, please. Go talk to Roman if if there's an in room problem. Just a reminder about the general resources in Yokohama oklahoma. Additionally, I wanted to point out that in this week, there are some upcoming presentations that very relevant to the topics of this working group. Made by some of the people you're going to be hearing from today and also some other folks. So if you're interested in learning more about these topics, from a different perspective. Or about helping some of these research groups to understand these topics a little bit better. Please do attend the privacy research group and the crypto research group. Sessions later this week This is our proposed agenda. Wanna take one moment to see if anybody would like to make any comments about this agenda, if there are any changes that people would like to request. Otherwise, will dive right in? Hearing no concerns about this agenda, we're going to move ahead Next up is Tim for the distributed aggregation protocol with some updates about progress there. Tim, you can request to share slides and and drive here own slide deck if that works for you? Thank you, Ben. You the video. That's my deck. Share."
  },
  {
    "startTime": "00:06:03",
    "text": "Alright. I'm always delighted when this works, but it does work quite reliably. Okay. Hello everybody. My name is Tim. I'm one of the editors of the distributed aggregation protocol. In this... In this tech, we're gonna discuss What's nuisance since the last P working group meeting in the da draft and it's limitations. Alright. But before we can actually get the gap itself, We need to discuss what changed in very five distributed aggregation functions, which is the abstraction that da is built on top of So as as Benjamin just alluded to, V app is being specified in the crypto forum And it's received two new drafts since I f one and fifty. So these new routes primarily were motivated by a paper that was published earlier this year. Which Hannah Davis and her, which conveniently includes two of the authors of V app itself. Provide a security analysis of V f and the two current instant of it, which are p zero three and alpha one. So the paper question is on Ep. And Chris Pat shared a concise summary of the implications of the paper for the protocols to the Cfr g list, and both of those are linked on this slide. And what was reading. Now I don't wanna get into all of the changes that have happened in V. Because this working group I feel is primarily interested in the implications of of the Uv reps for gap. Also, I would get all the subtle points of photography wrong anyway. But there is one thing I wanna highlight besides the gap points that I'll talk about in a minute. Which is that Uv specifies a a new pseudo random number generator. Is based on shaft three instead of Aes as before. So that's fine three is, you know, well regarded well standardized photography, but it could be interesting for implementations just because implementations of it aren't quite as widely available as shop three, but it was necessary make the security group's work. Alright. Moving on to gap itself. Looks look at the changes the first set of changes is those made to catch up with the new v draft."
  },
  {
    "startTime": "00:08:02",
    "text": "First off, V five now requires the client randomly generate a knot when inputs. Da addresses this by instructing clients to use the report Id as the not. So this should be easy for implementations to deal with since they were already managed the report Id when constructing the report messages. This does mean however, that adapt can now only work with those apps whose non length is at most sixteen bucks. Or put another way, this might heavily influence future apps to choose sixteen noises. So additionally, V five now spells out requirements for how ag should negotiate the V f verification key. Now the existing requirement is that this verification key must never be revealed to the clients. Because if they know it, then they can use it to sort of generate focus reports or forth proofs. The new requirement that we now have is that the verification key must be committed to by the ag. Before any reports are processed. So Have here... There's a number different ways that Aggregate here could successfully securely negotiate verification heat, but it does suffice for save a leader to choose it. Just by sampling a p. And then just distributing the verification key to helpers. What this does mean is that the verification key cannot be rotated independently of task. Alright. And finally, Now... Sorry. With worth noting is that now v eleven and app now both include requirements for how to negotiate the verification key task negotiation and how to how to choose and share the parameters of a task remain out of scope for the adapt document. And so currently implementations have to work out their own means of securely negotiating these values. Alright. Last interesting data change is that there are new rules now for the that aggregation parameter. So the motivation here is really about popular one. Which requires that any given level of tree, like I can to in the process of aggregation, only be query a single time."
  },
  {
    "startTime": "00:10:01",
    "text": "So that is you can only bury the set of candidates string prefixes by going deeper down the tree. But the requirements for validity of an aggregation parameter very based on the Vita f. And so Da needs a generic way to determine whether some aggregation parameter is valid or permissible given the previous parameters seen for the for the get the navigation. And so in indeed five, there's a new generic method on a have called is valid which allows daphne to do just that. Okay. Next, we have some purely da level changes. So first off, the representation of a collection. So this is the object that gets delivered a collector at the end of the whole aggregation pipeline. Now includes the interval of time that is spanned by the cons reports. So this is valuable particularly in the context of a fixed sized task. Because otherwise, the collector would have no idea what but span of time and aggregation referred to. But even in the time and interval query case, this this can be quite interesting. Because it could be smaller than the interval that was sent in the query. Say, you know, perhaps you were doing an aggregation over like a day. But as it turns out, all the reports came in only in six hours of that day. It's worth noting however, that the interval shown delivered in this message. Still gets padded to the tasks time precision parameter order to protect the privacy of individual contributions. So a more drastic change to the protocol. Was the introduction of the new Ac Api. So the major change here was to h a number of parameters out of request body and into http request paths, which removes needs for some really unpleasant parsing hacks implementations. We also spent a bunch of time thinking about request item and robustness of the protocol the face of Transient network failure. So all of this was discussed at length One and fifteen and even more so on github. So check out the links in the slide to all that material if you interested in seeing all the deliberations that went into that."
  },
  {
    "startTime": "00:12:02",
    "text": "Okay. Next, let's take... Let's talk about some running code as the Is sso always so interested in. So first, L p is our rest implementation of p zero three and popular one V families and the V abstraction. So v that four is implemented in three zero zero point eleven. And v five is in the three zero point twelve series price. And both of them are available on Great dot io right now. So at this stage, we have two different open source working implementations of adapt, which discuss in a minute. But they both use a implement yes. So we would really love to see more implementations of feed feedback up there. Go would be a really, really good choice for this. So if you're out there, if you're interested in doing this work or testing it against the rust implementation, Please reach out to us either or on the P list or know. Suppose anywhere we can be found. We'd love to hear from you Alright. Next, Daphne is a helper implementation that targets the cloudflare workers platform. It's four implementation is currently underway. And as of last week, they are publishing docker images to a public repository. About everyone can play with them. Gia is a complete four implementation module and he bugs in it. You. Of the client leader helper and collect roles of the debt protocol. We also have D s, which is a mostly native types people indication of just the client role of the Protocol. And finally, fire... The the interior team of Firefox have been working on integrating a adapt client into the browser. Which is mostly complete. Though they're they... They're catching skinny. Their gap before implementation is still underway. Okay. Last topic that I'm gonna cover today is I think pretty exciting. Which is that we did a real life interoperability test. Between"
  },
  {
    "startTime": "00:14:01",
    "text": "Daphne, Firefox, and Gia late last year. So in this test, what we did was to deploy a one task using the p three sum v f. Which is as it was defined in dat o two and V o three. So this is an navigation that does exactly what it says. It just sums over a bunch of reports where the measurement is a simple scalar integer. So in this deployment, the leader was honest deployed on Google cloud platform. The help room daphne running in cloudflare workers. The client was distributed into firefox nightly builds. And only enabled in one percent of nightly installs using Firefox experiments So we estimated this is about four hundred clients total. Those clients were set up to report this the through of fixed value of three every time the browser starts up. So since we know what all the inputs are, and we know the number of reporting clients, we trivial figure out what the expected aggregate is. And verify that it worked correctly. And of course, since we're just reporting the static value of three, there's no real privacy concern. Has the number three. Doesn't reveal anything about any real individuals. Okay. So the the good news is it works We ran aggregation for several weeks. They ran successfully and we didn't see anything particularly unusual or unpleasant happen. That being said, the scale of the experiment was too small really learn very much about performance or scaling. And then in any case neither implementation was expected at that time. To scale past more of than say dozens of Gps anyway. Interesting thing that we did learn, however, calling back to a previous slide, was that agreeing on task parameters and provisioning them across all the protocol is kinda tricky. So for this experiment, we only set up a single task. And so what we do was just to share base sixty four encoded blobs of binary using a Google doc that we all, you know, had access to edit. But as soon as you get to dozens or hundreds of tasks, which is not at all realistic for any serious real realistic usage of telemetry."
  },
  {
    "startTime": "00:16:03",
    "text": "It's way to become vital for deployments to work out some kind of automated early much more foolproof proof way to negotiate the encryption keys and insured right of seeds and all the other parameters necessary for this. So once again, this is that that provisioning flow is out of scope of dev itself but it might be an interesting challenge interesting problem for this working group to take on. Alright. To wrap up. I just wanna take a look at some of the stuff that's Oh, sorry. Sam as telling me that the rest of the question. Sure, let's go ahead. Keep this is Robert. This is this is from the room Ross is not here in person, although he is at the meeting in person. That's odd. Go ahead, Tim. I think I'll just wrap up since this is my last slide, and I'm half... The russ I'm happy to talk to you about if this was a real question at at point, Okay. Where was I? I yeah. So I just wanna talk about some of the future goals for the Deepgram drafts. That might be coming up in da five or later ones. So the next big thing area of focus is going to be popular one. So V in particular has been doing tons of work to make popular one scalable. And once we have some more success deploying three zero three, we're going to need a wider popular wide in more gap implementations. Get the tires on it, see if there are performance or other problems that wind up you know, feeding back in the form changes to the deck itself. Further, the draft text itself needs a lot of work. For simplicity engines just to clarify things. So personally, I'm interested in cutting as much of it as we possibly can. Eliminating things like error codes, or other features but aren't essential for the protocol to function."
  },
  {
    "startTime": "00:18:01",
    "text": "Of course, we... We don't want to say preventable limitations providing rich diagnostic information in various cases if they wish. I also... We've known for a long time now, but the text be the the text itself could be clarified, and we really should be putting in more visuals, like block diagrams or sequence diagrams that better illustrate this relatively complex protocol. Additionally, a future draft will have to in conjunction with ed includes the language around how to deal with central differential privacy. This would be applying some differential privacy noise to aggregate shares. Which unlike local differential privacy, that has to be in scope. Has to be dealt by the protocol. The security consideration section is well on a date point and needs a lot of work to be brought in line with the current state of the document. Another thing that we've been showing on is whether we should consider decoupling the aggregation parameter, which can be quite large from aggregation jobs. And or some details this is a detail topic that we want time to get into here, but there's a link issue there if you're interested in it. And I encourage anybody who everyone to take a look at that discussion and wait, if you have something to say about it. And finally, editors have been pondering whether or not Da should specialize to exactly one aggregate. Which is going to be the main thrust of the the very nice talk by Brandon and Chris. So I'll let them introduce that problem in detail. Okay. That's it for me. Thanks everyone. Got queue. Any questions for Tim? Before we move on? Thank you, Tim. Chris Brandon. I don't know which of be just taking this version."
  },
  {
    "startTime": "00:20:01",
    "text": "Hello below in my. You're on. You're you're you're faint. Hold the microphone close. Okay. Alright. Know I'm not driving his slide. I'm starting Can you put the mic or? It it's on, but maybe take it out and hold it close I think I just turned it on. Now I hear myself. Alright. Alright. Okay. We can hear me right? My good online? I'm gonna assume I am? Okay. So as Tim alluded to, this is gonna be a about an idea for a change to the dab spec that we are thinking about from an implementation perspective primarily, we would like to see if we can reduce some of the latency that we've noticed during the aggregation flow. Yep. So let's let's get started next slide. So a quick overview of how the aggregation flow works today. So just as a reminder, this is the part of the protocol call where we take our report shares, decrypt them, process them do input validation and then eventually commit them to long storm long term aggregate storage. So I'm gonna go through the current flow. And illustrate, let's think of p three in particular, So the salient details of p three are in the green box on the slide. So in the aggregation flow what we're doing is each ag, the leader and helper have an input share derive from this input share a value we call the ver share. And then we combine these"
  },
  {
    "startTime": "00:22:04",
    "text": "verify our shares into a message that we call the ver. And this is what we use to decide validity. So what we do in the... There's two Http requests over the network for P three for the leader in its request sends along the in the the helpers input share just and this is encrypted to the to the helper by the client that uploaded it. The helper replies with its ver share. And then the leader locally combines, it's share with the helpers and response to the helper with the ver message in the next request. Next slide. So the nice thing about this in this flow and really the the the thing that we envisioned for it is that it's quite natural naturally extends to V dash that involve multiple helpers. So the we... Basically, what the leaders doing is em a broadcast channel So it will send each helper its input share gather the responses, which are the the ver shares And then in the next round, it broadcast the ver message to helpers. And then at that point, everyone can commit their share of the input to aggregate storage. Next slide? So The thing I want you to notice about this flow is that it it inherently requires at least two round trips over the network, If we think about just the two ag kind of model, There's actually a nice optimization we can do. So what we the leader can do is along with its... The helpers encrypted input share. It can also generate and send its the leaders ver share. That way, the helper compute the ver message and commits."
  },
  {
    "startTime": "00:24:00",
    "text": "Sends the ver message back to the leader and then the leader commits second. Next slide. So the upside of this is less round trips of the neck works, which means reduced latency and also less of a chance for network issues to impact the aggregation protocol, which is the heaviest weight part of of of da. Concrete for P three, we would have one request instead of two for poplar one, Right now we have three requests. This change would mean we would have just two. And, of course, the downside is loss of general because we are now in a world where we have two ag, and we can't really generalize to to multiple helpers. So the question basically we have for the working group what we would like a decision on in the near future is should we continue to support this multiple helpers or are we comfortable at this point specializing to a one helper protocol? So we've we've done our best to get feedback from people on the mailing list and other menus on venues use on this question. And so I'm gonna I'm gonna go through some of the the the considerations in the next few slides. And then I'll turn it over the Brandon who will go go through the our actual proposal. And then we'll kick it back to the chairs and they can tell us what we what we might do next. Next slide. Okay. So as I said, the main consideration here is general. And there are a few use cases that have come up so far that are potentially relevant here. The main one is basically, you have more ag, then you end up with a weaker trust model, because for a protocol like Pre it's very not... It very naturally generalize to multiple ag. And to get privacy, you only need to trust one of those ag to be honest."
  },
  {
    "startTime": "00:26:00",
    "text": "So that's the kind of beauty of this extension to multiple helpers. It's important to note here though that not all V pdfs are necessarily general in this way. Popular one in particular is only defined for two ag. And we don't know how to extend it to more than two at least right now. The second kind of use case for multiple helpers is robustness in the presence of amos mis hating ag. So as a reminder, We have privacy if some of the are cheating, But we don't have robustness. That is the ability to detect and and and filter out invalid inputs. So to get this property, there's there's a couple of papers that looked at to do this. I don't think that this is compatible with the current broadcast architecture we have for adapt today, so I think to support these techniques that get robustness The stronger robustness property we would have to change the architecture. Basically, the problem is the leader is still if the leader is, like sort of you know, em this broadcast channel or, you know, or media communication between between two helpers still lots of opportunities for it in mis. The third thing that's been brought up is that there might be v dash that require at least three ag to meet their security goals. I don't think we have examples of this yet, but this is a possibility. And then lastly, there are other Mpc architectures other than V apps that would require three or more ag a good example is Ipa, the sorting scheme in that in that protocol. Go to... Per. Is that what we pronounce it Per? Okay. Per g. Thank you. Okay. And so you know, maybe we want shoot horn that into that, maybe not. I don't know if we settled that question. Okay. Next slide. Yeah."
  },
  {
    "startTime": "00:28:04",
    "text": "It does. It's the second citation there on It's twenty twenty three's slash zero eighty. So Yeah. Plasma does this thing where it's basically running a two ag v f three times among each pair of ag. And we can do this. I don't know if it works with our architecture at least not with trusting without trusting the leader a little bit more than the helpers. Sure Okay. Yeah. Change across cost. Yeah. I don't know if that's true or not. That seems like I mean I guess if it's This very cool. We're having trouble hearing that microphone remotely. You make sure... It might up be on. How about that, That sounds good. So try repeat myself for, we're just gonna be done. I'd like to have your repeat because I couldn't understand you. Right. So as I understand it, plasma requires strategy. And so what question I were discussing was where this change will break plasma. And so what... And so that was my question and then my... My statement was If this doesn't... It this breaks plasma then that's bad. Feels really positive then maybe it's okay. So it it so depends on what you mean by plasma. So plasma is essentially, it has... At its core is a two ag vita, that is exactly like popular, but better. And the way they achieve malicious robustness is basically this trick that that has similar features with Well, both of these papers basically do the same thing where you're running the V"
  },
  {
    "startTime": "00:30:04",
    "text": "three times among each pair of ag, and basically, you vote what is the result? There is a downside to this approach. You do you do have robustness in the presence of one malicious ag. However, you only have privacy in the presence of one malicious ag. If you have two malicious ag, they can actually c include and break privacy. So it's not a win in terms of privacy. It's only a win in terms of robustness. But this is like, you know, Yeah. A point that needs discussion. Yeah. I think I think like so like quite following. What the answer my question is, but alright. I don't... So your question was does this break does this brake plasma, I would argue that it doesn't. I don't think that the the feature... The the the feature that we want from There's there's two things we want from Plasma. One is the improvement compared to popular, and then the other one would be robustness in the presence of mis ag I think this has a downside, the way they do this. And we need to figure out if that downside is worse if if the trade off is correct. I guess, I guess I I guess, I don't actually like Right. So I think I I... Here. Because I just came for plasma discussion. Right? The very plausible was that you needed three... You needed three to data in order to even get the privacy jacket. Right? No. Yeah. There's there's a version there's There's the the thing they called V f This is basically popular but better. Okay. And it has the same security property It claims this... Designs has robustness in the favor in a place of one more. Yeah. Nothing we have right now. I don't think that I don't think that's important, but I thought I don't possible required. Even privacy. Is not correct. No. Okay. And then yeah. Okay. Thanks. I... Yeah. We we can talk more about about offline in in a little bit. I'll blast through the next three slides Next slide."
  },
  {
    "startTime": "00:32:05",
    "text": "So, yeah, So loss of general of the main consideration about this change The another consideration is complexity. So this this current spec is pretty complex. A lot part of this at least has to do with the general that we have multiple rounds, multiple multiple ag. This I'm little worried is is maybe in imp adoption I think we have some unspecified behavior in the current draft. I can talk about specifically what I think is under specified. We need to solve this in any case. It might be easier if if we make this change. I don't know. Next slide? And then, of course, there's the state of current deployments. We have some open source implement patients. We've had this Firefox nightly experiment But otherwise, you, we haven't... I mean, we do have to update code and we need to decide if this is if this is this changes too big at this time. I deployments are pretty limited. So I'm I think I'm less worried about that personally. But another angle that has been brought up on the on the mailing list about this issue. You know, more deployment experience might actually tell us if this... If this changes is warranted. We didn't observe any issues in our very small scale to appointment, but what you're sort of anticipating having issues and and hence hence the the the the the desire to make this change. Next slide. And I'll just say quickly, I think this this question gets at the scope of the the dab spec itself. There's an argument to me made basically too ship what we want to deploy right now and think about general realizations later on. Now I'll hand it on to Brandon who will go over the proposal go ahead, Brandon. Thanks please."
  },
  {
    "startTime": "00:34:04",
    "text": "Hi everybody. I'm Brandon. Here to talk to you about the specific design change that we're proposing that requires one helper down and especially the performance enhancement that is enabled by specifying to one helper. So kind of the core insight to one helper or adapt. Is that in incorrect the leaders in privileged position in terms of communication. Not only does the leader drive the aggregation process in the sense that it initiates all the network round trips, but it is also effectively the center a star communication layout, which means that it is sort of the central piece of a webcast hub and therefore is the ag that effectively must merge verify our shares. Into a. In one helper da. The leader, while it still drives the network communication. In terms of starting network round trips is no longer in a position either the leader or the helper can easily broadcast all of the because there are only two ag. So point point communication is the same as broadcast communication So a Pdf f evaluation requires that all the operators start with an input share which they can then derive their initial shares from. All of the shares can be merged into a ver and then each ag can use the to derive it's next verify share with the next round except the last round where the met where the is used to derive the output share and retrieving the output shares is the goal of the aggregation protocol. So the core insight is that the total count and order of the beat app operations is not changed by this by this proposal, but the total number of network round trips to complete aggregation is reduced by about half. Next slide, please."
  },
  {
    "startTime": "00:36:07",
    "text": "So this table compares the current specification to the one helper specification. The main change is in what is transmitted with each round of a adapt. So in current, the leader transmits an input share on the first round or on the subsequent rounds. And the helper always uses what it receives to derive its own share which have been transmits not to the leader. The total number of network round trips is rounds plus one where rounds is a parameter of the Vita. The reason the number of round trips as rounds plus one is that So rounds. Network round trips are required to perform the actual f evaluation and one round trip is used to essentially transmit the input shares. In one helper tab, the court change is that with each network round trip, the helper derive not only it's share. But also the next ver. So in the initial round, the leader transmits not only the helpers encrypted input share. But also the verify share that it drives from its own input share the helper derive the from the two verify shares. And then immediately uses that to compute its own next share, which it then transmits back. In subsequent rounds that the leader compute the ver from the next share and its own. Verify share. And then immediately compute its own next verify share from the ver that it derived and transmits both the helper her does similarly, it derive its"
  },
  {
    "startTime": "00:38:02",
    "text": "verify our share from the receives. Compute a ver from the leader and helper verify our shares and that immediately compute its next share and transmits both back. The number of network round trips is rounds plus one over to rounded up we're ceiling. And the reason that it takes this number of round trips is that in the one helper or that proposal, each network round trip. Effectively steps the underlying data up twice rather than once Next slide, please. So I want to walk through a couple of it's example, V evaluations using both current app and one helper depth. The first example I want to walk through is a one round for example, P three is a one round three dash. Although there's nothing pre or three specific about this example. So looking through the current communication sequence diagram. To perform aggregation the leader and it sends a message to the helper. Indicating the helpers encrypted input share. The helper decrypt this input share. And then uses the input share to derive its first verify share helper or verify our share zero, which returns to the leader. The leader during this time has decrypt its own leader input share. And has derived its theater verify share zero. From its reader input share, then it uses the leader in helper shared zero. To compute... Verify zero it then transmits ver zero to the helper. The helper attempts to use this to retrieve its next verify your share, but since this is a one round, instead, the helper receives its output share and has completed the aggregation protocol."
  },
  {
    "startTime": "00:40:00",
    "text": "It sends a message back to the leader saying that it is finished. And the leader uses verify zero to compute its own out share as well. And both the we in the helper have retrieve their output shares and the protocol evaluation is complete. In one helper or doubt instead of sending only the helpers input share leader also derive its own Shared zero. From from its own input share and transmits of the helper input share and the leader or shares zero to the helper. The helper uses the helper input share to derive its own share zero. Uses the leader and helper her verify our share zero to compute verify zero and then attempts to step forward from zero. Receives an output share. Because it is complete, it sends a finish message back to the leader. The leader uses the ver verified zero that's transmitted as part of the finish message two retrieve its own output share and the aggregation evaluation is complete. So the number of network ground trips is reduced from two to one. Next slide, please. So for one more example, for a two round v f, for example, popular one. But again, there's nothing special about popular one. This is a generic that evaluation example. The current depth is very similar to the previous slide except with an additional network round trip. So with each round, so in the first round, the leader sends a help. Helper input share, to helper derive the verify assurance and sends it back. And then the your compute the ver sends it to the helper the helper uses that to compute the next share continues for two rounds instead of one. At which point the helper completes. So and then the leader also completes and the evaluation in"
  },
  {
    "startTime": "00:42:02",
    "text": "of the of the aggregation is complete, and this takes three network ground trips. For one helper that. The leader just like in the previous example and its initial message since the helper input share as well as the leaders verify our share zero, which has derived. The helper derive helper verify share zero from the helper input share. Use a leader and helper verify our share zero. To compute verify zero. Use verify zero to compute helper verify our share one and since both verify zero and helper her verify our share one back to the leader. The leader uses ver zero to compute leader verify share one. Uses helper and leader verify share once to compute verify one. Since verify one to the helper the helper uses verify one to compute the attempts to use verify I want to compute the next verify share, but since the final round. Instead retrieves its output share and realizes it has completed evaluation of. It sends a finish message back, the leader doing this also use this spare one to retrieve its own output share and both the leader in the helper have retrieve their output shares and the evaluation is complete. This takes two network ground trips. The reduction is from three to two in this case. Next slide So in summary, we need as a working group to decide if we want to support an arbitrary number of helpers or to specialize the helper the protocol to one helper. The main pitch for specializing to one helper that you can reduce the number of network round trips in the aggregation flow by about half which we believe to be an important performance enhancement. It also there several other considerations."
  },
  {
    "startTime": "00:44:01",
    "text": "General, we may lose some things that could possibly be specified as a vw. If that only supports one helper. Complexity, specifying one helper simplifies the protocol. While there are some arguably some low level technical increases in complexity in the sense that the aggregation protocol is doing more work per step. We need to consider current deployments. This is a fairly large change a protocol, we need to decide if this is too late in the game for us to change. To make a change with this magnitude. And then we also need to consider the scope with the adapt draft. Do we want app to support every possible underlying Pdf behalf or the expresses a. Or are we happy specifying only one helper? Thank you. That's all for me. There was some interesting discussion in the chat? Martin or echo or anybody else do you want to get in new queue and continue? Go ahead. Well, I think first I have a clarifying question. Is there being measured performance impacted of this? Because it's sort... I sort assume there's quite a bit of processing this. I mean, these are like fast machines. On a latency networks As soon as a fair amount of precedent happens, with hit these steps. So like, approximately speaking, how many Cpu seconds are run on each front trip. Brandon you want take that? So I can't speak to the, like, a specific quantity of Cpu ticket for network ground trip. What I can say is that the total number of underlying operations is the same. Although the distribution of which data is performing those up operations. Has changed somewhat with this proposal. So it's"
  },
  {
    "startTime": "00:46:01",
    "text": "as I mentioned, the leader was previously performing all of the combinations of shares and the with with this proposed change. The leader in the helper would effectively be sharing or taking turns. Merging to verify shares into the ver. So I would expect that the total number of Cpu seconds or other resource usage metrics would not change all the the distribution of which servers or machines or deployments are performing the work which shifts somewhat more towards the helper. Sure. This is an Ambrose law question. Namely like these are fast machines, which have like links between them, which means that the enterprise, I'm probably in ordered by twenty milliseconds. And so if you're running five seconds of computation, and you're shaved off twenty minutes. Most milliseconds. You got lot of run making difference. So I'm asking what's the mac like the total total time in the system, how much that is spinal network drops? So I think, I mean, I don't think that we have good data on that right How long okay. Well how what is what is the time for the... This total then time of the computation typically. So on cloudflare workers, it takes about, like, cloud workers is slow for this because we're using W. Sure. So it takes maybe for like, a couple hundred reports, it takes, like a second to process and then the second request is much faster So, like finishing is does the initial processing step takes time. Right. So so it sounds like you're getting payments that you're got five percent being on the high end. I mean, yeah it depends on the network, I guess. Because like, you know, the... Sure... Yeah. Just just less round trips like, our thinking is less less round trips over the network the better. You know, latency being a consideration, but also just kind of complex city of the protocol because you have to keep state across these requests I'm what I'm trying trying to work through the picture. Right? Pictures. Right? And so Yeah. like it's easy to have headline pitch yours this is faster. And so I'm asking how much faster?"
  },
  {
    "startTime": "00:48:03",
    "text": "And I I don't think we know. So I think like that I think like if that's the motivation for this. I think really if I queen's numbers. Okay especially because like, I mean, Like, I would imagine that things are get bigger. Not smaller or in terms there's our number of reports yet value. Right? So we're not like, I guess don't like felicia wrong this but trying to break down like like the parking. And so it seems like what we're proposing is to give up some flexibility future in favor of some simple simplicity now. Yes. And so like like an set choice. And I'm sorry it's a level wait. I'm not not static, but it's like that's four sample or. I think that this is a much weaker story if the performance it reap repo performance swing. And so like, I I think, like, you know, Will I be arguing for, like, opposite? If like if you're were supposed russian, I don't know. But like, know, I think like if a primary Audio for this is performance, if my told is gonna do a faster. We just don't wanna do this, if the answer know we shouldn't do it. That answer... And you can actually put a lot faster. Right? The answer is even way exactly high speed, if still wanna do it then like let's discuss that that pass. I'll tell you what. Maybe we can, like, prototype it and and talk about it, like... And and just, you know, figure out, like, from, like, our actual deployment gonna be faster. And I think anything think you can do that, but I think you could just it. Right? Like I said. Yeah. Then I I'm have to send that and like, what That measurement what I would take. I think I can get this existing data Right? Yeah. Well, so you're... Like, I mean, it's sort of... The numbers are like, you have reports per aggregation job, Yeah. And then you have the number of aggregation jobs you're running simultaneously, And so the more aggregation jobs you're running simultaneously, the lower the overall latency of of aggregating the entire batch. So it kind of depends on how much you scale like, how much how much of this impacts? I don't think I follow. But anyway like I say, I think the things pushing with this. I think argument simpler, which I think is is is is a reason we. Against it, or or like less"
  },
  {
    "startTime": "00:50:03",
    "text": "general. This goes my question plasma as well. Right? If there no be reason why we'd ever need this three thing. Yeah. Then like cool. Like me not do it. But why me just stick it out. But if I if we think on horizon at one eight one three, then like when they really saw, we didn't we took it out. So I think like, you know, and so I think if if it's like if it's like a sort of y versus like, could you were in kind of discussion as martin move we have it? Versus a, you know, for discussion a different discussion thing. Okay. Thank you, Ak. I will add that the... Some of the load testing that we have done internally has has shown that a single server can handle something like a thousand Q gps of reports. Of p three sum. And then again, this is gonna be heavily dependent on the underlying B behalf, but I would suspect that these Cpu costs of evaluating some apps is going to be fairly low compared to the network round trip, especially for for aggregation transit the public Internet. Yeah. I I just want talk a little bit about the general question Yeah. Because I think. The current structure of deck is such that you've already made the decision to to throw certain pieces of general reality outside. By the nature of the system. It's a style arrangement. If if we're gonna put something like Api in this thing, we wouldn't wanna have later in in that situation. Or, you won't would wanna have help us talking to each other directly because the communication there essentially runs in a ring. Yeah. So we're already in a situation where we're building something that is is good for purpose. And close fit for the for the poplar and and and Pre. Designs that you have specifically. So I I think when you when you think about it in that context, the general question an advantage of the card design, looks a lot less lock an advantage in more likely."
  },
  {
    "startTime": "00:52:01",
    "text": "A deliberate choice that was made in order to facilitate a particular type of deployment in the future that I'm not sure I anticipate anyone ever ever doing. No we we have all of these systems that are that do Mpc. With, you, hundreds of different participants and people doing research on on scaling out to that that sort of thing I just don't say that happening in this case. Because when you're doing in all of those cases, it's just like increasing your exposure. So I I think this this idea that Da is in taught agent generic is more appealing than then it is a practical use. For the deployment of the protocols that we actually care about doing. Hey, Siobhan I have? I was just wondering you had a pretty helpful issue some sometime ago about talking about like, ingress costs and egress costs that you were envisioning, do you... It seem like this would help with those costs as well? Is that right? Now. I think you're transmitting the same number of bits but you are, you know, Yeah. I think you're transmitting the same number a bit. I guess less requests helps with... I know I actually don't know if that would help with cost, like, like, money costs But that's a good question. I mean, from my point of view, I think that would be interesting thing to see. It does actually lead to cost savings or projected cost savings. Think the everything thing was Yeah. Like the fact that it leads less complexity and Mainly that least less complexity seems like like a good thing So so, yeah. Supportive of that. Hi. Bench schwartz. Not. I wonder if you have thoughts on how this change"
  },
  {
    "startTime": "00:54:00",
    "text": "would impact the natural of the Api I know it's very subjective. But in the b Api, is a rest Api my experience often when you start trying to add performance optimizations to these kinds of system you you end up having to move away from clear semantics in your Http implications. Like, I requested a thing and you sent it back to me versus like, I'm requesting a thing, but I'm also sending you a component and you're going to then do some kind of complicated operation and send me back part of something else if we start... You are you merging operations in a way that makes some harder to conceptually model or or is it actually just simpler to understand. Single helper case. I think that's a really good question. I I is Tim's attempt. Do you wanna give a shot at answering? G Yeah. I think I can. Yes. To point. Then I spent a lot of time on the make for da. And I was trying to do the whole resting what I learned that Yeah. Like, trying stick to those you you just pretty it quite well. Copy with a. A lot of times it's not worth it. Especially where we're talking about something like this where. We don't expect, like a browser. To be able to go to the app stuff. Right? So we we expected anything that's doing that will be a server client that was written specifically with adapter line. So think we gotta be cautious about like, how precious we get about sticking to, like, rest semantics why. That being said... Okay. Do you question about, like, how would this change effect? The semantics of the H Api. It's not that bad, actually. And in fact, you can see a draft proposal of the changes that brandon had put together. I"
  },
  {
    "startTime": "00:56:01",
    "text": "think or hopefully it's linked somewhere these slides. If not, if not I wouldn't read it everybody to go look at the draft. Repository on github is just one of the small number of open under repository at the moment. You. A changes to the wireless messages right not that significant really. So I don't think it metals with the the semantics so the whole thing too much. Okay. So I I got into the queue for a different reason, my view which was to a response to Siobhan question. About egress cost. Sorry. Go ahead. I said go ahead. Thank you. So for quick context, like, the reason we're talking about this is because public clouds are happy to have you upload data into them, but then charge you a lot of money to move data out of their networks. So this is a concern that was raised early on in doubt. Okay. Let's see. Chris pointed out already that there wouldn't be the total amount of data that moves around with her without this change doesn't that should make a difference. But you will see though is that in the current draft, It's a leader's job up to broadcast combined verify your messages out to all the helpers. So it's a leader that has to eat all the egress noise. Now in this model, you would have the the leader and help boutique turns sending the combined verify message. Essentially means that the egress cost would be shared across the two ag maybe we feel that... Maybe that's more fair. That's when it. And last thing to say on cost, if we it's still something where you know, we're thinking about. Actually, maybe I should have mentioned this in like, stuff that's coming to the draft earlier. If we wanted to do something about that, the big thing to address is the size of the report shares themselves. Like the big thing is that the leader has to transmit to the helper the report here is sort of, band the aggregation sub protocol. So the way to am that would be to have... The one way to that rather, you have clients upload report here directed to either ag. But that brings... That has some complicated implications that we haven't got through."
  },
  {
    "startTime": "00:58:03",
    "text": "Thanks. Like Thank you, Kim. Thanks for the discussion on this. I appreciate it. I will speak to ben so that he goes too. I hope that you all got the input that you need there. I certainly think I got some input that I needed. And I think we're going to move on to star. Sophia is going to start with some performance measurements. And You I talked about the draft? A second? We do we do that, like how the proceed here? This actually has to get decided. Preferably. Editors. I I I think I heard a rough consensus in here. But are you happy proposing to the list in path four? And have some objection we move forward with that. Tim? So much or something. It's it's okay. It sounds to me like the thing to do as Extra pointed out earlier is to take some measurements that'll better help us decide whether this changes is is worth the trade off. So I think the next act here would be for say like, our team and and the Chris Patterson team to go implement this proposal and experiment with it and come to the working group with some concrete measurements of like, how... Is it faster? What's the difference bytes transfer, that sort of So what it's worth I'd be happy feature just benchmark ballpark that they constant data we already have. But it seems to me the main argument here is not performance inspector that we presented but rather Y. Right? Protocol. So I think if you need to... I guess, I guess what like,"
  },
  {
    "startTime": "01:00:01",
    "text": "Like, if you think this is with doing, based on that one, and we should forward. Don't think it's guess not alone most time about. I think it's worth doing I do as well. I just wanted to note that we're we're about to see a presentation that actually does put some numbers. To some of the the Cpu performance costs related to that. So hopefully, we can we can be informed by that presentation. Maybe that will will those most numbers to to because customers for the. Not. So There's the technique. I I guess I can. Item. What's what can you find and we need get keep it moving. And so like, I don't wanna... I don't want I don't wanna move on the presentation until a much weight it is we're going do I guess. So Not because mister sit downs you want, but like Like, they we need use this I moving. And so, like, how do we to how do you finish this? So Echo, you're saying you're fine with multiple performance numbers Alright. If if the authors in people in this room, feel like this is what doing you went up even if it that was not any faster, we should do it. And we should move forward. And I I can live with that. So if it don't is with the ring, then machine the performance number. So we should say it's users and not call list seventy to it. We should say it's number worth we have deployments and we shift numbers. So but I hope people for go through our outperform And so think we can forward that. Hi. This is Limited as at. Was just gonna jump in. I heard that this was getting pitched in two different ways. There was the"
  },
  {
    "startTime": "01:02:02",
    "text": "This isn't a database data driven kind of thing. We just get a lot of and implicitly simplicity will be good and we're we're gonna get that. That I also heard and there may be some performance kind a benefit we don't have our arms around it, but it may or may not be better. There's the offer to kinda get numbers but everyone I heard come up to the mic said, they're probably good on just the simplicity kind of kind of argument, I think, Martin, you got to set of best, you know, let's that's continue to grind you did it being fit to fit for kind of purpose. So if that's what I were in the room, way they gotta do this is let's just go back to main list, give it another week to say let's double check. New objections. And if there are no objections, we we kinda roll this way. That works me. Thank you. Chris? Are you still needing to say something? You know? Okay. Basically just that. Thanks for the discussion, Ec. Thank you for pushing us get to resolution. So ahead. Okay. Some can you share the slides so. Alright. Do I have to let that. Moment will be right of. It is. Okay. Thank you very much. Hi, everyone. My name is Cvs. And I'm crypto photography researcher brief. And today, I basically wanted to present you the beginning of our research word that we currently taking, which topic is different. But because of that, we also forms of measurements on the two schemes that have enough interest of the working group far I know which is the popular scheme that was just mentioned previously many of the talks. And also the stars team. And if you want to learn more about those measurements and actually put the bigger version of this presentation in the form of a pdf that can be fine"
  },
  {
    "startTime": "01:04:00",
    "text": "the Url of this slide. Next is like, please. Okay. Just allow me to set the scene, let's look at some of notation and this the notation that is going to be used either to the Stars scheme or to the popular scheme. And the first one because the size catering aggregation scheme, you won't have obviously a k, which is going to determine that threshold, which terms of what I have reading in the drops currently in on the part of a station at this working group, is the size of the subset of the different batches that you sent to either a collision of server or a single server. Also have n, which is a total amount of shares that you see share something two. You have seen which is the coalition clients that are going to be sending a next amount of measurements to correlation service or to a single server. Have s which is the aggregation server. The random servers that only exist in a store, not popular. And which is the message that you want to sequence share. In this case, the specific measurement that you want to send a client to an aggregation of service t which is an integer that belongs to the natural language that states in the popular scheme that a string sigma appears in the list in a list that can be defined as r eight one to eight. So see, more than three times. Sigma which is the screen the string that you want to I find that in that list an end which is the slice of. Next slide please. Okay. So that was just basically to set the scene, and maybe to give me a little bit of a background about this scene the scheme. Of the stars scheme specifically. I'm going to talk about more size because that might be not familiar for the people here in this working room. What I think that the progress team might be more familiar to people this room. So just to maybe they clarify what the stars is, basically car stars scheme is a k aggregation scheme, which means that if you receive k measurements about of case size of those measurements, you're only able to rebuild those measurements and meet that"
  },
  {
    "startTime": "01:06:03",
    "text": "threshold and not anything else that doesn't meet the threshold call. And there you prefer only below privacy of individual client measurements. So in this sky, we're basically using three specific algorithms where using our sharing algorithm good randomness this algorithm at the ten generator randomness algorithm and an encryption algorithm to perform all of their functionality that we need. So basically is line constructs the by encrypting the measurement and any auxiliary data. Using an encryption key that was there derived deter domestically from the randomness. Client sends the cipher I carried out of en randomness are times that informs how to them. Once the server receives a, what it does is that is an batches of case size, and only recovers whether measurements belong to those he case size. Let's slide please. Okay. Maybe less as this because maybe I will put down to wear some of the things that I have just spoken, a little bit more clearly. So the first thing is that I said that what you are going to do as a client is that you're going to be sending a measurement on a specific server. And then what you're going to do is instead you... So what you do in the size is basically with measurement you going to derive statistically some randomness. This can be done by the usage of an server you can also do it locally by using cash functions or a in City to derive the deter randomness, There's many ways in crypto photography that you can do that. But basically, what you get that this process is that you get a value that we're going to be labeling it as r I. Once you have done simply random value that was again derived the specific measurement at client. What you're going to do is that you're going to pass it in three pass, r one r two and f three. From one, you're basically going to arrive at the term"
  },
  {
    "startTime": "01:08:00",
    "text": "symmetric tricky key that is going to be used to encrypt a cipher that we're going to be calling Sorry. C. And then we're also going to think that that r one is going to be the secret the that you're going to see with. So you secret sharing a good to secret share one into different and amount of shares. For that secret algorithm as local at randomness, you basically use value that you also have that called are to. Once you have all of that, you have your share, you have your cipher apex and you have symmetrical. You're going to do also the claims is that you want to construct a message basically by doing a contamination of the cipher effects then the share, and then of this pack value, there is basically just the last third value that you derive from the ram Happy you go. You send that us a client to a serve. Next slide, please. Once the server receives a lot of these messages from different lines. What they're going to do is that they are going to group them together in batches of case size and how you're going to sort them is that you're going to look at the specific back of that message. There are value as you remember, and you're going to put them in a specific batches of case size, in which all of them have the same back Once you have them basically laid out in some nice batches, but you're going to do this run the recovery, algorithm on that specific shares of those messages to recover r one which is later going to be used to derive symmetric key and therefore be able to encrypt the message that each specific message from the client And in that way, what you're going to do this basically only the measurements that belong to the Cd k, a very specific batch of case size. And that's up. So next is slide, please. And as you say, this is a very simple scheme. We basically have a simple boring crypto a crypto and this is like. Very important if you about it from that point of view, we have very boring crypto because we basically have other randomness generation algorithm."
  },
  {
    "startTime": "01:10:00",
    "text": "That say can be an period, but can also be a hash. It can also be a based. Then you have a very simple secret sharing scheme, and then you have a sorting algorithm and also an encryption algorithm and you're ready to go. Is like please. Okay. So in the initial paper that david need proposed and was published in Ac Ccs. They perform some measurements and actually they show that the skin is very efficient because again, it's using really boring crypto photography that is implemented many variety systems on different systems. In General, So it's really amount you see here the they are the initial measurements that it really performs it. This is my piece. Yes. But there was one problem that I'm going to put in the next slide so let's just start looking at the secret sharing Algorithm. So right now, basically what is our basically defined to use as a secret sharing algorithm is one that we we have called in crypto terms as a depth c crochet And the original that paper is also listed here if you ever interested on reading about it, and it basically consist of the functionality, a shade generation and a secret recovery. A share generation you basically get the secret and in our case is going to be a client measurement. And you basically, what you do is that you generate and amount of shares with an instruction internally that the term means that but they belong only to specific threshold. And this procedure takes all of them depending on the bite message. Secret credit recovery is basically is going to happen is that you will be giving yourself a key amount of shares and then you're able to launch the recovery Mechanism but also has the same time of the same complexity and complexity as the The skin duration of Paper if you read about it, half certain security and privacy and also some level of privacy, one and it also can be expanded to perform a thing that"
  },
  {
    "startTime": "01:12:02",
    "text": "called error correction. So what it is error correction is that if you have our set of case size of different. And let's say that one of the shares was corrupted it because indeed, you can correct it. Then that algorithm room should be able of pinpoint exactly wish share was recover from that corruption and move along. And unfortunately, as it's stated in the paper, that's error correction. Algorithm has in a worst case of time complex city of two to the. So Not so. Fast. This is slide please. Okay. And of that as it was pointed out in the middle lesson this working group there can be any specific, which is basically this setback of actually having malicious shares and malicious client. So let's say that your malicious you want to somehow destroy the scheme? Then what you do is that you are going to based on corrupted shares and that you're going to be sending them to the irrigation server. Irrigation survey is going to take shares. They will not be able to pinpoint, which one of them was corrupted, and therefore all of the bad of case size or even a batch of inside is going to be discarded because you're not able to pinpoint exactly we share was corrected and therefore this card you will have to discard the whole set. So this includes the possibility as you see actually truly performing and the Us at that because you are basically denying this service of actually being able to recover the correct measurements. Next slide please. So one of the solutions I already highlighted one of the first ones is actually used the same secret in the scheme as the initial protocol code defined. But also perform Or aero correction. But as I already said, maybe this is not efficient because you would have to perform and today two I think operations. I don't exactly, but you can check the paper. Or, what you can also do is that you can also use the secret sharing a scheme that has very five there's many of them one of the most popular the film scheme and the Pate team."
  },
  {
    "startTime": "01:14:01",
    "text": "But there are many, many of them. There's a bus literature about and. In this case, we have only focus on them on scheme because it's the most simple ones worse over poly, so it's really simple to implement as well. But there's all this candidates in the literature. What you can also do is that there's other the constructions that you use that you don't have to use any kind of commitments so poly or any kind of proofs or rather, you can use all the computer science structure arrive to corrections. And right now we have a publication on the report, and indeed arrives to these two n times. But in this case, we just focus on the second solution So let's slide, please. Hi. Before we go to the next slide, I just wanna know I'm here to make sure that we get to the next part of the discussion about star. So you you may not be able to hit every point in your slides. Okay. Thank you. Okay. So, basically, as I said, you with this firm And you, basically what you do is that you have this secret in creation algorithm what is going to do is not only going to create this n amount of shares but it's also going to create with them at set of commitments. And those commitments is basically approved stating that each share was creating correctly. Unfortunately, you will have to create a case size of those commitments. So there recover... So the secret sharing algorithm is really fast because you will have to only create and shares and also the set of k commitments But the verification like could be considered not so efficient because you would have to verify on each one of the shares that are presented to you. You will have to verify that the that set of k commitments is valid. So you would have to eat rating that say it said of size k to actually verify that they are correct. This is slide please. Okay. So"
  },
  {
    "startTime": "01:16:02",
    "text": "We actually sat down and actually thought about the worst case complexity average case complexity, and best and complexity of this algorithm If it's more sense complexity, it happens if for example, you receive an amount of shares in a size of care a set of case size, And the malicious is at the end, then of course, you would have to reiterate iterate iterate and perform key operation page one of the shares until you reach the end of the the end of the set. Therefore, you have a worst case complexity of o okay times this size of what they were say. You have an average case complexity that is difficult to define because for an average case complex City you will have to determine what is the possibility that attacker to fast corrupt the shares and also to control the network in instead a way that they arrive in an specific order in western complexities, the contrary of the worst science complexity city because in the malicious at the beginning of the subset, then you're ready to go, You only have to verify one. Next slide, please. Okay. So now for a maybe interesting part of these setup talk. So what measurements we actually did. We we actually implemented it and I know that they Of light Loss running code. So we actually have running of the secret algorithm with this display scheme that is called. We implemented it rust the latest version of ross at the time of was speaking. And we also implemented it and we implemented it the the most apple with done Apple m one max. And we also implemented it with two curves with Christopher five one with the and calling and also with curve that is called sector five six k one, that is popular because it's using some blockchain application. And we found out that. Next slide please. It actually performs relatively well. In this case, I'm showing the the performance numbers for the specific curved the f one nine group. But as you see here that if I if I sent a report size of a thousand at two hundred annually and the threshold is one hundred and twenty"
  },
  {
    "startTime": "01:18:03",
    "text": "then it will perform in five seconds to complete a verification recovery procedure. When you seen this specific curve, next slide please. But if you're using a curve that is indeed more efficient, six k one, which is thirty percent more efficient the five one nine. You arrived to the same specific parameter two times two point zero five seconds. So what we see here is that the skin is dependent in two things. The size of k, and then the line field that you're using either This could be your final feeling if you're using human or the curve that you use. Is like. And here in actually grabs you can see how the skin grows proportionally in the size of cake. So the axis represents the the size of cake. And then the way axis represents the timing seconds and we see here that when we the I'm amount of shares to recover they still grow proportionally, you see the tam proportionally on the size of k. Next is slide piece. Again, this also does not only depend on k on the size of okay, but also on this Specific curve that you're going to be using. So we see here but if we compare fifty of five one nine with six two five six. Obviously, the curve that is faster is going to be arriving too much more faster times because Again, you're using the operation in a much more faster way. This is like, please. Okay. So basically, that shows that this is indeed this is an vision skin, you would have to actually turn in a correct way the cape parameter and also perhaps use a final field or on curve or around the line curve that is fast as well. But we can also think even a little further and also think about what will be you're actually grading and a smart verification algorithm. So the verification appreciated procedure right now that I benchmark market basically runs every time that you present them an amount of shares."
  },
  {
    "startTime": "01:20:00",
    "text": "But what if for example actually the define like for star in which that fast, you actually execute the recovery procedure And then only, then if it fails, then you perform the the verification procedure. Which means that you will not have to be executing this a little bit more timely consuming in verification, but rather we need actually face recovery then and only if you perform verification. In that way, we're actually creating something more small. Next slide, please. Okay. Because come? Do we want questions about these measurements now or later? Okay. Okay. I'm going to just go very fast on this. Which is you is distributed upon functions as you all know here, but the scheme instead of being dependent on the k value as it was with a star. It is dependent on n on l. Sorry. Which is the length in bit of the or whatever message you're trying to find out the most common values Missus slide. We did exactly the same. We also benchmark it in ross, by using the actual implementation from the original are paper by eight But one of the problems that we found out is start but specific implementation was in an older restaurant rust. And also that version of loss only compile is specific all the version of the up system. So maybe these spin are not that accurate beads of that because we had to use some environment that was a little bit older. So bear that mind. And what we actually was more interested in this case, was to actually see how the scheme behaves, it will increase the size of the string that we are going to be searching for. So we use both two five six and also five twelve bit strings. We couldn't increase much more this stream because the code segmented first segmented when we try to increase the size of the, But if we use another implementation that could be easily silly benchmark."
  },
  {
    "startTime": "01:22:00",
    "text": "Next is slide, please. Okay. And what you see here is that we actually using a threshold here that represents that more than zero point one percent clients holding specific string, where have times that are a little bit bigger when compared to step when increased also the size of the input of the specific string that you're going to be using Your arrive also too much more longer times. But I will argue you later on the final completion that is this not so bad as you seen here. This slide, please. And again, what we see here is what already the time complexity of the is telling us. I already told you that it's dependent on on the string size. Therefore, you would see that that when we increase actually this So the string then the increases as well. Next slide, please. Okay. And then just completion. So the completion are basically that is start with the specific seems to be efficient for a specific values of cake that can be bigger than ten probably for useful purposes, you don't want okay that it's a smaller than that. And this also is smaller than one hundred and twenty eight approximately. Generally from the real world, it seems to be useful in practice. I asked a lot of implement of K and anonymity schemes and they told me that there's those are actually used for values practice. And it says sufficient depending and find field all the curve that you use. So if you use two five six k one is going to be much more faster than if you use of performance. The performance on the country is sensitive to the l twelve, which is the size of the string that you're searching for. But in indeed public performs better we Bs when given, for example, a large percent of malicious clients, when you have a large values of their cable, But again it is difficult to actually compare these schemes and put them side by side. Because burden of them relying on different... In different photography,"
  },
  {
    "startTime": "01:24:00",
    "text": "And also because they behave differently, so put for example, you have the computational plus the communication times of the service because you speak to each other. When in time most of the time only have the communicate the computational as size from the service size. So comparing by side is a little bit like comparing post oranges. But unless we can take some individual measurements of the. This is that piece. Yes. We have future like. So the idea will be to actually measure the whole system always with assessed instead of our measurement of but this probably not much things because the boring crypto I guess added on the star is pretty extremely efficient so would not We like to update a quote base a to actually perform measurements with version of us, But as, I rightfully pointed out on the main list the other day, there's already an implementation of popular only please we probably can just take that on benchmark We we also like to formal this verification algorithm. Annoying way. So if we're going to introduce verification in this side, we should also use the same security of the scheme in the original of paper I use and see that all of the security and privacy properties hold. And we should also formal less and eventually present to this working group, the scheme that we're currently do a better correction that arrived to work. So I'm going to research an engineering work. With that I think that's the final light. Thank. That's. Yeah I do want to get to this to the discussion of whether or not to bring this into working group as well working to draft, but there are questions about Go ahead echo. Yeah. So Do you... Yeah. So I'm trying to get a sense of, like, what the the real world complexity of this algorithm. So you describe their verification complexity that's that effectively is the complexity of the best case really with no problems."
  },
  {
    "startTime": "01:26:03",
    "text": "So do you have measurements, you have simulations or or or c computations or say, percent of the... Other portal randomly we damaged. So right now we don't have that, but I know that our previous currently has some effort to actually put it in deployment, so there we can actually measure. And then I agree that I will be yet really good. Also, because On this scheme, I have only presented the computation as complexity from the service side. It will go to c also see the communication and complexity plus yellow. So it's I I mean, I I don't think we need to have it in in in the field answer this question. Right? Just a simple question of how many times how many purification passes you have to run at given tape rates. Right? So I think it's a appreciate straightforward for. I'm pretty... Pretty your for monte Carlos gonna like that, but I mean I think I guess it was really helpful. I think I understand it's hard to compare the grapple on apples apples. Be very helpful to see some candidate parameters and like curves for performance if each do these things are support trying to make decisions performance. See no other questions on? I think it's time for your. I thank you With okay. Requested to share. Think I should be able to do it on my phone. Okay. Let's see. Then you should have the call. Cool. Thanks. Hill, I'm Sure siobhan. I've been a version of this presentation in the past. So this should be fairly quick. And we can get to the main part, which is questions. Oh thanks Roman. Yeah. As Sofia sophia mentioned and went into Way depth. With star is to use"
  },
  {
    "startTime": "01:28:01",
    "text": "k for for clients, reporting measurements to server? And the goals are it should be cheap. Simple and private and like, did here that the client should be able to verify that. And then sorry you client can actually verify that the the that k value that's being used. So it's not it's not hidden from the client. Look server can just be like, yeah, key equals one. And just this... The client doesn't have to trust this over about that. This is yeah. Kind of a repeat. What I said, client wants to send certain telemetry value to the server and But only he wants to sell what you see if they're at least k values. That look the same. There's a bunch of implementations at this point. It's shipping in the brave browser, there's the few also different variants was the original one, which was just using regular regulation. There was the verifiable one that Sofia sophia talked about with benchmarks and Chris also the verifiable implementation and go well, also with benchmarks and the two thousand and binding so quite a few implementations at this point. And yeah. I mean, I think we're thinking about given the various attacks that we brought up and discuss, pretty extensively. The last year or so. On the Meaningless we We others have, like, made several changes and kinda done a lot of, like, leg work around, figuring out how we can mitigate those. This point, I think there's, like, various trade offs around measurement and I mean performance And complexity and what what, like, you know, what threads mitigate. So kinda put that in a table here, but I think The idea is that there's, like kind of two axes that you can like, move around like there's. A secret sharing scheme like there's the regular one, and there's a very verifiable one. There's also the signature scheme or protocol and back... And classically in the paper,"
  },
  {
    "startTime": "01:30:01",
    "text": "we booked with, but you can also use Oc bank signatures, which is think that Chris, Chris idea, and I think it's it helps with one of the attacks, which is the bad s for attack. So I think yeah that's... We haven't really explored this too much in the draft, but I think that is something in the next draft I think version would be good too couldn't to nail. And That's about it. I think This seems to be interesting star from what I've seen and we black. We work with the working group on getting it to a place where I think everyone's specific, like threat models were addressed, I think at this point. So I think from my point of view, I think from the author's point of view, we should just work out like the remaining stuff in the working up soon. Yeah. I think we'd just like to ask for a adoption. I think that's my last night. And, yeah, I think happy to take any comments and questions about that? Chris. Do you blind signatures help with the bad cipher tech problem. Yes. So I think idea is that you are then encrypting the the signature itself as well when you're sending it to the server. Then when you decrypt it on the server once you reach a certain k, then you get the signature and then you can verify that. That is my understanding. Yeah, I mean, it's kind of like just it was just an idea that we had and Yeah. I think it's worth exploring that. Like, putting that formally down in the draft. Martin? I realized we keep coming up with problems. Here and as good that's I guess, part of why we do this, but the basic shape of the protocol is that some number of people will submit a value to the system and you won't be able to query the system until at least k people have submitted that"
  },
  {
    "startTime": "01:32:03",
    "text": "same value to the system. But it turns out that if you if you know what you want look for, you can effectively use your Ip for or blind scheme and query this for any value that exists in the system at all. Which I think is a problematic characteristic of the of the proposal. I think you've you've talked about the fact that the inputs to the system have to be high entropy. Mh. And I I think that's that's still not necessarily it defense against the attack where I I wanna find out if if people have visited a particular website. And inputs of, for instance, I can I can still say this particular url here, I wanna know whether that's entered the system? At all over even over a given time period. And of course, those queries destructive in the sense that you once you've say the the k values into the system. You're done. You won't know where other people have submitted any values into the system at that point necessarily, but you can you can still put on value in there. So What do you what do you do about civil attacks effectively is the question? Let's so the last sentence again seventeen month. What what do you do about civil attack on on on the system. Yeah. I think we been peaks explicit about the fact that we Yeah. Like we don't try to deal with similar attacks, I think that... Yeah in the fact that is vulnerable to like a like a the fact that someone might try to create for a certain thing. As you mentioned, we who reason randomness exists is to provide time on that, but you're like attacks So exists. I'm not sure if you've I think I think we have takes around that, but would you like like it is? Randomness server intros that you have to be online to make that that attack. It doesn't doesn't really change the because. You can't do an offline attack on it."
  },
  {
    "startTime": "01:34:03",
    "text": "In the sense that you kind generate the values that go into the system without having access to the Ip or the randomness server. Well the server also helps you, like, if you're if your input spaces is limited then like, it... That... Like, that's the main value of it right to onto to Like, kinda, like provide van and that like could you like, maybe repeat that all online? So if it the done going in the system chosen from a small space. Of of potential things and and there's, like, five bad five different options that people could submit into the system. It doesn't matter that you've got around this maybe because I can simply just walk through all five values. Submit kay things and and work out work out exactly. How many other people have submitted those those each of those values. Mh. So if if you you haven't met the threshold, I can just ensure that you meet the threshold any given input to the system. I think results in line to maybe of that, but I think the idea also that we do an notation to help with that. So he did you have something interesting one? Yes. I'm not sure which one is the line. What the world I take this one. So what you're talking about is the degree of leakage, Right? That the scheme has So there's two things any teachers aggregation scheme exists will have a degree of leakage unfortunately. In this case, we use the randomly just to locally have another entity to the derive the randomness, but you can also have it locally, but with this same problem. One of the things that you can introduce is the financial privacy at some point, so some of the values we look random them enough. So they will not be or some of the values were indeed with Random, the attacker will not be able to launch that and much. Indeed, even the problem of the side bats like is can we"
  },
  {
    "startTime": "01:36:00",
    "text": "consider as differential privacy. And that way, two eleven. Some need to do I'm back to a level can that degree of leakage. So may like think a step back here. First of all, it would be really helpful if you talking about the local data rem it's not... And it's really hopeful sounds. That way, like, the local data is fixed. And the randomness if anything comes in the server. And that problem with the main scheme is exactly that. So if you step back and look at the Ai scheme, but one is in pro and then is in next star simple star, which has the problem that you can offline is also search all the muscle one. Supervised multiple small space. The radio administrator replaces that with having an online query that space. Right? Right. And so is actually a little worse than nothing Martin was just the way you're describing it, which is that don't need to get to cable. Like, for any any any value, I think maybe in the set. I percentage to the server. I get the tag what do list Period full stop. So So so they the the the the the situation for, this is useful. Is one is for keys, which are in a larger in space that is not... It's small enough space there's not that it is... Sorry. In large space that is not practical just so oracle. And in his smile space that Right? And so I think the question is, like do we actually have a that naming me how many systems do we have? Where the you wish query client. Where essentially the client values because this is like... It's a very goofy set of privacy properties, which is that if your Which is like, if we wanna capture say wells, right? Of those with hydra entropy and will not be que by the oracle. Seven in the. And so what guarantee we tell people if we collects say and we say it's like, well, if you're url is like Facebook then you host, But if you all is like a Google back or career."
  },
  {
    "startTime": "01:38:03",
    "text": "I guess bit hard thing just explained them. And so I think the question is, like, what is the environment which this is like is is like regional privacy properties. Yes. So I agree maybe later, we can actually formal less properly, but I took everything correctly. But I agree that it there should be a section also at least on what kind of high should be valley should be. And also we're going to be adding differential privacy, how will work on how to a it will stop but later, I I will fetch you through. Is Ben is next queue? Hi. So first, I mean, Eric just asked a a question about about use cases that line up nicely with the properties of the system. If they any one has a... Has a use case that I think, you know, highlights a good application of start. I would also be interested to to hear about how about hadn't heard up with the membership property I mean, we've... We thought about use cases in terms of the analytics like in terms of you know, how many tabs is a there's it there's a user have opened or that in combination with, like, what vision there from or what is there on like, that kind of stuff? Be... That's like what we're shipping right now. I guess Why isn't that just pre. I don't understand. Trail. Because of the fact that it's like, complicated and expensive for us run. That's like the... That's like the what are the main moderators for for star. I mean, I of the point stars are collecting arbitrary strings. When you're collecting here numbers."
  },
  {
    "startTime": "01:40:04",
    "text": "So the way confused Mean We could like like, most the data in inflammatory record without like even I trying to buy to parties that. Right? I like, most people just quite this day directly. Right? You collect that demographic information to clear and you have a counter. Right? So as I'm trying to like, I work out with the use cases here. So you're saying most people collect that kind of data in K. Yeah. But we that that's a problem, and we shouldn't be collecting that clear. But I mean, again, this is like what this just like what pre was for. Right? Precisely case scratch designed for. Right. But like given that star is cheaper and and faster, they could that's that's not the fact probably Vs dash for. That's not platform. For certain care values like like what Sofia sophia showed and, like un part of star, which is like, a second significant portion of our deployment. That I. You and I had this conversation before? Yes. Is like not relevant here. The question is with the it you see protocol, doesn't has the properties subscribing. And So like I think in order is that you you compare a verified version, to. Not like version. So so, you're saying that Star should only... We should only talk about verified and not Afraid. Is that? Yes. Okay. Gotcha. I mean, I think from my point, of you... The went of few, I think gonna be. Yeah. Because we found value in the deploying of un version you this? Because for telemetry, like the, you know, If there's a bad batch like we can just throw it and we have the application defenses. That's not a d breaker for us. But that's not what you started out I guess, yeah. I guess we this a separate discussion. Yeah. I I guess I guess like, I'm just trying to fail like, with the use cases. Like, you just out to use cases seems like automate. Now like poplar. Okay. I guess I'm just gonna repeat what I just said so. Okay. Yeah. So I'm not sure how to put myself in the case having the loaded application. But one of the things that took come into to my mind is"
  },
  {
    "startTime": "01:42:01",
    "text": "Come? I closed the queue already. Oh, I'm sorry. Okay. Okay. I'm sorry. I was Okay. In Chris, do you need to say something to this? I just wanted to follow with the question ben asked about use cases. One use case we've been thinking about is now So you have domains and, like, network errors And star would probably work. That's like a... It's a heavy hit sort of shaped problem. And star might be useful for that. I don't know about, like, men entropy, like I don't know hatch much entropy like the submission of, you know, a particular domain would have. But That's a discussion we can have. Cool thanks. I mean, I think if the question around use cases, I can I'm happy to, like, put together a document on use cases that like it's surprising to me that that's the issue here. Yeah. Because we mean like... Yeah. I think there's it's pretty clear that there several use cases Yeah. I I think that it would be really interesting to see use cases that you think that hit star better than they fit P or Sorry just clarify, I think it's use cases given that all the other benefits around like performance and and the cost of deployment and stuff like that. Sure. That was actually not my question. My question I wanted to ask you was specifically, do you imagine that access to the randomness server is effectively open or effectively access controlled."
  },
  {
    "startTime": "01:44:02",
    "text": "Or somewhere in between. I think it could be either depending on the deployment and your specific set model. Like, maybe have, like, application defenses, like, if you know, but like, treatment one would be, like, just Ip denial, the the aggregation server. But but you can imagine that you can have stuff around that. But, like, one of the points that around like, having an epoch and the fact that these is to prevent attacks against the aggregation over. I don't know does that help answer the question. So basically, it's to the deployment Yeah. I just... In in terms of, you know, your your perspective. It it sounds like you're you're saying that you you have some sort of soft access controls. Or a abuse dimension. That's sort of the where you landed. Yes. Yeah. So the question that cheers are facing is one of adoption. And echo use case objections. Do you think that they can be overcome? And are they actually objections to adopting the document? Don't know think could be able to come. I wouldn't asked the question wasn't rhetoric. Yeah. I think the documents have a use case. I I do think that by documents have used case that like something else as. Yeah. I mean, I think it does have plenty of use cases given the other performance and complexity consideration. But once again, ...this is because you decide you won't care remember everybody. I'm saying even with the, like we have certain case for which this just does work from I mean, we when we can like like draw flow here. The but then the one time here is that Like for lower inputs, this is like not secure for the reason Why was indicating."
  },
  {
    "startTime": "01:46:00",
    "text": "Mh because you're gonna... That's the oracle for the values. Right. And So on and and So the question is, and for very high... And so the question is, like, what are the input sufficiently high entropy to be safety using in the escape. And, like, is example you gave me Isn't one of them? Is you gave me by the demographic similar tabs, it there's like, maybe ten thousand possible values. So like, like, the we isn't we here in that case. Thousand So it has to be something that has pretty high entropy high enough that oracle a real. And so I'm asking for is, what is that Taking a step back. I think do we... So I guess you're saying that it's not worth adopting the draft and working on this as a working group until we come up with these like couple nice yeah. Don't think it to be like... I mean, what I'm trying to understand is like it's like, it's like, why is like, what motivates this work? Like, why is it Protocol? Especially his have been quite of time cabinet what it can can't be used for. And so I'd like to see a case where like this was this is obviously better than the systems we you're currently wearing on. And there is one great. And he's like, it's like, I think like, as I said in based on of presentation, I think it's quite likely but this is faster than popular for, like, quite a number of situations. Right? When the question is, because They say, once you have very high contamination rates you're actually gonna only have to run approximately k you know, k or two k or three k verification. So that seems like assuming there's numbers are right remember reason. That seems like a pretty quick. But the question is are there input values that is useful? And so I think... And I I may I don't know. But like seems like was it email now was should be enough answer to this question? So last. Like email I'm like not asking... I'm not asking for, like, extensive I'm saying like can we have like, two examples other for examples. Roman Mustard? Hi, Roman a as Ad. I just want go pine on how to help the chairs kind of figure out what"
  },
  {
    "startTime": "01:48:00",
    "text": "next. I mean, what kind of strikes me here is we have one person coming to the mic saying I wanna hear more use cases. I don't see other people at the mic say, no they're like, I'm good to go. I have not looked take kind of the mail when this to kind of track. But that that... That's a data point kind of for me. So we should hear if there are other voices that have opinions that like we're ready to go. Let's hear them too. I think we did have one point about how there is a use case. Right? Mean, specifically think we can have that discussion look on the list. And being aware of time, I think we should give philip a chance to do his secure conditioning for our presentation. Thank you Sean. Cool. Thanks. Problem. I requested slides. I'm not sure I got them. Alright. So Yeah. So so I have the. I want take a step back from concrete protocols for"
  },
  {
    "startTime": "01:50:01",
    "text": "aggregation? Hello? I can't hear the room at all. You cannot hear me well? Like this, maybe, better? Better No. Sounds good in the room. Well, okay. Alright. Yeah. Okay. So yeah, I I wanna talk about something that's useful for many measurements protocols, and that is secure partitioning. So the motivation for this is again measurements and aggregate measurements, and we've heard protocols about that. Something like that or something that's custom. Other working groups is example, this Ipa protocol for secure ads measurement. So the general setting for these, we have lots and lots of clients, think billions And then a couple of servers that perform some kind of multi party computation. To actually get the measurements. So the clients will upload there and encrypted reports to this to Cluster the M embassy cluster will do some computation within itself. And the result of then given to some collector who gets the aggregate result. Now the main question is, if we have only a couple of servers that process the data from billions and billions of clients that's going to run into some Bottlenecks in terms of memory in terms of computation and so on. So what we would like to do is chart these clusters. So we'd like to have many copies of these couple of servers. That each operate on a subset of clients. Now the issues, how do we distribute reports across these charts. How can we make sure that all of the shards that correspond to a certain client? If we want to aggregate with an client end up in the same chart. And that is basically what I'm trying to solve with the protocols that I'm presenting here and"
  },
  {
    "startTime": "01:52:01",
    "text": "I would like to have a discussion in the working group or in the About So the goals of these protocols should be that the overhead is low. We don't want to spend more work on the shard than we're spending on the computation. So we okay with a small factor overhead, but that should be a small factor. And same for wrong complexity, so having a protocol that takes fifteen rounds for doing a shout shard. Is maybe not worth if we then doing that to round aggregation protocol. And finally, we don't want to affect utility. So that is more design choice so maybe for some aggregation functions, it would be okay to affect utility. But I think it's possible to do it without affecting utility that's why I think which would aim for that as well. And yeah, then some assumptions that are making is that we have a bound on the number of contributions per client So we will have that to ensure differential privacy anyway and many of the protocols being talked about want the french privacy eventually? And again, as I said before, we have billions of clients and a few thousand maybe that's also some something that needs to be considered. So the threat model as with da and other measurement protocols, we have non cooling servers and here, I'm going to stick to including service, but you could also think about extending that to three or more. And the part parties are assumed that they can mis behave arbitrarily, so malicious security as long as we have at least one on a server, and the output of the positioning protocols should be private. So I'm quickly going to go into differential privacy. The definition just what it means in this particular tool server setting, that I think it's just the general of the general Dp definition. So In more detail, we have these many clients and the two servers, it the adversary is assumed to have access to one of the servers"
  },
  {
    "startTime": "01:54:00",
    "text": "and as many clients as once. And with that it's trying to analyze this view to learn something about a particular client. And now what differential privacy gives us, is that probability of observing two views that change in one particular climbs is close to each other. And what close means that is defined by these two privacy parameters at Epsilon Delta. Now the general blueprint of the partition protocols I want to talk about follows this particular structure. So we have two servers. And the way that we assign clients or inputs to a particular start, is by of an F computation. So the client will upload its value and it has some kind of index that identifies the client and will also identify the chart. And then some payload that gets input into the multi part computation after target. And it put both of them, where the encryption of the index is done in a particular way that allows the first server to apply the. So in the semi setting, A is what used here. In the ministry setting, there are different crypto systems like the Dolby Crypto system. That allow for evolution of an. So that is done by this first server. It can the Under the encryption given its private K, and also add some dummies and the way at these time is is to ensure differential privacy of of the output. It will then forward these encryption after we run randomization to the second server. And the second server can decrypt, get the Values and from that can assign client and put so. So that's the general blueprint. And now the question is, how can we instant that for a particular setting."
  },
  {
    "startTime": "01:56:00",
    "text": "So the first I want to talk about is if we have an f that directly maps client inputs two particular start Id. So let's say we have thousand twenty four stars. We have a ten bit output In that case, the the server one can actually add dummies to every single possible op output because it can just en all the possible outputs and then generate dummies for each of those buckets. After the second server gets the. I value, it will directly know which chart this particular input goes into right So that means for each client, we have a charge fixed right in the beginning and server tool just assigns the charge to the to this particular value or cut the value. To this particular cipher text. The amount of noise that we need in that setting is actually quite low. So if we do the math and think about, okay, how much noise or how much random dummies does the that server one have to add for each Output. Then you get to something like forty nine or fifty m, where m is the maximum number of contributions that similar client. And now if you think back that we have billions of clients and only a couple thousands of inputs that maybe this is a very small overhead over the size of a shot that we have anyway. One thing to note here though is that the size of the chart will in fact still revealed information to the to to the other party. So that means once we release the size of a chart, we have to make sure that at least one on party added noise to the size. And so in particular, in the setting, this could be mean that both servers have to add this amount of noise to to that chart. Yeah. So that's a very simple protocol that already allows you to distribute inputs to"
  },
  {
    "startTime": "01:58:00",
    "text": "shots. That... Oh, lost my flash. That only has one drawback and that is in some settings, we might want to do some local before doing the between the servers again. And that's the second partition protocol I want to talk about. Budget addresses. It allows the server who gets the partitioning after assigning inputs to petitions, to do some local aggregation. For example, if you have value that is encrypted under encryption, you can do local addition for running the the So that's what I want to call the spouse positioning. And spa because here the Output is not a dense domain, like one to thousand twenty but it could be something like one hundred and twenty eight bit identifier. So we have large Outputs. The the structure other than that remains the same. So again, we have the client encrypting under a certain crypto system their inputs to the first server, the first server ob oblivious evaluating the. And then the second server getting the output of the. Here now there's a challenge and how do we add dummy because we cannot just all the of the Op. And add a certain amount of damage each of them because that would require far too much noise and probably has exponential run time. So Yep. It it's going to be a bit more complicated to how to adam There. But we have a paper that was published in Ccs last year that addresses exactly that problem. That allows us to create these spa. And now the second server can perform a local aggregation and then input whatever gets from this local navigation into the embassy. So one question here is Now we don't have we don't have a hard Id directly coming out of the."
  },
  {
    "startTime": "02:00:01",
    "text": "Because what we get out of the is this long su and stream. That is general pseudo identifier of client. So how can now assign these to charts? And one approach them proposing here is basically we just take charge of a fixed certain size so of caps size that does not reveal anything to either server. The size chart. And then the server who learns the appear f value is is just gonna fill up these these charts with the cipher texts until it's full. And what do mean by before? Is the number of cipher we have the number of. So once we reach that many cipher in that particular chart, we say, okay, that charges. For one we start with the next one. And we can guarantee you If we just have, like, a slight number of charts that we allow above the threshold that is exactly the number of inputs that our client can contribute to contribute, then allows us to distribute all of the inputs without any any was being left out. So one caveat with that is that we are. We are we are over overtime for this session. Okay. So you I'll finish up. Couple last few words, but we're we're officially over overtime. Yes. So the that was basically the content of my presentation. So I just wanna say that there's a slightly larger overhead with the spa protocol And in general get some interest from the running group into working on these kinds of particles protocols, what other settings at must be useful, so I don't know much about star, but maybe it might be useful there. And what other properties, for example, ordering of inputs we might want from positioning protocols. Thanks."
  },
  {
    "startTime": "02:02:07",
    "text": "Thanks a lot for this presentation. You know, as I said we're we're over time. So I don't know that we can really have a discussion about this. I would encourage everybody to also check out phillips other presentations, this week. In Per. I'll try to go into more detail. Give more time maybe. So if this if this seemed interesting to you, then there's gonna be more opportunities for you to get more details? And and ask questions. Thanks. Okay. Thank you, everyone for coming to. And see you on the list. Oh okay. And so Hey. Good. Are you? Good how are you? Freaking jet."
  }
]
