[
  {
    "startTime": "00:02:17",
    "text": "yeah apocryphal it\u0027s okay as long as you\u0027re taking minutes Thank You Nathan Jabbar scribe anybody it\u0027s not like it we\u0027ve got anybody in the room and Jonathan has volunteered thank you we\u0027ll get started here in another minute I\u0027m sorry we\u0027ve actually got a short agenda today so we\u0027re gonna give people another minute or two to wander their way in we have whites I don\u0027t think mites are gonna be the problem part of Canada bugs sorry they\u0027ll kind of paused but physically stopped me I\u0027m just the hip dirty say like we\u0027ve gotten through the floor hesitation then power goes out then here I could say I think we should go ahead and get started I think I know there\u0027s a few more people that are going to be coming in but um go ahead and uh so welcome everyone to Montreal in every C session no well this is the new one make sure you\u0027re well aware of it please declare any IPR that you\u0027re personally aware of it doesn\u0027t have to be your own IP are welcome to make third-party declarations as well now for this working group in particular where we\u0027re trying to have multi free deliverable it\u0027s critical blue sheets are going around probably need to go around again because a lot people came in after they circulated please just keep them circulating we have one note-taker already Nathan right we have a second anyone else "
  },
  {
    "startTime": "00:05:18",
    "text": "you volunteer I\u0027ll probably take some notes myself here you already have Jonathan as odious crab Thank You Jonathan yes and uh Jonathan will actually be presenting remotely - all right so agenda bash we have the room for two hours but we\u0027re not going to need that we currently have about an hour of the agenda scheduled so we\u0027ll have update on our our workgroup documents the garments and testing and then we\u0027ll have updates on the codex xvc and authority one comparisons and then we need to have a discussion about what to do with the workgroup after after all the Kota candidates are not presented any other topics or adjustments that we need to make all right so the status of the workgroup our milestones for the first two deliverables requirements and testing are a little bit late but they look like they\u0027re they\u0027re doable pretty soon I think both documents will probably ready for Walker class call again but we\u0027ll see after after those presentations the big the big problem is the last three milestones the codec specification reference implementation and storage format we do not have a single merge could a candidate that\u0027s been adopted yet and we need to have a discussion about that following the presentations about what to do as a worker for this future work so starting with requirements Jose or Alexei are not on right okay so the requirements draft was a minor revision to add the profiles and adjust them to match some other industry fora that are using this document as input so there\u0027s a definition of what bit depth and chroma subsampling formats are allowed in each profile and we\u0027ll do a final probably two week work request calling that starting probably at the end of this week and close off that document and start the Shepherd right up so requirements pretty much done on to testing Thomas all right study from Mozilla and I have "
  },
  {
    "startTime": "00:08:19",
    "text": "another update of the PC testing draft okay sorry yep Thomas ad BC testing draft today next slide so there\u0027s only one change to the testing draft since last time I added a section on subjective tests there was already a section on suggestive tests but I had to add a lot of more information people complained that there was two different types of test pair comparison and the mosque or evaluation method but no guidance on when the pick which and also a lot of detail lacking so what I did is I took the pair comparison tests and expanded the section a lot I gave actual criteria for evaluation we can look at the next slide oh sorry yeah this is the last slide so but there\u0027s one more slide actually but yeah we wrote the pair comparison section on we actually used a methodology net pair comparison section will be used to test the cdf tool i\u0027m just an example of the results we got from one of the tests so we\u0027ve already made sure this methodology works so that this is a basically produces you\u0027ll get a votes for one side the host other side and you know votes i couldn\u0027t see a difference with images that are the same quality or in this case it was actually videos because i added a section for videos as well and you can see that there you know there\u0027s a strong preference for one for the other there\u0027s actually a way to compute you know there\u0027s a rule that says how many votes you have to have for it to be considered significant for example our are the fused in math and subjective test section the second third and fourth we\u0027re videos on this result page or considered significant but the first and in fifth and sixth ones aren\u0027t the colors are just for the color the far apart so red is voting for cdf a filter on a green is voting for the cdf filter off and then our gray means they could you couldn\u0027t tell the difference between the two so we gave the option for a tie button basically and in an exercise hey yeah I didn\u0027t we added a guidance to use and basically we found that the mosque or in method was not very popular because it was really expensive to do and secondly they were because it\u0027s an app you\u0027re giving an app\u0027s of quality rating we have to have a testing environment set up they have everyone go through this special environment that\u0027s basically really hard to do when you\u0027re relying on people\u0027s contributions you know so the fair comparison is really nice because it\u0027s robust against different test setup so you can have a huge crowd of people do it basically on their laptops and you can always view basic looking in relative differences so the apps the test setup isn\u0027t as much of "
  },
  {
    "startTime": "00:11:21",
    "text": "an issue um so that\u0027s basically all the changes I did the district pretty much nothing else was touched I think there\u0027s a couple minor myths but at this point is basically done so any questions that emerges area director so you think the next steps on this is basically writing up and asking for publication yes okay thanks so the chairs replying to issue a last call right after either after this meeting or before the end of this week your comments good okay thank you cool thank you next up there hello can you hear me answer you oh great perfect okay so I will give an update on the expressive video codec and present especially what has happened since the last IDF meeting when it was presented for the first time so we can look at the next slide please so I\u0027ll just give a short introduction to what exbc is and then just mention about the technology but the focus of the presentation will be about what has happened since last meeting news since IT f11 and then I\u0027ll show the results and results for the new royalty-free baseline profile of exbc and that\u0027s basically and then the conclusion is that actually C is considered a candidate for fournette we see so if we look at the next slide please so X you see is what we call a next-generation video codec we released the first version of it in September last year and then just a few weeks ago we released the second version of it the compression performance of X PC is better than other available codecs it\u0027s been developed by a company called the vision it\u0027s a software-defined open-source video codec there\u0027s also a commercial license available from before it\u0027s from from Davidian and we have a specific framework for for dealing with the evolution of the codec which I presented in more detail at the last meeting so if you have access to those slides you can look deeper into that we also focus quite much on making sure the decoder is "
  },
  {
    "startTime": "00:14:23",
    "text": "running fast and and the decoding complexity isn\u0027t too bad so we\u0027re actually have we have a JavaScript version of it which runs in real-time at our webpage which you can check out next slide please so this is just a recap of the technology which is in X we see there is quite lots of similarity with conventional codecs such as ABC and HVC but we have built or included quite a few novel tools which are some of them are listed in this list and one important aspect of the exbc codec is that all of the coding tools are isolated within restriction flags as we call it which means we can we can control from the bit stream which coding tools are activated for for a specific bit stream so the decoder will know how to handle bit streams which are only using a subset of the coding tools and next slide please so so focusing on what has happened since lot lost ITF meeting we have done some software improvements we added multi-threaded encoding support based based on picture level parallelism so we basically processing multiple pictures in parallel which gives a good speed-up factor and a nice thing with it is that it\u0027s producing bit exact result as a single threaded encoding and then as I mentioned we released the second version of X PC it\u0027s it has a little bit better performance than what we reported in the February meeting we have improved the consolation coding but and I\u0027m also defined a royalty-free baseline profile which is using a pure subset of the full exbc codec so by disabling actually roughly two-thirds of the coding tools we\u0027re just using 25 of these restriction flag controlled tools so that gives first performance of course but it also using a much smaller tool set so that\u0027s where why we are making it available right to free and the source code is available with dual "
  },
  {
    "startTime": "00:17:24",
    "text": "licensing so there\u0027s GPL or an or the commercial option and we also submitted an IPR declaration to ITF for the exbc drafts which is royalty free with reciprocity yes next slide please no I was not sure there Mike so yeah the the royalty-free baseline profile was that was a interesting development so that seems to be you know making this much closer to the the Charter but my major question is how did you arrive at the subset of tools to define the world III baseline and what what what if any you know IPR vetting was done to have confidence in that so I mean we have done a limited analysis of of the IPR situation will focused more on the the finding a tool set of the basic tools which which gives good performance and and seem to be generally well known from from from a certain time back but we haven\u0027t done a thorough IPR analysis so it\u0027s it\u0027s more relying on our process for dealing one with licensing issues when they arise so if we would discover that while there was actually someone having an patent on a tool which which would not be able to provide it under royalty-free terms then instead of using 25 tools we will be using 24 so so I mean we would apply our framework for dealing with that okay so so the tools that you disabled we\u0027re just basically a rough stab at what you think is is not going to impact the performance too much and maybe new enough that it may have some IPR you\u0027re not actually aware of any it wasn\u0027t people coming to you and asking you to remove things for your process it was you just deciding that these things may have high PR on them so you actively remove them yes okay so I mean we\u0027ve tried to find it find a good balance between the kind of the risk and the performance and you know that\u0027s the the state we ended up with kind of thanks it\u0027s a good question maybe we can "
  },
  {
    "startTime": "00:20:25",
    "text": "go to the next slide yes ma\u0027am so these are the results that that we presented in February and the performance has not changed almost anything on the on the full tool set but on the next slide we report results for the royalty-free baseline profile and in this case the the royalty-free profile is the anchor so we show how much do you gain from using the full tool set and that is reported to be around twelve and a half percent and yeah next slide at least there something that shows your royalty-free baseline versus I mean you saw you have poll xvc versus other codecs then you\u0027re probably baseline versus full spc you have that you composed can definitely chose royalty-free bassline versus vp9 or anyone I didn\u0027t include it in the in the lives or in the updated draft but we have published the results at this a wcy dr. video.com so you can pair the different configurations there if you want to compare a v1 with the royalty-free baseline of exbc for example it\u0027s possible to do that but in some times you can you can also derive from these numbers from from this slide and the previous slide you can get an rough estimate of the distance between the different options yes so maybe in the next time yes and this is just summarizing that we believe that accuracy codec is a good candidate for meeting the the net VC objectives that it\u0027s comparative performance it\u0027s optimized for web applications and we think the IPR situation is good and and that we have a good framework for for approaching potential problems for it and that\u0027s thank you any questions or comments Thomas Stadium Missoula I was just wondering if I was looking at the codebase and I couldn\u0027t find the baseline profile is that currently implemented in the reference encoder yes yes you should be able to just run with - profile and set it to 1 instead of 0 "
  },
  {
    "startTime": "00:23:25",
    "text": "okay thanks it\u0027s it\u0027s added quite recently so if just just like last week or something ok that\u0027s why I didn\u0027t see it Thanks no problem ozonated from for Mike again the JavaScript version of the decoder that you have on your demo page can you give a little bit more detail about how that was developed is it using web assembly is it using scripting or what what did you did you use the reference code itself it\u0027s based on the orifice on the reference code so we it\u0027s using M scripting to to convert the C++ version 2 to JavaScript okay you\u0027re not using smas or webassembly currently no well yeah ASM de Geus yes okay yes yes okay the reason ask is because the I think in Steiners presentation there\u0027s also some discussion about whether this may be practical for for modern codecs and it seems like your performance shows that it is can you decode high resolution like 1080p in your in your current JavaScript decoder I mean what we have on our web page is 360p because that\u0027s that\u0027s what we believe safety to demonstrate it runs on all pcs and so on but I don\u0027t think in general you would be able to do 1080p with that version because that\u0027s what we have so far is a single thread version of the decoder you might want to do multi-threading if you want to do 1080p okay okay well if there\u0027s no other comments thank you yeah we\u0027ll move on to Steiner and so Jonathan please stick around because after all the after Steiners presentation we\u0027re going to discuss what we want to do with all the codecs and so if you\u0027re waiting for a decision about whether or not to accept thanks pcs a candidate will do that after okay hello I will touch on for ecstasy yes yeah okay that\u0027s right okay Shauna for ecstasy and England so starting before "
  },
  {
    "startTime": "00:26:25",
    "text": "there have been no bitstreams changes since the last meeting not for the last two meetings I think but have been a few updates in the github repository all of them related to the entry in six library so I\u0027ve added the optimizations for on v8 the 64-bit ARM processor have some very various minor seeing the improvements for both x86 and arm also some new intrinsic s-- added which improves performance slightly there is also one bug fix which caused incorrect for behavior on arm and also there are various fixes to remove warnings and errors generated by some compilers when compiling Thor so still missing in for the most important at least is the dollar entropy culture and they are likely still some bugs probably most of them in the decoder and I\u0027m pretty sure it\u0027s possible to generate I mean an illegal stream and makes it equal to crash elaborate slightly on the seemed e-library your quick recap on what that is so Thor is using is not using the intrinsics instructions directly its instead using a library and the idea is that it enables an implementation rights in the optimized code once for all architectures and compilers and all the low-level compiler specific code can be hidden in that directory and if we want support for a new architecture for the codec will simply add support for that in the library and the actual code a code can remain unchanged so this in twenty-six are generic and easy to implement on most architectures which also means that intrinsics that are very specific for one architecture and difficult to replicate on others are avoided so the final assembly may not always be optimal but it\u0027s usually good enough and and also the limited support for the highly specialized intrinsics in the library forces the codec implementer to write code that runs reasonably well on all all architectures and then as Moe mentioned there is something called web assembly which is has some similarities in that it offers an instruction set "
  },
  {
    "startTime": "00:29:26",
    "text": "with generic instructions which can be easily implemented on different architectures but it hasn\u0027t support for Cindy I think there are a couple of projects aiming to do that but I\u0027m not sure if those are going anywhere but anyway if if there is Cyndi\u0027s report in webassembly it should be straightforward to port in two and six librarian thought to that and with that support a few possibilities interesting possibilities open up so it means that the decoder itself can be transmitted in with a bit stream and run at near native speed in browsers and that allows quick deployment so codec changes specifically IP are issues can be addressed quickly so I\u0027m just bringing this up this is not a formal proposal but we should do something like this and I think also adding simply support is outside the scope of this group so basically just asking for your own opinion if you have comments I have more sites so just interrupt me at any time the one thing I\u0027d say is probably it\u0027s worth sending the list of Cindy instructions you want to the people doing the web assembly projects so they because obviously a pretty comprehensive set of the things that are useful so they know that you know the I they presumably need to know what\u0027s people actually would use if they defined it so yeah actually these in the library in for kids use as a guidance within that but did you know if anybody is actually working on it or perhaps team the guy behind me you write for a browser offender yeah Tim terrier from Azure um yes whoever some of these people are working on Cindy I don\u0027t know any more than that but I can put you in touch with the right people you know if that is focusing on floats or integer or both um I think it\u0027s it will address both but it may address like 32-bit integers only which may be less useful than you might like right I\u0027m suspecting that yeah um the the question I had is is if you\u0027re you\u0027re targeting a webassembly target in a browser what role does standardization actually play there beyond the standardization of web assembly itself I didn\u0027t get that I mean if if you\u0027re going to make a codec that you\u0027re going to to you know change on the fly as as you see fit "
  },
  {
    "startTime": "00:32:27",
    "text": "then what would be the point of standardizing it and working group like this well you would have standardize how you do it by sending that\u0027s byte code so the cheers I\u0027ve had some discussions about this point along with ad we\u0027ve you know we definitely reach consensus that the majority of the work would not be done here for something like that I only open question is whether or not some kind of umbrella work needs to happen somewhere because if you just have the bits and pieces of this sharted across a lot of different different sto is not just workgroups but you know that clearly some things would need to be done in ECMO some things with need be done in w3c but there you know it\u0027d be hard to do all those without some kind of coordination or some kind of umbrella effort so the the only work to be done is really binding all of this up you know defining the the primitives then also binding it up you know communication to the browser API is talking to RTE or just to be feedback all those things so there\u0027ll be a lot of binding work in some parts of I it\u0027s you have to be done but what net BC could do is very vague yeah right I think that that probably not just me but a lot of people would be interested in seeing something a little bit less vague and I suspect what might happen is is that you actually need a different Charter than the one that net BC has so it\u0027s definitely not in charter in the current yeah exactly okay I\u0027ll glue on I\u0027ve done some comparisons I\u0027ve compared xvc versus the royalty-free configuration of X to Z which is what\u0027s also what Jonathan did but I was using a different test set not I\u0027ll be complicit because I didn\u0027t have access to a server with the ecstasy enabled so I\u0027ve been using what I used to benchmark for with before we had I will compare compressed yet and the test sets consists of eight sequences ten seconds each compared to 1 second for public and rest yet and for kingly values and bit rates also compare the royalty-free configuration of exbc width or what that would be interesting to see and I\u0027ve been using the high latency settings single pulse these are the the actual confirme configurations just for reference and for reproducibility okay they thought of the old sites I think did you get did you "
  },
  {
    "startTime": "00:35:33",
    "text": "get do you have it can have it on that it\u0027s uploaded it\u0027s uploaded it just uh it was pulled up sorry too soon yeah well I started the the runs more than two weeks ago and they actually finished two hours ago good timing yeah good Oh these are the results that I got I was using speed mode one was precisely because it\u0027s speed mode zero was just too slow so obviously well the default configuration of X PC is here the anchor and I\u0027m comparing with the relatively and obviously there is a PDR loss which is fairly consistent across the stream so I I got a bit rate reduction of a bit rate increase of 14.7% Jonathan had 12 and a half but since this is a different test sets and ten-second clips instead of one seconds own I think these results are consistent with what Johnson presented also tried speed mode tuned and I get similar results 13.8% bit rate increase so it confirms what Jonathan has presented just real quick on that Jonathan can you confirm what you were using speed mode zero I believe for your tests or we\u0027re using a difference we\u0027re using the same speed modes that Stan is presenting here assume you\u0027re using maximum proportion yeah we used to spin with zero for our report yeah that could also again different sequences you get different results then I used poor as the anchor the this lowest setting until the high efficiency mode and compare that with the relatively configuration of exbc and then I managed to get results for speed not zero which runs in this case six times slower than four so all the eight sequences exbc produced better result for seven of them on average 13 I got a bit rate reduction of thirteen point six percent so in the case of the one sequence which was slightly worse with its busy the only thing special about that one is that it\u0027s pretty noisy was recorded with a Britta noisy camera I\u0027m not sure if that\u0027s the explanation but could be then I also tried with speed "
  },
  {
    "startTime": "00:38:38",
    "text": "mode zero and using the same anchor but then I got mentor and exbc have the pretty much the same complexity and again xvc performs better for seven of the eight sequences and on average eight and a half percent better and even if the dollar entropy Qadri is added I don\u0027t I still think exbc roll free will perform better I also did speed mode too and in that case Thor was better in average but then again X PC is running three times faster also they have a quick look all this complexity defined as simply the number of lines of code exbc has about twenty five thousand lines of code which is quite similar to what for us depending on whether you include the simply call or not XYZ doesn\u0027t have simile I think but if you compare that with everyone the numbers are quite low well everyone has something like seven or eight times the number of lines which for the most part I think is unnecessary but I don\u0027t think I think it was very hard to make complete implementational every one with fewer lines so called them ecstasy and thought so finally a quick update on everyone the spec is Bros frozen I said that at last meeting but then I included quotes for frozen this time I left them out so it\u0027s supposed to be stable normal we\u0027ll see but there have been there have been changes since the last meeting so if we compare it in line with anyone the different production or the latest code is now between 31 and 33 34 % depending on what magic you use and the encoding time is 150 times that our reckoning which I don\u0027t think really tells the complexity of everyone but well the reference encoder is not very mature yet I definitely think it\u0027s possible to make that number go down quite a bit so finally looking at any compression history updated that shows ladies code "
  },
  {
    "startTime": "00:41:38",
    "text": "can question why\u0027s everyone is basically the same as in much less than 1% PDR improvement since the last making but it runs twice as fast and this is with loading delay configuration so graph so we have on the y-axis the negative PDR and the date on the x-axis and you can see that since March the performance is basically the same there\u0027s this big spike in mid-february but that that was of this lapdog so we can ignore that looking at the complexity the graph is finally turning so it\u0027s at least going in the right direction now but this is frames per minutes on the y-axis there\u0027s the still some distance to make the referencing called attractive but it\u0027s definitely possible to achieve the really high performance with everyone but then of course with some compression cost oh yeah that was what I had animal questions comments just for clarification when you compare the XP see and Thor was that\u0027s what this was with the royalty-free problem that was with the 51 tools disableds as specified in the drafts okay know what changes and just one comment on the sim D there there\u0027s a little bit of sim D next we see as well when it comes to interpolation filtering for example we have it just as a comment yeah thanks yep questions so I think the important takeaway from from this to me is that the last meeting we asked the exbc proponents to to look at our charter and come up with a royalty-free baseline and they did that and we asked them about what the relative performance to Thor would be because the Thor team believed that the work they had done was taking IPR into account and not as an afterthought and it seems that both the exbc and Thor folks are are in agreement "
  },
  {
    "startTime": "00:44:38",
    "text": "that that the performance is either equivalent or better for xvc royalty-free baseline versus Thor so at least Steiners cross-check seems to indicate that there\u0027s a speed mode where they\u0027re almost equivalent and there\u0027s a about eight eight and a half percent rate savings so the net of it is that the technical requirements are being met the real question is what is the IPR story around this RF baseline and is it something that the workgroup is comfortable with or is it something that needs a lot more thought and and you know I want to get a sense of the room of what people think about doing this I PR effort as you know something just since the last meeting and not in the ground up on the codec started and without any deep analysis of the IPR during design - territory from Missoula um well I thank you guys for for you know taking the effort to create the the royalty-free baseline I think the the level of analysis that\u0027s been done that the situation is still basically the same as last time um you know there are a lot of details here in the details matter and unless you really spend time reviewing all those I\u0027m sure Moe knows from from all his store work you know it\u0027s very difficult to have any degree of confidence that something is truly royalty-free and the other views on this Adam Roach is an individual and I share it Tim\u0027s concerns Mosin ideas speaking as an individual I think I also share some of the same concerns speaking for the work that was done the Thor team you know not not a majority of the effort but a certainly a large chunk of the effort was you know getting the IPR story right so you know if we had spent all that time on technical progress instead we probably could have made a much better codec but so I have some concerns about you know short-circuiting the IP or analysis effort you know into a few weeks compressing it down to one meeting cycle I think that wouldn\u0027t give me a lot of confidence about whether or "
  },
  {
    "startTime": "00:47:38",
    "text": "not this would have challenges if ITF published it as a royalty-free standard and and implementers browsers shipped it and then you know had to face challenges I wouldn\u0027t have a good comfort feeling about that at this point yeah and and just want to add like like to give some people an idea of the level of effort that was applied here you know just on the Mozilla side I think we can estimate the amount of time we spent on IPR review for a v1 was in the order of man years right and there were of course plenty of other people in the Alliance who are also contributing efforts in addition to the lawyers that we hired so you know this really does take a lot of effort to get right okay so okay so the only agenda item was was to talk about what we want to do is work group what future directions we want to take so I think Jonathan has done a good job of answering the questions that we had back in March ice come up with a good technical proposal that has very good performance the real question is whether or not the workgroup believes that the IPR story is sound enough to adopt the work and let me first recap with the other candidates so we started off this worker with two candidates early on Thor and dolla both of those teams have stopped active development on those there\u0027s been a little bit of work on Thor the Steiner summarized but it\u0027s largely stalled because both of those teams have been contributing actively to av1 and the goal originally was that that work may end up here in this work group but that\u0027s now controlled by a separate forum that will not be publishing that in certainly has not sent any signals this work group that they\u0027ll be any effort to publish that here so while those two teams are working in a different group in a different forum there won\u0027t be anything to progress here in DC for either dolla or Thor so that really only leaves X BC as as a candidate and the IPR story for X BC doesn\u0027t have enough confidence from enough people in the room unless others want to stand up and say something contrary I\u0027ve only heard three opinions and all three were low confidence about "
  },
  {
    "startTime": "00:50:40",
    "text": "deploying this and having it be truly royalty-free so that leaves us with a dilemma here in the workgroup about what to do we clearly don\u0027t have a candidate to meet the last three milestones so I\u0027d like to hear if there\u0027s any ideas from anyone of what direction we should take and if not we\u0027re probably going to pause the workgroup to see what happens in the industry with with a b-1 and some other initiatives that are happening in other groups like MPEG and see if there\u0027s a need to resume later but if we don\u0027t have any direct work to progress now there\u0027s probably not a need to meet in the next meeting cycle Adam Roach as an individual so I will also want to speak to your speaking sort of the technical ability to come up with the candidate we\u0027d be able to publish I think there\u0027s a much much larger meta question about whether given that a v1 will be out in the market soon it would be a net good or a net bad to put something else out that claim to have effectively the same properties in terms of IPR and performance I\u0027m over the position that that would be bad for the market and so although I\u0027m I\u0027m sad about the way that things play it out I\u0027m sad that the way that a v1 was developed was not in you know more open over both an organization like the IETF I think the fact that it has finished with the support of a significant portion of the industry means that even if we could publish a codec and here it wouldn\u0027t be a good thing so any other opinions on this the Adams basic comment was we don\u0027t want to fragment the royalty free market is that pretty much what others in the room feel - about to go from Polycom I would agree with that yeah - Terry very pretty much +1 does anyone feel that we should be progressing a candidate without waiting for what happens in the market with with a t1 or any other efforts so I\u0027m surprised Jonathan is not saying yes now I mean yeah we\u0027re happy to contribute to the Buddha ecstasy and if there is an interest in it but I think money we\u0027re not pushing for something which wouldn\u0027t be I mean we want to work collaboratively around it so so if there isn\u0027t it interest around it and I don\u0027t see a point in kind of pushing for it "
  },
  {
    "startTime": "00:53:42",
    "text": "Adam Roach and again speaking his individual and sort of outside that the the charter of this working group I I think the work that y\u0027all have done in terms of getting this to work in JavaScript is very interesting this is unfortunately the wrong venue to do anything other than maybe a little bit of work around the edges and I would encourage you to continue to do that sort of work as mo points out that\u0027s probably something that is more usefully aimed at either getting a getting and sort of socializing an open source library around that and or if you need additional work inside web browsers working with the w3c to have those api\u0027s 2-5 there\u0027s probably some additional very small bits of work around it to figure out how to send payloads that contain JavaScript defined codex because you don\u0027t really have the knobs that you would want to sort week that we\u0027re receiving is harder right I mean so they\u0027re gonna be a little knobs here and there that you have to do on like WebRTC to get this to work accurately in browsers if you want real-time and around the I\u0027m blanking on the name of the structure the audio and video graph stuff that we have inside web browsers to make it work for non real-time I mean so there\u0027d be a lot of work to do there and I think that would be very interesting it\u0027s just most of it is not I ATF work good point thanks okay so with that it looks like we will be pausing now this pause would happen after we essentially what would happen next is we would issue last calls for the requirements and testing documents and then send those along to the iesg assuming there\u0027s no no-bake qualms within this working group for those and then from there we would pause for roughly six months to see where things go so that would mean mailing lists would stay active but no more physical meetings wouldn\u0027t try to schedule time unless something really came up six months isn\u0027t the unit number of IETF meetings let\u0027s call it two two cycles okay definitely not me to November and will probably get guidance well before that we probably did not meet in March and make a decision about July closer to that and again what we\u0027re waiting for is to see if there\u0027s any clarity in the market around maybe one or mpegs parallel efforts to see if there\u0027s a need for continuing work or if there\u0027s a clear candidate that\u0027s emerging in the market all right well that is everything we had on the agenda so unless there\u0027s anything else some somebody wants to talk about we would be adjourned "
  },
  {
    "startTime": "00:56:43",
    "text": "going once twice okay looks like we\u0027re done thank you everybody see you in six months or Never um if the blue sheet if you have the police sheets by you bring them up if you haven\u0027t signed them please come up to sign them please make sure to sign it because uh we circulated them very early and a lot more people came in okay thank you Jonathan we\u0027re gonna pose up now okay if if anybody is interested in additional swag workers to do the know what is why always from the let\u0027s wrap your hands around my Thomas while eastery the Alexei Moscow yeah "
  }
]