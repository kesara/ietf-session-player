[
  {
    "startTime": "00:00:17",
    "text": "On site, I'll put out of the book It's pretty impressive that it can kind of hear me from that I know, I'm like, it can barely hear Indeed Obviously, yeah He's here How you don't? We need a bigger room for HTTP. Why does no one care about HTTP? Maybe it's good enough So, as you might have seen the news it's all hands It's already been released, you know You know, I know. As soon as it ends, I'll rush back down here Okay. So I suppose is button to the end of today I'll go. And if I'm not here, say, enjoy your all hands of today. And if I'm not here, say, on my whole hands Sorry, folks, we'll get started in just a moment Let's see, I can share Can I share?"
  },
  {
    "startTime": "00:02:08",
    "text": "we recruited a note taker Not yet. We can do that Hello, everyone. Before we start, one of the things we're going to need to do is get a note taker for today You will earn our undying appreciation if you take it notes and the link for that pad is in the agenda. Wow that is very blurry All right, anyone able to help take notes Note poorly It's not, it's not that And that tool we have RTC Screen share, it doesn't go to G Thank you this problem in this working work All right, note taker anyone, all we're noting well I think the loud ones over there. Yeah. Well, david hayes this excuse of leaving. Lars, do you like taking notes? notes? Ah. Somebody grab his bag right? notes? I chaired quick for how many years? Come on Will someone who is not leaving, please help us take"
  },
  {
    "startTime": "00:04:02",
    "text": "notes We got no answers. This bodes poorly, Mark Anybody Well, we can't continue if we don't have minutes Martin Tim's getting his laptop out Are you going to be able to help us? No. Thank you We just need a very brief summaries of a special league side Indeed, anything anything So this is the note well. If you're not familiar with it, please become familiar with it. You can find it by searching on your favorite internet search engine for IETF note well And it regards the terms under which we participate here regarding things like intellectual property, which is very important and you need to understand before you participate, as well as standards of behavior, which we do take seriously So again, if you're not familiar with this, please do become familiar with it And I'll just go to our agenda Excuse me So we have two sessions in this meeting Today, we're going to go over three active drafts. I think we may not use 20 minutes on all of those. And then we have a presentation from David if he's still here, on the wrap-up capsule and then a presentation from Tommy about"
  },
  {
    "startTime": "00:06:00",
    "text": "communicating proxy configuration and provisioning domains Then on Wednesday, we have a couple of more active drafts As you can tell, the number of active drafts we actually have to discuss is contracting, which I think is probably a good thing. I think we might have a slightly quieter period for a while. And we're going to talk about no very search and revising cookies I know I'm missing one thing from this because I believe we had a braid presentation as well didn't we? Yeah, so I'll get that on the agenda Is Wednesday good for you? Awesome, okay And I think we still need slides from you, right? Okay Yeah, so like I said, we're a little light on the agenda, so I don't expect we're going to use either of these two hours slots to their fullest, but we'll see how we go Any agenda bashing? Okay, let's get started then First up, we've got resumable uploads with Marius Let me put this into the right Thank you Morris would be. Yeah. If you want to slide your share your slides, Marius, remotely using the that Osk slides? Yes, so there's the share slides button with the little document and you can ask for permission Just one Correct, and you can select your deck Okay, perfect. Is the audio good this time, not too loud? We can hear you Okay, perfect Hello everybody. Welcome to the part of our resumeable uploads. Just a brief reminder with resumable uploads we try to make uploads more useful and more resilient by allowing the client to recover from unintended interrupt by querying how much data does they have already"
  },
  {
    "startTime": "00:08:00",
    "text": "received, and then it can just resume the upload from the point of interruption without having to retransmit all of the data again Before the IETF meeting, we published the draft iteration 4. It included a few noteworthy changes, which are we now have the applications that partial upload media type for batch requests We have also introduced upload limits which is a method for the server to announce upload related limits to it decline this currently includes a maximum or minimum size for entire upload, as well as a maximum or minimum size for an individual request which is especially helpful if you have proxies that limit request sizes Another limit is also upload expiration I will be getting back to that in a later slide We have also added guidelines for handling content and transfer coding as well as guidelines for you using digest fields for integrity checks In addition to that, we also have added problem types for common error responses All in all, the draft is shaping up pretty much that, we also have added problem types for commenter responses. All in all, the draft is shaping up pretty well, but there's still a few questions that remain over and that we would like input on This brings me to the first point regarding upload limits. So either few questions that remain open and that we would like input on this brings me to the first point regarding upload limits so as a general reminder when the so server creates a new upload resource, the server can indicate limits in the response it is done so using the upload limit header which you can see in the example below Here the client sends a post request to slash upload, requesting a new upload resource and the server accepts this resource and says to here the client sends a post request to slash upload requesting a new upload resource and the server accepts this resource and says 201 created at this location is the new upload resource, but with those limits In this case, it has a maximum upload size of one gigabyte as well as a minimum"
  },
  {
    "startTime": "00:10:00",
    "text": "request size of 5 megabytes Now, this is handy. The client now knows the limits, but it only knows those limits once it has created the upload resource. So it doesn't know them up front Meaning if the client wants to upload a 2 gigabyte, file, it would now discover that it actually cannot perform the entire transaction because the server wouldn't accept the entire file in the end which isn't great. So we've been thinking about allowing the client to discover the upload limits up front. This isn't end, which isn't great. So we've been thinking about allowing the client to discover the upload limits up front. This is an entire optional mechanism. This is not mandatory but if the client wants to, it could send an options request upfront. So we can see here in the example, it sends an optional request to it slash upload, and then the server responds with the upload again, a max Again, a maximum request size or a maximum upload upload of one gigabyte, as well as a minimum append size of 5 megabytes And especially this minimum request size is pretty hand to know for the client so it can properly split the upload into multiple requests if this is required by some proxy or some intermediate In addition now this is a big if, there haven't been any talks about this in the direction yet, but if at some point reasonable uploads would get implanted in browsers, we could be piggyback on the options requests that are already sent for cross-origin resource sharing, pre-flight requests, and the server audience automatically knows the limits and could apply them according But yeah, of course, there's only a proposal and this is the first question if there's any import on this, if this is a thing that is rather not liked in the design of HTTP or not so if there's any input on that"
  },
  {
    "startTime": "00:12:05",
    "text": "Yeah so I think the idea here with the append size you're saying that maybe a proxy wouldn't allow a chunk of that size going through. If this header would be set by this origin server who would be responsible for it? In my experience, it happens quite often that the server operator has a proxy on their side and they have a limit on the maximum size of the what can go through the proxies So they will be setting this header, yes. Okay, thank you you Okay, but there's no nothing else, then I might continue Julian had a question in chat Do new requests have new fields work with options? for course? I'm not sure how to understand this question, to be honest But we can also follow up on that later outside of this All right a next topic that is also a bit related to upload limits is regarding the upload size So right now, as mentioned before, an upload might be split across multiple requests For example, because this origin doesn't, or has a limit on the individual size of requests. So then the upload may get spread across multiple requests. But this introduces"
  },
  {
    "startTime": "00:14:00",
    "text": "a problem because then the server only knows the entire length of the upload once the entire output is completed because then the last request includes the upload completed. One header, in the once the entire upload is completed because then the last request includes the upload completed. One header indicating that the upload is done and then the server knows the entire side of the upload. But this also means that a server cannot reject uploads early on if they are too large. It also means the server cannot optimize the upload storage depending on the size So for example, smaller uploads get handled differently than big uploads So we've been thinking about including and allowing the client to include an advisory header in the creation request This advisory header would indicate how much data the client wants to upload in total across all of the requests, but the upload complete intentness state would still be entirely determined for the upload complete header. So here we have an example that shows this we see a post request to slash upload for creating a new upload resource and the client equals the upload length 500 header field indicating that it wants to upload in total 500 bytes. But the first request only includes 100 bytes, as seen by the content length header The server then accepts this upload and then the client follows up with the next patch request in containing the next 100 bytes and then this would go on until the entire upload is finished This allows the server to know the upload size up front and optimize accordingly but the server may also reject uploads if they are too large. Of course, this introduces a bit of complex handling for the server because a client can indicate a different length than"
  },
  {
    "startTime": "00:16:00",
    "text": "it would upload. But at the end of the day, servers already have to handle a mailfront clients that announced the wrong content length and upload more or less data But in our case, it would also allow servers to reject uploads which have a different upload length than they actually do. All in all, I think there was a proposal a few years ago by Mark about like a new length header that indicates the message size independent of content length and chunk transferring coding is a bit similar in that regard as it's advisor header for indicating the entire upload length We think this is quite handy but of course it introduces a bit more complexity so I wanted to ask if how you feel about this? Hey, Marcus I do think that this is likely to be used I also just point out the so I also have a draft on versioning, which has a way of doing related also you can do resumable uploads and I just noticed that there is a place in that draft that also provides the speech feature. So it's really cool to notice it here and I'll just probably want to follow up with you afterwards afterwards Thank you for a quick question. What about back? Marius, could you mute while they're speaking? I think there's some feedback of course what about backward compatibility with existing servers that? don't recognize the upload length header? Because in this case, they would accept the content length header and assume it's completed right um it header because in this case they would accept the content length header and assume it's completed right um the this would only work if"
  },
  {
    "startTime": "00:18:00",
    "text": "the client knows that the server accepts resumable uploads yes if you're uploading to an endpoint that does not where you're not sure if they accept resumable uploads and you would want to do like transparently upgrading to resumable uploads, then you would have to include all of the data in your first request, yes But it's a very good point. We should include that as a hint And I'll just say a reason why this is really helpful is I want to have a progress bar on the website to show how much of the file has been uploaded and I'm going to generate that on the server, so I want the server to know how big the file is going to My name is Michael, Michael Tiemann All right, thank you very much for this input This brings me to the last question This is regarding integrity checks using the type brings me to the last question. This is regarding integrity checks using the digest fields We have added some guidelines on how resumable uploads interact with digest fields which is just a recently published RFC And here we can see an example where a client includes an integrity field when creating an upload. We see post slash upload again, and then we also see the representation digest using shards SHA-256, meaning that when the upload is graded, the client tells the server what the expected digest is. Once the upload is, then complete, the server can check if the digest of the received data matches what the client told the server it should be. But this of course requires the client to know the digest ups front"
  },
  {
    "startTime": "00:20:00",
    "text": "or use trailers to send it in at the end. But trailers are not always available. Every HTTP API client, unlikely, unfortunately And knowing the digests up front, is also not always possible. For example, if you're streaming data from a video cam, for example So we've been thinking, um, about how this could be optimized and the Digest Fields RFC also provides a way for the client to request a digest from the server For example, or in this example here, we can see that the upload creates an new, or the client creates a new upload, but in indicates to the server that it wants at the end the representation digest SHA-256. So it creates the upload resource, then the upload continues over multiple requests. And once all of this is done, we can see the client, the server, responds with a response that includes upload complete and then provides representation digest back to the client and then the client can calculate the digest while it's uploading a data and at the it could then compare its digest that it has calculated over the entire upload with the digest at the server created as well or calculated as well This is pretty handy. It's a nice optimization. At the end, the client can then determine, okay, there's was something wrong with the upload. I should not be used this upload anymore but all of this is outside of this protocol But this also brings the question to the H2 upload. I should not be using this upload anymore. But all of this is outside of this protocol. But this also brings the question to the HTTP working group who also offered the digest fields RC is this a sense of use of the integrity preference fields? or is this ROTA not?"
  },
  {
    "startTime": "00:22:00",
    "text": "a well-designed? Thank you Marius, we're just looking meaningfully at Lucas and he's poker-faced right now Well, certainly I'd like to see his input, but my inclination is the, this seems like a sensible way of expressing it. There may be some questions about the naming, but see previous bike should like language We can bike shed that as much as we want The Juvenile right I might then check with Lucas outside I don't know we can have a look if this is the properly or improperly All right Thank you. Then I will go to the last slide Thank you all for the feedback with quite helpful As I mentioned before, the draft is shaping up pretty well, or from our point as the editors We hopefully wrap up these laws questions pretty soon and then we would like to do some more editorial improvements to draw off this a bit rough in its shape, has a lot of changes recently done, which doesn't make a structure easy to use. But we hope that after this, we can continue forward with this. I'm not sure if a lot of last call is too eager already um so please uh um with me here, but we feel that this is slowly coming to a finish and then we can hopefully wrap this up but of course if you as a working group feel differently then we'll adjust, of course"
  },
  {
    "startTime": "00:24:00",
    "text": "But yeah, that's all from my side and if there's nothing else then we can continue with the agenda. Thank you Any more questions? comments about this draft? Okay, thank you very much much Next up we've got, I think Julian with query yeah Julian did you have anything prepared or do you just want to talk to the state of the draft? Hello. Hello, we can hear you Okay I've got no slides um, status is I actually managed to update the draft so we don't have something that has expired two years ago After the lab, maybe Mark can pull up the issues list After the last meeting, we had a brainstorming in a small design team trying to find a consensus on how to derive a getable resource for the query And I think we are stuck with a question whether we want to use location or content location for that. I think there are good reasons for both We only need one and I'm currently don't know how to actually get out of this disagreement that we have mainly with Roy Roy So I guess that should be a identifying query results, the third one the second one The second one. Yeah Thank you"
  },
  {
    "startTime": "00:26:02",
    "text": "once we have solved that problem we will have at least a straightforward way to cache the results of a query Yeah, it's in the PR, not in the ticket, I think Ah, it's that ticket, sorry Yeah. So, um there's some disagreement whether a location or content location is the better choice And we somehow need to find a way out of that And I guess most of the other open questions will follow from that Most of the work for that poll request are on that ticket actually has been not by Mike Maybe he wants to say, he's here already raised his hand okay okay Sorry, I'm waiting for both the buttons to click through So, I'm not looking at what's back in front of me right now, but I think basically what it comes down to is there are two possible things that we could communicate. We could say on the response to a query, where do, where can you find in the future? these same results again. So let's say I do a query, I think Roy's example was for weather I do a query for weather in Vancouver Am I going to get back a URL that says weather in Vancouver at 127? p.m. on July 22nd? Or am I going to get back a URL for weather in Vancouver right now?"
  },
  {
    "startTime": "00:28:00",
    "text": "The definition of content location says that if you did a query to it, at the time this message was generated, you would get this response which is true either way because it's the moment that you're asking about So should one of them be evergreen and one of them be historical, should we, yeah, only do one? I don't know. I don't know both are probably useful having an evergreen one that preserves the contents of the query for future use is interesting Maybe for caching purposes, but that's a separate conversation but I think right now we just need to figure out we have content location, we have location Are we using both of them, which one is going to be which? I don't know that there is a right answer, I think we just need to come to an agreement and move on So Mark, you might want to have your coin ready Yeah, I don't think that it's either or I think we can document both patterns for use at the appropriate time much like the rest of HTTP. It's a toolbox and you use it in different ways to get different effects. But these don't necessarily confirm I can imagine a response with both locations and content location on it that makes perfect sense I think we just need to document it clearly And as Roy says, the semantics of content location are independent of the status code whereas and the method method I think you know the method where, except for a couple of weird exceptions, whereas the semantics of location we'll need to look into and make sure that that makes sense But I think it can work, and I think we should do it yeah martin thomson I'm warming to the same idea. I think the weather sure that that makes sense but i think it i think it can work and i think we should do it yeah martin thomson i'm warming to the same idea i think the the weather example is rather clarifying in this case"
  },
  {
    "startTime": "00:30:00",
    "text": "location would tell you what would happen what you would go if you wanted to make the same query again, maybe under different conditions Like the world has moved on since you last, made the last one, you may get a different answer whereas content location would be if you want exactly the same bits again, content location is where you go for that. So I think having a clear explanation for both of them is the right answer here. Now that we've had this discussion, we have a lot more clarity about it. We just need to work through the the wrinkles on location. But I think as Roy says here, it is tough to the semantics of the request type and so we can rely on that So I actually it didn't occur to me that we could actually use both for different purposes and i think that's something we can work with. Maybe, Mike, I can make a proposal for that and then get growth feedback and then move on So I think that would be a big step in actually making progress here here Yeah, just to add, I think the reason we're in a little bit of uncharted territory here is because as it says the type of relationship is defined by the combination of request method and status code semantics. And typically we've relied on status code semantics to carry most of the weight and assumed get or maybe post but now we have a new method and we're putting more weight on the method to define semantics. And so we need to think that through and yeah and actual in one of the commands in the ticket I asked if I wanted to do this same thing, for instance, for prop find would the same mechanism be? the same? And if"
  },
  {
    "startTime": "00:32:00",
    "text": "for prop find, would the same mechanism be, would the mechanism be the same? And if so, would I need to update the definition of prop find to say so and I think that's what Roy was um pointing at that we can define that for each method Of course, it would be good to define it consistently but it's up to the definition of each method to specify that concretely But I do think we can rely I mean, in the common case, if I'd send a query to a server and it creates a resource I don't see how it's going to get away with not creating a resource for repeating that query in the future And so the response status code is probably going to be a 201, and 201 is going to carry a low weight here. So I do think we're going to be okay Question? Okay So Julian, is there anything else? I think I agree that this is the big issue. Is there anything else we can do to help you? No not right now. When I looked at the tickets earlier today, I found your proposal from last year, whether we could define query as a transformation or define a transformation from a query request to a get request which would be an interesting idea. So essentially, define how the payloads combined with the content type of the payloads could be translated for certain content types to a query string for get, but that would actually wipe out the possibility to have the query URI actually already have query parameters because then they would there would be two things that we want"
  },
  {
    "startTime": "00:34:00",
    "text": "to put into the query string so I'm a bit skeptical that we can make that work I tend to agree Yeah. So I put that into that. You do have mic in queue. I just want to check yeah okay sorry sorry I was going to point out that the other issue that we kind of set to the side in that first kind of conversation in was going to point out that the other issue that we kind of set to the side in that first conversation, as part of that PR with the content location or now location, or both we have put the same text for query that we have for post that's says a cached, oh, so in RFC 9110, a cashed post can be used, reused to satisfy a later get or head request. So Roy was questioning that We may want to separate that out, but if people have opinions on the reuse of query to then get that resource leader in caching it now it's probably the time to talk about that as well Um dangerous, but also we said it for post and there's no logical reason to me that this is different It's, it's risky Mr. Voski proposed to I'll raise my hand. I think the common case is going to be what we described already in the draft where a query is cached and reused for another query So we probably should distinguish in the spec for the sake of"
  },
  {
    "startTime": "00:36:02",
    "text": "terminology the query result resource being created at there resource for the query itself being created one of which would be location and the other one content location location Well, I think there's three things. There's the resource that you query and the request body forms part of the cache key, and if you query again, then you can get it from cache. And then there's the resource and content location which is just like any other getable thing right and then there the resource in location which we haven't talked through but i'm a assuming is also a getable resource. It's not a resource you send more queries to. It's a resource that's kind of static re-expression of the query right? Yes, so as written right now, what's in, I guess, if we move it to location it's a getable thing to repeat your query without rescinding on your parameters Right, great. And I think that's a sensible thing to do And so then the question is, is a cat allowed to take the response to the query? and reuse that for queries to that? getable resources I say queries for request and get requests to that resource is the same question as for post, I guess Yes, so post allows it, I don't see a reason that query should be different from Post, but I agree that it's kind of a tricky thing for a proxy to do correctly Nobody does it for post And I think that"
  },
  {
    "startTime": "00:38:05",
    "text": "and i think that alliance with royce comment somewhere that maybe be sure shouldn't specify it right now but observe what people try to implement and come back to that question later but that's not a perfect solution of course If it's cross origin, I'm scared if it's same origin i'm less scared I think based on the design team meeting last time, we specified I think we specified how to be the same origin but I need to double check that We subtly talked about that putting in some text about that maybe we don't have it yet So my proposal is that market I tune that PR to address Roy's comments and def- the behavior of both content locations and location and then see what feedback began get And I think along the way that solves many of the outside issues. I see Martin's in Q was something new. I noticed that Mike's doing a lot of work here and his name is not on the draft Yeah, I was going to say that right now that we should add him Well, thank you The chairs will take that on board That's a simple, simple change This sounds hopeful. It sounds like we're making some progress Going down. Do you want to, I mean, we've talked about it before and not followed through it. It sounds like maybe a design team meeting"
  },
  {
    "startTime": "00:40:00",
    "text": "in a little while might help. Yeah coordinate people's holidays and so forth Sure Anything else in this draft? I think the other issues are not that hard to deal with once we are, we crossed that bridge. So I don't think we need to discuss them right now And I don't see anything in the room, so thank you, Julie Good to see. Okay And next up, we have cash groups So let's go to that real quick So like Julie and I don't have slides I did a revision. We had a couple of outstanding issues and I cleaned up some things Probably the biggest change from the last draft is it doesn't continue the kind of speculations speculative invalidation based upon we were doing it the other way where it wasn't a based on invalidation it was based upon what was it if there's a relationship between different things and something it expired, then we assumed everything else expired, I think it was was So I think this draft is ready to go. I don't have anything on the issues list right now. Have people had a chance to read it? Let's double check The issues list is still empty Otherwise, I would ask for the act chair to open working group last call Any comments, thoughts?"
  },
  {
    "startTime": "00:42:05",
    "text": "People think this is good to go for last call? No. Has anyone read it? Please read it. That's always a forcing function Last call, you see read the document as always we want to see not only you know, issues or whatever, but also support Okay You don't have david black. Are there any implementation? to this? Not of this exact syntax, no. It's designed to be complete with the number of deployed extensions that are very similar. They're just not standard. Okay, yeah I know several of us have something similar, but I was curious if anyone has implemented or will be implementing this one I've talked to our cash team and there's interest, but you know, it's been our priorities, and this may be one of those that has to sit out there for a little while before it gets a little momentum, I suspect All right You're doing very well in time So the next thing on the agenda was David's presentation on a proposal for the HDP wrap-up capsule. He is not in the room currently I believe he may come back later The next thing on the agenda was I was going to share some work that's happening in an int area that is relevant to the group but is anything we want to bash in or should we? just jump to that for now Okay, great All right hello everyone. tommy pauly speaking as a individual here who has"
  },
  {
    "startTime": "00:44:02",
    "text": "working on a document in the int area that is relevant I'm co-authoring this with Dragana from Microsoft and this is all about how do we discover proxy configurations either from a network or once you already know about a particular proxy configuration. This applies to things that go beyond HTTP proxy but most of the interesting ones are HTTP proxies. So it's relevant for here and a bit for mask as well So just to I'm just trying to try to give an overview of the document you can also go in read it, but we'd like to hear any feedback that this group would have The motivation here is mainly to discover the conf- configuration and information about these modern proxy types So we have Connect UDP and Connect IP from Mask. We have Connect TCP that we are finishing up in this working group and hopefully shipping out soon. You could imagine other flavors coming up. I think we have Ethernet coming down the pipe. So like new flavors of extended Connect proxies. But these have URI templates. They don't have great ways to configure themselves in existing UI. So there's a there's a gap for the configuration story And one of the goals here is to have something, at least a mechanism that will work with existing very simplistic proxy configuration mechanism like putting a proxy name port somewhere in a UI field or getting something from a packed file or proxies can come from lots of places We also want to have this be something that isn't really on pack file formats or W W-pad, stuff that isn't fully standard It has a lot of security"
  },
  {
    "startTime": "00:46:00",
    "text": "concerns and edges for how you're parsing out JavaScript and we'd like to have something a bit simpler, more straightforward, and more secure So the protocol overall is, it's leveraging another into area RFC that we'd work on before, something called provisioning domains, which is for the purpose of this conversation is a way to have like a HPS protection JSON file format that is a associated with a way to reach a network and that can be something that's provided by a route but it can also be conceptually a VPN configuration or a proxy configuration it's a way to reach a particular network, like you can think of it like a virtual interface or a tunnel and so this is we have this JSON format that already exists at a well-known, you are location. And so we're expanding the semantics of that to allow you to ask a proxy you already know about for its PVD configuration file and then it could list you various things about the configuration it has for how it lets you reach other things on a network including a list of other proxy protocols it supports. So this is a way to take an existing proxy you know about and upgrade it into doing connect TCP, connect UDP, etc You can also ask other things about the configuration. That's why it's not just a list of other proxies. You can have the DNS information of like domains that are relevant to this provisioning domain We could add other things in there It's also possible to get this file from a network advertisement and so while there are various security and private considerations for why you would trust a"
  },
  {
    "startTime": "00:48:00",
    "text": "proxy that's been provided by the network, you could learn that configuration using this mechanism So it's just some diagrams so we can visualize this. We have related proxy discovery where you say, I know about an HTTP Connect proxy that was typed in somewhere and I can reach out to it and ask what it URI templates are for other things. So I can do you proxying Woohoo! I can get this file and it can tell me, oh, I apply to these DNS zones and I won't let you actually reach in anything else. So if you're using it, now you know a priori that it's only going to be used for a subset of things and then you can also have a case where you have an in network proxy that you're doing something funky on a cell network and you need to use a proxy to reach their cellular service and they can tell you, hey, here's the proxy confederate to use and it supports mask and da-da-da-da-da So various flavors that this can be used for. As an example, let's add I know about proxy.example.org because someone typed that in some UI or I got it some other way got it in some configuration file. I can create a request for the well-known pbd file, ask for the JSON, and if it supports this, then I get back that file, and I can say, here's my provision domain for this proxy, and it includes these other related proxies and I can say oh yes it you know it has yield, HTTP Connect but it also does connect UDP and maybe it can do Connect TCP as well some of the so the have adopted this in into area just as kind of like it was originally the basic form where you just have this list of proxies we've merged in a couple things recently, like adding in the ability to associate like AOPN hints"
  },
  {
    "startTime": "00:50:00",
    "text": "so that you could know a priori if this is something that, if the proxy will support connectivity or H3 or H2, so you can get it right the first time clarifying how to do split dns control so maybe you could also have exceptions kind of getting into what pack files let you do without trying to go all the way down, that's the slippery slope. There are open, issues around should we have authentication parameters in here, and I'm not sure what to do there. But that's the state of things. So I'd love to hear people's comments, thoughts, suggestions please feel free to engage on the GitHub or do issues or on the interior list or the HTTP list Lucas Paddy, could you go back one slide please you got there listed in a protocol field with some value there. Where do those values come from? I was just curious. So they, the tokens we already registered like in somewhere or they new strings that reflect stuff that we do and you would like I was just curious Yeah, this is a great question. So originally before it was adopted we were just like oh we're gonna put the uri curious. Yeah, this is a great question. So originally, before it was adopted, we were just like, oh, we're going to put the URIs in and you're going to infer from the template what it is and that a bad idea So the current state of this is it is, it's own registry of strings because there are things that exist in there like socks, like things that do not fall into the upgrade token form So there are essentially there's a set of things that are like, these are the legacy types or types that exist outside of HTTP. And then the other ones it just says like these should match the upgrade tokens being used for extended connect proxies so they are exactly the same strings, but you kind of have to make sure they end up being the same If there's a better solution to this, I would love to"
  },
  {
    "startTime": "00:52:00",
    "text": "hear it. I don't know, I don't want to like here and now, but just looking at that slide, like both of those things are HTTP, so maybe using a HGDP prefix for anything that's HP based could could be useful to distinguish it from socks or whatever stuff. Right, that's a good point Yeah, so you could even, I imagine, do a thing where you have have HTTP extended connect connect to UDP. So you, you, indicate this is something that uses a upgrade token and then you just slip the upgrade token inside that. That could be a very nice solution. Thank you any other thoughts Can I, you get in Q one on Is there anybody else in the queue, or am I good? Please go ahead So, yeah, this is a different side deck than the one you have for interia. Sorry, can you identify yourself? I'm sorry, I'm sure cohen. Okay. This is are not the interior slides. Okay, yeah. This is a overview for people who have not seen this before in this group Great, great. So in terms of this, one of the things if people have paid attention to the interior lists, which is what to do about WPAD, and so part of that, you had mentioned, like, more specific or narrow discovery, can you speak? on how you would find these PVD files? files? Right, so this is getting into the question of what what do you do for a network discovered proxies in general and how this would be different from W-pad? Well, not necessarily, I mean, well, it's really two parts. One is so how do you like for these files, how do you, these JSON files, how do you, come to get them to use them? And that sort of, there's a secondary question of, okay, like, if part of that is network is,"
  },
  {
    "startTime": "00:54:00",
    "text": "discovery then how do those fit together but that maybe more elaborate than you wanna talk about here, but just a- general question like how do you come to get these files right so there are two ways the way that comes from a network that is defined in the pvd rfc is you have like an RA from the router that says, I'm defining a network provisioning domain, it has this essentially host name identifier and there's a flag that says, I have an HPPS file at a well-known URI off of this host name that you can fetch to get my config for other stuff that doesn't do belong inside an RA. And so you can get it that way that's an existing file you can fetch, and that could include a list of associated proxies But since that was all bootstrapped just on having a particular host name, you can also say, hey, I know about an existing proxy host name I'm going to try to fetch the well-known URI off of that thing and say, do you have a other proxies? Do you have connections? Do you have these other protocols? And then you can learn more about that way? okay so that's those are the two bootstrapping mechanism The document really focuses more on this format and what you do for kind of proxy to proxy discovery currently Again, yeah, there are more concerns that would need to be working out for when you use a proxy from the network And I think, you know, with WPAT at least historically, it's like, you get this from the network and you are expecting to have browsers or whoever else respects this to just like start using the proxy without kind of necessarily user interaction or like understanding, like, what's the trust relationship or security modeling? like that that's the concerning area since in the PVD discovery model"
  },
  {
    "startTime": "00:56:00",
    "text": "this is new it is an opportunity for a much more restricted use of this So you could imagine cases where I am just throwing these things out, like either you are already aware of lists of proxies that you trust. And so if they want to say yes I have I would like you to use this thing because this is more optimal for me, and if you already going to use a proxy, pick this one or cases where, you know, like for an enterprise, let's say you already have some other enterprise provision on your device that says you trust this network and want to use this, but the PVD is used just as a way to dynamically tell you, by the way, this kind of enterprise configuration, you are already going to use and you have set up and you had user permission to do the details of the current URI template to use to get to connect UDP is here. So it's more of way to just add information and steering and not to apply proxies to do people who otherwise would not be using a proxy All right, thank you Anything else? else? okay okay so unfortunately, David hayes he can't make it back So I think, unfortunately, that's our agenda for today I don't think any other presentations are already yet Yeah so it's great that we have something that is going to make backfell any other presentations are ready yet yeah yes yeah so it's great that we have something that is going to make back files go away one common use case for pack files is not define proxy for certain destinations but to define some exceptions so certain things that should go direct and certain things that we would go into the proxy. Maybe I didn't read draft carefully enough, but I don't think at the moment it allows that. You can define proxy"
  },
  {
    "startTime": "00:58:00",
    "text": "for certain suffixes, but you cannot say those things should go direct instead so you don't have that negation. It was added actually in the very last revision that was done on the draft submission deadline, I believe So we refactored kind of the split DNS config to be able to have exception Oh, okay. So you could say, you know, do it for all of these domains or everything, but don't do it for this list of subdomains So you could carve things out that way. Thank you And if there are other things that you see that would be useful to kind of bring over without expanding to the full syntax of a pack file, that'd be great I'd also be curious to hear if people in this room have any thoughts about the authentication angle if it's appropriate to put that type of thing into this configuration or you just rely on normal HTTP authentication challenge? that you would receive from a proxy Any other comment? feedback? So to the question about authentication mostly I would think regular problems would be okay except that this is only almost exactly the scenario that the unprompt off was intended for. So I think you do need some kind of indication if you're supposed to be using unprompted off with these endpoints endpoints Yeah, that could be And the other thing is you know, this is quite similar to a lot of the more like proprietary configuration files we've used on our platforms for doing things like"
  },
  {
    "startTime": "01:00:00",
    "text": "the private relay proxies or enterprise relay proxies And those can come along with like, hey, you know, use this privacy pass key or use this client cert authentication as a hint Those make sense in cases where you get, like, here's a profile configuration from your enterprise and they tell you, here's your client search, you use, that works they tell you, here's your client search, to use the product thing that works. That type of case doesn't seem to apply to a generic thing you discover out of the blue but potentially some of the cases like, hey I'm going to prompt you for you thing you discover out of the blue, but potentially some of the cases like, hey, I'm going to prompt you for this privacy pass token for this issue where if you want to go pre-fetch a bunch of these, that would behoove you Yeah, telling you what credential you should expect to present is reasonable Embedding the credential probably doesn't matter for that case. Right, but it's more like something about the type of credential that is supported by this and that could potentially influence the selection of proxies that are used by a client Okay. I've done very early We're done very early. So you get an hour back. Enjoy. And we'll see everyone on Wednesday again And thank you again, Martin Tiemann for no taking. Yes, definitely How did you get away without using Yan? Yan? Because I don't think so it. You know, because they had that configuration format for clients and I'm like, thank God they hadn't seen this this Thank you"
  },
  {
    "startTime": "01:02:08",
    "text": "yeah Okay. Yeah. You want to follow that Thank you. Thank you"
  }
]
