[
  {
    "startTime": "00:00:25",
    "text": "yes is sound check i think you ask for next slides unless you want to use it remotely just say next well that's a bit of an unusual fault [Laughter]"
  },
  {
    "startTime": "00:02:00",
    "text": "okay just looking at the slide deck now oh it's fine it's just difficult to read the first slide that's all so for anybody um who's getting themselves into this room this is tsvwg our wonderful first slide renders quite well in the proceedings and pretty awfully here so i'm i i'm this is this is a non-critical problem um we're about to start the meeting so we're just gathering people if you are one of the presenters and you want to do a quick sound check please do we will start in just a few minutes david west can you do a quick sound check please yep can you hear me yeah yes good morning good morning and can you hear me excellent david okay excellent can you hear me thank you tom right okay um i suggest we start the meeting so welcome everybody this is tsvwg it's the transport and services working group we have a two-hour agenda for today"
  },
  {
    "startTime": "00:04:02",
    "text": "i'm gory fergus i'm one of the coaches i'm the chair who'll be on the platform remotely we have where's eddie and david black apologies for the first slide it's quite cute but it's not very informative the rest of the slides i'm sure i will be readable so maybe i fibbed this is the not well the not well is traditionally in small print if you haven't read the not well by now then you really should um ietf not wells apply to all ietf contributions on the mailing list at the microphone and by any other means and are the ways in which we ensure that we have dealt appropriately with ipr and other issues that relate to the itf process we're using me taco for this meeting which means that the mic q will be via me techo if you're going to the mic please state your name it's important that people can hear your name in the proceedings in the audio so please make sure you do say your name as well as raising your hand in me taco if there is anyone who hasn't yet joined the room using the qr code or by launching the meet tekkel 2 please make sure you do this this is also important for the ietf proceedings that everybody in the room has joined the meeting in some way if you're frightened about joining and staying joined you can join just for a moment so that we tag you as being part of this group and we can see that you're a participant so please join online and register for the blue sheet"
  },
  {
    "startTime": "00:06:05",
    "text": "this is the tsvwg status slide there are five internet drafts with the working group chairs and authors all passed working group last call in different states of completion the ecn cups for lorelei's draft is shepherded by david black and needs text to replace the reframing interaction works words in that document this is a small change but it's a change it has to be agreed with the authors and will be put on list once that change is complete ecn for tunnels that use shim headers has a similar issues that has been resolved both of these documents are ready for working group shepard write-up and the changes will be posted to the list during that process and then it will be passed up towards to our a day we plan to do this before the next ietf we have three drafts that have completed working group last call some time ago and have gone through an extended process of further review and shepherd right up to document the process these are l4s architecture alphas identifier and l4s aqm we plan to issue that shepard write-up soon and wise might wish to comment at this moment if there was anything else to say why is there anything else to say about these uh no changes since uh we talked about it earlier this week i think everything you said is accurate gory good right we don't need to review these things and we will move straight to the agenda for friday then friday's agenda looks like this"
  },
  {
    "startTime": "00:08:00",
    "text": "we have transport protocols for dccp um we have a differentiated services section where we're going to look at nqb and dscp considerations and we have transport for udp where we're going to look at the udp options work we don't anticipate any other business but now is the opportunity if you'd wish to hack or modify or make suggestions on our agenda does anyone have any agenda suggestions that we should take into consideration in that case that's the agenda for this meeting and we will proceed with the announcements i think there is one announcement and it ain't here all right we'll speak i'll we'll cover that way after the after marxist taught them that's fine so marcus you're up for the dccp slides hey wait a minute wes can you advance these slides if i launch them or do you have to launch them or david or whoever yeah i don't know how about you one of you two launches this slide deck and this is marcus and we'll get your slides up in just a second okay can i start you can start your slides will appear"
  },
  {
    "startTime": "00:10:01",
    "text": "shortly yeah good morning everybody marcus armand from dodger telecom i'm here as a 5g attributes enthusiast um but more important i think on behalf of the mpdccp draft authors group so let's see if the first slide comes up if not then i can launch them from here i'll launch them from here there you go yeah so i want to give some insights into our progress on the multi-pass dccp draft and yeah and the main changes which have happened since last itf are around the handshaking procedure yeah well the problem is we don't have the the new site is not in retech and i don't know how to get them and that's true there's a lot of missing slides okay next slide no no no then then i will take this one unfortunately that is the old uh version of the slide set so if you want to have the latest one please look into the agenda that you will get it yeah we have uh changes um or we have a lot of changes in in the draft since since last ietf so we finalized the hand checking procedure have some more information about that in one of the next slides we did a lot of changes in the mpprio option also here i will give some more information about it mp prior is used for a fine granular path management"
  },
  {
    "startTime": "00:12:01",
    "text": "to to enable disable paths to set a path into a backup mode so that is only used if no other part is available and we can also use it for past prioritization as an input for scheduling decisions maximum packet size i think is also an important topic that is something what is already considered in the dccp rfc 4340 where the maximum packet size is described how how it can be detected and how it can be communicated to the upper layers to the applications itself and we consider now in our draft how this has to be treated in the multi-pass context so we defined i think a nice strategy here to deal with that and to keep comfortable compatibility with the single pass dccp we started to define some closing a procedure defining two new options mp close and mp fast close i will also have separate slides on this we added a congestion control sections or congestion considerations for bottleneck fairness with single pass yeah i think that's also worth to read i do not have additional slides here in general we maintain the draft at github so you will find much more information you will also find the individual pull requests there which describe exactly what we have done along with the draft development we also developed our open source code at github where we have a linux reference implementation for multi-pass eccp available and that one we extended with some of the changes"
  },
  {
    "startTime": "00:14:01",
    "text": "we made in version two and three of the mpdccp draft next slide please we were also part of the first tsvw interim meeting in february this year just want to highlight here what we presented and discussed during this interim on the left you will find the mpprio option which i already entities which gives us a fine granular path management [Music] capability so we can design with we can assign up to four bits or we can use up to four bits to make different prioritization levels to enable disable parts and to give the scheduling engine of the multi-path protocol the appropriate input how to how to deal with paths um that is for example quite useful uh for at triple s when the wi-fi path shall be prioritized over the cellular access we stabilized as i also said uh the handshaking procedure we decided for a four-way design more or less that resembled the multi-pass tcp logic which i think is quite stable so we adopted this idea it's not exactly the same as a multi-pass tcp but quite similar so at least these four-way design is taken from there we presented also some early results of a partial p4 multi-pass dccp implementation which was carried out by cartridge university and has shown the hardware acceleration potential on smartnix i have a dedicated slide to this in in the backup not sure if you will have time to look into but as i said it it's"
  },
  {
    "startTime": "00:16:01",
    "text": "the last slide here in in this document so both to look into yeah and we started to present during the interim what is the relation between um 3gbp and iepf if we discuss 80 triple s related multi-pass protocols i will have a dedicated slide on this here as well next slide please okay can i reclaim it yep fine okay yes on this one thanks for bringing it back um yeah now looking into the new closing a closing procedure we introduced in the latest version of the mpd ccp basically we defined two new multi-pass options one of the fast cloud the other one is just called close in the fast close we we used to start starter abrupt shutdown of the mp dccp connection there's not really a negotiation about that so if a multi-pass dccp peer decides to close a multi-pass dcp connection using the mp fast close it will just send this option"
  },
  {
    "startTime": "00:18:02",
    "text": "over all paths to the uh to the peer host and with ending already shut down the connection on its side as soon as the mp fast close is received on any of the parts at the pier host the pure host will close the multi-pass dccp connection as well so there is not this common procedure of closing a connection which is known from the dccp context for that we defined a new reset code a new dccp reset code with the number 12 and that we also added to the iana considerations that this can be adopted then the mp close that is was introduced for a regular dccp shutdown so that is more or less a following for compatibility reasons the dccp closing procedure so we add the mp close to a regular dcp close request or a dccp reset packet the amp cloud has to be used to shut down all of the passes individually so it has to be sent on all parties and first after all passes are shut down then the overall multi-pass gccp connection will be removed in general for both multi-path options we use a key data field that uses some material which was exchanged during the handshake to authenticate subsequent paths here we also use it to avoid a misuse of the mp fast close or mp close options or that mine men in the middle cannot close a multi-pass tcp connection uncoordinated next slide please yeah"
  },
  {
    "startTime": "00:20:00",
    "text": "yeah as we are moving forward with our draft i want to give you an overview of what is currently the feature set of the multi-pass gcp and what are the maturity of the individual features so starting on the left we have finalized the complete handshaking procedure in the draft as well as in the open source prototype so that is aligned we use the mp capable feature to to negotiate in general the multi-pass capability between two hosts that is part of the hand tracking procedure um and also part of the handshaking procedure is the multi-pass key option for exchanging the key material i already outlined which is used to authenticate subsequent flow establishment along with that now i trump a little bit in the table is can we also see in the multi-pass hmac that is used in the establishment process of subsequent flows when multi-pass join is used which can be found on the right but staying in the left table we have the multi-pass sequence option that carries um overall connection um number a sequence number sorry which is related to the multi-pass connection and last but not least we have the multi-pass rtt option which can carry some timing information that is quite useful in the reordering process we apply on on receiver side to compensate latency differences all in all the features in the left table we think are complete some of them still need some updates for the prototype but in the draft itself i think that is stable and ready for being reviewed on the right and the partial ready table"
  },
  {
    "startTime": "00:22:02",
    "text": "i think we also made a lot of progress but for most of the features there's still the implementation missing and that is starting with the mp confirm which we use for reliable exchange of multi-pass options at the multi-pass join as i already outlined to establish subsequent flows we have a section on a fallback mechanism so what what happens if multipath cannot be negotiated i think here is some editorial work missing yeah then newly added the mp fast close and mp close especially for the mp close it still needs some work in the in the draft itself um yeah and last but not least we also have multi-pass at address remove address so in case new um ip addresses are identified which can be used to establish new multi-pass dccp sub-flows then those options can be used or in case ip addresses are not available anymore passes are not available anymore remove address can be used and the mprio i think i already outlined uh during this presentation so draft work is almost completed and we have now the main focus on on the implementation to keep this in line with uh what we have available in the draft next slide please yeah that is uh probably uh interesting uh for those who are also interested in the 3tpp 80 triple s functionality maybe in one short sentence the 80 triple s is a part of the 5g system and it's providing multi-path transport from a mobile network operator towards a terminal device towards a ue that is where we are very active that is where we see the multi-pass gccp as one"
  },
  {
    "startTime": "00:24:01",
    "text": "in that space and just matching here what we think we already provide with the multi-pass dccp with the draft definition but also with the published prototype so if you have a look into into the right table what are the requirements from at triple s basically it needs the multi-pass transport it needs non-tcp support so maybe for those of you who are a little bit more familiar uh at triple s is an existing framework but so far it only can deal with a tcp multi-pass splitting because multi-pass tcp is is used for that so for non-tcp traffic there is no solution so far and that is where we look into at the moment so here for sure we have the multi-pass dccp uh proposed we need steering modes so in in the multi-pass terminology that are scheduling entities we need reordering to compensate the paths uh latency differences on receiver side to bring packets in order again we need path measurement to make good sketch as an input for scheduling decisions and we need path management to uh establish or destruct uh subflows whenever it is required matching this on the left with what we provide so far we think we have now a very very complete prototype available with the multi-pass dccp itself with a new encapsulation framework with a lot of scheduling logics with a lot of reordering logics multiple congestion controls ccid 2 and and 3 which were already defined in foil for dccp itself so those we have adopted and we're also working on a new ccid5 which is following the bbr algorithm"
  },
  {
    "startTime": "00:26:00",
    "text": "yeah and last but not least we also provide path management functionalities so you see the links here and they will direct you directly to our github repository where those functions are available next slide please well lars is in the queue hi marcus thanks uh last i could actually question this slide so have you started discussing with the linux netdev community about upstreaming this so good question at the moment it's a completely out of three uh implementation which makes it much much simpler for us because press it in the foreground to get some first experience before we read make the move and bring this into the main line that that to the lateness and for mptcp the problem is that nobody could really use it because you needed to build custom kernels and nobody wants to do that and if you want to run containers with this stuff you can't right so you so it needs to be in the linux kernel by default if it's if it's supposed to be a building block for like atss or something like that right because nobody's going to compile kernels um yes i think we are pretty aware but we also have to deal with a with our resources we have available so that is that is currently that is currently the so we are at the moment we just have this linux reference out of free implementation available nevertheless i think cardstock university they are also working on some user space implementation of this right that would make a difference yeah but it i just wanted to check what the state yeah but not not sure how mature they are maybe there is something for the next itf where they can present some steps yeah and i'm not saying that you know this stops the itf working on this right yes wanted to know what uh okay thank you yeah thanks a lot awesome we have a question from michael tucson online go ahead michael um as far as i know there are some iprs involved so um how is the relation between these iprs and upstreaming this to the linux kernel and or this open source code so"
  },
  {
    "startTime": "00:28:00",
    "text": "since you say you i can download the open source code does that mean uh what's in the iprs is not uh in the code i i i think that we declared before working group adoption so we made it free also the multi-pass dccp implementation the protocol implementation is part of the linux kernel network stack so it's gpl based okay so no no ipr's involved if i use that code yes yes please and please do so that would be great thank you thank you michael slide please next slide yep um so some general updates uh on where we are now with the multiple dccp here i make again the relation to 3tpp and i think on that we will also have a site meeting uh later on um after after the tsvwts session where also our 3gpp delegate from from the telecom will give some insights into uh how atriples yeah how it looks like what what are the time constraints from a 3gbp perspective and so on so everyone who is interested in that should join the site discussion um nevertheless the point i wanted to make is so multi-parts dccp is so far the only solution for non-tcp non-tcp splitting support which made it into the technical technical report after the last sa-2 meeting which has happened in when was it february yeah exactly so for sure we also expect that the other solutions will will come up into this technical report but so far only multiples gccp is there and we also"
  },
  {
    "startTime": "00:30:00",
    "text": "have some some great support from from big parties here i already outlined we have now the full uh set of functionalities available which are at triple s compatible i will not repeat all of them i think i made this clear already we have a plc agreed with a big terminal wonder who will adopt the multi-pass tccp into their android system and so that is where we are currently working on together together with this terminal vendor to get some first experience we also started some exploration of including random linear network coding and combine this with multi-pass dcp to see the effect especially when packet loss occurs yeah active drive development is at github with currently nine contributors um if i look at the time i think i have to speed up a little bit um so that is the relationship i think we will later on discuss again in the site meeting so maybe we can skip this for this meeting now there we go ah very good yeah that is that is something interesting um so we spontaneously decided to participate in the hackathon so we just took a free free table and started live hacking so we have a google pixel 4 phone now available with multi-pass tccp integrated we used it to demonstrate the effect what what happens if the commercial accesses the wi-fi and the 4g axis be used in the hackathon room if one of them fail so this google pixel 4 be connected to a multi-pass dccp proxy in the internet and we started a real skype call between this multi-pass dccp enabled smartphone and a traditional smartphone without multiples tcp through the mpdccp proxy so what what happened um when when one"
  },
  {
    "startTime": "00:32:01",
    "text": "or the the currently used access failed there was a immediate hand over into the other axis and there was no interruption in the skype call so it works i have this phone available and i'm open to present it to anyone who is interested yep coming to the last slide so we believe with draft version 4 we are feature complete so we are now in the process of getting reviewers on board and please feel welcome to join this that would be really helpful for us i further outlined that we did a lot of development and it does a lot of publications around the multi-pass dccp prototype including also now the encapsulation framework which is quite important to enable any type of traffic for multi-pass transport we are ramping up now poc activities with industry also to test interoperability and we will continue result generation and publication together with academia our goal is also to keep pace with a 3gbp release 18 timelines again i think that will be something we will later on discuss in the site meeting the details when it will happen you you can find here on this slide so please feel free to join uh the reviewing queue for multi-pass gccp also to start maybe hacking uh the prototype would be also great and with that i would say let's go to the question round thank you so any questions please thank you ever so much for joining the"
  },
  {
    "startTime": "00:34:00",
    "text": "hackathon and it's always good to see running code and i think evidence that things work is definitely something that's useful um you'll see the announcement while we're taking questions this is a tsv related side meeting across the corridor after the current break just after the end of this meeting the room capacity is always limited because this meeting was called together just to provide some coordination it's basically just a chance to talk and make sure that people understand the position of different things that are going on and we're really pleased that um we have some participation from three gpp representatives to help just tell us a little bit more we have one question uh go ahead uh yes uh checking here um in 3gpp uh ats ss3 discussion uh there was one study topic regarding to use more than two parallel passes like a three different passes in order to provide the multi-castings well uh when you did give the presentation i try to look for information regarding that beyond the two so can you elaborate on that one thank you yep so if i got your question right you ask how many paths we we support um okay very good yeah so we are completely agnostic to that uh we support as many parts are available so we don't have any limitation so it doesn't matter if there are just two paths or two access available or three or four or five or six okay okay thank you oh yeah by the way for the 3gpp part the hss multipath tcp they're going to provide some proxy and and"
  },
  {
    "startTime": "00:36:00",
    "text": "some ups so for your implementation mp tccp are you looking at the similar ones uh to put some proxy uh on some sort of ups in order to provide multipaths thank you yeah that is maybe something which has to be clarified in 3tpp if there is a certain protocol needed to signal uh the um that there is a multi-pass tccp proxy um so at the moment from the multi-pass dcp traffic itself there is no support for this and i think that is also not the idea of the multi-pass gccp draft so that is specifying really the basic protocol and not any proxy functionalities oh okay okay thank you okay thank you ever so much another question oh david question from david marcus there's some questions in the chat about whether remote participation will be available for the side meeting have you made any arrangements there is no remote participation support for site meetings we will make notes and we will distribute some of the materials from that to try and help inform this this is purely an information distribution meeting no decisions will be made everything that comes out of this will be made available to people and um sorry but we can't arrange remote participation at that martin thank you just to comment on that so um yeah so it is ietf policy did not provide the support for remote meetings that said if somebody wants to use the btc client of their choice um that's obviously okay um independently so um"
  },
  {
    "startTime": "00:38:02",
    "text": "because if if somebody chooses to do that we just email the list and let people know that's available or not it's up to you to marcus as the as the proponent for the meeting it's really fun this i mean maybe we need a longer ietf meeting uh yeah we'll see what we can do tell us yeah i'm not sure what the policies are if this is tsvwg endorsed then it's not tsvwg endorsed it's tsvwd related okay so it's purely information distribution about what is going on and what people think so it could be in a corridor but to make it a little bit easier because we saw several people interested we boot to side room so nothing we'll go in the notes for tsvwg about this but we will distribute the information to the list thanks marcus thanks so next up in our agenda is discussion of diff service differentiated services um we said we'll take anafist and talk about the considerations for assigning dscps we can advance slides if you're saying next not sure who's got side control yeah uh is this the latest version of the slide deck this is david i have high control just say next uh i'll i'll move them forward okay thank you uh right so hi i'm anna i'm here to talk about our draft considerations for assigning gifts of code points uh next so i'm going to start with some updates so uh we published revision01 and in this revision we included some"
  },
  {
    "startTime": "00:40:01",
    "text": "clarifications around the different pathologies that can happen to a diffserv code point as it crosses a path in particular we added a new pathology which is clearing the least significant bits of a dhcp and since we published that we also got a load of comments um in particular thank you very much to brian carpenter and rudy gargayeb who offers some very helpful suggestions uh mostly this is just adding or editing text on how we relate to other rfcs like 3086 on phps or um clarifying some of the text in rfc 2474 and especially what it says about remarking of this code points at boundaries between domains we also got some suggestions to talk a bit more about management code points and also to clarify that the gsma ir34 standard is not binding and has not necessarily seen a lot of deployment oops sorry um so we're going to make all of these edits i haven't had a chance to get back to people on the mailing list but thank you very much they are very helpful and i will propose some text and we will get back to you thank you very much uh there's something else we want to discuss and we want to include in a future version of the draft and i'm going to try and paint a picture here on what that is so next slide please so i'm going to start with um sure i have a lot of transitions i'm going to be saying next a lot but i'm going to uh try and show you on this grid which um these are all of the 64 chord points arranged in an 8x8 grid and i'm first going to highlight the ones that have already been assigned uh next so first off uh you have rsu 2474 we specified the"
  },
  {
    "startTime": "00:42:02",
    "text": "specifies the class selector code points i think this is back in 1998. um and these are the the code points that um keep compatibility with the previous dos precedence field uh next then along come all of the assured forwarding code points which can also encode drop probability um next and then finally you have three more assignments that have been made over the past 20 years you have one for expedited forwarding you have one for voice admit and finally in 2018 you have one for lower effort next please on top of all of those assignments you also have uh code points so if you take the sorry the binary representation of these code points those are the ones that end in one one are the ones on those two columns and they are reserved for experimental use next please right so this is how the grid looks right now with all of the assignments and over the years i've been i've been measuring diffserv ever since around 2016 and in doing measurements um well we kind of know what code points are popular in particular in specific types of networks or from specific uh types of edges so next please so for example um at the web server edge you see a lot of the af 11 21 and 31 code points uh and to a lot lesser extent cs3 and ef next please mobile networks a lot of mobile networks just remark all of the incoming code points to uh one only one value and that's often af 11 12 or 13. uh next please uh by examining a large number of packet traces at an internet exchange we saw a"
  },
  {
    "startTime": "00:44:01",
    "text": "lot of the icmp traffic does carry a code point cs6 as rc247 states so that's another one that is used next please and finally examining dns server replies we see that often they use cs1 that one in particular all of this is measurement data and the latest slide deck has an appendix and all of the highlights of this data and all of the measurements that we conducted are in there so i thoroughly encourage you to take a look so next please right so these are the code points that are used uh based on measurement data unfortunately the measurement data also highlights a problem so in our first study that we did we found a significant number of fruiters and what they do is they bleach the three most significant bits of a dhcp we call this pathology toss precedence bleaching and it happens on up to 20 percent of paths is that's what we found in our study it depends on vantage point but it's a pathology that we found for from every vantage point that we tested we also validated the data through different methods uh validated in a study on edge networks made through um ripe atlas and we also found this in the packetries analysis so uh those precedence bleaching is extensive uh what does it mean well if you clear the top three uh bits of a dhcp essentially what you end up with with a value of the resulting dhcp is between 0 and 7. so for example af 11 bleaches to dhcp2 ef which is 46 if you slash off the top three bits it bleeds to six next please"
  },
  {
    "startTime": "00:46:02",
    "text": "so essentially all of the dhcps on one column will bleach to the lower lower lowest value down there of that column so that is a big problem for assignments uh next please well why well it's a two it's a two-way problem because if you have all of these uh popular chord points that then get uh toss precedence bleach to one small code point that it means that small code point b two or six then can no longer be used for assignments because it's essentially polluted as it's being used by a lot of other traffic and also it it also has implications for the uh larger dhcps because then if you choose one of them then for example if you choose the sap if you choose to assign the scp 9 or 17 then well if they get close precedence bleached they end up with code 0.1 which is used for lower effort and you really don't want that in an assignment right so what do we have in that bottom row well we have zero which is the sign which is best effort we have one which is a sign lower effort next piece then we have two and as i've said a lot of traffic aggregates well those precedent speeches down to two so that one is not necessarily very usable at least in the core of the internet then we have three which is experimental next please then we have code point four and this one has a different kind of problem it's more of a historical ssh bug all ssh well not all ssh but a lot of ssh traffic uses this particular code point and we've seen this as well in measurements next please then we have the scp-5 and we have nqb which is provisionally um allocated to this to this value then we have six uh next please"
  },
  {
    "startTime": "00:48:03",
    "text": "six has the exact same problem as um 2 but to a lesser extent because on that column you have ef and f13 which are quite popular and then you have 7 which is also left in the experimental next please right so you have a problem with those precedence bleeding so you can either view this in two ways either those person is bleaching is something that is a given it happens in the internet and then assigning one of those code points that is smaller than seven is a big deal and then you should consider these smaller code points as aggregates as opposed to assign them for a specific purpose or you can consider it's not a problem because those bleaching is after all a pathology and it shouldn't be happening and then you can you have other options you can just choose well you can have a dual allocation like um nqb does and it deals with it that way because it has uh one quadrant assigned from the edge and one code point for the core and the codebrand for the core is the scp-5 which is meant to traverse but what if those precedence breaching was just a pathology then you could easily just choose one chord point to represent that of the same semantic across both edge and core right in any case whichever way you choose to go about this you have to think because um assigning the small code point kind of risks making code points in the same column unusable next slide please uh right so underlying all of this there are essentially three cases that i've seen in measurements and from talking to different operators you either have networks who don't care"
  },
  {
    "startTime": "00:50:01",
    "text": "about their server at all and then they pass code points transparently um and this is this is a valid use case of this and we've seen this in measurements uh then you have managed networks another you know good use case for difficult this service sorry um so operators uh police code points allow only some through remark the other ones to protect internal nodes in the network and that's perfectly fine so in this particular scenario an operator chooses to support a new code point when it is assigned and that's fine so whatever operators do with code points there's lots as long as it's not those precedent splitting then it's fine because it doesn't affect new assignments of gold points if yeah oh and then finally um there's the unmanaged networks or what i call unmanaged networks that have really weird behavior um i consider tostrescence bleaching to be in this category for example uh but there are also other types of pathologies like for example bleaching the um the other the other three bits of the dscp and that happens but only in some very few weird networks and you can have inconsistent remarking anyway problem networks and basically we'd like to propose some text about this what would like to get input from the working group on what to say about them next slide please so um yeah what do we say about them will go in the next version of the draft um i guess at the moment our draft is informational um we don't know if we could maybe make recommendations for future assignments i mean i'm going to include the table and the implications that i've just talked about in the version alongside with"
  },
  {
    "startTime": "00:52:02",
    "text": "the text that other people proposed and maybe it's also worthwhile talking to operators to understand a little bit more about um how things are used but yeah that concludes my presentation what i have is a lot of appendix slides with lots of data so please be sure to check those out uh thank you thank you anna do we have any questions we have martin at the mic that'll be good uh martin martin duke google um first of all i'd like this is my first opportunity to thank you in person for doing this draft um i'm learning a ton just listening to all this and that that grid you showed just really makes it super clear that we're burning the last generally useful code point um which is uh pause for some reflection on this um yeah like i would encourage you to take this to maybe ops area next time um that might be a good step in terms of the operator survey you may not reach the people who are still bleaching um because those are generally less informed less connected people but nevertheless um that is a good entrance point into this um into that community uh but yeah mainly thanks um so your intent is still to have this be an informational draft in your potential if not mistaken and you're proposing potentially additional draft that that was was that like what's the new draft supposed to be uh the next revision of this draft oh okay okay right okay uh maybe step in this chair here so the the current work item is informational yes and i guess this draft will be revised as informational"
  },
  {
    "startTime": "00:54:00",
    "text": "yeah and it is informational until we get to the point where we start clarifying the way that these 20 year old rfcs are being updated based on the current practice so i i hadn't realized this when we started it but maybe brian's carpenter's post recently on the mailing list was actually quite quite deep quite useful maybe after 20 years we should reflect on what the best practices as we deal with the last few chord point registrations we should kind of get this right so i think anna's line of this document is informational is quite correct if we think ahead if we decide to do anything more then this document maybe either has to have a pair which is not information but maybe bcp or ps or whatever it is and that would be a change for the whole disserv architecture which is currently all recommended um well okay so the thing the thing is um it'll be good to get discussion on the date that ana's had and to decide on the way forward i don't think this blocks the nqb work by the way because i think we can friend qb we can find the right answer no and then we really don't have very many chord points left so we have to decide what we're doing in future so i think these things could work in parallel it'd be interesting to see how that pans out yeah i mean i i would just looking i mean having been aware of this for five minutes now i i i would be tempted to a try to enter you know engage with the operator community and see if we can handle this bleaching situation which i think would be great if we could fix it but secondly like i mean we've got a lot of experimental code points and maybe like deprecating half of them would be wise so we have a we have a code a three bit code point that is available just to be off the top of my head i mean obviously it's not a fully considered opinion i think we need to consider um what anna martin's experiment was actually local use and experimental local use of the scps is incredibly"
  },
  {
    "startTime": "00:56:00",
    "text": "important yeah and we also have managed use of dscps and networks that just pass the scps without doing a lot of changes to them and those which do changes which are historically based which are kind of maybe harmful so there's maybe different categories so this is going to be a thing that's useful to explore i suspect all the people in the queue are going to talk about this yes and [Music] yes i think we should take it to op sorry i think that was a wonderful suggestion so as a core contributor to anna's work and i think a presentation upset would be so wonderful all right thank you thanks and after all that we have now rudiger who's also been active on the mailing list and rudika please speak to the mic yeah i hope you can hear me we can hear you please go ahead great yeah i'm would you go guys i'm configuring bleaching at the bacherators of dodge telecom and um long-term gifts of participant i appreciate uh work on an update of the existing drafts because i think and i contributed a lot of my operational experience and uh what i'd like to have or like to see in future is something which uh allows for default transport in the backbone default saying just default nothing else but uh service differentiation in the access and that should be also standardized uh sharing of resources and what i'm aware of is you can either optimize for throughput or you optimize for [Music] performance which is low jitter and low delay i don't want to say it's that or this option just should be fair and not discriminate against others so there are no pipes it's just a default behavior in the backbone and the standardized behavior on the access how resources are shared and i"
  },
  {
    "startTime": "00:58:02",
    "text": "can tell you that many people who request quality of service concepts from me nowadays come and ask for exactly that thank you um sorry what's their question no i guess the question i guess that we we can include rudiger's comments in that part of the draft uh yes yes if the result of your draft is to recommend an update of the div specifications i really appreciate that thanks okay ah that's useful input as well thank you erdogan let's continue this on the mailing list jonathan morton just like to express support for um some kind of bcp or uh um rfc updates to um try to discourage the use of bleaching in the network in some effective way so yes we can continue this offline yes it's in line as well with what we're thinking okay right so the answer is please revise the draft please consider a presentation to ops area to try and tell them what what we have found and also let's probe on what we mean by recommendations but do these three activities separately revise the draft think the presentation to ops area at the next ietf and also think about whether the recommendations for the use of chord points could be something we discuss on list and come to some consensus about these might have very different time frames but thank you ever so much for the talk uh yes i'll start the process on the mailing list or the one and the third things you just mentioned thank you anna wonderful"
  },
  {
    "startTime": "01:00:10",
    "text": "oh they are they appeared excellent we have a question from bob briscoe and sophia so bob please go ahead let's just have to suggest as well as upstairs the ieg which is an informal operator i'll put that um bob you completely broke up iepg can anyone channel bob i can bob type that into the chat yeah excellent that would help i think he said what i was also going to say that you should also look at the iepg meeting on sundays which is a sort of operator hangout thing that's adjacent to the iatf well warren kumari is sort of involved with that if you know him or talk to me afterwards i'm not involved but i can point you at people i would love an introduction um definitely so there's a bunch of operators that meet like on sundays and chat about this and that's what no the date every itf sunday they meet or yeah so the the comment was um consider also iepg where you can have the same talk with a very different focus because it's operators who are probably really engaged with this yeah so iepg as well and was that bob's comment yes as far as we know right please go ahead now this is to be uh two key questions one is uh you mentioned that there may be an operator survey will that uh will that happen and the second one is that when the recommendation will come will the recommendation will come to tsbg or somewhere else"
  },
  {
    "startTime": "01:02:01",
    "text": "easy questions to answer thanks ever so much for asking we can launch an operator survey we would have to do that of course with um the ops area because it's an operator survey and i think operator service have worked quite well in that area so we might try that i will speak to warren and yes the recommendation will come from this working group but clearly this is something that is a fairly substantial change to the way the internet routers work and the way we operate them so other groups would have to be involved if we change the recommendations which is kind of why i'm leaning towards separating the two discussions into here's the information on what we have and how we register things and here's any new considerations that we have out of it as a standards track document which we'll have to go around the ietf with okay this is a working group to discuss this that's that's very good so i think i heard you also mentioned that that recommendation possibly will imply that to look at deep server architecture am i correct it it looks like it might because the current diffserv architecture is all recommended it was put in place about 20 years ago to make something work when nothing worked now we have things working we might be able to change that a little bit however if it's working well we might want to make small changes thanks thank you sebia final questions great keep going jake please talk yeah i want to echo martin's uh this was really good i felt like i learned a ton in 10 minutes and i would encourage you to also take this to maprg as a measurement presentation there i think you would not only the operator community but i i suspect uh many others in the ietf community and the associated research communities would"
  },
  {
    "startTime": "01:04:01",
    "text": "benefit from understanding these observations thank you thank you thanks jake like i'm gonna have a very busy next idf thank you anna i think um you've had enough invitations for the moment for doing more work please do some more work and come back and with that and i do encourage us to use the mailing list and we will move forward with the next draft which is one which i think greg will present remotely greg are you online just want to excellent please speak to your slides all right um thank you um you can go on to the next slide this is a brief update for the nqb draft obviously some discussion around code point assignments will continue on the mailing list but here just wanted to cover the uh edits that were made in the draft recently and i did do a presentation at the interim um uh a short time ago so um a lot of time has passed since then but uh one update the draft has been made this graph 10. um and i can on the next slide i i did send a list of the edits to the mailing list um this is verbatim what i i sent um next slide has a little bit better breakdown uh of what the changes uh really amount to um this version here is instead of going section by section in the document but if you want my next slide really summarizes what the uh the changes were first one is um the section in"
  },
  {
    "startTime": "01:06:01",
    "text": "uh the graph that talks about what types of senders are compatible with the nqb marking and and would be recommended to mark their traffic as nqb in particular it talks about sports uh flows of sports applications that are sending at a relatively low rate and um for those who attended the last ietf uh as well as the interim note that that's been a point of discussion for um a couple of rounds to try to get that language right um and so hopefully we got it uh right this time but encourage folks to take a look at that and if there are further comments or suggestions on refining that language i certainly would appreciate hearing those the second item is some more discussion around the rationale for the choice of the code point 45 and this was sparked by some comments i received off list [Music] that suggested that a little bit more background and rationale would be helpful for explaining that the third item um additional implication of edca manipulation this was a comment on the mailing list that pointed that in the draft suggests that uh one approach to making legacy wi-fi networks look a lot more like they're supporting the nqb php in other words make them support at least some of the requirements of the php can be achieved by changing the edca parameters that are used for the video access category and one thing the graph didn't state um directly and then was commented on the mailing list is that"
  },
  {
    "startTime": "01:08:00",
    "text": "well by doing that you give up a priority queue so you turn a priority queue into a queue that has the same priority as best effort and so now there's a a discussion of that or statement on about that in the draft and then uh fourth bullet um the iana section um so reformatted that to [Music] align with expectations for the instructions to ayanna and also per a comment at the interim um gave unique names for the two code points forty five and five um names i've chosen are in qb edge and nqb core although it's kind of an open question to the working group um are those the right names i think um some of the discussion about um you know toss precedence bleaching and uh other um um network uh effects that uh that remark code points um we might consider whether those are the right names or not but i think um again some some broader discussion on on that hopefully to take that out and then finally some editorial myths i cleaned up along the way and that's it for the changes so far at this point you know what the next slide really um been looking for other comments or the review comments um before starting working with glasgow um obviously the recent comments about uh a good point of time i think we need to include those on the mailing list before taking this to working from the basketball looks like uh glory have your hand up oh gauri first talking from the floor so"
  },
  {
    "startTime": "01:10:01",
    "text": "i can stretch and get some exercise um yeah thanks greg um i think the whole dscp thing can be dealt with and i like the ch who registrate names the two registering them with different names is probably right i only wonder if we should think about adding some text about why we are doing this and also to perhaps clarify what the aggregate or law numbered in this case five dscp point actually means when we have other assignments with other dscps in the same column of anna's table so these seem like things which we should talk about they don't affect nqb but they may affect whether we choose should must may and what words we write so i think that might be a useful input from the floor as an individual right all right thanks um yeah the the you know should remark or and should not use uh the value 45 across interconnects i think that's the areas where i agree that you need consensus on those and it does kind of get back to what is the what is the end-to-end philosophy for diffserv going forward seems like you there's some view that uh diffserv is by intention um your as specific or you know domain specific um and then obviously other views that uh it was ideally intended for end to end use so um yeah yeah we have david in the queue as well david there uh for for the history uh this serve was trying to be both trying to allow individual networks to configure"
  },
  {
    "startTime": "01:12:01",
    "text": "configure and provide opportunity for end-to-end uh uh and end-to-end uh services the end-to-end has not worked out all that well see ana's wonderful slides for the gory details any other questions okay maybe david do you think we're near a working group last call because um it seems like the frameworks clause and all we have to do is pin down some new text around the use of these diff chord points is there anything else you think needs to be considered for a working group must call to start i think that's about it we should also have a real close look at exactly what we want to call the two new code points but i think that's about right and i think we're close comments from jonathan martin this is actually from jabber sebastian muller asks what is the time frame for the 45 assignment if nqb becomes popular and supported ubiquitously keeping 45 seems not needed as this is only to fudge nqb into existing or future legacy wi-fi deployment uh what's the the time frame um you know i think um the other applications that uh today uh would like to be marking their traffic with uh nqb code point there currently isn't one that's formally assigned and so application developers have had to use alternate um or been suggested to use alternate code points that [Music] they could also be classified into the"
  },
  {
    "startTime": "01:14:01",
    "text": "same or aggregate into the same uh php in the enquiry php um so i think that there's a demand for a code point uh sooner rather than later um maybe part of the question here is how long do we need the allocation for i wondered how good your crystal ball was um do you think 45 would work across the internet core in five years time and we don't need the five assignment or do you think we need the five assignment forever and we don't need 45 because all the wi-fi equipment will be updated within five years do we have any clue about where things are going how long a version of no would you like to hear gory well i just thought with asking the question i thought the answer might be no we don't have a great crystal ball and this has always been a problem in the itf we don't know what's going to be adopted by whom we just encourage adoption and then maybe we have to figure out this text appropriately in the way we can't consider the outcomes i'm jonathan do you have more follow-up sebastian says uh that you have conveyed the core of his question correctly and i would comment that as the draft is currently written uh the 45 assignment is long term because that's what's recommended to end points uh to signal uh signal use of this php thank you let's have a short focused set of questions greg after you've done any revised work i'll work with the chairs on those questions and let's then try and get them cleared so we can get to that working group last call sounds good we'll do our best to help everyone else please join in"
  },
  {
    "startTime": "01:16:00",
    "text": "thank you that closes the dscp part of our schedule we're a little later than the agenda but i think we're still on time for all presentations so uh the next presentation will be by tom herbert uh i took the decision to have a slightly longer slot for tom um so that he could have a full half hour um just because this is an interesting and useful background particularly for udp options but also for anyone who's in the transport area and wants to know about what is currently going on with implementation of internet checksums in real equipment so go ahead tom tell us please um thank you so my name is tom herbert as corey mentioned and i'm going to give a little bit of presentation on how we're implementing the internet checksum so as gore said this is um kind of a relevant topic it comes up a lot uh udp encapsulation there's a lot of discussion on that in actually any encapsulation but we're also seeing questions being raised in udp options and just yesterday fred champlain's talk on ib parcels the topic also came up so the topic is relevant because the internet checks them as we know it's quite pervasive it's in all major transport protocols udp tcp it's also in ipv4 and the fpv4 header checksum uh kind of the go to validation check we like it because it's really simple uh easy to compute that's really just an addition uh it's well known that it's not the strongest of verification checks but the thing that makes it relevant particularly to the implementation is it can be very costly if we don't um optimize it properly uh computing a sum over"
  },
  {
    "startTime": "01:18:01",
    "text": "uh some field of bytes if we have to do that for instance in the cpu on a tcp packet a large tcp packet that could easily overwhelm the cpu because of the per byte cost of processing so there's been a lot of work on the implementation side to really optimize this and i'll touch on some of that today but i think the the relevance with protocols especially new one is when a new protocol is being developed we do have to consider the implementation effects uh particularly something that is potentially costly like the internet uh checks them next leg please so a little bit primer on the internet checksums so they are 16 bit values usually they're put into a two byte field in a packet and that will be used as kind of the validation code the algorithm is a ones complement two byte sum and typically this just starts from a start offset in the packet to the end so we're going to basically sum up all the two byte words in the packet from some beginning point you'll see the end and that gives us an answer and that answer is kind of the check the sender and the receiver effectively both perform the same algorithm the sender actually sets the sum such that it sums to a known value in the case so the internet checks on it'll be all ones ffff and the receiver performs the same algorithm so it adds up the same bytes and all it has to do is match the answer to the expected answer and if it matches then we assume the packet is correct so as i mentioned that's using tcp udp the ipv4 header checksum uh gre checksum uh udp options will have a checksum also and it's probably used in several other"
  },
  {
    "startTime": "01:20:00",
    "text": "transport and possibly even some layer two protocol or layer three protocols next slide please so the algorithm uh the specific operation it's one a one's complement addition and the idea of one's complement addition is we add two binary numbers of some word size uh it's normal addition uh if a carry is generated though that carry is added back into the result to get the final answer so in this example we're adding 210 as a byte and plus 106. that does generate a carry in the basically the higher order bits so high order bits generate the carry and all we do is add the carry back in so the sum in this case is 3d or 61. next slide please so one of the nice things about the internet checksum it has a lot of very nice arithmetic properties that we can work with um and do some optimizations and you can contrast this for instance to some of the stronger checksums or verification codes like crc32 which don't have these properties and actually makes them harder to compute or harder to use so one of the the first properties that is well known and it's actually used in internet checksums today all ones is mathematically equivalent to zero and one's complement addition so for instance if we have a word and we add the os version of that that actually equals the starting word so it's an identity so there are effectively two zeros in checksum or one's complement edition it's also communicative and associative"
  },
  {
    "startTime": "01:22:01",
    "text": "so we can add two words we can switch the order and get the same result and then we can group uh sums together in different combinations to get the same result so given a set of words that we're summing through one's complement addition we can sum them up in any order uh we can reverse them we can group them together so there's a lot of options there and that is going to actually be quite useful in some of the um kind of sub algorithms that we have when we're manipulating checksum we can also define a sub uh check sub check sum subtraction which is basically the not operation so if we have a word and we add a do a one's complement add of the not of that so we flip all the bits so zero becomes one one becomes zero if we add those together then the sum is always all ones and again that's equivalent to a checksum zero value so sums to basically zero the other one is that check some checksums of a larger word size can be folded to a smaller word size with basically an equivalency so we can take a 32-bit checksum value for instance and we can perform an operation and make that a 16-bit checksum value which is equivalent of checksum going from 32 to 16 bits it doesn't work the other way but we can go from larger word sizes to smaller word sizes and i'll have an example a little bit later on on what the procedure for that is next link so the internet checks them as i mentioned it's a ones complement sum and what we do to set it is there's a start offset in the packet so in the case of tcp for instance this would be the first byte of"
  },
  {
    "startTime": "01:24:01",
    "text": "the ccp header there's an end offset typically that's the the end of the packet and we sum all the two byte words from the first byte the start offset to the end offset if it's an odd number of bytes then we simply add on a virtually add on a zero logically out on a zero to the n in some protocols for instance tcp and udp there is a pseudo header so the pseudo header is also added in um the idea of the pseudo header is to protect uh bytes and fields outside of the checksum coverage area so for instance a pseudo header would include the ip addresses and the length in the case of tcp checksum so the pseudo header is is created that's obviously standard we do the ones complement sum of the pseudo header we add that to the ones complement sum or that coverage area from the start to the end offset that gives us the full ones complement sum and then we basically take the not of that and that becomes the result and i should have mentioned that before this operation commences if the checksum field is within the area that we're check summing usually we'll set that to zero for the purpose of compute computation and then once we have the result which is again a summing over all of the bytes that are covered we take the knot of that and we set that value into the checksum field and then the result of that is when the receiver performs the same algorithm so we'll do the sum from the start offset to the end offset and a way out in the pseudo header the result will the correct result would be all ones fff in the case of the internet 16-bit internet checks on next slide please"
  },
  {
    "startTime": "01:26:01",
    "text": "that's the the purpose of validation so same algorithm there's a pseudo header there's no pseudo header like in the case of gre checksum then effectively just add in a zero which means it's a noaa and again if the result is all ones we consider the checksum ballot if it's not then it's considered to be a corrupted packet next slide so as i mentioned the internet checksum it's computationally expensive we do have to basically touch every byte every word of a packet in the case of something like tcp or udp checksum so there is a lot of motivation to optimize this and over the years there have been has been a lot of work to do just that we can actually divide this into basically two areas so we have some checksums that cover small amounts of data the best example of that is the ip header checksum typically this is 20 bytes maybe up to 40 bytes it's a very small amount of data so the way direction we've gone on that is to have very specialized cpu instructions to handle um handle that case basically a one's complement addition uh instruction the other side of this is large packets uh this is like payloads so this for instance is the typical case of tcp and udp where we're calculating the checksum over the full payload which could be thousands of bytes in that case it really warrants checksum offload this is when we basically have the hardware actually perform the checksum on behalf of the host and all nick vendors for instance today support some variant of checksum offload"
  },
  {
    "startTime": "01:28:00",
    "text": "it's heavily motivated obviously by tcp where where the checksum wasn't or is never optional but also udp so what they've done is they have optimized um the nics in a couple of ways we'll get into that in a moment but the upshot of this is for tcp and udp checksums from a host perspective the nics actually do all of the work and basically we completely saved the cpu um it's already baked in these have been around for a very long time so generally this sort of checks on computation is not considered to be a problem in terms of performance at this point next slide please so if we look at the um kind of the the naive method to write a checksum algorithm in pseudocode so we want to do a 16-bit sum and as i mentioned if the first thing we want to do is check if the length is odd if it is we have to add that extra byte so in this case we're just literally tacking on the bite and increasing the length to make it even and then we go over a loop and the loop is going over each two bytes and it performs a sum of each of those two bytes each so the sum on the fourth line there we're just adding uh every two bytes and having a running sum and each each time we do the add we have to check the carry if the carry is set which is what that um check is uh if some 16 is greater than all ones then we add the carry back in and proceed to the next two words so it's again a running one's complement some where we're basically performing a normal addition of two bytes and then adding in uh the checksum if it if the carry or"
  },
  {
    "startTime": "01:30:00",
    "text": "add anything in the carry if it was set next slide please yeah so just um is there any good data you know what the um biggest reasons are for check some errors and you know what their probabilities are we just kind of you know the use case always escaped me from the analysis yes there has been a lot of work on that um i think it's probably out of the scope of this presentation but we do know for instance that checksum is susceptible uh to search and combinations it will detect all one byte errors uh but it's possible that it can miss uh or one bit errors it can it's possible it can miss uh two-bit errors because they can cancel out each other so it's stronger than parity much weaker than crc um but it will it will provide some validation yeah i was just wondering kind of the most simple answer for this is what actually happens and it protects against it that the kind of the motivational are you asking um is it memory copies or dma failures or something yeah that it actually does protect against right so the biggest reason that because you know i would say we very often had this discussions about when can i leave away the checksum remember uh gory right so when we did these tunnel things and udp without checksum so there was the ongoing debate but me coming mostly from the network side i never looked into the end to end which is what the expensive part is so i was just curious thank you i i yes i would suspect it would be in the network if there is an error um modern computers obviously have a bunch of redundancy checks and have ecc and"
  },
  {
    "startTime": "01:32:01",
    "text": "memory so it's much less likely network corruption is probably more likely um it's still not not super likely uh as i mentioned we do know the the internet checksum is is fairly weak if we need strong integrity checks uh for security purposes for instance then we do have to use much stronger um much stronger things uh much stronger calculations it's so one question that often comes up is why isn't the ethernet crc sufficient the main difference is the internet checksum is end to end so ethernet crc um does just much stronger protection that's always in hardware um internet check somehow however is much weaker there's also another value to it um in the case of something like udp options the checksum actually can be used to differentiate between standard uses of a byte space and non-standard use use cases so a non-standard use case may still be valid but it might not be what we expect in the texan would actually protect us there a question from richard in the care not not a question but an observation so from my experience um with our customers we have checked some errors typically in the order of perhaps once a year across the entirety of our customer base and that typically happens with a fairly old network gear which has not ecc protect memory and when basically the packet is in flight and you have unprotected or undetected multi-bit errors which then show up in higher layers of the protocol where you do have crcs that will flag a bad transport in tcp for example okay thanks richard um tom you have about 10 minutes left okay"
  },
  {
    "startTime": "01:34:01",
    "text": "um so one of the optimizations the first one is we can actually sum over larger words as i mentioned so we can do a 32-bit edition and we can uh translate that into 16 bits next slide please so in this case we could have the same loop but now the boundary for the loop instead of being length divided by 2 becomes length divided by 4. so basically if we sum 32-bit words instead of 16 we have the number of additions so hence that's a a very nice performance improvement next slide uh so this is uh forwarding the checksum to 16 bits it's pretty straightforward basically just add um if we start with the 32-bit value add the high order 16 bits low order 16 bits uh do one com once complement sum and the result is basically the folded value and again this falls out from the arithmetic properties of the checksum next slide please on modern cpus as i mentioned there are specific instructions to do this to optimize the uh once complement edition in x86 for instance there's an ad with carry the ad instruction itself sets a carry bit in a control register on x86 and then the specialized instruction ad with kerry performs an ad but then it does that um check of the carry and adds the result back in so this is used extensively in networking stack for instance when we want to implement the checksum over the ipv4 header uh this basically is resolved to a few uh ads with carries next slide please uh so i'll briefly touch on this this is actually code um to do checks on the ipv4 header uh the first"
  },
  {
    "startTime": "01:36:01",
    "text": "section is actually doing eight bytes at a time so in order to check some over 20 or do to check some calculation over 20 bytes we do an eight byte add an eight byte add and then a four byte uh add and all those are ones complement add and at the end we um add in the carry bit when it was generated so that's what those four first four instructions are doing and then the rest are the operation we're basically folding 16 bits down to 32 bits and then six uh 32 bits down to 16 bits next slide please uh so i'll touch on this briefly um one of the common operations in dealing with checksum is if a packet header is updated for instance in nat the ip addresses are updated we do not want to recompute the full ip checksum we don't want to recompute the full tcp checksum what we can actually do is is figure out what the delta is meaning if we add a certain value into the checksum field that would basically offset the change we made elsewhere in the packet so it's very um very common thing to do and it's also very highly performant because we can even pre-compute in some cases this addition so updating the checksum for something like nat may come down to one single ad with carry operation one single one complement addition and then set the field so this again the arithmetic properties of checksum make this highly efficient in order to do things like this next slide please so checksum offload as i mentioned is very useful uh to get performance when we're offloading or when we're processing tcp and udp checksum as i mentioned all nics have this there's actually two methods i'm only going to touch on the the more common"
  },
  {
    "startTime": "01:38:00",
    "text": "method or at least the preferred method which is what we call protocol agnostic offload so this is a case where the nic which is network interface controller that's performing the checksum calculations on behalf of the host does not need to know what the particular protocols in the packet are it can do a checksum calculation both on send and receive for arbitrary protocols works to encapsulate checksums and we can use these techniques to validate multiple checksums per packet the alternative is more of a legacy mode which older devices did and some of the original checksum offloads did this they only understand certain protocols and can do verifications on those protocols however outside of that for instance introducing new encapsulation we found that they basically don't work so there's a strong preference in the community to use protocol agnostic offloads and in the case of checksum that is really important because of encapsulations and other uses of checksum next slide please so transmit checksum offload basically this is following the same procedure as a host except we're going to tell the um nick or the device how to do it so we send the start offset the end offset and a transmit descriptor you'll see the end offset is the end of the packet so that's kind of implicit and we give the device where to put the checksum uh the one thing the host has to do is it will kind of prime the checksum field so for instance if the pseudo header is involved like in case of tcp the host will compute the once complement some of this of the pseudo header and knot it and then set it into the checksum uh feel so when the device gets this um packet via a transmit descriptor it performs the calculation and all it does"
  },
  {
    "startTime": "01:40:01",
    "text": "is start from the starting offset to the end of the packet perform the ones complement some and set the result in the checksum field it doesn't have to worry about the pseudo header because that's already been taken care of by the host next slide please uh so i'll skip this for a day that's wanted to touch on there there is a way to do multiple checksums per packet um in particular network devices uh they only have the capability to offload one checksum per packet however we also want to take advantage of that uh tough load multiple of them like in the case of udp encapsulation where the udp checks them may be sent the tcp checksum may also be set we want to offload both of those there is a way to do this called local checksum offload without requiring the device to actually compute a checksum twice uh next slide so receive checksum offload is also similar so we wanted a protocol agnostic way to do that what we do is we just have the device calculate the ones complement sum over the whole packet and it will return that sum to the host and then the host stack can take that sum and it can manipulate it such that it can derive the checksum over any bytes of the packet basically the way it does that is as it goes through the packet it will subtract to a once complement subtraction of the small check sum so for instance if we want to derive in this case the ic excuse me i see sum which is the checksum uh covering or actually udp checksum if we have the full checksum value from the beginning to the end of the packet what we do is we subtract out the ones complement sum of the ipv6 header and in this case there is a surplus area we subtract that out what's left is precisely the sum over the udp and udp payload and then"
  },
  {
    "startTime": "01:42:00",
    "text": "the host can use that to calculate the checksum so this did require the host to do a couple of checks on calculations but they're on the small portions of the packet not the big portion the next slide please so similarly uh to transmit we do want to be able to support um offloading of three checksums uh this kind of naturally works on the receive side because the algorithm they just described so we don't need any special support uh from the device all we need really is that that full uh checks on what we call checksum complete uh next way so i will touch on these briefly both the receive and the transmit one of the things we want to do is what's called gso tso and lro this is where we want to use larger packets from the stacks perspective and then when we're sending we want to break those uh packets into smaller mtu size packets for transmit and similarly on our receive we want to collect together some number of packets on a flow maybe make a super packet and get that to the stack we get a lot of advantages from this if we are able to process larger packets versus smaller packets so it reduces the per packet overhead if we can consolidate coalesce packets like this we also have to consider the checksum though when we're both sending and receiving so i don't have time to cover this today but there has been a lot of work in this area and in fact gso and tso and lro they become quite critical again for performance so we do want to maintain these and this is another area where the checksum becomes relevant because we still want to maintain uh the properties of the checksum in terms of performance and i believe that's all i have for today any questions thank you we'll take questions we had a few during"
  },
  {
    "startTime": "01:44:01",
    "text": "go ahead jonathan hmm more of an observation here uh the checksum delta technique is very useful for um for updating fields in the ip header for example that commonly get changed on root um such as the ecn field um there can be bugs in the these implementations and these results in certain packets that have been changed on boot having incorrect checksums while the rest are correct so it's a useful technique you just have to make sure you get it right otherwise you get um problems that might sometimes be hard to notice because they um an incorrect received check some looks like a dropped package which has the same effect on congestion control as a ce mark for example yes yes can i put myself in the queue and just ask a question tom does the set of changes which joe touch put into udp options since the last ietf meeting where we place the checksum in a particular place does that make it easier to the offload i how how do you feel about that new placement um the the stack will basically when it creates a packet it'll know where the checksum is um so that's it's not super critical for it to be in a fixed uh location however the device also may have constraints so for instance um it's very likely that a device when it wants to offload a checksum the start offset"
  },
  {
    "startTime": "01:46:02",
    "text": "and and both both of the offsets may need to be within the header of the packet so all these devices really assume that the checksum were offloading and the field are in the header because they may only have for instance a one byte offset field uh real estate in the transmit descriptor is um very costly so we can only get a few bytes for this so they may use a single byte typically we assume that the checksum is at a two byte alignment so a 256 of 256 values we can double that which means the checksum could be anywhere up to 500 and um i guess 10 bytes into the packet so having it at a fixed location isn't as relevant as having it make sure it's aligned to an offset of two bytes and try to keep it within the header of the packet so that the we can put it in um we can fit it into the device obviously software stacks um it's not so relevant um there may be some instances um particularly on some older systems where they don't really like to do unaligned operations so it's very basically like um i think all their currently defined protocols uh the checksum um start should always be two byte aligned uh to avoid any issues with unaligned operations yeah and i think that alignment is what's in the current draft okay so yeah i noticed it was uh one bite a line so i also point out there's a little bit of a misnomer that i see uh come up um particularly this is with uh in the context of udb encapsulation and in the context of udp options when someone sets the mix of checksum optional that is not necessarily saving"
  },
  {
    "startTime": "01:48:02",
    "text": "cycles or saving performance and in fact in some cases it can be worse and the reason for this is if you consider something like european encapsulation where rfc i think 69 35 and 6936 um basically allow uh checksum zero even in ipv6 where ipv6 uh basically states that checksum is always required um in certain circumstances particularly from a host point of view if someone sets the checksum to zero thinking that that's going to save cycles we may still have to compute the checksum because there's an embedded tcp packet and we're receiving this on say a host in a virtual network that has a number of vms so we still have to offload that tcp checksum so we're not really saving much there because we have to go through all the algorithms and as i pointed out we're still going to get the full checksum from the device anyway but the problem is in some of the legacy uh check some algorithms that i described if we set a checksum to zero and we still have to offload that in our tcp checksum this receiver may in fact have to go through the whole checksum calculation on the host which is really where performance drops significantly so i i think the the checks the checksum we've absorbed uh at least on the host and the host on the next stack there's very little value to disabling the checksum performance wise from a host perspective the only reason i think that that you would disable it is if the device like routers which was the motivation for disabling checks on ipv6 if they're communicating and they're terminating uh udp they may not have any any hardware to support checksum offload but right uh disabling the checksum is hardly ever an advantage from host's point of view it's more likely to be a disadvantaged"
  },
  {
    "startTime": "01:50:00",
    "text": "performance wise and the routers also presumably had the offset problem that they couldn't see deep into the packet payload when they were doing re-encapsulation right and and yeah so there's a obviously there's a lot of discussion on this uh but but i do want to stress this fact and i said it before um we've absorbed it uh the cost of the udp the tcp checksum right that's not a current problem we have uh the current problem we have is when new protocols are introduced how do we continue to leverage those and not accidentally introduce some sort of protocol combination where we're computing checksum checksums on the host and basically the performance is such that the the protocol the new protocol may not even be viable so this is where really the implementation becomes critical we have to consider the implementation in these new protocols thank you uh we'll move to joel's presentation now thank you thank you tom for for that oh and i'm going to be joe so just [Music] so uh gauri fairhouse proxying as joe touch on the udp options update um there's just five slides and the first one talks about core updates between version 13 and version 15. and the first one being the new option area structure which is why we allocated most of the time in tsvwg to the overview by tom on what what the ocs is doing which is to check some that's applied in udp options over the options area where it's placed and how it's aligned and this is now in the draft it's been in for a little while being revised so the text should now be good please look at this if that concerns you joel also integrated the unsafe kind and primarily"
  },
  {
    "startTime": "01:52:02",
    "text": "and the fragmentation text was updated request response was now required as an option in other words if you're implementing udp options we expect that function to be part of the implementation you provide next slide there are a few other updates um obviously nits we got quite a lot of feedback by the working group and in the working group feedback people noticed little inconsistencies numbers that didn't form a complete series numbers that were missing and a few places where we made clarifications about the format one of the things we did uh change in the more recent versions is to decide when the ocs field was optional the thing that tom was just talking about whether we should have an optional mode to ocs the conclusion come by joe reflecting the current revision is that the udp options checksum the rcs is only up is only zeroable when the udp checksum is zero this means that it doesn't affect not traversal and it means by default if you supply udp checksum then you must have an ocs checksum i think the other updates are fairly minor if you've been following this you'll have seen that these were introduced in version 15 and jules just pushed version 16 which corrects this and some other things so next slide this is to 16 specific limits on options corrected the table of contents corrected a lot of the terminology as you can see joe thinks this is now reaching maturity next slide and there are a few pending updates meaning that joe is going to produce a new version of the document"
  },
  {
    "startTime": "01:54:01",
    "text": "i'll happily take questions on from anyone who wants to ask questions and see if i can answer them otherwise we'll push them to joe does anybody have any questions on this draft tom go ahead so i asked this on the mailing list um [Music] what is this state of implementation uh do we have any information on that i think the question is really directed to joe and the working group in general um we implementation experience of the latest version i have not heard anything discussed on the mailing list please blink it there the general concept of udp options was that an earlier version of this was implemented tom jones will speak on dplp mtud and he did part of that implementation work it wasn't pushed to kernel it wasn't reflecting the latest version of this draft but it demonstrates perhaps that the thing might well be implementable um as in other areas we'd love an activity to implement this we'd love a hackathon activity to take and make something out of this implementation experiences would be welcome does that answer tomorrow do you want to follow up i mean at this excellent clashing toms that's good is that the last slide okay um i'm going to the working group chair position because i'll sit down i'll just announce that when we complete the revision of udp options that's coming we expect the document to be stable and at this point i've invited some"
  },
  {
    "startTime": "01:56:00",
    "text": "people to review this on behalf of tsvwg tommy paulie and colin perkins have agreed to look through the specification and see if they can see anything from a full read-through as this is our first stage of review this is a new transport protocol we've done this same procedure for dccp and sctp so we're going to get some independent reviews based on their output we expect a further revision and then a working group last call please provide comments and finally tom tom's going to talk about dplp mtud can i have the next slide please this is just our names um so we have the the dprp mqtt udp options document um it just provides additional text on top of udp options to explain how to integrate the requirements to implement dplpm2ds so the formats and a bit about how to send packets it's a really short document it'd be great if more people could read it um since the last revision we've aligned this with um joe's spec a lot of this alignment has just been minor updates and terminology and what things are called and so we changed probe token to nonce value because that's what the language joe went to we clarified that we can't send the two kinds of options more than once in each datagram and we've rewritten some of the text on probing with data to make it easier to follow uh it's a it's a small change it's a really small document um we don't have a ton to say right now and if we go to the next slide i think the most important questions there we think we're finished i know we're we're metered by uh udp options proper but we think we're done uh we'd love to get some more feedback from the working group uh i actually think this document could probably be almost wrapped up pending just minor changes from joe in terminology and language and udp options so what does the working group think are we done can we be done"
  },
  {
    "startTime": "01:58:09",
    "text": "anybody got any questions and you want to comment on this one go ahead chris yes uh mike heard um i've i read the document i didn't post any uh comments to the mailing list because i didn't have any it looks really good um the one question i'd have for you tom and gory uh would you envisage that uh the uh the dpf the dpo pmtud procedure could be implemented as a shim on top of the udp options rather than being integrated uh into it uh i asked that because that it make it that makes a difference in what we want to specify in the base spec for uh an upper layer uh interface i think that's something that hasn't really gotten sufficient uh attention and scrutiny thank you i am not really sure what the question is um i think you mean i mean so if we're using the the udp options to implement dpl pm2d then it's not really a shim [Music] i think the the service offered to the upper layer is reporting the discovered value turning on and off dplp m2d and maybe tweaking some of the parameters there's an sctp implementation of dplpm2d which is experimental which has um sort of five parameters to it so it's a really small service set uh i don't really know how you would shim this in it's not really a core part of udp options because it is protocol action rather than just the"
  },
  {
    "startTime": "02:00:00",
    "text": "wire format which is most of udp options um see i'm a bit maybe you could clarify first of time perhaps i'd better think it think it up and put the question in writing to you cool i guess the church action is um this document will be declared finished if nobody comes and says that more work is needed so please review please check it and if i hear nothing then we will ask the co-chairs to start a working group last call on this although we will probably keep that in synchronization with the udp options based pick it's 12 noon and we're at the end of the meeting unless anybody has a final statement i will say goodbye to you i will start saying goodbye now thank you ever so much for attending tsvwg we look forward to participation on the mailing list there is a side meeting occurring at 12 30 if you wish to join and look forward to seeing you in the email list perhaps in philadelphia bye-bye happy lunch time everyone flash"
  }
]
