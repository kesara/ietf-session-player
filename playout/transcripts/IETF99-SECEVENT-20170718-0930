[
  {
    "startTime": "00:00:04",
    "text": "and even Scotty over tottering say what [Laughter] oh you gotta get volunteers huh okay okay this is fine no it is morning shall we get we\u0027ve got a post there is people hiding behind the post that\u0027s okay they\u0027re not really paying attention to me so I\u0027m dick Hart we have our own chauffeur we\u0027re chairs of second events first slide of course is no well everyone wants to read over that so we\u0027ll start with some administration we need a minute taker and volunteers for a minute taker yeah so this is where we stop until we get a minute taker we actually do need one it\u0027s your first time in the working group people are supposed to say their name could it take minutes boss thank "
  },
  {
    "startTime": "00:03:10",
    "text": "you very much and we need the jet ascribe to channel people from the table room thank you and the blue sheets are going around everybody is a blue sheet moving around where is it now thanks Tony are you gonna let other people have it too so our focus we still have one working we have a single working group draft we have a couple of IDs that were we will have presentations are and that are at a higher level and we\u0027ve got some use case discussions going on and you\u0027re on drew this pretty picture which you want to talk about your picture so for people who are new to this working group and actually also for people who are not new it can be confusing we all the time we have a zoo of the internet drafts so this tries to put the stuff in order at the bottom we have the working group document the set format which is related to their job best common practices that were working on in parallel on top of that we have a single a set delivery over HTTP draft that will be presented today and then we have two ways to manage those HTTP streams one is with REST API and the other one is with scheme the REST API will be presented today scheme will not be present and presumably it\u0027s just using scheme at the top we have profiles which will be done by external identity management organizations stos and we have use cases and people will be presenting to use case documents today so that sort of covers a plan for the day which obviously is a very busy agenda so let\u0027s segues into doing some agenda bashing we of course are doing that right now then we\u0027ll have set token the token delivery the management API which is the REST API and then we\u0027ll go through the risk in scheme use cases any feedback on the agenda not I guess we can get "
  },
  {
    "startTime": "00:06:12",
    "text": "started with Mike figure out how to go on oh good morning all I\u0027m Mike Jones from Microsoft and one of the editors of the security event token specification I liked the airplane better deck okay Oh how do I make that fullscreen where\u0027s my there you go next so we currently have the third working group draft of the document the functionality has actually been stable for quite a while most of a year we bashed it out when it was still draft hunt ii vent and the edits since we last met together in person in chicago have been to address the issues that were discussed and raised there and have subsequently been discussed on the mailing list and i do thank people on the mailing list because there has been vigorous and i think well informed discussions so i think this has been a productive few months next so what have we done since ITF 98 those of you who are following the list know that most of the discussion has been about how to prevent confusion between security event tokens and other kinds of tokens that attackers might want you to confuse it with and in particular the open ID connect ID token received a lot of discussion and i\u0027m happy to report that we did develop a recommendation or practice to prevent confusion even if no ID token implementation is ever modified to know about the security of that token also as part of the preventing confusion discussion we worked out a way that had been discussed in fact in Chicago and on the list for explicitly typing the JSON web token which represents the security event token and that being using the "
  },
  {
    "startTime": "00:09:14",
    "text": "existing header name type typ which was already in the job and really those jason web signature spec for that very purpose so the new things in our draft are just to register the content type and to describe when and how you might want to use it also partly in response to some discussions that Marius had helped lead we put a note in the spec explicitly telling people using set spec that some types of events and profiles might choose to put subject information not at the top level as a jot claim but inside the event body in particular and this may be esoteric or to some of you but it matters to other use cases the ID token and I think some access tokens define what\u0027s being acted on in the ID token with two claims the issuer and the subject where we\u0027re naturally using the jaw issuer of the set to say who issued the set so if you also want to have a claim to represent an issuer that\u0027s the thing being acted on you would put that in the payload and we explicitly say that oh and if there\u0027s a subject related to that issuer you might just want to put that in the payload as well for consistency finally we added a new section on requirements for set profiles which is not actually new content because it\u0027s been widely discussed on the list for most of the time that we have had the mailing list even before the working group but it tries to write down as guidance so that people get it right when they\u0027re defining an event or a profile with a set of events not just that you have to define the syntax of how your event is represented which is kind of obvious but just as important it talks about needing to define the semantics and the validation rules for the data carried in the event and in particular one of the "
  },
  {
    "startTime": "00:12:16",
    "text": "most important pieces of semantics that any actionable profile is going to have to define is how to validate that the issuer of the jot controls the keys or key used to sign the jot indoor encrypted why does that matter and this is kind of crypto security 101 that if you don\u0027t know who controls the keys anybody could be doing the crypto operation including parties that you might not want to place a lot of trust in and so this is not a new set of requirements this is just writing down in the draft what any same profile is going to have to do to make it work and so that recipients of the set no both syntactically and semantically what they need to do to safely process it and use it next so drilling down on a point I mentioned on the previous slide the way that the draft now says that a set is to be distinguished from an ID token is by not including an expiration claim which is something that the previous draft already said it\u0027s not recommended now we\u0027re just saying if you\u0027re in a context where there could be ID tokens never do it is this a hack maybe but I mean my ass and others were good advocates of saying practical problems could result if existing systems with ID tokens are extended to ad sets and a set which is from a legitimate issuer could be captured by a malicious party and presented as if it were an ID token with mayhem possibly resulting the reason this works is it\u0027s required in the ID token validation rules to look at the expiration claim and so if it\u0027s not present any correct ID token processor is going to throw the result away because it\u0027s malformed all now following up on some previous discussion in Chicago and on the list that this is actually defense-in-depth because already in any normal context for an ID token it\u0027s impossible to confuse it "
  },
  {
    "startTime": "00:15:16",
    "text": "because the set wouldn\u0027t have a valid nonce claim with the correct value which is also necessary for the ID token to be accepted but you know now we\u0027ve got two ways both of them are fully effective that should do it for the short-term next and we also added the ability to do explicit typing that\u0027s something that among others are two chairs in a different role and I had worked on this preliminary jot BCP which Kathleen had asked us to do apparently because of the discussions in the set working group and some related discussions in OAuth and while the BCP does talk about confusion there\u0027s a gob of other stuff in the BCP talking about ways that people might implement things wrong ways that people might fail to do checks so that\u0027ll be discussed in the Roth working group later today but we invite you to read that the reason I bring that up now is the explicit typing is something that\u0027s in the draft jot BCP and the first use of that is in the set spec at this point next so as I said in my introduction the functionality both syntax and semantics have been stable for most of a year I believe that the draft does and already has met the needs of all the known use cases that have been discussed the possible issues with the previous draft have been vigorously discussed with the results being incorporated into the current working group draft and while I have a half hour this is the end of my deck I\u0027ll just say that now I think the right discussion to have or any other discussions that people want to have at the mic is is it time for working group last call I\u0027ll note that after this draft was published that addressed the known open issues that about a half dozen people spoke up on the lists and said yeah it\u0027s time and I personally concur it\u0027s time to get this done because it already works and it\u0027s already in use thank you yeah questions "
  },
  {
    "startTime": "00:18:26",
    "text": "good morning smiley scooter school so there\u0027s a couple of issues so let\u0027s start with the easier one was a discussion on one of the email threads about explicitly identifying the profile in a set because it\u0027s sort of implicitly identified by the event types well it is explicitly identified by the event type that gosh sure so you can have multiple events now if the set is not if the set is mixing events from different profiles which it shouldn\u0027t but it could right then a parcel it might be not deterministic because it depends which type it picks up to check the profile also it\u0027s not clear how do you map map the type URI to a profile so those things are I think there are concerns I think it would be much better to explicitly identify the the profile so I just want to raise this as an issue and the fact that there was a discussion around that so and there\u0027s a couple more things but this is the first one okay and that\u0027s something we could describe in the draft more explicitly I will say that there\u0027s profiles for which there\u0027s only ever going to be one event and so adding extra data is just superfluous rhythms use case well there\u0027s no fuss we look so far maybe there might be but most profiles will have multi pretty but I agree many profiles will have multiple events and I think rather than having duplication of semantic information what I would recommend is for a profile that wants to have a gob of events that it come up with a naming convention where there\u0027s a prefix on the event name so for instance the risk working group I know in open ID has discussed having a prefix something like schema static open ID dotnet slash events slash risk and then the event names and so for a profile that you wanted to do profile identification it\u0027s easy to do that with prefix matching without needing duplicate information one of the problems I have is a protocol designer with adding redundant information is it introduces the possibility of an inconsistency that was previously impossible what if for instance a malicious or just badly written party was to use the event URI and then say this is in a profile but one that\u0027s not related to that event URI "
  },
  {
    "startTime": "00:21:29",
    "text": "because you have this duplication of content there is an inconsistency and error processing code that you\u0027re gonna have to have whereas if you only have one an unambiguous way to determine the information you\u0027ve designed the possibility of those mismatched errors out of the system you\u0027re in so I\u0027d much rather do that I think you have the mismatch problem anyhow right because you can have multiple events in a set and technically the URIs could come from different profiles so this mismatch issue is there to begin with the prefix that you suggest it\u0027s practically the profile identifier right so maybe one solution is to ask each profile when did they define your eyes to have a common prefix I\u0027m not sure but I think is something we need to try we we could describe that in the draft if people are interested right but I think\u0027s also considering adding a top-level claim describing their profile it\u0027s a valid requirement so we should discuss that as well again adding the top-level claim I think introduces the mismatch possibility that\u0027s currently impossible it\u0027s possible we have mismatch possibility the draft I think I know what you\u0027re saying the draft already says that if you have multiple events in the set that they must be from the same so compatible no from a compatible set of events using common you know syntax and semantic conventions listen whether you call that one profile or whether it\u0027s a set of profiles all adapting the adopting the same conventions is sort of semantics but practically we normatively say that you must not mix events for which they\u0027re representations are not compatible okay so yes you could still violate that but we already have normative text saying you can\u0027t do that sure you could have no motifs text saying that the profile identify should match the URLs like it\u0027s the same thing right well the other thing is uh not sure how how is solving the key resolution issue because I think profiles have to define how the key is resolved right that\u0027s right on which case in which case because there is only one signature we do have only one profile per set it\u0027s a hard requirement there is no way around that one issue are per set but it should be only one profile too because it should be one way to resolve the key right again I\u0027m gonna quibble with wording because semantics matter like that they all have to use the same means of resolving the key that "
  },
  {
    "startTime": "00:24:30",
    "text": "doesn\u0027t mean they\u0027re from the same profile it means that they\u0027re sharing the structure of the list of the set Jori I say this because I think there\u0027s going to be some identity related sets that you know some are from risks some are from other working groups some might be from other identity contexts but all of them might for instance do the key resolution in the same way that an ID connect does where you look up from the issuer a place to get the jwk set and in fact that\u0027s not just open ID Connect now that\u0027s also specified in the oweth metadata document right so part of why I wrote down the requirements for profile writers is to capture things like that very point and I call out that determining key ownership is one of the most important semantic things that you have to say how to do that said there\u0027s going to be profiles that do it in completely unrelated ways just like jaw is now used in some non identity contexts including for caller ID for sip calls and whatnot which I only learned about because I happen to be one of the designated experts and they registered the claims and Shawn Turner and I talked about it and I said okay that looks great but their key management is completely different which is fine and so sets from that world or from worlds that may not yet exist can and probably will do key resolution in their own ways I just want to note one concern consequence here which I think we have to live with is the fact that we won\u0027t be able to write a generic set parser and validator without having intimate knowledge of profile without having what intimate knowledge of profiles because that\u0027s actually going to be that\u0027s always correct because you must implement the validation rules and the processing rules defined by the event to correctly use the event so I think anything that tries to be a generic parser can be written but what it will actually be is a big case statement that you know may share a bunch of branches for stuff in the same profile but you have to know what you\u0027re processing there\u0027s there\u0027s no sense in which you can generically an event or for that matter a jot without knowing the the rules syntactically and semantically for how that application uses it your own chauffeurs participant so so I\u0027m a little bit confused because what I had "
  },
  {
    "startTime": "00:27:33",
    "text": "the model I had in mind for a recipient was to have one big dispatcher that would be able to do some initial work on each and every set including validating signatures and then dispatch it to the different profile plug-ins for for lack of a better word so is it only my my personal model do people not share it I think that there will be use cases such as the risk one where you have a whole bunch of different events processed by a common recipient endpoint but it still is the case even for recipients that are intended to process many kinds of jots as a baseline they have to understand the conventions for securely and correctly retrieving the keys that\u0027s explicitly outside the scope of what a jot does it\u0027s explicitly outside the scope of what a set does and so to write that general purpose processor you have to build in knowledge of the key management regimes for all the sets that you intend to process otherwise you have no security and you don\u0027t know how to get the keys right so I think a lot of us maybe without realizing we have assumptions only route open ID Connect use cases which simplifies things but if we if you don\u0027t have that assumption then many things don\u0027t know as a practical measure I would encourage people in the identity world to write a set profile which describes the things that are going to be common for our digital identities such as how to retrieve keys and you\u0027re at the JSON based world so awesome so abet I don\u0027t think that belongs here that\u0027s part of a common profile that might be used by a bunch of identity use cases right I don\u0027t even think that just because you\u0027re doing connected you\u0027re gonna have the same key management scheme yeah we\u0027re looking at like full mesh key management schemes based on like expect explicit sort of signed signed bags of keys use cases which will certainly not fit into the download your key from from HTTPS so I I don\u0027t even think that you will be able to do a common profile just because you\u0027re doing connect FairPoint let me expand on that just using a little personal knowledge I have of this talking with Roland Hedberg in Sweden has been very involved in "
  },
  {
    "startTime": "00:30:34",
    "text": "academic Federation\u0027s in the saml world and now connect one of the things that they\u0027re doing with this open ID large-scale Federation draft is defining ways to manage the keys where you\u0027re not necessarily dependent upon the web PKI for the security of them where the jwk set thing is explicitly counting on the security guarantees provided by web PKI so life is actually raising a great point that there\u0027s people who want different ways to do key management even in identity context sure but you could still have like you could have a common profile which defines one way and then wait and I encourage yes people to write that down right but you can\u0027t assume that just because it says connected that you will do the same key management I think that was the point are Michaels making right key management is a is a thing that varies even within profiles I\u0027m not sure I understood the lasting key management varies within profiles so which work prefers it so if you if you\u0027re doing if you\u0027re doing connectors this thing called um is a mobile connector I think the TSN a yes made mobile connected my understand is that they do key management in slightly different ways then then like this what is sort of the the the received way of doing key management if you\u0027re reading the connect specs right so it might be you might be tempted to write a connect profile for Sept key validation that just sort of looks at the specs and do what what your what your sort of said what is suggested that from from those pegs on the core specs but that would certainly not cover a number of use cases that could still claim to be doing open early connect open early connect is simply too too broad to include a unique key management it\u0027s become a big world out there sure no no I hear you but you could still write a base open ID connect profile and then you might need other ones for that do things differently right well if honestly yeah you could do a connect profile that validates the content of the the this the set token right but you you wouldn\u0027t be able to figure out how to validate its authenticity okay maybe we disagree here but so my main concern so the second thing I wanted to raise is that most of the use cases that I\u0027ve seen so far come from the identity space right what people are trying to survive in a wedge space "
  },
  {
    "startTime": "00:33:34",
    "text": "identity space right and basically we\u0027re writing a draft which requires all of them to undo some things and do them differently so from the get-go we are writing a draft which is not going to work for basically everybody who showed up to do something that can I can finish okay and the thing which is not working I\u0027m not talking about the the the the second issue I\u0027m raising is the top level single issuer and sad right so for basically most identity use cases that\u0027s not going to work and one of the solutions as you suggested is to push the subject down to the event level there were other proposals to push it to some other nested level another solution I was proposed is to use two different issuer top-level claims one for the set one for the to give context to the subject but basically we\u0027re creating a draft which from the beginning is not going to work for most of the use cases that people are the big right now are trying to solve right so I can see two solutions as you said maybe we have to write a common profile for identity use cases to cover key management to cover how the subject is treated and maybe it has a solution or maybe we have to make it flexible enough so we don\u0027t contradict all these use cases from the beginning I think it is flexible enough now I take exception to your language and it\u0027s probably just wording saying we\u0027re writing something that\u0027s not going to work it\u0027s not going to work until the event definitions write down where their claims are and how to validate them and that\u0027s true of all claims it\u0027s not just true of issue or subject it\u0027s true of every claim and data value in the event so there\u0027s nothing you know special about subject other than in the particular case the case is derived from ID tokens subject is paired with issuer and if you\u0027re going to have an issue or a connect like issuer in a set you would put it in the event body which we\u0027ve already said I think a lot of the sort of angst that I\u0027ve heard on the list and I\u0027m hearing here will be solved if we write down sort of the one page this is what connect identity sets that are using the JW KS URI key management discipline sure would do and I\u0027d be glad offline to like write a first draft of that with you I don\u0027t know where it goes I don\u0027t know that it goes here it might go in the connect working group it might "
  },
  {
    "startTime": "00:36:36",
    "text": "go in the risk working group and we could set that later but I think the parameters of how to do that are pretty well understood and I suspect that risk already actually has them written down probably by you so okay so let me rephrase that because here is my concern we write a draft which says that we have only sure and one subject at a top level and every profile that I\u0027m aware of will have to override that and say no subject is not at the top level it\u0027s in this other place right and we are at the beginning when we write such a draft that is not naturally like solving the use cases for all the the profiles that we are interested in at the beginning to me that that says okay we\u0027re not doing something right there that that\u0027s that\u0027s what I\u0027m trying to say I hear you let me give an analogy which again it\u0027s been discussed on the list but it\u0027s probably worth talking about here as well John took an intentionally very light hand about what\u0027s required we to find how to do the cryptography and how to represent claims but there are no required claims in a valid judge that means that of course you\u0027re going to have to have a profile to understand what claims are present and how to use them this is a good thing that\u0027s why it was possible for for instance the caller-id people and the sit people to define their own claims and their own key management to use jots in a way that\u0027s pretty different than an ID token if we you know the same people wrote jawed says route ID tokens we could have just said well all shots are going to pretty much be ID tokens and make a bunch of rules in but if we did that we would never have gotten that unanticipated uses in completely different application domains and I want us to also be able to get these unanticipated use cases from people that you know we\u0027ve never heard of using sets because they\u0027ve got the flexibility to likewise match the claims to their needs so don\u0027t let other people interact here and you guys are talking past each other you know I think Mike you\u0027re making a valid point which is we don\u0027t want to be overly specific in the token specification but I don\u0027t think that was the point that Marius was making which is that he thinks if what is specified is something that other profiles would need to change Marius I think would be useful if you as opposed to making those sort of general positions of saying that it doesn\u0027t seem like it\u0027s useful the way it is would be for you to like call it "
  },
  {
    "startTime": "00:39:36",
    "text": "exact you know precise use cases where you think that the profile will need your override what is in the spec so it\u0027s clear to that and I\u0027m curious if anybody else feels similar to Ameri us about that I don\u0027t think it\u0027s over right I just think it\u0027s sad I\u0027m using Maris\u0027s words which overriding it William Dennis say I was actually an ask a clarifying question of that I don\u0027t understand why the the profile would actually to override it because the way I understand how John works is that you don\u0027t have to include the claim and the event kind of market of claims lets you put whatever you want in there so to me it seems like if a profile wants to define something they can don\u0027t really have to undo anything all override anything so well I think what Marius is saying is that those things that are specified as required and set that profiles would not want to use if I\u0027m in my phrasing that correctly means we require some no this is that that\u0027s not required well the subject sorry the subject is not required you can use it or not if it\u0027s just like any other claims committed but not required so that\u0027s why I don\u0027t understand why it is be overridden it\u0027s just that you\u0027re just opting not to do something that is optional so that\u0027s your right to do and then your option to add something which is also your right to do in the in the event there anything required in a set events yes there\u0027s the issuer an audience and some time related parameters um the second kind of finishing I wanted to make is that Marie she said that that there were no specs that currently defined the top level sub no profiles but there actually is a profile is the only connect all the aspect that that is using that so I don\u0027t agree that that no one is doing that okay so maybe override is not the right word but basically you write a spec where you say issue is here subject optional is not it it\u0027s here right and now maybe not to logout but pretty much all the other profiles will have to say oh actually no subject is not there it\u0027s over here okay so technically you can argue it\u0027s not an override maybe but for somebody reading these things right like it\u0027s an override basic saying no it\u0027s not here it\u0027s over there and it\u0027s not like saying that everybody can define their own claims these people are not defining new claims they are just repositioning an existing claim which is a different thing right and yes logout might be fine with it at the top level might be I\u0027m not convinced that for all use cases that we work actually but many other profiles will not just not gonna work for them see if I understand but I think I think this is you know what I would do if I were to define full mesh key management for a pro I would take the Kinect profile and say you know ignore everything that it "
  },
  {
    "startTime": "00:42:36",
    "text": "says about key management and key validation and just do this instead right so I don\u0027t think it\u0027s necessarily that far from what I hear you wanted to do MERIS window so I guess if someone is implementing like risk is that a problem if they\u0027re just reading the risk spec I go and I don\u0027t quite see that as a bad thing I just like if that was your reference document and it tells you how to do it so anyway I\u0027d like to make a general comment I think it\u0027s slightly to this so as one of the co-authors I just want to kind of highlight one of the reasons that we actually wrote this spec almost two years ago one and a half years ago and that was that I think when you\u0027re using jot you need to ensure that all your use cases are mutually unintelligible with the same issuer so I so job provides you know you can you can partition on the issuer but if you don\u0027t you have to make sure like every particular type of job is mutually unintelligible and I think we achieve that here with event and I think the real value of this spec is then allowing all of those subclasses of event like risk and like log out to kind of coexist with ie tokens and I think that\u0027s a valuable achievement I think it\u0027s also a reason to get this done soon because if if we kind of dally around too long then all those people that are thinking of profiling this may just move on and profile themselves and then we lose that benefit of kind of having this world where you can have you can have an issuer that only knows about a tokens and events and is happy that that that\u0027s a secure and safe environment so that\u0027s that\u0027s kind of the value of doing it this way um just want to make that point decorative participant so one of the values of a framework would be to enable implementations to people to implement and do some piece of code that\u0027s going to be common that other people can reuse right so we\u0027ve got that for jots the idea first set would be there would be another layer that we\u0027d go and do some things to require too common there i worry a bit if there\u0027s a bunch of things that are optional and if they\u0027re in different places that then you can\u0027t have a common implementation that does all of that so people don\u0027t have to worry about that I also have a concern with methodology aren\u0027t signalling which profile a particular set is for and in you know as I\u0027ve participated in some of the profiles at a higher level it seems that at times you could have messages for different profiles potentially mixed into some of the same place and so I think it\u0027s key to have a clear way of knowing which profile particular set is with and I think parsing the start of a of a event in some sort of hand-wavy way of saying how you figure that out is not nearly as robust as a clear signal of which profile is set belongs to him potentially as opposed to having the type field be first set the type field could be for a particular profile of set "
  },
  {
    "startTime": "00:45:37",
    "text": "and so that you\u0027ve got a clear signal at the type level as opposed to you in the event and that way the event is really orthogonal to the profile which would allow different profiles to use the same type of event type but responding to that particular point which I\u0027ve thought about since you talked about it with me in person yesterday the problem with that is if people like like the risk people or others want to have a common processor you actually want them to have a common type otherwise they\u0027ll be using the type and rejecting things that they actually want to include if they want a processor so it\u0027s going to consume more than one profile and they can see is it one of those two profiles that seems fairly straightforward right this hospital nice nice easy string compare and I\u0027ll note well I thought I would go under time the discussion has now taken us over first so if you want to time manage this but we thought it was useful discussions continue on okay now just one more clarification I\u0027m not sure if I it was understood where I was trying to see yes it\u0027s okay for a profile to override where sub is it might not be an override maybe specification I understand that if there was only one profile doing this I think it was fine and maybe it\u0027s gonna be end up ruining one profile my suspicion is there\u0027s gonna be lots of profiles which will have to do the same thing that\u0027s that\u0027s the only thing about having lots of profiles to me as a sign that we did it right well in Dennis second but sub is also defined a job right so in any case your quote overriding job but we know we have profiles that need it so like like logout is using I think conceptually though it makes sense um if I didn\u0027t hear more as he was saying that logout he\u0027s doing it that way but doesn\u0027t have to but but I didn\u0027t see the Pythian conceptually it\u0027s you it\u0027s using jot the way jot was defined it\u0027s using sub the way sub was defined in drop which to me makes sense yeah having a discussion cross the rooms not can be productive for people that aren\u0027t here I\u0027m sorry so how many people in the room can get a show of hands everyone looking at their laptop pay attention who all\u0027s had a chance to read and review this fact "
  },
  {
    "startTime": "00:48:39",
    "text": "okay if you can\u0027t see me I can\u0027t see you okay so about Tanit looked like beeps sorry lift your hands again now we know is that kind of half a hand it\u0027s about nine yeah yeah yeah yeah we\u0027re kind of wondering we\u0027re kind of on the edges whether we\u0027re ready to do last call on this or not be useful if there\u0027s more people that had sort of read it to get more feedback and so can I make us so yes you know so it sounded to me on the discussion there that\u0027s some of them sort of bigger push back is sort of on the the overall aims of an architecture of the document I mean it whether you\u0027re gonna focus on the profiles or not right and if if that\u0027s the kind of pushback that you\u0027re saying maybe it would be better just sort of ask for more that\u0027s not us that\u0027s not detailed edits right that\u0027s not you know give me text right that\u0027s a complete rewrite that\u0027s a refocus of the drafts if you\u0027re gonna do that right and I think if you\u0027re gonna do if you\u0027re if you\u0027re seeing that kind of pushback I think that shouldn\u0027t come with text that should come with a separate draft I think if you\u0027re if you\u0027re in the camp that thinks we shouldn\u0027t be have to rely on profiles as much no those people should actually produce a separate draft because I think that\u0027s a major rewrite that wasn\u0027t what now that wasn\u0027t the conclusion I had but I would agree we had a statement but I don\u0027t write but I don\u0027t think it I don\u0027t think necessarily you have that much pushback but if if you sort of have that kind of pushback I think that\u0027s a major rewrite to the draft like this and it that does that it doesn\u0027t really help you whether you go to last call on this draft or not right you\u0027re gonna have to do somebody has that kind of feedback you know go and write two separate draft and then we can talk about it I think what agreed if this isn\u0027t solving somebody\u0027s problem then potentially there needs to be something else that solves a problem this is the wrong tool for the job yes Kathleen Moriarty area director so I think once you make the decisions you know what they are already ten reviewers is fine it\u0027s all I wanted to say so I don\u0027t think you need many more people but ten is fine in terms of what I see across other working groups okay as long as they actually review and and it provides a feedback so for me it was it was clear from the get-go that we will need profiles that we will be relying on profiles to fill in details for each and "
  },
  {
    "startTime": "00:51:41",
    "text": "every use case so so at least what I\u0027m hearing from the from the mailing list and from this discussion is that there are some points missing but not at the level of complete we architecture well we got us one one can we just on the timing I think we\u0027ve sort of been going around for a while the drafts been pretty stable I think for a while and it has means to these lingering questions I don\u0027t want to see that uncertainty persist for years and us never getting complete so I think if the decision is today not to do a working group last call I\u0027d really like to see a decision on what the plan is to get there because if we just punted another four months I just don\u0027t think I think we\u0027ll be back back here arguing about the same points again and we\u0027ll have the same indecision and in fact indecision is used as the reason not to go working group last call will just opechee having a decision well I on the plus side weren\u0027t talking about completely different things in the last meeting the core thing I\u0027m I see is sort of the signaling are in which profile the set is aren\u0027t and there seems to be some discussion on that I sort of of what I\u0027ve captures being the outside thing I\u0027m clear on Mario\u0027s points as to how those are not something specified at the profile level versus in the set level but when we get a consensus in the room what do you want to do I will be asking two questions whether we do want to go for working group last goal or not whoever is in favor of working group last call on this graph please hum if you are opposed to working with last call at this time on this graph please hum that\u0027s kind of clear thank you okay I just give us a thumbs up yeah so we\u0027ll run that over the list those were the two I think yes okay thank you Mike and next up we have Marius Arne and thank you again all for the vigorous discussion on the list it\u0027s been really helpful to refine stuff and we are 15 minutes behind right son - go to school we\u0027ll be talking about delivery of sets so we\u0027re "
  },
  {
    "startTime": "00:54:41",
    "text": "going to the result we have a draft which looks at two ways to deliver sets one is push initiated by the transmitter and a pole initiated by a receiver and also defines a verification process for for events themes I have some definitions I\u0027m going to skip through them if we need them we can talk about them during them later on the other slides so the event delivery down there all right thank you so first of all the way the sets are defined and how the streams are assigned to sets is out of Scotford for this draft the event receiver has to register with the transmitter delivery mechanism and that\u0027s how they are delivered in the stream there are two define one is push as I mentioned an HTTP POST to an endpoint defined by the event receiver and Paul where the transmitter is cueing the events up in a buffer and then the receiver is doing a periodic pole to retrieve them and also has to be noted that other methods of delivery can be defined outside of this draft another important note is that the event receiver has to acknowledge receipt of the of the events and a transmitter is not required to store the events after they have been acknowledged so the first mock metal is the push delivering it\u0027s a very simple HTTP POST to a configured endpoint we have the content type the accept header to the response content type it\u0027s important no there\u0027s only one set per per push per request the defined HTTP status code 202 it\u0027s also the acknowledgement that set was received and in case of an error there are other HTTP status codes to signal that he is a very simple request example and then there are two response examples a success one which is trivial and an error response which is a JSON blob also important is the 400 status code in this case and then the JSON blob with two fields there and description and these are defined in enough slide further than the other delivery method is appalling so the receiver is to English deep opposed to both acknowledge and get more sets and this to an endpoint which is defined by the transmitter you ever "
  },
  {
    "startTime": "00:57:41",
    "text": "defined the content type pot request response a JSON in this case multiple sets can be streamed at once as opposed to only one and also in the request there are some polling parameters we are going to look at so there are two so these are the request attributes so there are some processing parameters max events and return immediately max event zero means that the receiver is only acknowledging sets received in a previous request and it\u0027s not requesting new sets and return immediately allows for long pole and also the request can have two arrays and AK array which specifies Olga says the heavy success will receive and then a set errors which is another array which defines all the sets that had errors and then there is a nested JSON object they are describing the error which each other says the response has a bigger set which contains all the new sets that are to be delivered to the receiver and then there is a boolean flag signaling that there more are available playing with the request attributes the receiver can have work I know variations on how it\u0027s polling so it can pull only so that means it just request new add new sets and it\u0027s not acknowledging anything it can acknowledge only or have a combination of both and here is an example of a combine request where it acknowledges some of the previous ones seen on some errors and it\u0027s asking for Ron Paul and the response it\u0027s sending the list of new cells these are the error codes split and split into pages next page yeah also the draft defines a way to verify events basically the receiver can trigger to the control plane which is outside of out of scope for this day but it can request the transmitter to send the verification certification message and in that request he can specify both to confirm an announced value and as a response to that because the transmitter will deliver a verification event and here is an example the URI for this event app has to be defined but it\u0027s a very simple event it has nested "
  },
  {
    "startTime": "01:00:42",
    "text": "attributes for the confirm announced as they were sent by the receiver just a few knows the Chicago I think it was mentioned it\u0027s important to specify authentication authorization and it\u0027s just standard methods used by ATT HTTP and some examples are given but it\u0027s up to the transmitter and receiver to the transmitter probably - for the transmitter to document which authentication authorization minutes using and the client the receiver to support that so can I ask a question on the error sure so duplicate is an error but it also says it has been ignored so why even make it an error that\u0027s a good point I don\u0027t know maybe just a signal to the yeah I\u0027m not sure III would doesn\u0027t matter I mean if you\u0027re doing if if they\u0027re if the sender is duplicating stuff and you don\u0027t care right why even that I mean you could you could have a another class of feedback saying you know hey you notification or something a informative message or something right but but if it\u0027s just a convenience log it and let the suicide and figure out why are you sending duplicates but you don\u0027t have to sort of throw your error on the client-side on the other side I think yes we can look into it I don\u0027t know like it\u0027s it gets interesting because the the transmitter has to keep events queued up until they are acknowledged if you keep ignoring them and they keep sending them then maybe you should send an error here it\u0027s useless to keep sending them to me because absolutely but if I\u0027m if I\u0027m sending them twice it\u0027s because I didn\u0027t sort of get their ACK right possibly unless I have a serious bug in my code right right but you know I can figure that out from logs too I guess fair enough I think debugging should be out of scope fair enough ok yeah I think so I have questions so two quick questions you said in passing that you say who you are please Iran Shaffer you said in passing that you can say send multiple events at the same time with the poll facility but not with push why is that why is that because you know push you can signal that you can act easily with an HTTP status code if you send multiple at once then you cannot rely on the start HTTP status code anymore you need to send back a JSON blob and it complicates the the way the the acknowledgement work and for example for a server sending for a "
  },
  {
    "startTime": "01:03:44",
    "text": "transmitter sending pushing events the way they do monitoring and alerts is going to be affected because they cannot rely on HTTP status codes anymore it gets way more complicated if I have a good a reasonably good the network and I\u0027m just concatenating ten JSON structures into one body one HTTP body and just send the whole thing why wouldn\u0027t it work I\u0027m nothing he\u0027s gonna not gonna work the problem is we had this discussion on the mailing list the the transmittal will have a harder time to do monitoring and alerts in this case right because if you if you keep pushing individual sets then you can have your alerts and monitoring based on HTTP status codes if you have multiple in one payload then you cannot rely on the status code anymore you need to be able to parse the JSON and extract multiple error levels from a lower level right it gets more complicated okay but the question behind the question is we\u0027re moving the complexity into this whole whole thing right which I think it\u0027s is much more complex than we could have done with just using push with post so the the the the need for a poll is because there are receivers were before behind a firewall and they cannot be contacted with HTTP right so they need to reach out the transmitter cannot reach to the receiver in that case so there are use cases which require poor push is not gonna work for them okay actually the firewall thing is not very convincing to me because you are expecting to receive events from the outside so you should be able to set up an external IP but well that that was a motivator some people had a use case where they the receiver was not yes okay yeah all right maybe the document could call that out more clearly why Paul exists in it that\u0027s a good point okay Annabella Beckman the few questions we have and comments building on the earlier comment about the duplicate error code it\u0027s not clear to me what we\u0027re expecting a transmitter to do in response to these error messages are the the error codes that is receiving from the receiver looking through them most of not all of them like the sort of errors that are not going to be remedied through some alternative code path at best the transmitter is going to resend the event which is going to result in the same error that the only other alternative really is for them to log it pipe it into a messaging or a error logging "
  },
  {
    "startTime": "01:06:44",
    "text": "system something like that I\u0027m not sure how valuable that is versus alternative existing out-of-band troubleshooting in essence right fair enough so from practical experience I think yeah I think logging is the only saying the thing that the transmitter can do at that point but having a detail of what went wrong from the receivers point of view it\u0027s very valuable later when you do troubleshooting I think would be helpful to in the spec make clear what the expectations are what expectations are a seer should have about what a transmitter is gonna do in response to these error messages should make sure the implementers have a reasonable expectation of what the behavior is gonna be at when they implement that there are other errors will retry might actually work there might be some overlap when a key rotation is done and for a while it may not verify the signatures and then starts working again I don\u0027t know but there sure yes the other question I had is we have the pull and push mechanisms defined are in the same draft if I understand correctly the expectation is that an implement a transmitter would implement both in all cases is that correct maybe it\u0027s not spelled out explicitly we would have to check that I think the expectation is a transmitter implements boat and then receivers what whichever works for them is it necessary to do that do we need to hold them together like that to be compliant you need implement both or can you decide which one you want to implement or choose between something we have to discuss I think it came up before and the conclusion was the trust or so further we say the transmitter will have to implement both to be compliant but and it maybe we shouldn\u0027t go there the pull mechanism it involves a lot more complexity on the part of the transmitter which may not it may not be worthwhile if in a particular use case there are not going to be any clients III could be wrong I\u0027ll have to double-check maybe right now the brass dimensions that it\u0027s on a similar note the more available per response parameter it also adds complexity on the transmitter side I don\u0027t see the value of it given that a client is a receiver is always going to have to handle the possibility that they make a request and there are no events returned i kind of agree the only case where it\u0027s kind of useful is if the receiver let\u0027s say paused every five minutes but if it\u0027s more available stays in the loop until exhausts all the events but yeah the "
  },
  {
    "startTime": "01:09:44",
    "text": "receiver could do the same thing it can pull until you sees nothing and then waits for a minute so I agree yeah okay that\u0027s it thank you Tony nedelin we have definitely used cases for polling only and so we would definitely like to see it as two separate things all right we don\u0027t have to implement poll we don\u0027t have use cases for poll very much make sense so two separate ones means splitting in two drafts or the drafts should specify that one by one or the other I don\u0027t want to see him I don\u0027t want to see the draft split right I\u0027d rather see it as one but this just be up either one be an option but you have to employ one of them straight well the point is not to save our time with the specification the point is to have an interoperable draft and in my opinion if we split it in two we\u0027re not going to have an interoperable draft so if we say that the optional for both senders and receivers we\u0027re not going to have interoperable implementations so it\u0027s an issue for me why because we will have some that only do this one and some that only do this one and they will not interoperate with the other guys okay thank you so given that this is on our Charter and most of this has been around already and we just cut it out and massaged it we would like to to call for working group adoption of this draft so we will we will have a ham on that I will ask Kathleen acoustic thank you so I would ask for yes some and no harm people who are in favor of adopting the HTTP delivery draft as a working group document please hum now people who think we should not be adopting this as a working group document please hum okay we\u0027re adopting the draft Thank You miles [Laughter] all right Thank You Marius next up we have Annabelle "
  },
  {
    "startTime": "01:12:51",
    "text": "oh right do we have sites think we have slides cool okay hey good morning I\u0027m Annabelle back men I\u0027m going to be talking about the other side of the set space that is the management a simple management API for events treatments excuse me event streams specifically what we\u0027re talking about here is codifying the way that receivers can manage this stream of events that they\u0027re receiving from a transmitter we and discussions have identified four specific operations that receivers are going to need to perform those are what the spec is currently focusing on you can see them listed there we have querying the status of a stream adding subjects to a stream removing subjects and requesting verification the other side of the verification event that Marius mentioned in his draft to be clear when we\u0027re talking about adding subjects and removing subjects what were or talking about there is a receiver indicating to a transmitter that this particular subject is one they are interested in receiving events about or not interested in receiving events about what we are not focusing on in this draft is anything relating to registration of the receiver itself with the transmitter any of the credential management key resolution kind of problems that that Mike discussed things of that nature next slide the the big key here is we realize that these profiles are going to be implemented not in a vacuum they\u0027re going to be implemented alongside existing mechanisms or existing protocols like skim open ID connect that already define ways to do a lot of this stuff registration authentication identification of clients we can\u0027t reinvent that at the set level and expect people to follow that so we ultimately need to leave a lot of that up to the implementing profiles to define next so briefly we\u0027ve thrown out the term set event streams a few times just to be get everyone on the same page we\u0027re talking about a relationship between a transmitter and a receiver or there\u0027s a flow of events from the transmitter to the receiver over some delivery method such as the ones that Maya\u0027s just presented that\u0027s a quick comment there this both the word feed and stream are being sort of bandied about in various drafts it might "
  },
  {
    "startTime": "01:15:52",
    "text": "be good to harmonize the terminology I like stream better agreed I think there\u0027s there\u0027s been a lot of back-and-forth in the past on terminology here I think there\u0027s starting to be a consensus around streams but there are likely places and drafts that have not been updated to use that terminology well to be clear that feeds and streams were actually different but that was confusing because people thought they were the same thing at the other thing to note about event streams as a relate to the management API according to this spec we\u0027re saying that there is one event stream between a given receiver and a transmitter next the other one object that or one entity that the specification has to define for us is something called subject identify our object this gets to some of the earlier discussions of the various ways that subjects need to be identified by different profiles in open ID connect logout they are going to be defining subjects using issuer and sub in risk we might be using that an event might be using a phone number and email address other profiles could be doing all sorts of things so if the management API is going to be dealing in adding and removing subjects we need to define ways to say what are those subjects how do we how do we know who we who that subject is so what we\u0027re we\u0027re saying here is we have a subject identifier object that is a JSON object considering containing a set of claims that uniquely identifies a subject and that profiling specs are going to define for us so if risk wants issuer and sub as a subject or phone number or email as subjects then the risk profile would would define those as different subject identifier objects for use with the management API next step add some kind of clarify what I\u0027m talking about here you\u0027re a couple of examples that you might see from risk events so talk about the actual API the transmitter implements an HTTP set of HTTP endpoints that the receiver calls again these are event stream management which is the query endpoint ad subject remove subject and request verification the spec states that these are independent URLs they may be the same URLs for multiple streams or a "
  },
  {
    "startTime": "01:18:53",
    "text": "transmitter may define separate endpoints or each of these for each stream that is up to the implementer next reading stream configuration it\u0027s just a HTTP GET next you\u0027ll see the simple example there\u0027s really not much to it next in our response is a JSON object containing claims describing the delivery method defined for the stream as well as an optional events claim that lists the event types that may be transmitted over the stream this is a may there\u0027s a no guarantee that the transmitter will actually send any of these events to the receiver they are just possibilities next adding a subject and removing a subject are likewise pretty straightforward HTTP posts containing a subject identifier object in the body and expect to get a 204 no content back on success next we see here with an example using an email address based subject identify our object next next like I said remove his basically looks the same next we\u0027re just posting to a different endpoint next verifying stream configurations again simple HTTP post to a verification endpoint this contains a the JSON object that may contain a state parameter it looks like there\u0027s going to have to be some harmonization between this and what\u0027s in the the HTTP delivery spec as far as what\u0027s required for a verification event and what we need what the receiver needs to send in this request since we need to change important thing to about verification there is that it is expected to happen completely asynchronously a receiver is going to make a request to the verification endpoint to ask for a verification event and the transmitter will be expected to send that event at some time in the near future the receiver should not expect that that will happen before the the transmitter returns a response to the verification endpoint request here we see another again simple example request and response lastly yeah good next lastly the error "
  },
  {
    "startTime": "01:21:53",
    "text": "reporting is just using standard HTTP error codes next okay any questions on that your on show for two comments and one of instead of the for explicit end points I would be I think it would be nice if we had the director in point from which I could get a JSON with a foreign horns and then my other comment is if we end up with an explicit profile claim or profile signal I think we should replace the list of events here with a list of profiles that would be I believe cleaner and easier to handle so just to make sure I understand your first point it sounds like you\u0027re talking about discovery type of mechanism for the for the endpoints yeah I think that\u0027s I think that\u0027s worth discussing to your other point the my only concern about that would be if there is a use if there are use cases where a transmitter will only be sending a subset of events that are defined within a profile over a particular stream and if there\u0027s a need to be able to indicate that up off the top of my head I\u0027m not 100% clear that that use case exists so be interested to hear if if anyone has that in mind looks like good topic for the list yeah yeah there are different use cases were only some events would be said but yeah we can discuss this oh I will look forward to the email fad right just as a note so we have to decide which control plane approach we are gonna use either this one or one based on scheme just wondering how are we gonna move forward at that move with this one when are we gonna decide or how are we gonna do that is there a requirement to have only one control plane that\u0027s a good point yeah so we want to have multiple ones to define one well it seemed the skin people were keen to use scheme as a control plane and the non scheme people were thinking that didn\u0027t work for them okay um that may be more clear as we go through the risk in scheme use cases as well alright and then we\u0027re gonna keep the draft separate like the delivery and from the control plane I think as opposed we decided I we\u0027re gonna have a separate draft just for the control plane is that correct we\u0027ve got an ID "
  },
  {
    "startTime": "01:24:55",
    "text": "from on the control plane or you know the management API and we have an ID on that you just presented on delivery right but the ID working group document now of course right but the ID for the control plane and because it\u0027s just a temporary one and could be merged back into the drafts there was one possibility we discussed it already but potentially it makes sense for skin people to have a different control mechanisms there have a comm and delivery mechanism alright thank you I think given that were looking at having n number of delivery mechanisms and M number of control claims potentially there\u0027s value in keeping them suffer Kaplan Moriarty area director just a request if you do if the working group does decide to go ahead with multiple control planes I think documenting the architecture and applicability for each of these might be very helpful and what I would suggest is just starting out simple with the you can use the data tracker working group wiki and keep track of this and then maybe when the working group is closer to final taking what you\u0027ve pulled together there and putting together an overview document overview documents seem to be well received in the iesg right now as opposed to some other formation documents and you know that would be more towards the end where you have all of this stuff defined and you can show how everything fits together but if you use that as a collection point to guide the work and prioritize it especially with multiple options it could be useful good thank you yep thank you I was gonna ask where should we put that and then you answer the question so if only the history provided the tool to convert my architecture slide into ASCII art that would be great there\u0027s no other questions do you wanna thank you really yes so the distribution had been sort of part of something been in this working group for a while and factored out of a previous ID the control the management API is a relatively new piece of work looking to get a sense in the room as to whether we\u0027re ready for this to be a working group document or whether we need to do more work on that that\u0027s what I do and that\u0027s two questions "
  },
  {
    "startTime": "01:27:55",
    "text": "you you found at every time this is my first time okay I\u0027ll ask two questions one a hum for who would like you to be you oh okay okay okay so first one on Hama as to whether we\u0027re ready to adopt this as a working group document and another home for no we\u0027re not ready for home if you\u0027re ready to adopt this as a working group document and how many of you think we need more work on this okay so looks like we need another turn on that and so in I guess whatever we need to fix on that if we make sure clear on the well there\u0027s a different question which is should we have this as a document should we have a control plane as opposed to not right like should we be doing this yes I mean it\u0027s in the Charter but is is it worth another term should we continue to do work on this so how much we should continue to do work on this if it wasn\u0027t clear from their presentation can maybe Anabella Mario\u0027s stand up and say in a few words why this is important why you\u0027re spending the time on this why we should have it as a draft sir so okay can I just ask I mean you\u0027re doing this is an individual draft at this point right you working you doesn\u0027t need to make decisions on the individual dress right no just keep working right sure wouldn\u0027t be useful to know whether you\u0027re beating your head against the wall or it\u0027s something right that\u0027s a different question right that\u0027s a sort of almost a shorter question do you think the working groups the working group should be focusing on this type of problem right that\u0027s a that\u0027s a valid question right and if I was at that mind Kathleen Moriarity area director it could also be at this time right you could take honest work later this is Barry leave us the question then is if you hummed for no should should we reconsider that after a turn or two of the document or not you know is your no not yet but maybe later or is your no no "
  },
  {
    "startTime": "01:30:59",
    "text": "let\u0027s forget about it that\u0027s really the next question right well then why I\u0027m asking that as there wasn\u0027t a bunch of negative feedback about the document but there was a hum for no right so that that may mean that nobody want nobody cares about it and we should just they should just go off and do whatever they\u0027re gonna do on their own but it would be better to ask the working group would you consider adopting it in the future in the near future right you know so they know right so we\u0027re good make me do it again all right so I will ask two questions whether you think this could this document could be adopted after say one or two revisions and review on the list and possibly in the next meeting or whether you think this is work that\u0027s inappropriate or uninteresting for this group to work on later could I make a suggestion for a simpler question just also working group whether they think that management API should be should be in scope for the work Europe fair enough then you know then if that\u0027s an that\u0027s an that\u0027s a baseline right you know yeah but I will still qualify it a little bit so so I will ask the group if the management API is exemplified in this draft is in scope for the group or not so if you think this management API of the sort we\u0027ve just seen is in scope for the group please hum and if you think the management API is not in scope for the group please hum okay in scope but not yet ready thank you okay hues kisses so we\u0027re going to look at risk use cases the once we identify so far and the reason we\u0027re looking for these use cases it\u0027s to have a set of requirements for for the other drafts I\u0027m gonna skip over the go back just "
  },
  {
    "startTime": "01:33:59",
    "text": "from most of the definitions I just want to highlight the definition of an explicit IDP to RP relationship and implicit because it shows up a lot in the use cases and I think here on pointed out that if you don\u0027t understand that the use cases don\u0027t make sense so an explicit IDP to RP relationship it\u0027s where when the RP is register will the IDP and the user is going to an or to flow so basically the IDP has an aura to grant for the user and photo for the RP and the implicit use case is when the RP is using an identifier like an email or phone number and the IDP is the one controlling it and that identifier can be used in a recovery flow so implicitly the implicitly you have the IDP rerp relationship it\u0027s not explicit through some odd grants alright so first use case it\u0027s the simplest one when you have the explicit IDP to RP event flow the transmitter is the IDP the receiver is DRP the our IDP connects expose the control plane and the RP can make or the management API can make API calls to it and it can authenticate it access tokens because CRP has those the second one is the reverse one where the RP is sending events back to the IDP just make a note in this case this is what the use case when the aware we have the issue a conflict he also one requirement for this use case were nice to have feature is to make it easy for for our piece to to participate in the interaction without complicated crypto if possible because the RP can identify itself with an access tokens we are exploring the idea that maybe in this case the sets don\u0027t need to design would have to look at the security implications of that the IDP can document the endpoint for the data plane and RP can simply start posting events that to that endpoint of course the RP can have a full transmitter functionality that\u0027s that\u0027s another case now we have the use case of an implicit IDP to RP so the the first point is that the the two entities need some legal agreement because the user is not clear to the user that there is a relationship in with them just because I logged into a website and I\u0027m using my email address it\u0027s not clear to me that the email provider should send risk events to the "
  },
  {
    "startTime": "01:36:59",
    "text": "to the website where I logged in also these cells requirements for the management API so the remove subject operations are coming from from this use case because the RP needs to make these use cases in order to start receiving risk events and there is an assumption made for this use case that the RP is registered VIP as an auto client even though the users don\u0027t participate in the dance so for the control plane we access tokens can be used yes okay can you jump back one slide alright there are I just wanna note there that in yes in the in this case the since the Opie is registering with the RP that sort of adds save significant potentially add significant complexity for the for the RP because you have to manage manage date for for well you have to manage a lot of these relationships right am I missing something and so in this case you already have an relationship established between the write the RP it\u0027s an or to client to the IDP and all that yes now you\u0027re onto turning this around right in this case the IDP needs to be a client or client of the office no no no that\u0027s not in there okay so it so that may be a mystery so you\u0027re right so testing the last paragraph so yeah if the RP wants to have a full transmitter functionality then that needs to be happen exact that\u0027s why in the first two paragraphs said he said the requirements to try to make it easier and not have that require right and I what I was trying to get to is that part of the work on key management work that we\u0027ve been talking to to Mike about right is to get away from the need for a lot of symmetrical so symmetric crypto so it would be nice if we if one could sort of call out in some of these Q\u0027s cases where key management sort of comes into the profile right because it or where you know the complexity trade-off between push and pull might come into this right because I could so naively I could say that in this case maybe it\u0027s in it maybe it\u0027s worth doing whole because you don\u0027t then don\u0027t have to have this this sort of reverse security relationship I push for it should be a good one I haven\u0027t thought about it yeah I mean it\u0027s one of those things where you\u0027re sort of Paul might actually be worth it if I if then I don\u0027t have to have the IDP registered as a as a north as Ana was kind to the to the right already a few of these considerations maybe might be worth putting into the use case document to sort of because it actually informs sort of the your implementation choice yes thank you one more okay so open questions for the "
  },
  {
    "startTime": "01:40:01",
    "text": "implicit one what are the implications of unverified identifiers like unverified email addresses that\u0027s an important one and the other one is discovery how does the RP find the correct IDP for a given identifier so if you have an RP and in some cases might be easy to map to email addresses to who the provider is but in other cases is not easy and we might need to so these are these are these are problems to be solved for this use case sure but those are at the risk levels post at the shot level right and then the the reverse is the implicit RP to the IDP in this case no enrollment call is strictly necessary because the RP has the user identifier already so it could simply notify the the IDP directly but still the open question is easier among our Mountain norman necessary it might be based on the implementation like each RP or IDP my decide on that and also again we have the assumption that the IDP is registered with the RP as an or to client and can use access token and this is the reverse one again so there is a purely implicit uski so you have two different websites and they happened as an example and they have they both use email addresses as main identifiers and technically they could do cross discovery to see if they have common users and then starts and agree see that\u0027s between them obviously there\u0027s legal agreements and there are open questions about legal and privacy implications for this identity as a service use case so you have identity as a service so you have one entity managing many RPS at once so this identity as a service could technically automatically do the configuration with all the corresponding IDPs on behalf of the RPS and the Assumption for identity as a service is that the identity as a service provider can impersonate the RP at an IDP so it can obtain access tokens on behalf of the RT very similarly security as a service the main difference is that in this case the service provider cannot impersonate the RP and just head there are some delegation rules so the IDPs will accept some requests but they know that they talk to a different entity and not to the RP so this complicates all the all the use cases although I\u0027m sorry all the control planes and the whole the scenery "
  },
  {
    "startTime": "01:43:02",
    "text": "would work because now the management API will have to explicitly become aware so I think what currently we have proposals for a management API are not covering this use case I\u0027m not sure if this is a use case we will want a service or not but it\u0027s it\u0027s one is important to note and on-premise are paid so this is the one that is requiring polling because they are sitting behind a firewall and push to an HTTP endpoint is not possible questions sorry could you clarify again what security as a service means what is happening alright so maybe the name is not right but you have a service provider which provides services for many RPS in one case they can impersonate the RP in the sense they in an or two terminology they have the client ID and secret of the RP they can obtain I access tokens or some other means they can get access tokens and that management API endpoints they show up as being the RP right maybe a dozen all the difference in the other use case at security as a service maybe it\u0027s not the right name but the number seven they just they don\u0027t provide full IDP or RP implementation but they provide other security but they do still manage a large number of RPS but in this case they cannot obtain access tokens on behalf of them and in all case when they make an API call they have to identify them as themselves as being I\u0027m the service provider and the IDP will have to or whoever manages that eight management API they have to understand that there are some delegation echoes there and they are allowed to make calls on behalf of the of the RP so in other examples of this fuel has examples of this the requirements comes from Oracle and few hansel so I\u0027m not aware of this example is directly but I just can\u0027t let it sounds like in general there are examples of delegation when you make API calls when you make an API I have clear examples where you make an API call and you say I want to make the API call as if I was the card but I\u0027m not the card and then the receiver would have to make sure that I\u0027m allowed to make those calls on your behalf so basically the delegation it\u0027s clear to the implementer of the API right would it be correct to call it risk assessment as a service or something like that right side is it that different from security right maybe "
  },
  {
    "startTime": "01:46:03",
    "text": "security it\u0027s too wide okay yes sure thank you any other questions okay next up is one of our favorite presenters Tony okay I\u0027m just gonna present this is draft zero zero and this is the skim use cases for scenarios there are some pre assumptions here which is we use skim triggers and they are things that we use to make sure that we can we can keep track of all the things all the events that go on within within skin processing we also listen the skin security model that\u0027s documented in the in skin and then we also have a privacy aspect to it to make sure because we are sending information trick we are sending updates security information around around the net here okay and so we have to we actually have three use cases the first one is a push use case the second one will be a poll and the third is a mobile SMS and stuff like that but there are pretty simple use cases basically the skin client we have down there it\u0027s going to issue commands over to the gym service provider we assume that all the security and tokens have been set up correctly this is we believe out of band stuff that needs to get done and then what and so so the skim client skim processing client controller will send skim security commands such as update users and things like that and it will also do the the event commands at the same time so we may want to not be notified of you know things that have changed with a particular user or stuff like that so that gets also done through that aspect and then the skin event stream is going to kick off push events down to the down back to the skin client if if it detects that the triggers have been pulled and and you need events to be set and then "
  },
  {
    "startTime": "01:49:04",
    "text": "we also need a a polling in this particular case because we have a we have a firewall situation here and we also may only want you you know we may also want to have the client tell it when it wants to receive updates it\u0027s not it may not be advantageous to have it pushed all the time so there needs to be there needs to be a pull pull mechanism here but the but the use cases you know the flows are the exact same same situation and the last one is just is basically the same go ahead go ahead next yes that\u0027s what I said and so the last one is just we have a we have a mobile situation and in the events may come over SMS or some other mobile means instead of instead of coming over to HTTP types of events so those are the three basic skin.skin cases that we that we have we\u0027ve implemented the second case where the long hope where the long polling and we do directory synchronization via that comma you\u0027re on Shaffer comment to both drafts actually there\u0027s a major mismatch in terminology and so someone coming from the outside will not in my opinion be able to know whether the specific use case is appropriate for this solution for this solution and maybe both so could you add to these three use cases in some wording using the terminology in the other draft such as implicit IDP ERP and so on and on the other hand could the authors of the other draft please say whether stuff is appropriate for the cloud for the enterprise for mobile yes Tony yes Turk if I was an author of this I would you\u0027re just the straight man just the straight man here I have a question identify your I\u0027m sorry I\u0027m dr. Michael B Jones I work at Microsoft I actually have a question about control point aspects of the delivery of messages "
  },
  {
    "startTime": "01:52:08",
    "text": "through skin and the related events as you\u0027re viewing the architecture is that already implicit because of the skin to context yes so you wouldn\u0027t need a distinct control plan as Annabelle described because that\u0027s that\u0027s already and that for free so you get that because we in the skin service provider that\u0027s what we\u0027ve got so you have to implement that skin okay thank you and about Backman or a clarifying question so within the mobile scenario you\u0027re actually looking at transmitting events via SMS not just via mobile push yes correct I think that that\u0027s our it could be expanded to to the mobile push but that\u0027s our current usage and the reason I ask is the way we\u0027ve discussed delivery of sets and packaging those it does not lend itself very well to being transmitted directly over SMS so some interesting questions that are gonna come up over what that would look like perhaps a great topic for another delivery method would there be another spec for SMS delivery of set if people would if it\u0027s if that\u0027s a use case I would assume so well but your will be for SMS you are presenting the use case no I\u0027m just saying Annabel was talking about mobile push and my question about mobile push was just to clarify whether whether the slide was correct and referring to SMS yes since you said it is then then we would correct okay I thought you were I thought Nick was on the mobile yeah I think as long as if skim has the use case for events via SMS then I think there potentially would be value in defining that delivery outside of the skin specific contacts agree okay thank you so I\u0027d like to thank both groups of authors and however right now these to use case documents are not in charter for the working group and we do not expect them to become working with documents unless does massive demand for that so that\u0027s the end of our formal "
  },
  {
    "startTime": "01:55:13",
    "text": "agenda we\u0027re at the any other business if there\u0027s anything else no other business yeah thank you everyone thank you in Singapore everyone signed a blue sheet that\u0027s right "
  }
]