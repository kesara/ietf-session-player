[
  {
    "startTime": "00:02:15",
    "text": "Yeah. Yes. Yes. 3 Alright. Let's go ahead and get started. I got some echo from meet echo. So please turn talk to speakers, whoever's in the room. Welcome to the Ohio, session here atietf119. This is the note well. Please note it and understand your obligations that you undertake by participating in the ITSF. Couple of tips, for folks, this is as we have been doing a hybrid meeting. This is probably pretty familiar with folks, but, you know, folks here on-site, make sure you scan the QR code, which I think is attached to the microphone or Otherwise, sign in to meet our code and make sure you're counted and we get an appropriately sized room next time. Remote participants, you know,"
  },
  {
    "startTime": "00:04:02",
    "text": "please mute unless you're speaking and, headsets was always recommended. We have, Basically, one current item and new item on the agenda today. Does Tommy Polyick in the room yet? Randy lost Does he navigationally challenged? Ronnie Well, perhaps. Yeah. So, yeah, we have we, had an interim where we discussed the trunk to HTTP draft. And agreed that we were gonna adopt that. On it is now draft I ETF. So Tommy has, most of the agenda to talk about that. Then we have some time to talk about a proposed use case, for unreliable OHTT t in support of private metrics. Oh, there's Tommy. The IV room's before. Alright. So that's that's the end of the agenda. Any agenda vashes, before we launch into it, Hearing none, tell me, take us away. Okay? I could I'll get your slides up. Just tell me when you just show slides? Yeah. want the next one. Perfect. Alright. Hello, everyone. Sorry. I had to run across the building. Okay. So I'm Tommy Poly from Apple, and I'll be talking about are chunked oblivious to HP messages, this is a document I'm writing with Martin Thompson, and we had a interim on recently since have adopted. So well, is the overview of what it is. quickly go through And then Ideally, let's spend the majority of the time talking about some of the open issues that we need to work out. Approach you wanna take, Alright. So next slide, please. Yeah."
  },
  {
    "startTime": "00:06:02",
    "text": "Alright. Yeah. I'm gonna skip this one. Alright. Okay. So what is chunked HTTP? So you. It's a it's a relatively small variant on the normal oblivious HTTP that allows instead of having to decrypt and encrypt and decrypt the entire response. The requesting response in single flow. It allows you to Take separate chunks, and encrypt and decrypt those pieces, without having the entire request sponsal in one go. This has a couple of advantages. It allows us to use what binary HTTP already had a support for of determinate messages. We are reusing features of HPKE already supported having multiple chunks with a counter, And then overall, this is still still O HTTP, still a single request response transaction. Next slide. Sorry. Yeah. That's fine. Yep. Slow slow. Okay. So this is the brief one slide overview of, like, is the actual content in the draft. It's a pretty simple format there's the existing I kinda like, request header at the beginning of the HTTP flow. That's just like, you know, here's the key ID I'm using. Here's the algorithm I'm I'm using. But then instead of just being followed by on the request side, the HPKE encrypted chunk. The entire thing now is prefixed by a link field and then a chunk, and then further link fields until you get to a sentinel length value of 0, which denotes the final chunk followed by the a chunk extending to the end of that stream."
  },
  {
    "startTime": "00:08:02",
    "text": "And then on the response side, similar to normal OHP begins with the nonce. And then has various chunks. There is some crypto work that you can see in here of how to handle the counter. Going into the AAAD encryption on the response side, but it's relatively straightforward there. And so the properties of this we get is, we are preventing a reordering of chunks, we're preventing truncation of the entire stream by removing chunks without appear knowing, it really is just allowing you to process incrementally. In order to handle the fact that this is a different format, it also defines new media types. So instead of Message OHP rack and res, it's just OHP chunked. Wreck and res. Alright. So that's the technical bit. Relatively straightforward there. So let's get into the interesting stuff. Okay. So, we have a issue here. I think this is probably the most interesting to talk about, and this is something that when we were originally, discussing it on the list a while ago, I think Mark Nottingham brought up. As a thing of like, how are you gonna handle this? So really it's like, how how do we wanna negotiate use? Do we need to negotiate use? Overall, OSGP is kind of kind of kind of kind of kind of Interesting, you know, how it handles negotiation. It it certainly allows for out of band, very explicit configuration. That's not necessarily, has to go through some standard mechanism So some uses of OHP you just assume, yes, a client learns about an oblivious HTTP key configuration somehow knows that it should apply it."
  },
  {
    "startTime": "00:10:00",
    "text": "Somehow. So for cases like that, one option for, you know, knowing that you should be using the chunked variant, is to just say whatever other out of band mechanism you have That is what you use. To essentially additionally pass along the information that you should be using chunked. I can say, you know, for the uses where we in our stack, speaking for Apple, like, I've currently used OHDP, A lot of it is like that. So Yeah. We we've been using it for things like a safe browsing lookups where we're trying to get a, a hash list of potentially malicious URLs inside the browser. So in that case, We just currently get a configuration from, like, a cloud serve config bag you know, a protobuff thing, and it can, alongside it, say, use the chunk to vary this, and all the clients would use that. That would work fine. We also have like, APIs today where an app just says, I want to use this key configuration. Could very recently have an API where you say use the chunk variant. Donna, did you wanna Jump, have you taken questions here now? We can. Have a great day. I I yeah. Go. I don't have the context for this. I haven't read the issue yet, so apologies for that. But this sounds like a general discovery problem. Why is the specific to OHTB? chunked Meaning, meaning that you could apply the same idea to any O HTTP relay, It is What instance are they? It's true. So I think like, it's more how does this fit in? So Great. So today, like, yes, you could get your OHP configuration out of band. Out of band. There is a definition. So, like, this b option Like, that the core document does specify"
  },
  {
    "startTime": "00:12:01",
    "text": "you know, here is the format of the OHP key configuration. And that has a media type. And things like, we have our RFC on how to discover essentially through DNS, that you that that something supports OHP, that tells you, hey. You'll go to the gateway, do a get for the media type that is this key configuration, that's how you fetch the key configuration for that gateway. So there is like, a standardized mechanism, but if we are having that How do we fit in the fact that you would want to do chunked? Into that, is it a different media type for the key config? Is it some extension to the key config? Or it sounds good. And then the other options here are it's not explicitly in the configuration and clients just use it, but that seems a little for consistency purposes. Yeah. agree with I that. Okay. That makes sense. Thank you. Yeah. So think for, like, the case of where people are doing fully out of band You know, it's up to the the implementer to figure out what they want to do. So probably the most part here is you know, if we have cases like the discovery from DNS or any case where we are explicitly using the media type, that was defining the base draft, how do we Or do do we need to know along with that that this No. Gateway resource. Supports chunked, or that the relay supports chunked. There's a lot of things that needs to be worked out if this is not something that is like a pre arranged pre agreed. Setup. Martin, love to hear what you think. Yeah. So, Martin Thompson, Richard mentioned options. In the in the document, that would be essentially something in the form of the client just asks the gateway what it What it supports? There's there's, client initiated content encoding, Support, support, in HTTP, which is a sort of"
  },
  {
    "startTime": "00:14:00",
    "text": "Clanche tries. Which is another option here as well. Right. Which is, like, yeah, And and that's not necessarily a bad option in this case. I don't. I think you the the relay doesn't have to anything special for this one. Although I understand that some relays, might, based on what I heard. Yes. I mean, so but I I mean, even You know, even if it really would support it without any other configuration changes, and we can talk about that separately. It is a different media type that they pass along. So if they have a very explicit allow list for known media types for a particular gateway they would need to at least have that within their allowed list. Right. Right. Right. But you would find out Fairly quickly. When that request was rejected with a 405. Or is it 4a6? 1 of the 2. Yeah. So The Just just trying is not a bad option for something like this, your discovery thing, I suspect that most of your use cases for discovery won't care to use it anyway. wouldn't. They They wouldn't. And so, It it it Lucas had an option D, which was, DNS. I might have an option, e, which is Yeah. Mean, personally, I kind of lean more towards the, you know, either you have something explicit or You just try it. You know, I was listening here as potentially one of the concerns with just trying it is the consistency being of if for some reason, you, like, you let one client think that it's sports junked and, like, Or you're saying, like, for this hour of the day, I'll allow it. And then I'm gonna assume that people come back and try to, like I'm not sure if that really adds up. No. For for something like this where you have a if if you think that there's a clear need for something is. Yeah. Then"
  },
  {
    "startTime": "00:16:00",
    "text": "That need may have been anticipated by the server anyway. So you can just ahead and give it a go. And if it doesn't work, Okay. You put a little mark in the thing that says, this particular endpoint doesn't. Doesn't do chunking. We'll just send them all at once. That's fine. And You move on. That may be that may be what we can suggest what we you. Actually, I think one thing that makes me more comfortable with it is Is the relay bit? Because Presumably, in all of these cases, gateways and relays, have some relationship. And if the gateway Yeah. Essentially says to the relay, like, hey, I I support this media type. You should let this through. Then that you imagine would be more consistent in letting that through for all clients. And it's a bit indirect from what the gateway sees directly. Jenna? Jana ingar, first, I don't know if we can make that assumption broadly. That the gateway and they really have some sort of a relationship. Right? Because In this particular case, it really doesn't have to do anything. Really, the gateway could keep itself open 3rd to relays and could receive relate OHP from from from from any relay for that matter. So that's one, but hold on to that thought. The The thing I'm not sure about is if an application needs chunked, and you try it and it doesn't work. What's the fallback? For the client. Because if you don't have a fallback, then what's the point of just trying I think when we talk about these things in general, like, oftentimes when you're using this you have a application where you know a priori what you want to use. very particular I I agree with that. And I think I think maybe we should just say that. Like, I Okay. I don't know that, you know, trying trying, Trying anybody can try. Don't have to specify that people try all kinds of things. And sometimes they get, you know, they get they get identified as bots. But I'm just saying that, you know, we don't have to specify trying If you're gonna actually do something here,"
  },
  {
    "startTime": "00:18:00",
    "text": "it'll be useful. The auto bank configuration thing, using DNS, whatever it is, is is probably more helpful. In my opinion? Yeah. That I think is useful. Actually. To to the point of the relationship, And if you need a preexisting relationship between the gateway and the relay, you're absolutely correct that the gateway does not need to know about every relay. However, The relay since relay needs to have a explicit mapping between It's path. For the relay resource and the gateway resources entire URL. As well as allowing that particular media type, like, you do need a relationship or at least, Preconfiguration, generally, of the relay to know what gateway to allow talking to. Unless people have a fully open relay that has like, a way to encode gateway. URLs. In the path or, like, in the query parameters. Is there anything in the protocol that this allows that. Nothing DSO allows it. Correct. I don't think anybody in the right mind would do it. Right. We haven't seen anyone. And I I'm I'm not doing it for sure, but I'm just saying. Okay. Okay. No. No. I I think, again, I think this is it's useful to have you out of my configuration. I'm not sure that we need to actually talk about just trying Okay. Which Rick Swalzakwa. Are the o t O HTTP keys Always gonna be the same as the trunked keys. I certain I I mean, that's my mental model of it. So then could ask for the trunk. got back, you And if you want, you've was the non chunk, then you know that the server doesn't do That that would be in a case in which you had the key configuration, like, have a different media type or something, which is not the case"
  },
  {
    "startTime": "00:20:03",
    "text": "the driver. Yeah. Alright. Yeah. That that that's a direction to go, but then that potentially things more complicated, more fragmented to to Yeah. Mark Nottingham. I I think, you know, part of what's happening here is is that you know, there's not a particular Wow, Richard. Oh, fair enough. Fair enough. There's not a particular, you know, protocol flow that you're starting trying to bootstrap where you would do this negotiation. There's not a figuration file format that you're standardizing that would contain this information. You know, the use of OHP so far is application specific kind of ad hoc and an So it, it, it, you know, talking about negotiation without that context doesn't necessarily make a lot of sense. Maybe some hooks or suggestions about how one might do it if one too. And that's why maybe the media type might might be enough plus whatever, you know, doing it in the in the, keys, the media types doesn't really make sense to me because that seems like it's It's it's it smells bad. It's like you're using some out of band information there that where it doesn't make sense. Agree. It's not about the payload. You're using media type for something else. So I wouldn't do that. But I'd say, yeah, maybe just just have the separate media types for the actual payloads and maybe, you know, suggest some patterns of use. Yes. think that makes sense. I Yep. Alright. So I've reached the end of the queue on that topic. I I closed of managed times. You have to feel like you've got a direction forward? think Yeah. I I Yeah. We're not we're not doing anything explicit I think we just want to describe, as you were saying, describe the the patterns of, like, could be out of band, it most likely is and here, like, you know, if you're if you're trying because you think supported, here's the right approach to take. And if one day we wanna approach, like, some automated OHDP setup configuration file format or something. Yay. Sure. So that's work outside of this document. Okay. Great. Thank you. Good feedback."
  },
  {
    "startTime": "00:22:03",
    "text": "Just so that this was a, you know, comment on this issue, which is probably not applicable since we're not trying to put this into the key config that if we did, that would be subject to consistency checks probably a good reason not to do that. I do think if we're having discussion in the document about approaches, we may wanna point out that, like, Once you know that, you know, you as an application client. Want to use chunk and you know that it's supported you should be consistent in using it in order to not accidentally, like, reveal something about, like, you don't wanna, like, be saying, like, oh, for this one request, I'll not. Chunk and the other ones I will that could leak information to the relay, etcetera, about the nature of your request. Okay. Think we can move on. Good. Good. I think the other interesting issue to discuss is around max chunk sizes, I think, Martin, you had open this, So it will yeah. So this is like, you know, do we need to restrict anything here? I'm I would kind of lean towards no because the base OHP spec doesn't really have a max. Request a response size inherently on it. Do people have reasons why they would like to have a max chunk size when they are doing chunking. Yeah. So the reason I I raised this issue is that maximum chunk size, is, like, 2 to 62 bytes. And it turns out that if you were doing an AED, you have to hold 22 to the 62 bites all at once. Before you can release anything, that might be a little bit bad. So so having some sort of guidance"
  },
  {
    "startTime": "00:24:00",
    "text": "at, at a minimum would be, would be good. I, I tend to think that specifying a maximum chunk size would be, would be advisable. Rather than and just saying, you cannot have a chunks size larger than a megabyte would be, I think. So not not a negotiated field. Just not a negotiated field, just a straight up If you want interoperability, Here's the number. If you have out of band information that says otherwise, you know, go for your life. But, but, if you want interoperability and you don't know what the other side is willing to tolerate, Here's the number. And we can we can argue about that number. But but but but but but but we can pick your favorite power up too. Which is kinda like this last option here. A pair of 2. Is it not an integer power of 2, he says. It is an integer. So and a power too. So win. 5 of this. Booths. Hello, Lucas Pardo, co author on the resumable uploads draft. That just raised an issue on ourselves the last couple of weeks where we're discussing upload chunk sizes. It's a different interaction model, but that work is based on existing work of resumable uploads pre standardization where some of those folks did benefit because the the maximum thing you want to upload is potentially terabytes. But, each proxy in the chain of the intermediation of HTTP in the world might have their own strictions on per reese, like, per chunk upload even though it's our trans transfer so we have an issue that. I don't know Like, we were suggesting some headers to kind of advertise these limits to help avoid having the hard coat things. And make it it was a per resource limit as well rather than a server limit."
  },
  {
    "startTime": "00:26:02",
    "text": "So that, you could maybe have discretion between a free tier of an upload service versus people who might be willing to pay have more things. So it it feels like there's some overlaps and maybe some of the stuff that we're talking about in that group are relevant here. Or maybe there's some text you're gonna put up that we would borrow back depending on how the discussion goes, but dot Yeah. That's interesting. I mean, I Well, I could totally see for that case, having the per resource negotiation would make sense. I for, like, the consistency and privacy reasons, I'm leery of that here. So we may come to different conclusions just because of the different nature of would probably be fine, but maybe if we put that in a header, and we define the header Yeah. That you could reuse here, and you just always have the same value. Maybe. Yeah. Or or And I'm worried that, you know, a header becomes an attractive thing to look like it's a negotiation and instead we may want we could, as you know, say, like, default values of recommended values are similar. I think like if I'm using this, wanted to limit the, maximum amount of memory you have to commit to receiving a response is probably one of the stronger reasons to do it. So do think it's important that we have a maximum. I don't really have strong thoughts on whether it needs to be negotiated. But I feel like if we had a negotiation mechanism, the maximum size here is more important to negotiate than whether we use it at all. Since the maximum size could theoretically or a lot more plausibly vary among different use cases. So I'm just gonna speak from out here next to Nick here. For for what it's worth, the, the way MLS addresses this is to actually just limit the size of the VAR sits So So that value is beyond, 2 to 32 or illegal."
  },
  {
    "startTime": "00:28:02",
    "text": "It's still pretty big. I mean, it's still pretty big. I mean, that might not be your hour of 2, but I was like, well, it's it's really 2 to the Okay. So so you could just said the field itself only be for to the 30, I guess. The the by its long. Right. So the the Actually, it's not quite to do the variances a little bit. 2 set. top bits Whatever that is. That's that's illegal. Interesting. I could copy that. I mean, it's a hack, but It's a yeah. If if if if it to you. If if that's an acceptable power of 2 for you, then off you go. Jenna Einger. There's a the problem with that is that you are actually limiting the use of this. Thing for larger I mean, so he he he what Martin was saying earlier, which I which I liked that, you know, you should be able you know better than go ahead and configure it to be larger. The problem is just to change your password. You just change your bar and parts, sir. Sorry. Say that again? You changed your car. Parts are to allow the big values. I'm Change your of our end parts, our end. Oh, so allow the big values. sir. Change your of Yeah. But then but then you lose that. Yeah. You mean, you're essentially just saying, like, rather than choosing a max a random maximum that doesn't line up with a warrant overflow boundary, you may as well pick the 1 That's like, well, I also get to save space by default. It's Is it are we actually talking about a maximum? So if if it's If if we are saying, I wanna understand the semantics of what this is This question is Is it something that you want for interoperability or is it something that you're actually limiting the messages to be? Because If it is a ladder, it's a max. If it's the other, it's really a min. If you want for interoperability, you have to support that site. Oh, I see. It's a min max. Yes. Basically something. or But it's min max of the something. It's the max max. It's not the max max. It's the not I think it should be clear about exactly what we're trying to"
  },
  {
    "startTime": "00:30:04",
    "text": "Do here with the max. If it's max, if you wanna say max, then we should say max. And, yes, your idea is good. But if you want the technology to be able to if you want deployments to be able support larger than that. Which I believe is the case. It's not a real max. It's a mint mix. That, Thanks. Rich, Yeah. Rich Salzakima, as an operate gateway operator, it'd be good to have a fixed upper limit just so we can do resource planning. And whatever you do, don't encode it in the protocol. Because if it's in the document, then you can change it by issuing a biz that says, oh, when we one making real meat for Mac. If you have to change the protocol, you'll never be able to fix Yep. Okay. So we'll pick our favorite color. Let's do like a hex color. Encoded as a number. Exactly. Alright. Are you I I Okay. Thank you. Okay. Oh, sorry. Yep. So those those are, I think, the main things that need discussion. So we got good feedback there. So I think we have enough to to Go ahead. Other things that need to happen are adding formal analysis, I was talking to Chris Wood. I believe he's gonna kick that off. Since we you had models for some of the other OHP. We'll be adding test vectors. To this always good to have. And we definitely need to beef up some of the privacy security considerations based on the discussions we've had at the interim etcetera. I think that's that's it. For this as last slide, I believe. Some and think that is the last slide. That is the last slide. Thank you. Good. So we're making progress on that working group deliverable. Next presentation we have is, Lin Mao Song."
  },
  {
    "startTime": "00:32:00",
    "text": "But now are you, able to yep. Come up on video. And I'll pull up your slides. And when when I'll just everyone. Hi, You're welcome, Apple here. In this short, forever has the whole abuse cases. Uh-uh. We're we're getting some background Well, well, feedback and background noise, do you maybe have a headset you could use? Alright. Let me Hello? I hope it's a better Yeah. That sounds a lot better. Thank you. Okay. Yeah. Sorry about that. Hi, everyone. This short presentation, I'm going to share how our use case has been using O HTTP on our platform for, privacy enhancement and how the other, draft, which was previously discussed. The unreliable HD extension might be able to help us further to enhance, enhancing our privacy protection So, next slide, please, I am still able to, move the page forward, or thank you. So the main component of our system is shown up here. The specifically, the main component is on the right hand side, the dev leader, and it is basically, an implementation of the distributed aggregation in protocol, which is another IETF draft, a draft standard So for the sake of this presentation, we won't go into the that protocol details but it should suffice to say that that leader in just a huge amount of data from the participating clients"
  },
  {
    "startTime": "00:34:00",
    "text": "which is shown on the left hand side, And that the data contributed by declines can be privacy sensitive. So for example, there might be measurements and the machine learning gradients and so on. So to safeguard the user we have a number of measures in place. For example, differential privacy noises, and the OHP is a one of these measures. The way we use O HTTP is to basically force every payload from the clock to go through the OTT Transportation And in this way, we leverage the old HTTP to decouple the client's IP address from the targeted resource. Which is the tab leader in this case. so And, sorry, next slide, please. Thank you. However, there are all the things mitigated specifically the relative ordering and, timing of the uploads remains a concern. So here on the diagram, I'm using different lines to represent different clients upload. And one might be able to argue that for one specific client, it's requests, it's a high payloads are among a vast ocean of other HTTP requests. So order. However, if you look at the path between the it way. And the leader, the relative order and the timing of the requests are more or less, still preserve the and so can still be, inferred So in theory, the information may still enable a malicious observer a militia leader to craft a certain smart, correlation attacks. Next slide, please. So, what we, have found that we single have found that previously discussed, unreliable or HTTP extension, might be able to help mitigate, this risk."
  },
  {
    "startTime": "00:36:01",
    "text": "Why? Because as previously discussed, this extension would have enabled the really to reshuffle and batch the requests and it doesn't mitigate in the, for mention the risks. Next slide piece. So, here is, our That's that's to be with the likes of working call over to to review. Is is this a reasonable use case and also is the unreliable OLED extension, the right approach we are aware this extension was previously discussed and there were outstanding questions. So there were details to be ironed out, for example, m if the, Accept header is the right way to signal the sport And the other e series, for example, if the batch might, I need to be inspected further to prevent a new attack service and so on. Were other or 4th prego king questions. For example, a, if this should really be a more fundamental change to be discussed in the HTTP group but it seems to be It seems to be to us that the extension can be a promising solution for our program and that we would really like to hear your opinions and and Thank you very much. Alright. Ben Shorts, please. Hi. So it's been a while since I've thought about this, but my recollection is that this was originally proposed in the context of DSS start. Sorry. I should say, benchmarks co chair of PPM or DAP is is Vandis So my recollection is that this came up in the context of DSS star which as I recall, had some particular, Requirement essentially for a traffic anonymizer"
  },
  {
    "startTime": "00:38:00",
    "text": "like oblivious HTTP, and so it made sense there to strengthen the the anonymity that that provides. But in the context of DAP, you you sort of you mentioned some potential misbehaviors by the leader as the motivation for this, but DAPS threat model already includes misbehaviors by the leader and if you believe DAP's threat model, The leader cannot accomplish any denonimization. Because of the multi party computation guarantees. So is there could you tell could you say more about the motivating attacks? Because from my perspective, DAP seems like a uniquely uniquely uninteresting use case. For this architecture. And I think this architecture is actually much more interesting in the context essentially, Unsecured data submission, if you imagine that oblivious HT, oblivious HTTP is essentially the only protection in place and that, you know, user reports are just being digestive verbatim on the other tech. Yeah. Sure. So, I I guess the, original the motivation is a probabilizer of the debt leader. Sorry. At that I mean, I I mean, I misspoke. So they I I guess the the main, concern is really if somebody is like, observing the traffic, then because of the relative ordering and the timing, then there might be some way to infer the membership prefer attack on this and this. So that was the The main motivation, So my understanding is is that this wouldn't help with that because you would still be able to infer, I somebody sent a report. It was aggregated, into some batch by the, by the unreliable,"
  },
  {
    "startTime": "00:40:00",
    "text": "OHTTP relay, And then that batch was passed up into DAP, which it did its analysis, so whether this is in place or not, the only thing I can infer is that this user appears to be a member of the bat the from which we have this aggregate output so so my, understanding is that when doing the, a passion you may not necessarily focus on the pack interest thing therefore, for for example, for example, the there is also reshuffling So that would further disrupt, like the a limit or limit the capability of somebody doing allegiously grouping the request together And, so I I I think I think I think that the, some of the details might still need to be fake the oath the simple act of, grouping and the shuffling and the patching seems to be a potential way to Amit, a meat, to basically, mitigate the ordering issue. Okay. Well, so I guess I'll say I'm not convinced that there is an ordering issue, and I think if there is, it it could probably be addressed within that, internally. But so that it's not I'm actually not opposed to to this extension in general, but I'd like to see a more compelling use case. Sure. Some? I'm kinda split on this one. Unfortunately, I don't I don't want us to be in a situation where we sort of submarine something into into HTTP without being deliberate about it. And It seems like from many perspectives. This is just using an existing status code in HTTP,"
  },
  {
    "startTime": "00:42:02",
    "text": "and and simply having a way to request that the, the thing that's serving the resource that you're talking to use that status rather than provide you with an, an immediate response. Which we could use things like prefer or something like that. There's a bunch of other mechanisms that we could use, but it doesn't really matter what the spelling of the mechanism is as much as it is that's going on here, but if you're if your somatic is we want store and forward for HTTP requests that's kind of a new scene. And, having the ability do that. Creates interesting questions for what it is that is sitting on the other end of this architecture. And I wanna make sure that we don't just stumble into that without having thought of the consequences of that. So having a discussion the HTTP folks a little bit more would be good thing I see. A number of them in the room, but, maybe more formally asking questions of them to to make them aware of it because there are some implications, I think, what this means for reliability and server infrastructure. To to have clients ask the question and be answered in this way. Martin Hold on a second. Mean, you say that, you know, this is store and forward. For HTTP I mean, that that is it is true that the relay would be doing something different. Than, and, you know, a generic HTTP proxy say. But that's already the case. It's already the case that the relay is doing special stuff because it's an orange GTP relay. Could this not just be another bucket of special stuff the that the relay does. Yep. And that would be When if we build a mechanism, it's gonna be somewhat generic in nature. That's the thing that concerns me there. Sorry. I'm I'm tying a string up here. So"
  },
  {
    "startTime": "00:44:01",
    "text": "No. The fact I'm on the strike still. I'm done. Make sure they're not as secure. Would you like bow line or a got a granny knot? Is that okay? This takes time. To do it right? Anyone else have thoughts on on this, on this draft? Anyone else anyone violently opposed adopting this draft. Proposed at all. In favor. Mark, nodding him, you were making a gesture. Which Are you trying to in queue? I give you permission to approach the microphone. Sir, Mark Nottingham. Yeah. I have not looked at this draft. And and I admit that freely in front of everyone. But uh-uh listening to what Martin was saying and from a very quick scam, Yeah. I'd, I'd be very concerned if this was changing the footprint of HTTP unintentionally. And I think we need do need to have that discussion. That's always been a risk in OHAI, and it's been managed very well to date. And I think we need to continue to keep that in mind. K. 3, Just very generally, every time you you make a change to HTTP in in a significant way. You have think about how it interacts with all the different components and all the different functionalities and that can get quite complex. Tommy Polyapple."
  },
  {
    "startTime": "00:46:00",
    "text": "So, yeah, I Definitely agree with with what Marcus Singh, But I think to the point on this slide, the the draft, which is Long expired, you know, is one particular way to try to expressed these things within HTTP that I don't think had a ton of review or consideration for these concerns in it. Some, I think the interesting question now is Yeah. Is this a problem really worth solving, that And, you know, maybe to Ben's point, maybe it's things other than DAP, but other cases where we have some sort of upload that you know, the the client has no useful need to get an encrypted response from the gateway. And there are privacy benefits to having to be batched. And potentially scrambled before it actually gets to the, gateway. So is that a useful thing to solve? And then can we find secondarily, can we find a way to write it in a way that either is you know you know, only using existing semantics that aren't that isn't exposing something as as a new attractive nuisance within HTTP or you know, can we very narrowly scope the semantics of what allows this such that you couldn't use narrically. Yeah. I just wanna point out that the definition of 202 more or less invites this interpretation. And so this is already something that I think might already be in in HTTP. But it's not a very heavily used feature of the protocol and it's quite possible that there are some there are some gotchas that we're not aware of. And so having that discussion would be would be, useful I I think there's that this this 2 modes. Sorry. Just to be clear, Martin, the 202 does I mean, just 202 encompass the sort of"
  },
  {
    "startTime": "00:48:04",
    "text": "batching, scrambled, you know, it doesn't talk to discussing. About that sort of thing. And I don't think we necessarily relying on that on that capability here. Just saying that if you're a relay and receive a request, with whatever indication that the client says, it might prefer that you just deal with it and not return a response, sending a 202 in that situation, And then and then dealing with that request and forwarding that request at your leisure, is entirely something that's up to the implementation of that resource. And would be fine. that However, making sure that we don't accidentally stumble into a trap that exists because 202 is not a very well used capability and feature in the, in the protocol is, is something that's worth spending some time on. I think So so let me ask the the proponents here at Lynn Lynmouth Tommy. To what degree is it important to for the clients to get something from the server that Asure is the client that the server is gonna do whatever you know, batching or scrambling or or privacy enhancing actions. As opposed to simply getting a notion from the server that the the response is, you know, request has been accepted and will be eventually delivered, delivered, I mean, my personal interpretation of this is that we don't need anything semantically from OHP here that says, I am going to batch this at a 10 minute interval and scramble with this level you know, shuffle the deck this many times. Like, that you know, given what we were talking about earlier here, All of this OHP stuff already is very, ad hoc and how it is configured. And we have explicit relationships and agreements. And so, essentially, it's like, We would just expect via some other out of band configuration that that really knows that if it's being told to do this, it will shuffle in this way"
  },
  {
    "startTime": "00:50:00",
    "text": "And you don't need anything about semantics for that. Okay. It's part of that weird out of band OHP configuration, which is something that you don't have with the generic browser going to some HTTP resource. So that already is a big difference. Well, I actually, that kind of raises the question given as Martin points out 202 already exists. Could you just have a Relay that that, of course, this behavior just returned 202 all the time. Could, yeah, so you could say there's no way to ask for this. It's just like this is really that the relay would know that for this gateway, It always sends 202 Okay. So the case where you would need protocol is where the relay isn't always, only a request. Goodbye. Yeah. And maybe maybe that is a way to make this less of an attractive nuisance. The Yeah. Just just to clarify, I think there are 2 layers of questions here. One is How do you, you know, the relay itself is an HTTP resources So how do you perform this the other layer. And and that's that's a question that can be answered, and it's has to do with the definition of the resource, which means this document might have to update the original Ohio document. It's actually changing the semantics of an existing resource potentially. But that's a discussion to have. The other layer is the one I think Martin was referring to is is that because this is a protocol built for applications that are expecting to be using HTTP, if you're changing the interaction patterns. That are are implied by that, you're changing the expectations there. And that's, I think, what needs more digging into. Alright. Then, Mel, that help hope that was helpful feedback. I don't think we have a clear next step here. To to to hopefully that was useful and you can evaluate where you'd like to go with this. Yeah. Thank you. Thanks for the presentation."
  },
  {
    "startTime": "00:52:05",
    "text": "That brings us to the end of our regularly scheduled programming. Anyone have any other business for the working group Alright. Then, in that case, have a good evening. Have a good morning or afternoon or whatever time zone it is, where you are to remote folks. Talk to y'all later. Like, the other question is, like, what happens if the client is the connection if you're sending the report. No. No."
  }
]
