[
  {
    "startTime": "00:00:23",
    "text": "can y'all hear me hear you we can hear you ned okay great i'm gonna uh let's dive into this so welcome everybody to the rats working group meeting the session is being recorded um let me uh go through a little bit of the note well overview just for all so we're all on the same page um it's uh uh participation in itf you agree to the following ietf processes and policies uh any anyone that's aware of uh uh oitf contributions that are covered by patents or patent applications there you have a duty to disclose that as a participant in the uh or an attendee to the ietf activity you acknowledge that written audio video and photographic records of the meeting may be made public personal information that you provide to ietf will be handled in accordance with ietf privacy statement as a participant and attendee you agree to work respectfully with others and a few notes for a meeting tips just make sure your audit your video is off unless you're sharing the presentation mute your microphone using unless you're speaking use a headset strongly recommended a session blue sheet is automatically generated based on the ietf data tracker logins chat rooms and media echo are connected to the jabra chat rooms on ietf data"
  },
  {
    "startTime": "00:02:01",
    "text": "tracker and there's more information there as well just a quick review of the code conduct right itf participants are expected to respect and courteously and be courageous to their colleagues at all have ex participants are expected to have impersonal discussion participants devise solutions for the global internet and meet the needs of diverse technical and operational environments participants are prepared to contribute to the ongoing work of the of the group the uh uh it's an information sheet all all folks are are available have that available uh thanks to thomas fasadi and michael richardson for volunteering to scribe and take notes for this meeting i will say michael uh you're up your first speaker and so we'll need someone else to volunteer at least during that first talk so if somebody could could do that that would be great and then we're going to jump into our agenda so uh we have a full day today so please be uh you know sensitive to time uh the a lot of time for the various speakers and we'll try to try to fit it all in so first up is a rat's architecture overview with michael richardson and i can i believe i have those slides here so michael okay you're going to project them well there's really only one slide there's really no change since april uh we've been waiting for the shepherd write-up uh to finish and we're waiting for the isg reviews just to start"
  },
  {
    "startTime": "00:04:02",
    "text": "um and the design team hasn't met since april um uh anticipated uh multiple times that we would have to restart when we got uh area director reviews um but uh we haven't gotten there and we're not sure why we haven't gotten there um and i guess there's another new ipr claim that has been the chairs have posted about um and i have no particular opinion about it um and so it's really just discussion of what it is we're waiting for and uh what's going on um and that's about it go ahead kathleen good morning so when as shepherd i did the call for ipr i did receive a message um that we need to wait until around december and so that's what happened and now we have the ipr claim from intel that the working group has to decide what their decisions are as to you know what we do on that go forward so that that was the hold up and so um that that person didn't send it out to the group they sent it individually it wasn't really my place to put that out to the group it was that person's place right so that was the hold up okay i apologize but it was out of control because that's you know ipr stuff we have to um we have to address okay uh it would have been great for the group to know that we have to wait to december even if uh we didn't know why um that would have been wonderful um do is there still some additional area reviews that we should have been getting at this point though the area reviews kick in once it goes into the adq because that's how the um"
  },
  {
    "startTime": "00:06:02",
    "text": "the various people like tarot who does the section reviews knows where to kick it off so so it held it up and i'm sorry i didn't feel it was my place to disclose other people's information or to put some vague message out on the list that would force their hand to say something so it's just you know in terms of maintaining proper behavior and not creating problems i chose not to say something on the list yeah so someone else has got some stuff on the list here so let's uh move are you done with that part kathleen uh yes i just want to get the explanation for your your statement as to why there was a delay okay roman good morning and good afternoon good evening kind of everyone uh yeah i just wanted to comment on a couple things so so uh nancy just put out something on the mailing list i think yesterday or the day before about uh the ipr stuff and just to explain kind of how to handle that yeah we definitely have consensus to proceed with that document but since we got the new information on with kind of the ipr i just want to make it clear about what needs to happen so what the working group needs to do is decide hey we have some ipr claims this may or may not change what we do with the document but we need to positively confirm that we want to proceed kind of forward with the information we have so what would be great on the mailing list uh is not to debate what the nature of kind of the ipr claim is it's to kind of talk about what is a working group we want to do with that document relative to that ipr claim thanks so um do we have are all of the claims"
  },
  {
    "startTime": "00:08:02",
    "text": "actually now submitted or are we still waiting to december for additional information uh i need to help answering that question i believe that there is something more coming in and we should definitely kind of characterize and have that conversation on the mailing list so uh this is ned i believe that the status is that the for the the ipr that intel is aware of they've contributed that according to the disclosure agreement uh which includes what the terms are the the uh there was a request that was made by someone on the list directly to me to identify to to be able to go to the patent office directory and view the work in progress uh they were not able to find it in that directory and the reason is because the uh patent office has not made it public and the patent office has said they will make it public in december okay i understand there's usually some delay for that before it shows up in other places like google i mean but that's the easiest way to place to find it when that happens hank so hi everybody um so whatever here now is independent of content of ipr claims the working group should agree how to move forward i read from the shepherd document and i absolutely agree with that we want to move forward so what's the vehicle we are using here now is someone initiating a call for do we want to move forward and everybody"
  },
  {
    "startTime": "00:10:00",
    "text": "is like yeah we want to do that and then we just barge ahead until we hit the road block that is then maybe coming in december or are we just staying dormant until december i'm unclear on this i would like to have some guidance i would say that if you can make an a form an opinion without having read the patent that our app patent application that you could express a view um it may be that you're never going to read the patent because many of us are advised not to um and so all that matters are the terms so i would say we don't have to remain dormant but we don't have to that we probably can't finish our we can't form a conclusion until uh other people who do wish to read it are able to read it okay just a very uninformed and individual opinion here i think the claim is about section 3 and 3.1 and i have no idea how that should work so i am a little bit uh on the side of yeah let's just proceed with that and see how that is tied uh some ipa i should be tied into that i i'm not sure that's a relevant blocker to be honest i guess it applies to the layered attestation more than anything else is what i think but uh i don't know because i haven't we don't know what the uh content is dave you guys hear me okay yeah um so yeah i think we should uh proceed i mean i had hypotheses about what uh one or more patents might apply to uh whether my hypothesis is right or wrong is um not the main point but for example if there were patents on say the com i think there's two of them right um now the you know total uh let's say that there was one on you know the composite device section let's say that there was"
  },
  {
    "startTime": "00:12:01",
    "text": "one on you know direct anonymous attestation um even if there was one on layered at that station which would be the hardest because that's part of a tcg standard but maybe but my point is this is an architecture document this is not one that one claims compliance to in an implementation per se right you do that to you know eat and other documents and the architecture document covers multiple different ways of doing things so like composite device is not you know mandatory uh direct anonymous attestation is not mandatory even if an architecture document could be mandatory the point isn't that all of rats fits under this particular category there's multiple uh the point of the architecture was to say that hey oh we lost you dave you went mute rationale for saying i think they should go forward because um i think that it is very unlikely that any patent could cover the entire document you could always find some way of implementing a coin a document that would um uh limit the applicability of any particular patent i am not a lawyer but i'm saying based on the things you know that i've seen so far of applying to specific sections i don't think that should block the entire document just because one section that would be narrower would but again i can't comment on the specific patents but just the general rule that says okay if any patent covers one way of doing things and there's other multiple ways of doing things that's one reason why i should go for it anyway and the other reason i should go forward anyway is because this is a it's not something you claim compliance to per se so thanks that's my opinion i would agree with you um roman go ahead yeah hi just to repeat what i put in chat i mean i i want to make sure there is an ambiguity on how we're supposed to handle this in terms of the process so we have something on the mailing list saying hey we have these ipr claims we need positive confirmation kind of from the working group so feedback here is kind of great what we're going to do is request for folks to comment on the comfort level or discomfort on the"
  },
  {
    "startTime": "00:14:01",
    "text": "mailing list and then we will adjudicate that almost in the same way we would adjudicate kind of a working group kind of last call sense of feedback about how how to proceed harness is on the queue one minute left wrap it up hannes tell us like it is can you guys hear me yeah yeah um so i was a little bit uh surprised by this um by this development uh particularly because uh we have made a lot of investment in in the at the station technology and obviously with uh our contributions to open source and we were hoping that many of the developers open source developers um either directly through our code or indirectly through other libraries utilize this and every time there is uh sort of patent claims on documents uh it scares off uh developers unfortunately um they are not going to make an assessment of the patents because that's typically something um they cannot do and and in our case uh we are uh are not allowed to look at those patent claims uh or to make any judgment about it um so so that looks pretty bad for uh the work we've been contributing to overall um that's my first remark the second remark is about the timing and and the way the procedural aspect of it um it it it doesn't look um give a or shine a great light on on the work in the group when uh the co-chair and who happens to be document also um then very late in the process contributes a patent um delays the work uh further it's it's just um it's just not how things should be done in my opinion"
  },
  {
    "startTime": "00:16:00",
    "text": "um and i wonder whether this uh whether we should just take this as an example of not publishing the document at all on preventing further harm to the industry in that case that's my view okay thanks for sharing your view we are out of time for this topic we can bring it up again on friday there uh there's some open mic time so we're gonna move to the next topic this is attestation event stream subscription uh eric voigt hello can you hear me you hear me guys yep all right i can hear you this is gonna be a short update uh because we did get this adopted by the working group since the last iepf um i will because it's gonna take a very short update i just add one claim that i put in the note i don't think patents themselves are bad i think it's the ipr claims actually can protect from other people down the road but we want to make sure of course is that there's nothing that's going to apply royalty-wise so just to answer at least with a few of my minutes hannah's claim i don't think it's actually i think i think patents can be good as long as it's royalty-free right so jumping onto event stream subscription as i mentioned we now have a a in ietf draft zero zero uh there's a slide which we've been presenting ever since the first uh rats group that shows a relationship of many of the giraffes together the subscription itself is dependent on the chara draft which is now an a.d review and roman we're done most of the comments uh and replying to them that should be coming to you in a day or so"
  },
  {
    "startTime": "00:18:00",
    "text": "and that's an ad review as is the basic attestation draft for routers uh which guy is spearheading and that's also an ad review and you know the working group last calls we're just discussing is complete so we now have a just adopted subscription draft with a lot of dependencies that go through a number of drafts okay next slide um basically the idea here is that the subscriber to a router or switch or some piece of network equipment will go ahead and use a rpc to say subscribe to the device and go ahead and give me pcr quotes from that device over time either periodically or let's say whenever something changes on the pcrs and that's really the the magic of this draft is that it's difficult to maintain freshness of quotes if you're not continually sending a a not a new nonce every time let's say values in the pcrs change within the t within the secure chip on the router and the center of the draft really is around mechanisms to ensure that there's freshness being maintained on each of the subsequent quotes from the very first quote that's delivered that identifies the values of the pcr and there's a number of mechanisms do that the draft describes those next slide now without going through all the specifics because you can read them there's a number of things in the document and i encourage you to read them as we progress it includes things like sequence diagrams ways of measuring freshness looking at event stream to make sure that we're able to get the"
  },
  {
    "startTime": "00:20:01",
    "text": "signed quotes from the pcrs as well as the raw data that went into the pcrs in terms of events that are recorded in the tpms and then talks about other things such as filtering the events at the attester doing a replay of those events so you can reconstruct things later and configuring the the stream so you only send those events that you care about to minimize the amount of information on the other side so our plans in the coming weeks and months are to respond to any changes if any on the yang model upon which is a dependent because chara model is going to have some very minor tweaks you know maybe nothing that even impacts this draft and then once the chair gets through the ad review and the isg then you know see if there's any changes there then progress the itf uh part of that into the into the rest of the process that being that once the ietf model for shower is done we can go ahead and do yang doctor reviews and other things for the yang model for the subscription draft and then add anything else that's needed and so that's pretty much it we're just going to continue through the process thanks for your adoption okay so we're one minute overtime there's no questions or feedback we will move to the next topic okay so the next topic is a seaboard tag for unprotected cwt claim sets carson boarman yeah hi you are showing the slides i am good um so we wanted to quickly talk about uccs next slide"
  },
  {
    "startTime": "00:22:02",
    "text": "um so this probably should thank thank you this probably should be known to most people so cwt is a cozy envelope around a cwt claims set and it's defined as a sibo data structure with a tag that you can but need not use depending on on whether it's clear from the context that this tag applies and the ccs actually is uh quite similar uh but but not entirely the same as a jwt claim set so it's a map a video set of something that i called claims uh in in jwt and which we also call claims that way but actually all these claims together form uh the the predicate part of an assertion and this is very useful and it can be used to to make all kinds of signed assertions and so on and what has turned out is that sometimes it's actually possible to do the same thing with some other form of protection for instance a secure channel that makes clear who is making that particular assertion so in in those specific environments you can use an unprotected cwt claim set the same data structure but without an envelope because the the function of the envelope is taken over by some other thing that is protecting this uh uccs and therefore it seems like a good idea to to have a tag for just the the naked"
  },
  {
    "startTime": "00:24:02",
    "text": "ccs itself of course you cannot say naked so we say unprotected next slide um we actually don't have anything normative to say because essentially we are just defining a tag for a data structure that is already defined in 83 92. um so why do we write a document now the reason is that it's really too easy to confuse the uccs with the cwt and that is a criticism that has repeatedly been made so it seems really important to point out how the uccs is just the predicate inside the cwt but not the entire assertion so it becomes an insertion by embedding it in some envelope that provides a signature or some other form of yeah turning it into an assertion and the other reason why it's probably a good idea to write this up is that those security considerations actually get very specific in the reds context so it makes sense to write up how ucs's uccs would be used in the reds situation and specifically what are the requirements that reds would have on a secure channel next slide so yeah writing a document always provides some some opportunity to do little things at the side and uh one thing that came up but but hasn't been incorporated in the latest draft there is just a branch on the the repo for that we could actually provide a cda specification for the cwe claim set"
  },
  {
    "startTime": "00:26:01",
    "text": "the the cwt rfc predates the completion of the cddl rfc so at the time it requires some some special dance uh to have cddl in in a normative document and we could fill in that gap now which would make it easier to use cwt in general not just uccs so this is one thing that that we are proposing but that that we might still agree not to do then we would just do another document and have to find a home for that and that's it's lots of overhead for for very little gain the other suggestion that has been made is that we could use as use this as an opportunity to do a grand unification between jwt and and cwt and um yeah um this is probably not what we want to do and uh i mean even if we do start such a grand unification project we probably don't want to put it into this document because the timelines are very different next slide so where are we we still have to accept or reject the idea to end the ctd specification we also have a review from thomas fasati with lots of great editorial suggestions that we want to include so that there's a little bit more work needed that hasn't happened yet and the plan is to submit a new version with or without the cddl and with that editing and working group plus call that questions"
  },
  {
    "startTime": "00:28:04",
    "text": "thanks on thecube click all the buttons okay i clicked all the buttons thank you so yeah thanks carson for that uh presentation of the state of the affairs i think uh we are really okay on the uh the scoping here today that has been discussed uh multiple times already and i think everybody got somehow used to the idea that uccs's are context specific and i'm happy to see this in rats as a first iteration first of all and then um i i think that uh yeah we really have to get our uh backlog of uh comments uh done and and thomas already uh i think unfortunately for him is aware of that so i think it will be done in the next uh course of the next weeks in in contrast to our typical pace and so what i'm i'm unfortunate here is yeah we will do the update and and please stay tuned because that could be the uh id that will have a working goobras call thank you lawrence is on the queue yeah hello um i just uh the um my present presentation that's coming up next has a whole bunch of stuff in relation to that so that's all i wanted to say is there's i have a lot more comments coming coming soon anybody else on the queue all right so uh looks like we're done"
  },
  {
    "startTime": "00:30:00",
    "text": "with that topic next is the ndds station token r11 changes this is lawrence fund blade lawrence you're up yup all right next slide so uh i'm uh commenting uh here now about um the uh uh dash 11 version of eat that was released like a two weeks ago it's a pretty large set of changes this slide here shows the planned contents of an eat just the kind of just the areas where the claims are different different areas for different claims i'm kind of pointing out down at the bottom is a little different than before and that yellow box down at the bottom is claims that are suitable for attestation results so one of them is the dloa which i presented at the last meeting and then um there is verification results and then over uh overall verification results and software measurement results are also claims the overall verification results is not in the dash 11 draft next slide so waiting for next there we go so you can see the blue arrows are indicating where work was done in the on the dash 11 draft so a fair number of areas personally i think all of this is ready for last call so um the only things that are this this shows a little bit of uh um a couple areas where maybe there's some comments about whether it's ready for last call or not"
  },
  {
    "startTime": "00:32:00",
    "text": "but personally i think that it is all ready for last call so i'm going to go through yeah let's go to the next slide so uh one of the uh this this is a slide i've been presenting for a while of that work was needed to unify terminology with the rats architecture and um remove a lot of the text that that's uh that was there before there was rats architecture some of that text is is like three years old so that's all done we rely on uh rats and cwt rats architecture at cwt for verification procedures so that was removed there's a lot more examples so that's a big chunk of work that's done uh next slide so kind of this is the kind of the the uh laundry list of um uh changes that were done in uh the dash 11 draft i'm going to kind of go through and speak to them uh one by one i don't have details on each one but i don't think that's necessary so first of all um the the technology is now or the terminology is now consistent with the rats architecture and cwt and jwt documents i removed the operating model procedures and that now there's a reliance on the rats architecture cwt and jwt documents for the operating procedures i added a claim as for a simple software name and software version as an alternative to having a coast width to describe the software um coast woods have the are fairly large and complicated when you just want a software name uh or in"
  },
  {
    "startTime": "00:34:00",
    "text": "software version and cos widths are not available in json so that's why that's there uh there's the dloa's claim that was presented uh last meeting so that's all in their detail um there is a software software results claim so this claim is you know the um description of the uh for for attestation results that describes the results of comparing a software measurement to the expected values that was i believe discussed last meeting as well but wasn't in the document so now the the oem id claim uh was improved um it's clarified that it's only for uh hardware it's it wasn't clear that that's what was the case um it allows uh use of uh the pen the private private enterprise enterprise number also allows a randomly generated oem id claim which could be which can be a hash of something else so uh then there's a a lot more examples the lamp examples are all filled in in uh in detail there are several coast coswood examples in there there they they verify against most of them verify against the coast with cddl so that the whole document builds where the examples in diag format are verified against the cddl in the document and cddl pulled in from coswood and suit there's also example of a a measurement"
  },
  {
    "startTime": "00:36:00",
    "text": "and a detached bundle which i'm going to talk about in a slider to here okay so now uh um has cddl in there now for a claim set um this was the the same as the claims that that karsten was was talking about um i'm going to go into detail on that in following slides it defines a ujcs the json equivalent of a uccs this is what carson thought we should not define i put it in the document to have a clear articulation of it uh so um um so i i actually i see you you see the comments here i'd actually appreciate it if you guys uh let me finish and go through a lot of this before you jump to conclusions and things um uh that would be uh i think that would be really helpful to see what what i actually have to say about this before you are going there um so there are a bunch of clarifications and improvements on nesting of one eat inside another that and the the work on detached bundles actually drove me to a lot of the structuring of the cdl to get that all to work and to validate so it's it's to me it's kind of a uh you know it's a real nice goal here to be able to write the cdl uh for the whole specification and then have it automatically verify against the the diagnostic example so that really kind of proves out both the the examples and"
  },
  {
    "startTime": "00:38:00",
    "text": "the cdl in the document okay next slide so those are the slides we had i don't know if there are questions or comments we want to talk about hang on what happened to the dev slide that's in the next uh that's in the next batch if you want to jump to that we can do that yeah i've been yeah okay i said many times many times that's where i wanted it oh okay yeah i know that yeah this is yeah because so okay so this is the dev slide so this is still part of the the uh dash 11 changes um and so i'm still in my first block of of work here um okay uh so at the tax to eat bundle um the basic i'm only going to introduce the topic here briefly um just to get you so everybody kind of has some idea that it exists i don't want to have a long discussion about it i don't think there's time for it um the um so on the the the picture on the left shows and eat which is you know a uh some claims it claims that uh as carson i believe says a ccs if it's cbor format which has the cose headers the coset payload and a cose signature so then if you look at the kosai payload there's the claim of ueid and nonce and then there are sub modules in the there's a sub module section and one of the sub sub modules is named xxx and it has a software name and software version so what's what detached here is that you can take the uh the claim set for xxx the sub module which is"
  },
  {
    "startTime": "00:40:02",
    "text": "a seaboard map that has the two claims and detach it so it goes outside of the eat and in this particular uh and then what goes in the sub module section is a digest of that or a hash of that that claims that so you're in in detaching your you know you're able to take the claim set and um transmit it uh outside of the heat um in a uh some other some other way so um there is uh the the detached bundle is a way to take the the eat and the detached claims and send it together you do not have to send it together um but to find a way to send it together so the reason why you might do this is it allows you to build a smaller a tester that um basically can be kind of a like an attestation hardware block where the claims are built outside of the attestation block and then the claims that can be the hash of a claim set can be fed into the attestation hardware block through something like a pcr that a tpm has um basically when i when i you know for for a long time i've thought that it would be a good thing to have a to be able to build such a hardware attestation block that does eat um uh any format so um this is the the way to do that so i uh i"
  },
  {
    "startTime": "00:42:02",
    "text": "don't want to spend a huge amount of time having the discussion on that right now i didn't there wasn't really time in the agenda for that so um and this is not my top priority to get through that it's more the the cw jwt issue discussion is more important to me here so so that's uh detached each bundle so you can go look at that in the um in the latest draft um uh so uh that is it for my first uh part um so i think we can move on to the next part here okay so the next topic is eat topics in general so we can move to that if you like there is one person hold on um i see dave thaler on the queue i didn't know david you had a question we have two minutes left on this slot so yeah i do have a question but you're free to tell me if you'll cover it later but i suspect not because uh uh my comment is so first of all uh i want to say i like what you did with the sub mod stuff so i think that's very useful thank you um the comment that i had was you know you had the slide that had all the green stuff saying ready for last call so i'll uh repeat my comment now along with a thank you for another change that you made um i think the document is ready when it this is a personal opinion when it also meets the teep requirements and since i've mentioned this at the last two ietf meetings i'll mention it again that the teep architecture had uh five requirements for things that were not in the old eat spec um i and i had asked can we merge those into the main document and out of the general section of hank's draft suit rats claims because they're not specific to teep or suit they're just general things one of those was version and so you mentioned you added software versions now you have both software version and hardware version just a separate claims and so i think that one is now checked"
  },
  {
    "startTime": "00:44:01",
    "text": "so thank you for adding that i think that checks off that and i think that obsoletes what hank you had in the uh in the version claim there there's uh four other ones that i have not seen in there and so uh my question is and you may not have an answer right now is is there already some other way to do those or do you plan on adding those because i think that's what would block going to rfc in my opinion those were device identifier vendor identifier class identifier and component identifier and hank's document and t the t protocol is referencing those right now as well as referencing version but i'm happy to update that to point the software version now that you have that in there so yeah um so uh i wrote some emails about that um i had some comments about that and i uh i don't remember what i wrote right now in detail um i know um i i thought some of them were very much suit specific and not lined up with uh um general stuff and e those four are ones that are not suit specific there's other ones that are but those four are ones that we'd all argued including on the list discussion a year ago that none of those are suit specific well there's other ones that aren't sure the the detailed discussion um of some of those those things i i think we need to go back to that discussion and and so just look at that that i don't think it's ready for last call in my personal opinion until those four are either in there or until there's an argument that says there's already something in there that covers those four requirements so that's my opinion so and i see hank is in queue so he has a different opinion so i think yeah it's also probably not different but uh um the these these kinds of identifiers and identities uh we are dealing with in in that's like of course on multiple um conceptual messages and one of these is uh the reference integrity manifest the concise one so"
  },
  {
    "startTime": "00:46:01",
    "text": "i think we can borrow semantics from there what i really like to have is to us don't see that semantics change anymore because we took like a year with several um let's call them harvard of trust stakeholders to to get them right and so uh so if you want to borrow them um maybe that's not for the current eat it but but we can we can of course i think uh either includes uh a notion that and these can be these claims for each please add them to cwt registry or do another id that says okay and these are about identities of various things and now we have this id that ties us all together so so again i wouldn't want to stop each progression here but i want to say that we have several identity related claims that i think that working out quite well um and we're happy to have yeah my my request here really is for engagement um that i think that's the most important thing um uh i feel like i haven't had comments about a lot of the stuff and people haven't read them or or or and stuff so um please like gary said file issues um and follow follow up with the comments i mean that's that's what i i think is really important here yeah the the thing is that that we are not working on each here we are working on the other side of the things that's coming from supply chain and endorsements and such so so uh yeah our direct need is not to fire a issue on it um but but maybe we should align anyway so so the synchronization is i think key but i would not put honors on one of the parties to to to to jump into the pool of the other uh so so maybe we should join"
  },
  {
    "startTime": "00:48:00",
    "text": "and and and some some design meetings here i think i think we're we're out of time on this discussion if we have time during open make we can continue that discussion there but i think we need to move forward yeah so next topic is also lawrence all right so i'm going to talk about these three things here uh cddl for a claim set that is for both stibor and jason for on talk about ujcs and talk about nesting eats next slide so i believe there is quite general agreement that cdl can be used to define stuff that is both to encode in both jason and cyborg appendix e says how to do it i see lots of other protocol defining drafts doing it now there was an email discussion and there was consensus on that i see seabor and jason will coexist for a really long time i mean seabor has the the compactness that jason doesn't have and jason is you know used very very broadly in back ends next slide so we have um i mean my sense is that there is agreement that um uh eat and all the eat claims are to be in both seaboard format and json format so eat is either a cwt or a gwt my understanding is that there's consensus on that and that that's what's been in the document for a long long time now a couple of years"
  },
  {
    "startTime": "00:50:00",
    "text": "there's been no objections to to that and it's kind of been the the way of proceeding um uh karsten yeah um i i just wanted to point out the difference between what what other documents that define both sibo and and json representations of the thing same thing do and what what you're trying to do here um cwt was never designed to be a mirror of jwt so these are two different standards where crut just was able to borrow a lot of stuff which is nice to to get the thing kick-started but there are also things that are cwt specific and it will in general not be possible to have the same city for everything that is in cwt and everything in jerusalem because they are not the same thing and so i think we need a slightly different approach to to solving the formal description issue for cw3t and jwt and i would love to find find a good way to do that but we first have to give up on the premise that these two are just interchangeable literally they aren't so um i'm i'm looking for i mean i again i can understand to some degree what you're saying i don't know exactly uh what you're seeing as the difference here um but i i understand that um i'm kind of looking for a solution to be able to do what i thought we were agreed on doing and eat where uh eat was both could be either a cwd or a jwt"
  },
  {
    "startTime": "00:52:00",
    "text": "so i'm open to solutions here um uh on how to do this uh other than what i've what i've done so i put you know there's a bunch of stuff in in in the dash 11 draft there was stuff in the dash tender after the dash 9 draft for all of this before the stuff in the dash 11 draft is much improved um and it's working with validation in a lot of good ways um so so i'm going to continue on on here and because because some of the some of what i'm doing here is kind of problem statement and describing a solution that i i've come up with um and then let's see um what comes out of that so um uh it claims that um uh [Music] i mean that's the sort of the core of the uccs carson referred to this as a ccs um so i have defined cdl for a claim set and i'll show it in a few slides so a claim set is basically a group of label value pairs that that it you know pertain to a device a subsystem a transaction a result something right um both cwt and jwt revolve around the claims that they're both groups or a label value paris preston referred to that as an assertion um so a claim is that is it's a convenient unit of conveyance between roles and actors and if you have some things to say between this role and that role um putting in a claim set uh works pretty well the other way to look at it is that it is a really useful structure to sign and or encrypt so the you know the payload for cose or jose so um so this this part seems uh largely in common between cwt and jwt so um seems very useful to have cddl for"
  },
  {
    "startTime": "00:54:02",
    "text": "a claim set that and that seems like that can mostly work for both uh uh seabor and jason the the definition the cdl for claims that is the same in uh sea war and jason i'll get to that in more detail so then you go off and define all the individual claims in cdl and they just plug right into actually using a cdl socket they plug right into the claim set cdl structure um so then so that's when you're constructing claims you write them in the cdl to plug into the claim set structure when you want to have a pro when you're you're designing a protocol that needs to have a claim set in it then you just refer to uh claim set and uh that you can just use all the off off the shelf use that use that off the shelf and you know even not any station product close to this could do this and then you're you're just writing cdl once for jason or cbor uh so um uh karsten go ahead yeah i agree that when you design new claims that are designed to be both in jwt and cwt it's certainly a relief to to only have to write the city there once uh so i think that that's a good thing and and developing some some standards convention agreed way to to write the city is definitely a good idea so i'm with you on that i'm just not sure that we we can retroactively apply this to things that are already out there yeah okay"
  },
  {
    "startTime": "00:56:03",
    "text": "um so uh then uh with with um sub mods uh and you know nested tokens it became interesting to nest one claim set in in another so having the you know to write the cddl for that uh i mean i needed to have the the cdl for a claim set um and i'm going to i'm going to tell you why i even want to put seaboard claim sets inside json claim sets and vice versa next slide please okay so here's the uh the cdl for a claim set um the really the important important important part is the first line there so a claim set is a map or the first entry in that in that map is a plug claim set claims where you plug more claims in so then and the the second line there the with the uh dot feature control that's uh a uh kind of a catch-all to make sure that anything that is not defined uh in the in the socket um uh is in the right format with the label but your primary thing is the the cdl for uh claim set claims so then what you do is when you define a claim in this case i'm i'm giving an example of the the subject claim from both cwt and jwt which is just a text field you write that line in the second box there where you say slash equals label equals greater than text"
  },
  {
    "startTime": "00:58:01",
    "text": "so that's that's the definition of a of a claim so if you're off inventing claims and um you know some other document in suit or something like that you're basically writing things that plug into that socket that look like that and then because uh labels are integers in seaward or you really want them to be and that's kind of the point you wind up with assigning the label twice you can actually assign it with a slash equals as well so the label can be either the the integer or the text string and json um next slide so here's the cddl for the seven claims in cwt and jwt the one place you there is an issue is that the cti jti uh claim um in its text in jwt and bytes and binary in cwt so this is definitely an issue um between the two um i don't have a solution for it um it's also an issue generally where um you know a claim in cbor is bytes um by string and it needs to be base 64 encoded in json um and this this comes up yeah you know as an issue with the cdl validation tool so kind of been skipping around that one but that that's an issue i was kind of looking for some solution to it um so uh next slide there's uh hanks on the cube by the way okay sorry i keep switching between the yeah go ahead actually that's just going"
  },
  {
    "startTime": "01:00:02",
    "text": "yeah but you're bringing up the good arguments here so uh i would also not have a good solution how to deal with bytes and if you're going to into the tech space um that that seems to me that yeah as i see what the super said there might be a predominant way to express this and then you transcode it down to jason it could be possible but yeah but that's not talking about this so yeah but sorry sorry for being in line so just please continue yeah um so then now that we now that there is i mean this is the cdl this is all taken directly from from the dash 11 draft now that we have a cdl for a claim set we can write the cddl for uccs and that's really really simple uccs is either tagged or run tagged if it's untagged it's just a claim set if it's tagged it's a claim set with a tag so i believe that lines up similar to what carson presented uh next slide um in uh for uh ujcs um the uh you know the kind of equivalent of uh [Music] of the uccs there's no tagging in jason so all you do is write a ugcs message is just a claim set so this is in the dash 11 draft as it is right now so the definition and there's a definition and description of a ujcs in the dash 11 draft there's a section for it um and i'm going to go in into a little more detail on why i thought we needed"
  },
  {
    "startTime": "01:02:01",
    "text": "it and um but i i don't feel like it has to stay in the e document um you know we're kind of trying to figure out a solution to fit this all together here so um i i put this stuff all together in the e document so we would have something to look at and work on that was all written written down in one place next slide okay so here's why i think uh ujcs is important so um jason is far more widely used in seabor if uccs is important why isn't ujcs important i mean we're taking the trouble to define uccs why aren't we taking the trouble to find to define ujcs um and you know today uh backends use json in a huge way they have many mechanisms in place for integrity integrity authenticity and privacy usually tls no one is feeling like they have to use jwts [Music] in the back end as far as i know they're not that widely deployed jwt has this kind of null cipher thing that you can do um to uh to have a kind of the equivalent of a ujcs but it's um kind of lar a bit large and awkward basically you have to construct a a jose message with algorithm equals null um so it seems kind of like why would you do that i mean i think the reason they did it is because um we're trying to be explicit that this uh"
  },
  {
    "startTime": "01:04:01",
    "text": "this thing is not uh signed and secured so you should know that um and you should know you're doing something that's not signed into outside insecure maybe it's the sort of the the spiritual equivalent of all the security considerations that are in uh uccs but i mean to me um that uh is sort of an unnecessary and awkward overhead um so um you know attestation results i think is something that we're uh from the verifier to the to the rp is usually uh you know b2b kind of back end stuff so here jason's highly appropriate um and people probably look at us funny if if we were saying you should use seabor there so uh that seems like a place where ujcs is useful and where we would want to be using ujcs next slide um so uh maybe some people have uh have uh disagree about the first point about it not being much work but it didn't seem too much work to me um i'm certainly not talking about going back through all the the entire cwt and jw registries and like you know making them all retroactive and cdl for them and all that so uh just mainly the seven claims that both cwt and jwt have um writing just writing cddl for those because some of those are definitely reused in uh hate i mean we could even not write the cdl for some of those what's what's really important is that the the central uh claims that document um and then you know if you're if you're"
  },
  {
    "startTime": "01:06:01",
    "text": "writing a ujcs document i think the security considerations from uccs would be exactly the same okay next slide um so uh it it seems awkward to have a uccs without ujcs um seems like there will be some you know you'll be going uh you know re-encoding uh claim sets uh sometimes um between seaport and jason i mean i'm working on a tool that does that um uh it makes uh all the nesting constructs in eat the sub modules and the detached claims that's more complex today people send json maps of label value pairs all all the time without jwt i don't see a logical reason why a seaboard claims that can be set in the clear and adjacent claims that must have you know can't be must must have that jwt alg none construct okay uh next slide all right so um now this is getting to uh some of the reasons why um i got to to this in the the design work um so why do you nest seaborn coded tokens in json encoded tokens and vice versa why do you do that the answer is com composite devices and the testers um so you're going to have i mean in that there's there's the the diagram from the rats architecture document there um so you're going to have the testers feeding tokens into other attesters so you can see a"
  },
  {
    "startTime": "01:08:00",
    "text": "tester b and a tester c are feeding uh you know fully full signed attestation evidence into a tester a now you might be assembling a a device like a car or a phone or maybe a whole nuclear power plant or something like that where you have you're getting uh devices from lots of different vendors and you want to aggregate them all next slide please go back can you thank you um uh so um you're gonna you're gonna be getting devices off the shelf that happened to have a testers and they are not as necessarily all going to use cbor or not all use json and you don't want to when you're you know building a composite device you and that that you want at a station for the whole device made up of all the different uh components you don't want to have to say well i can't use that that device because it's a json a tester and i'm only using c4 you really don't want that so [Music] you that put push puts us to the point where you need to put cwts inside gwts and gwts inside cwds so you've got to do that so um there's also the scenario where all the composite evidence might not be signed so you might be putting the the output of a tester b might be a uccs and that might be okay for that particular architecture because of the way those devices are put together and it's understood that you know chester b is producing um some uh some i mean actually the whole in in this diagram tester a b and c could all be um"
  },
  {
    "startTime": "01:10:01",
    "text": "producing tokens that are not signed because you're relying on tls to for the verification to go to the verifier so that's why that seems like you need the mixed um now one of the things i uh clarified in the dash 11 draft was that this this mixed encoding the only place that's allowed is when you're putting one token inside another you can't like you know have a uh a few claims and json and a few claims in cbor i mean the whole token has to be either siebel or jason it's just when you're nesting tokens that you can go switch between seabor and jason next slide so here's the summary of the um all the the six token formats um so there are um sign tokens in seaborne json there are unsigned tokens in seaport and jason and there are devs that are in seaboard adjacent so you get you get the fan out of six different token formats and any one of these tokens can be put inside the other uh one of these tokens because you want the full flexibility of to put stuff in so um the way the dash 11 draft handles this is that it uses seaboard tags uh so a sub module that is a nested token has a seaboard a seabor tag or is a seabor tag that says which it is whether it's a cwt jwt and so on um if it's a if it's a json format token you know how"
  },
  {
    "startTime": "01:12:02",
    "text": "do you put how do you do that in jason because jason doesn't have tags um so i came up with this this structure the the cd cdl of which is there which is basically just an array of two things a type string and the actual token so trying to be as simple as possible um and also trying to be uh make use of seaport tags and like you could do this simple tagging thing in cbor as well but i decided to use seaport tags that seemed more natural so than to use the same structure in both so this nested token is different in json and in seaport um i think i'm getting towards the end here um next slide yeah okay so that was it go back you can go back um so in order to construct cdl for all of these things which i've and and examples and verify all of them i had to have um a that definition of claim um that works in both jason and sabor so i mean there's a consistent hole there in the the in the dash 11 draft where all of this stuff is is working most of it is working against the working against the examples so i guess now is probably the time for a discussion until we're out of time i'm sure there's a lot of comments on um we have two more minutes for this topic there's a couple of minutes for this topic and then we'll have five minutes for"
  },
  {
    "startTime": "01:14:00",
    "text": "uh to cover uh last call you know issues okay i don't see anybody in the queue karsten's on the gear yeah yeah i just uh sent a couple comments to the jabba to the message queue um i think what what you're doing here is some some pretty interesting um on the cw20 and jwt world that i think requires semantics and not just the syntax how to carry these things around so it's for instance not quite clear what what the claims within such a detached thing or nested thing have to do with the claims in in the main uh cwt and um i think it would be a good idea to to understand this [Music] this processing a little bit better and i think it should not be a problem to actually put a signed message inside a claim set because in in that case it's clear what what is being signed and it's also pretty clear that um the the signature of the nested thing is not influencing uh any individual claims in the outer claim set but i think putting information in there that is nested and even of a different format than the the main claim said that that is more complicated than then may appear on on a first look"
  },
  {
    "startTime": "01:16:00",
    "text": "so i i would be a little hesitant to say we already understand what that means um tons of different claims can be defined and these claims interact with other claims and come up with unfortunately relatively complicated uh combined semantics what we call feature interaction in istn 25 years ago is unfortunately coming up here again so you really need to understand how these things work together when they suddenly are hidden away in a hash that you may not even be able to resolve at the time when you check the main claim set so all i'm trying to say is this needs some some significant analysis before we really understand what what is being designed here and i'm all in favor of doing that analysis yeah so let's separate the semantics from the syntax um i mean the semantics of a sub module and a nested token i mean that those those are you know that issue has been there since uh you know day one with sub modules and it that issue is there uh whether we combine you know do both jason and seaport or not um so and i mean and then there's some discussion in the draft and there's about that and there's there have been discussions about that so i mean uh personally i thought that was a settled issue because it it has been there for years um uh what is uh at issue here for me is how to do you know how to do the keyboard inside the json and the jason inside highlight this yeah and then the jason said the snowboard how to how that how to do it syntactically and how to do it with cedl um hank yeah hi uh lawrence um yes i'm i'm a little bit yeah sorry to say that i"
  },
  {
    "startTime": "01:18:00",
    "text": "think we should some to do some divide and conquer here i don't see the uh uh ujcs and uccs converging anytime soon because it's not a central problem it's a it's a it's a process procedural problem and a semantic problem and and i really want to have it done like seriously and then another pose of doing that to doing that work but i would like to cut it out and do it in a different place to be honest so that's just me maybe but um if we are starting to to trying to solve this here in this document this will take more than a year i am afraid so um so so i'm not against tackling the problem actually i actually want to have a solution that makes merges the rams of of people reading and working with something json an everyday basis but in the end what they really want is to have something useful and and and scalable and similar and it should be somehow feeling like the same thing but but i don't know if this idea is the right place for it first of all but i'm i'm i'm really really interested in solving a problem afterwards so i mean this this is all because of sub modules and sub modules are pretty important part of each yeah and then stay there they're encoding stay within coding stay with one encoding and then later on enable nesting of different encodings and semantics of the encodings and the caveats that we inherit there later on right so so no note also that in some of the claims uh like the manifests claim and the measurements claim um that allows other formats that are"
  },
  {
    "startTime": "01:20:01",
    "text": "pluggable so you can do co-switch suit and and a switch um so you can put like an xml document inside a any token that's and and we have to do that server as a value that is agnostic to the cwt ram at the very least or it's a it's a co suite and then you can you can understand the uh the structure because you're doing the same encoding but but i think you're you're comparing apples and origins sorry yeah no maybe maybe here right so yeah we're gonna you know we're gonna have a conversation on uh last call issues this sort of feels like it's the last call conversation do you wanna yeah move to the next uh segment yeah i wanna one one other comment here um uh is i mean i i hope everybody can see how i got to where i got to and um you know if we're gonna try and trim and and sidestep this issue maybe we figure out which what what do we do and do we give up on the maybe we give up on the on the json part um i'd rather give up on that than the other than the the sub modules part um and then i also would really like to hear um uh what the issues are that are so difficult here at least uh write an email and get and give me some idea here um i mean i know of a few issues but uh you know hank and carson have both spoke about uh that these these issues are quite large and i'm not sure i see that and i think it would be really helpful for the group to understand um uh what those issues are okay thank you thank you so gary you're up next we're gonna review uh eat open issues um i hope everybody can hear me so this will be brief i know we've been discussing a little while and this will not include uh if this is not include the previous discussion on uh"
  },
  {
    "startTime": "01:22:01",
    "text": "some modules uccs etc so let's move on to the next slide please okay um as per ietf one one one i had submitted um i submitted materials that uh it to as part of that meeting i didn't get a chance to present so i had to post those uh after the after meeting but i at that time i said i would be classifying issues in github repo as last call blocking um so far i have not found i only we have only one issue unresolved that's currently last call blocking and i don't believe that that should be a uh that should prevent us from going to last call now that's leaving aside any of the discussion that's happening on the chat window or in the uh or prior in the prior half hour of discussions so far let's move on to the next slide thanks the last issue is a rather old one as you can see from the number it's 15. uh it is so broad that i'm not sure i can close it in good faith at the same time there's been no activity on it it's just a general comment on should must consistency um i do think we can close this issue um mainly because i think it will cut mainly because i think it's just too uh it's just too difficult to resolve and i expect during the uh during the course of resolving last call comments this this will come up again should must consistency and um so i i and by the way just an overall comment i view last call as the first step towards our eduard's long process to rfc not the last step and i'm expecting to in expecting the document to undergo several revisions as we uh as we resolve not only working group last call comments but ad comments as well as a broader review ayanna iesg"
  },
  {
    "startTime": "01:24:02",
    "text": "etc so uh so i think uh some some uh some people may be in the impression that last call is a is is a last step it is maybe the first small step towards to start to towards the last step but it's really far from the last step in my opinion okay let's move on and i understand the time so i'm gonna go quick okay there were two issues when i submitted this deck that were current were unclassified one was a general issue to fill in list for the iana uh for for all the to be registered claims i don't believe this should be last call blocking um i've actually submitted a formal request for the cwt claims review for an expert review on the claims that have been identified in the each spec i haven't heard any response on that yet ella but um but uh i expect that that's in the queue for cwt claims that's your expert review um then the final one was uh say the sub modules related to it related to target environments actually i don't believe we should resolve that either prior to last call because i would like the i would like to see what the rats architecture uh experts when they do actually review this document as part of the last call actually say about the concept of submodules so let's move on to the last slide okay yeah okay so um just to be clear i think there is some discussion in the chat window we've already been you know at least i've been under the impression that uh the github the github repo is where we file issues um it is sometimes a little difficult"
  },
  {
    "startTime": "01:26:01",
    "text": "for me personally to track issues on the mailing list so i i'm not a you know i'm not saying we close out the issues now but i think uh i think i think um what i would recommend to the working group to think about is if there is a claim that uh that that needs that you they feel needs to be added to this fact first review the spec to see if an existing claim that's already described does not meet the yeast case second consider whether the uh whether whether it makes more sense as a profile and each does have the concept of profiles so um so there are so so the you and that would actually mean that you can actually bring in a suitable claim set uh for for your particular use case even after it goes to rfc that's all i have thank you thank you so we do have some time to discuss readiness for last call and so there was some some chat on the list of people expressing opinions that they think it's ready uh from the perspective of the group that's here today we get get a sense for who who is uh thinks it's ready to go maybe we'll use the show of hands tool well so ned are you asking the question or you want to have the discussion first i want to have the discussion yeah yeah so you have two people on the queue yep dave taylor all right and uh again you guys hear me okay i know i glitched for a second there everybody over here okay yeah yeah okay cool uh yeah and thanks uh gary and and lawrence for your comments uh i"
  },
  {
    "startTime": "01:28:00",
    "text": "appreciate them uh and i'm probably not going to say what you think i'm going to say but i'm going to say that see a couple of potential ways forward that i would like to hear the working group's opinion on uh this is specifically on the the cheap question i raised i think we had the discussion before that for the class of things we're talking about a profile is not really what we're talking about for this class of stuff there's a separate things that we're already having a profile for but out of the otherwise there's at least three potential ways forward just summarizing things that have come up in the chat one is to say uh well we could have a separate document okay that ex that adds some additional general non-profile specific things to to eat and you really have to have the eat document and this other document we gotta wait for before uh you can actually do an implementation in certain contexts that would need the claims that are in that one okay so that's one possible way forward that's just a separate document another way that we could do things is to say uh any comments here is done as part of last call meaning you just issued the last call on the current version and you treat this stuff in which case we might have to do a second round of review and stuff and gary kind of mentioned this one which i agree with your comments carrie that says you know uh you might have multiple rounds of review right last call is the beginning not the end right plus one to all of that and so that's one way of doing it in that sense you know nothing's really last call blocking but there are times that working groups do multiple do last call multiple times okay and so um i don't like having to do it multiple times if you can avoid that and so i'm trying to minimize work but uh that is a possibility and then the third one uh lawrence or somebody one of you two had said okay it's possible if there were non-controversial stuff to add that in there and then start working your last call um my preferences for that one if we can do that and that's just because i would like stuff to be reviewed all at the same time rather than doing multiple rounds of reviews and so that's why my preference is to treat it as if you can do it dash 12 add in uh the uh four little sections out of uh draft perk holes uh if you think that those are non-controversial and lawrence i did see that you said within the next day or two you do an evaluation that would be fine"
  },
  {
    "startTime": "01:30:01",
    "text": "with me to defer the decision until uh and then talk about it the next next rats meeting if you've had a chance to do that during the week so that would be lovely but either any of those three possibilities i would say would be possible ways for and i would not object to any of those just my preference is to do it as part of the first working your blast console thank you hank is on the queue so thanks dave so first of all any decisions here should maybe if there's only a few days of more input to make a decision i think that is fine of course especially in the course of the itf meeting here right now um having said that i do not see a easy solution to resolving anything uh in in a blob as i think was your um preference so unfortunately i have to say uh let's get the cbo based stuff that was the initial cwt space out now maybe anchor some preliminary sockets in the document to enable the next document and do it in parallel that's me just one opinion i i see the point of of resolving this all at once makes a better document i i really see that um unfortunately i don't think this is will be done until the end of next year to be honest curious on thank you yes thank you um yeah i guess one general comment uh following up on dave's uh dave's um we can go through at least on the tt items and before you know hopefully me and lawrence can turn this around with the next day or so and we can uh and we can even put out you know a version 12 before the friday meeting i"
  },
  {
    "startTime": "01:32:02",
    "text": "believe i believe the uh submit tool should be open again today i guess uh going back on what hank said though on the general uh cddl versus uh versus uh jot representation well uh unsigned uh unsigned uh json claim representation that wants to discuss would it be possible hank in your opinion to actually to actually if you think it's going to take a minimum of a year to actually potentially take e to rfc but then have a follow-up document that builds off of each that could that would also be it's uh it'd be its own standards track um which we do all the time updates rfc xxx for instance exactly yeah yeah i think this is consecutive i think eid is our our basis and and from there we can we can build a lot of rather cool things i think from it and and and i think we should not stop um following the route uh or the trail that lawrence is blazing here um but but i think we should should cut it at some point because we are really waiting for this and and i like i like to see a good transformation i like to see a mapping of semantics i'd like to see a matching of semantics to current solutions with maybe some frosting on it so it's intuitive all of that but um yeah i i think this will take time and and yeah but i really i really think this is uh we can build the basis and add on thank you that's that answers my question okay so i thought i heard some interest in a version 12 before friday"
  },
  {
    "startTime": "01:34:02",
    "text": "does that imply that we would continue the last call discussion on friday can we do that sorry to sort of jump in the queue we can well can we yeah go ahead and then i'll ask the question i usually say we we we can do what we want to do as the group but maybe you can jump in nancy yeah my clarification question gary is um you're volunteering to to rev version 12 to address some of the the teep suit stuff but to hank's comment of calling out the cd this that i can't speak sorry um would you be able to address that also with the version to do what hank is asking uh basically turn the document into a c bar only document uh remove all the json stuff out of it i think that's what i understand that that seems not possible by friday and i don't know that there's even consensus that that's what we should do he's the only one saying that at this point right hank you're in the queue not uh lower my hands um i'm apologize and then yes the the the lawrence that is not the thing for friday i think that the friday ask was the cheap claims that the dave highlighted and then not not the jason uh uh just just being clear yeah just being clear that's all okay and thank you for clarifying yeah okay"
  },
  {
    "startTime": "01:36:03",
    "text": "okay so um sounded like uh there was some consensus for that dave's in the queue i just want to say on that nesting point uh separately i think the teep use cases do require the ability to do nesting although teep is only using seabor uh independent of the cheap stuff my preference is probably for the same reasons as florence mentioned to keep the json stuff in the existing document i think there are use cases for json and so i would rather do minimal changes and try to get the document out sooner even if that means that uh you know json nesting or something like that was in a separate document uh and i say that because i don't think anything is currently blocked on it but i think it's an important use case and i don't think it's worth major um changes to the document that might be destabilizing which is what i got the impression from lawrence that it might be destabilizing and so we could pull it all out there but if it's going to destabilize the document or whatever then i'd prefer keeping it in there that's my preference but again keep us blocked on having nesting in a seabor which it already supports in fact the new way of doing nesting is even better um thank you so just jumping quickly in here so now we have the uh choice between um delaying it to be honest sorry and therefore not satisfying t or satisfying t by uh not delaying it so so i this is a conundrum so i i i i would not understand how to choose between these options well perhaps issuing on the rev 12 um issuing a working group last call will force that issue to accelerate yeah i mean my gut reaction to address"
  },
  {
    "startTime": "01:38:04",
    "text": "hank's comments and karsten carson's comments is all the jason stuff has to go it it's just a seabor document and and we'll do a json document later uh that'll be a a second thing that when we when we learn how to uh to you know kind of work through the issues but i i again i think i would like to hear much more specifically from carsten and hank what they think the issues are what's really wrong with the the document as is okay but um lawrence that should not preclude us from from you moving forward with the group consensus of doing the update and then starting to come like for the dash yeah for a a dash 12 i'll certainly add the you know you know add to figure out what the claims are that the dave wants and add them if if they're if it's straightforward i'll certainly take care of that by friday and if there is consensus by friday that uh you know to go to last call and move forward with the all the nesting and all the json and all the sea war um that's fine um but i what i think i'm hearing from from hank and carson is that the all the nesting and all the seaboard and all the cdl and all the json is is maybe not suitable for last call so so i i heard that there was work to be done but that it didn't it wasn't last call blocking as it relates to json well i mean carsten is saying it'll take a year to solve all that hank and karsten are saying"
  },
  {
    "startTime": "01:40:00",
    "text": "i have a general problem with uh standards that start out by fragmenting themselves in a false sense of trying to appease certain user groups but that's unrelated to the question of can we get the semantics of of all these these things working together right i think we can get these semantics right it might take a little bit of time um i'm just not sure it should be done in this document because it actually would continue on the development of cwt and jwt beyond what the scope of it is okay so in in the interest of time um cabo i hear what you're saying um but i'm i'm trying to move forward and and how would we get to to publish if you will so um gearing lawrence if you can rev to a version 12 announce it to the mail list and then for the participants um we can certainly put a a call of are we ready to do a working group last call um we've already clarified so uh dave thanks for for putting in your expectation of what should be on the eat draft but i would encourage and solicit everybody else to do the same thing of if there are things missing or things that need to be addressed for us to get to working group last call that we start putting them both on the mail list but more importantly as the authors are tracking it on github to start putting them and documenting them on github"
  },
  {
    "startTime": "01:42:02",
    "text": "okay so uh should we move on yeah next up is attestation results for secure interactions eric voight yes you bring up the slides this first slide is just highlighting that there's three drafts that last time we want to discuss as a group has potential overlap this discussion is going to be happening later so let's jump past this slide what we have is at the station results for secure interactions and we have version two and you can see the set of authors who've been contributing as well as getting uh suggestions from other people on the call here next slide the big change that occurred from last draft is really a split of the draft into two parts and this was requested in the comments of itf 11. the comments were let's put the document in between the information elements that include the attestation results and then into end-to-end implementation options such as background check or the augmented evidence so we now have a document which really focuses on those two different areas there are a couple implementations of the overall types of attestation results information elements that we're going to be talking about and after at the end of the presentation we're going to be hopefully asking for working group adoption of this draft after we get through the intersections with the other drafts next slide just briefly the drive behind this draft is that there's many kind of a testing environments out there and the relying party can't support an infinite number of permutations and what kind of claims are going to be coming in"
  },
  {
    "startTime": "01:44:00",
    "text": "about a verifier saying hey this is what i think about the tester so we got to make sure that we have some commonality in the kind of information that's coming into the relying party and we need shared definitions next slide the shared definitions really have to be that the tester and the verifier have the right information elements that are documented and defining just a small subset of information elements is part one of what this document includes next slide the simplification of the draft is that we took all the claims that we had previously and instead of having boolean like either the executables fail the executables are approved instead we have things like ah there's executables and there's a there's a claim about let's say executables do we have the right binaries the right runtime files the right time scripts loaded and so getting a general claim about executables or hardware or the file system or the config this is the kind of information that is in this draft coming up with a minimum set at this point of eight things around identity integrity and confidentiality of the information that is asserted by the um by the verifier in regards to the attester and so that's a key there and then the other part of the big change along that next slide is that we instead of having boolean now have a unsigned signed integer and that sign integer uh provides information saying that there's affirmation about the claim uh warning about the claim or contradiction a contra indication about"
  },
  {
    "startTime": "01:46:01",
    "text": "the claim so there's standardized results about what was found out about a particular aspect for example the executables we could have a green or firming value that only genuine's genuine files and executables are included whereas if we don't find that and we find a file or an executable that has been loaded that we know is not good we could send a or assign a result to that to that executable's claim that is contrary interdicted for example we know that there are files are not good in there so the the key here obviously is that we have tiers of values that simplifies things to relying party because the relying party can either code against the specific number in the claim or against ranges in the claim if they just want to say i'll accept any uh claims or any claims that are currently affirming i will go ahead and deny any uh connecting to any device that has contra indicated claims so the beauty of this particular way of encoding is that the relying party can either code against generalities or specifics next slide and uh we have looked at these claims against multiple types of hardware technologies including different kinds of of confidential compute hardware as well as tpms next slide so last thing about the part one it's important to remember that just because you say that something is affirmed or contraindicated doesn't mean the relying party has to accept it this is just the normalization of what's being asserted from a claim you might say oh i trust a lot more a"
  },
  {
    "startTime": "01:48:01",
    "text": "confidential compute environment such as sgx or trust zone rather than a tpm for an equivalent claim so it's important that when you identify the value of a claim it's considered in the kind of environment that was possible to make such a claim so you have to understand not just the claim but the hardware source for what could be concluded about that claim all right next next slide so that was the part about breaking things down into various claims there's also a second section and that second section talks about how to take the claims that are shown in green in the middle match it with freshness indicators from the draft architecture as well as verifiable identities such as chip vendors or development environments or target environments that say here the is the code build and it's really the combination of freshness trustworthiness claims and identity which are what would be combined together into uh something that would be evaluated at the relying party and that's the second part of the draft uh next slide and that second part of the draft matches to uh a call flow in the uh architecture draft which uses the times and the rest of the things so that the relying party and effectively the verifier b at the far end can go ahead and evaluate the information bundle to make a decision on whether to start a secure interaction between the a tester and the uh relying party right next slide i think that might be it yes summary so we've gone through and broken the document into two parts the information elements for attestation results summaries uh we have end and implementation options and there's"
  },
  {
    "startTime": "01:50:01",
    "text": "at least a couple implementations out there including a trusted path routing that we'll talk about second and that we're hoping that we can get a discussion on working group adoption so the um the uh this is where we are right now uh questions thoughts gary's on the queue yes uh thanks eric for the uh the draft and the uh the explanation sorry i'm having trouble getting my camera on um so i uh i've read through the trustworthiness claims section a few times and one of the things that i don't that in my impression reading it is that although the claim values are defined the criteria that the verifier use in determining those claim values are not and therefore interoperability is going to be a very difficult issue like i'll give a uh let me see if i can give a concrete example like take for instance an attestation result or sorry an attestation is provided in the form of a token maybe that says the firmware running on the device is that version x that's and that's not the tip one verifier may actually be it may actually uh lower the trustworthiness of the device based on that because it's not running at the tip another verifier may know what is at the tip and they view that that uh it may view that the the additional changes in the fir in the later version firmware are not sufficiently consequential to affect the security state of the device and may not uh impact the trustworthiness claim accordingly so i'm wondering if we can i'm wondering if we can't really define how the verifier is actually you it is actually determining the values on the trustworthiness claims can we ever really come up with the interoperable specification from that"
  },
  {
    "startTime": "01:52:01",
    "text": "perspective at least at least that's useful okay now good question we certainly have had discussions in the past at least uh in the verifiers i've worked with on this in the end the verifiers like to compete based on how good they can do something some verifiers will say here are the rules of which i'm going to process um a conclusion others might say i'm not going to actually discuss how i look at the evidence in order to generate the conclusion it's up to the verifier to determine what level of exposure they're going to do in identifying the rules for processing there's actually a good reason for this a lot of the people don't want to show what their issues are in terms of what they see as vulnerabilities so people don't start to design to their attacks to pass the test so instead of saying here is the exact equation to have the result instead they're saying you know this is what i'm willing to release this is what i'm not willing to release the goal to meet this standard is not a rule but a definition of a particular claim and it's up to the relying party to determine whether you know they uh accept the assertions that are made at the standard level by the verifier against those claims there's a bunch of other things that can go along in that but um in the end uh you know the the rules for calculation are not always formulaic especially when you have a huge amount of evidence and we have to generalize some of the values across different types of technologies we have many types of technologies and trying to say how to calculate a constant value across them will not always be something will be that uh formally defined in an equation so we're over time uh can we address the next topic in two"
  },
  {
    "startTime": "01:54:02",
    "text": "minutes which is trusted path routing yeah that'll be a real quick one okay all right trusted path routing uh we have the same authors from last time it really is an instance of the attestation results draft can go to the next slide and what happens is you take the appraisal policy for attestation results and we take the new definitions from the attestation results draft and we build a topology across a set of routers that is able to bypass routers that don't have the the trustworthiness claims as expected next slide this just talks about uh the means of evaluating the information coming from one device to another and there was a question on the mailing list can we do this with eat can we do this with yang how's this going to be encoded really the trustworthiness path routing and the trustworthy path rallying draft talks about how to parse specific fields and in various encodings next slide and so the only thing that's really changed in the draft is that we match to the attestation results and i think that's it okay so we're just going ahead and keep on uh defining and no need to adopt this until we get a decision on the attestation results okay that's it oh okay thank you so next up is scalable remote attestation for system containers and applications catholic moriarty good morning uh next slide please i'm going to provide an overview i've done this before but it seems there's confusion on the draft however the explanation that went out"
  },
  {
    "startTime": "01:56:00",
    "text": "but there's no overlap but it uses e is a correct summary essentially this is to provide a way to scale bringing local attestations to a remote a single remote attestation and so and part of this is thinking about the posture assessment use case and what's working what's not working with current posture assessment techniques it requires a lot of customization on the part of every single organization and while the standards are there and they work that has been a barrier um you know even though lots of vendors have implemented it because people don't have the expertise to deploy or have a person responsible for that level of detail now what we've seen with trusted boot process is that vendors a number of them have been able to demonstrate a trusted boot process that relies on a series of trusted or attestations working out or resetting a process if it doesn't work out and then you know the system is brought up as as being trusted and it even can provide an assurance to the hardware that's expected on a system now and so these are aligned to nist sp 800 193 so the firmware resiliency specification and then it's further instantiated in tcg's reference integrity measurements documents next slide please so that would constitute a set right all of the policies or measurements um and and you might break it down in different ways you might have multiple sets represent the document but having this um having this guiding way to take a set of what's been done locally and report it remotely could help us better scale what the posture"
  },
  {
    "startTime": "01:58:00",
    "text": "assessment looks like from a system gathering that information and the reason is that you're not going to want to send every single attestation across the wire because then it would just be too much data but we have logs and we have evidence when these attestations happen locally so the idea is really very simple let's group them up provide a way to label what that group looks like and then be able to send it to a remote repository whatever that is and so this draft sets up a so that we could define what those sets look like so that we have interoperability across the wire and we understand when a set is attested locally what does that mean to the remote entity and it you know it obviously uses eat um it would leverage uh you know assurance of what's coming from that host and how that was provided but would be essentially just grouping those sets so that we could better scale posture assessment where it's possible and it might not be possible to do attestations for every bit of posture assessment but if we could do a lot more via this technique that puts the onus on the vendor to create the set of what's expected and then have remediation capabilities where possible then this is going to help all of those end entities that cannot hire somebody we have a 3.5 million person deficit globally and there's lots of organizations like ones that we support uh at center for internet security at the state local tribal and territorial networks and that's just an example because there's lots of small organizations that cannot hire resources for functions like this so if this were to be provided by the vendor this gets us closer to not just built-in security and provided built-in security but then ongoing assurance to that expectation"
  },
  {
    "startTime": "02:00:00",
    "text": "um and so you could use whatever format you need and it would be sent to a repository and it would just match up what is that set and and how that is uh registered next slide please so we're we're over time okay i think that explains it well enough um if there's any questions i'd be happy to take them i guess at the next session yep and please read the draft it's short and simple thank you and i think that concludes our session for today next session is on friday check the agenda to get the actual time zone that works for you thank you until friday everyone thanks so"
  },
  {
    "startTime": "02:02:36",
    "text": "you"
  }
]
