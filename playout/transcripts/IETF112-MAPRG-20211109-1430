[
  {
    "startTime": "00:00:08",
    "text": "all right looks like we got about 60 people signed in it's about time to start so i'm ready to go all right uh good morning good afternoon and good evening everyone this is the uh measurement and analysis for protocols research group meeting in uh in concert with ietf112 my name is dave lanka and miria cooliwind the co-chair is also on the irtf follows ietf intellectual property rights if you're going to talk about anything here that your company or your organization is uh has applied for a patent or has been granted granted patent you're required to disclose that in a timely fashion see the details in the rfcs and documents linked here if you need if that's appropriate for you uh the note well privacy and code of conduct this meeting is being recorded it's in the public the information you present here will be available publicly privacy policies linked there uh we also expect you to abide by the code of conduct uh be respectful to other people harassment is not tolerated if you find instances of this there's uh contact information to the ombudsman there but just please be courteous in your participation in our meeting yeah let me actually add a few words because um i think this is really important for our community and so uh just pointing people at this um code of conduct and the anti-arizona policy uh is a serious point and not only something we skip through and i think this is also very important for us in the irtf because in this especially in this group we have a lot of newcomers and so we should be very welcoming and"
  },
  {
    "startTime": "00:02:01",
    "text": "open i think um and that doesn't mean that you cannot criticize anything but if you criticize something or if you provide feedback provided in a constructive way and be friendly and help people um to get to know the ietf um i mean consider this for this session i don't think we had any problems in the past also consider this for all the other sessions you're participating in for all activities around the ietf and the irtf also for the chat not only when you speak up on the mailing list or in the session and also please speak up if you see behavior and that is not appropriate you don't have to speak in public and of course it's always a subjective judgment but it does help to approach those people and tell the people that you personally had the feeling that something was not okay so we can all improve and make this a better environment when i go to the next slide thanks maria um so the goals of the irtf is to to support and present research work it is not the standards organization that the ietf is even though we are co-located and use some of the same procedures and there's more information about that at the link provided here so administrivia the charter for map rg which has been running more than five years now is available at the link there please subscribe to mailing list if you want to hear about upcoming map or g things but also related topics we regularly get advertisements for calls for participation or contributions in other workshops in symposia and conferences that are about measurement of internet things and you'll see today that will we sometimes host those in the map rg meeting as well uh today's slides are available go ahead go ahead sorry uh today's slides are at the link there you can find them in the agenda search for mamprgy and i just see that i missed the meet echo link but you're all here so that's great yeah i was i i saw that too and i was like well we're showing this like to people in medeco"
  },
  {
    "startTime": "00:04:01",
    "text": "so i thought the one place it didn't need to be was that right there right now all right next slide the jabber is by the way linked to the same uh chat you see in midair a small announcement uh the iab workshop on annelle's analyzing in ietf data is coming up maria is one of the organizers of that and uh that's um november 29th is number two the call and the selection process has already occurred but we're letting you know that that's there for instance um to give you an idea of work that will be presented there that's peripheral and related but um but not in map rg for instance stephen mcquisten and his co-authors did a work on characterizing the ietf through the lens of rfc develop deployment so you can imagine it has a lot to do with the things that you might be interested in especially if you're working on protocols and the standardization but it's not about measurement of the protocol itself so we're not hosting it here um uh on on a similar note uh sig com uh 20 2021 happened in august of this year there's also some work that you might be interested in that again wouldn't be in map rgb because it's not about you know two had a nice piece of work there called insights for from operating on an ip exchange provider that is about running a global network of fiber optic links in parallel with internet use for instance for global roaming for mobile so you can see why that wouldn't be here per se but we wanted to let you know that there's work in sitcom that's related to the work here that you might want to go and visit the next library yeah maybe just also the the authors of uh of those documents feel free to use a map of gmail just to announce this work and make people aware absolutely yeah and also i recommend everybody to check out the last imc that was just last week there's a lot of interesting papers and we have a bunch of interesting papers today from imc as well"
  },
  {
    "startTime": "00:06:01",
    "text": "okay so the agenda for today uh first up we'll have so a number of these pieces of work are from imc and uh and it's a subset that samples across the kind of things that map rg uzi does first up we'll have giovanni mora talk about uh sue name and this uh problem with the dns system and work that they carried on to to adapt the protocol to not have this problem so an actual engineering effort there uh next up we'll have nicholas kuhn bringing some new work to us that and some early work about vpn performance over satellite communications and then and each of these will have 10 to 15 minutes and uh let's go of time for questions between then we'll switch to iot or iot ls uh from taha paracha um and uh and that's a piece of work from imc obviously about um how the protocols are actually being used in operation in this case with iot and then we'll round out the meeting with kyle mcmillan bringing us their work on measuring the performance network utilization of popular video conferencing application um and uh what i can tell you i'm happy about this meeting today because we've just got four things and if i stop talking we'll have we should have approximately five minutes of comments for each of them so uh let's get underway um miria can you stop sharing that slide i guess i should call and say is there any is there any uh any questions or comments at this point i don't see anyone in the queue so so we can bring up the first presentation uh giovanni can you put yourself in the queue all right there you go and do you do do you do you plan 10 or 15 minutes for your talk it's perfect uh you folks hear me well yep yep all right so thanks dave thanks miriam and so a good morning evening or afternoon"
  },
  {
    "startTime": "00:08:00",
    "text": "depending on where you are um so i'm gonna present here this work we did together with folks at internet new zealand and usc um uh was a paper that we presented last week at imc so if you want to get a full paper here's the link um why actually we actually identify some issues uh with current rxcs with regards um dns and we wrote a new draft which the link is also here so we're looking for feedback with i sent the draft to the dns uplist last monday but if you are interested please have a look and provide some feedback on the list um so let's get it started it's name we all know that the dns is one course the car services on the internet and you know that because when it breaks people do notice and there is this famous mirai button and attack against dyne a major dns provider that provide dns services for netflix qualifying and all and so forth and when dyne went partially down in the u.s and made to the you know front page of the you know the new york times you can see here a picture of the zones in the west were like partially affected on this picture here uh so it's a big deal and and we talk about dns there are two major types of servers there is um if you have a client in this figure here um the client wants to go let's say to a domain like wikipedia.org the client sends a dns query to its configured with this local resolver which is configured with and there is over those sort of the heavy lifting the resolver is just like trying to find where this information is it's located in terms of dns to map the you know the domain name to ip address and this information is fetched automatically from these authoritative servers as you can see here and once this information is fetched the resolver responds to the client the client can go happily to wikipedia and surname effects specifically traffic to authoritative servers is the resolvers that would kind"
  },
  {
    "startTime": "00:10:01",
    "text": "of overwhelm uh authoritative servers and this all happened when we were working together in a paper for imc 2019 um artillery and there is 2020 actually and this is traffic that arrives at the authoritative servers of new zealand and the folks there were getting you know an average of 750 million daily queries so all the data in securities that come to them and but one day to the other they saw this 50 traffic surge in the traffic and if you're an operator you know you don't like such surprises and that got them concerned obviously and when they start to dig into the data they saw the two domains in their zone basically had no carries before very little daily currys and out of the suddenly they start to get like more than 100 million queries each and they wonder if that was a deny of serf's attack and if that were why it was actually uh targeted domain names were not popular at all that does not make any sense but it turned out that there was a misconfiguration in this particular two domains domain a was misconfigured with a loop which we call cyclic dependency domain a when you try to resolve that would try to would actually point to domain b but domain b in turn would point back to domain a which would create a loop in that situation some resolvers when they find loops or some clients they start to look and send in non-stop queries and the effect of that that overwhelms authoritative servers and this particular event on new zealand that was not a major issue for them but it could be have been um so as i said and cycle dependencies is an error it's a configuration error and one domain points to let's say category points to nzc.dog then ask.nz but dog.z would point back to ns.com and then we create a look and 1536 describe it uh this paper papa's 2004 they covered at"
  },
  {
    "startTime": "00:12:01",
    "text": "the more details the issue with this domain that can never be resolved and what it did in this paper in particular is to show how this vulnerability can actually be weaponized we also provide a tool for dns authority server operators to get the rid of these loops in their zones because many times you're not aware that it exists in their zones so it's if it's if we provide a tool that's open source too cycle hunter they can download and scan their zones and also identify what's missing in current rfcs and we help like them also fixing bugs we carry out responsible disclosure we notify first the vendors and the specific groups and then later carry out the public disclosure and that cause that led to google and cisco public dynastics in their servers which was we're very happy about that um so the but the real threat in this case of surname is that its weaponization is that two domain names in the rnz that had zero basic little traffic cause a fifty percent total traffic surge and the threat suits the diversity will hold many domains and it would be configured many many domains with the slopes and then trigger recursive resolvers queries from botnet that could potentially you know bring down dns providers so we got very concerned about that and in practice uh the root causes of those loops are two-fold the first one is that resolvers themselves this infinite number one they're uh the resolvers when they see the sort of loops in the dns configurations they would simply start looping we found like old versions of windows resolvers doing just that um so that's one of the cases but the other case is that the clients themselves would start looping they would stop and send queries non-stop and that would cause resolvers also to look and the ultimate effect is on the targets here this authoritative service would see the surge in traffic um the solutions will cover later and you know people know that loops in dns are no problem but it isn't that"
  },
  {
    "startTime": "00:14:01",
    "text": "solved already but they turned out that rfc 1034 was like the the first dns rfc it's very vague about loops they say it resolves just about the amount of work to avoid infinite loops and but not but that would only protect uh resolvers from overwhelming for the for the first part of the loop here the infinite one it was just for bid resolvers from looping even indefinitely and overall mean authority the name servers but does not protect any amplification from clients that the clients would send the queries non-stop to resolvers and then resolvers in turn would loot themselves for every occurred that arrives so that does not protect in this case 1035 recommends to set counters in this case to forbid again um resolvers from uh looping to prevent resolvers from looping um but again does not provide any protection if clients or forwarders are actually looping themselves 1536 says that loops can occur again does not protect from looping clients so the solution we actually provide in this paper is that this is not really uh covering any servers at the moment which the resolvers should actually do negative caching should detect those cycles and put in their cache so every new client query can be like responded from cache and now it does not make it to the authoritative servers and that minimizes the both causes of looping here and that's where our draft comes from here on the dns hub and we also in the paper not only investigate what happened to new zealand but also we carry out a bunch of control experiments in the wild with using ripe athletes and other vantage points to that so the most basic experiment we did we configured ripe atlas 10 000 probes to send one query only per probe um to their local resolvers we wanted really to determine if we could get that should if you really one probe wants to uncur if that would be enough to start looping and it's kind of the lower bound"
  },
  {
    "startTime": "00:16:02",
    "text": "um so we did that and in atlas you know one atlas probe they may be configured multiple resolvers but the what we collected it's the traffic arriving the authoritative servers and this is the figure you see here uh on the top figure you see sort of a spike in the y-axis we see the number of queries that arrive the first spike there you see after two o'clock and when the normal traffic arrives at the resolvers we see like more than 150 000 queries but after that there's no more queries for an atlas but we're still getting queries at our 32 servers for hours and hours and hours and he only stopped when he turned off the experiment uh and the re and what happened if you look at the graph below is that a portion of the resolvers you see like on the y-axis here and on the graph below and the number of resolvers doing that in this particular experiment 47-7 574 uh actually looked and they came from 34 autonomous systems including google and cisco and the paper have way more complex scenarios and it gets worse if you make longer cycles it can make three fold cycles and so it gets worse and we have different vantage points so it's a widespread so that's the first figure into this newspaper but the second thing we're interested is not only understand the phenomena but also prevent it so we wrote this tool cycle hunter which you can download here here's the link it just gets your zone file gets all the ns records you have in it that's where the authority div servers are defined try to resolve them if they fail they try to find it they're cyclical or not and then you have an output and what we did we ran cycle hunter and by the way thanks for all folks that contributed to the tool later after disclosure uh we ran cycle hunter uh against multiple zones 184 million domains and we found that only 44 and 1500 domain names were like affected by that and we"
  },
  {
    "startTime": "00:18:00",
    "text": "believe it's like human error because if you have this sort of thing your domain is not resolvable then if you're really legitimate use of your domain you're not interested in that but you know the malicious actor could just do differently and try to weaponize this and so that's the prevention part and then we came to the fixing box part we carry out responsible disclosure and here's the we started december last year to do that and we ended up in may this year with the public disclosure we talked first to google and then with a bunch of private groups that had contacts and including dnsr which which was the biggest uh iraq 34 was the biggest group that we disclosed and then we that calls like google and others and spoken as in cisco asset effects and we actually confirmed that google fixes public dns because we ran measurements uh before they fixed and and we repeat the same measurement using ramp atlas after and you see here that before in this particular scenario it's also in the paper uh we would get four million more than four million queries in our traditional servers but after that it will get like fewer than uh two hundred 000 so we can really confirm that the google fix and we see that they fix that by deploying negative caching too um and after we came forward with the post with the disclosure and at the work 35 uh i think was like five or more months and a half after we started the process of disclosing this some operators came forward to us and they said hey your folks are not the only ones we've seen we have seen that we saw that ourselves do and one european-based cctod they were kind enough to share this graph with us and you see here when the graph around 17 hours starts to grow it's when two domains in their zone was were also misconfigured and their total traffic increases like 10 times because of two domain names so each color here shows a different authoritative name server for that eu based cctld operator so that's a"
  },
  {
    "startTime": "00:20:02",
    "text": "big deal and you'll see a draw a sharp drop later on around 11 a.m the day after um when they fixed that manually so we're not the only ones seeing that in order to they also came forward during the work presentations um so that's um the third part of this the third contribution and the conclusions is that ns loops are no problem dns that they have been specified since they have been talked about since the original dns specification and we showed we must address it now uh current standards current rfcs do not cover them and that's why you propose this new draft and what to do if your operator you can run cycle hunter if you run your automated servers try to find those loops in amazon and if you're a developer of resolvers you should we recommend they would just do what's in it with what's in the draft like negative caching uploads and with that i think it opens questions uh we have two people in the queue and we've got a couple of minutes for their questions or comments so first let's uh take jonathan hoyland hi uh jonathan hoyland cloudflare um i'm interested have you seen uh g root or groot by the microsoft research people um they have uh they also do cycle hunting in dns and i was wondering if your tool is different the same solves the same problem i i haven't seen that one no i have not seen if you could share a link you could have a look at that in time yeah well not aware of it but thanks for sharing all right thanks jonathan up next we have daniel gilmore daniel are you there okay danielle you're at the top of the cube but i'm not hearing you"
  },
  {
    "startTime": "00:22:01",
    "text": "uh do you want to put your question in in the chat and then you'll delay it oh i think daniel just wrote the question there uh i see him in the chat yeah i'm trying yeah oh now we can hear you go ahead uh i was just hoping you could say a little bit more about looping it's not about leaving the cursors what sort of clients were looping um so our vantage point was like we we used rap atlas and they created whatever the resolvers they had but it would also collect traffic and authoritative servers but there's a lot of things that come in between both of them uh what we could find specifically it's on the paper like two versions of the an old version of powerdns from 2014 was looping uh an old version of microsoft dns server from 2008 was looping we know that also that the clients that google which was the major responsible for the traffic and all the experiments we did google pump dns did not look so the only uh we talked that we worked with the operators on that so the only reason that could have been this could be happening is the client from google downstream they would before the fix they would be sending queries one after the order and every query would trigger let's say 10 new currents in our authoritative name servers but i don't know which clients were looping i i haven't looked specifically to that because my client my vantage points didn't allow me to see that unfortunately but at least two resolvers we could confirm that were old versions they were open and i think there's a does that answer your question i think let's assume that it does i think there's a little bit of audio trouble there and we're at time thanks so much giovanni um for bringing that work to us super cool uh i especially like the cycle hunter tool so people can"
  },
  {
    "startTime": "00:24:02",
    "text": "all right so up next we have nicholas nicholas can you put yourself in the queue to share your slides there you go all right there you go take it away nicholas uh you've got 10 minutes okay uh hello everyone uh so my name is nicholas and i'm presenting this work on the behalf of colleague of mine from varis this study came because we are all with all the pandemic that occurred we are all using vpns and we have measurements showing that when you use a vpn solution and you have satcom access things can be very bad so we wanted to do some work on an experiment wide experiments on trying to find what is the best vpn solutions for different circumstances and we have an archive paper showing lots of results so as i said we have all been working from home recently uh also enterprises networks need to interconnect their um for their different components and uh this comes with increased security needs and vpns are usually deployed in these schemes so i guess lots of us know what vpns are but the devil is in the details and and there are a lot of different solutions on here so we have been testing wire guard that is an ip6 solution but also comparing it with open vpn on top of udp and tcp dave told me that everyone is not always aware of what we do in satcom system but we are not the only ones we usually deploy tcp proxy so basically we have two components intercepting the triple check messages from tcp to have in the end three different tcp connections uh we do not do that because"
  },
  {
    "startTime": "00:26:01",
    "text": "we like to break the in to end principle um we do that because it has a lot of interest and it is to answer to the specificities of the satellite links in short uh we have issues in connection initialization we can have lots of tuned specific initial windows in tcp pep sometimes the end-to-end buffers are not in adequation with the very high bdp that we have on satellite systems so we can have custom buffers also splitting the reliability in three subsystems abs helps a lot loss recovery is splitted in three segments and not really end to end on with a very large rtt and last but not least um when you are when you know your system and you know the condition status of it and then you can actually very quickly increase the rate at which you transmit data and so you have very homemade condition controls that are possible in these components also we we do that because basically here is just a basic example on you know showing the pager in time without with different initial windows of tcp and the pep and we can see that with tcp proxies even if we just speed the the connections in three we can have the page loading time that being said um if we look at an um let's say an enterprise network and using a satellite network we have end-to-end the server in the pc and we may have a pop um a satellite gateway that a terminal and an access box the pep can either be in"
  },
  {
    "startTime": "00:28:00",
    "text": "or out of the vpn tunnel and basically we have seen deployments where a lot of configurations are possible so i can put my vp pap within my vpn tunnel out of my vpn tunnel i can have lots of vpn solutions so i can sometimes choose my connection control sometimes i cannot so basically that is the main rationale of this study we have tested it over a lot of configurations and uh on for to emulate satcom systems which are uh or geo-based or for geosynchronous systems or leo we have sometimes usually on jio systems you have no losses uh that being said um sometimes when you rent a subconscious access you may end up having losses you don't know whether there are transmission losses congestion losses but you can measure lots of losses on the system um and then we have tested cubic cubic without ice bridge lost start and br v2 we have tested initial conditional windows um and so three different vpn solutions and um basically um the results are for the case where we don't have any losses so basically here i show the transfer time of 30 megabytes and i will just point to different results basically we have measured that when we use vpn tcp and that and there is a pep uh within the tunnel we have very bad performances uh we guess this is because we have some sort of a tcp in tcp issue and that end up with even bbr v2 exhibit uh exhibiting a downline time of up to 40 seconds um"
  },
  {
    "startTime": "00:30:00",
    "text": "in this configuration when we use just um for the pep in position b for the green circle so the pep is outside of the vpn tunnel and the vpn wire guard is just an ipc ap sec tunneling that ends up providing the best performances anyway a vpn on udp and without or without pep and basically the orange circles we have lots of cases where we have very fair and good performances in summary i thought we'd have summary of the results later on um when we have losses uh things are very getting very uh as we could have expected basically a cubic is very sensitive to losses on the network while bbr v2 is not um bbrv2 ended up providing very good performances in terms of downloading time and using it helps a lot in these cases and when so when um we cannot use bb rv2 and we are we have to stick with cubic we can see that it is better to actually face the tcp and tcp problem but have a proxy and and assuming and vpn solution based on tcp so that the proxy can somehow help and so what we have measured in our short technical report um that you think we are god is very interesting um and basically we have more or less the same performances with qb and bbrv2 when we don't have losses when we have losses in the systems and that you don't manage uh actually activating bbrv2 helps a lot"
  },
  {
    "startTime": "00:32:00",
    "text": "when you cannot turned on vbrv2 we have measured that the damages can be reduced when you use the pnvp and tcp also we wanted to mention that in this short technical study we have emulated losses on the satellite network sometimes when losses are on the local network the pep can help much more because this the recovery process doesn't is not uh i am occurring on the large delay path and so basically we we we we have to admit that in this case that we have considered the pep cannot really help the risk of lost recovery process but um that is what we sometimes face in deployments where we actually cannot guarantee your loss free satcom system so we have recently published an archive paper and sent a link to the list and basically on top of what we have shown here in the paper we have also mentioned the conclusions we had when we tried to introduce um congestion and when baby rv2 is not alone to see if there are any fairness issues and in a nutshell we don't have much fairness issues with rv2 in our experiments so thank you all for and for listening and thank you very much for my prg to give me the opportunity to present this result hi nicholas this is this is dave um i i wanted to relay a couple of questions of basic questions that maybe i should interrupt you for can you go back to your slide with the results the questions were just about were these numbers total times the completion for the 30 megabytes 30 make by transfer okay so it's time to completion instead of some latency measure uh okay uh"
  },
  {
    "startTime": "00:34:02",
    "text": "yeah that was there's a there's a little more discussion in the chat that you might want to check on afterwards to see okay and anyone else with the question or comment for nicholas okay tommy paulie's in we'll take tommy's and then uh we'll switch to the next presentation so tommy go ahead we can see you yep great yeah thank you uh so much for sharing this uh definitely interesting to see your results um one thing i i'd love to see more work on if you're able to do more experiments with different types of configurations is you know what can happen if rather than using vpn and tcp proxies here we could look at using quick base proxies so within mask working group we're using quick based proxies and those are able to send both reliable and unreliable data i've been working on a project at apple to use multi-hop quick proxies for our service called private relay which is kind of like a vpn but it's using these proxies so i think it'd be interesting to try to see you know rather than having to choose between okay i'm doing a tcp solution here with a pap or udp solution with a pep if we have an ecosystem of quick proxies could we maybe get the best of both worlds across the no loss and lost scenarios to be honest we are very interested in deploying mask-like proxies in this kind of systems and because we didn't have running code for that we used what was available and we think that sometimes when we use the open vpn udp somehow even if it doesn't include a question control that mask would proxy will have uh we can still have some trend of the results we could observe um but then indeed we are very interested in going further i think it's"
  },
  {
    "startTime": "00:36:01",
    "text": "very important for this kind of systems to look at mask proxies and what is possible we are all right thanks tommy and nicholas we're gonna spin up the next presentation thanks again for joining us all right we can see you uh and uh now i should be able to see my screen okay yep there you go i'll let you know in 10 minutes that sounds good okay so hello everyone i'm talha i'm a phd student at northeastern university and this work is about tls usage and iot devices and was published at imc last week it's done in joint collaboration with daniel narcio and dave uh so as many of us know internet of things devices such as smart tvs and voice assistants are very popular and are expected to become ubiquitous um invasive nature of these devices raises significant privacy implications for example some of these privacy issues in the past have been found in baby monitors voice assistants and even biomedical devices in addition compromises in device security can also lead to severe outcomes for example in the past there have been internet outages credentials leaks and even vehicle hijacks one of the ways to improve iot privacy and security is to protect the network communications from iot devices our prior research shows that iot manufacturers mainly rely on tls to do so now tls is the de facto web security protocol that provides confidentiality authenticity and data integrity to network connections um nicholas i just want to briefly say that your mic is on in case you forgot okay but to use tls properly we need a client needs to use secure protocol version and features it needs to properly validate certificate chains and it needs to adopt new features as the protocol evolves over time now tls usage has been studied rigorously in various platforms such as web browsers and mobile operating"
  },
  {
    "startTime": "00:38:01",
    "text": "systems but little is known about tls usage in iot devices hence the main objective behind our work was to study how effectively iot devices use tls however there were a couple of challenges that we needed to circumvent first for example iot devices provide limited ways to trigger traffic in order to interact with the devices one needs one typically needs to plug them with a power supply and manually interact their functionality with their functionality and second there are limited vantage points that shed light on tls on on a traffic that is tls traffic that is specific to iot devices uh here's how we mitigate these challenges first we build on the prior insight we build our insight by prior works that devices generate significant network traffic when they are powered on we automate device reboots with the help of of smart plugs and hence we have a way to generate traffic uh whenever we need for our experiment and second we complement these controlled experiments with uncontrolled ones that span a long period of time and enable us to study longitudinal trends we conduct these experiments in the iot lab at our school we focus on the 40 tls supporting iot devices across a wide range of categories we also recruit more than 30 participants to interact with these devices in the lab through an irb approved user study as you may notice our lab is designed like a studio apartment and our participants were told that they can use any of the devices as they please and with this setup we conducted we obtained two years of longitudinal data from 2018 to 2020 i'll now share some of the key results and we'll then talk about one result in more detail so first the first question that we asked in the study was if these devices securely establish tls connections on the positive side what we found was that most devices were using tls 1.2 and none of the devices were using insecure cipher suites but on the negative side"
  },
  {
    "startTime": "00:40:00",
    "text": "we also found that very few devices upgraded to tls 1.3 or modern cipher suites over time the second question that we asked was if these devices properly validate tls certificates we found that 11 devices were vulnerable to tls interception attacks our manual analysis revealed that many of these devices were sending potentially sensitive data we have reported this vulnerability to all these vulnerabilities to all device manufacturers we also found that devices do not appear to update their tls root stores and i'll talk about this result in more detail in a bit and finally we also asked if these devices share tls libraries with other clients uh using a technique named tls fingerprinting we were able to show that devices and applications from the same vendor likely share tls libraries in the paper we talk about more details about the positive and negative implications of this finding so i'll now talk about tls root stores in more detail to understand what these two stores are let's consider an example dls handshake here our device initiates a deal initiates a connection with a web server there are many steps in the handshake the one to remember for this talk is that at some point during the handshake the server will send a certificate chain the certificate chain contains the certificate authority which in this case is digit these certificate authorities vouch for the authenticity of the server in order for this handshake to succeed the device must trust the certificate more specifically the name as well as the signature of the certificate authority must already be in the trusted root store of the device if the device does trust the certificate it can continue with the handshake and may mark it as a success these root certificate authorities have the power to compromise authenticity of all connections that a device makes hence it is essential to know what root certificates are trusted by iot devices"
  },
  {
    "startTime": "00:42:01",
    "text": "other platforms such as web browsers and mobile operating systems publish the list of root certificates that they trust and regularly update them over time for example here a root certificate is being removed from mozart from mozilla route store because of administrative reasons but here the removal of this root store is due to negligence and misbehavior on behalf of the certificate authority inspection of root stores and iot devices is difficult due to their black box nature i will now share our technique i'll now show how to use completely black box measurements to try to infer root stores of iot devices let's take a look at the tls handshake again but this time we intercept the handshake and certain send a certificate chain that contains a certificate authority that is unknown to the client in terms of both name as well as signature if the device is properly doing certificate validation it must reject this certificate and mark this handshake as a failure the device can also choose to share the reason of failure through a tls alert which in this case is unknown ca let's compare this with another scenario where we also intercept the handshake but this time we send a certificate whose name is known to be trusted to the client but whose signature does not match the signature of the certificate that is present in the device in this case the handshake must fail as well so we can see that in both of these cases the handshake fails but the reason of failure in both cases is different and that in one case the reason is that a certificate is unknown while in the other case the reason is the failure of a signature these two different reasons can lead to the transmission of different tls alerts if an iot device behaves in such a way we can reliably infer the presence of a given root certificate in its store and to explore all root certificates that a device has"
  },
  {
    "startTime": "00:44:01",
    "text": "we can simply repeat this methodology with the names of all publicly known root certificates our technique of root stores exploration worked for eight of the 24 devices we could test in order to get a list of root certificates for whose inclusion we could check we extracted historical root certificate data from various platforms using this data we generated two set of certificates one commonly certificate trusted certificates are the ones that are available in latest versions of all platforms and second deprecated certificates are the certificates that were once a part of one or more of these bad platforms but have since been removed over time we first checked for the inclusion of commonly trusted root certificates our results reveal that most of these certificates are present in iot devices this is good news because it shows that iot devices web browsers and operating systems likely trust a similar set of root certificates we then check for the inclusion of deprecated root certificates ideally none of our devices should trust any of these certificates but our results reveal that most of these devices trust some of these certificates us devices such as google home mini trust a few percentage of these certificates while some others such as lg tv and invo restart percentage that's quite high the likely reason for this is that devices either do not update their to tls root stores or they do not update them at a required frequency in order to explore more of the security implications of trusting deprecated root certificates we manually analyze the certificates that were still trusted by these devices to our surprise we found that all these devices trusted at least one certificate that has not just been deprecated but also explicitly distrusted by either firefox or chrome based on this new analysis we argue that tl tls root stores can be considered as"
  },
  {
    "startTime": "00:46:00",
    "text": "the weakest link of security in iot devices to conclude our study reveals a mix of both good and bad news about tls usage and iot devices unlike the perception in the community we do not believe tls usage in iot devices is completely broken rather we think it suffers from some of the same issues that existed in other platforms when they had just started their reliance on tls uh please feel free to read our paper for more details and i'm happy to share that we also have released the tls handshake data and some software from our research uh thanks and i'm ready to take questions now thanks a lot taha uh right on time perfect uh what up first i want to refer you to uh people like that you're doing this work and there's some questions for you in the chat i'm gonna refer you to their uh dkgs a couple of things and was also referred to your paper and then i see we have uh uh hannes uh uh actually benjamin i guess is ahead of him we'll have benjamin go and uh and we're gonna have to switch pretty quick to kyle's so uh let's make it quick uh go ahead benjamin hi uh what uh so you said this worked for eight of the devices what happened with the other 16 so what happened with those devices that was that uh they would either not send us a tls alert at all or they would send the same dls alert so it means that we need to find some other channel to like study that uh difference because the certificate validation would be different in the both two cases but the others are not necessary to be sent i should also mention that the tls protocol does not mandate the sending of these alerts um thanks anas can you can you go quick yeah sure um thanks for doing the work i was wondering what type of devices those were like did you um sort of analyze uh whether those were sort of like uh"
  },
  {
    "startTime": "00:48:00",
    "text": "high-end iot devices like with a-class processors or more these uh low end devices which obviously have different constraints they were all popular consumer devices so pretty high hand i would say and i have a slide in the slide deck which has a list of all these devices but they were like alexa and smart tvs and samsung fridge okay so it's most likely running linux off the shelf linux okay cool thanks so much taha for bringing that to us uh follow up in the chat with them if you would like bringing kyle's slides now and we'll finish up with our last presentation where kyle will be sharing with us uh performance measurements with video conferencing apps go ahead kyle you got at least 10 minutes great thanks dave uh yeah so my name is kyle i'm a second year phd student at the university of chicago and today i'll be presenting our imc paper measuring the performance and network utilization of popular video conferencing applications and i want to start off by giving a little bit of motivation for this work which actually came from a question that our local city officials here in chicago asked us towards the beginning of the pandemic namely what is the baseline level of internet performance needed to support common video conferencing applications for remote learning now this question is becoming increasingly relevant as local policy makers work to provide sufficient internet access to its uh citizens so to answer this question we've conducted a series of experiments to better understand both the requirements of vcas and the causes of poor performance so in this talk i want to briefly highlight some of the core findings from each of the sections of our paper and to start uh in this work we study three of the most popular is in use right now zoom"
  },
  {
    "startTime": "00:50:00",
    "text": "google meet and microsoft teams so we start by determining what the bandwidth requirements are for a two-person call on each of the vcas and find that meet and zoom use under one megabit per second on average in both directions while teams uses 1.4 and 1.86 megabits per second in the upstream and downstream directions respectively now for context uh home internet users have access to speeds uh of up to one gigabit per second and many subscribe to plans in the tens and hundreds of megabits per second uh additionally the federal communications commission known as the fcc defines broadband internet as 25 megabits down and three megabits up now while there's uh still some debate over this definition the actual utilization rates that we found for these apps that many consider to be pretty big bandwidth hogs are actually relatively low but uh while utilization rates may be low uh insufficient bandwidth is not the only cause of poor performance home internet connections can be dynamic and encounter interruptions in connectivity so in this next part we study how vcas respond to these sorts of temporary disruptions and to do so we use the following setup where we start a call on v1 which is a standard consumer laptop and adjust the bandwidth capacity available to v1 at the router in order to simulate an interruption um our experiment proceeds by starting the call under what are effectively unconstrained network conditions"
  },
  {
    "startTime": "00:52:01",
    "text": "and then one minute after starting we reduce the available capacity uh to one megabit per second or less for 30 seconds after this 30 second period we revert to the original unconstrained network settings and allow the call to continue for another three and a half minutes before ending it uh among our results we find that vcas can take quite a long time to recover from uh interruptions in this figure we measure the time to recovery which we define as the time between when the interruption ends and when the median utilization routine excuse me when the median utilization returns to the median utilization from before the interruption the levels on the x-axis indicate the available uplink capacity during the 30-second interruption and while zoom and meat are usually faster than teams to recover from drops to 0.75 and 1 megabit per second all three vcas can take over 25 seconds to recover from the most severe uh these long recovery times may lead to poor performance especially on networks that are prone to these types of interruptions but uh interruptions aren't the only cause of dynamic network conditions so in this next part we study how the vcas respond to competing traffic and this is really important because there are often more than one user on a single network and these other users could be hosting their own uh video conferencing calls or using streaming services like youtube and netflix so to test how vcas interact with other applications on a constrained network we use the following setup where we run a video conferencing call on v1 and initiate a competing"
  },
  {
    "startTime": "00:54:02",
    "text": "application on c1 both v1 and c1 are connected to the same network and will share the same bottleneck link again we're setting the capacity available to v1 and c1 at the router in each experiment we start by reducing the capacity available to v1 and c1 before we started either of the applications then we initiate a call on v1 wait 30 seconds and then start the competing application on c1 now it might not surprise you to learn that applications aren't always fair with other types of applications but we actually found that the vcas are not always fair with themselves so in this figure we plot the upstream utilization over time for two different teams calls using the same three megabit per second uplink the gray region indicates the time period in which the two calls compete the purple trend line is the utilization for the incumbent call running on v1 whereas the black trend line is the utilization for the competing call running on c1 and throughout the duration of the experiment we find that the incumbent teams call has a significantly higher average utilization uh than the competing call now this lack of coordination between the calls has obviously implications on fairness and could mean that one competing vca call could use more of the available bandwidth just because it started first now uh up until this point i've only discussed utilization and performance in two-person calls but as we all know there are many different ways that people use vcas so in this next part we explore how varying the number of participants and"
  },
  {
    "startTime": "00:56:00",
    "text": "how people view the call affects utilization we use the following setup for the experiments in which all participants join the same vca call we consider two viewing modes gallery and speaker mode uh in gallery mode uh you see everyone's video on the screen at once this works by shrinking the size of each person's video and in speaker mode all participants in large participant a's video streaming it at a high resolution and what we find is that your utilization can be affected by how other participants use the vca uh in this figure we show user a's uplink bitrate or uplink utilization when all other participants have user a's video enlarged in most vcas this is when you pin a specific participant's video to the screen and we show how the uplink utilization changes as we increase the total number of participants in the call what we see is that as the number of participants increases the utilization for meat and zoom remains relatively constant but when using teams user a's uplink bitrate tends to increase with the number of participants and uh this is a really realistic scenario scenario you can imagine it occurring during remote learning when all of the students have pinned their teacher's video to their screens so understanding this behavior is really important when drafting broadband policy especially given that the uplink teams utilization approaches the fcc standard for broadband internet at three megabits per second when there are eight participants in the call so to recap in our study of vcas we have several interesting findings that can inform policymakers that are designing internet provisioning legislation"
  },
  {
    "startTime": "00:58:01",
    "text": "namely that vcas have relatively low utilization that they can take quite a long time to recover from certain interruptions that vcas may not compete fairly even among themselves and finally that uh how other people view the call can affect your utilization i hope you've enjoyed this presentation uh i'm happy to take any questions you can email me at my last name macmillan at uchicago.edu i know we're running a little low on time here hi kyle uh thanks this is dave we've got two people in the queue with a question or comment for you and there's a couple more in the chat if you want to pick them up there otherwise they'll do as you said uh go ahead andrew hi thank you and thanks for the uh interesting presentation it was uh fascinating so uh good to see uh just two quick questions uh when you did this did you consider uh or did you look at the any differences between using a native app versus a browser client and also did you look at any differences from different uh device types to see if that made any material impact on this thank you yeah thanks for your question so we actually looked at um how uh well google meet i guess the native application would be google chrome so that's what we used the whole time but we also looked at how microsoft teams performs in browser so uh for that part we look at how utilization changes as you adjust the network settings but also how certain qoe metrics change uh under different network settings so stuff like freezes and uh quantization parameter uh and then as for device type we we did most of our experiments on uh this uh dell laptop that was running ubuntu uh but we also uh replicated some of the experiments on a on a mac computer but uh in case you were asking about like mobile devices or something we were uh"
  },
  {
    "startTime": "01:00:00",
    "text": "only looking at laptops yeah yeah i was thinking more different processes so without any i9 type the distinction but maybe discussion uh offline thank you okay thanks a lot um ali why don't you go and then we'll wrap it up i suppose we can hear you yep right thanks for the talk uh my question was when you were doing the video comparison the video betrayed between team teams versus another team's client or another competing client uh where were you double checking that you were actually capturing a similar video uh because you know uh talking a head versus talk you know moving body or moving ahead i mean makes a difference in terms of video uh bitrate right so uh i just want to make sure that you guys were uh uh you know confirming to pre you know using pretty much the same video for each webcam so that it will be a fairer comparison yeah no that's that's a really good point uh and we did so we uh we had a pre-recorded talking head video that we uh used for all the experiments um okay all right all right thank you yep great thanks so much uh for joining us kyle and thanks to the other contributors those were great talks uh you can go find their papers and another recording of the presentation for the three of them are ymc there thanks to miriam for helping put together the agenda again i hope you all have a good week and thanks lastly to teresa encart for taking the minutes for us and we will see you at the next meeting bye bye and thanks to dave bye"
  }
]
