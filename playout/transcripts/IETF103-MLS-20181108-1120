[
  {
    "startTime": "00:00:07",
    "text": "[Music] [Music] [Music] [Applause] [Music] [Music] [Applause] [Music] [Applause] [Music] [Music] [Music] [Music] [Applause] [Applause] [Music] [Applause] they can\u0027t pull it out the target name into the shiny stars he\u0027s sick of it too far beyond the microphone is on okay "
  },
  {
    "startTime": "00:03:34",
    "text": "let\u0027s close the doors come settle in if you are at the MLS working group if you are supposed to be here versus supposed to be somewhere else make that decision now this is the second meeting of MLS at IETF 103 let\u0027s just let the let the door closed all right here\u0027s the note well seeing it as it is Thursday you probably have seen this already so please read this consider this if you have a PR please disclose all right so before we get started we would we need a jabber scribe someone who\u0027s willing to talk to the jabber room translate ask questions anybody out there jabber scribes a prescribed thank you the other one is minutes taker is someone willing to take minutes of this meeting Chris generously did it last time all right we have Joe thank you Joe and the blue sheets are being passed around so please please sign them if you\u0027re here we want to know that you\u0027re here if you were here so yes this is the second meeting we had meeting on Monday today it\u0027s potentially going to be very short because this formal analysis update piece is a question mark we don\u0027t have the formal analysis folks here this time so agenda bashing but we are gonna try to add like five minutes at the end ik to describe that possibility of an interim in January yes so modification of the agenda here bye bye bye Shawn rather than formal analysis update we\u0027ll discuss the possibility of in an interim meeting anybody else any other items people want to add because we do have some extra time nope okay well I\u0027m going to invite up Richard Barnes to present in in lieu of Benjamin for MLS message protection hi I\u0027m Benjamin reduce I\u0027m not gonna try "
  },
  {
    "startTime": "00:06:34",
    "text": "and imitate French accent so this this is a recap of some work that was was done around the time the interim which I think has been incorporated in the spec now I think was still a PR bat-like back at that point so kind of like we did with some things in the first session MLS session this week this is kind of we had a sketch the last IETF we got some text we discuss it at the interim that\u0027s landed since then and and here\u0027s kind of what we did so for for people\u0027s further comment next slide please so putting this in the broader in the overall context of MLS most of what we talked about with MLS is the authenticated key exchange how do we get everyone agreed on a group a key that symmetric heated shared across the group that\u0027s talking to each other the focus of this presentation what we\u0027re calling message protection is how you protect oh yeah you put that key to use and how you actually exchange messages within the group for some application their purpose so this is gonna be about how you take things off the the master key schedule and put them to use and identify who\u0027s sending things using digital signatures so there\u0027s kind of two broad topics for this one is what\u0027s the key schedule you use to get things like forward secrecy on messages as you go and then how do you actually construct the messages that you\u0027re gonna protect and sends to the group next please so this is kind of the branch point from the the handshake key schedule so as you\u0027ll recall from from the key exchange discussion overall the overall key schedule looks like you know we have has this kind of stepwise process of epochs where each epoch is initialized with an init secret and some update secret that was produced from an MOS message an ad or an update or remove and that results in Network secret from which we derive various Secrets that are used for different purposes within the epoch the one we\u0027re going to talk about here is the what we\u0027re calling the app or application secret which is derived in the same way as other secrets in during the epoch so that\u0027s gonna be you know it\u0027s that is a secret that is shared as all the secrets are here shared among all the members of the group and nobody outside of the group and we\u0027ll use that to initialize to initialize a keystroke II schedule that people use for sending messages yes I guess the only thing I would add is that this sum should look pretty familiar because we\u0027re using the same structure kind of its TLS yeah the things the meanings here are slightly different a gif extract is the same but derive secret is slightly different because we\u0027re folding it in group state as opposed to some of the things in TLS Fulton next so kind of follow up following the example of double ratchet here we want to get forward secrecy on a per message basis so we\u0027re gonna have "
  },
  {
    "startTime": "00:09:34",
    "text": "hash ratchets some sort of hash ratchet that advances from one key to the next on a per message basis and the question here is whether at what level we change kind of what shape of hash rhetoric we wants do we want one hash ratchet for the whole group that then it\u0027s kind of a long ratchet which with branches at at each at each step in case people send it in parallel or do we want a separate independent ratchet per potential sender per group member each of these haven\u0027t have different trade-offs but the whole idea overall in either case it\u0027s a bribe provide forward secrecy so they use a different key for each message and you can then burn those keys we delete those keys to to get forward secrecy later yeah Russell so is the goal really per message PFS or is it per instance of the key schedule what would you say is the difference there because you\u0027re not gonna update the key schedule for I can think of applications where you\u0027re not going to update the key schedule for every message but you\u0027re gonna see for NIH\u0027s send a couple of messages people come or leave the group then you change it then you send a couple of essence and so on let\u0027s say do we have a picture of the key scheduling sorry these are Benjamin slides I know I understand yeah so right right now as as we have it right now the key schedule drives an independent key and nonce for each message and so you really do you you are operating at some level per message regardless of how you construct this see like right there the on that slide you have a nonce it\u0027s so you\u0027re just saying if I update the nonce for every message I will get P FS for the message and if I keep it stable for a group of messages you know because once we yeah so I mean so forget let\u0027s forget let\u0027s forget about the multi-party setting and just assume that there\u0027s a one party setting so I start with this shit I start with we have a shared key and I um and in this version I Drive a key off that to do insight from it and then what I do is I throw away that key and then for the next message a drug new message any definite set from it and continue and so on the on so every message if it\u0027s in fresh bean a fresh nods um and yeah and actually it just just I want there\u0027s like make sure if you don\u0027t forget this in the set of constructions in this document like assume that incredibly hard and so if you were to attempt to deviate from that I mean there\u0027s no I wanted to clear "
  },
  {
    "startTime": "00:12:34",
    "text": "technically there\u0027s no problem like as long as you\u0027re willing to give up the security property they\u0027ll like this is attempting to achieve there\u0027s no problem with like using you know the same application secret from little messages but separate nuns but this particular key construction tries exactly the same nonsense at the same key every time and therefore be incredibly bad that you had so if we wish to if we wish to have to rely constraint we have to change the keys get the one number of ways and that\u0027s true for the interleaving as well that\u0027s true yeah in general the thing people should keep an eye out for here is the risks that arise from a kind of potential state reuse that could arise from you know sloppy shutdown or whatever so if you shoved it if you in sight for a message and send it and then shut down without marking that application secret has they haven\u0027t been used and use it again then you\u0027ve got an answer you situation that\u0027s an interesting point Richard um which is that I\u0027m given that in this design you generate you generate a fresh very fresh key for every message you one might argue that it would be better to generate also a random dots and he says diversifier the key generation to avoid this date we roll that problem you just indicated no no sorry so in so like let\u0027s consider the problem you just you just suggest it right which is that one is supposed to do isn\u0027t supposed to generate key and generate key and in Cherokee n here right I\u0027m send a message and then throw away you know then throw a key and generate key M plus one right it\u0027s but imagine that like I\u0027d make exactly a mistake you just indicated which I generate PN I I send a message with Kien and then I crash and I don\u0027t VariCam plus one now as you say have a horrible state reuse problem when I want back up again right so um if in this and put in if in this expansion stage now like like ordinarily like I mean I\u0027m sensitive this guy planes that another protocol there date like ordinarily like an TLS or IPSec you wouldn\u0027t worry with this because like the states all soft it would go away but in this case it\u0027s hard state so one way to fix that problem would be to replace um that the empty string in those key in the HTF expand labels with a randomly generated value that was part of the that was generated before you sent the message and it passed the message as own IV and I mean you could also just never have a random nonce but my point is like that like you could if you added a written if you added a fresh randomness as opposed to deterministic rid of this at this point then you wouldn\u0027t have to worry so much about cute about that I said Alt key were use and you wouldn\u0027t need like a normal Mouse right tom I mean probably you really only need like as a practical matter you don\u0027t need enough don\u0027t like the chance of that like the chance of like collision was like you know is it we\u0027re suitably small so probably for probably for date on catch will be enough this is dkg you could also just actually have four day doc tats every time that you your process starts right across whatever "
  },
  {
    "startTime": "00:15:35",
    "text": "whatever so you just mix that in here yeah although the members of the good need to be synchronized in those port a doc tests and so you know they they know it if you\u0027re just you if you\u0027re just misleading to the nonce generation and you\u0027re shipping the knots with the message okay III guess another thing to note here is that even if you do reuse this nonce key pair it hasn\u0027t compromised the application secret and so as soon as you ratchet forward you\u0027re you\u0027re clean again and it\u0027s only those two messages that were used that are that are that are bad that\u0027s correct it also doesn\u0027t it also isn\u0027t as bad even with GCM it\u0027s not as disastrous as it ordinarily it would be probably because you\u0027re in a sign and so the intent the horrible integrity toxin GCM are not quite this is really quite horrible well which I mean didn\u0027t to say it\u0027s good this is the interesting question so this is what I was hinting at in terms of the shape of the key schedule so I got like I said so the either way the primitives gonna be kind of that hatch forward the application secret approach the question is whether we hashed that forward on hash forward one common application secret value that is shared by all the members in the group and that gets hashed forward every time anyone in the group sends a message or whether we take the initial application secret and generate per sender routes of hash ratchets and then each one of those ratchets updates independently when each sender sends something the benefit of that former approach where you have a common ratchet that updates whenever anyone sends is the only it\u0027s a store one thing and so you get slightly cleaner a forward secrecy slightly easier forward secrecy because you can just you know keep around the last ten states than anyone said and erase anything older than that the challenge of course is that because you\u0027re dealing with the timeline of the whole group if someone comes back to the group and doesn\u0027t have real recent state they might send a message with them they might have to kind of branch it off a whole way forward before they can send yeah I don\u0027t think I\u0027m persuaded by this forward secrecy argument that don\u0027t think it\u0027s backwards so I couldn\u0027t even walk me through it again so forward secrecy and these diversion I\u0027m familiar with the first to rehearse to compromise and the key after the data was sent and received and so classically for if you\u0027re running individual if it\u0027s first of all its second or plus it\u0027ll mess up sure you ignore message loss summer green it\u0027s not party argument sure okay so I\u0027m assuming that at the beginning of time everybody\u0027s storing um we appreciate you so we pre generate promised promises change for everybody in the system right so we have your keys that box zero for "
  },
  {
    "startTime": "00:18:35",
    "text": "everybody right and then uh if I receive a message for someone that by zero then what I do is ignorant that part one key and the throwing that back to zero case to not have PFS respect to the messages I received right so by contrast in the case where in the case where I have only one chain because I don\u0027t because because there\u0027s because there\u0027s some there\u0027s some parallel activity when I receive a message that this message we that Park zero what I do is I hold the upon zero key for some time wait interval and then and then I discard it and as and then as your M plus one and then once the time we didn\u0027t if it\u0027s expired I throw that box your keys used to be the the PFS duration is strictly worse in the one change situation but maybe I don\u0027t understand your argument no no I think that\u0027s right I think that what your point is that there\u0027s ambiguity in the single changes entertain it because the these group ratchet case because you don\u0027t know when you can burn a key that\u0027s been right if there were pure synchronization I think these would have identical PFS properties I think that\u0027s right I don\u0027t think I agree I think I just think this I think you just have like you\u0027ve got the Plus on the wrong tongue well I mean it is improved in that you only have one thing to delete you don\u0027t have to yet that\u0027s true I think I think that the perhaps the thing that the that this what this does apply to however I think is that there\u0027s a naive implementation of / of perching keying that actually has incredibly terrible PFS properties which is to say that i store the original person their chains or yes / center chains sorry um which is that I store that instead of generating the percent or application secrets I just store the the root of the tree and then generate them on demand and that obviously is hideously terrible on properties though you and I of course I\u0027ve talked about a tree version and removes that but I mean but so like I think if you actually wind it if you actually are going to throw up the storage then this is then you have as part of it good good but if you nay evilly don\u0027t do that maybe if it\u0027s probably quite terrible yeah so that\u0027s the point about the the person your ratchets is that you know either you have to store a linear number of of states one per sender or in order to avoid this is storing the great problem that echo mentions or we have to come up with some tree based structure so that you obviously break out each sender as they send and then you have you can store kind of log size stuff for everybody else yes I agree that good and you know as much as we hate linear stuff in this working group I\u0027m not sure it\u0027s really merits the complexity too good to do that tree thing unless ya feel strongly about that and I think the unfortunate thing with the tree thing is it actually is it requires changing the key computations namely that you can\u0027t like so right now the key expansion is per Center and what you have to do is effectively construct a binary tree of senders and then and then basically walk down this way to compute each each leaf "
  },
  {
    "startTime": "00:21:35",
    "text": "so it\u0027s not something you can compatibly decides to do you have to do it absolutely yeah you can\u0027t simulate this the entire group has to agree that\u0027s right algorithm yeah and and of course means the target must agree on the tree structure don\u0027t preach that\u0027s already the case that I\u0027m not so worried about because we have already a bunch of stuff that presumes agreement on the tree structure yep yeah that\u0027s my understands well I think me tomorrow I think both of them are common so I like I like them I like divergence for EFS but I disagree with the complexity I think both of them are complex in Tunisia you mix them with without the key updates I don\u0027t know which key was watching this review chickie however I think the group is changing is more complex in what\u0027s in terms of synchronization right because all of them are competing for the single value at for high dynamic group this would be very terrible like you have to force ordering for the message you\u0027re not for that so before we were talking about forcing updates for the handshake messages now we are forcing ordering also for the user message which I think would be pompous yeah you don\u0027t technically have to enforce ordering because you could ktf person they\u0027re off each step in the group ratchet to you know avoid collisions in the same time stuff but you know that\u0027s yet more more KDF and it has the in still has the ambiguity property that I could pointed out so yeah I know in order to get a clear forward secrecy property you do need the synchronization you don\u0027t need to you don\u0027t technically need it to avoid keynotes collisions so if all you want is to have um per is to have a common key at each epoch and you don\u0027t and you want to avoid sender um sender collision on my count um you don\u0027t need another KDF in that stage because you embed the sender in the knots and so like so I mean I don\u0027t think there\u0027s a big deal what kind like this protocols like hash crazy-like are like all not another 19 protocols but not in the the performance of the the performance of the of the group keying a substantive energy Lenora hashes and one thing is worth pointing out about this design actually which might motivate the the tree actually is that in a large group the amount of like basically bogus keys you generate is fantastically high right namely you know I\u0027m in a 10,000 person group and like in each time step probably one person ascending and um maybe no one\u0027s there after each each whatnot times that\u0027s right in each group um iteration so if you think the overall drew structure right or him the group structure changes to a Kia piki that exist are never a key update step only a small fraction people are sending but you\u0027re forced to generate the the chain at the head of the chain for every single person\u0027s and in order to have PFS right I mean you can like cheat a tiny bit like if you don\u0027t generate like any of them until the first message you receive is sent um and then hope that like and then like hope the key update "
  },
  {
    "startTime": "00:24:35",
    "text": "will come really fast but like so I think that that\u0027s actually a more serious problem the storage books the storage I I mean like my argument the storage here is that most of these systems like keep history anyway and so if I stick with a bottom line is asking the domina storage cost but the idea of having to do you know every time the key if they change or hit the kid they changes but I\u0027ve got to do 10,000 hash at 10,000 KH k BF says it\u0027s pretty offensive so I think I think now that I\u0027ve like made this point I think actually that if we\u0027re gonna absorb that I\u0027m still in favor of the other profit percentage or Jaynes but I think we probably have to the tree this is T kg so I\u0027m just wanted to observe that when we talk about forward secrecy what forward secrecy means is that the adversaries captured a message and then they exfiltrated a key for the message from somewhere that has it still stored and to get forward secrecy every copy of the key needs to be destroyed I just wanted to observe that for a 10,000 person group some of whom are not online there\u0027s gonna be copies of the key that lie around so I mean once again like the security properties that we\u0027re talking about here start to sound a little bit dubious as we get into the scale of groups that require the kind of engineering you need for for the you know the 10,000 like the kind of engineering you need that requires the key tree structure that we\u0027re talking about right so you\u0027re saying an in small scale you don\u0027t need the tree structure because it\u0027s not enough to be appreciable optimization right if I\u0027m talking too large it might as well 100 people that I do 100 H PDS who cares and but if you\u0027re talking to 10,000 people you\u0027re not getting that much benefit from the for secrecy I do not convinced by the forward secrecy in the in the 10,000 person case I mean I wouldn\u0027t complain if we had a mechanism to do it but you know if we\u0027re talking about this being like super complicated engineering that has more tricky failure modes that makes me nervous yeah you mad you have any thoughts on tree versus linear KDF I believe is a linear I think it makes more sense very intuitive than carotids the question might be a more of architecture question like if system support house for the delivery how big should be the window which should have recommendation like if we save message hundred Julio register case hundred time but if we if a very good message 1,000 could you fix the window 1000 which is very big but maybe this is a fun quotient different discussion fourth architecture effort yeah I think there would be something interesting for the architecture you have that thank you for suggesting a poor request on your own document all right so it sounds sounds like the the consensus here is is around this person to ratcheting and I\u0027m pretty sure that\u0027s what\u0027s in the document right now so good job pass Benjamin on getting that answer right before we had this discussion next slide please "
  },
  {
    "startTime": "00:27:35",
    "text": "oh okay I think this is just more of the key schedule stuff that we talked about before yeah Q : Q : okay so talking about the actual message encapsulation that we\u0027ve defined here and which is kind of how these keys get applied the idea is to get the the key schedule kind of provides these forward secrecy and NPCs properties between the hash ratchet and the the group handshake messages and then the so secrecy is provided some encryption will do on the account encapsulation then we\u0027ve got kind of two levels of authentication we\u0027ve got a Mac or a EAD under the group key that authenticates that the sender is a member of the group and then we have signatures in addition to disambiguate which member of the group sends a message it\u0027s a mixed slide please so the internal interior you know right so this can you go forward one more slide sorry I forgot to reorder these in the arrangement I liked better right so we\u0027re kind of following as we do often here some lessons from TLS we\u0027ve got some serialize content and a signature over that content that goes as the the kind of internal of the thing that is encrypted so the kind of order of operations here is you take your content you you encode it you compute a signature over it and what was on the previous slide as you sign the content together with the the metadata about where you are on the key schedule and then you take the content and signature and you basically encode it as a plaintext with with whatever padding you want to add so for traffic analysis purposes just like in TLS we allow the application to add some padding to hide the lengths of messages then that plaintext message is encrypted under the group key that\u0027s right so the the again the signature authenticates the specific sender of the message within the group and then encrypting under the group key provides the confidentiality and the authentication that this is a member of the group and you know a member of the group according to where you are in the key schedule so ultimately we end up with this application message which is what we send over the wire the group which is slightly wrong type here that just needs to be an opaque byte string identifies what group you\u0027re in the epoch identifies where you are and the overall handshake key scheduler coarse-grain key schedule and then the sender and the generation identify where you are in that / / epoch hash ratchet trees so that the sender is what kind of which branch of the of the of the tree you\u0027re on and then the generation is how far down that chain you are so the processing here of course is you you look up the key based on those four fields you decrypt the content you verify the signature and then you\u0027ve got "
  },
  {
    "startTime": "00:30:36",
    "text": "the author the content that\u0027s authenticated from a member of the group now you know even one thing you might notice is there\u0027s no that the only identifier public key here is the sender ID that UN 32 there and the presumption there is that the nodes are keeping around a list of identities and public keys for the other members of the group that that is one of the pieces of linear size state we have right now and so it\u0027s possible some earlier revisions had didn\u0027t have that requirement for linear state and carried proofs the Merkel treat con sense of the signers membership in the group so G this is d kg just wanted to point out that given our previous discussion about potentially needing to ship a nonce if we didn\u0027t want to have this nonce reuse potential problem then there\u0027s no place for the nonce here yet so that would have to be added here outside the in the application construct here that\u0027s right yeah that\u0027s where you have to happen all right I think and I think that\u0027s basically it what else yeah so a couple of open questions at the bottom here I think we\u0027ve discussed the top stuff pretty well there\u0027s there\u0027s two cipher suites and document right now which differ only in terms of which elliptic curve is used P two five six versus curved to five five one nine they both use aes-128 for their a a EAD if people were interested in a higher grade cipher suite that was using bigger curves and aes-256 that could of course be added there are some discussion on the list about AES GSG cm versus SIV I think given the discussion here I think we\u0027ve got a pretty safe use of GCM would be interested if people thought that was not the case and we needed to move to SIV but there\u0027s kind of some document performance issues so the feeling of the discussion at the internment wasn\u0027t critical that we moved SIV that we there was a pressing need occur do you have any I remember you were active in that discussion you remember anything to highlight here not really is a I\u0027d forgotten that um that the safer streets were tied at the curves that\u0027s I mean I saw my first design that did not well not the when we drove for DLS I\u0027m wondering with them with Russian Alice I don\u0027t think we ever had a real detailed discussion about it I think the idea was to just say it\u0027s a bundle pretty much all the primitives we needed in one because there weren\u0027t that many comments were competent torques that you would want in practice that\u0027s what we thought too um they\u0027re obviously obviously the pendulum seems like yeah for of course yeah um yeah I\u0027m not like particularly bent about it um I mean some of some of the feedback when this when we first released the drafts was you know why do you have such for sweets at all yeah sure there is that body of thinking and in literature so I think you know in "
  },
  {
    "startTime": "00:33:37",
    "text": "between negotiate on the version number only and full combinatoric possibilities having fixed Leiper sweets was kind of an intermediate is sure I\u0027m not I\u0027m not bent about that um yeah sure Katie yeah so are you saying that this this aligns with that philosophy is because we have one cipher suite joint yeah so and we already have some exercise of that joint here because we\u0027ve got two implementations going the one that I\u0027m working on in C++ and when the wire folks have been rust and actually I think Benjamin has won an F star that he hasn\u0027t quite released to the world yet but we\u0027ve got three different implementations which started off using two of the decipher Suites so I didn\u0027t line with PG five six the other guys use curfew five five one nine hour hack both trying to add agility so that we can talk to each other so we\u0027re already exercising that joint the last thing we just had a little bit of discussion with about at the interim was earlier I wanted to have some basically whether we wanted to have the length field the the length of length bytes have enough length bytes there to accommodate potential post quantum primitives we might have for the the key exchange values and we I think we also aim is of not deciding not to do anything about that because you know in the postponed world we probably have to change other things besides the the number of length bytes we have and so well we\u0027ll cross that bridge when we come to it we\u0027ll see what bigger changes if it only is the length bytes it\u0027s an easy update so I think all this is in the document right now it\u0027s in the draft as as pretty much as described here so if people have comments we\u0027re glad to have them they should be able to see it in drafts and see if the draft accurately captures what I\u0027ve convinced you up here today and whether matches expectations and it seems like a good construction hacker can you just go back to the signature construction yeah yeah so I think this is the only piece that I have a little bit of a chat about and I\u0027m not really like bothered by it a lot less writing at all but I guess like you know this got added this got added partly because like parties guided because we have this cut and paste attack between the different different groups and I guess like this isn\u0027t necessarily a bad design in any way but like know what they\u0027re like I\u0027ve not seen any analysis this is exactly the rice of the things to put in the ginger and so I think this is the point that I think we like we need to like spend more time on is like I don\u0027t know does this meet the mood of the hash tree or does it need other like some other nonsense right I\u0027m just like I don\u0027t know I guess probably it\u0027s probably fine but like you know like um you know I just like I know how I know has Custer I think I made I was just like like I said Benjamin email one day it was like like you need to put this in "
  },
  {
    "startTime": "00:36:37",
    "text": "head so I\u0027d encourage people to like think about this problem oh but look at this and make convince themselves that this is the right set of things it has to be psyched because um you know like you know then they look okay but and then for the purpose of like you know it\u0027s like for instance is it possible to have too is it possible to get two groups of the same group ID um you know I don\u0027t know right um it\u0027s up to the architecture up to the overall system this room right I mean this is I mean there\u0027s no rules about group ID selection right so I mean so that so so I mean I think it should be clear that like if it\u0027s possible to groups the same group ID then this allows cut attack and then people also reserve any keys now you\u0027ve got to pay for that right and so on um so again I haven\u0027t like thought about this too for too much but I\u0027m just like saying like this that this is the piece we need analysis on and then and press T on it\u0027s the resting that\u0027s kind of like the straight mr. yeah thanks good point um so this is dkg following up on what I said the kind of analysis we need here isn\u0027t actually I think particularly formal analysis I mean we also need that but the analysis that we need the the the classic kinds of failures that we\u0027ve made for decades are where there\u0027s message signatures over something that doesn\u0027t include the the right context right and so for example I am sorry I haven\u0027t followed clearly enough to know exactly whether epoch and generation place the message in a particular point in the stream or whether due to potential for a message reordering or whatever you could make this look like it was replying to somebody who it wasn\u0027t actually replying to or to previous message that it wasn\u0027t replying care yeah it puts you at a given point in the key schedule that doesn\u0027t necessarily map so kind of the timeline of messages right that\u0027s where I feel like the the formal analysis is not necessarily gonna do us a lot of good because the formal analysis as far as I can tell rarely extends to like can you confuse someone about whether I\u0027m replying to Richard or whether I\u0027m replying to Erik now that also reminds me of one thing that isn\u0027t one feature that\u0027s not in here which is any idea of conversational integrity I\u0027m so some of these message security systems you see a message of tests the last predecessor that it\u0027s thought so you end up with a dag of messages and we haven\u0027t we don\u0027t have anything in there right now but I think it would be a straightforward and perhaps useful thing to add yeah so I mean the issue with a dag of course is is rendering to the user we don\u0027t know how to do that well especially for large long threads but I I would tend to and the other the other issue with a dag is that out of order delivery can appear different to different parties even with the dag and so so there there\u0027s room for confusion just with timing applied to the dag but still the dag is significantly better than completely context-free like and my next message to the thread was X right so I do think we should think about some kind of representation there yep if you would like to send the PR be happier you all right ok thanks Richard and speaking "
  },
  {
    "startTime": "00:39:39",
    "text": "of which could be good to know from the folks in the room who has who has read the the protocol document the latest version draft - ok and of the people who haven\u0027t read it please take a read and we could definitely use the comments and so of the people in the room who\u0027s willing to do a full review of the the current document as is for the protocol document ok ekor and I won\u0027t Chris I believe and we didn\u0027t discuss the probe the architecture document here but is anybody willing to do a review of the of that document the architecture document of the folks right here ok we\u0027ve got a few hints so great AG occur and Richard Kevin we got one from John Macmillan and Joel as well we\u0027re getting there so the formal analysis stuff we didn\u0027t actually I put it on there as aspirational as hoping we were at something and we didn\u0027t I know that car thinking cats are hard hard hard at work we\u0027ll try to make sure we have something next time but we basically bashed around in Paris when we might have our next interim and we figured it would be good to try to suck the some security researchers in and it was suggested that possibly we do it a little before or a little after on the real crypto 2019 and this is there at the splash page so we\u0027ll put out a you know doodle poll to see whether it\u0027s get better to go before or right after so we can kind of second the the security research crowd episode there any any comments objections to this we\u0027ll be posting this on the list as well as collecting information as to who would attend and who would not attend if were the proposed location for the interim all right thank you very much and that concludes our session thank you [Applause] "
  },
  {
    "startTime": "00:42:39",
    "text": "[Music] "
  }
]