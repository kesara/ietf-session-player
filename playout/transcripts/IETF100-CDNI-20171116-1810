[
  {
    "startTime": "00:00:10",
    "text": "you ready yeah we got ready good room the people about 15 people here maybe all right actually blue sheets are going around Matt\u0027s gonna do Jabbar and Magnus is gonna do notes he asked for somebody to help him on the the ether pad somebody could do that that\u0027d be awesome anybody Bueller Oh Kenda\u0027s gonna help excellent all right let\u0027s get going it all right everyone this is C D and I thanks for coming I guess for you guys it\u0027s the end of your week hopefully everyone had a good week fill you I go next slide this is C D and I this is I guess we have minutes tankers and blue sheets next slide I don\u0027t know if there\u0027s just like really bad lag but all right there\u0027s the note well everyone should have seen this all week know well that all of your contributions are subject to the rules of the IETF IPR and whatnot included next slide please my connections really bad this is our agenda if anyone has any complaints now is the time otherwise we have three presenters today and then the chairs have a couple of questions at the end if no one has any objections to this agenda we\u0027ll go ahead and get starting to get started and Phil you\u0027re up first all right nobody\u0027s objecting alright end of the day end of the week no better alright I\u0027m just gonna hold on to it I hate these mics alright so what have "
  },
  {
    "startTime": "00:03:10",
    "text": "we done since Prague [Music] there we go okay so drop to draft 13 lucky number 13 here\u0027s what we changed on here we added a registry for CD ni s TT that was to do - support so that they could add different values in that we added back the text about the key usage symmetric versus asymmetric this was brought up on the mailing list relatively no big deal stated that key distribution is out of scope I also went and made the HTTP adaptive streaming support more generic and I was asked to not call it token chaining I was told that the security guys were offended by this because wasn\u0027t actually doing chaining by including content and the previous token going into the next token so it\u0027s now called token renewal and some other small typos and stuff like that really there we go okay so changes from 13 going forward we\u0027re still not done we have an implementation though so rough consensus and running code we have running code now this was done at my employer Comcast and during the implementation Chris lemons who I believe is on the meet echo ran into a few issues and he opened some some github be ours so these are the the some of them were real minor I was able to merge them and actually get them into draft 13 some of them are a little more involved and so I wanted to bring them to the working group and see if we could get some consensus on them so the first one number 28 replaced the audience claim with the CDN IIP claim I\u0027ll explain why this is kind of a big deal in a minute the next one is number 29 make CD and I ETS mandatory when using the sign token chain this one seems pretty trivial but wasn\u0027t quite sure about how to how to word it so we could put it in the claim description and just say you know a requires B B requires a kind of deal or we could put it in the actual token renewal section "
  },
  {
    "startTime": "00:06:11",
    "text": "and describe that to properly do it you need to have both so it\u0027s kind of a trivial change but wanted to get the wording right for it number 30 changing subclade to CD and I you see and introduced new sub claim this is kind of related to number 28 and I have exercise about this but both of those are kind of unfortunate parts of the JWT RFC number 31 is clarify the definition of parameter this has to do with the fact that query parameters are not actually specified anywhere they\u0027re just kind of a convention that everybody uses so we figured we could explain how we intend to use them in the document number 32 is chicken-and-egg problem with uri containers this is how we need to specify to strip off the uri signing parameter before we validate i think it was something that we kind of thought was obvious but didn\u0027t you know took for granted but when somebody\u0027s implementing it they need to need to know that and limit number 33 limiting globs in the URI container so let me go on to the next ones here so replacing the odd claim with the CD and IP claim this all this laser pointer yeah so this is from the JWT spec and it says that the the principle intended to processor JWT must identify itself with a value in the audience claim and we were using this for the client IP so the CDM is clearly not going to identify itself with any value in that audience claim and it says if it does not do that it must be rejected so there\u0027s very specific usage for the audience claim and we\u0027re just kind of misusing it so the PR for this essentially adds a new claim in inside the CDN i namespace and treats it how we treated the audience so it\u0027s basically a new claim with the new name so any thoughts on that or bad feelings or good feelings I saw Matt back there nodding no okay this is the CD and I ETS being mandatory for a sign token chaining seems fairly straightforward I would love to have some feedback on the PR if I don\u0027t get any I guess I\u0027ll just come up with some wording for it but I think we need this this is another one from the the GWT spec where we kind of ran afoul of it so there\u0027s two things about "
  },
  {
    "startTime": "00:09:11",
    "text": "this one that are really interesting so it\u0027s of type string or URI and what they define that as as any string but if it\u0027s if it contains a colon it has to be a URI so all of our containers first of all are prefixed with something like you know URI - reg X colon so we\u0027d have to fix that for one but in the regex case if you\u0027re making a regex against a URI you\u0027re most likely going to put a colon in it and it\u0027s most likely not going to be a valid URI so an idea that was tossed out to correct this was do something like escape Co escape the colon unfortunately it also specifies that no transformations or canonicalization czar applied so unfortunately they just don\u0027t want us to use this for anything other than your eyes or strings that are not your eyes so this creates an another new claim under the CDI namespace that has the same behavior as what we had in sub before so it\u0027s kind of a big change because it\u0027s a new claim but I think we have to to not be breaking the JWT spec any thoughts on that one I guess you guys are always wiped out as I am all right continue on this is what I was talking about the no real definition of query parameter or path parameter so we just need to have some text in there to clarify that this is talking about the URI signing package needs to be removed before matching the URI and we need just a plain way to do that so limiting the globs in the URI container basically the glob can be because the way they\u0027re specified they\u0027re overly greedy and you can make them match a URI that they weren\u0027t intended to by adding a query parameter and then putting the matching string on the end and it\u0027ll match any URI on the front end so the change that was put in this PR from Chris made it a bit more strict but I wanted to bring up the issue again on whether we need this container because we have the full regex support there was there was we added the regex support the feeling was why get rid of the globs because they were simpler to implement and simpler on CPU but in light of security issues and ones that we might not find in the future I "
  },
  {
    "startTime": "00:12:13",
    "text": "was just wondering if with everyone thought we still needed this we could just add this text and keep or we could remove it entirely everybody familiar with the glob the pattern one that I\u0027m talking about what\u0027s that gently um yeah gee I assumed this is the simple pattern case right that the one sir can you speak up I can\u0027t oh okay the microphone um yeah so the glob that you\u0027re talking about this is a simple I mean basically there are three cases right so this is not the red X all right this is correct it\u0027s a simple one okay yeah um like he said I think I mean I can\u0027t sit in the mailing list - right it\u0027s more of a historical you know that initially we had something well we we call it simple right for the reason that it didn\u0027t require the full where I gets and all that stuff so um I don\u0027t know the rationale that we had before is gone now I mean I think that\u0027s the part you know I mean there was a rationale to be able to simply no I didn\u0027t say that so I guess I\u0027m I\u0027m still a bit on the fence on this one I guess yeah I think it was the original one and then when we added reg X we said well is there a good reason to remove this one and I don\u0027t think there was so we just said well why not we\u0027ll give people the option it\u0027ll be in the draft people can implement implement it if they want or use it if they want but now it seems like there might be a reason to remove it and I\u0027m I\u0027m kind of on the fence on it - but echoing for Chris lemons essentially steps back a little bit another issue with the sub claim is that is designed for the subject which seems to be interpreted as the user bearing the token yes so let\u0027s go back to that one so his thought was that it was about it was about can you read that again another issue is that the sub claim is designed for the subject seems to be interpreted as the user bearing the token okay yeah so he did some research because it wasn\u0027t he can correct me if I\u0027m wrong but he did some research and there wasn\u0027t anything specific in JWT the JWT RFC I didn\u0027t find anything in there either but he looked at other usage in other RFC\u0027s and found that to generally be the case so I don\u0027t think that that was anything that we had to change but if we wanted to be in line with the way other people used it we should but I think I think the : issue and the no transformations issue are much more cut-and-dry and I think they supersede that so just something "
  },
  {
    "startTime": "00:15:19",
    "text": "that matthew miller i mean at this point it\u0027s kind of i mean like you said the syntactical requirements kind of muted but just want to point out i mean that subject is meant for the entity that flames are over flames are over the uri it seemed appropriate up for the you know syntactic problem yeah I agree it\u0027s it\u0027s really I guess it\u0027s a moot point at this at this time so all right let me jump back here I think that was you yes can I jump in I am in favor this has an individual I am in favor of new sub claims and in general I think OCD and I specific ones make more sense since we aren\u0027t using them exactly like everyone else is and then on the last slide the the question was about the glob if if folks are okay with the matrix I don\u0027t really see a good reason that we have to keep the limited glob we had originally done just to make it simpler our end and and it was partially because we decided we didn\u0027t want the regex but if we\u0027re gonna take the regex then I don\u0027t really personally see a huge point in keeping the other okay I will create a PR that removes the simple pattern matching and post a link to it on the mailing list and give people a chance to to give more feedback and if we don\u0027t hear anything we can we can go ahead and merge it lessers though Chris lemons selling past the close jeido UT RFC just calls it the subject but doesn\u0027t define what subject is and he determined subject by looking at existing implementations okay um so yeah I just want my comment that I think there\u0027s silence because I think I agree with pretty much what what you present it basically right it\u0027s just the last one on the simple as lawanda I had Olympic on the fence issue but um I agree what I think they wake or go forth right I just probably create you know delete it publish it thank you yes one last chance people say I don\u0027t like it I otherwise that\u0027s alright sounds good I\u0027m gonna insert myself in here at chosen so do we think that version 14 will be ready to go the last call do you have thoughts on where we are well we we have an implementation now and we will actually so the the use case for it "
  },
  {
    "startTime": "00:18:24",
    "text": "will be in February you can figure out what that might be Comcast NBC so I\u0027ll be able to publish after we get real usage and and before London and so in London I will feel really good about saying yes and right now I would say I\u0027m really optimistic about saying yes all right excellent so I\u0027m gonna insert myself again I it\u0027s 5 a.m. here and my brains not working very well we skip the doc update but there weren\u0027t really any doc updates there are no new RFC\u0027s we have the bunch come out and before Prague so I\u0027m just going to go ahead and keep skipping that and we can move on and let Frederick start you I whew so I will present the last date from Umbra so I will start with providing some insight of the date we have next I will explain what which you bought we we I did for the delegation methods particularly on ik mister in today\u0027s subsets draft then we I will talk about the definition of security negation metadata we have two options that we consider in this draft and which need to be discussed actually so we have some pros and cons and finally we consider other area for study so to record a bit goal of this document is to propose some extension to the c2c dni metadata interface to exchange metadata this "
  },
  {
    "startTime": "00:21:26",
    "text": "version two updates the the delegation object we we defined in the version 1 so we in the version when we add support for short term automatically renewed certificate the ik mr. draft and in this version we consider delegate it will ensure for Tila subsets so the JIRA subset draft which has been recently adopted by the jealous working group so to recall a bit acme star draft did the use cases that you CDN delegates delivery to the CDN requesting the CA to issue a shortened automatic automatically renewed certificate and we hear we had a new metadata object to support this method basically by adding some properties namely star proxy and Acme server so these two proxies to properties should allows the CDN to contact the you CDN and to renew politically the certificate so basically this could be used at initially initialization phase and at the renewal phase in this version 2 we add the support for TLS subset so the you CDN delegates delivery to the CDN using its own credential without the need to request a certificate from this year so the TLS absurd method so here we add a new metadata object to support this method and so we have two subsets delegation method with a bunch of properties the credential delegating entity the credential recipient entity credential location where I and parody city and those property so the credential delegating entity will be fine stones will be the you CDN so we need to have the address of the endpoint of the you CDN then we that will sent the delegated credential to the DCN and we have the credential recipient entity that basically the the decision or several of the d CDN then we are also have the credential location where i and the periodicity one important object we we defined also "
  },
  {
    "startTime": "00:24:27",
    "text": "is the secure delegation objects why do we need such an object it\u0027s because in the case that the you CDN delegates so deliver to the CDN we need to convey delegation information about how the delegation will be enforced and to do so we propose to model to the two options that could also you see the end to describe a secure delegation for the CDN so the first option is a secure delegation object define as the top object so this means that we try here to specify the delegation once we define the decision for all pass and domain of the city and interconnection in in in a global object but currently we can say that this method doesn\u0027t exist in the RFC 806 and thus it requires a new delegation a new object here we call we call security Legation so we have in this object we have of course the delegated domains we have the past patterns that are concerned by the weather delegation and we also support in methods a delegation method for the further delegation the second option we have is to provide an extension to pass metadata that is already defined in the RFC 806 and this methods involve the definition of delegation metadata for each pass URL of the delegates identity so basically is the ideas to indicate for each bus which has a delegation delegation methods that are supported so a slide that shows some examples so yes I think we can maybe we can move on to the next okay so we try here to evaluate the pros and cons of each option so we consider the option one as as interesting because we can provide easily information about the delegation in one shot but drawback is that it "
  },
  {
    "startTime": "00:27:31",
    "text": "extends a bit the CDN cDNA metadata model so maybe it\u0027s not that quickly how to use it for now the option two is obviously fits obviously inside the RFC 806 but the drawback we can say that it may require us to repeat the pass the pass dedication metadata for each pass so maybe it could be more greedy so the last slide to say that we have the next step we envision to identify ozone needs on sadena interfaces to support the HTTP delegation we might want to find some methods to provide purge or for certificate when you all if necessary so through other interfaces there was a point is to possibly discuss all the delegation solution for cDNA so here we have listed lakh and OB so such solutions are not uh not yet accepted in the IETF but anyway they can be good candidates for delegation and we have also the next presentation that could be used also interesting next time so thank you so one comment from jabber by Robert Mugabe Mugabe do you need to repeat the delegation metadata for each pass you could make it a different use a different resource last URI and link to it that\u0027s a possibility yes we think that made the option one will be maybe more easier to to use [Music] can can I insert myself yeah I I also think that listing the pads in an object versus having the pads listed elsewhere I don\u0027t know that there\u0027s a lot to be saved there I agree you could link it and where to save on the object itself but it seems to be from my personal "
  },
  {
    "startTime": "00:30:33",
    "text": "opinion as an individual and as a metadata author it\u0027s it\u0027s making a custom object just for this one thing and that wasn\u0027t the goal of the metadata interface right we tried not to duplicate that data like past data because that the paths apply to other metadata objects and so the the structure of it would be significantly changed by this and I\u0027m not sure that it\u0027s that it is a change in a good way but if there were more details on why it\u0027s why it would be necessary that would be helpful I understand your remark yes maybe he\u0027s a reception one would be more concise I don\u0027t know yeah I took a look through the draft and there wasn\u0027t enough really there for me to come up with a good reason why it\u0027s significantly better or necessary but if you have more on that then we should talk about it anyone else all right I believe or is up next everyone so this is work done by Sanjay Mishra and myself it\u0027s a result of work we\u0027ve been doing when the streaming video Alliance and architecture that we\u0027re calling open cashing the obligation basically is a kind of a CD and I just that the CDN is a commercial CDN and the the use again is the commercials at the end and the D CDN is an CDN within the ISP and it actually takes they takes out that we had while specifying and starting to implement it starting to implement it and we came across lots of issues and we started thinking how to solve them and some of them we think should get back into CDN I so I\u0027ve discussed what\u0027s open caching is so maybe we can go to right so we\u0027ll start with the easy stuff just a bit about request so the first thing we would like to discuss is how do we discover the request out or Alice currently this is not defined by CD and I and the second one is what do you do "
  },
  {
    "startTime": "00:33:35",
    "text": "when you have to do fall back from the D CDN back to the you CDN looks like this so let\u0027s start with them request I\u0027ll to address so there are quite a lot of use case is why we need that two of them is that we want to have different request auto addresses for different footprints some CD ends have global or nationwide presence and we want to have different request authors for a different location another use case is scaling by adding more request routers so again this should be by footprints so the what we propose here is to add a new FCI object called request auto address and just give that address the footprint um all our proposal here are not very fine-grained I think we can discuss a lot about it the syntax it\u0027s just very initial proposals for your references and feedback so any question about this one slide so next one is the end for back address that\u0027s not a use case that we have in some cases if there is no cash availability or the cash cash cannot properly handle the request we would like to redirect their client back to the you do you see the end so basic proposal is to add a new metadata and generic object to specify the fallback address of the you CDN so that the D CDN can redirect back to that specific address so it should probably look something like what we we show here but we can discuss later on the exact syntax okay have your stuff so content management so we define of content management all the stuff that has to be done on content basically that means per evaluation in invalid in validation everything is covered by RFC eight zero zero seven so I think new here from the operation point of view but along the way we found that we need to add more stuff to the art the interface or to the RFC in order to implement everything that we wanted to do on content management so first of all the RFC proposed on the global pattern matching in order to match against the content and the requirement for a regular expression came a few times in order to something more specific needed to catch more specific assets and not to do overreaching around delivering more "
  },
  {
    "startTime": "00:36:37",
    "text": "content than is needed so first proposal here is to add a content reg X for the trigger specification I know that it actually changes the trailer interface by that that\u0027s the first major proposal we have I can stop here for questions or feedback or continue next next one since we are in the streaming video Alliance we focus on on video and when we\u0027re coming to do things like pre positioning we find out that we need to give there the DCB and a list of URLs for preposition possibly the the full list of the objects in the arm in the in the manifest so it really makes sense in order to instead of passing the full list within the trigger spec to give a URL for the playlist because that would be the most natural solution for a video CDN so what we\u0027re proposing here is to add the option to pass that playlist URLs in the trigger specification and allowing the D CDN to parse it as a playlist it can be all those different types of flat leaf-like HLS MCU a tour MSS MPD and parse them and then just generate the all the requests needed in order to do the prepositioning geo limits so trigger as it is specified right now is applies to the full D CDN again since this idiom can be if it\u0027s an ISP CD and it can be in a nationwide ins or sometimes even even wider and we want to be able to limit the operation to specific footprints um a good example for that would be from regulatory reason or business reason you you can\u0027t really put some object and specify the location that are controlled by the content provider so our proposal here is to add a location object to the to this trigger spec we could possibly use the MA location ACL there the issue here is that ma location ACL was designed to be ACL on the client locations and here we are talking about caches locations which is different so I\u0027m not sure if it would be the right idea to use that same object and maybe we should create a new object for that so that\u0027s an issue to discuss neck "
  },
  {
    "startTime": "00:39:39",
    "text": "schedule triggers so it turns out that sometimes what you want to do is you want especially in in preposition use case you want to trigger the downstream see the end to preposition but you want it to be done in specific times for example if you want to pull a new episode of Game of Thrones you want it to be done in the middle of the night rather than 9:00 p.m. because that\u0027s the whole idea to do it before the peak time so first of all you would like to tell the DC DN I want you to preposition but I want you to reap reap addition at that time so next question could be and so why I want the you CDN just wait for that time and then send the trigger so first we want the trigger not just to have a start time but also have an end time but second the actual time is the local time because what we\u0027re trying to do is preposition in a specific local time per geography and that calls for some new interface to be able to do a time scope and be able to tell that time scope is either local or UTC so again we\u0027re proposing to add a new time windows object to the trigger spec and again there\u0027s the question here if we could if you could use the time the time window ACL of the metadata and I think that in that case we can\u0027t just because we need to add the local and the local option but also because that object initially was designed to do to limit or to create an ACL on data usage rather than restricting and operations so it\u0027s a little bit different so that\u0027s also a discussion point if we want or need to define the new object have a quick question for you on this one so is the UNIX epoch isn\u0027t that already in UTC do you need it have a timezone there so it should be in epic or a possibly what we can do is do an epic plus an offset in order to uh to define the local I I didn\u0027t mean to to have like a full final thing that\u0027s here just to get the idea that we need to have something that can say we want it to be nine or let\u0027s say 3:00 a.m. at local time so we need to discuss how we can do that syntax was but so can you can you just say you know the the three o\u0027clock in local time is whatever in UTC and just store it always pass it as UTC like just a regular UNIX timestamp yeah but that the problem is that three I am is different UTC in "
  },
  {
    "startTime": "00:42:39",
    "text": "different locations so let\u0027s let\u0027s just imagine I have to tell the a and a nationwide CDN that I want them to pull the next episode of Game of Thrones but I want them to do that in 3 a.m. depending on the local time so how would they do that well if you if you\u0027re passing your timezone presumably you\u0027re gonna have to tell them multiple times anyway right I guess I guess if if you\u0027re doing it per time zone anyway then setting a different time isn\u0027t a big deal and if you\u0027re not then you\u0027re still you still have the same problem I think so let\u0027s if I\u0027m doing it a third time zone and so I\u0027ll need to pass different triggers for different time zones and so then I need to have a trigger time zone and then I have that that trigger should be geo limited to that specific so that\u0027s kind of combination between the geo limit and and the time limit for that geography I wanted to do in that UTC and other geography and other UTC in another book is that ad yeah yeah so it sounds like you\u0027re trying to specify a generic time like three o\u0027clock a.m. but you want each of the CDN in says you merged that requirement with the local time that it\u0027s serving out against right I\u0027m not sure this does that yet but it\u0027s close so III I\u0027d suggest maybe just take it and tweak it to do that that policy that it\u0027s a local you want to apply the local serving time against this generic representation that can be sent out against any CDN so I get that you wanna have the start in the end to be applicable to any CDN no that\u0027s receives this but you then want it to interpret it locally to the client as it\u0027s being served out Turkish yes yes yes yeah so like gosh you know it back you want per client right you want it served out so it\u0027s also if I send a a a pre position to Denver and I say serve this at 3 amp for Denver clients you want a serve a 3 amp but if it\u0027s a client gets redirected for load balancing to that cache from Boston you want to actually interpret against the Boston 3m not the Denver 3m it\u0027s a it\u0027s a client side request isn\u0027t it well III didn\u0027t think of it like that until now but once now that you say that that\u0027s possible that I I think the whole idea the reason it was raised to begin with was that pre positioning comes to serve the the purpose of content which is "
  },
  {
    "startTime": "00:45:39",
    "text": "going to be massively used to be repositioned ahead of time and at off-peak hours so this is an embargo this is an embargo time you know for content release and and that I think it\u0027s actually a very useful addition to CD and I as an so by the way I did include declare myself for the whoever\u0027s yeah blending I\u0027m cast NBCUniversal but I so I think this is a good requirement I\u0027m not sure that\u0027s capturing quite yet the the notion that it\u0027s a localized time whether it\u0027s localized to the client or localized to the cache because the cache may sir our clients and other time zones but but it\u0027s I would say that it is a good requirement because it is something we do all the time in real life situations so I agree that um it\u0027s very you know crude in in if current status but I\u0027ll be happy if we agree that this is an important requirement and we need to fail work on it and find a way out to solve it which is reasonable I mean maybe one approach here is to merge it with the there\u0027s your peers they have the Geo the geofilter tags maybe these interact with those so limited it for that geo for that time right on T okay so we can we can try and merge there okay so next yeah Sanjay Mishra so I think Glenn is making a good point but I think the requirement as we have thought about it is the restriction is on the local cache that is actually serving the content so the instruction was meant to tell the local cache that if you are a cache serving content in Denver area then you are restricted for that 3 p.m. right right hey hey Horry this is um this is Kevin I\u0027m just gonna serve myself here as chair we\u0027ve only got about thirty minutes left and I know you\u0027re only about a third of the way through so we may need to just pick it up a little bit and then we\u0027d like to get through all of the proposals from the SVA just that we all have a idea of what it kind of changes we\u0027re looking for and then at the end the chairs are going to ask whether or not we\u0027d won this we want to look at taking on this work so oh oh I\u0027ll just run through and just make sure that everybody knows what I\u0027m talking about then we can see how cool time is later so um another requirement is that we came by is if you look back on the previous requirement it turns out that when you do triggers sometimes you know you need more functions you need more abilities to to pass something from the DCD and to the UCD and and currently that\u0027s not "
  },
  {
    "startTime": "00:48:39",
    "text": "possible so what we are proposing here is to do some kind of mechanism of trigger extensibility similar to the metadata generic objects and that way even when it\u0027s not fully specified C\u0026I object yet implementation can start having something that actually works and path objects between use of the entity CDN and tell them to do something one such an example would be lets say I want you to do some invalidation but under a given scope or I want to do an invalidation but only to stuff that you acquired in the last two hours because something happened in those two hours these kind of requirements keeps coming up when we started to do specification and integration and uh that\u0027s not something that we cannot do right now so that\u0027s a requirement for the armatures to see if we can add something like that to triggers next so when coming to do all those stuff to triggers to adding more and more functions or maybe generic or extendable functions it turns out that it would be good if we can have the in the foot in the FCI as capabilities because of course we are not planning everybody to support anything so the same mechanism that applies to me that I tell by FCI telling I\u0027m supporting that metadata object would it be good if we can have the same for triggers to say that FC I says I\u0027m supporting that trigger object okay more heavy stuff so another issue that we\u0027re coming across is that when you start you know when you start delegating traffic from decision to you see the end and you come across all those request authentication that\u0027s an access control issues URI signing is most notably the first one and the idea for the DCD end to be able to implement the same URI signing which is done between the content provider and the D and the you CDN becomes infeasible because there are many different client access controls and authentication schemes and this again this is and cannot implement whatever it is you can find in the market right now that goes between content providers and commercial CD ends and some of those algorithms are on the other NBA and most of them are using symmetric keys which cannot be cannot be provided to the d CDN and eventually we needed to think of some kind of a generic mechanism that will be able to accommodate all that so I\u0027ll talk about a little bit about what we came up with and I know that Phil here has a "
  },
  {
    "startTime": "00:51:41",
    "text": "different view and maybe we can reconcile both approaches into one thing but just I\u0027ll just go through it so you know that we have this issue so looks like this so let\u0027s start with a URI signing case so we was a mechanism which we call we started calling it split authentication but then change it to a relay token authentication and it is really designed for their use cases of video of long ABR sessions and what we wanted to do is minimum exposure of the DCD end to of to the algorithms running in the you CDN and zero exposure of Scimitar keys and leave all the verification logic in the you CDN and enable the D CDN to verify verify consecutive request using verification state what we proposed here is that since video sessions are long and they are chunked into small requests the DC the end can cache can send a real a request to their you CDN for the first transaction it can be a manifest transaction or the first transaction of the of the representation of the video representation get a response for the verification and cache that response for that specific session and that session can be defined by the the URL - the chunk IDs plus the token the signature token and once that verification status is cached the cache can repeatedly verify the next request against that States again and again until some TTL that which was given by the you CDN so basically that\u0027s the whole idea it does require maybe next slide it requires metadata it requires new metadata because in the metadata we will need to tell the cache that for that specific service or that specific metadata the fields which should be used in for the session are those specific fields so it is different than the you are assigning mechanism of cd-i in that that it does actually require new metadata and we need some FCI in order to advertise that we actually support that so maybe feel you can refer to it and how we can reconcile between both approaches yeah so this Phil schwarber so I think this is really clever the surrogate authentication part so that you can do stuff and not have to basically pre-negotiate make sure everybody can do everything but the "
  },
  {
    "startTime": "00:54:41",
    "text": "extra metadata adds a dependency because the URI signing can be mostly implemented without the other CDI pieces and then this is also putting like metadata relative to content and you know it\u0027s having to put like the the cache key directives in there so I would I I would basically like to see a way where we can get this merged with the URI signing in such a way that we can do both and not have to store like this the session State on the server side and be able to store it in the token and the details I think I haven\u0027t really thought about them enough we had a little side conversation but but I think I think there\u0027s a solution there somewhere where we could basically add surrogate validation to your I signing and then do the rest in more traditional URI signing ways so if I get it right the idea is that we keep the original URI signing logic between the content providers and the you CDN at the you CDN and put some new logic in order to do the surrogate between the you CDN and the D the D CDN and that logic will be with some kind of a TTL so the DC do end will have to repeatedly go and do a relay to the UCD and once in a while possibly once in a long while but still that that kind of a revocation mechanism that the UC Dean has yeah so it\u0027ll it\u0027ll basically get you the validation against the you CDN and then create its own session State in a new token for example and then pass that back and forth with the client through the regular you know the the token renewal method with the TTL and when that TTL expires then it has to go and redo the surrogate validation and start that process over and then you get all the benefits of the claims like the what was formerly the subject claim and stuff like that to do what you\u0027re talking about here and you know TTL and client IP if you want that doesn\u0027t have to go into metadata it can all go into the into the your i signing token fill or e we\u0027ve got ten minutes left and I\u0027d like to get some chair questions so I know you have logging and course left can we just make a quick statement about each of those please so I\u0027m passing the mic to uh Andre Sanjay Mishra I\u0027ll be really quick here so the CD and I spec actually does talk about the logging but what is different here is that there are a couple of motivations that we had for proposing a alternative method one is "
  },
  {
    "startTime": "00:57:44",
    "text": "that Syrians have largely done implementations with the logging already in place and they are currently using this quit based logs so we wanted to make sure that we can keep that flexibility that already exists for the Syrians to be able to use the logs so the intent was that for anything that the d CDM delivers on behalf of the you CDN we leverage the existing logging mechanism so we wanted to just keep this quit logs as it is the second question that came up was that is there a way for us to also leverage the transport mechanism that may exist but that may already be supported by the Syrians so we thought we can add a sort of mechanism for a CDN and you CDN to negotiate what kind of transport mechanism that is already in place so we can leverage that so we added a provision here to allow CD ends to be able to negotiate transport method which could be logstash or it could be a you know SFTP type or any other method that might already exist next slide so I\u0027m just gonna be really quick 9j we\u0027ve got one minute left I am sorry I\u0027m sorry we only have one minute left all right all right we can you know I can skip this section here it\u0027s pretty self-explanatory as it is so we can keep the minute for you here I\u0027m sorry I think I have to cut you off the chair still would like to ask their questions to the working group I think folks should go and read the draft that orient santé put out there\u0027s a lot of interesting stuff in here that I think would be good to add but at this point Phil if we could just go to the last slide okay so at the last IETF the the question was raised about adding additional work and so we wanted to get a gauge here today of whether folks are interested in in doing taking on the HTTP delegation HTTP delegation and stuff as well as the SVA open caching stuff I had convinced myself and I think I\u0027ve convinced Alexi prior that what we were looking at was would still fall within the scope of the existing Charter but given the the stuff that was discussed today I think we\u0027ve definitely gone beyond the scope of our existing Charter so I\u0027d like to get an idea of if this stuff that we would like to work on that that working group would like to work on and if so then we can start thinking about how we need to address the Charter address reach our during in "
  },
  {
    "startTime": "01:00:45",
    "text": "order to take on this work so the first question I\u0027d like to do a hum on is do we have interest in doing HTTP delegation I don\u0027t think I can hear the hum so this is gonna be all you if you if you think that we should take on HTTP delegation understanding that there\u0027s a lot to be worked out there and we\u0027ll decide that as a working group please hum now and if you\u0027re opposed Phil I heard maybe two four yes and one for now okay it was okay and then I\u0027d like to ask the same question for the open caching stuff if you think that this is interesting stuff that we should work on please hum now and if you are opposed all right I heard I heard several for for yes and nothing for now okay that\u0027s that\u0027s good we will of course go in and and ask the list as well I apologize that we were in that time but I appreciate everyone coming we are out of time right over time so I hope you all have a safe flight back and enjoyed your week in Singapore and we will see you in London you "
  }
]