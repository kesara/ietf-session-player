[
  {
    "startTime": "00:00:09",
    "text": "Welcome. We hope that the microphone check from remotely works later. Welcome to the netcon session at the IT at 120 I'm here with kent watsen My name is Pat Anderson. And we wrote the facilitate this meeting. It is being recorded. I'm a Remember that. On the clicker But so Per is our new work group chair. Thank you for joining and thank you Mahesh for uh you know service for being chair before and now being our AD Thank you so note well this this is the IT chair before and now being our AD. Thank you. So note well this this is the IETF. The participation is our defined in these BCPs. You should go look them up, read them, evaluate them. I will not explain them to you, but a reminder to look at these documents and evaluate their contents So notes really well We come here as individuals and collaborate together as a community Be nice to each other. We can have opinions, technical opinions but be excellent to each other, to each other with respect There is, if you feel that you're not being treated with respect, there is an ombud team that you could contact You can also approach the chairs if you feel that something is not right and we will step in We've not had any such issues during my time in the IT and I sincerely hope that we will not have issues going forward either in the future"
  },
  {
    "startTime": "00:02:00",
    "text": "Meeting tips, so those that are joining remotely you already have this dialed down, you're here For the people in the room, please check in with the onsite client so that we get the blue sheets for participation. It's important so we know the size of the of the NetConf room going forward and subsequent meetings More resources on-site tool. There are minutes that you can join. We have a chat an audio track We have a total of a slot. We have a basically full agenda. We have 10 minutes left in the end that we can use for open mic. If you want to see something, put yourself in the queue, remove yourself from the queue when you have said your piece And also lastly, please help us taking minutes. They're linked in the chat as well So a couple of new slides. As I said, we before, the IETF is a volunteer organization We encourage participation I've met several new participants at this IETF and there are several ways to engage in the community to do work So you can do just engage in the mailing list, answer all or any questions comment on the microphone at the IETF sessions, state your opinion review drafts, this is also for long-time participants. Please review drafts that is the way to progress work Another thing to do is to implement the work that we're actually defining here. That was very helpful. We value running code And then to progress work outside of the working group there is the possibility to be a document shepherd and lastly currently we don't have a secretary"
  },
  {
    "startTime": "00:04:00",
    "text": "I was secretary before being a appointed as a co-chair so that is vacant vacant For authors and presenters, you might have seen this in other work groups as well. We will now request authors of all working group documents to provide a status up update at the IETF at every IETF meeting. Status includes at a minimum risk recent changes, outstanding issues, and a plan to complete the document making it leave the working group And updates are done each as a presentation here at the IETF or a mail to the working group list no later on the ID cutoff So continue as I said, we're a community, the netcon community is a sub-community in the ID IETF. Active authors are encouraged to participate in the review of other working group documents not only your own work or the work that you're interested So that increases working group participation and activity activity It reciprocate efforts shown by others And also illustrates a broader understanding interest and thought leadership about the work that we're doing here And be aware that your co-chairs or we co-chairs we are human beings and we may forget things missed deadlines, things fall between the cracks So if you observe the please reach out to us so we can mitigate it So these are the current documents that are now post the working group initiative So we have a few in the already editor queue the Zero Touch, the first six client server drive andy newton over TLS 1.3"
  },
  {
    "startTime": "00:06:00",
    "text": "and then we have a few that are in IESG evaluation or AD evaluation HTTP as notive, HDP client service NetConf and RestConf client server So we ask the current AD, Mahesh, to please say some NetConf and RestConf Client Server. So we ask the current AD, Mahesh, to please say something about the drafts in AD follow-up and AD evaluation Mahesh so starting from the bottom the last two drafts were actually on rather when he was area director and he had actually already provided his review on those two drafts and there was a subsequently there was an exchange between him and Kent um i did follow up Rob actually has agreed to finish up those review comments And since he has the most context on those comments that he provided, I thought it would be better I'm more than happy to step in if need be, but as of now, I think Rob said he's more than happy to look at at the other two drafts I noticed that Kent I you did post an update to the HTTP client server draft a couple of weeks before this meeting and at this point I guess are we waiting for kind of a okay? from mark nottingham and others? that we had a meeting about because I think that's what is kind of gating our, whatever the example update for HTTP note of draft right? so the question sorry for k you are at the point as far as as HTTP client server is concerned my understanding is that we are waiting for"
  },
  {
    "startTime": "00:08:00",
    "text": "a kind of OK from that group of people that had put a discuss on the document, right? Kent as an author Yes, exactly that. The draft was updated and we're just waiting to see if it was okay or satisfactory Okay, so, so the status is, I think, once they kind of give their testimony, approval on the draft, I will go ahead and update the HTTP or between Kent and I, one of us will update the HTTP's notice they kind of give their asset approval on the draft, I will go ahead and update the HTTP. Between Kent and I, one of us will update the HTTP's not a draft to get it to publication status Thanks. Rob, do you want to say something? I need to confirm that I'll do this finish off those reviews with you. I'm not sure I get to this week, otherwise I'll try to get into next week. Okay, great carrying on These are the drafts that we are currently working on in the working group Everything except the last one, adaptive subscription to Yang notification will be discussed in this meeting The adaptive subscription to Yang notification has had an update on the mailing list. So go read that This is the agenda We will start off with a list pagination presentation Then we will have transaction ID and trace context External trace ID for configuration netconprived candidates, support of versioning in Yang notification subscriptions subscriptions, UDP based transport for configured subscriptions, yang groupings for UDP clients and UDP servers, subscription to distributed notification and now entering non-chartered items Yang model for netcon to event notifications support of false name and sequencing and yang notifications, support of network orchestration, timestamping, and yang notifications Using NetConF over quick connection, yang groupings for quick lines and quick service"
  },
  {
    "startTime": "00:10:00",
    "text": "and augmented by addition into the IETF yang library That concludes the chair slides on to our first presentation. Shin, please take the room, the floor Good morning everyone. My name is Chin Wu and on behalf of the draft, I want to present this pageination for Young Driving Protocol For this work actually can be break down into three draft The first draft focused on standard mechanisms control, filtering, retriever or entry list and leaf list and just recap what it is job about. And the other two jobs is about a net-cove extension and a rescove extension to support this pageination And the current status actually this job, I think, already passed through the working group last call and, by the way, do receive the young doctor review from NADA. So just before this meeting, we also get together to discuss the issue with the and by the way do receive the young doctor review from NADA. So just before this meeting we also get together to discuss the issue raised in during the young doctor review and Richard Graham for, you know, proposed change So you can see the latest version actually we post you know all version 04. Actually, we add a bunch of examples and also, you know, make some text change and also fix some back in the, in the job, actually and in addition actually we make an update for in implementation status. I will, you know, introduce this later slides and still we have three open issue remain. And the don't know define limited equal zero, and local for order by the list and we also have a x-mail list example"
  },
  {
    "startTime": "00:12:00",
    "text": "validation, so these three issues we would like to associate feedback from this meeting so the current status you will see, actually, we have a functional implementation actually we have one more completed implementation from all accent actually is one of the Nispegination author. And this, implementation is based on, you know, clicks and open source project support of both NETCOF and the REST COF protocol And it is supported, you know, almost all the feature, except, you know, cursor, local, and sublist limit RESTConf protocol and it is supported, you know, almost all the feature, except, you know, cursor, local, and sublist, the limit. And the other, you know, implementation actually, not a complete implementation but, you know, try to cover you know, most of the functionality or feature we, you know, define in the draft actually some of the invitation only support the netcom some of job implementation only support RESConf and so these are current style of implementation know, defined in the draft, actually some of implementation only support the netcon. Some of the implementation only support RESConf. And so these are current status of implementation And for a young doctor review, actually I think two issues raised by NADA. The first is about the expats default context issue and based on also discussing, actually, we think we should afford the Young 1-1, Section 6 641. That is actually a you know, for NetConv case, we will use the prefix to identify the X-Path default content For RESCONV, we use module name And I think this already be a you know, be repeated discussed on the list. It's kind of general agreement you know, we also actually believe that is the right way to go and to address these you know, issue"
  },
  {
    "startTime": "00:14:00",
    "text": "and the second one is you know is about the kernel of the mechanism we define whether you know, it's, you know, only design for SQL database or tie with, you know, SQL database, based on also discussion with single you know, the mechanism we define is more generic mechanism, so we're more focused on standardize the common functionality so we can cover not only sql mechanisms, so we more focus on standardize the common functionality, so we can cover, you know, not only SQL, but also some other, you know, database system so in the introduction we you know you know cover not, you know, not only SQL, but also some other, you know, database system. So in the introduction, we, you know, shortly, briefly discuss the variety of the database system. We also emphasize in draft, we are leveraged all the underlying database system capability to address a lot of comments. So I think we also actually you know, already actually just just before this meeting and per know take action send a response on behalf of all the author to check, you know, not that whether, you know, he is happy about the change. I think we also believe, actually the comments raised in a young doctor review has been resolved So, so we have three open issues The first is, you know, limited equal value zero This feature we already, you know, implemented in COVID incorporated in the latest version, actually the basic use cases, you know, to support a deep back and to, you know, validate the query and in some example, in the response, we can you know, make sure that, you know when we set the limit as a zero in the request that we can return the empty result sets We think it's a good feature, but we want to get a sense of the room, whether people think that it's a useful feature. And it's"
  },
  {
    "startTime": "00:16:00",
    "text": "result sets. We think it's a good feature, but we want to get a sense of the room, whether people think it's a useful feature, and it is necessary, since you're limited only evaluation at the last order and so actually we also make some other change actually i probably should you know summarize early actually, for example, we'll fix some incorrect example and they're in the appendix. And also, we add missing error identity examples also in the appendix. And we have you know sort by string pattern especially for the decedent scheme node ID actually make sure that you know it is correct and so the second open issue is about local for order by the list actually for list that we know actually it can be order by user order by system. So the question is master the list report local used without sort of buy And based on also discussing, we actually you know, we think you know into you evaluate these two cases for the case so by the user, which probably is not a you know, desirable to report local without sort by, since the user, you know, just randomly, you know, define the order But for the case of the order by system, we think it's the way to code since the system lexically, store the item according to a system locales And if you have any, you know, sort of about this, please feel free to comment on this And the last issue is about Young Data XMeralist validation. Actually, as we know, NetCOV are already support XMero encoding So to make sure, you know, provide consistent as"
  },
  {
    "startTime": "00:18:00",
    "text": "access of the list of resources, we think you know, it's also necessary to add XML encoding for the RESTCON protocol And so in current job, actually, in the appendix, we have several examples. And we think if we add this feature, this support, we need to you know validate the example but the the the some missing pieces we think to support is to validate this example we need to you know, introduce some model extension, maybe define the model, for example to make sure we can return in the response, you know, using the top level elements like X marrow list to include all the XML data that it defines in some other model model Yeah, next step, I think we want to get more eyes on this draft and we want to you know, make draft ready for publication So the author for the next, the proposal step for the author is we will you know validate this example and to you know try to fix it for publication. So the author, for the next, the proposal step for the author is we will, you know, validate this example and to, you know, try to fix the missing pieces and for, for third open issue and also we are corrected the ambiguity text. For the open question, we raised here, actually, we are happy to hear more input feedback and we will take on to narrow down these three open issue. So that's all and any comments suggesting? Quickly as a chair the draft hasn't gone into working and a blast call just yet. We're hoping to go to work with Blaskol about three months as soon as we can Mahesh, so I was happy to see that there's an implementation of the drafts this came up as a common actually from Thomas if I want"
  },
  {
    "startTime": "00:20:00",
    "text": "He suggested that we should try to get more implementations of our drafts So thank you for that um on um get more implementations of our drafts so thank you for that on on the question of locale I maybe I didn't understand the problem statement isn't ordered by user supposed to be meaning in the order that the user thinks is the correct order and I can understand why locale might be used for ordered by system, because it has to be but what the locale Lexically, it thinks is the right order, but I'm not sure if I understand why ordered by user is an issue and how its relationship to locale A short response is that ordered by you have got it exactly correct so ordered by user it doesn't make sense at all. But for order by system, you can ordered by you have got it exactly correct. So order by user, it doesn't make sense at all. But for order by system, you could present, I mean, the system order could be sorted lexically by the local used. Okay, the server can or may present that, if that is the case That is the thinking. And per saying that as a co-ophe co-author So learning on the job Thank you. Yes, thank you. Rashad you'll drop your question. Okay, so let's thank you very much, Shin, and let's carry on to the next presentation Jan, transaction ID All right. So we are about to present three documents in 10 minutes so this will be with some tempo it seems I don't have control, so can you take the next slide, please? please? Give me a second to give you slide control. Thank you"
  },
  {
    "startTime": "00:22:00",
    "text": "please Give me a second to give you slide control. Thank you. So, uh, currently we have the draft IETF netcom transaction ID 06, actually. There was on Monday I submitted a new version but functionally function wise the is no big change since 2003 there has been several reviews and that's actually why I did a six, version six, recently because there was a lot of several features with stylistic and language spelling and so updates but functionally the document has been the same since 2003. And the only thing that has happened in between is basically a small bug with the namespace reference that was wrong and some other page material Oh it's related to a number of different drafts you have seen through the years We have the trace draft, the family of trace drafts And I think that now the separation of concerns between transaction ID and the trace drafts are quite clear and in a useful way And we have the PIVCAND. There was some overlap there too And I believe that now we have cleared up important points with the pricand as well We know how they should work together Transaction ID style can now be used print of PripCants and it is possible to abort a pre-PICAN transaction when there are conflicts. So those two things have been fixed from the Pritcans side And there is now of course a new draft coming up. We talked about Yang provenance that is defining a fairly similar mechanism for keeping cryptographic checksums over Yang data trees that maybe we should align with in some way So next steps for this piece of work"
  },
  {
    "startTime": "00:24:00",
    "text": "we have done the alignment with the trace track with the pre-of-hand drafts and we have a sort of partial implementation of this And it seems to work fine. So we're sort of asking it hasn't been any sort of material changes in this draft for a while and I think the all the administration pieces of it that I can think of are done also. So I wonder if it's maybe time for the last call call So Kent as a chair, I think you're asking for work working group last call. And if there's no objection we'll be doing we'll be starting that immediately after this meeting Thank you And with that, I'll hand over control to rocky because we're going over to the trace strats Roke, you should have side control Okay You need to move to the next deck All right So thank you very much. I hope you hear me well. Okay. I'm presenting on behalf of the authors All right. Thank you. All of the authors of the trace context extension and there's two different documents because one is for netconf and the other one is for RESConf so a very quick update on the two drafts basically we were and the other one is for resconce. So a very quick update on the two drafts. Basically, what we are doing is taking the W3C has the very quick update on the two drafts. Basically, what we are doing is taking what the W3C has defined us as as trace context and implemented in the two protocols we"
  },
  {
    "startTime": "00:26:00",
    "text": "has defined as a trace context and implemented in the two protocols. We, the only thing we've been changing the last releases was basically the adopted the requirement from the iESG to actually minimize the number of shoot and review that and which should actually be must of should and review that and which should should actually be masked. So we did a number of these changes. But besides that, and add the security consideration, pretty much we believe the draft is, both of them are in very good shape, pretty much done from our side as an author and we actually do have a full implementation in the case of netcom from client and server and also in the case of rescom for the server side this is going to be part of with we're really looking forward for any interpretability with did took some open source tools particularly in python and did test of this implementations. So regarding the document, we think we are in a mature stage with nothing in our to do this right now so just to give you a quick brief of the interpretability that we've been doing and just to remind everybody on what exactly we're trying to achieve here, what we're trying to do is to tap your RestConf or NetConf environment into the application performance management suite So the idea that there are where we are really to do was to show that the same content, that you implement in your Python request and flask libraries can be used to send to a response server and then implementing this to backends than talk open telemetry So this was very successful and we're really looking forward anybody who wants to also participate in this sort of test either with NEPCOF or RESTConf We also show that, you know, that the context that is actually seen back to the backend, the backend can actually"
  },
  {
    "startTime": "00:28:00",
    "text": "review them and implemented. You saw that we tested with around 10 different backends, some of them are open source some of them are commercial and basically the key of the puzzle here is the next slide where you're going to see that for a, you know, when you have the Python, uh, uh, commercial. And basically the key of the puzzle here is the next slide where you're going to see that for a, you know, when you have the Python RestConf client, turn into the to the actual RESCOM server, a given trace context, and then the backend is able to put all the traces in the right order. So now we are able to analyze and create the use cases that we detail in the draw. So all in all, just to summarize both drafts for are in a very mature stage with think we're pretty much, we don't have anything else in our to-do list. But we have as a next step The first one is I want to ask a German chairs maybe not chairs, maybe not directly not, but there is an option to submit and register this protocol in the W3C registry and this can be done pretty fast. I wanted to check with the chairs the process you want to do It's very simple editing a Git repository so getting that we wanted to check with the chairs, the process you want to do. It's very simple editing a Git repository. So getting that will give visibility to the overall developing community than this document exists if there's any implementation test needed, that would be great. If anybody wants to do an implementation, test with us or modify any open source, Netcom, RestConf client server, we're happy with that And then there's a monitoring work we're doing to monitor some other developing in W3C lateral to this, which is the baggage headers which is something that is not yet fully in implemented in W3C, but we are monitoring So that's about it for our summer yeah. So pair, I sorry So that's about for our summary, yeah. So Per as a co-chair, do you want the chairs to"
  },
  {
    "startTime": "00:30:00",
    "text": "register this or should it be a section in the draft? or how would such a registration in with? W3C actually go down? yeah so i discovered w3c in their case it's they just need somebody to do uh push request in there Git, and then they go through a review process and I'm happy to do it or you tell me the process is pretty simple I can in their in their side their, in their side, correct? So I'm asking, asking broadly also as a co-chair and IETF participant, how is the process for going? about this? Because I don't know I don't know. That's what I'm asking. I can do it. That's why I'm asking. That's why we're going about this? Because I don't know. I don't know. That's what I'm asking. I can do that that's why before doing it, I wanted to ask the chair how we deal with these registries which are outside of the IAM correct? Mahesh, I don't know it either, but I think if you are familiar, with the process and if you feel that this would be beneficial to the community can we, maybe the chairs we should ask whether you can do it i don't believe it's necessary from an it IETF perspective to register with W3C We've never done it before. But if it's the right thing to do for that community, then we should But who would do it? Is it a would it be individual contributor like the authors to do or? I would take that the- More formal? Can we really stop them or anyone? I mean, I would take that as an individual you should be able to create a registry entry right Why, does IETF have to get involved? necessarily? So if I just sort of squint hard and the feeling from the room is that it's up to you"
  },
  {
    "startTime": "00:32:00",
    "text": "Just one comment, I think it's beneficial for the IT community also because it involves giving a you know, awareness of this work, correct? in that regard for developers who make it to the work through the W3C, correct? Roberton so I would check I mean Chris who make do the work through the W3C, correct. Rob Bolton, so I would check, I mean, christian hopps has put the right message into the chat, because I think, we might have a liaison to W3C. I can't remember who it is but we could check the iab i mean reach out to them and they'd actually sort of guide it through the process and tell us We talked to the right people on this side to say, well, this is a good thing or not I think you mark nottingham or maybe Martin might be the people involved, but I can't sure. I think that also might be what WG, so I think Chris is in the room in the net come from if I see the attendee list. So maybe if he can come to the mic mic But regardless, I mean, does it have to be a liaison statement? or I'm wondering this is any anyway, we'll probably should ask chris box Mark for guidance on whether which should be IETF initiated liaison statement Chris says he's unable to come to the microphone, but this makes me wonder, are there other drafts that we should have been registering with that W3C? as well? So let's see we've had, we're out of time at the moment, but this is very, interesting. Thank you, Roque On this one I think is there a desire to go to work with a class call? Glasgow? That's a question for the authors. Do you request that working? your past call? Is that your next step? Yeah so yeah, from the perspective, we don't have a anything else in the queue to add. So we do, we leave a the documents already and we have some implementations already already done Okay, so we will start that as well after if there's no objection after this being"
  },
  {
    "startTime": "00:34:00",
    "text": "Sean external transaction ID for configuration tracing. Thank you Hello. So, yes matthew quick update on the configuration tracing So just to remind the context the idea is to be able to trace the configuration changes from the orchestrator up to the any. And basically it's a very aligned with the work of Yan Nerochase, the same thing so i will just go into the updates um so basically the um main update was to propose here to add as we have for the trace parent to have another extension in the RPC to pass another annotation into the RPC node to pass the client ID And yeah, so first question would be is that the right thing to do because otherwise, it's just a proposition, but I think it's the easiest way to obtain it it and I actually for the other one the second part of this slide it's more experimental I think I tried to actually have the trace parent and the and yes that's basic the, yes this W3C Transparent implemented in Young Lib and C's report and Netopier and Netopier and"
  },
  {
    "startTime": "00:36:00",
    "text": "to define this annotation to get it accepted so the question is is that the correct way to do things? to add an annotation? To meet it seems like it's not at the right level but this is what Youngling like likes And maybe, Jan, if you want to take this one right now Sure As far as I've been looking at the annotation, draft, it doesn't speak about the you would annotate administrative tags like a RPC. It only talks about how you apply these to content notes so that's why I intersection ID, for example, we didn't use this because it's not, we have many attributes sitting on things that are not content notes So that's why I didn't use it. So I would think that this what we see on the screen right now is actually beyond what you can do with clients client with this annotation mechanism properly at least you are in the undefined area right now okay maybe some tools require that I don't know can't as a contributor um you have an xml example or actually a net config example. Is it a RESTCOM example as well? No, not no no res con for that but I could add one. Will you add a rest-comf example? Yeah, okay. Yeah, please. Thank you And so the next step, actually, um, I think on this one, basically Jan already answered this question because he already did the work about how to align the draft, so I have to admit I didn't read the last update from from this from this draft so I"
  },
  {
    "startTime": "00:38:00",
    "text": "will just check that it's correct, but it seems that this part is done at least. So that's all for me. Andy? andy bierman, can you go back to the slide with the RPC on it? Well, well, so two comments. One, you're aware that the RPC element is not modeled in Yang and never will be So that's, it isn't need the annotation because that only applies to things modeled in Yang Um, and RFC 6241 mandates that all of the action annotation because that only applies to things modeled in Yang. And RFC 6241 mandates that all of the attributes in the RPC are returned unchanged in the RPC reply So just be aware that. So these aren't special or anything in any conformant implementation just returns everything that was in the RPC and so you can put whatever you want in there you know he always could so okay you'll get it back in the RPC reply You know, so that's message ID is obviously one that's that's like you know uses that mechanism Okay, thank you Thank you. Next presentation Notcom Private Canada is James Thank you All right. So a quick reminder for anyone who hasn't read it The idea of the NetComp Private Candidates draft is to allow you to have independent candidates configurations in NetConn and Rescon on a per session basis So some updates from the last meeting draft 3 was published that had some fairly significant changes based on working group feedback from the"
  },
  {
    "startTime": "00:40:00",
    "text": "last meetings, particularly around conflict detection and resolution and making that a little clearer and identifying kind of how that works And we gave a structured set of minimum requirements for what is a conflict and then allowed it to be extensible and then draft four was published recently before the meeting and just had some minor largely grammatical and what have you errors fixed there are however a few outstanding issues One was to do with Yang models We'll talk about that. One was about selecting whether a private candidate is used at all or not we'll talk about that. And then about whether or not we needed to include the source data store and a commit And those two are kind of linked together And then there was a question from yan thank you Jan about how just clarifying the workflow for how a conflict is much are kind of linked together and then there was a question from Yan, thank you Jan, about how just clarifying the workflow for how a conflict is marked and then resolved So we'll show that as well So these are changes, as I said, mainly around what constitutes are conflict. We added the Yang models We'll talk about that in a moment We clarified the behavior with commit confirmed because that was not very well specified We provided a solution for delete config, which also wasn't in the previous version we updated the diagram for nmda just to give a more complete picture It's used to have the useful to have the pictorial version as well and we added some sections of the described following the feature from Kent about what the draft was updating in other RFCs This one I'm not going to cover in too much detail. There were two models for providing this information. One was to update the base models in the various model sections"
  },
  {
    "startTime": "00:42:00",
    "text": "which makes private candidates blend very well with the rest of the NetConff infrastructure But there are some downsides to that. You know, it's updating both technically and from a procedural point of view So it's updating many modules and actually you can't in Yang 1.1, which is some of the base modules are in. You can't do the all statement for a feature, so actually that causes a technical problem but you can't do if feature candidate and if feature private candidate, or rather, or you can only do the and the other approach is augments and i mean that provides visually a different approach for private candidates from the rest of the base operations, but following the advice from the working group on the list, and this feels to be the more favoured approach, so it's the approach that we kind of plan on taking forward and it's just an examples of that we're the next two because they're they're available for your use later and but some examples of the errors that you get with the or statement and some of the procedural and technical issues if you choose the if we chose the updating the base models approach so say we're going to move forward with the augmentation approach and that will be in the next revision The next question was how do we select if private candidates are used at all? and this kind of boils down to should nmda client be supported there's a feeling amongst the authors and there was been no objection so far in terms of the list and I'll talk about the side reading we had earlier this week as well in a moment So there's a feeling that non-MBA clients should be supported our experience is that most of the clients out there in the industry today are non-NMDA clients"
  },
  {
    "startTime": "00:44:00",
    "text": "Clearly not all, but the majority that are in use today seem to be in that bracket. So the draft already provides a very straightforward mechanism to make this work with all of those with very little changes and no changes to clients, which is kind of the most important piece here However, it does ask the question, should an individual client be able to select on a per session basis whether or not they are using private candidates or not? And this comes down to the NMDA candidate approach There are a few options. I can't remember if I'm here no, there are a few options around this One is that, you know, you can, on a person, session basis, have the private candidate choose which target data store it's going to target in the NMDA way The other option is that you could essentially say, we'll use the same approach for non-MDA as NMDA and use the client capability approach it. And there are pros and cons for both. And that's something that's we did discuss at the side meeting, which I'll cover in a second. Andy, do you want to do your question? now? Yeah, so because the initial module, is 1.0, you're not allowed to augment it in 1.1, and you're not allowed to publish a 1.0 module. So your second solution doesn't work either Sorry. Okay All right. So when you say we're not allowed to augment the 1.0 yang 1.1.1 is not allowed to augment is not allowed to 1.0 has to be augmented by 1.0. Yeah, well I need to double check that. I'm sure I know there's text about mixing 1.0 and 1.1 It could be that it just has to be automatically converted to 1.1, maybe maybe double check it, but it's there's definitely issues with mixing"
  },
  {
    "startTime": "00:46:00",
    "text": "1.1 and 1.0. Yeah, that would be great if you could point us at the text that would be fantastic we we did do some test implementations with the various linters and they do seem to work but i mean that might just be the linters and not conforming to the standards, that's quite possible but yeah that would be really useful thank you so and Sandy Yeah, let's move on to this one you so. Yeah, let's move on to this one. So, the reason that we kind of asking this question is because there was some feedback earlier on in the kind of working group that locking individual data store individually was important and if you follow that then should you be able to target individual data stores with a single client? so should an NMDA client be able to target candidate and private candidate as they're the theoretically independent data stores, in a single session? And if the answer to that, the word group feels is yes, then it comes down back to this question which is okay well then when you do commit, what are you committing? and should we therefore add the data store extension to commit as well? So you could say, push stuff to candidate, push stuff to private candidate, I'm going to commit the private candidate one or the candidate one. So that's an approach there um if the answer is that we feel we don't want to be able to target things on a per transaction basis, or we don't need to, or that it's explicitly bad not to then you could say everything in one second is a private candidate or a candidate and then it opens the question of do we need the private candidate data store or do we follow the client case? capability where candidate means private candidate? Yes, Kent is a contributor of the two choices. I much prefer the second. I don't understand the reason why we would ever want to have both"
  },
  {
    "startTime": "00:48:00",
    "text": "private Canada and shared candidate in the same session Sure. But when you say you proceed, the second, so the second has a couple of nuances to it as well One being that if you target private candidate, you're targeting a private point. If you then target candidate, what should happen and what makes that decision? Is it a first right or is it some kind or is it the client capability? And we say we always use that, including for NMDA so there are a couple of nuanced kind of questions I guess you asking me um as a contributor again i like the idea of if we agree that you cannot target separately the candidate and shared kind of same session, then private convention could just be called candidate and that idea and that that makes sense to me and it seems cleaner, more backwards compatible with existing systems yeah i would agree in some ways in other ways it's also isn't very nmdae like where we have the list of data stores and we're adding more data stores as we go and then you have one data store that means one thing except when it doesn't So that's the only concern there is it feels a little less in line with some of the nmda other nmda extensions of the Just a quick comment, you could read actually, you always have one candidate later as I think it's just a candidate store, and what you're changing is the property is to whether that's shared or private So I know that then, and then you don't have less justification saying it has to be have a different name because it's actually still the same day store, it's just different property. Yes thank you. All right, we help a side meeting on Tuesday um the items were discussed um and uh the outcome from that was essentially that there's a"
  },
  {
    "startTime": "00:50:00",
    "text": "preference for the augmentation approach which is think matched the discussions we had on the working group list as well There was a discussion then of the would then be potentially rolled into the you know the more base models approach in a Neckon Connect solution which would also make sense There was a preference to providing support for existing non-MDA clients I think we kind of communicated that and you see some people nodding around the room And we did have this discussion on the NMDA clients thing And I think the short answer was that there was no clear preference I would say it was still fairly hung in terms of well they all work and they all provide this solution. And yeah, no particular preference so the plan was for the authors to take people and yeah no particular preference so the plan was for the authors to take feedback from this meeting bring it to the list again and then ultimately pick a proposed solution in the next version of the graph And then very quickly, I know we're out of time This was the response to which the graph. And then very quickly, I know we're out of time. This was the response to it, which I don't know, maybe a bit of an eye chart This is, how does an element get marked as a conflict? I'll very quickly talk through it and you're probably better reviewing it on your own laptops. I'm going to be able to zoom in But you have a configuration two private candidates open their copies of the candidate private candidate two which is the one in the kind of orange-y type color makes a change to a leaf, calls it Apple, and then commits that in Private Candidate 1 that originally took its copy before that change happened changes it to banana Does its commit, the draft says commit, runs an update, and the default for update is that it will fail if there's a conflict, so it fails"
  },
  {
    "startTime": "00:52:00",
    "text": "gives you the error and the running configurations stays as Apple Just to demonstrate, you could also run an update with a default and it will fail in exactly the same way But the mark the banana kind of leaf now is marked as in conflict. The draft doesn't define kind of on purpose how you should mark this We felt that this is probably an implementation detail that should be left to the influence You can then run another update with a resolution mode of ignore, which will say I'm what I have in my candidate is what I want to keep and ignore anything that comes in and at that point we mark that node as resolved and then next time you do your commit it will then pass So that's just a kind of a quick example of how the work and then our next steps we wanted to add an addition rPC error tag for conflict There weren't any other kind of error tags that were ideal Final institution for the NMDA client piece clarify whether a conflicted node being edited rather than updated resolves a conflict or not, and then move to last call Let's see. Not right now, but I mean immediately after the next. Great. Thank you, James Looking forward to move into last call before the next meeting But we're running three minutes behind so push you off stage Alex All right Oh, sorry, Thomas Good, hello everybody. Short up. Let's just a quick follow up to the, I got it backwards. It's 1.0 that is not allowed to import 1.1. Sorry"
  },
  {
    "startTime": "00:54:00",
    "text": "Sorry Have we had seven or six? Oh, yeah, okay, my bad So hello everybody. So this is a short update on support of version and young notification subscription. A brief reminder what the document is about. So it's about adding in the subscription start not notification message, the revision module name and the revision label label so that we can identify which yang models are behind and also with the capability during the subscription that we can actually define that young module revision because that could potentially change due to a software upgrade on the young push publisher We only have one minor change to the last review number, so during an implementation we noticed that in the case statement, identifiers needs to be unique. This has been addressed and fixed. Thanks to Jeremy from six Sinkswind noticing that we have an act hackathon activity at IDF 120 where we continue the validation of among different implementations. So now current for the Yang notification version we have two implementations And as a note, this is a part of six documents. They are related to the NEMO document about the message broker integration if that is already interest, please join on Friday between one and three That's all. Looking forward for your feedback Okay, great, thank you Now, Alex"
  },
  {
    "startTime": "00:56:03",
    "text": "And we are running about six minutes behind our schedule, which is okay because we have to minutes remaining, but we would like to have open So it should be a short presentation, this one So Alex, uh, uh, from Insan Leone on behalf of the authors presenting an update on the UDP notive drafts um so we haven't got okay, we haven't got any feedback from since the last iterations, the only abbeks has been regarding the young module from the work group. We understood that there was some interest on having the generic udp client server groupings in an external draft So we have exported that in a dedicated draft and therefore on the UDP not if we are using that grouping. The impact is that now rather than configuring a receipt to an IP address nose on, we are able to Conf- is that now rather than configuring a receiver to an IP address no zone, we are able to configure in-net host, so host names and we are also able to configure local addresses Given that on the first version of the UDP client, server draft, there was a default statement on the port we had to ask IANA for a default port to put on the on and be refined on the UDP the port we had to ask ayana for a default port to put on the on and be refined on the udip notive but we got feedback from med that it was a very weak argument for for UDP notive to ask just because of the young needs to refine He was proposing to remove the default statement from the UDP client server draft and put the mandatory again on the UD Noti. So we did that and just"
  },
  {
    "startTime": "00:58:00",
    "text": "and there are no pending items on this rough. We feel that it's ready almost for our last goal just yeah, so just a quick update it's this young module where we are configuring the board, the address and the local addresses So Mahesh, you're in the queue Ah, Mahesh. Sorry, I might be confused about so do we need a default port? and should be requesting and I know and the rollback to the mandatory report could you possibly clarify where are we currently with the status of request? for a default board? so the default port for utip not if it was at it's already some iterations ago We got feedback from the working group that it was not necessary since when configuring UDPNNNF, you already need to configure the IP and therefore it's already the operator who can configure the port. So our position is that it's not needed but given that the UDP client server there was a default statement and we needed to refine that default same but given that the UDP client server, there was a default statement, and we needed to refine that default statement on the UDP notive, I had to us the Ianna for a default port. So our position is that it's not needed, but given that now we depend on the udp client server draft, and in that draft, there is a default statement, I had to I think I that's the wrong answer. So I think they're going to turn around and say no. It's like if you ask them for a port and it's limited resource, and it's like we don't really need this, but we're asking it just to take a box then that's going to say no other thoughts. So"
  },
  {
    "startTime": "01:00:00",
    "text": "is there any use here for D for having a port assigned because if there's not then I think we should find a way that we don't need that I can't as a contributor when I published the netcom call home, rest comp call home we did get ports assigned for it, because of course the remote server like what is the port you're connecting to so I think in this case we're talking about the remote port that we're connecting to so so it's the remote port for the receiver you are configuring where to send a the notifications to. And we didn't have to do this for the HTTP note of draft because of course it was for for 443 because I'm I guess it's do this for the HTTP note of draft because of course it was 443. Because I guess if it's always configured and you're configuring what it's going to then you sort of it doesn't really matter you don't need to use actually use a default ports. I think it's worth speaking to not INA first. I'll speak to whoever the experts, designated experts are for this to find out from them whether we should have a port allocated or not and they'll give you an answer and then take it from that direction is what I suggest channeling christian hopps on the check He says, you aren't doing first con doing first contact to a server so you don't need a reserve default port. Yeah, okay So yeah, we try to avoid the to ask for the default port So, yeah, and then the next presentation is about the young generic groupings for UTB clients or UTP servers So here these groupings was on the first iteration extracted for from the UDP notif and feedback from"
  },
  {
    "startTime": "01:02:00",
    "text": "the work group is that it is generic and therefore we are going to generate. So we are able to configure a host name on the client and the server and we are able also to configure local address on the client and on the server was based on the discussion on the TCP grouping and UDP grouping where a server can support dual stacks so a server can yeah can the discussion on the TCP grouping and UDP grouping where a server can support dual stacks. So a server can configure IPV6 and IPVE on the same server So there is a list of local bytes So, here it's a bit, the same discussion with the UDPNOTI We received feedback from MET that the default port zero was not flexible enough on this grouping and therefore should be removed. So we removed it in the dash 04 iteration but i understand that therefore it mismatch a bit with the TCP client server draft So yeah asking for feedback what should we do? We should add, again, the default port or remove it and give flexibility to developers So is this default port for the local or remote port? I think it's for both if I, but I'm not sure now And what was the reason to change it from being the same as TCP clients overdraft? to consistency so so so the first iteration, I wanted given that there was already an existing TCP client server grouping having a consistent let's say groupings right so that was the only reason"
  },
  {
    "startTime": "01:04:00",
    "text": "Consistency is good. I guess my question is, what was the reason to change it to be different? It was a feedback from it. So, so, so give flexibility, because the thing is that when we add a default statement on our grouping, the ones using that grouping cannot refine and remove that default statement They can refine it? They can refine the port but they cannot remove it and add a mandatory statement, for example That was my issue on the UDPN. So, UDP notive we had a mandatory port to be defined and I tried to, okay, I want to remove this default statement from the grouping but I could not. So, and I checked with Yang and that's actually not supported from a young perspective. It's true you cannot remove it but I'm not sure if that's important. Let's take it and I checked with Yang and that's actually not supported from a young perspective. It's true you cannot remove it, but I'm not sure if that's important. Let's take this one to the list. Okay So yeah, apart from that, there are no other all comments are addressed so I think it's ready for last call. Depending that discussion. Yeah, exactly exactly I think it's ready for last call. Yeah, exactly, exactly, exactly. So yeah, if there is no comment I will follow up And then also present an update on the distributed not if draft on behalf of the authors There have been no change since the last iteration the only ones have been very much the authors. There have been no change since the last iterations, the only ones have been very minor, adding the message publisher ID, so that's the process where the publisher sends the message to a receiver and that's it and this process ID is added to the different state change notifications push update and push change update notification now and given the"
  },
  {
    "startTime": "01:06:00",
    "text": "we are pushing this process IDs on this draft, this has led to the removal of this push pushing these processes on this draft we this has led to the removal of this publisher ID on the sequencing draft and there is no pending items on the district native. Rob is in the queue Hi, so as long as long as I'm getting the right draft, so I had a discussion with thomas werner this week at the hackathon about a concern that I have the way you split up a subscription into child subscriptions, you may want to know what X path those child subscriptions are for and to advertise that both of the the sort of parent subscription and the child subscriptions. And my particular concern is about when you're sort of pushing on re-synchronization data and you split up this parent subscription is you need to make sure you have all the data from all the different child subscription so it was about how you piece that data together and know you've got everything. So I think that would be useful discussion to have. It could do a last call but I think that would be exactly correct Yeah, that's correct, Thomas Yeah, so that's all So basically, yeah, the only div is adding this pool adding this Polish ID on the push update and push change up the notification Okay. So I see that you're hoping to move to working group last call. I'm just a little bit surprised to do that or like it's seems like this this draft got parked for a while We weren't working on it. We weren't discussing it It was updated, the 09 was published was a three months ago but no discussion on list It may be ready for working group last call, but because it was kind of in a, background status for a little while, I think I would"
  },
  {
    "startTime": "01:08:00",
    "text": "encourage pushing the other drafts that you have in progress first, try to get them through working with bless call and then we'll bring this one to work Yeah, so every time we have been pushing this draft to Lascault call and then we'll bring this one to work yeah so every time we have been pushing this draft to last call when the udip not if was right for last call so to work. Yeah, so every time we have been pushing this draft to Lascault when the UDP not if was right for Lascault. So that's what, in a way, we were waiting for everyone all the drafts to be last called at the same time And a little more history of, sorry, Mahesh a little more history on the distributed notif was, that I think we parked it because we were waiting for hcdp's not of draft to get through before they, we did more history on the distributed notive was that I think we parked it because we were waiting for HCTPS not of draft to get through before they requested for publication Yeah, and Thomas and just to top of what just Alex said before we also have now three vendor implementations. That was also another reason why we see just Alex said before, we also have now three vendor implementations. That was also another reason why we said, like, let's make sure that we have enough implementation So we are sure about that. OK, excellent excellent Okay. Great. And you giving back some time to the working group? Happy. Thank you. I think I am more the next one. Okay Yeah. Just next slides slides Sorry. Yeah sorry. Yeah. So yeah, I'm Alex again. So on behalf of the authors presenting an update on the young model for netcon event Notifications. So to give you back a bit of context, what we are trying with this draft is to get a young tooling to validate a young push notification. The issue is that young push in 8641 they rely on 5277 for the notification header. When this message is encodded in XML, we have the model in XML"
  },
  {
    "startTime": "01:10:00",
    "text": "and Yang Push in Yang. So we are able in a way to validate the message. But when this message is encodening in other encodings, such as JSON or Zibor, there is no Young model to validate that message And that's what we are trying to tackle in this draft So just to give your study there was a working group adoption call It showed plenty of support and clear interest from the working group to fix with this RAP graph, in a way, how to validate JANPUS messages but there was a push from MET on whether, on why this draft was only defined in the notification and not the whole model from 50 to 77 the position from the authors is that all the RPCs are redefined on Jampush and there is only one piece missing which is the notification and that's why we are in a way trying to solve this gap And then there are a few YAM push related topics that were triggered and a bit sidetracked the threat and is in the queue andy bierman, yeah The structure only validates event time. That's all you're allowed to put in in. So there is no industry problem at all having to parse a notification and then the event time leaf. I But if you want to I mean, so the structure would only be good for the first element not the next one which is an abstract element in XML which is absolutely not supported in yet"
  },
  {
    "startTime": "01:12:00",
    "text": "Yang, not even slightly So there's no way to do the entire message but you could have a structure that validate the event time but I don't think that's very interesting I think you should just publish this to just to get the SID file because the procedure for getting a SID file requires a Yang module So if you want SIDS assigned to these two, I items, that's the only way to go. And it isn't for validation because you can't represent the message that is defined in 5277. You can't do pretty much like the RPC element you couldn't do either because as soon as you get to the method name Yang has no way to do that Yeah, so there are two things When we are explaining vendors or implementers of Yampo, they are always asking why there is some sort of IETF notification with a young module, since Yang defines this as a namespace And second thing, yeah, I agree we are all only defining the event time header, and that's all The rest is defined in the Jump Push RFC, and we are not touching that I just want to be exactly to say then Rob and the kid. So I mean I think it would be useful to have a Yang definition of generating events that we can use for any encoding. And I feel at the moment that it's all a bit hoping and piecemeal that we've got 5270 that defines for XML and we've got other dot documents that say, oh, we're going to send it over this one, use this module name and it's this particular encoding and we can somewhere get a commonality for that that would be really nice, because that's the thing that we're missing"
  },
  {
    "startTime": "01:14:00",
    "text": "that you can't augment stuff in here because there's no module and you may you may think it's like a yang next issue i don't know but i'm hoping it's not but well any parser will get the entire message, not just event time, so it's not useful to part to validate a message that has more than just event time in it And it's mandated to have more than just event time in it The method, I mean, the element for the event is not optional The RFC-257 XSD is very clear. It's a notification element, event time element, followed by something, one more element You know, so the, you won't be able to have what you want, Rob because you won't be able to use that against a real message you can use it to define SIS, but you won't be able to validate an actual notification So let me go to online backups not this one, this one So, I think the missing guy is in Yang where we define the notifications with the notification statement but uh my understanding of Yang and Yang Poo with the notification statement, but on my understanding of Yang and Yang push is that this notification somehow it adds this event time leave. And this comes from rFC8 5277 so that's why in a way I think in in the structure defined in this draft we are only defining this header and the link with Yang is the notification statement So that's why I see the link and how to value the whole thing I don't know you mean you would create some new procedure?"
  },
  {
    "startTime": "01:16:00",
    "text": "with like normative text that's not anything to do with Yang? Because as you're aware, the event cannot be modeled in this structure So if you're using the structure, to validate the notification message, it will fail because it will have extra stuff in it according to the struct. That's all you're using the structure to validate the notification message, it will fail because it will have extra stuff in it according to the struct. Okay, maybe let's start offline Jean sorry, just to say, I think just even for the sake of having the seeds, as Andy was saying, and being able to have a common structure common way of encoding between Cibor, XML and GZon, I think this draft just for that is very, very useful all, I only have two minutes now So given the fit, feedback, we have revised data major revision on this draft and now we are proposing three things using normative text to explicit how message are in encoded in the different encodings a bit making how RESConf is doing it defining the young, and then given the RESCOM uses their own namespace, we have decided to put RESCOMF out of the scope to not break in a way RESCOMF And it's updating a few sets of RFCs since to explain why in a way we are doing this. What do you mean RESCOs? is out of scope? So, on RESCOMF is out of scope it's saying that on RESCOMF, there is normative text saying that notification has"
  },
  {
    "startTime": "01:18:00",
    "text": "IETF RESCOMF. As a namespace and what we are saying in the draft is that when the notifications are sent through RESConf, we are not changing that namespace. That's it and what we are saying in the draft is that when the notifications are sent through RESConf, we are not changing that namespace. That's the only thing thomas werner, just to add what Rob's said before about it's a bit honky So in IETF rescond we have this normative tech where in HTTPS note if we have a digital way of doing it. And here we're just trying to make sure that we can find a comment way of doing things Could we make try and hold an interim on this topic, possibly? I think it's quite a knotty one. I think there's a lot of details. I think that needs a lot more discussion. Sounds like a good idea. Thank you Yeah so this was one change. The young module, also to be backwards compatible with 50 to 77 using the name, the same name namespace. And right now we are using normative text saying that an notification is composed by a notification container IETF notification and so on question to the working group is, is this is this way to fix the issue? Is the normative text solving this gap? or should we change the approach or how? should we approach it? I think we just decided that we're going to have an interim, a virtual interim, so let's defer the question until then Thomas"
  },
  {
    "startTime": "01:20:06",
    "text": "Thanks. So that's about support of host name and seek sequencing in Yang Notification. So we just had the introduction about the notification element. So here currently what's missing is when the notification message is being forward from the Yangtush receiver downstream to another data processing element without augmenting based on the transport IP address, the host name we cannot identify anymore from where the message is coming from. So therefore we think it's essential that the host name should be part of the notification message and we believe it's best in the notification header itself since it's unrelated to the subscription So here in yellow these are the two elements which we are adding in the notification message and we are also adding in the so-called system capabilities and also in the notification capabilities of RFC 9196 These elements so that it is discoverable so that the young push receiver knows that the Young Push publisher has this capability and will be adding this information to the notification That's in a nutshell what changed in the last revision of the document looking forward to get feedback from the working group Uh, Rashad, so when I last looked at that draft, I think this sequence number was used to figure out if there were messages"
  },
  {
    "startTime": "01:22:00",
    "text": "dropped. That's correct, yes. But depending on the transport you use, you could get, I think we tried to do, we're trying to do something similar in BFD if you get out of order you, you might make the wrong conclusion right right so here we differentiate between transport and messaging Okay. So since that message can be forwarded across the Young Push receiver, we want to be able or want to be capable of identifying message lost end to end Okay, I'm not sure understood your answer but it's fine. I'll follow up. Okay My, I don't know sorry, I preempted Perv, why don't you go ahead? So I just wanted to ask, do you, do you, any more metadata that you want to add to the notification? Asking as a contributor? No, I do don't. And that's a discussion currently we have with the RFC 3535 piece I believe at IETF for network telemetry protocol, we should agree on some basic action elements, like all the protocol should should use and I believe one of it is a time stamp is a host name and a sequence number Thank you uh Mahesh I think what Richard was referring to is in BFT, you, get BFT packets in a particular sequence number and if you were to receive them out of order not for that I don't know bore everyone with BFT details but generally it would be considered that you have dropped packets and BFT session would consider that the session has actually gone down in your case, what I think what Rashad is referring to is"
  },
  {
    "startTime": "01:24:00",
    "text": "the fact that if you get updates out of sequence, you might actually decrement the count say you're getting updates on input packet count If you get a packet that is out of sequence, you might land up decrementing the count in instead of if the fact that it has been income So I think, Rashad, sorry, is that what you're referring to? That was not exactly it, but it's, that's being valid. Okay, right And my point was just, these are discussions on two different ozi layers so one is the transport and one is the messaging layer, or in this case the application layer. And we just want to keep those two things different different andy bierman, so I have a couple of questions The sequence number is only relevant for UDP because the other transports preserve order So, and the UDP transport already has a message ID in it. So I don't see why the sequence number helps, why it needs to be in the notification because it's already in the UDP header And then also the host name I just can't imagine all our customers being happy with adding a really long string to every single notification we send You know, I don't think that's something that that's needed everywhere if it's only needed for you every single notification we send. You know, I don't think that's something that's needed everywhere. If it's only needed for Yang Push, then why isn't it only for Yang Push? so I think it's fine to have metadata and I don't agree that every single application on the planet will need the exact same set of metadata. So that's probably something that needs to be considered So maybe Andy here a question, how else would you identify? from which note this message has been published?"
  },
  {
    "startTime": "01:26:00",
    "text": "from? Well, the mean, the UDP header has the observer ID and the message ID and a sequence ID. Right, but that's on a different uh ozi layer when you forward that message you need to augment currently that message This is what... That's an implementation detail Kent is a contributor. You said that the server would publish its capabilities so that the receiver knew that it would receive these extra headers but is it not that the subscriber, you know, says that I wish to receive these extra headers? Like in this description request, it's it saying I wish to receive these extra headers or is it just automatic? It is automatic That's a change in behavior for existing systems right? That's correct. So why wouldn't it we don't do that normally. We, we always have it that the client says that it wishes to have a change in behavior. Right I was revering before on RFC 35 piece and some basic requirements which each network telemetry protocol should have And one of the requirement requirement, I believe, is from where the message is being pushed from I don't deny or dispute the requirement or the desire, but in order to support backwards compatibility with existence systems, I'm not sure if it's okay for the server to just push new data automatically. Right, I understand that we thought we addressed that with the it's now discoverable Okay So just quick on, on that maybe you can make it configurable or something on the device to determine that pager. I actually want to comment on the sequence numbers"
  },
  {
    "startTime": "01:28:00",
    "text": "If I understand this correctly, the UDP sequence number has been used for the hop between the device and the initial collector you're collecting to, whereas the sequence number you're putting in further down is for, like, the end-to-end flow. So you've got the sequence I need to track it all the way through to the final destination. And it's the same information as to do with it, like the host name thing. Exactly Difference is it's not to that first hop is can you get it all the way through that? through the Kafka bus, through into the time series database? and have the integrity all the way through. Correct Benoit Clays, on top of what you said in a the host name, which is fully right throughout up, the thing with UDP, is that UDP, whenever you are on a collection, on beyond, what you see, Andy, is like the unique idea of the pop that you manage is the IP address that you see And whenever you take any protocol with UDP management protocol, with UDP, this is the IP address of the outgoing interface of the router. So if you take this interface of that, one if you see Netflow if you see CISLO you're going to see two different management IP address Right, so this is an issue at the top there As Rob was mentioning, one hop further after the collection system. So I don't believe this is important detail. It's actually a basic problem we have, which is what is the management idea of routers in the network And I believe that we should have all the management protocols having the same ID, at least the one at the time based uh the udip based ones So the queue is locked. I think we need to wait with respect to the next presenter We need to progress. So you have to take these comments on this. I'm sorry, Olga. The queue is locked locked You have too much slides and we can. OK, let's move on"
  },
  {
    "startTime": "01:30:06",
    "text": "So the next document is about adding observation time stamping into young notification Just to remind, currently we have a timestamp which is describing when the notification message is being sent from the young publisher to the young push receiver What we are missing is when actually the matrix were being observed in a the young push subscription And we are adding two information in that in the young push header one is the so-called observation time. So when the information was being obtained from the Yang Data Store And in point in time, we are described basically depending on whatever we are doing, periodical or on change subscriptions at which point this has been observed. So for instance, at the accounting start, so at the polling interval, in the periodical subscription, or for instance in change when actually the change for instance, for instance, from an interface from up to down happened And yeah, we also added in this document the capability to actually discuss that additional information like I explained in the previous document relates to RFC 9196 9196 And for both documents, which I have shown so the sequencing and also the observation time we already have the first implementation Please refer to the hackathon slides if you want to see more on the text cases we have and also the results we have drawn and we are looking forward for the next IETF 121 Great, thank you"
  },
  {
    "startTime": "01:32:00",
    "text": "And we are running a little bit, 10 minutes behind, so our 10-minute buffer has been consumed Per, I believe you're up presenter Hello, on the behalf of the authors of NetConFover quick, I will present this draft to you So why do we need NetConn forward quick? Well, almost all currents secure transport protocols used by NetCon, they are TCP based so they have so shti TLS, soap, B, etc. TCP has some shortcomings that we all know of, head of line blocking, three handshake and not supporting connection migration and so on So why do we need a quick So it's, as you know, it's a transport protocol, connection oriented, secure UDP-based, it has support for streams, stream multiplexing, low latency and authentic encryption header payload So during the hackathon, I talked to one of the co-authors, marc blanchet, and he said that Quik was conceived to shave off a few say, milliseconds or seconds on planet-wide operations but for deep space, you can actually shave off, say, 45 minutes So that is one of the main motivations So what's in the draft, connection management? You have the virtual identification for quick and negotiate that, establish connection, and then it's defined how to close the connection and terminate it So this is familiar"
  },
  {
    "startTime": "01:34:00",
    "text": "ASCII art. We can see here basically what this tries to show or convey is that we have mainly two different ways of operation so RPC based where you call out something and get a response that is bidirectional and the other one is notification, so unidirectional So, mapping this to quick then would mean that the bi-direction stream is the type 0 and the unidirectional stream notifications is mapped as quick stream type 3 Can authenticate by TLC client certificates and matthew quick transport quick TLS also defines the server identity and client identity with TLS Okay So there's Ianna considerations in the draft registering, registering this protocol the NOQ, NetConf over quick string these three bytes, and also a draft, registering this protocol, the NOQ, NetConf over quick string, these three bytes, and also to be done is to register UDP port quick string with these three bytes and also to be done is to register our udp port for netconf over quick was done in um so recap from iatef114 uh done in, so recap from my ATF 114. I actually didn't attend that, but the sentiment is that this work is valuable and that was also the sentiment from last IETF, where marc blanchet came and asked at the mic It was needed updates in the 06 version general document overhaul, improved citation"
  },
  {
    "startTime": "01:36:00",
    "text": "to quick RFCs, improving the striction of the endpoint authentication and description about connection management Next step, further comments and endpoint authentication and description about connection management. Next step, further comments from the working group and the authors request adoption I believe that's that last slide, thank you. While I'm bringing up the next slide, can anyone speak to the interest level? I would do a show of hands, but it's disrupt me from bringing up the slides, but are folks interested in this? Should we go ahead and try to move? to adoption right away? I see one hand, two hand, three Okay, yeah. Good Thank you. Oh, and someone's in the queue For the record, beep and soap have been marked historic. They're not current I believe there was a comment comment in the queue? Disappeared. Okay So I yield the rest of the time, five minutes No, no, no, I'd cancel that time. Yeah presentation. But bringing to the next presentation Yang groupings for quick clients and quick servers, basically quick client server draft draft It's a placeholder draft to define configuration for quick client for matthew quick protocol It's reusing TLS Client Server and UDP Client Server At this moment, there's nothing more yet I've done some experiments adding we'll we'll come to those later So the solution overview, as I said, uses TLS and UDP groupings and quick required TLS 1.3. So there's a new feature requiring this in the model. These are the models AATF Quick Client, AETF Quick Server This is basically it so far. These are the groupings for matthew quick client"
  },
  {
    "startTime": "01:38:03",
    "text": "These are the groupings for the QuickServer So if we drew up another draft, HTTP, client server, it has this quick case in the transport choice where it defines basically this, but not the feature for TLS 103 So this quick client server, could instead replace this and with quick server parameters and there should be client server wrapped This would all tie into then the NetConflient server draft where probably the NetConflient server quick draft as was mentioned in the previous presentation would augment the NetConf Client Server draft to add matthew quick server grouping there as a possible transport for a netcon That is what I've tried. It's not in the draft yet or any draft and don't really know where it should go yet but I'll discuss with the authors, probably in netcon Yeah, so that is then a good way to go I believe, because then Netcombe client server doesn't need to stop, because that is nothing is hindering that draft to what progress. But if we would stop it and add this quick choice, then that would be stopping that and there's, it's unnecessary so open questions. There has been some discussion on list with med what other parameters are valued to add what is the correct level of configuration option exposure here? and next steps to work on the questions raised more feedback from the working group is it valuable to update other documents that we saw hdp client server for instance and adopt a document?"
  },
  {
    "startTime": "01:40:00",
    "text": "Thank you. Can't? Yeah Kent as a contributor. It's great to hear that we don't need to hold up the NetConf client server draft in order for it to be augmented later on to introduce this case statement for a quick. But what about the HTTP clients? Server draft? Would there be any need to hold it up in order to support yeah yes again yeah I guess if you would if you want if you would like to bring in quick clients server instead of the thing that is in the protocol stacking now, we would need to hold it on that draft I'm not sure if there's uh appetite for that, but Mahesh is going to come to the queue Rob Sorry to jump the cube from Mahesh Yeah, it's not just the HTTP. Then it's you're back to impeding the NetCon Clancy and the rest of plants server, right, so. And HPS notice And of course, HTTP is not as so question really is what? harm would it do? If we go ahead and push the H2P clients over without waiting Is it possible to refine? the Yang model afterwards? You can refine the if we go ahead and push the HB clients over without waiting? Is it possible to refine the Yang model afterwards? You can refine matthew quick transport cases Sorry, do you say it is possible? possible? I think so, but I mean I have to go to the computer and ask that the computer what they fix the tools. But I think so Yeah I think my post personal opinion, I think we should go ahead with the drafts we have and then come back and look at what needs to change. I really don't want to hold those drafts up anymore I guess if it's really wanted to"
  },
  {
    "startTime": "01:42:00",
    "text": "support QuickLine server draft when that is finished one could update those documents It'd be a biz. Yeah, exactly So just a couple of quick comes I think that we had discussion about the encoding for me making an HTTP connection. And if that's using a URL, then obviously I think that might mean that you don't need to do this because you wouldn't know we're connecting to it's HTTP 2 or 3 that is for the client as I have that's the client so I think he's of the draft might be yeah so if you have a netcon server yeah you would like to configure that where to suppose a quick um quick parameters right and then give me have a little bit of time, I was going to make a quick comment on the previous presentation which is to say that in terms of having matthew quick setup, the connection is bit of time, I was going to make a quick comment on the previous presentation, which is to say that in terms of having a quick set up, the connection and negotiation, I think it depends on how security you want in that first pack of the first data So to get the really fast reconnect, I think you lose some security properties and what data you can put into that first pack is limited But you need to look into the details. Zero round trip and the one. Yes, yeah. And I think that is in the netcom for a quick that it, um, um, um, um, not use zero architect into the details. The zero run trip and the one. Yes, yeah. And I think that is in the NetConforbic quick that it mandates to not use zero RTT, if I recall correctly. That seems sensible But that is for the netcon for a quick client server doesn't Correct. That's pretty sure okay we've drained the queue. Thank you, Per. Last presentation and then open mic If there's an open mic conversation people would like to have, start thinking about that I've just passed side control to you You're muted We cannot hear you"
  },
  {
    "startTime": "01:44:09",
    "text": "No, not yet Okay, so let's try the open mic right now. When she comes back, we'll bring her in. I have one topic. I'd like to start with, which is the feature compatibility between RestConf andy newton It is my strong belief that we as a working group should ensure that the two protocols are the same from a feature perspective, feature, you know, like anything we add to next NECOF, we should always be adding to RESCOF and vice versa Show you, please go ahead All right, I'll just a quick comment because RestComp supports RPCs in action then anything you model in Yang is automatically supported by RESComp Still can't hear you, Zelen I saw some nods in the room when I was saying that, so others believe that the, you know, compatibility between the two protocols is something the work group should try to do. I think looking to our AD, Mahesh, I would perhaps we should update the charter to say this Oh, yes, we can hear you now but hold on a second. No, go ahead, Mahesh Um, Mahesh, so other, uh, I'm thinking about putting it in the charter mic, the real question would be um, in concrete terms"
  },
  {
    "startTime": "01:46:00",
    "text": "are we evaluating every submission to say we want compatibility between Raskan and Atcon? I'm trying to understand the implication of putting something like that in the charter, instead of it being an implicit assumption. Maybe it doesn't have to be in the Charter, perhaps the wrong location, but I'd like it to be posted somewhere official so that is we can point to it because many times drafts come through and there's, you know, everyone who wants to do it for netcom because they're focused on device, you know, but and then it's always the conversation we have to have like oh can you add it to the rest comp also? And I want to head that off the past and say, it is our working group's intention that we always try to make the two protocols the same i suggest that maybe we cannot add a milestone Sorry, add a milestone to have a feature part. It's very tongue-in-cheek comment but then it wouldn't go into the charger and it would still be official and it's something we're aiming for is my thinking yeah well um adding it to the milestone is kind of left-handed way of putting something in into the charter Maybe we can chat a little bit about how to make that happen But I think the sentiment is the room that we should do this, the mechanisms or the mechanics of how we do it how to make that happen. But I think the sentiment is the room that we should do this, the mechanisms or the mechanics of how we do this question. Right. I mean, I thought that was and maybe it was just me that had that impression that, yes, when we try to propose something, in this working group, the idea is that it's not just for netconf, it's for RESCOM also also But so I'm not a strong opponent to it, but that's the impact assumption in the working group. I don't know if we need to update the charter for it but but it may be in place"
  },
  {
    "startTime": "01:48:00",
    "text": "but it's not obvious. So a number of the drafts that we have currently working group documents the only reason that they have anything about RESComp in them is because there was a conversation about can you please add it support for rest comp to it as well so i wish it to be more explicit. Okay Sal Lin, can you come back, come back please? Can you hear me? Yes, can hear you Okay, so on behalf, of all the others, I will present this draft And during this period, we have said submitted three new versions and changes are mainly in the section 3 use case of Kafka Yang integration. And we have added explanation that we will limit the scope of this use case into configure subscriptions because of the use using the udp notive as udp as transport method And we also have explained how the feature proposed in this draft will improve fine dependency solution compared to the existing get-o schema solutions And in the zero two version we submitted this week we have added in appendix the IETF Young Library Impact Analysis, as an evaluation for doing a draft RFC doing an RFC 8525 piece draft draft And as for a further explanation for the context, of UDPD-NOTIF and configured subscriptions, since we are working on the YAM Kafka in integration architectures, which main goal is to organize our data into time series database Due to the need of real time instructions, we are expecting it to handle massive amount of data"
  },
  {
    "startTime": "01:50:00",
    "text": "using the UDP with higher frequency and less performance impacts while preserving necessary metadata so that we can we also enable receiver that the receiver can understand the Yangs semantic and because of the usage of GDP we do not expect that there will be one communication channel that will do both the job of making the subscriptions And that's the receiver we receive in this channel the YAM push notification message And therefore, it has to only the configure subscription will be applied here as opposed to the dynamic subscriptions, and then the issue is how we're going to obtain real time knowledge of a specific YAM young model's dependency list when we learn about a new subscribe modules. And in the architecture, in Step 3, it is relying on the subscription started message to learn which module is subscribe it. And then we use it is relying on the subscription started message to learn which is which module is subscribe it and then it will use get schema to get the subscribe module and depend dependency list of it And from the perspective of the collector, with what currently yang supported if you see only through getting all the modules from the device, that it can make sure the receiver has the complete dependency of one module due to the existing of reverse dependency augments are augmentations and deviations but it is getting all the modules is very time-consuming because real router usually implements hundreds of modules and the process could take up several minutes to be done. And it is not an option for closed-loop automation if it's going to be done each time there is a subscribe module learnt and"
  },
  {
    "startTime": "01:52:00",
    "text": "Following the questions we propose in the last IETF, we decided to augment the deprecate its container module states, but only put it in appendix, and we will not model the module set's name as a key in our proposed module, because allowing the fact that allowing a module to augment another module in another set might cost bigger pro problem And the in the implementation status for hacks set might cause bigger problem. And the implementation status for Hexon's throughout these three the past three hexons, we've been working on still delivering open source codes for this feature augmented byte. And in the IETF1, we have used to get all schemas in the YAM-Push message parcel library, Lipyampush as the method to find dependencies And we have implemented in the Libyan and CIS reports in IETF1 1-1-1-9, the augmented spy feature in it. And during these sections, we have a Docker net appeared to Docker image to work about this feature And according to the screenshot, we can see that this Net2Pier version can support exporting the augmented buy list. And for the Libyan push, we fit it with the subscription-started message and then they were sent to get Yenlib to the device and we verify that it provides the correct dependency, reverse dependency list And here as an explanation to our fine dependency solution based on augmented by, and also answer to feedbacks we receive"
  },
  {
    "startTime": "01:54:00",
    "text": "the problem of whether the gaps or schema maintain non-abendant module whether it can be solved by subscribing to Yangli updates or not. So it is true, but it does not apply to the architecture where we have applied the UDP Notive because the get-all schema is the guest scheme action is sent we have applied the UDP Notive, because the get-all schema is, uh, uh, the guest schema action is, um, since each time we learn that there is a subscribed module and then after it's done the connection and then the connection is caught and we have no idea that during this time whether the module has updated the device has updated modules or not and we will not receive any Young League updates since the connections lost And for the current status of documents, we have resolved all known issues, and we have provided open source implementations here in the Hexon's And we like to call for adoptions but since last time during the last IETF presentation we have heard idea about doing an RFC 8535B's draft instead so we would like to follow up on that idea We have put it as an open issue to whether to an independent submission or to RFC to order issue to whether to do an independent submission or to RFC or to do a base draft. And according to the IETF Young Library Impact Analysis, there are currently three XF documents that's augmenting this IETF Yan library. There are the IETF Yan Library Semwer and the ICF Yang status conformance and the full embedded library And regarding the next step,"
  },
  {
    "startTime": "01:56:00",
    "text": "we as author, we favor to standardize the draft first because to do a bistra draft, it might take more time And here, this is the information for links and draft author and in the appendix we have with the rest of module in the impact analysis Thank you Okay, Andy, you're in the queue Okay, there's a lot to unpack here, but I support the use case that you want to only receive part of the Yang large because or part of the module So that's my first comment. It's not an issue with Yang Library, it's an issue with get schema that you're having, correct? You're getting the entire yang library in order to read the whole thing and then you only want to retrieve a subset of modules from the server instead of all the modules And we should point out, and I don't, a lot of people aren't aware of this, that because the module name revision date isn't actually you unique, then a yang file is useless, so you have to use Get Schema to get it from the server And so one should look at optimizing that retreat I agree that doing 150 get schema requests could take you submit minutes. So I would think the solution would focus on optimizing what you received for this partial, how you, how are you are doing get schema there is no get all schema. There's only the one get schema that we're one at a time, but doesn't mean there couldn't be a new one that returned"
  },
  {
    "startTime": "01:58:00",
    "text": "all the schemas you want in one go So you had one round trip instead of 150 thomas graf speaking I'm sure yeah, thanks a lot. I mean, it's always great to see open source implementations of dot com I think this is really important And you've been raising the questions about the tools options we have. And I would like to comment on that I would rather support an incremental approach. I think we need to move forward quickly and to follow up what ends says, yes, I think we need optimizations And I think what we're describing here is that we do not have to obtain all the Yang models, only the relevant part. Thanks Thanks Benoit, can you put back the slides about it to all the Yang models, only the relevant part. Thanks. Benoit, can you put back the slides about the two options, please? So Andy, you're right. The issue is that if you take the OASic right now, there are like 1,500 young modules. And just a couple of them. So whether we do this and improve our PC, or this young module, in the end it's the same thing. Now, the router can find the deviations and it's the data directly. So if the router knows this, right, it should be directly in this young module and IETF library X extension. So one way together, we need this optimization, right? So the option one there, we favor it. Actually, it would a have been cleaner to do 85, 25, but we know it's going to take some time, so maybe that's going to be for future, call it whatever you want, young night whatever. And we have a presentation and it's required Mahesh, yes, I also support this word as, of course, as a contributor And to Andy, your point,"
  },
  {
    "startTime": "02:00:00",
    "text": "that one of the optimizations is to Andy your point that one of the optimizations you said is I guess what I understood is you make one request and you get all the schemas in one go, but it still doesn't optimize the actual gearing of 150 schemas right so the idea I thought to hear, yeah hear Again, library lit or something just like the chunk of the Yang library that you can about. So, so no, you don't not one request you receive all 150 you. So the, the use case I just got a subscription and it's gonna be for IETF interfaces Well, actually it's a bad one because there's so much stuff that augments high ATF interfaces, but there are a lot of modules that it will be a very significant reduction. So we see in implementations hundreds of Yang modules and maybe the push will only need six okay we're running over so please keep your comments short Only one second So what Andy commented is for that we need to know the dependencies, and this is what the draft is about Okay, great. Thank you, everybody. We are going to have an interim coming up shortly to discuss that one item. There's a few drafts That's what I'm getting to. So we're going to, we have a few documents that are going to go to a working blast call and there's a few documents that are gonna do we're gonna have adoption calls for You want to do it? quick show show?"
  },
  {
    "startTime": "02:02:00",
    "text": "So we're doing a poll for the interest in the last presented draft Should we adopt augment Yangwe? Add one to support because I already shut down the laptop I couldn't catch that it Oh, okay, okay. Plus one for Andy Well, it is so far unanimous, yes, so thank you We will move to adoption And thank you everyone for joining. This is a the end of the NECOM session. Thank you very much unanimous, yes, so thank you. We will move to adoption. And thank you everyone for joining. This is the end of the NECOMP session. Thank you. Thank you very much. See you 1201"
  }
]
