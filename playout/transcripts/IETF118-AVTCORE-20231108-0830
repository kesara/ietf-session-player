[
  {
    "startTime": "00:00:02",
    "text": "And let's see. Do we have anybody wants to volunteer taking notes? But it looks down. I see you all over there. We will need a note taker and try to get this going. To the quickly of a pretty full meeting. Session and just interested Yeah. I I was I've been surprised by that. Yes. Okay. Well, it is 9:30. So let's get started and hopefully Somebody will volunteer take notes when I get to that So, Bernard, can you hear an audio good? Let me take my mask off so I can feel a little more That's muffled. Yeah. We're good. Good. Good. Alright. So welcome to ABT Core. IETF 118. Meeting tips, in the room, please sign into either the like client or the full client, if you sign in to the full client, please turn off your audio and video, Also, audio playback if you're in the room. Otherwise, we'll get echo. Which is unfortunate. Remote participants. Please make sure your audio video off unless you're speaking. And use of a headset is recommended. Her opening tip I think the UI has changed slightly, but these are still roughly accurate. Raise your hand to join the queue if you want to speak. You will need to enable your audio"
  },
  {
    "startTime": "00:02:03",
    "text": "manually. You can also double your video, but separate from audio, video was encouraged, but not required. Here are some links. If you have the PDF, and I'll be going to the PDF, whatever. Agenda in the notes We still need a A notetaker. Before we can get started. So Would somebody please hold your tickets? Somebody who's not presenting. Uh-uh. Moove volunteers. Thank you, Bo. Alright. Not well. We are in the IETF. We have various processes and policies about IPR, about for use of your personal information about code of conduct, Please be aware of these and follow these. Especially, oops, like, Do you want it to do that really well? Okay. Yeah. So, particularly, there is code of conduct. So please behave professionally and appropriately with everybody here. If you feel that must behave inappropriately, you can talk to the Ombudsman team or any of the leadership. Here's the agenda. It's a pretty full agenda. So we'll try to stay on time. Know, we're not usually good at staying on time, but we'll try. And, So but now let's just to get through the flevinaries first. Yeah. My suggestion is that we actually use time or tool for this meeting because I think we're gonna be extremely extremely tight. Yeah. Do you wanna run the timer or do you want me to run the timer? How about if you run it? Okay. Sounds good. Okay. So draft status, various things published. VP 9 is it still in Misref on What's the mistra? This ref is, LRR, which is a misrefund framework. So Okay."
  },
  {
    "startTime": "00:04:03",
    "text": "Skip is an AV follow-up. We'll be discussing that a bit today. Frameworking, I think didn't realize there was a more ID revised ID needed, which I think is just the boiler plate. Yeah. The BCB 4 in stuff I think what I think the draft is older than the current brother plate, which is what It's fine. I just would rather we fix it than the editor make the editor fix a BCP problem. Okay. Fair. So, okay, but not so good. And every every every every every EVC is an idea of last call. I think you just started Yes, ma'am. Yesterday. Good. Okay. We did a a, WG's last LC on B3C, And we've adopted a number of graphs, which we'll have, I think, be talking about most of these at least. Alright. Okay. We have some errata Do we wanna pull up what these actually are or Yeah. Probably. Let me see if Well, I can't can't do that from here because it's the pdf Right. How do you wanna do this Let's see. Sorry. Say say again, Marie? I can do these now for you if you want if you go through them. We just need to look pull up what they are. So let's see. Let's see. Could just Google it, I guess. I could probably do a screen share from It's probably the easiest thing. Yeah. That might do it. Hold on. Let me let me do pull it up that way. Hold on. Alright. On me. Let me do it. Alright. I will"
  },
  {
    "startTime": "00:06:00",
    "text": "in shape screen share. Oh, all the stock for the requested media are already taken. I think you have to unshare unshare the slides before you can share the I will unshare the eyed, and then I will share the screen and I will and to share. Yeah. Here we go. Alright. Right? Oh, here's, here's Francisco stuff. No. I then double click on this let me stick it in here. Maybe that will do it. Okay. No. We're still seeing the slide that you only shared the tab. Oh, no. Well, here we are. Here we are. Good. Okay. Maybe make it a little bigger. Can I make it a little bigger? We make make the window smaller. Okay. Make the window Yeah. No. I could I could see it. I think I could see it here. I just can't see it on my Alright. Okay. So, Yeah. That that one's pretty it it That that was pretty clear. Yes, definitely. Yes. Okay. Good. So that's So basically for well, for this one, We for EID 4873, the notes should reflect that We agree with Francheska. It should be verified. Yep. Yep. It's No. Murray doesn't. Murray is doing it live. verified. Yeah. No. Very cool. Okay. And then, we will This is EID 4938. K. We're still seeing this slide at the moment. Do you have to switch?"
  },
  {
    "startTime": "00:08:00",
    "text": "But are we still see the slide, not the mail message. Oh, it's not coming up. Yeah. Yeah. Oh, weird. It hasn't oh, because it came up in the other one. Hold on. If I do this, should come back. Okay. Hold on. Now it should show up. Now you see it. Right? Yes. Okay. Okay. Okay. Oh, this is actually cryptography. So we have to pay attention to this. Alright. Oh, right. I remember this. We discussed this, a long time ago, and I think This was actually a interoper bug we found between two of them. And I believe The IRADA is how everybody then implemented it. It's a problem that should be approved. But I'd like to make sure that people. So Yes. Hold on. Let's take a look at wanna make sure that we're working with signs off on this change. Was this always the intent should be should it be hold for document update? It's not completely clear. I think it's pretty clear. I think it's pretty clear. I said it, Murray? I would say verify it if the reworking group originally meant to say what's there, even if it was wrong. Mhmm. And then hope for document upgrade if if it if in in the other case, Yeah. No. I just I'm trying to remember. Can you go back to the mail up There we are. Okay. I I mean, I'm personally, I'm comfortable with either status here given what given what the what the request is. It's not clear to me which one it should be, and both of them have basically the same effect Yeah."
  },
  {
    "startTime": "00:10:00",
    "text": "Yeah. I mean, it would it's I mean, this was the working group consensus on how to do it, but I don't know if that was actually the original intent or it was actually ambiguous in the original and then because I think I wasn't I'm not sure It was well described in the I mean, I think we I think it wasn't thought about clearly when we brought brought the draft. So then I would say hold Okay. Alright? When AD and former AD in the room, they can argue with me if they want. All for document updates. Okay. K. And then last one, 6752. So let's look at that one. To find What? Because So it actually would get into You will see the live states if they're thinking you've got it wrong, but that was the consensus of what to say, then verified is the right thing. If the wording you've got it right, like this reflects consensus, even if consensus was a bad idea. Yeah. Then it's hold. The I'm not sure consensus would ever I think it was not thought about clearly. Yes. So, okay. Fine. Alright. What is this? This is just, somebody got Somebody said, frame when they met field, because people aren't thinking about an early video I flicks the number. Right. Which one is this again? This is, that Yeah. I guess 6752 RT payload format for you. I've got it. Yeah. Yeah, I I believe this is Yeah. The intent the intent always was that, you know, they have just supported"
  },
  {
    "startTime": "00:12:00",
    "text": "And so we should save people are re were being sloppy about field versus frame. But they met field. Yeah. I think this one is should be should be verified? Verified. Yeah. Right. We're done. Okay. Great. Thank you. Yeah. Back at the slides. Basically, we agree with Franchesca. Yep. Alright. So, actually, let me go back to the slide is probably gonna be PDF. And we will go back there. And share the previous loaded slides, blah blah blah blah blah. From selection and then go to slide Okay. Yeah. So now back to the old registry, Question, and I don't know if Harold is in the room because I know magnetism, which is Harold, they're all just over there. Yeah. Okay. Excellent. So, basically, this is the issue with the RTP panel type registry, which is missing a bunch of video codec maybe other stuff. The MIME type registry is more complete and I guess Harold is tracking this in the media man working group So we wanna get a rough sense of what to do, And so just so people remember, this is covered in Rfc 8887 section section 74 where it says it shall be requested. The media type is include it. But the was not for IANA. It was for the authors. And, so it didn't happen automatically and the documents didn't include this. And so that's how we ended up where we are. So, we had some posts from the mailing lists, Stefan, made a recommendation that we revised 8888 Section74. And then Magnus, suggested that we close the RTP registry and update"
  },
  {
    "startTime": "00:14:01",
    "text": "4855 and Rfc 8888. And then in the process, clean up the registry, which I think we discussed doing anyway, and, with, with the missing formats, at least the video ones. And then the question is who depends on the registry? And I guess that's the original reference that caused all this whole stuff was in WebRTCPC I guess that could be that reference could be changed to refer to the media type registry, Harold, do you have a comment on on Magnus's recommendation here? I know you're tracking this in media, man. So I am afraid that we Hello. Avastron speaking. I'm afraid that we actually forgot to put it on the again that we the medium and meeting. So the medium, group doesn't have an opinion yet. And Oh, have I Personally, I think that, closing the registry is reasonable somewhere we ought to preserve the information that this media type is useful for RTP or not? But, having 2 registries was obviously done by the Magnus Switzerland. So, I mean, this information is actually kept it needs registration that supports RTP usage. So There are information in the registry entries for the media time registry for which supports RTP. At least for all the after 3000 or so. The first So say 18 8090 failed for that single regional profile might be not have that information. We didn't fix that in the in the 1890 biz. Don't remember need to check. Okay. Can you take it"
  },
  {
    "startTime": "00:16:03",
    "text": "working out and check this. And, well, I presume we just need a short, a short, document to say close the It's a registry. Can you can I ask you to take that Magnus? Since you since you made the offer and suggestion, that's a Spanish list you. Yeah. Yeah. Alright. Man, man, this is going to, to write a short document closing this registry. Okay. And just to check with Harold, assuming we do this, I guess we can move the WebRTCPC reference to the to the media types registry, and that will not cause a problem. He's not in, but also. Okay. Alright. Okay. So I think we're we're making progress on that. I don't have to talk about the response from IANA, but basically, Ayanna's folks are basically saying, hey, we don't read your mind. And whatever you did, be be very clear and make sure you don't understand what triggers what. So you can read Amanda's, advice there, which obviously we had an in before. No. Okay. So now, we're at the JPEG 2000 not to be payload format. Okay. Is, Do we ever present her? Do we have a predator? We can come back to it, I guess. Good. Yes. So maybe that's the Oh, can you hear me now? Yes. We can. I can hear you. Cool. Alright. Okay. Thanks. We can set the set the timer for 10 minutes. Yeah. Where is where is the timer control now? And I can't find it. It's oh, here it is. More tools. Yeah. Alright. Yes. Okay. Good. Okay? You very much. So this was a, proposed payload format that improves on, the existing JPEG 2000 RTP bill format that was presented at the last working group meeting,"
  },
  {
    "startTime": "00:18:00",
    "text": "So next slide, There's a subsequent call for adoption that completed, successfully yesterday And, there's a new Internet draft that's expected shortly to address 2 issues that were identified during the last WG call. And, I've actually set up a GitHub repo with 2 poll request that address those 2 issues. So I'm And I'm gonna go in a little bit more detail with the second one. The first one is pretty trivial. It's just updating the figures to kind of be more consistent with, other RTP payload formats. And, but last and but not least, also, there was a demo FPG implementation that uses the RTP failed format just recently at, not an industry event. And, packet captures are available if folks wanna play with it, Alright. So next step. So, one of the issues that was, raised at a lost working group meeting, and I had the chance to dig a little bit more deeper into it. So the proposed payload format has a field, header field that contains They time stamp on every single packet in the same time base as the you know, as the standard time stamp and the RTP header. And, the goal of this field is to provide a much higher a much higher granularity clock to, facilitate or to improve clock recovery by the receiver. And, it was pointed out, during the last working group meeting that there's there's an art CRC 5450 that also discusses, a an offset, you know, a timestamp for every single packet. And So, but it looks to me like both PT stamp in this proposed payload format and RFC 54 5th t"
  },
  {
    "startTime": "00:20:03",
    "text": "address kind of really different issues. So 54.50 is a very generic mechanism, to provide offset a temporal offset when the transmission time of a packet is significantly different from the presentation time of its payload And that's really typically in the case, for instance, of, enter inter frame, inter frame codecs. So when there's frame reordering when you do retransmission or large variation in video frame sizes, And as a result, because it's a kind of a generic mechanism, it's a pretty big Payload the time stamp. Whereas PT stamp is a much narrow use case, which is really to just improve clock recovery by providing additional clock samples, and it's some much smaller field, and it's, much more hardware friendly. So, anyway, so I think, after, doing this research. And so I'm I'm my my proposal is to add informative text to the to the j to this j2k, scl payload format to, you know, kind of indicate that 54 58 exists for those folks that do wanna handle, you know, large differences between nominal transmission time and actual transmission time, but and separately, there's PT stem for improved clock, recovery. Anyway, so, I don't wanna go over time. This is all in the GitHub. So for folks that wanna comment, please use the reflector or go directly on the GitHub and, provide your feedback. Thank you Okay. Great. Yes. And please submit your document with a new working group name. Exactly. That's right. So I I plan, you know, unless I hear otherwise, maybe at the end of next week, I'll a new ID would deem, with resolving those 2 issues and, with the new name. Thank you very much. Ifs Great. Okay. We're now gonna talk about the RTP payload format for stipend. We can reset the timer to, 10 minutes. You know, Dana Hello."
  },
  {
    "startTime": "00:22:02",
    "text": "Can you hear me? Yep. Okay. Let's see here. Yeah, we published draft version 6 just before the last interim meeting on September 19th. Updated the abstract added a key point section up front. Included the link to the public, old public version of skip 210, know, we've we're re reluctant to give that out before, but sort of bit the bullet to provide that link to because the reviewers just asking for it and kinda capitulated to to let them have it. So it's It's now in the document we also added some STP examples for prioritized codecs in there. Unfortunately, we received no comments back from the from the ICSG g regarding version 6. What we're doing now for version 7 is, again, we're writing additional text, updates to the abstract probably get rid of the key point sections we added before Since now, most information is in the abstract, And, again, waiting for additional feedback from skip skip working group as well as others him the baby Tigor group before, we publish And then basically next slide, Again, at the Skip Working Group meeting we had in, a couple weeks ago in Warsaw, management expressed concern about why this ever's really been kinda stalled for the last So it's basically since January much has really happened with the ICSG at this point. So kind of trying to figure out Hopefully, we can get whatever last updates we have with version 7 to make everybody happy to to move things forward because people are trying to Both the US government and NATO are kind of the easiest document. To to to"
  },
  {
    "startTime": "00:24:00",
    "text": "proceed in order for the next generation skip product center being proposed. So It's kinda basically where we are at this point. So I wanted a just just go over where I where I think what I think we can do to make 7, hopefully, the last draft here. Because I think 07 is a lot better and that it it kind of addresses some of the fundamental misconceptions In some ways, adding cars. The publicly available skip 210. It's a mixed bag because it'll it will let people know, yes. It's publicly available, but then they could think that that's somehow important. Which it is not So that's the downside of it. But I think, we have try to make it clear why you shouldn't be parsing skip. But I think there are a few little things more that we need to do for example, in section 5, which is ought to be payload need a little more detail on the RTP packetization. Think we've made it roughly clear what happens. Which is at skip handles, CMQU. So just provides stuff in the appropriate bite sized pieces so you don't packetizer actually doesn't have to packetize really. But we just need to state that, I think, explicitly. And and explain the figure a little bit I do think we need a little bit of of of of of and there's been a whole there's a bunch of discusses related to profiles, So I think we need a little bit more on transport. Which is the interaction of this of skip with multiplexing my understanding is skip is orthogonal to our GP, our TCP multiplexing Like, you could multiplex it the RTP and RTP or not, or you could do symmetric RTP or not, but it's it's kind of irrelevant. Is that right? Yeah. Yeah. Yeah, it doesn't mean, it's just the payload that's being encrypted aside to Right. Right. So anyway, things like that are useful to just"
  },
  {
    "startTime": "00:26:02",
    "text": "even though they're obvious to you, it may be useful to say them, because then, The other question is could you do bundle. Like, bundle audio and video. Is that something that could ever make sense and skip It would change the STP I wouldn't say anything much, but Is that is that I mean, my understanding, I think, again, I'm I'm read that briefly. Few months ago with some of the comments on that truly understand how it works, but I think that should be completely separate from scale if you wanna do it or not. Right. Right. I don't think it should matter. Again. Right. Just just sometimes just saying those things just explicitly may may help, clear up some confusion. And then there was a bunch of ISG comments about profiles and feedback. So let me kinda describe what I think my clear up the confusion there. Which is basically the skip provides security services, confidentiality, replay and integrity protection for the FTP payloads, does skip provide any security services for our TCP? No. No. Right. That's what I thought. Yeah. So it might be useful to say that explicitly And then, you know, the question is, the additional security by SRTP you know, does that have any value? So you you've already you've got all these services for the payload. Should should anybody care about using SRTP. Is that Are there attacks that you know, as an example, you get the authentication services if you use srdp and then you could use cryptex or something to do the RTP header extensions and CSRCs, that would prevent some attacks, like trying to figure out who was dominant speaker or something like that. Is that a is there any value to SRTP there?"
  },
  {
    "startTime": "00:28:00",
    "text": "Yeah. Again, I think it's kinda sort of separate from skip. I think if you wanted to do it or to So, anyway, it would just be some texting. Some text saying, yes. You can use ABP, and here's why it might be good or you could just use ABP if you didn't you didn't care about this stuff. So And then the other thing is relating to the feedback, which is whether you need the SABPF know, skip handles retransmission. So if all you need is MAC or RTX, then I think it's your, you know, you you could dispense with feedback But then the question is what about other stuff? Like, if you're doing skip video, Would you care about PLI, FAR, or RPSI? See, would you need the feedback Is there and the implementations to, to people dispense with feedback I'm not quite sure about those those PLIFRS hours. Say say we're doing skip in a video conference, and you lost a picture. So, you know, the the skip RTX is it's trying to recover stuff but for some reason, it can't recover a packet in a in a frame. What happens? Is it Was the communication terminated or something? No. No. You'll just For for audio, typically, you know, if if you lose a packet, then you may Yeah. Audio, you can just give it for for video. Right? A packet for video. At this point is more likely the same thing. You'll just disc you lose it and, move on and get the next one. So Yeah. But it won't be decodable. Would you I know. I mean, you'll you'll you'll lose cryptescriptographic synchronization for the brief amount of time, before I get And then what happens once it's reestablished, then you'll be able to get back into start decrypting all the packets again. So Yeah. But I'm just because my question is, yes, you'll have you'll be able to decrypt would you be able to decode?"
  },
  {
    "startTime": "00:30:02",
    "text": "I'm I'm just wondering if there's an automatic key frame generation in there somewhere that k. I I gotta be a quick one of us. I interrupt for a minute. Can I interrupt for a minute? That is the device will handle what it needs to do. And if if they do need to do this that that can be covered elsewhere. We we you're you're talking about how the application works, and we're really and and with regard to RTP, And we can't change the terminals that are out there. They're going to be there. So we can't mandate things. And and discussions at this level might be just considered out of scope for the purpose of this RFC. Yeah. Well, you've gotta discuss the base people wanna know should you negotiate ABPM? That's the only question here. Right? If it's if if the feedback isn't necessary, if handle by getting any answers. You don't you don't need it, and we can you can say terminals aren't likely to implement it, so don't don't negotiate sounds So, Yeah. That's that's basically the question. Yeah. Anyway, So if that's the case, you can basically say forget about the the f and and if you if you care about the s, you can do that. Alright. And then the last is the security considerations, which is just I think all you need to do is just state the security services you have and then just talk about some of the stuff we just said, you know, what you get if you get certificate or not, And then maybe a few things about RTC, which is not protected. So, anyway, that that's basically a summary of what I think you need to do to kinda address all of the discusses. It's It shouldn't be a lot of work. Maybe maybe an hour or so just writing this stuff down. I think you understand what all the answers are. And then that'll that'll take care of all the discusses, if that makes sense. Is it is it appropriate to use the words that that, I mean, you're you're bringing up things that we have"
  },
  {
    "startTime": "00:32:00",
    "text": "I've seen in comments, but were never considered as part of this. We consider them to be out of scope for what this document is trying to do. Yeah. See what you What you're dealing with, though, is you've got an RTP payload document ISG is looking at RC8088 looking for the stuff that's supposed to be in that document. It isn't there. So that's why you've had these discusses and that's why these discussions will remain until you actually do I mean, there's stuff. Like, I don't think any of the things we've just talked about are particularly important. They're just text in there that just checks the boxes for an RCA. Basically, just make sure to mention, no, this is not important. Right. That's basically what we're saying is a whole bunch of things about why this doesn't matter matter or you know, just but clarifying it so the box gets checked. And will we be expecting to see more of these now? Now that more people might be looking at 210. Well, that's that's that's that's I am a little bit apprehensive about this But, hopefully, we put in enough language about why it's irrelevant that they'll They can look at it and go, oh, now I understand from the document, why I shouldn't act on this. It's like, yes. I have this information. And, no, you should not parse anything using that information. We have the health we need we need to understand something though too about this. You know, some of these these concerns about vulnerabilities These products are not normal. This is not an app you run on a PC. Because these devices have gone through their nation's security verifications to to get to the level where they are. So so maybe that's not understood that they're thinking that this is just something that that that that you download and put on a PC and off you go. You can do that, but you're you're not gonna be doing the things at the level that what This is meant to do."
  },
  {
    "startTime": "00:34:00",
    "text": "We have a comment from the. So, Ed, Hi. This is Jihad. I'm one of the AD that has discusses on this, and a lot of things that we're discussing here Actually, that was the reason for having the discussion to know, like, what are the things? So when we are basically looking at an to VRC or like in a draft coming to us. Or at least to me, is basically whether I understand what is written there. I understand there's a lot of thing that, well, this is already in the and all these things. But this is not about is already in the device. This is about RTP payload from it as we understand. And I'm reading the draft saying like, hey, you have not in in in in talking about this. This is like some of the things you cannot really keep keep like, unattended saying, like, I have this is up to my interpretation. Because I was actually looking for whether could understand, like, there's a V. P. F. That's not what we needed at all here. Or RTCP is not really the big big thing here. But as the RTP alert framework, the document then those things why those parts have made mock needed? And y and make it clear for the leaders, whoever implementing this one. Is really important. So that's why that's what you're talking about. Because this is so try to understand, like, this is about the clarity the RFC that we're publishing also. Yeah. So as a as a question, if we do the things that we've suggested here, will that help you? That would help me. Yes. Okay. Thank you. Okay. I don't think this is a lot of work. You know, it's just like spending an hour just writing this stuff down. I think we know what only answers are. It just will help the clarity. So, Not a huge deal. Not a huge deal. Should be. Anyway, I Alright. Thank you. Great. Great. Bernard, you'll follow-up with the authors to make sure that I'll get Yes. Right. I'm Okay. Alright."
  },
  {
    "startTime": "00:36:04",
    "text": "Alright. So now we're at RTP over quick, and we should the timer for 15 minutes. Oh, 15 minutes. Sorry. FS or Spencer? What just happened here? Yeah. The office agreed to, to have the security, suggested security and profile considerations. Yeah. And Bernard will work with him to make sure it gets done right. Okay. I'll keep you over quick. Alright. Try to update to RTP real quick. Next slide, please. We updated or closed quite a lot of issues in the last or since since the last interim meeting. I think the biggest changes we made is that we rearranged the congestion control, section and made a lot of changes there. We added IANA considerations. I'm not really an expert on IANA consideration. Very nice if some people could review that. I think, Lucas had already a look, but it would be nice if more people could look at that. And then we moved a lot of, the parts that we had in the RTP analyze a section to an appendix because they nominated references, which we don't want to have in the document because they were referencing individual drafts, and we moved a lot of that to the appendix. So it's still in there as informative references, but we don't depend on that in this document. And, we we also have a list of which, potential extensions to create we could use in the appendix. So there are a lot more changes listed here. And in the next slide too, I think, you can to that. Yeah. So if you're interested in the details, I won't go into that now, but please have a look at the neck and you're working off the draft. Yeah. Okay. Then next slide. We have closed a few issues as won't fix."
  },
  {
    "startTime": "00:38:01",
    "text": "Please reopen if you disagree with with these, but for these 4, we think for the first two that they are dependent on drafts that are individual drafts or may process further somewhere else and if they are become our sees, then maybe we want to say something about this in RTP over quick, but we don't want to do this in this RTP were quick, but maybe in a follow-up document or later because we don't want to depend on this now. And also for some of these, we think that there's actually not that much that we need to say about in our document because, they are not specific to RTP over quit, but more for RTP in general or quick in general. And then the last two here, reset stream and the stop sending and closed stream, that's what we discussed in the interim meeting, that We added this section for, the reset stream part we discussed last time. And, yep, then the the decision from the last interim meeting was that we don't need to do anything about stop sending a close stream next slide. There are 2 more issues that are currently labeled as probably won't fix. The first one is interaction with ice. We kept this open because there's still work going on in the quick net reversal draft. And last time we pay to pay a quick graph here. If there will be something to say about this in our document and we can still do this, at a later point where we wanted to what's going to happen with these drafts first. I think that probably also don't need to do say much. I do need to say much about this in our draft because it's not specific to RTP over quick. So once we have a connection using IS or a quick not traversal or something like that, then we can use RTP over quick on top of that. But, I don't think there's much specific to what our draft needs to say about it. Maybe some signaling, but our draft also doesn't handle signaling because we have moved that to another individual draft a long time ago. So if we need to say something about signaling then that can happen in the signaling graph, and, multi path. There's still the issue for that. We added some,"
  },
  {
    "startTime": "00:40:00",
    "text": "considerations for multi pass and the motivation already. We don't have specific things to say important multi path, and our document except for the motivational part, and I think multi pass, is going on or moving on in the quick working group. If there's anything to say about this now, document at a later point, then we can still add that, but I done. Think again that we need to say much about it, except for the motivation. Next slide. So then we have 4 issues which we would like to discuss or ask for review today. These are these 4. We'll go into detail in the next slide. So next slide, please. 484. We want would like to add some more detail about how to do congestion control when we are sharing one quick connection with our and some other non RTP data streams. We added the multiplexing part, I think last year, we discussed that a lot, how to multiplex different, data streams with RTP and RTCP. And one requirement was that remake this possible. But we don't have a lot of detail about how to handle congestion control So I think one thing we say in the document is that option is, of course, to use different connections, then you have different congestion controllers for both. It would, of course, be nice to have one connection and since we have this multiplex thing, we didn't have a protocol that could actually be multiplex with RTP on the same reconnection. We wrote these 2 toy, protocol drops down there The first one is just a simple mapping of data channels to click, and the second one explains how this multiplex with RTPA with the same connection. I don't know if they are useful for anyone, but these describe how the multiplexing itself could work, but now we need to say how can we do the congestion control to make sure that, the data doesn't start the meteor or vice versa. And one way, of course, could be to artificial right, limit the non written streams. So,"
  },
  {
    "startTime": "00:42:00",
    "text": "we still have, fixed ratio or something like that for the media stream. Think I have a few more thoughts on this on the next slide. Yeah. So I mentioned the ratios, and we could set fixed ratios for media and non media. We could define some complex structure to explain, or to express some policies, how this could be mapped. One easy option would be to just leave the whole thing to the application but the application would probably need to have a lot of information from the quick stack. If it can have this information, for example, if it knows what, how much data is queued within the quick stack, how much congestion window or how large the con gesture window is then may figure out how much data or how much real time it can send at any moment. If the application keeps the quick buffers low anyway, then this could be quite instant actions. It, would allow to adjust, at, like, the decision how much data or media send at any point. But it would probably become a new API question of do we need to expose to the application so that the application can actually make this decision Spencer. Yeah. Thank you. I I just wanted to say that, I was able to attend about the 1st 20 minutes of ccr, CCWG yesterday. And I'm thinking that, I'm thinking that, we really don't have a huge amount of guidance that we would be able to say on, you know, more than do the right thing. On this topic, just just based on that based on discussion, right at the beginning of, CEWG yesterday."
  },
  {
    "startTime": "00:44:01",
    "text": "So, I just wanted to provide that as input. Thank you all. Great. Thank you. Use empty, I guess. Yeah. Okay. So, yeah, if you have any input on this, the would be great if you could let us know or put it in the issue here. Number is 84. Please comment there. Then the next issue is I think also congestion control. Yeah, this is about real time quotation controllers and quick stacks. We have some guidance in our document that says, it would be nice if the quick on, a quick implementation could use a low latency contestant controller. We have references to screen later and GCC, and I know that Bernard already mentioned, there's Copart and Creek in our GitHub issue, I think. I add this to the site because I only saw that later. So I don't know much about the co prime implementation and quick But it would be nice to have some information in the draft, I think, about what would be required to have these low latency implementations in Greek. And whether it makes sense to have the references to these algorithms in their know that there are time stamps required for some of them. And We wonder if there's anything else that our document needs to say about these algorithms and how usable they are in quick And then there's also FRS, which is already mentioned in the draft, but it requires some more, corporation from the network. Bennett. Yeah. Both L4S and Copa have been implemented. L L4S is in the Apple quick implementation. And I don't know how available that is. Like, but Copa is in the better, Move fast implementation of quick. And I believe that's also been used in some of the mock demos. Spencer may know more so anyway, both of those are available. I don't know that anybody's"
  },
  {
    "startTime": "00:46:01",
    "text": "permitted with RTP over quick with any of those two things. But we do have 2 low latency implementations available I don't know, Alright. So if anyone has experience with this would be nice if you could also comment in the issue or now so that we can add any, information that is helpful to the draft I don't see who's next on the Alright. Randall, we don't hear you. Peters. Double Meters. The current draft for a surveillance Mozilla. The current draft for for, web transport at the uh-uh 33 side is that the, you know, we can request a real time, a real time congestion control. We cannot mandate it. You know, it's it's merely a request and the implementation may do so or not. So I think it, you know, I think for this, draft you have this you should say that, you know, you should use a real time congestion control but I don't think you should be saying much about what congestion control should be used. You know, you may perhaps give some that you could give examples, but I don't think you can do much more than that. Yep. That's what the draft currently does. It references these 3 and says would be nice if the quick implementation, should the, the quick information should use 1 of these or any other low latency algorithm, but we don't require which one specifically Yeah. But the question is just to, like, do we need to add more information about what the quick implementation or, like, what of these algorithms are applicable and quick implementations because"
  },
  {
    "startTime": "00:48:00",
    "text": "for these 3, which we had before, I don't really know if there are any implementations in quick stacks and if that's easily doable. So who's next? Peter? Another thing that might be useful to say in in response to Randall's comment is to say you should implement, say, one of these timestamp extensions because if you don't, then the remote side will be more limited in which algorithms that can implement and I can also mentioned that I saw another implementation of COPPA in a a library for quick called Tquick. So another data point, I guess. But I I believe that COPPA does not require the any timestamp extension. Peter, what was this key quick? Is that a what language? In rust? Okay. It's on GitHub. Alright. Thanks. That's good to know. Jared, yeah, I think I mean, it's it's a good good that we're referencing all these all the three, we have been like, talking like GCC. I don't know, like, what is in the draft and what is in the implementation. So This is, like, I don't know So, the the what what I actually came up to say is, Well, we need some consideration on the like, red adaptation part. I mean, we could also think like a quick will do condition control of this one depending on whatever pre implements because we don't expect with RTP. This one, we don't expect, like, quick to change a lot. Just to clarify, right, that's the spirit of this whole document. So, I mean, we can, do his own condition control. We build the back pressure we actually do pretty a specific rate control dependent. Like, the need we have."
  },
  {
    "startTime": "00:50:04",
    "text": "And, actually, in Aramcat, we we support that part in this screen. So at I know it works. Just so we we might actually be in this draft focused more on the rate adaptation part. But not in the condition control. I'm telling the quick stack should create some information back so that we can do the rate assumption better whether it's a back pressure or building up queue or whatnot. Or in even more specific conditional control will put it, signaling back to the rate of attrition part of the application. So we could also do that. Alright. Thank you. Just one last comment. There there is, for red adaptation, and I don't know there are exam fairly small, examples of things like per frame, which is very responsive. That kind of assumes that you know what the target rate is, But anyway, that that is something we could play around with. As assuming that we ever get, a bandwidth estimate that that can be assumed to be provided by quick. Could do something like just get an idea of whether per frame could be would be useful. Yeah. Yuck. And we're close out of time here. So Yeah. But not your quote, not just Just trying to understand what's being proposed here. We have been trying to stay clear of hand waving suggestions that may or may not work because it's hard to come up with very concrete wording that would of any good use. So are you now suggesting that we should do, again, some try to come up with something, or was this from both Moa and burner, more general suggestions."
  },
  {
    "startTime": "00:52:00",
    "text": "I'm I'm I'm trying to transfer. Or like the experiments. I I don't Yeah. I don't think any hardly any of this needs to be in the document. Okay. You. Just want to just want to have playing with this stuff just because it's out there now, and and you could just do experiments. That's all. Okay. That that that's what we are doing anyway. I'm happy. Thank you Alright. Do you wanna quickly go through the rest of the pre as a how much more presentation do you have I think I think one more slide which we, like, to discuss this pencil slide as the next one. And then we have 1 very or 2 very quick sites at the end. Okay. Let's let's take a few minutes, but I think we're This is an important topic. Okay. So this one is Spencer. Do you wanna present Sure. So basically, since 00 of the re individual draft, this draft has always include both streams and data grams, I did ask on the mailing list. And, if this was something that people actually expect to use and, got response back from Bernard, you know, with with a couple of examples of why that would be, you know, why both providing both makes sense. First question is, would it be useful for us to provide guidance on streams and dataograms. And, the second question is that, because we're doing, Stop sending to allow a, allow an application to catch up on streams to basic, you know, basically, The receiver has decided that what it's getting is old enough to where it wants to, catch up to the the front end, you know, the front end of the leading edge of forthcoming, what's happening."
  },
  {
    "startTime": "00:54:00",
    "text": "That and that's that's fine. If this works to the draft now, but we noticed that, quick, rock center can resume resumes something that was reset in streams using data graphs. Is that is that also okay? The Straumann SDP would require s different S proto proto, the the big question is, would anybody want or need to do this And if, you know, if if anybody wants or needs to do this, it should be allow it. So those two questions about providing guidance between, choosing between streams and, grams, and about, resuming a rock receiver resu resuming RTP sending RTP that was sort of streamed using diagrams. Kernat, Yeah, I'll just give my opinion for what it's worth, which is that for a given media, you should choose 1 or the other like, video, for example, will you do it with streams and then audio with Datagram's but you can't. Doesn't make sense to switch. Like, send you know, video with streams and then switch over to Datagrams that that don't know. That doesn't seem like somebody that makes a lot of sense to me at least. Yeah. It it doesn't make a and, I can't see the key my apologies, but medicine. But it doesn't make a lot of sense to me. So I think the question for the draft is, do we need to say anything about that and at the guidance level. Yeah. I mean, see where it could get really confusing. Like, I send I send a a frame with stream, and then I start sending data grants for pieces of it. Like, what would you do with that? I I"
  },
  {
    "startTime": "00:56:00",
    "text": "Yeah. But I and we could I I think we can make it work. The question is, would that ever be the right thing to do? So with data grams, we really, actually, this is a good thing for us to write down too. With Datacrams, my understanding is that we can't use anything like stop sending to catch up on streams. Because telegrams don't have streams, but, But, you know, so we we can we can we can observe things like that. But, just like I said, what what need what guidance would be helpful to include in the spec and what guidance would just be silly if we typed it. I guess the main thing was probably just prohibit weird types of mixing and similarly for RTCP, right, why would you mix streams and data grams? Like, if you chose, I wanna send out be over data grams, which seems most logical, just do that. Don't don't mix them up in a weird way. And, Bernard, thank you. Thank you for that, thank you for that comment. I think what I think what you just said was that that can be part of the guidance on choosing between streams and diagrams, which is of, it would be, you know, don't plan on switching back and forth. You know, that if you if you choose 1 because it made sense, The other one is probably gonna make less sense. Thank you for that. No. I got Mosenady. I don't know how relevant it is here, but in in mock, you know, we're kinda struggling with something similar about should receivers be able to"
  },
  {
    "startTime": "00:58:00",
    "text": "request their media in one format or the other, you know, over some particular stream structuring or or Datograms. And I think we kinda gravitated to the fact that, we're gonna let the sender's send however they wanna send and not allow receivers to to dictate a preference or negotiate a preference so maybe something like that can be useful here. That decision was more motivated, based on the fact that mock has fan out to many receivers you know, almost by by default. Most use cases, whereas maybe you're thinking a lot more of 1 to 1 interactive scenarios here. But it does seem it's like same kind of principle could apply that you let the sender. You can negotiate both up front, and then you can let the center decide whenever it thinks it needs to send Datagram or stream, should have the freedom to do so. Not under any receiver restriction or preference. Mode, does it ever make sense to you to send both like, send videos a combination of data grant. Oh, okay. For for exactly your scenario, Bernard, you know, video over over streams and audio over datagrams or even core video over streams, but, you know, disposable b frames over Datagram's also in addition to the audio. But that that's, yeah, I think easier to do as a is a sender optimization rather than a negotiated you know, receiver preference or anything like that. Peter? Moe's comment made me think of one possibility where you would wanna send with both streams and data grams, which is if you fake protected some video, but not other video So you may choose to use fact above data grams to do the video on some, and then non infect video would use streams."
  },
  {
    "startTime": "01:00:00",
    "text": "It's just something that popped in my head. So possible scenario. I I do agree with Moe in general that letting the sender do whatever it wants is better than making some constraints about what it can and can't do because then your implementation on the sender is gonna be more difficult because you could do some things one time and other things another time. Okay. Okay. Thank you. So, yeah, then this one very quick. I mentioned the RTCP analysis earlier, which we moved related in the document, would be really nice if some expert could review this too. We will this again too, but it would be nice if people on this more experience could look at it. As well. Next slide. And then we have, these 5 more open issues which are, which we didn't discuss today, but we are gonna work on next. I think most of them are quite clear what's to do there. We are planning to have put requests for them or merge put requests for them for an expiration until interim meeting. I think that's it Alright? Great. Okay. So I'll hopefully try to catch this up a little bit talking about the HEBC profile for WebRTC. Little bit of an implementation update. We now have work underway in Chromium and Safari. There's tracking bugs for each of these. And they're reaching, making progress. Basically, they're getting SDP negotiation is in, for the base profile and level, and the RTP payload format is in there. We'll talk a little bit more about some of the issues with assign from the patient, and the, the HEBC encoder and decoder is already in Safari. A couple of issues in in Chromium and Edge with that but hopefully that will that will get working in the next couple of months. And then Books as usual. So, anyway, progress being made, and, hopefully, at some point, we'll have something working that people can play with. In terms of issues and PRs, we now have a working group draft"
  },
  {
    "startTime": "01:02:00",
    "text": "and, three issues I wanted to talk about and just get some working group, feedback on. T x mode, the the packing stuff that we talked about last time, and then a little bit more about RPSI. Okay. So we talked, last at the interim about TX mode, and here is the proposed text And basically, I think we agreed that the default would be to not include the parameter in STP and default to SR t only question is, what would you do with MRST and MRMT were saying it's option to support this And if you don't support it, don't include it in the SDP. So presumably, I don't think any of the implementations and progress are planning on supporting MRST and MR MRmt So you'd never see that in an offer and presumably shouldn't answer answer back with that. Any objections to this proposed resolution. Okay. So then, next one was for the packy packet. Basically here, this is panel type 50. It's used to provide the temporal scalability control info like the TID, stuff like that. And then the the thing is in WebRTC, we negotiate RGP header extensions that provide similar info like the dependency descriptor or generic frame descriptor, the question was what what we do when we have both the proposed text here is basically to say that if you've negotiated the use of these that provides CSCI don't send it in the in the packy extension. And then if you get it in the PACE extension, you just ignore it. And if you don't don't negotiate the RGB header, then you would use PACI and obviously pay attention to it, but this is this is the proposal for the"
  },
  {
    "startTime": "01:04:00",
    "text": "for handling the pack. I Any objections to that. Okay. So last one is RPSI. This one's a little bit interesting. We won't try to totally hash it out, but, we discussed previously that It is, recommended in RCA 34 to support our PSI. Defined in RFC 7798, section 83, how to do it, so the proposed text is to basically say that it's there and and 1st of all, recognizing 778 98 that it's only used as a reference picture selection request not as positive acknowledgment So say that And then say it should be generated, if you detect black of synchronization, these are basically suggestions that Stephan made and the potential is that you send our PSI, but only get a I essentially a a refresh back on IDR If so, you you don't send our PSI because even though it negotiated, it isn't really capable. this is the suggested text here. So We did get a little bit of feedback that asked what it meant to say must act on the message, and should change the reference picture. That was a comment from Philip Elijsen Oh, Google stock home, And he was wondering, you know, does it make sense to figure out whether the the that the receipt that the sender doesn't support RPSI. They on it, sending an IDR instead of the RPSI. I don't know if anybody has an opinion on that,"
  },
  {
    "startTime": "01:06:01",
    "text": "Okay. Not obviously, something people are passionate about The last thing, I don't wanna get into this in too much detail. But, we have had some problems implementing RPSI. And it has to do with the 2 usages defined in, 4585. 1, you know, a is, indication of a requested picture, that's what 7, 17,98 does. The other is a positive feedback of its successfully decoded picture, which is not used in HDC. So The problem is that Live WebRTC was assuming usage B and, essentially the way it worked at one point was that it would forward the RPSI to the encoder and would generate the new p frame and Because it was a positive acknowledgement, the SFU could keep track of what reference pictures people had So it knew when it got back to the p frame, who would be able to coated or not. Can The problem is when you only use it as a requested reference picture, it's it's a lot more difficult to figure that out. So, anyway, my WebRTC is it exists at least currently without a bunch more work, the SFU won't be able to figure out whether it can actually whether this new p frame can be decoded. So anyway, there's a whole bunch of discussion going on as to what to do to fix this or whether it requires, you know, new new feedback messages or whatever, but, I have heard actually, Wide WebRTC isn't the only implementation that's actually have this problem with our PSI So one question I wanted to ask is, were there any actually implemented our PSI with HEVC successfully. Whether it's just us who can figure this out."
  },
  {
    "startTime": "01:08:00",
    "text": "Okay. No feedback. Alright. May bring this back and if we if we do figure out how we wanna do it. Actually, before we move on to the next presentation, do we skip V3C? I think we might have might have jumped over that Bernard when you're doing this ZIP Okay. We can go back to that. I think it may be later. No. It was it was I think it was supposed to be earlier. Oh, oh, Okay? V3 Oh, there? Before quick. Alright. Alright. Yeah. Yeah. That's what I thought. Yeah. So let's Okay. You can set the timer for 10 minutes and Yep. Is Laurie here? Yep. I'm here. Can you hear me? Yes? Alright. Perfect. Thanks for coming back for me. And, yeah, this is another opportunity to save some save some time. Let's go jump right right in. So the last call was issued on the deadline was yesterday, I saw 4 votes in support and no no votes against don't know how practice is from this on, what happens next yeah. So if you've done working with last call, you said there's 3 open issues, you should resolve those. They don't seem like any of them seem like they should be Those doesn't look like, at least as you list them here, any of them shows should require a new, underworking the last call, they all seemed pretty editorial. Oh, yes. They they definitely are. Yeah. And so we, at that point, we need to I think pick a, document shepherd and go to So, you know, request or submit it to the IO history. So"
  },
  {
    "startTime": "01:10:01",
    "text": "Yeah. I'm still, I'm a shepherd for EBC and for Skip, so I'm kind of and both of the so I I don't know if you have the shepherd I mean, I thought as as Stephan mentioned at the last meeting that the shepherds don't have to be the chairs. So Yeah. That's also true. If you can find this update, Jim, Yeah. And Stephane volunteered to be the shepherd for something. So maybe we could ask him if he's willing to do that. Maybe we can ask him. Okay. Great. We should put that on the notes. Yep. Or we'll find somebody. Yeah. We will pick it up. We the chairs will discuss who we wanna have document shepherd and Hopefully, it will not be one of the chairs. Okay. Well, thank you. Alright. Very good. Thank you. Saving us time. And, I guess now I'm gonna ask for him, Peter. Alright. Can you hear me okay? Yes. I'll just wait for the slide to show up. Did we have 10 minutes for this too? I think I'll have to let me start your timer until we actually, Get to your slides. Yes. There we are. Alright, Javier. Alright. Since the last meeting, The document has been adopted, and I submitted it with just morning change. Yeah. Yeah. So next slide. Next steps, I think the primary thing is to have more eyeballs on it. So please go read it. It's short. So it shouldn't take long. I assume not many people looked at it because I haven't gutting much feedback. I know after a quick look, Bernard fixed my ASCII art. So can make a new version with Better ASCII art, but, I do think we need more eyeballs on it. Then my next question for everybody is or I guess Should I pause and ask? Who would like to Read it. Or is that, Hey, Harold."
  },
  {
    "startTime": "01:12:03",
    "text": "So just, had all the strength I read it. Suddenly, I got this horrible confusion in my mind. Minh. Minh. Put we put The purpose of s frame is so that you can do end to end encryption. Means it's pass the packets pass over multiple hubs. That Yeah. That's The payload type that we have now put in the 1st bite of the of the Hello. Is negotiated. Hope I hope. So does that mean that So, really, it's supposed to change the payload types when they really the pickets, Is that outside the end to end encryption? If so, I guess they have to. I mean, if if they have to, that's important to call out in the the document because it means that you have relays modifying payload, which means that relays can only relay a frame if they understand. That's fine. And nervous. Magnus Westlock. Yeah. I think it's an unfortunate consequence for all that uses normal, like, of offer answer, like, negotiation where you're you you don't set it. You need to if you would have a negotiation style setting all the figuration. Equal to all notes. You wouldn't have to rewrite it, but for current WebRTC usage is set you would I think you you have no choice than to rewrite it. Or or orchestrate your offer answer in such a way that Yeah. Yeah. Definitely something that needs to be pointed out that this is the a consequence of of the signaling system if you don't orchestrate correctly."
  },
  {
    "startTime": "01:14:03",
    "text": "Mosenetti, we we had the same problem with PERC. Then we introduced the another payload type, enter in outer pillow type, just just for that. Because we knew that we couldn't force them to be negotiated end to end And so we had, the, inner payload type and the outer payload type, both in the same the same packet. It has good feedback. I'll, make an issue on the GitHub k. I would appreciate more such comments for more reading. I'm glad that you only came up with 1 such, issue Harold. I'm glad you had it. Thank you. Okay? So, well, can you go back to the next, question I had was, about implementation. Is anyone interested in trying to implement it because I'm sure At that point, we would find more issues that we could talk about. Or does the working group feel like that is an important thing to do before I was eating. I certainly, I think having an implementation of this to make sure it works would be a good thing. I'm not sure I mean, the problem is there's kind of a chicken and egg doing anything in a browser because we don't have APIs to do this, and we need to how to do it to design the APIs. Harold, I'll just say that we're interested in at at Google, we're interested in implementing it, but we have no idea of the time frame in which we were able to get to it."
  },
  {
    "startTime": "01:16:03",
    "text": "Well, it might be useful just to have a discussion among potential implementers even if they don't not ready to actually do it Okay. Well, I had 2 other we had time, and it looks like we have 4 minutes there were 2 questions that I put on previous slides that I thought warranted some discussion the per not perhaps not as challenging as the one Harold brought up, but both basically have a size simplicity trade off. So the first one is whether the enter whether the header extensions get copied from the Intercodics value to the outer So the broken up packet, For each of the broken up packets, or in which case it duplicates data, or not. You know, I'm Sorry. Yeah. It's an individual Jonathan's getting in the queue because I'm I think it's actually might even be more complicated than that. Because, like, for dependency descriptor you want to have the start and end flag set properly for the outer packets. Even though inter packet will have both starting on the set because it's a single back at, you know, single large packet per frame, So This might be you might actually need to be different. That would be hard. But, yeah, mo mostly for certain end flags for things, but lots of things have certain artifacts. And you want those to be correct for the outer packets. Mozanati, you have a similar problem here again as payload types. Because the header extensions are also negotiated."
  },
  {
    "startTime": "01:18:04",
    "text": "Hop by hop in MSTP. And so you're gonna have potentially different header extension IDs have to get remapped, to be meaningful to the, to the endpoint. The NDA endpoints. So whatever solution you pick for a payload type, you may have to mirror for the for the header extension remappings Oh, Those are slightly different because they're not within the encrypted portion, sauce, I just wanted echo more, like, the the idea with work, I'm not saying that we should do anything like that or but the the alternate payload header was inserted it's called inner inner inner header wasn't, inserted so that it can go end to end, and and that was used to kind of fill in the things that we don't want to be negotiated, or that would be be used in computing either Nuance or anything for that. Mean, I think this isn't the the inter codec does we don't have the header extensions in the encrypted context. It's just a matter of how do you transfer them from the virtual from the conceptual you know, Peter, Bob, a conceptual packet to the actual on the wire packets. You know, done so. Yeah. Right. But I I would like to ask, most had something about how There was a solution for this in Perk or not not the header extensions, but for the payload type, how is that done. With the the the other payload type. Was that done with the header extension or I'm also gonna say sorry it's been several years. I hope is not too rusty, but I think we'd flip flop back and forth"
  },
  {
    "startTime": "01:20:01",
    "text": "several times between header extensions And payload, headers. And I think we think we arrived on header extensions at the end so there was a header extension for the OHB, I think, or something like that. The outer header block or something. Yeah. And it and it went it was a header extension that then defined things that were different from the original packet so that you knew that this packet originated with these other RTP fields, to be header fields, instead of what's in the current art to be header. Gotcha. Okay. We'll include that info in the get hip issue that'll make. Looks like I'm out of time, Thanks for all the feedback And just the other thing, the S frame core document is in working group, best call in the S frame group. So please people, if you're interested in this, please review that to make sure it's right and does the right thing for what we're trying to do here. Alright. Visual volumetric. Yeah. Thank you, Mister Jake. Can you hear me? Yes. Yes. Yeah. Thank you. So, So we published the new draft version of the report and, region of dependent area of visual volumetric media on 25th September. We majorly addressed the commands received in earlier, for inter meeting. So I'll go through the, the updates in this current version. So the main the syntax and semantic of the special region and the report basically are aligned with the cations at the gate time mpaguay part 5. The recorded representation of P3C data. And then also with mpaguide part 10 andmpaguide part 7, which is basically the"
  },
  {
    "startTime": "01:22:00",
    "text": "MP guy, employee must submit your metadata specification. And then, we added the definitions for the coordinate systems you provided and to field a few some of the nominations that we used And then also we clarified in the drag the the draft that the origin point and the size of the special agent are defined in terms of volumetric pixels. Some of the comments that see that here. And also the 3 d special region origin and size formats are find, basically, the anchor point is 32 bit signed in teacher. And the size is the an Einstein interior. And all the 4 the 4 byte values origin sizes are basically expressed in the beginning format. And the the other changes were basically on the viewport feedback control information, which is basically updated to align with the vacation. So it now represents, presence of intrinsic and extrinsic camera parameters information in the FCA messages based on some on the flags that were different and it also indicates the the horizontal and they have particular field of you or same or different and other other countries and other considerations. And then we added the security considerations and it Anna considerations, to the draft. So we propose to add the attributes such as, like, a 3dregens the STP parameters and RCP feedback type parameters such as static 3 regions, arbitrary, special region, and the 3 d view ports and also some of the feedback messages, types for special region and the viewpoint. And, also, we defined the RTC RTP header extensions. So the URLs are also defined for transmitted. Static 3 d regions, arbitrary special regions, and the dynamic special region."
  },
  {
    "startTime": "01:24:02",
    "text": "We also added some fences and, and some editorial, enter fixes in the draft. Yeah. So can you go to the next slide? So mostly we, we addressed all the comments that we received in the earlier meetings. Any suggestions or feedbacks are always welcome for our draft and and we can for the suggestions. So that's what basically as of now, we are we are in that state. If we yep. Yeah. No. I think, Yeah. It sounds so it sounds like this is ready for an adoption call. So, if you if you let me know if you think that It sounds like it is. So I guess we can if you if you think that's ready, the chairs can take an action to to, drop some calls. Sure. Yeah. That's what actually we feel like because if you don't have any further suggestions and feedback, yes, we would, right to go from working group adoption. So right now, it is in the individual draft status. You can go to the IIT work draft status. Oh, yeah. So we'll do that call on my desk, but I don't see anybody objecting here. So that sounds like should be the next step. Thank you. Thank you, Mister Great. Great. Somebody else you're gonna do adoption Yeah. Okay. So now haptics Can we reset the timer for 10 minutes? I'm doing that. Hello?"
  },
  {
    "startTime": "01:26:04",
    "text": "I'm Hix Yang. Today, I'm a president about RT payload for haptics. Next slide. Yeah. So Okay. So I will explain briefly about the haptic. So, haptic can be defined as our tech lines that deliver have to get back to the users here that kinds of tactile feedback generated by the electronic devices. So bivra tactile feedback, and the first feedback are mostly common modality for happy today. And in the haptic specification, it it defined and raised 14 modality for haptic But I think the EDU would be It is expected to it is expected more will be implemented as tech technical independence. And the haptic can be used between the human and the haptic interfaces. And or the virtual model for the communications And, have or so haptic can be used along with audio and the video, And the one of the one of the representative device is HMD head mounted display. But the mobile phone or the game devices are so one of the example of the bices, Next slide. So this is a background of the haptic standard, we are participating the development of the MPAC standard for haptics, So in the phase 1, it defined the haptic data structures, data component, and"
  },
  {
    "startTime": "01:28:03",
    "text": "some parameter for haptics. So is it going to move to the final draft, the instruction is tender, around the January 2024. Next year. And, the ISO's 10 dot would be complete teeth, Bye. End of the next year. So And then the haptic phase 2 or, discussion of the haptic phase too, or so having started with a new topic such as haptic inter interaction avatars, XR, or and the scene descriptions. The next place. So In the haptic specification, it defined M IHS. So M IHS unit are the unit of the streaming defined in MPAC haptic code extender. So I think it's very similar to the noun unit in the video. But, so and the functioner is almost same. But in the haptic, you define the new name. For the haptic streaming format. So it has 4 type of web matches. You need one is the initializing unit And it includes the timing information and the metadata So it can be used to set up the timing or change the timing. Next one is temporary unit. A temporary unit include have to impact that barrier over time. Suppression unit or, so, include a haptic effect, which do not vary continuously. And the last one is slight, silent unit it can be used to notify the haptic silence period So it NIH has a 4 type and the MIH has comprised MIS uni header and the multi pool MIS packet X Lite."
  },
  {
    "startTime": "01:30:07",
    "text": "So for the API, we define this, 3 parameter And now with the we define the structure for the IT payload header, So first one is dependency. That we call it the d, the the indicator whether the packet containing the payload is a sync, pick it or not, And the unit type is indicates the type of the packet contained in the RT payload and either. So represent, transmission method, such as aggregation or recommendations. And the l means the MIS layer So MIS unit layer set by the sender based on application festing need, So based on that center or receiver can decide which packet should we manage the more prioritized at a next slide. So this is the example of the essay parameter. I think the most of the thing is same, but we defined the new soft tie hampg is it is defined by the, ethics specification And then, other thing is almost same as the, the general SDP parameter Next slide. I could actually add one comment. Got a lot of access and individual. I believe that this will also require registering the m equals haptics for the s for the STP registry as well. Yeah. Okay. Great. The next slide, please. Yeah. So I this is a the this directly is the first step to describe the IP payload format for happy coatings, standard, And, our reference opportunity implementation is available for the encoder and the decoders."
  },
  {
    "startTime": "01:32:02",
    "text": "And we developed in a in house implementation of the art gallery format, for future interrupt taskings. And so I think we are looking for people interested in the reviewing, implement thing or the participant, the draft, And And then, like I mentioned before, the coding standard is nearly coupling complicate, So we need to follow it and then adapt the draft if need to be and then the to solve the the problem to access the standard, MPX standard documents, So we can ask the Ampek to make some information available to the IETF member, Judy, resumed statements. Any questions? Check. You're you're caught. Maybe question comment First of all, I think I think this is interesting. It's nice to see to to see that actually here. I'm curious. There's often many many 4 are working on similar things and gaming and the like have been around. So is Impact the the only entity that has been looking in the into these kind of content format specifications. I think so. Because the rest is proprietary then by whatever Sony or playstations and or whatever. Yeah. You know, you know, always a commercial commission industry and the standard cannot go to the same way But like like the IoT. So maybe I hope we I hope that and specification will be good standard for the industry too."
  },
  {
    "startTime": "01:34:00",
    "text": "Okay. Thanks. Then then just one comment. You had the synchronization bit in your header, have you considered the fact that you might be using the marker bit contained in the RTP header, which is usually a bit left out of, practical uses in, in, in many formats. So I'm just curious whether it could help you save some somewhere, but this is more of comment to think about rather than requiring any instant response. Okay. Thank you. Thank you. Stefan, So to answer your your and I'm aware of at least one effort that's going on naturally. It's at the somewhat different there is of standardizing haptics. It's at a somewhat different level. In the technology sector, though, than than this impact thing. I believe there's also some art Vazie Oprah spec by apple. That It it does, subset, I think, of what what the Epic guys are doing with the difference in tags. So it's it's it's not only Ampek, which is doing that, but Then again, the AMP extenders have some, have some history of, of taking taking over certain technology fields and I'm I'm personally following this a little bit. And if if cortex who are following very closely and and they say it's it's it's probably the best, technology that's currently out in development in this particular field. Thank you. Thing. Round. I don't know all this junk. That's in the discussions in the media man working group for registration of the have the ex top level type we have had at least 4 different efforts of defining haptics type The current draft only references ISO because that's the"
  },
  {
    "startTime": "01:36:01",
    "text": "believed to be the most stable reference. But, we expect the number of vendor types to be registered once the registry is ready. Yeah. Okay. I will consider it and check it. But, I mean, I think just as we have no problem having any number of video codex. We have food have no problem navigating a number of haptics codex that people wanted to find us. So but, I see Okay. Thank you. Okay. So, yeah, so do you think something that we would be ready for adoption, or do we want to Do you wanna develop it further first? Actually, we got some response. In in the email, and I Melanie. So we will update soon. Before the next meeting or the interim meeting. And then What about sharing? Okay. Great. Thank you. Thank you. Stephan did you have something more to You know, this this thing is pretty darn good already. So I've, I would, I don't think the 2 authors have a lot of, experience on how the IPF works. In so far, I I would almost suggest, let them update it and then make an adoption call. Yeah. Okay. We are not operating here in meeting cycles, like the impact people do. So and and that's maybe a misunderstanding, I guess. So Okay. That thing forward. It's good. Thank you. Sounds sounds good. Thank you. Alright. And geometry. Let me reset the timer. Alright. Alright. So this is a very early draft on RTP panel format for geometry based point of compression. Next slide piece, or is this something we work together with, Europe and Turkish? First, a little bit background on front clouds. So front clouds are data structures used to represent three-dimensional data. There are basically a list of, points in three-dimensional space and where each point in this list can be associated with"
  },
  {
    "startTime": "01:38:01",
    "text": "attributes, such as color or reflectance or something else, whatever you want to represent or associate associate with these points. Point lots can be, acquired by lidar devices or radar or multiple camera setups and can, for example, be for representation of, surroundings of a vehicle, or, to make scans of objects for archive purposes or something like that. Next slide, please. So background on this codec, earlier, we have talked about 33 see, I think. And, this is a little bit different because we see we see uses a little bit different technology to, encode three-dimensional data and I think B3C is targeted as at more dense, geometries, whereas GPCC is targeted as more add more, sparse point clouds, such as generated by lighter devices, for example, in vehicles. The codec itself, and codes geometry data and attributes data as 2 separate, parts. The geometry data is encoded first, and the attributes is then afterwards, and the decoding of attributes, depends on the decoding of geometry data. The bit stream of the codec, is uses different types of data units. This could be parameter sets. General parameter sets and parameters lists for geometry and attribute data separately. And then it has different types of data units for geometry data and attribute data, which we mapped to the pilot format later independently. And then there's NXP in the, codec description that describes some type value bitstream format where it basically just type of the data unit and the lengths of the following data unit and then the value. We defined a very simple pilot format, next slide please."
  },
  {
    "startTime": "01:40:01",
    "text": "For this building on this type links value, and and and and coding, but only or kind of adapted it to, to the petite from it. We used a very standard RTP header usage with the timestamp defined the earliest sampling time of the point cloud frame. They could be different sampling times for different points. In one frame, but since the QPCC, specification uses the notion of point cloud frames. We also use this notion and say the oldest one of that is used as the some some time stamp. And for now, we settle we say in the document that we must use 90 k kilohertz, frame rate for for that, or frequency for the timestamp. The payload header, is then only one byte following the, RTP header and the payload header basically consists of 2 fields. 1 is the or the first one is the field describing whether this one is a single unit and aggregation unit or part of a fragmentation units. And then for fragmentation units, whether it's start of the end of it or the middle part. And then the second type field in the payload header is, the unit type of the data unit that's contained in that RTP packet And then since we don't need the length field from the table length value encoding for single and, fragmentation units we included the links field only for the aggregation unit following the one byte payload header. To indicate the lengths of each following, data unit in the packet, and then we have for the next one, the following data unit in the same aggregation unit. Again payload header with the one byte and Next field. Alright. Next slide, please. Would you find some sing simple signaling for the first version, which, lose a profile and level ID for the"
  },
  {
    "startTime": "01:42:00",
    "text": "Kodak. And then we define some, parameters for signaling things like the resolution, of the The coverage of the, field, like, the which part of the environment is cover it, for example, that this could be defined as the field of view, of a sensor, And we have an anchor point defined in the signaling that describes, like, one anchor point and 1 screen of fine clouds, that could be used to relate multiple point clouds together. Then we have an orientation and position of the sensor and then we can also signal the attributes that are associated with single points in the point cloud. In the stream of fund reference. Yeah, think that's all for today, Magnus. So are So none of these are gonna be time sensitive that they will they wouldn't contact that hammock, I would say. It was changed over time. Like the so the current, what you're saying is you're creating an RTP payroll form for something where to view of a set of polling clouds. The polling clouds position in space is not changing over time. Yes, for this one. We were also thinking about how to signal this in, like, if it changes over time, like, we can't do this in I guess, but, maybe something like a header extensions or RCCP feedback to request some some of these the receiver side could be thought of in the future, I think, but that's not in the graph yet. Okay. Yeah. Just to add on that, actually, Srivast? you know, the the the friends"
  },
  {
    "startTime": "01:44:00",
    "text": "or or do change over time. So we we can can either have single frame of data per one point roll, or it can be changing over time as the GPCs supports both of them. And we also have, like, part 18, the specification that talks about the carriage of geometry data, which supports both time and on time to take out the GPCC frames. Courtesy successive frames. Okay. John Black side. So this is a marked as a video Correct. I mean, what is the top left? What is the mind pipe you're using for this? I think the graph currently has application the application. Alright. It's redisc rediscussed Sorry? So we we discussed this in our group. We were thinking about video application, resettled for application for now. If they're good arguments, something else, then I think we can talk about that, of course. Alright. The magnets? Or I guess you have other Okay. Yeah. Sorry. I was trying to pass, are you still in queue, or did you not un queue yourself? If not, Spencer? Sorry. Thank thank you. This this was just my, opportunity to to ask people to take a look at what you said and make sure that it it was captured correctly in the notes. I've been I've been, helping with the notes, but, and, yeah, but I mean, like multiple people were taking things and they're still taking those, and there's still some questions. So that's just for the group, for the, entire session. Right. Okay. So, my name is Lester. Yeah. I mean, when it comes to media type, it's an interesting, but I guess They're also similar. This is like"
  },
  {
    "startTime": "01:46:03",
    "text": "motionary picking and things like that. It's time sequence snapshots. Of of the point cloud. So, I guess, video could work, but Yep. Application, I guess, is is So Do we have any application slash RGP formats. I don't think mean, there's nothing We had proposals in that space, but, I mean, the game event was in there. I picked the earlier some of the for other binary object like things for me, but, yeah, I mean, yeah. I think that's the same thing. But it it sounds like you have to think about how we're gonna do this dynamic update if you actually writer of pretest and video with and get the encoding inside the payload format for each frame in in when they are updated, etcetera, when the boundaries of it and coverage. Yep. True. Thanks. So, Alright. Is that to do what what do you say think about the status of this to So if need more work, or is this it's an early draft. I think it definitely needs more work. Okay. So, Keep working on is that just FYI. Okay. Great. Cool. Alright. Thanks. Alright. Thank you. And was that I think that might have been everything. Yes. Alright. Do we have any other business people wanna mention? Yeah. I just thought we could just clarify what next steps we need to do based on all of the craft suite. Just went through. Mhmm. That's a good plan. Wanna let's see. How do I get to the note taking tool now. Let's see. So I think one thing was to summarize the working group last call for the B3C. Mhmm. Which just finished, like,"
  },
  {
    "startTime": "01:48:01",
    "text": "2 hours ago. So I will do that Great. Action item to do that. Think we have but but 1 or 2 calls for adoption we're supposed to do now. I think so. Yeah. Certainly, Okay. Yeah. So the But it looks like the options are gonna do a revision of haptics and then make sure all we do is call for adoption on that. And I will do a ready for call for adoption non visual volumetric. So, yes, and then Let's see. Some of the other draft authors have actions to take. Bernardo, you're gonna work with him on skip. Right? And I think was that So I was looking for the notes. You know, we're we're just repeating authority in the notes. So But, Yeah. Vv3c Bernardo's going to go over, basically basically summarize the WGLC. And, you know, Sounds like it's just editorial changes that need to be made. And Okay. Yeah. I think that's I think that's everything. Okay? Alright. Well, thank you, everybody. And we'll Given we've seen to have been having success having interims in this group. So we'll probably have one Sometime before the next meeting, Bernard and I will talk about that. Yep. Yep. I guess probably after the holidays, January, I should suspect. Right. Okay. Yeah. Yeah. Okay. Will talk about that and talk about a little Thank you all. This was super helpful as usual. Okay. Thank you."
  },
  {
    "startTime": "01:50:03",
    "text": "Yeah. It's amazing we got through all of it on time. Thank you everybody. Okay. Great. Yeah. I think I think every everything else was already basically, I was just looking over the notes and summarizing what I saw. Yeah. Was"
  }
]
