[
  {
    "startTime": "00:00:31",
    "text": "let\u0027s get started welcome to the Seaboard working group meeting you\u0027re not this is not your destination please leave please no the note well you\u0027ve seen this several times now but if you haven\u0027t take a moment to read it through just a reminder that minutes are taken this meeting is recorded at presence is logged there are blue sheets we would need volunteers for the minutes can someone volunteer to take minutes minute taker Thank You Christian and can someone check the jabber okay thank you okay I can I can take a look at the jabber if there\u0027s anything this is the agenda for today so we are at the introduction we the chairs will give a short status update of CDL and then Kirsten will present the rest of the documents yeah see board base and array tag and then we will have a discussion about the next steps for this working group anything anyone wants to add to this agenda or looks fine so cyber working group status update first of all we have a new co-chair thank you Jim for taking the role and Thank You Barry for the service we had 16 dreams since IETF 103 they were I think very useful you can see all the minutes and minutes and in slides when the when there were in the sea board meetings data track in the data tracker so take a look at that about the 70 49 base we\u0027re now at version 5 it was submitted in January 2019 but a lot has happened in the key table since so you can see the dip there and I hope we can address the leftover issues today in car stands presentation about the seaboard rate tag the working group last call ended a couple of days ago or one week ago there were some reviews posted also we will discuss race points if there is any controversy and then Carson should meet an update CDL congratulations so it\u0027s now in RFC "
  },
  {
    "startTime": "00:03:33",
    "text": "atat√ºrk you so good to know it\u0027s in cluster 325 so this is unblocking number of documents in anima that\u0027s great so just a for you information there were two version published so version seven it was published to answer discuss and then version eight was published to answer some comments that were leftovers so that\u0027s it I haven\u0027t counted how many how many version that is actually I think it\u0027s 19 but yeah congratulations so casting you can come and take over now yeah so usually when when work is done that is exactly the time when you start thinking about what what\u0027s up next so let\u0027s talk about severe once more so I made another one of those slides we already had some discussion both at ITF one or two and ITF 103 about what the next steps in the evolution of that specification might be I don\u0027t think we want to repeat that discussion today but if you do have an idea that is not on the slides of 102 or 103 please send a message to the Magnus if you are sitting there writing a CDL specification and are bothered by something please make that known because we do want to evolve the specification to make it easier to use make it even easier now there are a few questions that came up at this meeting and and the first one was how do you actually pronounce it idea and about half of the people say CDL and the other half say cuddle and I think we as a working group should have an opinion on what what we actually want to say I mean some of you will know about the small computer systems interface that nobody knows as SCSI but everybody knows that scuzzy so there are some abbreviations that really are in the minds of people in in a pronounceable way and we have to find out whether we want to pronounceable abbreviation and whether cuddle is the one we want if you know what the history of scuzzy that actually entered "
  },
  {
    "startTime": "00:06:34",
    "text": "the committee being pronounced sexy but in in the prudish USA of the 80s that wasn\u0027t possible so it became scuzzy after a short while and yeah I\u0027m not sure about the cultural sensitivities here so I don\u0027t know whether cattle is actually acceptable in in all the the jurisdictions we are trying to reach here so does anybody except me have an opinion on this what are you saying who\u0027s saying cattle who\u0027s saying City [Laughter] now of course you you don\u0027t have to have a single pronunciation so for instance an ASO on object ID is often called a s and one or jiggidy and it\u0027s often called voyage so yeah I don\u0027t know so maybe we can leave that open but maybe you can also keep this in mind and build an opinion and if that has ripened please send it to the meetings one other observation that came up in in one working group that was working with CDA was where are the CD VA doctors so we have SNMP doctors we have chanted well hang from hosts calling them huddle fairies because that\u0027s maybe better but generally the the objective of course is to have CD it will be sufficiently accessible that you don\u0027t need a mediator a priest that establishes your line through God but you you actually can do it yourself so maybe we actually making a point out of the fact that there are no CDI doctors but on the other hand maybe some tutor tutoring and coaching is useful and there is this website CDE out of space sitting there that that is now ripe to be filled and I think maybe I would like to have pointers to a few people who actually are willing to be tutors and coaches in this space Jeffrey this is Jeffrey askin I I think that it it will be useful to have this this kind of advice available your point that it\u0027s intended to be kind of self explanatory I mean it\u0027s it\u0027s pretty close but I think some of the matching algorithm is is less obvious than then would be needed in order to be completely self explanatory so it\u0027ll be it\u0027ll be useful to have these people even things that are self explanatory don\u0027t always arrive "
  },
  {
    "startTime": "00:09:37",
    "text": "at the recipient I mean sometimes so yesterday we had the this brief discussion how do I write down my key map in severe so there is a idiom for that and and maybe just putting it somewhere and Pawnee people this is the way we write our logic that\u0027s that\u0027s something useful so if you are interested to be on this page I don\u0027t know with you of your own advice or just with your name please contact me after the meeting okay I think that\u0027s all I have on Cydia now the syllabus part I think the the major advance we have made in the last couple of months is that we now have a pretty well understood separation between three levels of errors two of which are at the CEO level and one is at the application level don\u0027t think we have a very good term fall for the application level yet I have used the term expected because that that turn in some discussion but maybe we need a better term for that but the idea is that there are syntax errors which make something not well formed and generally in the Siebel space that means you are not continuing and Appendix C contains the the wavy lines of code to do this well from this check and then second we have validity which is on the semantic level validity errors do not stop the possibility of presenting something through the application but it might come to the application in a much less durable form than the invalid stuff so if you have a tag true with a text string in it that\u0027s not something the the the decoder can just process into your bignum it\u0027s definitely a reality error now whether the application wants to do something with that or not depends maybe on a discussion that we still have to have and the third level is things that are just fine from the zero point of view but may be a problem for the application because the application is actually expecting data in a certain shape or with certain semantics and that\u0027s where we\u0027re CDL might come in or yang or some some other modeling language or it\u0027s just defined in in text so these errors exist and the reason why it\u0027s it\u0027s a good idea to talk about them "
  },
  {
    "startTime": "00:12:37",
    "text": "in the spec is that it\u0027s rarely useful to just think about well fondness and validity at the CEO level that there is a particular with validity there is a gray area that really only can be disambiguated by the application and the first example of there the tripped us up for the last five years was the integer versus floating-point thing we originally the intention was to integrate these two spaces as much as they are in JSON and it turned out that that implementers didn\u0027t really want to do this at all so we are now moving to keeping them separate at the generic SIBO level but your application might still do that in particular if it\u0027s a JavaScript based application then it\u0027s much easier for the application to throw all numbers into one bin so that again opens some validity questions so imagine that you have a tag that only takes floating-point numbers you cannot even write that down in JavaScript because some numbers are integer by nature I mean unless you write them down as floating-point they will be converted into something that actually is integer so I think we made some progress here and I definitely did not understand these three levels when we wrote down our c70 49 so I think that that significant progress we have made in this working so number 17 which is Jeffrey\u0027s pour request that does most of the work of getting this distinction in is mostly integrated so I don\u0027t know Jeff do you want to rebase this one small it\u0027s very asking a little bit much but so I took most of your changes but some of these shows I polished slightly which is why there are so many merge conflicts now and the items they didn\u0027t integrate yet delete redundant text and it\u0027s just very tedious to check that all that redundant text is already covered in different places so this is just a to do an editorial to to do that needs to be done but I don\u0027t think we have a technical issue with number 17 at the moment we do have a slightly wobbly definition of Street so the diffusion of strict was done before we did the work of defining the preferred encoding and actually the preferred encoding still requires some editorial changes as well but yeah as usual there is an application content to this you cannot entirely do strict "
  },
  {
    "startTime": "00:15:39",
    "text": "decoding on the generic Zeebo level and again the same thing happens when you have a decoder that is checking deterministic encoding so generic SIBO decoder can check it a monistic encoding at the CEO level but not at the application and level so there always will be an application component to a deterministic checking decoder does anyone have a slightly less this is Jeffery askin I think Lawrence one blade suggested in his email that we might just remove strip decoder and I I like that idea I haven\u0027t double checked that it that it works but the the use that I can see for restrict decoder is in an application or in a protocol definition or an application spec you would say like the decoder must be a strict decoder and I don\u0027t think there\u0027s anything I don\u0027t think that means enough beyond like the decoder must reject you invalid input like I think I think we should just say that you could or must reject invalid input and that that covers everything that strict decoder might cover and so it\u0027s it\u0027s unnecessary okay well I don\u0027t have the text in front of me but I seem to remember that it actually was about preferred encoding as well Jeffery asking again there there is also I don\u0027t think that strict decoder currently requires the preferred encoding but it might but we can also say that in an application spec like the the encoding must be the preferred encoding so we would say it must reject invalid input and must reject non-preferred or non-deterministic encodings and that that is clearer than saying strictmode unless we I mean we could define strictmode as that but that would be a very short section and in that case it would be fine yeah so so maybe we should have this single paragraph somewhere that says encoders may want to be preferred checking and in photos may want to be deterministic checking and get rid of the stretch saying otherwise Lawrence time plate so I was just looking at strict mode and it does talk about deterministic but it\u0027s not sharp about it it also says a lot about rejecting invalid see war so I went through all of the Seaboard defined in this to see what could be interpreted as invalid or not I found but about 18 instances of things that from simple things like is the day an epic based date that you gave me a B string right that\u0027s easy you\u0027ve also got an example of a utf-8 "
  },
  {
    "startTime": "00:18:41",
    "text": "string which is very hard to check for and then if you really if you really extend the model I mean you should have a mime parser and you should be because if you have something that\u0027s tagged as mime yes yeah you should invalid and it\u0027s got invalid mime it\u0027s invalid right yeah so the set of What\u0027s in valid and invalid is it very expensive to compute and could be very highly variable from one implementation to another so I\u0027m yeah yeah and it\u0027s it\u0027s extensible so that notion of valid and invalid it seems really problematic and and strictmode definitely is around oriented around valid and invalid strictmode also seems to have this thing about a firewall functionality and security characteristics which yeah we told that don\u0027t already I think that is fixed I\u0027m not happy but I think it needs to go so I guess I\u0027m still I\u0027m just advocating maybe strictmode going away yeah a mode where you check some things for validity and not other things where it\u0027s really undefined that seems like not like a mode that\u0027s just a collection of things you can check for or not check for and it\u0027s definitely we are not going to expect encoder or decoder x\u0027 to check for all of those things it\u0027s just that does not make sense to me because some of those are so expensive and they make more sense being checked at the next layer up right well so strict mode as a way to check for valid and invalid I that I I think it\u0027s not a good idea I\u0027d like that to see that go away strict mode as something that for deterministic I I\u0027d have to think about that one a little bit more I\u0027m not sure I wasn\u0027t the way I was thinking about it so so one thing a strict mode decoder could do and and I think this is the only religion thing that happens outside of tags is the non duplication of map keys now that is interesting again because whether a map he really is duplicate or not may depend on your application and so it\u0027s again something that a generic decoder can only do to a certain extent utf-8 checking is also outside of tags but this is Jeffery askin I my mental model has two kinds of decoders there\u0027s generic decoders and protocol decoders and I think it is it\u0027s totally unreasonable to ask a generic decoder to check tag validity for for several of the reasons Laurence mentioned but a protocol decoder has many fewer like the protocol has defined "
  },
  {
    "startTime": "00:21:41",
    "text": "the set of tags that uses your sum and and those decoders should be able to check for validity and I think that\u0027s where it that\u0027s where it makes sense to use must must not be invalid as as a part of the specification that\u0027s a great conclusion for the next five slides I have [Laughter] so really the the per request that was most difficult for me to integrate was the technology one from Jeffrey so the clarifications are good but I think before we do that we should think about the direction taken by 1749 here so each tag defines its own validity requirements based on the state of the universe at the time it was defined and the the problem really is that the state of the universe actually changes and so one example might be Chang one that everybody knows that takes an integer or a floating point where you we have a few more numbers in in Siebel and for instance we should have you find tag one to take decimal as well but we didn\u0027t so then we had two environmental one to do that and to me that sounds pretty onerous or take 36 is defined as taking utf-8 and of course there are my messages that are binary encoded so we now have 257 for those and that seems to be a recurring theme that we don\u0027t get the tank validity quite right and really mean something different then what we actually write so the the idea was that take 36 actually is a valid my message but the idea really wasn\u0027t that it only addresses duty ever ugh coded once so let me just propose two models using some some terms I borrowed from the political space so you can define technology in a reactionary way which means you write something down and then you spend the next 200 years trying to interpret what the founders meant so a tag is defined at the time it is defined with a certain set of sub structures that are acceptable so for instance take one was defined to only allow integer or floating-point numbers as its tag value and a new sub structure in this model can never exceed to an existing tag so I cannot defined a new "
  },
  {
    "startTime": "00:24:42",
    "text": "tag and say either way this tag here do you find something that is really useful as a part of tag one because it\u0027s tag one that defines what can be in it and not the thing that you can put into a tag one that you find that so the good thing about the reactionary approach is it gives very little ambiguity about tag validity even at the generic level but as Jeffrey already has said technology is really more interesting at the application level and the application might be quite happy to accept a new type sub structure in that check let me just quickly explain the other one the progressive technology works by having the tag defined with some abstract semantics so for instance take one could have said any real number can be a tank value and this makes clear a byte string doesn\u0027t cut it because it\u0027s not a real number but if I do find a new tag that that also provides a real number that can be immediately used in tag 1 so and any sub structure that fulfills the abstract semantics will do and now I have the opportunity when I define a new tag to say this is actually useful as the tag value of those and those existing tags this doesn\u0027t mean that all possible combinations will always be hit but it makes it more likely that if a tag is defined new tag is defined the relationship to existing tags actually examined and people write up what combinations work and what don\u0027t so for instance take another example attacking the extracting an array of numbers currently would look explicitly for major type for and now we could say well it\u0027s taking the array of numbers and so it can take a touch right this is Jeffrey askin I really like progressive tech malignity I think I think to decide whether whether it works we have to think about what what it is we use tech like why do we use tags in in any particular protocol you could just define the structure of the data and and say like we interpret the like the array of numbers as as or sorry this byte string as a typed array and and not tag it and the protocol parser will understand that fine I think the benefit of tags is is for kind of debuggers and and things that turn something into a human readable form you know in a fairly generic way without without needing to know the protocol that\u0027s embedded in and so those will get broken by by new "
  },
  {
    "startTime": "00:27:44",
    "text": "things that go in tags until they get updated to support the new thing and so and so I think as long as as long as we\u0027re always defining the structures in in specs those those debuggers will be able to keep up it does mean I think it it effects section for the the guidelines for writing protocols just because you can no longer say such-and-such must be a valid instance of this tag you have to say what it is allowed to contain for the purpose of this particular protocol so you raised one one very scary Spectras there I don\u0027t know if you noticed that so when when I compose my application out of various pieces of software I want to use a generic decoder and I want to write an application code and a situation where I would have to wait for the generic decoder to accept a certain new tag combination so I can write my application that would be bad but if we say it\u0027s actually the job of the the generic decoder to deliver tag combinations it doesn\u0027t understand as is to the application we are not running into this deep liability problem I think that\u0027s one thing we have to make very hey Shawn Leonard I also agree with preferring progressive tag validity for similar reasons and treating as you said cases where a generic decoder doesn\u0027t understand the particular cat tag combination with the data is being novel as not treating as a fatal parsing or decoding error but allowing some of that to go up to the application so that can make a decision on how to process that so applications can polyfill I guess right the the lack of the lack of capability of the generic decoder and also I think that would allow us to keep a smaller set of more universally applicable tags right which i think is actually very important for me for the my message case that\u0027s important for some of the applications that I use and I would much rather just use one tag for my messages then you know two tags or eventually have having to recognize huge quantities of tags that do the same thing right just for different types of data Brendan Morin I think the progressive tag validity is begging for vast quantities of compatibility failures especially in the area of IOT devices where they will not necessarily be updated to handle new tags this are new interpretations of a tag this is going I mean the the tag one taking any number in our if you were to build a firmware update system for example that requires a timestamp for validity and the the "
  },
  {
    "startTime": "00:30:47",
    "text": "very data structure that\u0027s delivering the update to handling the test eggs can\u0027t understand the tag it\u0027s been handled you\u0027re going to wind up with problems so I think that this is it\u0027s a great idea semantically it\u0027s a great I approach to reducing the number of tags but I don\u0027t think that it\u0027s gonna play out very well in practice I think there\u0027s gonna be a lot of compatibility fillings so right now when you look at the time stamps and insert do you see anything about they are completely untagged for this exact reason yes okay but you say they are integers oh they have their integers yeah yeah so the you did the right thing the application protocol made a decision yes but the point is if I have to make that decision and the tags aren\u0027t helping yes and no so again there are two reasons why when a tag could be helping one is the the reason that Jeffrey said there are diagnostic debugging tools those are actually enabled by having safety scrubbing information like things in the structures and the other place where it takes actually extremely useful is if you want to define your protocol in such a way to enable extensibility and I use that as an extension I understand the goal I understand the approach that\u0027s being taken here but I also see that in a world of in frequently updated devices if these are used in any place that is critical they will cause a critical failure yeah but only if the educational didn\u0027t do their job this is Jeffrey Gaskin I think we can expect application developers to not do their job in some cases but the point I wanted to make was that tags I think are not are not for the benefit of protocol designers they they don\u0027t help with with kind of defining what what data your your application must accept i I don\u0027t fully understand the use case about extensibility points but I don\u0027t know that we need to go into that in this meeting but the the use for for diagnostic tools I did realize one one thing that that I\u0027m worried about which is that you\u0027re you\u0027re sending tag to data to to an application that expects say you take tag one that expects integers or your your protocol expects integers and your diagnostic tool renders any number as as a timestamp and so you you kind of are inspecting data you see a time you think it\u0027s good but it\u0027s actually the wrong kind of time and so your application breaks and you can\u0027t see why in the diagnostic tool so I\u0027m I\u0027m not sure if "
  },
  {
    "startTime": "00:33:47",
    "text": "that is kind of if the downsides are enough to convince me progressive technology is not a good idea but like there\u0027s there\u0027s definitely trade-offs which we should think about and and probably discuss on the mailing list yeah it\u0027s a sharp instrument so you have to handle it with some care you know Laurens done like one thing I saw tagging is useful for was knowing how to translate or how a generic encoder would translate or represent in in the native representation so if it knows it\u0027s a date it can the a generic decoder can put it in the date representation that\u0027s most appropriate for it for that you know platform and programming environment so that seems like a beautiful thing and a convenient thing and it makes generic decoders easier to use right so let me just give a number of examples one example is I have a place in my protocol where I can accept any integer number now if I can represent that in 64 bits I\u0027m using major tribe 0 and 1 if I need one and 64 bits I use take two and three so in that case the tag actually is part of the set of SIBO tribes that that create the space of integers so that\u0027s one example of using tags I have different types of things they are all acceptable to my application at this place and I\u0027m using eggs to represent some of them then we have places like like in Yangtze bar where we use tags to identify certain pieces of information as a little bit different than it normally would be so if you do a new engine of enumerations in in Yangtze bar you sometimes have to tag things within this Union of enumerations because yang is slightly weird and has different ways of interpreting that so that\u0027s an application function that is entirely about tagging things so a tag is quite appropriate but it\u0027s really the application it\u0027s not something a generic decoder would understand or support the first example I had a generic decoder in any programming language that has a large integer of space we\u0027ll do that for you so you will never see it in the application the second example always has to handle we handled by the application and that is also a way to provide extension points in in your application by saying this can be a number of things and then you later come in and say oh it can be that thing as well Jim Chad individual I think that you "
  },
  {
    "startTime": "00:36:47",
    "text": "also need to look at the opposite side of this issue which is the generic encoder all of a sudden is a real pain to think about because the application now needs to say generic encoder you can use this set of things but not that set of things and that\u0027s actually potentially more problematic than the decoder off we have the problem with floating point numbers already so yes that\u0027s painful um a couple of questions I supposed to hide eyes that you could use one or the other mode it\u0027s not you can choose based on your application whether you do progressive or or strict mode is that the case I have a slide cuz I mean I kind of share what Brendan was saying some applications we run into a lot of issues okay so there are put two parts of this one is what do we actually do about the the tags we have I mean we can we can enable progressive validity for for new tags but we have some tags that say only use this with something so we have to decide whether we actually open up those tags or stick with reactionary validity and in the end you\u0027re right the application makes the call so but as Jim said now we are making the interface between the generic encoder and the application significantly more more complicated because you now need to be able to pair the generic encoder use this tag but you don\u0027t use the other track okay another question on the semantic interoperability no that\u0027s a word you used in the previous slide who gets to choose if this abstract semantics or how do you define let\u0027s say set a number now it\u0027s a string that has 42 is that compatible or not or how would you go about on defining that we remember so so it\u0027s only so is there existing rules that you have here that were it what are compatible what or not no so when you actually define a tag you would say what what can go in them if any a times but not by by prescribing specific structural features of what can go in there but by defining it at the semantic level and you are asking are we using to do DT you come for that was more "
  },
  {
    "startTime": "00:39:47",
    "text": "thinking like you know do what do I know if I define an attack how do I describe an action level like maps to something on the wire what what do does fulfill the absurd semantics how maybe I have to have a closer look and and see how to work out yeah so the the weird part is that the progressive approach actually creates something like like a type system and so the idea is that a new tank definition should document both what it expects from the tech value and what it actually creates what it exposes to the application or to the next tag around it and we don\u0027t have a formal system for that I think that\u0027s really what you were trying to say yeah I\u0027m not sure we have to invent it right on the spot here that might be something we want to do at some point so at some point something like CDL we\u0027ll want to learn semantics as well so that may be the place where we actually introduce such a type system jeffrey askin the the data model section kind of anticipates that tags will define new types i think i\u0027m comfortable with the idea of doing it in an ad hoc way for a while obviously we\u0027re going to get it wrong as we as we learn how to do it but it shouldn\u0027t be worse than what we have now thank you okay so if we go all the way on the progressive scale we would allow the application to define its expectedness within tags so we would allow the application to say Oh 36 really only was defined for utf-8 but I I kind of know what my message in binary encoding is so this is a little bit the extreme case of this but it would allow us to kind of reclaim 36 and say okay that that was a mistake only allowing text encoded my messages we are adding in binary later this creates a little bit of instability so I think I have heard that we don\u0027t really want to do this which doesn\u0027t mean that "
  },
  {
    "startTime": "00:42:48",
    "text": "we don\u0027t want to apply 18 but we want may want to put 18 into a context that then it\u0027s clear that\u0027s kind of the default validity until the application says something different and what we probably want to do we want to explore this progressive tag validity a little bit and yeah this is an Internet standard so saying we are going to do this in a fashion for a while is kind of weird but I think that\u0027s what essentially applications already have been doing in one form or another so I\u0027m not sure that we are actually changing a lot we are making things explicit that that people already have been doing so I would be comfortable with doing this but of course the the is she might not be Jeffrey askin I think progressive tag validity is pretty experimental and I think I\u0027m uncomfortable saying putting it in in a document we want to call an Internet standard hmm I would be totally fine pulling the tag definitions out to a to another RFC that is that stays in the proposed standard category and publishing it at the same time okay that\u0027s certainly one way of finding this first ed that goes against the better is included idea but there are a few tags that that kind of re needed like they take two and three and this is Jeffrey asking again uh yes so tags two and three perhaps we can we can say those those use the reactionary type and are defined in exactly the way they were in the original standard and are now locked down but like tag one definitely needs to move to the to the other document so so yeah I get I get your point but we maybe should do it anyway okay sounds like takeaway forward Sean Leonard so I just have a question about the big num types why exactly can somebody maybe just elucidate what the controversy is about why they\u0027re reactionary or why anybody wants to extend them because I thought that the byte strings have infinite length I don\u0027t think there is controversy there okay but that also means that there\u0027s no nobody sees a need to extend them or change them in the future all right well that hasn\u0027t surfaced I mean I cannot predict the future but I would find that "
  },
  {
    "startTime": "00:45:50",
    "text": "surprising right all right okay just wanted to just wanted to check because my read of 70 49 was that it wasn\u0027t very apparent that the reactionary approach was the approach taken I thought it was more I wouldn\u0027t exactly say ambiguous but it just wasn\u0027t was it wasn\u0027t it wasn\u0027t contemplating so if you look at the the tags we do you find some of them are really locked down like like two and three and some of which are really so experimental that we got them wrong why do I give them like 36 so my message so I think it\u0027s a good idea to like we did with cozy where we have split the document up between things that are going stand up and things that recycling it proposed differently yeah we don\u0027t have that Liberty we are not security the security area is the only area that can do knowledge of things in information or documents I [Laughter] like see that\u0027s not entirely true so other areas may be able to do informative normative things in information that\u0027s right yeah so I think that\u0027s that\u0027s not the outcome I expected but I think it\u0027s a pretty interesting way and we should try that and see how it looks like and your head with it so should we also continue the discussion in the main in list and custom do you want to suggest a proposal to start with or always start with the meaning based on them so I think that the next step would be to integrate a gene do the split and then see whether we are happy with what we have so that would lead to another draft IETF SIBO or something that you would have to acknowledge so I think it\u0027s much better to do this in the concrete when we have hope that all three something tags and understand whether it\u0027s obvious what you want to do yeah great yeah I think we got to do here on this list I really said we we have some editorial work on the preferred encoding to do and we probably want to base the deterministic encoding on this so it becomes really hard we said we have one minor update to the IANA considerations by the way if you look into the documents related to C "
  },
  {
    "startTime": "00:48:53",
    "text": "bar you find one more tag application that is in the specification required place so it really starts getting probably gobbled up so it\u0027s probably time to actually do this and yeah probably no longer true so we will do the split see whether we are happy and then do one more launch of reviews can you give us an indicative timeline or that you think estimated well we should have the split within April so we still so in like three days with in April end of April then yeah it\u0027s not going to really professor first need to get home and start the term and it\u0027s more like a pretend good there is one more piece of civil housekeeping that I think we should be doing you might have noticed the civil sequence draft so there is something called Jason sequence you want system yeah yes please so I think this my minor probably straightforward one is there\u0027s I found a few things with section on syntax errors that\u0027s the one that mostly gets deleted by the number seventeen I was looking at the the tip yes you know I haven\u0027t integrated the rest of seventeen because I want to check the text that I know it\u0027s not perfect okay and and Geoffrey is proposing to delete it I just want to check whether all the things that are said there I actually already being said at another place then we can even right so I\u0027m not sure yeah this is in progress work the right thing but it\u0027s just done it so most of that is I don\u0027t think he knew that is difficult or controversial the the one thing that I really want to bring up is the sort of secure coding or secure implementation security considerations and strict mode and how will you actually want to approach this the way I would like to see it done "
  },
  {
    "startTime": "00:51:55",
    "text": "that everything to do with decoders implementation in a in a defensive style should be in the security considerations section section 9 and probably nothing else anywhere else in the document it should all be there in section 9 and it should be pretty sharp and to the point you know that there also I\u0027ll see where decoders are really expected to be very defensive stand on their own not to expect any magic firewalls or anything else to help them that every every decoder or generic or protocol specifically stand on its own so I would assume that\u0027s an eternally agreed-upon thing and we should say that yes okay so then strictmode talks about kind of firewall functionality no longer no longer that\u0027s that\u0027s okay that\u0027s that was the part that we took out in the last round but it\u0027s not in the tip of the github yeah it should be maybe I missed this up but it should be okay but the point is that we just said we are going to cut down slick significantly yeah yeah right right and I think the amount of promises that should be in the C or D Conservation\u0027s section about this should be very small yeah probably okay all right so that was the main thing I want to make sure there\u0027s an understanding about how we\u0027re dealing with documenting what decoders expect how defensive decoders are supposed to be okay I think that\u0027s it so one one nice thing that somebody who has an hour to at the end could do is look at the code in Appendix C and find out whether that\u0027s actually you\u0027ve had the defensive enough it\u0027s pseudocode so it\u0027s a bit hard for me to test so you have to translate it into the prover language of your choice yeah I wasn\u0027t too worried about that that\u0027s looking at the tip section 4.7 and all of section 4 about the use of must and sometimes must in section 4 is used to mean you\u0027re out of compliance with the whole protocol sometimes it\u0027s used to say you\u0027re in strict mode or not or you\u0027re here so it seems like it\u0027s used to two different ways in Section four sometimes it\u0027s qualified it sometimes it\u0027s not yep so the problem of those must is that the "
  },
  {
    "startTime": "00:54:56",
    "text": "one must that you\u0027re probably talking about I think there are two in Section four that I left the one actually is a must on the application but which is slightly weird so we have we are placing an owner\u0027s on the designer of a C by application protocol totally designed it in a certain way and we know that do that know where it\u0027s of course we have a lot of implicit musts just from the the way C bar is but this particular must which is about Tector brocation that\u0027s called out explicitly again in Section four that\u0027s that\u0027s the qualified one okay it\u0027s right I don\u0027t know what you mean by qualified if you\u0027re doing preferred serialization then you must do this taking a minute or so but you could be useful so from from the github so section 410 there\u0027s a bunch of musts that if you\u0027re doing deterministic encoding then you must do this bus do this and must add it so those are conditions on what are you doing deterministic and coding or not so that those like yes I would call those us as qualified musts or conditional musts because you may not be doing deterministic encoding but then there\u0027s a there\u0027s another must which is you must not know protocol must rely on tag ordering yes that\u0027s one ordering and that that should not be qualified at all that\u0027s just an absolute yes for SIBO right so so there\u0027s the example of the two kinds of musts yes and it seems awkward and confusing to have to those kinds and musts so maybe putting the duty listing and coding into the section that that really is about creating Sigma based protocols wasn\u0027t so smart sorry what was that well right now if you can scroll up so we can see the table of contents it\u0027s called the table of contents it\u0027s two fingers there\u0027s there\u0027s no one finger scrolling off the table of contents just move them don\u0027t squeeze me it\u0027s completed the wrong way wrong yeah okay so yeah we\u0027re getting rid of this sweet decoding mode reducing it to a paragraph somewhere and then we have this deterministically encoded seaboard "
  },
  {
    "startTime": "00:57:56",
    "text": "section yeah and that\u0027s really part of creating SIBO based protocols section they want to structure this slightly differently this is jeffrey askin um the 4.10 gives a protocol a piece of terminology in order to define itself and so like i think i think it\u0027s in a reasonable place okay but but if someone was confused when reading it then that that\u0027s a counter indication and it would be fine with me to put it kind of in in its own top-level section saying like something about terminology that protocols can use in or that authors can use to define protocols because like the core deterministic encoding requirements are art it\u0027s a term that that you\u0027re supposed to use in another definition and then it\u0027s just defined here using some musts so i could imagine putting out for nine in for 10 and putting them in their own section okay maybe even in front of the existing section of four would that help Lorentz with that answer your yes so so then that means all the musts in section 4 would be non qualified or unconditional they\u0027re really absolute musts yes and then there are some some text at the beginning of intro in section 4 that could be deleted that says some of the things in here are must and some of them are not yep okay and we may not believe it but change good so I ran a hedge with one super house keeping the bike coming up which is the SIBO sequence so jason has adjacent sequence C bar for all intents and purposes also hazard because application protocols already using it but it doesn\u0027t have a media type and it doesn\u0027t have a content format member and this document is mostly a registration document but it also clarifies what what the foreman really is and gives it a name which has civil sequence so if you compare the two documents you will find that the zero sequence document here is about a third of the size of the JSON sequence document which comes from the fact that it\u0027s just much easier to concatenate see board and it is to contribute in SD so we don\u0027t need to record separators who in this room you what the record server it is well I think the two of us are old enough to know if you need to know more about the records operators you can read RFC 20 which by the way I recommend to everyone "
  },
  {
    "startTime": "01:00:56",
    "text": "you may not have known that that exists but it\u0027s actually an internet damage really the other thing is that the JSON sequence actually tries to leverage the [Music] record separator to provide a level of error recovery and I neither really know how to do this for SIBO sequences nor do I think it\u0027s needed we are using CBO sequences and channels that already have some form of integrity protection so yeah if it breaks it breaks so there is no attempt at doing ever recovered yet so I that thing and people already told me yeah right that\u0027s exactly what I need when can I put in a knowledge of reference to this so I would like to find a way to accelerate this it\u0027s not currently in our Charter so plan a would be to find an ad sponsor and Plan B would be to look at the chartering discussion with having 10 minutes and and see whether that is fast yet who is Alex hey where do you think in the whole priority of all the things done in the working group this sits this is modulated it\u0027s a relatively small number of applications that need it it\u0027s a relatively trivial amount of work so that kind of balances Sean Leonard I read the draft I think it\u0027s I think it\u0027s fine and I don\u0027t have a problem with the working group adopting it if if it goes anywhere I think the working group should adopt it that being said I\u0027m just curious what the use cases are because it is sublimely simple but I think that one of the reasons for JSON sequences was there were applications around logging I think where they need to stream you know these sorts of things I\u0027m just curious you know what what is the industry or the demand for C bore sequences Thanks the the one document that was defined before the zero sequences and where we kind of regretted is cinema cinema has a streaming mode that is defined in a pretty weird way and with SIBO sequences we could have done this watch and I could imagine that other documents are in this situation where it just would be good for them to have CBO sequences as a little brick they can use in building their application so I think John John Watson had one example for "
  },
  {
    "startTime": "01:03:59",
    "text": "using that it\u0027s just a natural thing in in in when you have an environment where you have to send what we call a records of data in CDL and you already have a length available it\u0027s really not necessary to bind this record with an array check this is pretty much what happens there and the advantage is that when this stuff turns up in your streaming way you are have a complete seaboard data item you are not really waiting for the rejector to close and you don\u0027t have to guess at a value for the array check if you want to stay there flat so that\u0027s the reason why I see those sequences make sense so who accept John has read this one Sean Leonard so there is something I think you might want to think about about this draft and about parsing it right which is as you pointed out in JSON sequences they chose the record delimiter intentionally to be able to easily write without parsing the structure go through and find you know where one structure ends and the one PDU ends and the other PD begins if you did this type of thing with X 690 aka ve rder etc for for PD use that have a known length you can look at the first few bites of the first PDU and then skip all the bytes but you can\u0027t do that with Seaborg because see people see more composite data types have the number of items so have you thought about a delimiter melt it or Sebald does not use kilometers period right well no no that\u0027s true but neither does JSON right that\u0027s why they chose an out-of-band character jinsol is not using the entire character such correct that\u0027s right so they could just use the second record separator but the answer to your actual requirement already is in certain documents do they put the elements of the zero sequence into byte strings so they already have a length tag on top of the thing so you can get all your your ace and 1qg they\u0027re all your basic encoding with beauty by packaging the zero data I come in once it was my dream god right okay I can think of a few ways to do it but I guess I\u0027d want to know what applications are using it for and whether being able to skip large quantities of Seaborg items is desirable if you need something skippable in the super document that\u0027s the design pattern I put a byte string around it okay yeah with where it\u0027s tagged as a sieve or encapsulated data item you\u0027re good but it\u0027s not needed if "
  },
  {
    "startTime": "01:07:00",
    "text": "the whole thing is a sequence right okay should this document suggest or require that pattern it could suggest it I think that\u0027s a good idea secondly not required so there are lots of application where we are trying to use the internal delimiting function of the data now that\u0027s okay we\u0027ll continue talking about this and the place in this working group when we go to the Charter discussion quickly yeah this battery battery security so there are a number of texts drafts out there and right now I want to talk about the array draft because that has just a completed work noob last call and there were some pretty good editorial comments that again need to be put in just to remind everyone what there is it\u0027s a table of 2 times 3 times 4 tags and it allows you to have a genius erase of certain data types as fashionable in the graphics community and and other communities that are handling large data items but they are also useful for small data items like like RGB rates so the issues that are in the Trekker have a number of good editorial suggestions these just need to be done there also was requests to get more explanations about the use cases for homogeneous and clamped arrays so why do we define a homogenous tag why do we define a clamped tag and yeah so this has to be written up the context that that explains that for the clamp tag is really easy to misunderstand so it\u0027s it\u0027s not trying to tell people what the history of the data in that array is I mean that\u0027s also interesting but really how they should handle it once it\u0027s unpacked again so that that\u0027s something that that\u0027s very specific to the work this came from in in the JavaScript environment where these arrays are defined there is a specific child for "
  },
  {
    "startTime": "01:10:01",
    "text": "clamped arrays of 8-bit numbers and this work is mirroring that and finally we had a discussion about deterministic encoding of type arrays and I think we have arrived at the conclusion that the decision what precision to use what range to use what byte order if you use is really an application decision here so there is no deterministic encoding implication at the generic civil level so if an application wants to define its own deterministic encoding words here it\u0027s free to do so on the on the big endian versus little endian so you could imagine then a generic encoder or decoder should have to support both big and little endian and it lets the caller decide what they want to put on the wire and what they want to accept and that\u0027s that\u0027s a little weird because you wind up doing a lot of you know having some extra code in there for the out that yes that it that the point of supporting choosing one is to avoid that code yes so yes this is out of character with the rest of SIBO and the nice thing is that that C was actually stable enough so that it can survive that I mean we can sometimes do something like that willfully ignoring our own principles just because the the work we are trying to interface with has different principles and the typed arrays just come in these through false and it would be unnecessary right for these people to require one of them but again let me ask again why not just choose like little india and and say that\u0027s it well the application will do that why wouldn\u0027t why not choose one representation in 4/4 our eight eggs and just say that\u0027s it so there\u0027s not an ambiguity well because the work that we are referencing allows both and if you build some something that is informed by two tricks of standards colliding with each other how do you handle that you can try to impose the will of one group over the other group or you can try to find something that that doesn\u0027t break either "
  },
  {
    "startTime": "01:13:01",
    "text": "of them this is trying to not break the the world of typed arrays as defined by Cronus and and Java switch so definitely I I didn\u0027t like that but Jonathan the the kola found this really fun Winston feels that this is what we want to do and fortunately he has vanished from the face of the internet so I don\u0027t know where he is but it was really important for me good almost on time so before we talk about next steps just one thing I wanted to say I forgot in the introduction was that we\u0027re going to schedule interim meetings we\u0027re gonna continue with the calls so every two weeks and we\u0027re gonna do a new doodle poll and coordinate with ace and core so that we get the same time and cosy so that we get the time that is good for everybody and then we would have one week quorum when we see Bohr and then ace and cozy in the middle there sometimes yeah in the interim between 103 and 104 we had regular call and SIBO meetings and they both were on Wednesday but they were different times of the day and that so please make sure that you enter your preference so that we can select a time that is best for everybody on the coordination side my iot directorate on let\u0027s go so coordinate with other groups like oma one DM and others I mean not like to the level but yeah you can probably try to avoid the slots where we know that other groups are also at the stairs as long as they get enough it\u0027s up okay on the plans so last time Wednesday was horrible he\u0027s probably still gonna be Wednesday but we can fix the timeslot I mean Carsten I\u0027ve already kind of started with activity on that collecting on one wiki page you know Haiti Directorate when other each groups meeting things already outdated but let\u0027s do an exercise on that because I can I\u0027ve been telling all the other crews this is gonna change after this meeting so it wasn\u0027t much point doing but now let\u0027s do it together good yes hi hi McManus I\u0027m wondering if now is the right place to this the right place to ask whether we can use GTA instead of WebEx for these types of meetings or simplicity okay the idea is that with WebEx we can "
  },
  {
    "startTime": "01:16:03",
    "text": "record the meetings that\u0027s the official way of of doing and scheduling in but we look into it and now for next steps so we have listed here some documents that are now in backburner and we should be considering for recharging discussion i just noticed there is a new one I mean two new ones so there is the stock for coordinate reference systems system that was submitted three days ago and then Jim\u0027s CMS content types for C bore as well the last one is interesting because really it\u0027s not something we do to interface with the Amish it\u0027s something that CMS does to interface with Siebel I basically put that in because I wanted to see people and see war to know about it but I wasn\u0027t planning to run it through this group it was basically I wanted him to people have a chance to look at it and say yes this is the right set of things that we should be encoding yeah so now you\u0027re aware that that exists so we have talked about the sequence tag and Carson has mentioned CDL 2.0 and also we have the one document that is charter but not yet adopted which is the oil we\u0027re waiting for an update on that to do the call for adoption and this oil plus is anything that might get taken out of that so that\u0027s also something that is up for discussion so I\u0027m asking for people\u0027s opinion here what do you think is prioritized what should we do I think we need to sort this into different buckets so CDR 2.0 really is about evolution off of one of our call specs so that this is not maintenances and housekeeping this evolution new stuff new features trying to react well to user requirements that they begin to understand more fully and so that\u0027s one bucket and the only place where you see this right now acidity I don\u0027t think we have any we have to evolve in this way with the potential exception of the time tag where probably you could do a couple more time working groups but we\u0027re not going to do that then we have housekeeping stuff like the sequence "
  },
  {
    "startTime": "01:19:04",
    "text": "thing and we have tag definitions of different qualities some of those tag definitions are really not not much more than also housekeeping stuff some are we motivated by applications within the IGF asourian for instance the template check that that\u0027s not on this list is really something that came out of AP when and that we may want to revisit they have been busy doing their protocol but now they are thinking about the data models that actually control the thing and that\u0027s where the template take comes in again so we have one bucket of tags that really come from from inside the ITF then we have another bucket of tags like the time tag which just kind of obviously need to be done and so they are very similar to the text editors we already have that they\u0027re good parts of the ecosystem and maybe with a decision to split out the most of the tags that\u0027s a good time to tour think about restructuring this area and then we have a third area of tags which really are registration requests from outside like the arrow tag or the geographic coordinate thing which are mainly the the domain of the designated experts talked with with the applicants but in the end of course if a tag comes out that has some wide applicability it would be good to document this in in our C so I think we should develop a standard procedure of doing that whether as a working in procurement or in the independent document I don\u0027t know but I think it makes sense to think about this bucket of documents because those will be becoming flowing in at probably increasing Aleksei do you have an opinion as ad not yet I\u0027m trying to come up with one okay good I was just about to check what\u0027s in the current childhood so it\u0027s a super bass CDL and are a tag and old tag and then retarder for adding more items or well my general advice would be try to prioritize them and try not to take too many I mean it\u0027s fine to have a chartered work genetic charter working on extensions try to limit here number of your milestones you have for this how many documents you have actually being worked on itself I recommend one cover "
  },
  {
    "startTime": "01:22:11",
    "text": "the sequin stuff is actually quite interesting because it\u0027s not discussing things in Archie and Beyond we\u0027re seeing more and more of these streaming kind of use cases which we haven\u0027t been seen before and having good tools in the toolbox for handling those cases is pretty useful and then another comment on them air attack reminded me um do you have how much capabilities of sealing errors within c4 and also oxide I\u0027m thinking of is I use co-op to exchange my see boards there\u0027s something wrong with in c4 document and were the error codes to use in what conchae said now we have like a bad request but is there something more should we come up with some more detailed ways the link that okay this the cannery what went wrong in the request and it\u0027s something in the interplay between the seaport things and data models in general and on protocols that are carrying them when we define the coop we thought about this problem for a while and came up with arrows that are supposed to be handled by the application and said you changed the application state machine these need to be defined and that\u0027s where we have things like 404 and so on and there are other errors that are really hard to handle for the application because something went wrong and that\u0027s something that went wrong is often only be described in ways that are specific to the application in which it went wrong so that\u0027s why we invented the diagnostic payload there\u0027s something similar now in the HTTP space which is not exactly called error document I think it\u0027s called problem document or something like that and maybe it\u0027s worth looking at this space and seeing whether there\u0027s anything we should be doing on the sea both side but we already have this concept of diagnostic payload and reduction and so we could start out from that I\u0027d have to see some very big tight problem statements before I we think that would be in scope yes such as things are just yet but just like yeah something for us to perhaps explore later on and yeah some of the exploration of course can be done anything Archie or we are looking into this let\u0027s do it together so what I hear is this - two working areas let\u0027s say "
  },
  {
    "startTime": "01:25:16",
    "text": "extension for we have the evolution of our core documents which is only the city we have the housekeeping stuff that\u0027s wasn\u0027t a second for me that\u0027s what I call yeah but go ahead sorry and we have the three buckets of tags the ones that we want the ones that the IDF wants and the ones that other people want so we should and what Alexei said we should prioritize on those to make sure we don\u0027t he can\u0027t I don\u0027t have an opinion which one you want to work on I think that\u0027s your if you want to do a poll on them do a poll on them I don\u0027t really care just pick the one you really think I\u0027m the most important one and prioritize them yeah that the importance goes across these five categories so for the tagged documents that the IETF wants we could decide to systematically push them out to the using side and just may keep us under keep us in the loop that would be one way to handle it just trusting that knowledge about see was this sufficiently widely spread in the IETF that we can do that the ones that we want as a way of evolving the see what ecosystem I think we still have to do they usually don\u0027t come with extremely tight timelines because they come up as we learn and we learn slowly and at some point things are kind of right for saying okay now we can write this up and ship it so it\u0027s little agency and usually also not that much work because by the time it actually hits the working group probably the problem is well understood so that\u0027s why I think these can be done with a relatively high priority because they\u0027re little work and then these external requests that those are all over the map so many of these can actually be handled by my first registering there and then going ahead and then fixing up this justification which is a little bit unclean but but it works for people who have chip dates so again it may not be a high urgency saying try to get these documents published but of course it it\u0027s nice to the people who suggest these things and work and Honi them to actually have a publication process taking notes so "
  },
  {
    "startTime": "01:28:18",
    "text": "again you know being a bit ignorant and actually not knowing what documents are registrations are in the other IETF working group category what the working group like to triage them and check you know are they competent enough to be you know delegated to other working groups or are they better be done here and also coordinate the time line you know with the other working groups you know when they need to be done so that might be just one input to your decision process okay I think we that was good discussion to start with sure so so since we still have three documents that are supposed to be published in the current charter I think it\u0027s good to start now with discussing the Charter but I don\u0027t think we will have anything very soon anyway well of the two main documents one is shipped and the other one is in the process of making so this kind of opens up the opportunity to do find new slots from my point of view and I wouldn\u0027t want the text documents that are currently in the Charter to be a gating factor for during the recharger you can do the recharge ring based on whatever model we want to come up with for handing take documents and whatever we haven\u0027t done at the time we do the recharge ring just goes into that model and we are fine I don\u0027t have a strong position on whether we should have shipped see you abyss to the isg when we saw reach out doing that\u0027s Alex\u0027s decision but I think we should be ready by the time with the Charter that is accepted I think asking for a chattering once he shaped the base back revision Taurus G would really help from perception thing I think this working group was a bit slow starting but it seems like it\u0027s picking up pace so certainly finishing CD DL helps but demonstrating that you can you know nearly done with one or more other things would certainly be more encouraging for the rest of Asia [Music] "
  },
  {
    "startTime": "01:31:20",
    "text": "well yeah I mean my expectation was that the chairs would sit down over the next month and put together a candidate charter and then have discussion oh absolutely in May and then we can as soon as soon as we get through on agreement then we can push it up today is G and they can sit on it or not as they feel like that\u0027s fine once you have charter we can discuss where you are with the rest of stuffs yeah we\u0027re out of time so thank you for today thank you me no takers anyone didn\u0027t design the blue sheets please come forward Karsten "
  }
]