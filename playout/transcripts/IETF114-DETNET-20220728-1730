[
  {
    "startTime": "00:00:11",
    "text": "oh hi good day everyone welcome to the that net working loop session at iitf 111 uh hybrid meeting uh welcome everyone who are in person in the meeting room in philadelphia and also online uh we are chairing the working group together with blue berger and damianos farkas and many thanks to ethan for being our secretary and taking care of the job minutes and so on you find the information at the usual places i don't go there but i would like to remind everyone to the ietf note 12 which is our rules of uh way of working operation and i would like to also remind everyone that uh what is being uh set here is getting minuted and becomes part of the uh permanent record of the itf as as a contribution if you are not familiar with uh noteworld then please please go and double check uh also a reminder on our guidelines in terms of behavior like we expect everybody being familiar with it and expect to be here professional to the other people other contributors as for attendance in these meetings"
  },
  {
    "startTime": "00:02:00",
    "text": "a couple of hints on this slide in person attendance please uh join me the call uh either from your uh phone uh by a mythical light which gives you the opportunity to control the slides if you are presenting for instance or if you join the full meta code and please pay attention not to use the audio and the video and also very important please wear your mask that's how we run and how we have this idea uh as for remote participants i think we are all very familiar uh with it in the past two years oh yes that's a good point that we will have a couple of questions uh to the group and we will use the polling tool of mythical we would like to ask everyone to join uh for that reason as well uh yeah the qr code is on the screen if you are in in person uh right hand side uh to you that's an easy way to join or you can join from the agenda page uh the blue sheets are automatic uh via joining with a post so you don't need to do anything extra and we also use the chat uh for example you can just use what we have in the medical note taking minutes is a joint effort uh so i would like to encourage everyone to join and and head on and go and double check if you say something that it's been captured correctly so the link is on the screen"
  },
  {
    "startTime": "00:04:01",
    "text": "and also you can find it from the agenda page and so on and the other usual links as well here we are on thursday at the death note session but on a tuesday we had a joint session with the pass and the mpls working groups hosted by the pass working group and thank you for that arrangement these discussions is about the evolution of the mpls data plane and this is one of our data planes in that net so we pay attention that it remains good for that net that's our main interest so thank thanks everyone contributing to that and for the effort uh we have a packed agenda so we will pay attention to the time and we ask the presenters to also pay attention and and stick to their allocated time slot to let everyone have their slot and and speak update on on our the status of our working group we have two documents uh for which publication has been requested uh the first one on the screen is the bounded latency draft which got into the rfc aq editor very recently so heading towards the publication and the young draft is the next one in the queue to our publication we have a document in working group last call the oem framework document the last call closes on the 3rd of august we will get after this intro an update on that and i would like to encourage everybody to review and and comment it is really high time we have a draft which is a candidate for"
  },
  {
    "startTime": "00:06:02",
    "text": "working group adoption the ipr call process has been or is being ongoing and we are going forward as usual and we have two uh drafts working group drafts that are not on the agenda at this meeting one is the controller thing framework uh which we should come back and maybe touch upon it a bit later at this session and um one of the the new ones the the that nuclear wire mpls over udpip we have received a liaison letter from itu this study group 13 question 6 i think yes question 6. we have been in liaison exchange with them received one formally for information we provided a response to their work on deterministic communications and we have received now this newer liaison for information with three attachments you can find the link via this stack or the other ways the typical ways please check and if we would like to respond as a working group we can develop a response on the list one significant step happened since the last ietf is that our charter has been approved i mean updated and approved the approve was the new step we have been discussing the update you can see on the screen the actual changes and as we have been discussing the intention behind the update is uh to address uh sort of enhanced"
  },
  {
    "startTime": "00:08:01",
    "text": "requirements towards.net and uh to address these requirements uh to enable uh the development of queueing solution we will have contributions on this later today milestones we have just recently updated the milestones in the beginning of the week uh capturing our our our progress the the blue ones on the screen are the actual changes uh of the dates just uh to adjust like buzz dates are not valid or were not valid and we should i think try to pay attention to move forward to to meet these microns and i think it's a good uh motivation also a reminder on on the ipr disclosure process is very important to disclose the ipr and the last step is a bit more than the the rest that if there's a new author then we ask the disclosure as for progressing our work we have the virtual possibilities in between uh the idf sessions like we have been leveraging the the working group webex we can do that uh for uh for other topics most recently it has been the oem progressing the oem drafts we had by weekly meetings and upon request we are happy to set up working meetings or interim meeting if that fits better please feel free to to contact us working group chairs and we figure out how to say that that's"
  },
  {
    "startTime": "00:10:00",
    "text": "that's for the intro do you want to add anything okay so let's uh move on uh to the first uh presentation you can just tell me when to go next time okay thank you um can i take it off you you don't need to i'll feel more comfortable i'm sorry okay um next slide please thank you okay so um we have uh three documents working group documents uh in the framework um for that net as you've seen that uh this is in a working group last call and of course appreciate your comments reviews and response to the working request call and two documents that analyze um applicability of existing oem toolbox for ip data plane and mpos data plane to the specifics of the net architecture specifically that we have two sub layers uh forwarding sub layer and that net service sub layer so let's take a look at what we have uh the framework document um lists a general requirement for the detonate oem that is executed between that net maintenance endpoints and requirements specific for proactive on on-demand monitoring and measurement oem methods for the active oem uh also uh we uh recognize that uh some of the tools"
  },
  {
    "startTime": "00:12:01",
    "text": "are used as um troubleshooting mostly it's on demand or proactive for longer lasting test sessions and they may be configured and to be instantiated and activated upon the service being brought up [Music] so active oems should support active and passive and hybrid oem are identified active oem it's uh using specifically constructed uh in injected in their uh network uh test packets uh passive uh it's uh we're more familiar with their snmp queries but at the same time that can uh be based on um [Music] notifications or rpc uh with their using based on a yang data model and hybrid uh it's sometimes characterized something in between so there are mechanisms that combine elements of active oem and passive usually with a minimum modification of the data packet to provide a simplified identification of their marked packets thus allowing onpath telemetry information to be generated and collected an ad collector side for network analytics and possibly use for close network automation loop so in addition to supporting unidirectional oem methods such as a"
  },
  {
    "startTime": "00:14:00",
    "text": "continuity check and packet delay loss measurement in some cases for the debt net there is interest to support the bi-directional net falls next slide please so uh as i mentioned that uh we identified their detonate architecture identifies uh there are two sub layers a forwarding and uh service sub layer for the forwarding uh it's important is to be able to do a path mtu discovery and use a remote defect indication so that [Music] the remote appear can indicate their loss of path continuity that's usually how it's done in bfd also support monitoring leveled for path segment oem next slide please so for the service sub layer uh we identify the uh use of pre-off or packet replication elimination order preservation sub functions that can be uh instantiated in a net domain and that's what their requirements for the dead net for the ser that net sub layer oem uh to do discovery and uh functionality verification of the pre-op next slide please okay now we next step would be to talk about and discuss their that net and ip data plane so um the well-known mechanisms are such as their icmp that we usually refer to as ping and trace route well known to for"
  },
  {
    "startTime": "00:16:02",
    "text": "path continuity [Music] detection and the troubleshooting defect localization also it's a bfd it's a bi-directional forwarding detection um and for performance monitoring it could be t worm stamp or some other protocols the challenges here is that these are as in case of icmps based on ip or a bfd they're using their udp protocol as a transport and well-known udp ports so they're mapping to the particular that net flow and the forwarding flow um it cannot have um if the detmit flow identified based on a six tuple so the mapping is probably could be an operational challenge yes it's possible it's doable but so the operator might be uh aware of it and use appropriate mechanisms to do their uh correlation so that oem is used to monitor a desired and targeted that net flow okay any questions okay let's move on next slide please okay so uh one of uh possible methods of doing active oem uh in a forwarding sub layer in ip environment for that net is to use that net is in udp encapsulation so the detmit flow itself is encapsulated in the udp tunnel and then active oem is"
  },
  {
    "startTime": "00:18:00",
    "text": "encapsulated in the same udp tunnel so thus we ensure that in the forwarding clear uh they are fade sharing because they use the same okay questions comments okay we'll move on so i'll i guess i'll all right sure in the past we've talked about using uh aggregated state to not have to put um do an exterior encapsulation and we've not had any firm proposal on that so it does not it's not reflected in the current document um go ahead yeah um actually if we look at the previous slide so that's where okay that's how existing tools without any encapsulations envisioned to be used so basically there are a lot of operational mechanisms to establish relationship between monitored or that net flow that intended to be monitored and oem mechanisms because the problem is or the challenge is that we're using a specific icmp protocol a specific ip protocol as icmp or we're using particular well-known udp port for different oem uh protocols bfd is distinct from t-wamp stamp can use the same uh udp port well known 872 okay so because uh we already are bound by oem protocol"
  },
  {
    "startTime": "00:20:01",
    "text": "what um destination port uh udp destination port we use and that with the fact that we're using udp transport so it uh requires special provisioning on uh within a detonate domain on a forwarding sub layer to establish this correlation so that test packets are treated the same way one way of helping is for example it could be use of source port numbers or udp source port numbers to help to establishing and uh to that degree we have this uh discussion reflected in that net for ap data plane document but again we are not prescribing how to establish this correlation because i believe this is a operational issue and there are many ways to do that sure and on the next we go to the next slide for a moment it would also be possible to have that active oem in a new udp tunnel and have the net flow outside and have through control mechanisms through the controller plane have the association and we haven't seen that one oh okay that's interesting so basically uh to have all different active oem protocols in the same uvb tunnel and then map that udp tunnel oh okay that yes that's that's something different yeah that's a good idea i i thought we had uh it had been discussed but never actually done no actually i think that okay then i missed that because that's a little bit different that's interesting idea because as you see okay i have okay i have to say i haven't"
  },
  {
    "startTime": "00:22:00",
    "text": "thought about it okay that's fine no but no no it's it's a good idea i'll i'll make sure that will be included in the next version of detriment and id great thank you um we also have pascal on pascal go ahead yes thank you um so basically we need that correlation that's that's clear um for ipv4 i understand that we are stuck with what you're saying for ipv6 uh we have the possibility to tag the packets in an option editor like hobby hub and in that case if the that net operation is dictated by the hub by hub option as opposed to the flow we can effectively encapsulate multiple flows into a single with the same hobby hub option the cool thing about using an option is you don't have to create an extra udpr caps and you don't have to have the silicone go all the way far into the packet after the udp to find which that operation you're looking at uh if it can hold a signal right after the ipv6 header in a hub by hub option so that's why i have this draft i mean i don't we have not discussed it much but the whole reason of this up by hub or it can also be a destination option i mean depending on what you do i mean if you look at the drafts you'll find more but basically the flow is something it's an application layer concept the recognition of the network operation on the packet is a network concept it doesn't have to be signaled by the application layer the application layer can have multiple flows and it's up to us to decide to tag the treatment that we're going to give to those flows that can be oam that can be data and there can be multiple flows being merged in one big pipe so for us it's this pipe that does this procedure we need to tag the packet with"
  },
  {
    "startTime": "00:24:01",
    "text": "the pipe and then do based on that tagging we can do that in v6 um okay pascal um there okay um i think that there's still um need for external tunnel because their identification of the multiplexing of active oem protocols is based on well-known udp port number so if it's not an external udp encapsulation then um their destination port number has to be for the given protocol and then it basically the case of previous slide when we have what's i refer to as existing uh oem yeah that's exactly what i was telling you we can solve a lot easier because you don't have to change your packet you just tag the packet with an ip hobbyhop header but your your all oem packet remains the same but the that net treatment does not depend on the ports anymore it depends on the hub by hop header um so they get the same treatment as long as they have the same homebuyer pedal and you use the port that you like you do you do everything you like really maybe can we continue this discussion yeah we need to talk about it because i don't think that uh their processing of oem protocols with hub by hop header by transit nodes have been defined because i for example in uh in b in the case of"
  },
  {
    "startTime": "00:26:01",
    "text": "bfd like uh well single hop obviously it's considered to be for single ip hub but if we talk about multi-hop uh i don't need to look at and we need to look at and think of how the transit ip node react to multi-hop bfd packet which is it does not have a bfd discriminator so would it just forward it further let's get some interesting idea but i'm not sure that the mailing list over the draft the draft is there right it's been posted it details all this and one of the big goal of these drafts is to enable to decouple the treatment from the transport ports right it the goal is to signal the treatment at the lar3 and let the application information like the ports to the application so they do what they like now we can we should we should discuss that at the remaining list they don't want to clog euro please look at the draft and let's discuss on the ml but going all the way udps is a poor idea for silicon yes thank you okay so for the sub layer oem uh the proposal is uh to use uh mpos in udp so we are have the outer udp tunnel and then uh within it we encapsulate as we encapsulate that net for mpls network and thus it will give us uh detonate control work and for oem.net ach and then we can do their uh pre-off oem in terms of discovery and function uh verification and if we go next slide uh so this is more specific what's defined in"
  },
  {
    "startTime": "00:28:03",
    "text": "that net for mpos data plane uh they're modified ach word so as you see it's different from that net control word uh first it's by the first nibble it's one comparing to zero in the control world and then we're effectively we're modifying from the ach defined for the pseudo-wires with a new version number and then a new format so to support batman's sublayer oem operation okay we have about two minutes for questions and comments thank you any further questions comment okay then let's move on to the next presentation hello can you hear me yes i hear you fine and i give you control over the slides so you can uh okay thank you my name is gino jean uh it's nice to present here um this is about the asynchronous deterministic networking framework for large-scale networks if you could speak up a little bit or or go closer to your mic that that would help us hearing you oh okay [Music] okay so uh it specifies the framework for"
  },
  {
    "startTime": "00:30:01",
    "text": "both latency and cheetah bounce guarantee in large-scale networks with dynamic sources with arbitrary input patterns here the large scale means the network has arbitrary topology and it may include loops and the link capacity and the propagation delay may vary the dynamic sources means flows join and leave freely the arrival or input pattern is arbitrary that is a periodic or random packet arrivals here the the only constraint is the t spec the the burst maximum burst size and the average rate parameters so this is similar to the internet the overall framework tries to avoid time synchronization and to decouple the latency guarantee problem from the jita guarantee problem the latency guarantee is implemented or a bit done by the mainly by the regulating functions regulators digital guarantee is based on three part the first one is the latency guaranteed neto and time stamping and the buffering [Music] the internet already has the solution for the latest guarantee in some sense that is the deep sub framework but it is provided that in every link the total high priority traffic rate does not exceed the link capacity or to be precise the every flow has to be [Music] serviced by the rate greater than its input rate"
  },
  {
    "startTime": "00:32:02",
    "text": "so the link capacity has to exceed in order for every flow has has the guaranteed rate that is higher than the average rate so the resource reservation and the automation controls are mandatory so these are the out of scope of this draft so the diffs framework works well for lightly utilized networks however when utilization is medium to high the burst accumulates assume there are unidentical flows coming into a switching node each with a parameter b and r b is the precise and r is the average rate at every node the burst accumulates as much as according to their scheduler type the b out here is the uh the flows uh burst size out of that node so anyway the the burst becomes larger but you can see that the the burst out is the function of the utilization and function of the other flows first or sometimes it is a function of the other flows maximum pekka length so they can vary a lot but anyhow they increases now the flows are with new parameter v out and r and this accumulation continues as flows travel now if there is a cycle in network topology it acts as a feed for the loop then the burst explosion phenomenon occurs and latency guarantee no longer holds [Music] so these solutions to mitigate the burst"
  },
  {
    "startTime": "00:34:02",
    "text": "accumulation there are quite a lot of solutions i would say the slotted operation maybe without strict synchronization can be the solution and metadata based packet forwarding such as the latency budget etc can be also a solution and the flow regulation that is the direct solution to mitigate the burst accumulation it is to force a flow into each initial shape they have their own shortcomings for example the slight slotted operation or just likely queuing [Music] either strict or lose requires the slot planning and the source cooperation and moreover the cycle time can be as large as the accumulated burst size because it may have to accommodate all the other flows in its path the metadata-based folding it has many variations i i think may may disperse but sometimes may not disperse the accumulated burst and it requires the lookup the metadata lookup and decision based on the metadata and the node state and q reordering and overwriting the metadata at the departure in line speed these are required these are required in the in the meantime the flow regulation has its own i show coming it requires flow state maintaining but we argue that this can be overcome with the flow aggregation so here the the regulation of flow aggregate is suggested as a solution the first such example is the ats i triplets and ats"
  },
  {
    "startTime": "00:36:01",
    "text": "it is based on the interleaved regulator which is the nice property that the ier does not increase the worst latency of the fifo system so the the fifo system must be given in front of the minimal ir it can be implemented in the fixture on the right side the ates has to be implemented at every node an ir per input port has to be implemented but ir has only one queue but still it requires individual flow states the second solution suggests in this draft is the fair uh it is it represents flow aggregate and ir it is basically a generalized ats here the fifo system is suggested as a network domain called aggregation domain for aediota so far the regulator is implemented at the av boundaries and the flow aggregation is defined as a set of the flows with the same path in the aid it has been shown to work better than ats in the academic paper [Music] third another solution suggested here is the port-based faa regulation it can be implemented at every node or at critic only at the critical links to break the cycle here the flow aggregation is the set of flows having same input output ports of a node and mainly it regulates flow aggregate not individual flow based on the uh the parameters of the sum of the burst size and the sum of the average rate"
  },
  {
    "startTime": "00:38:02",
    "text": "so it's kind of a loose regulation so it has the best scalability no need to maintain individual flow state and it has been shown to work almost as well as the ats there are other possible solutions not uh specified in the draft um [Music] for example a more strict regulation then this pexa just can be can be a solution as well here the regulation is based on the parameter l and the summation of the r so regardless of the birth side the t-spec suggests the regulation can be very strict and in that sense it can be seen as very similar to slotted operation or cyclic cueing another possibility is the use use defaulting method data such as the source timestamp to reproduce the initial interable process at every node so there are lots of possibility in this framework i would say um finally the based on those uh latency guarantee framework we can also guarantee cheater upper bound here the jitter is defined as the yeah the there is a okay so i will say the jitter guarantee is reproducing the enterable process within into the departure process of a network so provided that we have the latency guaranteed network we can timestamp at the network boundary near the source"
  },
  {
    "startTime": "00:40:03",
    "text": "and based on this timestamping timestamper timestamps we can offer the package to reproduce the interrupt process at the inter departure process yeah the it has been shown it has been proved that the jitter is upper bounded and the end-to-end buffered latency is also bounded we can control the jitter bound we can even have a charity term in that case the entity and buffered latency is uh almost twice as the entire 8-inch bound it has been proven [Music] sorry for the the time passing so thank you please look at the draft and comments and questions are very very welcome thank you okay thank you that this is actually our first uh document on sort of this new area where we're looking at enhanced data plane uh queuing mechanisms and uh changes in in how we can support uh traffic treatment in that net and that's the the the term that was used in the charter uh it's um a new area for us we're very interested in the contribution so thank you and thank you for the that we have a number of uh presentations on this topic so that's great one thing to keep in mind is there's a sort of a theme throughout a number of these solution documents that talk about changes to the data plane i think this draft used the the term metadata that's sort of used in others but the there's a common theme of some extra information that's needed to support the enhanced queuing and enhanced traffic treatment and one of the questions for the working group is"
  },
  {
    "startTime": "00:42:00",
    "text": "going to be do we want to identify a common one how many of these do we want to put forward and this is just something we don't want to discuss it right now we just want to put that in into your head as you hear the different discussion and uh we are going to be asking about if you are interested in in hearing more on each of these topics um so i really don't i see twirlish getting up for this i don't want to have a long discussion about this i want to give time for the presentations i we had one question on the last one so why don't we we go there and then uh uh we'll move to the next so uh sure so uh who was first so uh lincoln from fishway this is very interesting work and i think it's very important for the then that applied to ip network but i have a couple questions here so first what is the definition of flow here it's ip or this map okay second question is absolutely you're using regulation or record traffic shipping uh how do you get the rate by provisioning or by whatever methods i would suggest that you'll be best to put this to the author on the list uh they're not in the room and we're actually they went over a little bit they were nice enough to apologize for going over but they really didn't need a question at a time for questions on the document sorry uh please please send it to the list shusang was next yeah [Music] hi can you hear me well yes thank you uh two very brave question uh just for ex clarification the first one is that because we have another document called"
  },
  {
    "startTime": "00:44:00",
    "text": "bonding latency so i think that this document is really very very related to that one so the the question is for the others uh what is the relationship of these two documents i understand that this document mainly focus on the uh a synchronized case but i think is still have to deal with the the deal with the relationship with the existing document and the other question is that um i noticed that this document is called a framework of the synchronized maybe shaping or scheduling mechanisms and it listed a set of mechanisms that could be used to provide a funding latency or bonded jitter i think that is a very great work and it could be a good start but it is still um a question for us what is the relationship with the existing mechanisms defined in ieee because the as we um we discussed before in the working group there are a lot of existing work that has been discussed for a long time in lee so if we have done similar working than that what uh what is the method we can you know synchronize with actually people and how to cooperate with them i think that will be another question from from me thank you it's a meaningful work i think thank you for the contributions uh from the others okay thank you i'd like to ask again take it to the list for five minutes over on this one and there's others so we're eating into other people's time just a quick comment on what what what you were saying um to better compare maybe at some point in time we want to you know even have some summary of alternatives or the"
  },
  {
    "startTime": "00:46:00",
    "text": "structure or something to just not have a long list and you know don't even know how to do it so for example the biggest you know two buckets i can think of is you know one of the solutions where you can get better dead net treatments by just relying on existing uh packet headers that we have effectively you know i think that's what we've been hoping by doing to be able to attach state to the five double or six tuple uh flow elements that is implying maybe we can even just have you know whatever the stolen from tsn queueing discipline and we don't need to treat anything in the forwarding plane my proposal here also it tries to do that trick to quicker get deployed and the other ones do cooler things by having new packet headers so that's that's one big you know areas of distinction yeah and and going to shusang's point we sort of do expect that there's going to be some falling out maybe some consolidation between these things that are it may at first seem pretty separate but they're aiming towards the same place in some cases some cases they're not uh but hopefully we'll see some consolidation as well all right thanks we should press yes move on to the next one clown please you have the control and go ahead hello and i'm john chong from bt um i would like to talk about the uh that led enhancements for large-scale details to peak networks let's slide please you have the control to click the next slide okay thank you okay uh so first the background is that uh the latest working group charter was updated in july package treatment related methods should be supported and data plane the milestone showed the document plan over deadlift wg in the future two years enhanced that that is the last focal topic so uh next slide uh so we will uh talk about some problems uh"
  },
  {
    "startTime": "00:48:03",
    "text": "lead to be discussed first what is the enhanced that led from a charter and milestone the enhanced that that is required to provide the enhancements uh overflow identification and packed treatment and support the enhanced functions or mechanisms for that data plane to achieve the data that cues and so was the enhancement of package treatment as per rfc 8938 uh that led related date plane functions must be decomposed into two sub-layers a surface sub-layout in the forwarding sub-layout and so that last specific metadata and uh that led ipmps data plane has been described so in my view uh for the the enhancement of packet treatment uh the uh treatment functions for that data plane should be described and the treatment specific metadata and encapsulation should be defined for the net flow um for requirements the enhancement requirements has been discussed therefore several times um including technical uh requirements and the data plan enhancement requirements and worth more the requirements from a perspective of surface sub layout and forwarding subnet has also been described for example the deterministic surface may demand different this ministry queues requirements uh these missed rules should be established and the distributed rules and the inter domain rules should be taken into consideration and the the resource should be managed"
  },
  {
    "startTime": "00:50:01",
    "text": "to provided pending latency guarantees for the dismissed forwarding so some of the queuing related and the date play requirements have been merged in their last scale requirements so folder data plane uh the enhancement for the data plane is shown uh on the right um a right side contrast to rfc 8938 the enhancement uh in the enhanced treatment functions may be added such as flow aggregation flow redundancy you show a different slide not the one you are talking to we see page five here and you are talking to page four oh sorry okay okay i will continue um so uh for for the date playing consideration we think the enhancement for the data plane should be enhanced shown on on the right side contrast to rc8938 the enhanced treatment uh functions may be added such as flow aggregation flow redundancy under surface level aggregation and for forwarding sublio maybe multiple queueing mechanisms uh deterministic paths uh resource scheduling and distributed routed routes and so on and and many functions to improve their their uh their that letter performance to achieve the dalek queues and the treatment metadata used by functions should be carried such as the service level information aggregation aggregated flow information"
  },
  {
    "startTime": "00:52:02",
    "text": "redundancy information pass information q information and so on and many and many other information can can be added to the metadata and then the the encapsulations format such as fpv6 are so e6 and then ps should be taken into consideration um and then a particular require requirements for the controller plane should be taken into consideration according to the enhancement of the download plane so we list out some requirements for controller play such as management and scheduling over resources distributed deterministic paths and their inter-domain dismissed path did mispass calculation and so on and other requirements to be discussed in the future and so the solutions over enhanced treatment functions and metadata are open to uh working group we call for co-workers and the reviewers and hope to provide a more visible and achievable way to progress through this work comments and the questions are pretty appreciated and welcome to join us thank you you please go ahead with your question uh hi hi thank you for your presentation uh could you please go back to page five i think my first question is also for the chairs because uh the page five uh has mentioned some requirements for control page five a next slide thank you uh yes uh"
  },
  {
    "startTime": "00:54:00",
    "text": "you mentioned some controller plan consideration actually uh as the order of the controller plan framework um my question is that whether the existing controller plan framework is supposed to only contain the net controller plan requirements and some framework considerations or we should also consider the enhanced net control plan consideration if the if we go to the previous method maybe there will be another document uh maybe called controller plan considerations or framework for hansa.net as listed in this slide but if we goes to the letter method maybe it can be combined into the net existing framework as the other i prefer the latter one because the the controller framework is controller plan framework document itself is uh is still under discussion so we would like to combine the considerations of enhance.net yeah i think the existing contour airplane document the contour brain framework is a working glue document it's it's uh being developed so we can add at the material right now as we progress i don't see issue with that okay thank you and the second question is for page four i noticed that uh the here you also listed some enhanced data plan requirement for service sub-layer for example flow aggregation flow redundancy uh and the service level aggregation all these functions i think that have already been defined in previous destination discussion so my pro my question is that what is new here or what should be enhanced here for service supplier"
  },
  {
    "startTime": "00:56:04",
    "text": "uh h9 has been released and some of the functions or some of the uh encapsulation has not been covered in in that rfc so in my view there um there are additional functions or encapsulations all belong to their enhancement so it's up to their data working group thank you i think we could look at some specific text and see which parts are line up with what has already been published as well as what other documents are coming into the working group for instance you mentioned the requirements document the individual draft and we do have on our uh milestones uh adopting such a requirements document and it seems like some of the text you've described in your draft could go to that document and perhaps as we start looking at the specific text some of them will find already exist in rfcs and others will maybe go to uh other documents so we might end up realigning and redistributing as we move towards working group adoption of uh solution documents as well as the uh architecture document that's sorry requirements thank you and we should move to the next i think it's the same presenter yes so please uh go ahead with the next presentation you have the phone and please watch the time as well okay thank you uh this is about uh the deadlock queuing option sorry"
  },
  {
    "startTime": "00:58:00",
    "text": "so uh we just discussed about the the enhanced death length that they play with the data plane we should uh provide the functions to achieve the data queues such as entry and deterministic latency so what is the end-to-end deterministic latency as per itf that abandoned the lantern sea uh the end to end the band can be computed as the sum of low queueing delay under the queuing delay along the path the upper down bound of no queuing delay are constant so the end to end latency depends on the value of a queuing delay along with the queuing mechanisms so the qe information should be taken into considerations and enhance the deflat data plan to realize and realize the deterministic latency and how to ensure uh deterministic latency first we should provide the functions or technologies to ensure deterministic latencies such as pure mechanic queuing mcleans and carried the related information in the data plane and the second we pro we propose a common queuing option and the generic uh q information should be carried in data plane uh metadata uh and there are finally mpls ipv6 srv6 inside encapsulation should be taken into consideration and so for the request requirements the enhancement requirements as described has described that it is required to uh provide to provide information used by uh functions ensuring deterministic latency and the defined related uh method data to help"
  },
  {
    "startTime": "01:00:00",
    "text": "regulation and the queue uh management and the large-scale enhancement also proposed there that the enhanced that database required to support a method over a packet treatment and that will include uh we include the deterministic latency scheduling uh the package treatment should support the uh cueing treatment and the identification of killing related information and so multiple killing mechanisms can be used to guarantee their uh deterministic latency for foreign application in data networks so it is required to carry cueing uh information in data plane to make a pro point pack the forwarding and the scheduling decision to meet the 10 bonds and so we what sorry also what the q information will list out their qm mechanisms uh which has been discussed in that lat uh that that will that should get a confirmation confirmation from a working group um but uh for the first uh first of all uh the and unique mechanism should be selected in enhanced that data plane um that could be selected to uh guaranteed the latency for example the tas cbs cqrf a ats cyclic queueing deadline based queuing and adn just we just talk about second the queue information may cover the planned and required queuing delay"
  },
  {
    "startTime": "01:02:00",
    "text": "such as maximum qe delay and the maximum qe delay variation and the queuing like parameters uh should be carried for uh further correlation between nodes uh for example their cycle uh information that line permission and their uh the nantucket uh badgered uh and so on and many other uh parameters will be uh added to the uh the q information so uh we proposed the uh the i2 fpv6 extension solution to provide uh the input absolution for the q information um uh we defined a new ipv6 option for that led to cyclo q information uh and we defined the queuing flag uh helps to this uh dis discriminate the types of cumin metallisms uh we use the uh we use subject to carry specific that data q information and we also specify the format that the new option uh is to be placed in an uh hobbyhope or doh extension header we also proposed uh the mpls extension solution uh we provide additional encapsulation for the queuing delay over deadlock flows in mps data plane uh we align with the the ongoing work in nps working group uh this uh itf mpls mna framework and that has been just uh adopted as the working uh document uh so we propose uh to add spl to carry deadlock q uh redefine uh deadlock queen and catering spl and they used uh tre to carry that qa information"
  },
  {
    "startTime": "01:04:02",
    "text": "and use sub tlv to carry specific data queueing information so the types of queuing mechanisms used for that sled and the related queue information should be discussed uh in details uh that may be uh that should get a complete confirmation from a working group and their last steps other encapsulations such as mps over udp uh and their srh may be taken into consideration and we will follow the chatter and the milestones of deadlock and the line with the tommy terminology so comments and the questions are appreciated thank you and we have time for some quick questions so first off is greg mursky frank gary q are you leaving um um so i realized that you proposed to have this queuing information that includes time budget for the packet be included either as a hub by hop information end to end what you envision uh the system behavior if their time budget for the node is exceeded um the this is up to the uh the uh new liquor uh queuing mechanisms so uh we we this doc draft just proposed uh the scheduling over multiple uh queueing mechanisms so i think what you ask is belong to the"
  },
  {
    "startTime": "01:06:02",
    "text": "the um qa mechanism not their scheduling so uh really understanding the draft talks about guarantees so then there is no guarantee i guess but let's take it to the list thank you yes yes thank you so we are really over time uh i don't know if if if you can take it to the list that would be the best sure i think my question is similar the guys right now they're talking about coding is too early so we're actually jumping you're jumping the queue so if you don't mind taking to the list that'd be great uh robin if you don't mind uh taking the list as well uh thank you and i think uh uh tourists please and we're gonna steal a little time from you and the next presenters it's not just you it's the next presenters also all right thanks so this stuff has been around for five years uh three different drafts next slide faster all right so um there is a very long draft that i wrote with all the nasty and interesting uh background expired if you're interested to have informational or even individual for that draft let me know separately the requirements also integrated in the active draft that carries it as requirements this is all the good stuff this solution does bounded latency dough right minimum jitter that's the most important part synchronous industrial control loops and other stuff and also it makes end devices cheaper because it removes the clock synchronization requirement from them arbitrary links and jitter which is what tsn doesn't need and then the big thing it scales because it doesn't have perhaps flowing state uh so it's not not the five tuple state even though it just then has the latency.net services um and so all the good things that come with it like you know no interruption during network reconvergence and so on um minimum clock"
  },
  {
    "startTime": "01:08:00",
    "text": "synchronization requirement proven mechanism so this is basically tsn cyclic hearing and forwarding adapted to that net and no change to the packet headers uh is one option we can obviously as you saw these uh cycle stuff also put into new headers but we don't need to especially not in the mpls forwarding plane which we already have so makes it a great you know first step uh mechanism where we don't only have all the queuing stuff well worked out but also no packet headers and uh sorry no coffee for it next slide okay how do we do it as i said cyclic q and forwarding from tsn well proven understood meets all the requirement except for number five uh has a very high clock synchronization accuracy requirement um because it synchronizes on nanosecond clock which we don't and the throughput for that stuff goes quickly down to zero when you have a network path longer than let's say two kilometers on the typical parameters so with tagging we're synchronizing based on attack in the packet header which we need three values at minimum so that would be mpls encoding three values of the traffic class field this is in the draft um and the validation that we've done is based on 100 gigabit fpga three four years ago production routers with additional qs fpga and that was deployed in a 2000 kilometer network in china across uh multiple parties uh to validate that this is running fine and as i said proposed since then um but obviously not on the charter so always waiting in some way not deterministic queue next slide okay so this is i'm going to skip this right so this is the mechanism this is when we ever discussed the details of the technology next slide so what did we change uh since uh 113. so we added a reference to the 2021 published research paper um that is showing all the gory details based on"
  },
  {
    "startTime": "01:10:01",
    "text": "lot easier to do a lot of timing validation in the simulation this is an ifip conference which means there is no paywall the url is here um and we edit the text and forwarding pseudo code for the ingress operation when you get your tuple flow and you do per five type of flow and queuing into this non-perf low forwarding mechanism the way the spec is written this is all uh done uh based on textual plus pseudocode i come from a multicast work where also a lot of rfcs in multicast routing have been defined on pseudocode i preferred over some of this diffserv behavioral description that we've seen in diffserv so that's you know for us to decide how we write these texts and that's very simple right every flow just has a certain amount of configured bits that it can enqueue into every cycle has to be larger than a single packet of course um and the pure code explains that um and then i added more implementation deployment validation considerations for high speed implementations for network with different speed links so next slide so i think uh you know from what i think we want to we need to achieve in a draft to actually get to a point where we can approve uh build and deploy it it's functionally complete obviously you know not a lot of review done um the uh shutter puts it uh into scope i think as i said um it can be done with existing packet headers because we just need a few values for the tag in each header mpls is what we've defined if we put it into dscp we can do it for ip but we may not have you know worked out all the net service stuff in the architecture by itself which is trying to tunnel it over mpls at this point in time that might be an additional text and then of course yeah how do we want to structure this stuff i was talking with ishan in vienna and he was saying maybe separate out the mechanism independent of the tagging in in mpls or dscp or so um"
  },
  {
    "startTime": "01:12:00",
    "text": "but that might be an informational document so i was in the first place trying to go what's the minimum one document has the mpls in it we do an add-on document in tsvwg.net for dscp so that's all structure in the end i think would be great if we could do an adoption call right this is uniquely different from all the other things that are being brought in right now because i think it hits all the check marks of you know high speed validation being around long being derived from proven tsn technology and you know meeting all the requirements that i could have ever think of and written down in a requirements document so thank you thank you for leaving time for questions we have a few people in queue uh thank you for uh reviving this reusing just from a basic stuff using the existing data print mechanism simplifies any deployment because trying to bring any new forwarding mechanism into the data plane puts in a very long cycle before we can see any results that can be put into commercial offerings it's mostly an itf issue right because the real challenge of all the qs we're doing is some form of fpga to do really cool new dead net queuing right so but if we can use something that is already in there and it does have to be fpgas already in the asic then if you're lucky if you have an ethernet switch that is tsn based maybe that makes it a lot easier yes there are there are ones available that are commercially available so that's the we've been trying to look into this with p4 and we're still struggling with the you know it's on the p4 tsn switch okay there are taiwanese vendors that are providing you broadcom with the functionality that you're looking for and they even give you the ptp if it's needed so they are so if if this gets adopted there is commercial hardware available that where this could be uh implemented"
  },
  {
    "startTime": "01:14:10",
    "text": "please go ahead with your comment question let's move to david david please all right well it's uh good blood loaded question what's the scope yes sorry wait a minute did we get shafu on yeah the sake of traffic from a multiple incoming interface so assuming that the world is traffic i expected to be sent in a single cycle at the same time the problem is how to ensure that the sum of this traffic we know that you can see that the maximum number of bids that can be sent in a single cycle if it exceeds is it any compensation schema by t circa f can we take the question to the list because i think it's really hard to understand you here so it would be great and i'll answer immediately thank you loaded question um what's the scope of this um you know i would say replace tsn but obviously we want to start with the you know where the network becomes larger where tsn doesn't work well right so this could ask a different question um how many administrative domains sorry how many administrative domains and who knows the answer let's see if you know it too right the answer is one okay so i have good news for you you do not need tsvwgs permission to go forward"
  },
  {
    "startTime": "01:16:01",
    "text": "here within a single administrative domain dscps are generally usable at the operator's discretion it might be worth talking a little bit to tcwg about how to select some dhcps will cause less trouble but you don't need to drive a full diff server that's good yeah you're right so i think dan is going to come to the mic and say you know it allows you to reuse the existing formats and there's going to be huge value in that and then we should move to the next person to allow them okay [Laughter] so next up is how and i uh thanks uh so i just realized this one actually possibly would be best to put before a tallest presentation so it basically talks about the similar thing but it gives a little bit of background and reasoning why uh this kind of tagging or the or the cycle id would be required in order to enhance the cqf but this one is more focused on the ipv6 data plane rather than mps so let me try to control to move the slides yeah yeah i just realized that yeah so a quick quick quickly try to refresh the memory we have the fundamental cqf which was defined by ieee and i'm not going to touch the details of it here but basically the fundamental cqf is has two buffer port and the input up and output was swapped once every cycle time tc so this cycle time sorry cycle interval tc is very important and also"
  },
  {
    "startTime": "01:18:00",
    "text": "as given by the working group document bounding latency we it has been shown that the minimum end-to-end latency and max maximum end-to-end latency basically are determined by the cycle interval tc and the number of hops of course here we have at that time terminology defined i'll revisit this later but in the fundamental cqf the uh the that time dt value is really small so basically it can be ignitable so that gives very attractive simplicity features from cqf um which means it's simple that it gives the simple simple calculable latency bound which only relevant to the cycle interval tc and number of hubs and also it gives the simple maintainers those are the attractive uh features that people want to consider it for the wider deployment and we are also seeing that the cqf has the potential for the wider deployment when we talk about the wider deployment basically we're thinking about four at least four four features to be supported which are labeled as one two four under the first bullet namely they are the smaller end-to-end latency bound the second one is a larger number of hubs the third one is longer links which means the longer propagation delay and the first one is the larger processing time variance because we are expecting on the different node types will be will be put as the intermediate nodes such as different uh switches or routers from different vendors or even some of the layer layer one equipment which are not visible at the layer to a layer three layer so i recall that the secure latency bound are only relevant to the number of"
  },
  {
    "startTime": "01:20:01",
    "text": "hops and times and and the cycle interval so uh when we talk about these four requirements the first two we are thinking that naturally can be supported by the higher speed links so there is a there is a hard requirement that for each of the cycle it has to at least support a maximum size packet which is normally 100 1500 bytes so look at the table here it basically gives when the link bandwidth increases we can achieve the smaller cycle time in order to uh send one maximum size packet so that gives the potential that the cycle interval can be decreasing from a few hundred micros a millisecond to a few milliseconds sorry a few microseconds so uh so we are seeing that the potentials for uh for the item one and two uh basically can be achieved so let's let's talk about um item three and four which are the longer links and the longer time variance so if we look at the fundamental to buffer cqf we are thinking that it can support the requirement three and four but it will encounter the low utilization issue so here we want to revisit the that time uh which imposed by the fundamental cqf which is uh in the red box here uh we can see that basically that that time is is a time to be put normally at the end of a cycle it's the last byte the the purpose of it is to make sure that the last byte sent by the node a in the cycle i minus 1 has to be ready for sending at the next node which is node b here before the next cycle which"
  },
  {
    "startTime": "01:22:02",
    "text": "is cycle i here so basically the dead time should be at least the sum of the maximum propagation delay between two neighbors plus the maximum processing delay at the next node and also the um and also some of the other time variants for example like the clock shifting something like that so the the the longer the propagation or the processing delay the larger the dt so if we want to achieve the lower end-to-end band lower end-to-end boundary latency that means we have to use the lower uh cycle interval so that basically means that that time will eat up the cycle interval when the when the cycle interval is small so that's that's why we see that the low utilization uh here by the fundamental cqf and uh the secure variant is introduced actually it's not a brand new idea it has been brought brought up from time to time so here we indicated here the cqf as a three buffer so the three buffer works in rotation manner so it's a straightforward variant to the fundamental two buffer the configuration is very similar and the logic can be easily deduced from the fundamental to buffer cqf we don't think there is a rigid requirement to produce a new standard and it is quite it is in general is feasible but when we take a closer look at the cqf variant we find out that there is there is a time ambiguity window exists as there as the uh the the the diagram at the left show we see that there is a processing time window here it swells because we want to support the larger processing time variance with the"
  },
  {
    "startTime": "01:24:01",
    "text": "increasing of the time variance we can see the the degree of the swelling is is more severe so the time ambiguity window would exist for two consecutive cycles from the node a so which is here is a little bit smaller i guess but if you can see it there is a ambiguity window here so basically uh the larger the time variance or the smaller the that time the larger will be the ambiguity window here and remember that in the cqf normally we need to preset a time demarcation to differentiate the packets from two consecutive cycles then in here it it would be in impractical because the blue dashed line if we said here that it looks like for the case one the green and the red uh packets which are from different cycles from node a they are perfectly demarcated however maybe for the next round uh there there would be again ambiguity the the leftmost red uh box here will be wrongly identified as the green one actually so a simple and a straight way out is to let the packet carry the cycle id as the metadata at the output to help the downstream node to determine which one is the correct buffer to put it in i think i'm running out of time yeah yeah so uh so here uh we have showed the packet of ipv basics of option format but i don't think that's the most important one um we want to select the feedback to see whether people think that the right way to address the ambiguity issue in order to facilitate the increasing demand to use cqf and these variants in the wider deployment and also we want to study the feedback and also from chairs if we want"
  },
  {
    "startTime": "01:26:01",
    "text": "to define ib basic options uh whether and how to collaborate other working groups yeah i think it would be good to try to collaborate with those others who are working on similar topic and we'll have to continue discussing this and other solutions in the group oh seven we seem to be having a problem with the slide so we're going to uh skip to uh just and we'll find it okay i think we're having trouble with your slides just hold on one moment yes we have it now it's coming [Music] forwarding the following updates first modify some amount for each of the reading that is"
  },
  {
    "startTime": "01:28:01",
    "text": "under deny it changes to plunder root residence time attitude the world time change to actually residence time accumulated division change to accumulate the residence time iteration and the second further inaugurator and the scenario of partial upgrade so for motivations of this document is that uh deadnet defines the goals of deterministic the routine the body that legit packet loss ratio out of all the neighborhood uh use resource reservation explicit routine under service protection to achieve these goals well resource resolution is the basis of ensuring bounding the deleted and ultimately depends on the queue mechanism of the floating plane the issues of candidate mechanisms for large scale packet network cbs and ats come with a high latency values because uh the minimum latest is not affected by the this mechanism uh seeker is quite challenging because it requires time of synchronization uh anyway the maybe some other uh seeker for best violence uh to widen it use the priority based uh scheme make it but a very generic test but with worst case latency so this document proposed an enhancement"
  },
  {
    "startTime": "01:30:00",
    "text": "scheme of people to adaptively adjust the sending authority according to the planned time and uniformly conceived bonded delegate so this is uh uh our way of the the total scheme uh we introduced another mechanism using cool that struck here 39 kills uh violence of pq and are also based on priority scheduling world 39 qs has haha tdl attributes a staggered follow me on the decreasing with the positive of the timer i uh the third and accuracy 0 has the highest priority after the authorization time for sending it is the tdl will be reversed to the maximum initial volume the 39q with ctd090 has a normal priority if interval mode all profibusing probability for anthem mode the former can be involved in scheduling rather later canada the following is a simple example of terminology it contains a photonical so how to put the package to 2009 cruiser first get the data information of the packet many including the planned residence time and the accumulated residence time of devastation this information can be get from a pocket itself or figure entry or policy entry please refer to a deny option in six month working group second put the packet in the specific data queue"
  },
  {
    "startTime": "01:32:00",
    "text": "we need to compute the allowable skill in italy it is close to the planned residence time plus the accumulated resistance time modulation minus the infinite forwarding delay the falling figure shows that two packs is a hard product to the technicals so traffic localization and shipping traffic regulation and ui interface to ensure that the bandwidth consumption or for service recent capacity interval complies with serious traffic specification for example data rate underneath we should do bandwidth management for multiple sources for unsourced finding should meet the sum of data rate of each sales must be less than the broadband values other social market management will be provided in native wishes traffic shipping is performed on an eye to distribute the packets into 39 kills the following figure shoot that six packets follow the same deterministic service are received on the ui port assuming that the arrival at the outgoing port one by one after internal the forwarding delay each packet we enter the key with the tdl value consistent with the alarm excluding the delay q"
  },
  {
    "startTime": "01:34:01",
    "text": "of the packet that is current time for punching upgraded scenario a detonator person may consist of several upgraded bottom nodes for example r1 r2 r3 r4 and the traditional sp path in the domain sp path should contain field hopes with the worst case latency hope given by the paper as the latency the legacy device in the sp path does not support the deadlines goodness and may or not mercy and insert the data information in the package uh the former recorder does not even knows and the native according to our awareness internal mode is similar to sp latency however compared with sp the borderline consecutive package by ternary information other than traffic class that means our partners will not always experience the worst in the failures delay i will hope the effect of anthem mode is similar to seeker for all traffic dumping the packet will be delayed and the board in order to achieve the jitter target so what's the benefits for this enhanced scheme of course the timer synchronization is another required before networking knows i'll operate based on the relative time stays the flow all flow aggregate is not required for deployment a particular multiplexing base is an enhancement of pq scheduling algorithm easy to upgrade each node"
  },
  {
    "startTime": "01:36:00",
    "text": "can independently set authorization timer of the data locals based on self-port bandwidth and support partial upgrade for scalability a single set of dynamic queues support the multiple levels of residence time kills with a higher max maximum material can be created incrementally according to services for performance good achieved control just a single authorization time any questions on the comments section uh we're sort of out of time so i know torlas is in cuba no wasn't cordless was someone in queue and then left i bet you left thank you so we really don't have time i'd like to discuss this more on the list if you can take your comment there would appreciate it and with that the last person on this particular topic is uh okay we got one moment okay i see the slide uh this is fanyang from huawei and i'll present this the net enhancement plane let's see if i can flip yeah uh here's the simple logic that uh while we have this uh draft uh first according to the net architecture then that is required to support bond latency and right now we see there are already uh several mechanisms proposed in data to support the boundary latency so in the short in the short feature that people envision that that net data plan should be enhanced to support the latency which is which is specific um"
  },
  {
    "startTime": "01:38:00",
    "text": "specifically at at the moment the latest specific specific metadata and to meet the goals of supporting the minimal and maximum end-to-end latency in date plane in that data plane that uh the one that net specific uh metadata flow id is used to identify the net net flow but however there is a there's no other metadata defined to support the end to end lattice latency so we see there is a missing in the net data plane and also there are also other requirements to then that data plane that defined in this requirement to the large scale than that draft and including the functions the functions uh including the explicit inclusion of the metadata and also compatibility uh to different underlying network and network technologies etc so to meet the goals uh and the requirements to uh to support the boundary latency that there there there have been several mechanisms that proposed to them that to solve this to support the boundary latency and we list the mechanisms here on the left and um we think that if there are more mechanism proposed it should be added to this list but of course we think that it should be accepted acknowledged by uh then that first so we have in this drafted we propose a new net specific metadata which is called monthly latency information and it is used to it is used to be carried in data plane to facilitate that that that net transit node to support the boundary latency transmission and as we as it's shown in"
  },
  {
    "startTime": "01:40:00",
    "text": "this figure that this bounded latency information is transmitted across multiple than net transit node and used by the deadnet forwarding sub-layer and this page discussed the design principles first we think that this bounded latency information should be carried in is targeted to be carried in the data plane to help the deadline flow to map to the forwarding and scheduling resources uh which the that net flow requires this funding latency information doesn't focus on the local mechanisms which equipment equipment uses and second we think it we believe it is good to have a uniform format to accommodate the the different uh underlying technologies or mechanisms there are two reasons for the for it one is inter interoperability um to have different to have separate uh format for each uh mechanism uh obviously obviously doesn't help the interoperability and second is this creative consideration if there is uh if there is an equipment with non-standard algorithm inserted into network this boundary latency information should help the equipment either drop the packet or transmit without processing the packet and uh according to the analysis uh to the mechanism that in previous uh shown in perez uh previous slide and we we we classified this boundary latency information into two categories and and they are shown in the in these two tables below the requirement category summarizes the requirement from the data services and"
  },
  {
    "startTime": "01:42:02",
    "text": "local and the equipment will use this requirement information to map to those resources and the the resource resource category actually is is more straightforward it's more straightforward and indicate the local resources directly and in this boundary latency information data field that we use um bri type to it to represent or indicate the type of the boundary latency information if there are more and if there are there is new um algorithm that's accepted by then that and if the if the boundary license information is different from the what we have to in the in this table that um it will be added as a new about the latency information type and the format actually it indicates the both the format and the lines of the body latency information and for the flag currently we don't have any uh definition for this flag it is reserved for the food for future study i think and about the latest information carries the actual information used in data plane um for app basics based uh then that data playing that we define a new ipv6 extension header option called vra option and this bri option can be encapsulated in either ibra6 however help or the oh extended header depending on the processing uh behavior and we uh the there could be more than one monthly latest information appear in one bri option so similar to acquire 6 based that net data plane that in npr's based that net"
  },
  {
    "startTime": "01:44:02",
    "text": "data plane a new nprc extension header called the bri extension header is defined and the the processing uh behavior and how to use it is very similar to to the to the processing in ipv6 and also this bri information can encapsulate it in nps over udpip based then that data plane and next step we would like to have more discussions on this on this bri data field and we want to hear the comments and stencils from working group thank you greg and i'll note there's a bunch of people behind you so try not to go on too long all right um what's the benefit of having this bli information both as hub by hop and end to end option in ipv6 yeah actually if you look at the um the yeah the detailed design definition about the bri type and we have the different types of the uh we have different types of the bri uh body latency information uh some of these uh some of this type can is and some of them some of them some of the bri from bli is used um is used in the hobby help scenario and some of them actually can be used by uh can be can be processed by the the destination node so that key so in in that's in that case it is better"
  },
  {
    "startTime": "01:46:01",
    "text": "to be placed in the ho ho in the destination option header yes and it's like what happens if a particular uh hub uh spends more time than it's allowed back it gets dropped the response go to the list that's a good question i'm interested in the answer too but you have a few people behind you running out of time uh so uh fan did you hear the question yeah yeah yeah yeah we can get it to the list yeah all right daniel the benefits to carries and the delay budgets in the discipline when actually the transit node makes a forwarding and routing decision based on specific resource type or and the the specific uh mechanism such as the equivalent types what what is what is the benefit to to take this kind of energy and the requirements that the bond needs to say i'm not sure i could quite catch the question but here that we define a format and this format can be placed in in hobby hub or or at the end uh doh so this information can be um can be played um can be processed either by help either either hope i or at the end destination um so so it depends on the on the algorithm that other requirements uh from of the algorithms i'm not sure i quite catch the question but maybe you can uh come back to list for more discussion here i'm i'm not sure the the i answered it okay i post the questions"
  },
  {
    "startTime": "01:48:02",
    "text": "okay thank you okay thank you and um before robin asks this question i'm going to put up a show start a show of hands i i put in the chat that this was coming basically we should keep in mind that our new milestone is is to get a uh a requirements document adopted so with that in mind i'm gonna start this show of hands while uh robin continues uh asking questions on uh this the same draft so this this is uh the question is independent of what's being presented right now it's on the requirements draft that was actually presented at the last meeting and referenced earlier today so thank you robin go ahead okay hello we think you have an audio problem group go ahead maybe a little bit louder if you hear him fan if you could just reproduce repeat the question uh because we can't hear okay so dhruv go ahead please uh while robin is coming let me ask a quick question my question is maybe to the working group and the chairs also we have uh two documents from that net on pc agenda and we had uh the documents on enhanced net in spring as well as in bgp so idr so wanted to i think from this meeting i realized that this is very early work i think you guys are still sorting things out uh but just so that other working groups can catch on if clear requirements can come in while you guys are developing that from the protocols uh what are the clear requirements that you would have and the terminology because right now we were seeing that even the terms used in the documents were very very different and it was a"
  },
  {
    "startTime": "01:50:00",
    "text": "little difficult uh to fill things out so just a request for the working group uh uh think about that as well uh when you are developing this thank you so i think you're saying you really want this requirements document that we're talking about uh at the moment with the the poll so you really want to exactly already uh complete and include a terminology section that we use across our our solutions is that correct crew thank you thanks for raising it much better no no i'm just making sure i i heard you correctly so um we have uh like the numbers if i look at them we have uh 67 who are on meet echo uh we have participation which is a little better than half and we have about half who've read the document so you know we we clearly need uh uh people to take a look at this document if you have authored one of the proposed solutions take a look to see if your solution fits into the requirements that and i think drew brought up a great point about language about terminology see if the terms you want to use are in the document and start sending comments to the list we really would like to mature the requirements document to the point where we can uh accept it as a working group document hopefully even before the next meeting we had hoped to do it before this meeting the iesg took a little longer to give us a new charter but we have that now and we really want to start moving out uh get the requirements in there and then start getting some of the uh the solutions there um with that uh robin are you still are you able to see he's okay now he's okay sorry uh in fact either quick comments uh jamming from huawei in fact in my opinion we should not expose the q implementation information"
  },
  {
    "startTime": "01:52:00",
    "text": "in the network layer and the ip layer so based on this thinking we think we need the requirement information or some this the resource id to indicate the specific process for each node that's my comment okay thank you very much and with that we're actually switching topics and i believe it's carlos and carlos you're going to squeeze down to eight minutes sorry no problem thanks i probably will be even faster so i encountered another preset in uh draft on behalf of my quarters allen would have myself next please basically well they are here and we already have a presentation in still showing the uh yeah i have no idea how to get rid of it no i did it already i did the dismiss uh already that's a good idea [Laughter] if you know how to get rid of the poles [Music] okay so thank you so the idea here is that uh we have been dead in that role mostly even though the architecture and the service model supports multi-domain we have been more or less focused on single domain aspects so we don't have any explicit discussion on multi-domain here we i'm just copying the the service model diagram from the rc so the idea is to basically try to study and analyze what could be needed to be done to support multi-domain"
  },
  {
    "startTime": "01:54:00",
    "text": "that's the idea to identify potential gaps and if there are gaps then discuss whether we need to do some additional work in the working group or not this discussion started at the raw and then in an interim we basically we thought i got the the request or the suggestion to move the discussion to attend it as this belongs more to the net discussion this next slide next slide i'm sorry so there are different scenarios where we need to have multi-domain support where we have for example one host connected to a domain that is connected to a different administrative domain and uh there is another uh host there there may be i mean i in the draft we list some use cases potentially that where we where this may happen one important qualification is that by domain we need administrative domain and or technology domain so we may have a wire domain connected to a wireless domain and this is also multi-domain even if those two domains belong or are managed by the same administrative domain so as i mentioned the goal is to explore what are the potential gaps in the architecture or mechanisms control plane data plane and then if there are to identify potential solutions next slide please so the the draft is very simple at this point we basically try to identify some very high level things where we need to take a look from the application control and network planes so an application plane and then that document we have this user area which is the application the entity that is interacting with the the user and the operator and performing the net uh the request for the net services and if we consider a multi-domain deployment that user agent may be aware or unaware that there is multiple domains if it's a word that could take care of the negotiation of the different services to the each of the different domains but if he's unaware of the monthly domain"
  },
  {
    "startTime": "01:56:00",
    "text": "then we will have to rely on the network to transparently take care of this next slide please can you have a good question it's just a very simple one multi-domain is within a single enterprise or or between multiple enterprises that's a very big that's a very big issue which one are you just focusing on this single enterprise multi-domain or multi-domain in general multiple enterprises both are in a scope at this point but is to be discussed i mean yeah there are different problems different complexity here is the accident defining gaps not going into the solution so then we have the control plane which is according to the definition in the document the aggregation the control matching planes and we have the cpf the control and plane function and at that level again if we consider a multi-domain environment or deployment the cpfc in a different domain may need to interact for example to discover an authentication negotiate and depending on the application on the multi-support multi-domain support by the application layer we may need to do different things at the control controller plane again very high level but these are the type of things that we need to get into an additional row may be may maybe bring in additional gaps that's also the discussion we are having in rowing the different uh draft regarding to the pce coordination that may be required as well in a multi-domain environment next slide and again the same type of high-level analysis on the network data plane in a multi-domain environment nodes belonging to different planes may have to exchange information and there may be potential need for protocol translation or abstractions a different domain might not be using or offering the same capabilities because they are for example different technologies and the same thing oem protocols may also need to be extended to support multi-domain operation as another example performing pre-offer period across multiple domains may also pose additional challenges that's the knowledge"
  },
  {
    "startTime": "01:58:00",
    "text": "of the different domains may not be available at the one domain and the data planes may be also different or very different capabilities and the last last slide please so again here the the idea is to present this problem initial work very initial work there are some gaps high level gaps identifier identified and uh to discuss or to get your feedback on whether this is something interesting to work in the working group and if so please join us in the mailing list and offline we will be happy to take more people on board oh god that's loud rick taylor uh speaking of my raw chair hat on we would like this work to begin in debt net so if it's we'd like the the resolution to start at that net and then raw to build on whatever happens in debit but personally i support this thanks the there is a multi-domain coordination needed but based on my experience dealing with the enterprises and then some multi-domain coordination that we have from the internet i would like this work to be focused for intra enterprise for a single let's say overall administrative domain and they can have multiple sub-domains because i believe this work would get them too much too diluted and uh by keeping precise for the enterprise because the the that net use cases are very much applied for intra enterprise network so that would be supporting this work that will likely focus for within a single enterprise yeah so maybe split it halfway so i think we'll only have one round of you know"
  },
  {
    "startTime": "02:00:01",
    "text": "improving forwarding planes so um you know we have options that don't require it but hopefully we'll get to one option and then it would be good which takes longer right but which would be good to be sure that we know all the candidates of what needs to be in the data packet header even if maybe we don't know all the interdomain stuff but we feel very strongly that some you know forwarding plane stuff is required there so and then the whole solution i would agree kind of uh build it later okay uh doorless are you saying you wanna have a wider scope or more narrow scope i was trying to say it halfway right so i'm saying well i mean well what did it have the cake and eat it too so no no wait a second so so very short term i think no forwarding plane header changes then we have one option i think for each of the forwarding planes to come up with a great new header right and either we figure out we make it extensible or we're safe that we don't need to extend that header for for example inter domain case right so if if the parameters we need for intel domain we also feel safely we need them intra domain we don't have a problem if we feel there are parameters we need for interdomain we're not sure about them we'll have a problem if it's just control plane we can push it out all right so thank you for the comment work no we're actually uh out of uh time um i was in queue so i'll make the comment it's actually a chair comment i'll point out that you brought up controller plane changes the controller plane document is still an active working group document there is no reason why you cannot suggest text about multi-domain that should be included in the controller claim document immediately so please don't wait don't you don't have to you know worry about adoption of your document just take text that's appropriate and suggest to the list that it be incorporated in the open working"
  },
  {
    "startTime": "02:02:01",
    "text": "group document so thank you for the topic really appreciate it uh thank you all for a really good session and we appreciate all the contribution and look forward to seeing you all uh virtually or physically in the uh next meeting and a special thanks to all who participated remotely you should yes"
  }
]
