[
  {
    "startTime": "00:00:04",
    "text": "town we\u0027re here for a week Patrick it\u0027s going alright is 9:01 good morning welcome to HDTV this if you don\u0027t intend to be in each this you should risk it reconsider that thought because this is the this is the right place to be in my opinion Chris is gonna help us out scribe in its gonna do it right in the ether pad if other people want to help him this is his first time describing and thank you for that sir if other people want to help them that would be great as well before we get going we need one jabber relay I have accidentally omitted this in the past as a major chair faux pas so I do need someone to volunteer to do to jabber anyone jabber jabber alright excellent thank you David alright so we are set on that the blue sheets pass them out Mark\u0027s gonna pass up the blue sheets okay this is the note well note it well it is day two so you have seen it before but these are the is the first meeting of the day so we\u0027ll call your attention these are the general rules that govern your participation in this meeting and all means this week if you haven\u0027t seen it and feel free to come talk to your chairs or your ad we\u0027ve got a Lexie sitting there in the second row I\u0027m sure he\u0027d love to talk to you about the note well I just wanna point out I didn\u0027t choose that typeface or color I like high contrast fonts we will get to the agenda here in in a moment here is "
  },
  {
    "startTime": "00:03:04",
    "text": "there\u0027s an agenda of these slides for both today and for Thursday as you see the both of the work today is in discussion discussing HTTP core and it\u0027s issueless I have made one change to the agenda last night that with the consent of the group I would like to bring forward and that is sort of a Leo\u0027s liaison activity with DNS op they\u0027re talking about a new record type that addresses the cname issue that often impacts HTTP implementations so that\u0027s still an individual draft but they did talk about that a little bit in DNS off yesterday and so we\u0027ve invited its offer rate Bellis over here is Kyle aid agreed to join us so if everyone\u0027s okay with spending you know three minutes or so I mean that may be one question from the floor I\u0027m just to make everyone aware of the work that\u0027s going on there so they can discuss how that interacts with you know their products and their needs so that being said we\u0027re going to make comments on today\u0027s agenda new additions and subtractions to that addition okay we have we have no objections so that\u0027s great so how are we doing on bootstrap we got jabber we got minutes we have those blue sheets we have added a new co-chair which is great but he is chairing a different working group at this moment so time time Johnny day and you can tell that he was that it so reasonably that we didn\u0027t manage to make that conflict in terms of the agenda and we should know just for you know work product of the working group since we last met in Montreal we have two new RFC\u0027s 84 41 which is bootstrapping age WebSockets over HTTP 2 and RFC 8470 dealing with early data and zero RTT and HTTP so thank you all to all of those authors for making that happen and there are two others that are in the hands of the is G going through a couple little bit of a blast call and ad requests on those so with that being said this is Ray Bela talked about his draft I got slides here somewhere there we go Thank You Patrick so yeah rev Ellis I see kind of Dennis head but also programmer web programmer all sorts of stuff so I was at the site meeting we had in Montreal on the HTTP avi group there I thought was a very useful meeting good next slide please and as a result of that but somewhat belatedly I put together a draft on Saturday which was published about a minute after the submission window got open again saw a minute pass one on sorry a minute past midnight on Sunday morning and this is a draft or a resource record that is specifically designed to allow web browsers to find "
  },
  {
    "startTime": "00:06:05",
    "text": "content without going through a cname record and specifically this also addresses the problem of the fact we can\u0027t put a cname at the apex of a domain name so there\u0027s an example there yet example.com in HTTP and then pointing off to a CDN host we heard at that side meeting that there are various issues there so V which is why the HTTP community hasn\u0027t embraced that my hope is that this would satisfy the requires to the community but Northpoint it\u0027s very very easy to invent on the dns side of things there have been some other proposals that specifically a name which add very very difficult complicated changes to DNS servers both at recursively and the authoritative layer and yet this bright time and we\u0027re actually trying to simplify the DNS protocol also called DNS camel you know the thing that breaks the camel\u0027s back so it\u0027s a record where if you\u0027ve got sorry the recursive server can optionally return the a in the quad a records that are associate with an HTTP record so there\u0027s opportunity for minimizing the maratti T to the server it works Legionnaire subnet so if you\u0027ve got CD ends that are doing geolocation yeah it\u0027s putting the resolution of the geo-located records and thright passed those infrastructure IDs in a recursive layer next like this so I should touch on this already but basically there is no way as far as I can see to fix the scene of the apex problem without massively complicating the DNS protocol and even then proposals that do that aren\u0027t gonna work very well with Jukka geolocation CD ends the downside and this is why we obviously need to talk about this here is that ultimate this would require a small change to the resolution code within web browsers at the moment you\u0027re typically off from using something else by name we\u0027ll get a drone foe this is a different resource record type so it\u0027s not gonna be resolved all with that but I believe that ultimately the only way to fix this problem though afford is for the DNS community to move towards you guys and the web community to move towards us and come up with something that\u0027s architecturally sound and optimal and thank you for your time we can take like one one comment right from the floor so Mike Bishop Akamai we already have on the HTTP side alt service that provides kind of cname like behavior and we separately have a draft for putting an old service record in the DNS can you comment on how you see this as being different or better I see this is being essentially the primary service I\u0027ve read the Health Service drafters to be honest from somebody who\u0027s not yeah "
  },
  {
    "startTime": "00:09:06",
    "text": "an expert in HTTP protocol is a play to see how it fits on that initial look up how to actually find the first possible web content it\u0027s simply deploy for something from the DNS side of things because it\u0027s just a domain name that\u0027s the only field that\u0027s in there but yeah all right thank you man you know whatever interest there is ray you know mingle amongst er yes please yeah I would love to hear for our particular from browser developers what you would see is the impediments technical or otherwise to deploying list in your browser\u0027s because we know it we done the DNS and we know the Dinesen that this particular part of DNS is the right place to put it compared to other admits are hacky ways of getting around the problem but we need to meet in the middle somewhere and this I think is the right pressure donut thank you thank you and I think it\u0027s certainly in scope of little discussion of this you know on the it should be business they folks want to do that I think it\u0027s certainly in scope so we move on to HTTP core I mean Julian are you with us remotely are you there I don\u0027t see there actually so Marc I think you may be delivering the slides or would Roy like to deliver the slides Roy you can walk yourself into the queue if you like to deliver the slides hello Roy so can you hear me try that one more time can you hear me ooh that\u0027s not sounding good one more time well thank you for joining us check in with you later okay there isn\u0027t much to the slides next slide please so we had a burst of activity in September October and we introduced a new set of drafts if you\u0027re interested the change notes are in the bottom of each of those drafts and of course they\u0027re gifts as well and from the page next slide Julian\u0027s been chucking away at the errata so currently we have 27 valid errata 14 were verified 9 health update and 4 were reported so far we\u0027ve addressed at 20 address 22 of those there are five that are still open and they\u0027re all mapped to different issues on github and we have a separate a Status page which is cool next slide yeah so on github we have around 80 "
  },
  {
    "startTime": "00:12:08",
    "text": "issues up and right now as mentioned 34 are those were for a rad I know five of those are still open and 51 are editorial with 33 of those closed that\u0027s the home page where we keep the issues and all the the stuff what we\u0027ve done for this meeting is labeled I think on the order of yeah 14 yeah 14 issues with the discussed label and so the plan is just to go and work through those those are ones that we felt we needed input from the working group to make some progress if you have other issues there on the issues list you\u0027d like to discuss we can talk about those too or if you have issues that aren\u0027t on the issues lists we can get them on there make sense you\u0027re out of slides all right I\u0027m gonna slides thank you for prepared preparing the slides Julian and sleep well I might since I need to consult the actual issues list I might just move down here and the mic there is no pink box if there\u0027s no paint box does that mean everyone\u0027s on camera I think that\u0027s a yes thank you did everyone get the blue sheets oh we\u0027ve got a couple just thank you this is good I feel like I\u0027ve got my coffee and my mic I\u0027m on radio all right so should we start this where would you like to start let\u0027s start at the top let\u0027s start with issue 138 so this is in the cache and specification cache control private and no cache have taken optional argument you can actually provide a list of header field names that is used to modify the semantics of those directives so for example cache control private and then a list of headers means that you can actually cache that in a shared cache as long as those headers are kept specific to one user so they\u0027re kept private and and I pointed out that this isn\u0027t widely implemented I don\u0027t think it\u0027s implemented by any browser Roy pointed out very recently while we slept here in lovely Thailand that Apache HTTP D implements those directives and so I guess the question is if we have you know an existence proof that it has been implemented maybe we should keep it in there maybe we shouldn\u0027t but I wanted to get a sense of the working group of whether people thought that it was you know in the in the last round of HTTP in the in the cache in spec we noted that these things were not widely used they fall back to the generic same semantics if an implementation doesn\u0027t support them do we want to go further than that excuse me so right now in the section 5 "
  },
  {
    "startTime": "00:15:10",
    "text": "2 to 2 we say 4 4 no cache we say at the very bottom no cache response directives with field names are often handled by caches as if an unqualified no cache director was received ie the special handling for the qualified form is not widely any other thoughts on this I I didn\u0027t know that mod cash supported this oh hello Julian did you join me buddy no he\u0027s uh he\u0027s like a presenter okay he heard me hello Julie he is awake good I love having to learn a new IRC client for every meeting okay fair enough [Music] so Roy uh if you want to channel through ever since the audio didn\u0027t seem to be working too well mm-hmm I\u0027m guessing you would not like to change anything here is that correct correct he says correct he says yeah yeah I think given that new information we either have to make a decision to pull it out and then make you know Apache non-conforming or leave it at is I don\u0027t think we can really modify the language anymore um so I think probably close this with no action is the right way forward and are you gonna record these names I\u0027m trying to record them yeah but I\u0027m not gonna log into github on the Chromebook yeah why wouldn\u0027t you do that okay let\u0027s move on then all right next one 129 request cache control directives and I think we know the way forward on this I just want to make sure that everyone understands right now there\u0027s a must in the cache and document that says that you must honor request cache control directive so if a client sends cache controller no store you have to honor that as part of the caching algorithm in practice no one does that browser caches don\u0027t pay attention to it at all most CD ends actually probably all see the ends by default don\u0027t pay attention to it our reverse proxies don\u0027t and Ford proxies sometimes do and sometimes don\u0027t and so the suggestion here is is that we shouldn\u0027t be paying attention to the requiring cache implementations to pay attention to this and Roy I think gave some feedback again while we slept and I think I think yeah that should be okay with him so the proposal here excuse me is to downgrade the strength of request cache-control directors probably did not have a requirement level at all just say it\u0027s an advisory thing from the client and the client can choose whether or not sorry the cash can choose whether or not to honor them and Bruce has I work best when everyone sleeps okay so my I\u0027ve never seen anyone presented and channel jebra at the same time you may be yeah break it break me I know it\u0027s good um David looks relieved so does that make "
  },
  {
    "startTime": "00:18:12",
    "text": "sense to everyone to not make this a firm requirement they\u0027re just advisory and Roy I think was talking and I agreed that you might want to we might want have some text about how it\u0027s good to have a cache be able to be put in a mode where it can pay attention to them because in some cases it might be desirable but it doesn\u0027t make sense to do this by default for a lot of folks you push back okay good next up is issue 128 quoted cache control directives again in the caching spec so last time around we had a discussion around this 472 to 34 where the cache control syntax in an ideal world it would be generic in that you could take the quoted or the uncoated form which is a pattern that I know Julian especially has been trying to pursue in most of the specs but a lot of implementations didn\u0027t support the quoted form and so we in 72 34 said that senders should not generate it in the quoted form but must accept it and what I\u0027m wondering here in this issue is should we further codify current practice and say you know you should not generate it that way and or sorry you must not generate that way and you may accept it and I\u0027m seeing on jabber roy says it is much harder to say that at the quoted form is an error in validating past implementations than it is to say should not that\u0027s a fair point all right you want to try talking again making a feel like I\u0027m talking myself a lot so we could partially hear you boy we\u0027ll see what happens this time not a big change there I\u0027m African sometimes it takes 20 seconds or so they\u0027re awfully saying good now you sound good so talk to us about quotes and cache-control directives oh I was just saying that what Marcus said that the yeah if if we if we say they must not send it than we\u0027re saying that existing HTTP systems are no longer compliant and in theory they have to all go out go out and change that code which doesn\u0027t make any sense to me right creating a new air conditioner effectively yeah okay um since you\u0027re against this and since joins against this and I don\u0027t hear anybody in the room jumping up and down I\u0027m happy to "
  },
  {
    "startTime": "00:21:13",
    "text": "close this with no action yes it wouldn\u0027t do it and you and Roy are both speaking it\u0027s great thank you for joining us Julian if we think that implementations are broken visual trace box and spree cop the links to the box and the tickets is anyone in the room is anyone in the room aware that their implementation generates these quoted values I\u0027ll be concerned about us raising this to a new level that\u0027s not the sole determining question but that would be interesting if someone stood up and said for five years I\u0027ve been doing this so I I think we can you know I I have a test suite both for browser cache conformance and for intermediary cache conformance I can I forget what the results are for this particular test but I can bring that information back and see you know how much what task we have in front of ourselves I I guess the only if we came to a place where we understood that no cache or were very few implementations supported the courted form then I could see you know making armond yeah we really should just roll it out but I don\u0027t think we\u0027re there yet I think Interop is kind of 50/50 ish if I remember correctly on browser caches at least yeah and this doesn\u0027t come up as a common source of Interop pain doesn\u0027t it depends I mean the problem is is that if it causes someone pain we\u0027re probably not going to hear about it it\u0027s hard to debug right now I just get default freshness behavior yeah whatever that might be so are you still favoring closing with no action or leaving it open and you\u0027ve gained accuracy actually item to gather a little data on it and if the data isn\u0027t it\u0027s conclusive unhappy close with the auction so next up is status codes and caching Julian says my theory that is that parsers that fail in this will fail on other things as well this could be Julian the mic is still open for you so you can just so you speak as necessary I did I didn\u0027t press the button for him last time you talked okay so issue 120 status codes and caching so in RFC 7230 4 we said that a response can\u0027t be stored if the cache doesn\u0027t understand its status code so in other words if you know status code for nine one is sent to a cash and that cash "
  },
  {
    "startTime": "00:24:16",
    "text": "hasn\u0027t been written to know what the semantics that stats could are then it can\u0027t store it on disk and we had I did a little digging on this we had a discussion in the lead-up to that we said that there\u0027s a link in the issue if you follow it to a discussion of åland least a fairly brief one I think and I think the path we took was probably the wrong one in that our current approach makes it very hard to deploy new status codes that are cacheable if I wanted to you know define a for nine one status code and say that you know you can cache it if you want to it\u0027s not that it\u0027s you know casual by default even if I put cache control headers on that response by the spec a cache can\u0027t storage which seems to add quite a bit of friction to introducing new status codes and so I would say that if a response contains cache control headers even if it\u0027s status code isn\u0027t recognized if by all other counts and we have a lot of different criteria if that response can be cached why should the cache washing the generic hash Dart so Roy asks again whilst we sleep slept what\u0027s the problem we\u0027re trying to fix I think the promo trying to fix is make sure that we\u0027re not introducing a necessary friction against the introduction of new status codes when we need to do that yeah I guess the problem comes with the issue of when you introduce the new status code like 206 which is likely to carry cache control information that\u0027s it\u0027s assumed that the client understands in addition to the processing required for 206 how where\u0027s the trade-off there I get I agree that you know it\u0027s not ideal that we have difficulty caching or a new status code without understanding the status code but on the other hand status codes aren\u0027t that frequently updated and they\u0027re pretty much never something you want to cache to begin with when they are updated yeah and I remember that from the discussion that we had I mean you know the way I look at it right now 206 wasn\u0027t exactly a thrilling success it\u0027s caused a lot of problems so maybe we should just avoid doing that like Mike Bishop so I think the thread that you posted convinced me that we probably should allow catching bees and I think if we have something that shouldn\u0027t be catchable like say a 421 the right place "
  },
  {
    "startTime": "00:27:16",
    "text": "to enforce that is to say if you and if you omit the status code you must say cache control most or just explicitly include it on the server side where we know it\u0027s understood well you wouldn\u0027t have to do that in that if it doesn\u0027t have any caching information and it\u0027s not known by the cache to be cashable by default then the cache can\u0027t store it so you don\u0027t have to make an explicit no store but what Roy\u0027s concerned about is if we have one of these weirds test codes like two SEC\u0027s where it\u0027s it\u0027s you know carrying metadata that\u0027s intended for not this message caching made it enough for this message as a response body but for a synthetic that our terminology around this still sucks for something that you\u0027re combining with or or modifying and then it applies to that and that was the case in 206 I personally I think that that\u0027s probably not a great design pattern for us to emulate in future status guys the important I was entertained caching information that had to be communicated to the cache at the same time it was trying not to be cached by another otherwise unknown recipient so it\u0027s difficult for it to contain something that says like no cache what I was thinking is that you could define a new exciting cache parameter that says like cache like 200 or whatever where you can say that well if there is a cache control cache like 200 then then clearly you\u0027ve been you\u0027ve told to clients that you can cache it like 200 yeah that\u0027s a solution but I wouldn\u0027t say I like it yeah I hear what you\u0027re saying this one\u0027s ok to cache even if you don\u0027t understand it my kind of cache control directive yeah but then how long do you have to admit that for and yeah I\u0027m happy to kind of let this one simmer for a bit longer anybody else have any thoughts all right we will summarize the conclusion is no conclusion so next up is 111 header terminology we\u0027ve had a back and forth discussion about this new issue for a little while yeah I agree with you Roy that I don\u0027t want a bike shed this or paint the shed in the meeting but I do want input and then I think I I brought this up for the same reason that you point out I would love to have other folks input on this I don\u0027t want it to just be me and Roy and Julian coming up with these these terms you know we have this you know what\u0027s "
  },
  {
    "startTime": "00:30:16",
    "text": "the difference in the headers complete value and had her you know one line in in a header block and an individual that value and a list based header field and one thing I added which I\u0027d like to get some further input on is you know it\u0027s very common in in use outside this working group to just call it a header and indeed sometimes in this working group and we have in the specs we require you to use the phrase header field which I always found a bit clunky Aleksey is it the mike um yes in email space latest email definition document says we don\u0027t use header we use header field and had theirs had their block and various other things so it recommends not to use just single header anywhere so yeah I think it might be better to invent new in your terms we\u0027re about to hear the reason for that I suspect from people the speed um the reason for that is because there was a period of time in some Docs or header referred to the block yes right instead of the line and yeah it was just easier to make up new magic words sure we do have like in 7540 we\u0027ve got whole frames they\u0027re just called headers the notion that they contain a plural of header is not that odd to me you know and having like rewritten inspects where I colloquial refer to things those headers and people correctly you know say you need to say header field there my conclusion is that is like consistent with our naming but it does not actually make the document more readable it makes it actually harder to read yeah Mike Bishop I will point out that we now have beverage from the email case because in h2 each pack and q pack header block is the output of the compression process so fine we\u0027re not in the same space okay yeah so when we were doing the editorial pass on the HQ doc I actually wrote on my whiteboard kind of a message header and body header fields at her block trying to figure out exactly where all the terminology went it makes sense once you draw it out but it\u0027s not immediately obvious just from reading the box yeah so I think we can do a cleanup and probably a you know if folks can chip in on the issue what they think about you know different proposals for me the high order bit and what makes this really different from email is is that no offense but it\u0027s not like there are millions of developers around the world who are minting and using male header "
  },
  {
    "startTime": "00:33:17",
    "text": "fields I can\u0027t hear you yeah I don\u0027t think this statement is true so right anyway well let\u0027s not get into a contest with the email about you know who has more developers but in in in the HTTP developer community it is the by far the most common terminology is just to call it a header and if we want to meet that community and make our documents more readable and more usable for them personally I think we should probably use the terminology that\u0027s most widely in use does anyone find that controversial does anyone want to stand up and say we should really continue calling them header fields Julian are you still awake okay Julian says but we\u0027ll make no further comment now he said me and Inge ever so well told some oh we have a lot of documents that call them head of fields I guess you\u0027re gonna have to make some sort of acknowledgement of the fact that we used to call them out of fields in this process but otherwise oh yeah people call them hitters and it\u0027s just annoying talking field Mike Bishop honestly I think the easiest thing to do is consistency with the existing knocks but maybe for readability sake and acknowledging that we will always slip up somewhere in some document is just to note that they are colloquially called headers and if you see that that\u0027s what it means well I think one option is that you know core is a you know Restatement of 72 38 X right and so it can be consistent with header field and we\u0027re also defining the fact that this term is interchangeable semantically with header and then we can you know in other documents that are just a strict Restatement of 7230 we can you know a lot of these of ever right okay should we move on to the next step okay well let\u0027s see I think there is actually the other part of the ticket where you talk about value or header fields that allowed multiple instances or single instance which allows repetition this is probably more interesting the other one is more of a bike shed this one I think right it\u0027s more interesting to settle on some terminology I just wanted to get a sense of the room as to what color of the two possible colors that particular issue if there\u0027s leaning in the room and I think we\u0027ve done that good Chikara one argument for you "
  },
  {
    "startTime": "00:36:18",
    "text": "keeping the header field is that when I read it I explicitly know that it means about key and by a name and value and if it\u0027s just had their this there is some ambiguity can you explain my time take us well if I just just written I mean do you think it applies to just the name if you say header just yeah now you might be one of the other right okay I think what we\u0027ll probably do is is try and chuck away at a terminology list in that issue and bring back the group 415 and except I\u0027m not sure why we have discuss on this we discussed this in Montreal and I think we forgot to take the discussed label off of it because in Montreal we said their support for doing this but take it to the list and yeah we didn\u0027t take so discuss label off so we can move on to the next one was there any list discussion no not yet so this is basically expanding could be for 15 - yeah hey - number 45 here or used to long sorry no yeah go on - 45 that\u0027s fine so we have this syntax for parameters that is specific to media types I believe and it is referenced yes in six one one of core semantics right now and it is referenced from other places as a generic a bit of syntax and the question I think the proposal on the table here is to make that a separate section so that it\u0027s clear that when you reference that syntax you\u0027re also referencing the implied semantics of how you parse it so that these different forms are indeed equivalent it\u0027s not just you know you\u0027re not just literally referencing the syntax does that make enough sense I think this was your assure originally Martin yeah so I think Julianne answered the question well enough I\u0027m not sure that the document answers the question well enough currently but I think that\u0027s that\u0027s a part of what you\u0027re talking about here might make the section make sure that\u0027s very clear what it what what it means to reference that section and then yeah I don\u0027t really care what the "
  },
  {
    "startTime": "00:39:19",
    "text": "answer is as long as it\u0027s written down uh checking for feedback no the jabber channel is happy alright the hetero registry issue 42 um we discussed in dispatch so we discussed this in Montreal and we agreed that it was worth having a chat with it but we needed to take it to dispatch I took it to dispatch yesterday there wasn\u0027t any pushback in that room so now we\u0027re bringing it back here I have a draft of how I think the registry should run it\u0027s patterned on how we\u0027ve set up the link header relation sorry the link relation registry as well as the well-known URI registry fairly lightweight so I\u0027m not gonna go through that here because it\u0027s it\u0027s a relatively new document but I wanted to point people to it so we can start that discussion Pete you had a comment Pete Resnick so I bumped into a Michelle on the way out and she said what what\u0027s going on and I said don\u0027t worry about it um one of the things that that conversation sort of developed was separate out how you want things to work from this perspective from how they implemented on the back end because whether they keep it all in one database that\u0027s viewed separately here we don\u0027t care yeah I think but we want to have procedures that we can input stuff separately we don\u0027t have to go through those general sure yeah to follow up on this and Michelle was saying she will investigate whether they can have multiple views since you talked to us back saying you know whatever it c is for them that\u0027s fine and I don\u0027t think that we should go into any of that of how it\u0027s presented or that sort of stuff we will enter that pain for the link relation registry so let\u0027s not do it again okay so that\u0027s just a heads up on that one yeah I mean I will say you know just sort of as as chair I think that\u0027s like a very helpful thing when composing our documents was we\u0027ve had a bit of confusion about what all these headers mean I think this is gonna be a good good change so Roy says plus one and should we also talk about reorganizing the registries in general Roy can you speak to each other what I mean is that the that their registries that we have misses and wraps right now if you look through them you\u0027ll see that each one has a different style of title and a different location in the Ayana database some of them under a directory related to HTTP and some of them elsewhere it "
  },
  {
    "startTime": "00:42:19",
    "text": "would be nice if we just had fun HTTP subdirectory of Vienna that you know had that consistent set of titles for the registries and I\u0027m wondering if we should just do that editorial Asia as an instruction for Anna to fix that\u0027s why we\u0027re done with these drafts Alex he actually I can speak on on this typically documents don\u0027t say the structure IANA always ask and you can don\u0027t actually need a document to tell Ayane that you want to restructure it you can just talk to me or talk directly to I and I say you know can you you know move these pages over there there they usually very responsive to this we\u0027d like to put the URLs and documents I think this up Toya and I whatever the current policy is because I think it has changed in the past and I\u0027m not entirely sure where it lands now whether they\u0027re happy for the URLs or I suggest you after you talk to Ariana I know it\u0027s gonna show this week I think but in principle I think I agree with Roy that if if we can harmonize the titles and the URLs and then and that statement of that you know the framing of the different registries that would be a good thing I don\u0027t think it\u0027ll cause any harm as long as we have the proper redirection place yes you might have the that\u0027s what I was thinking you might have to preserve the old URLs in case you know and especially if they\u0027re referencing documents already who knows well and I was thinking about whether renaming them would be bad or not and I you know if the only place that the registry name is gonna be referenced is gonna be in the IANA considerations section of a document and if the documents already published and that I in a considerations is already executed so it shouldn\u0027t be an issue even if we rename them I don\u0027t think but let me talk to Michelle yeah okay so we don\u0027t need a new core issue dealing with that right that\u0027s a um beyond the core really there well potentially no it\u0027s not really the document if you can could we open an issue just so that I don\u0027t forget sure who\u0027s gonna affect more than core it\u0027s really every document with a registration but actually next up is Oh Mike just curious mark on your document that reorganizes that pulls out the header field registry is it is the intent to publish that very quickly as separate RFC or just know what core yeah that\u0027s just a suggestion for what it would look like if we put it in our to open it yeah yeah that was a let started in life a long time ago as a separate document before we started core and then we started court it was like out well we start a core issue 38 so we put this on "
  },
  {
    "startTime": "00:45:25",
    "text": "the discuss list we talked about this I think in Montreal and there was support for trying and I have an action to go and do a strawman for this which I still it\u0027s a good idea Roy you said seems reasonable but we\u0027re at the top of the three accession yes that is where I think it probably should go at least until it looks like it shouldn\u0027t go there we put this in because we had the discussion on the list about the confusion around redirects for certain kinds of clients especially in this case I think HLS and other livestreaming and and my takeaway from that and I may be misunderstanding things but my takeaway from that was that the people reading the documents were confused about you know there being some linkage between the resource that created a request and then the resource that you actually fetched the content from when you when you execute a redirect you know just because clients automatically follow redirects doesn\u0027t mean that there is a an effect on the base URL for that second request and I think that this confusion is caused for the by the same phenomenon that we see sometimes in content encoding where just because clients a lot of clients automatically up you know apply content do kind of negotiation for encoding and then remove the encoding doesn\u0027t mean that it\u0027s not a separate entity that it\u0027s a separate response and so if we can clarify that I think at the top of 3 xx section and say that when you you know make a redirect you know if it\u0027s automatically followed that\u0027s fine but you know things like the base URL and everything else still apply for as a first-class request the redirected request and I think that that could be incorporated in the text we\u0027re talking about in this issue pretty easily now am i talking gibberish ooh does that make someone that sense so Julian\u0027s now in the queue I guess he can\u0027t just talk anymore so Roy I\u0027m gonna have to bump the out to let Julian in but you can get back in queue I guess I just thought it would be more friendly to raise my hand it was a boy off the line I do not disagree with the proposed change but I disagree that just helps in any way was the - issue that was mentioned because that issue is just because the people did not understand the difference between a URI and the resource identified by the URI so I think their problem is very easily explained that we need to find out why they\u0027ve failed to understand that footing a URI into an HTML document that mean that document that the resource identified by the URI is embedded in the HTML document that\u0027s what they thought and that\u0027s of course rubbish so I\u0027m fine with adding more "
  },
  {
    "startTime": "00:48:29",
    "text": "text to redirect handling but that wouldn\u0027t have helped them at all okay so maybe we need to draw it at conversation a bit more than I didn\u0027t I didn\u0027t get that from that is Ori who actually introduced this issue to the list a couple days ago available I was a little confused on please join my clan help us understand I so am orphan German so um this issue came up in the meeting over streaming video Alliance um it seems like there are multiple issues with many many clients not following in or not following a direct that\u0027s that\u0027s a different issue but not properly resolving relative references that is being read from playlist or the manifest files after redirect and from talking with different Syrians and and that\u0027s using HTTP redirect for CDN for video is is very commonly used and talking with several phidian\u0027s it seems that they had a lot of issues with different clients and most of the time when trying to resolve that client the software developers are just saying that they are following the RFC as it is and the problem is with the RFC and not with their implementation and that\u0027s what we are trying to resolve here is to understand what what is the correct understanding of how you resolve reference relative references from the thread and especially from the inputs from Julian it seems that after when a manifest for or an MPD file is being requested through a URI it doesn\u0027t really matter where do your I came from because the URI itself is the file the manifest file base URI is the retrieval URI and then anything that comes afterwards should result according to that so if that\u0027s the case I think that some clarification either in the original HTTP or through our document could be in place and then we can start working working with our players software to fix it so the question is is do we have consensus that that\u0027s really the right interpretation of the RFC so I have not heard an alternative interpretation does anyone well why\u0027d you wanna get that thank you yeah here we go yep so Roy fielding already near me I\u0027ll give it 20 seconds right Yap can you hear me now okay so this is actually defined by RFC 3986 the your ear I spec not by HTTP and second to that is the the specification for the media type itself so that in this case "
  },
  {
    "startTime": "00:51:30",
    "text": "that\u0027s the I guess HTTP Live Streaming RFC so as appealing as it might be to add more text about that to the HCP RFC it doesn\u0027t actually we don\u0027t actually define that behavior it\u0027s part of the way how your eyes are defined but we can still add additional information to the spec explaining how we expect redirects to work but the issue of what is the base URL that\u0027s already handled by the other specs yeah speaking individually ie I agree that\u0027s true but in the name of readability you know when this issue came up you know I\u0027m like oh I just need to cite and then like I had a 20-minute slot conversation with mark trying to figure out what to cite so I think you know a little annotation here of you know you know no must level language or anything we\u0027re just a little helpful information you might I\u0027d give us more consistent implementations which is what we\u0027re going for here with core right so okay if no one else has anything and they will move into the next issue again then I\u0027m sure that you need yeah wait wait for the Raja latest test hello that\u0027s their arm the issue that was raised here what happened what\u0027s fly without any redirect as well because the confusion is about what is the base URI for the content of a manifest file reference from HTML so even if there is no redirect that would be confusion about that unless you realized that that it\u0027s the URL of the manifest file so the issue is about whether something that your reference from an HTML page is embedded or not and it\u0027s not embedded if it\u0027s only the you\u0027re right it would be embedded it would if it would be a data of your life but that is not the case here so adding text to redirect is can\u0027t help but wouldn\u0027t solve this issue okay so next up we have number 34 which should be an interesting one we have suggested to use the URL standard from the what working group for the location header [Music] so Roy commented again whilst we slept I just looked oh it\u0027s pretty clear that location is a URI reference anything else is not interoperable the problem with double hash and redirects is because it isn\u0027t allowed in ER a reference and is commonly removed for interrupt not just by browsers the other wiki concerns were already addressed by the last revision so does anybody have "
  },
  {
    "startTime": "00:54:30",
    "text": "any thoughts on this one right now I think we reference RFC 3986 the suggestion here is to change that to reference the URL standard or I suppose put some explanatory text you can also look at that right I\u0027ll wait for it perhaps you could cite mary had a little lamb of lamb okay I know you said good yeah no fucking way that we\u0027re going to replace this with replaced 3986 with how do you\u0027re all spec aside from the fact that it\u0027s not a standard can\u0027t become a standard by declaring itself to be a standard it\u0027s just not how the world works it\u0027s not a suitable reference for the for the ITF and in any case it isn\u0027t correct so it\u0027s not going to be a replacement but that doesn\u0027t mean we can\u0027t learn from it you learn a great deal from it but in this case the location header field itself if you test all the five exciting browsers you\u0027ll you might get consistency in how you handle the location but you know of course HTTP isn\u0027t protocol for just the five browsers and the reality is even in that the the error reporting that that was being discussed on the I think it was the Mozilla issue reporting system was that that in fact a piece of soccer that uses a double hash sign forage for its identifier doesn\u0027t work very well because one of the hash hashes across hatcheries is by the internal software within the referencing of this both the browser and the reason it does that is because historically the euros have never allowed more than one hash in the string it was a very fixed hard requirement it goes way way back to two Timbers these original drafts so you know that indicates to me that it\u0027s not interoperable to use more than one hash in an identifier that\u0027s what we\u0027re trying to get with the specs is what is interoperable not anything else so I will attempt channel on ax which is an interesting experience I think that that the reasoning here is that because location headers are arguably under control of a broader set of authors all I think that\u0027s may be debatable you need to have better more crisply to find error handling and URL offers that I\u0027m "
  },
  {
    "startTime": "00:57:36",
    "text": "not saying that\u0027s my argument but that\u0027s what I understand to be the argument does anyone in the room have any warm thoughts about doing this I see a lot of people looking at their laptops which is you know I know I\u0027m gonna IDF meeting now that\u0027s good okay something like the sense of the discussion in the room such as is to close with no action see if Ana pushes back I think the most I could personally justify would be referencing the URL standard not normatively but informatively and say by the way there\u0027s this thing over here that tells you how to do their handling if you\u0027re interested but I don\u0027t hear anybody supporting that I see some shrugging shoulders that\u0027s that\u0027s progress I think that would be a strange reference if it were only scope to location matter we want to add location header that says how we should deal with vectors that are not allowed in the your I reference a bayonet you know that\u0027s fine that\u0027s that\u0027s just a normal error handling I\u0027m just saying as as a the grammar the grammar that we use is okay if you follow this grammar it\u0027s going to be an interoperable that\u0027s the intent of the interoperable standards if you stay within the grammar you\u0027re good but if you go outside the grammar it doesn\u0027t mean that you didn\u0027t receive the characters it just means that the that it\u0027s not a valid message but you still have to deal with the valid message and it\u0027s perfectly reasonable to add text to describe what you should deal with in that situation Mike Mike Fisher so it sends I don\u0027t know the what working group URL spec and terribly well but it sounds like the biggest thing they\u0027re dealing with is percent-encoding things that otherwise wouldn\u0027t be allowed is that reasonable uh if you\u0027re familiar with what working group respects they they use an algorithmic approach it\u0027s a specification so it\u0027s quite detailed in terms of do this do that and you know you get into this state and so forth and so on yeah so I\u0027m wondering if maybe we just beefed up some text about you\u0027re allowed to present in code things that otherwise couldn\u0027t occur here and that\u0027s okay yes so we\u0027ve heard a little to what working group is still crazy okay so this has come up in a couple different ways is there support for adding a bit of text about error handling for a location URLs and I think when we started the core work one of the things we said we would look at is when something has security or interoperability impact but "
  },
  {
    "startTime": "01:00:36",
    "text": "especially security impact we\u0027d look at tightening up things like error handling to make sure that that we meet again at that and I think there\u0027s an assertion I don\u0027t know that Donna\u0027s made this assertion in the past that location handling can be a security issue now what do people feel about that so here\u0027s one that for a resolution drafted and see if this captures what we\u0027ve been talking about maybe people can comment on that this proposal isn\u0027t compatible beyond browser scope URI reference is required however to do add some non normative advice about the grammar and error handling noting that you still have to deal with valid incoming messages instead of summary my only concern here is is that defining that error handling in any depth is not a trivial in that\u0027ll work well I think that\u0027s the non-normative hand-waving that okay so next up is issue 13 field name syntax I think we talked yeah we talked about this in Montreal we had a fair amount of interest there\u0027s been a bit of back and forth this may be one where we forgot to take the discuss label off again but I think it\u0027s towards highlighting here for folks this is not a trivial change it\u0027s it\u0027s further restricting the field name syntax we\u0027ve seemed like we were pretty enthusiastic about this in my recollection in Montreal are we still okay with this okay sure on a push back in the issue but in fact that all browsers support headers with a wider character range doesn\u0027t seem to be relevant here yeah London told some I don\u0027t think there\u0027s any need to use that to make the decision here yeah I think there will be implementations that\u0027s a support the entire grammar permitted by the RFC\u0027s some of them may even commit other things we don\u0027t have to oh we can constrain that the range that\u0027s safe Chikara just for the record nginx by default this allows underscore for "
  },
  {
    "startTime": "01:03:36",
    "text": "example because then it treats it the same as - for terms of internal the ambiguity yes yeah that\u0027s a good point and I expect and that\u0027s the same it\u0027s using a CGI and stuff like that so - is translated to understands a lot of languages there\u0027s a lot of star I don\u0027t think so that\u0027s a good point actually I put in an underscore there just because I thought there might be some headers out there that use it but that ambiguity is not good so maybe we should disallow underscore as well I suspect that anyone doing the environment variable CGI thing is going to be rewriting that one yeah rewriting that the - to the underscore in there yeah weird things happen I imagine her right I mean - is uncontroversial underscore I think you\u0027ve got a good point period it\u0027s got to be used out there somewhere it doesn\u0027t seem to harmful periods used a lot in mail I don\u0027t know if that translates into the wave I haven\u0027t seen it I haven\u0027t seen it much but I suspect it\u0027s out there - yeah and Plus seems like it might be handy to keep around for for some purposes perhaps what do you have to achieve with Plus I don\u0027t know maybe uh maybe I put it in there just because we use it in things like media types is a kind of an escape valve but maybe we don\u0027t need it I mean with with two non digit non alpha characters you can do the whole by 64 thing anyway so my mouth we don\u0027t need the padding character as well yeah um I\u0027m tempted to say maybe just - period digit an alpha plus it\u0027s the new X - thanks for that fields that begin with HTTP - we should disallow that\u0027s a good point Roy and I\u0027m wondering I I think maybe one of the reasons I kept this open was if we want to go one step further we could require field names to start with a digit or alpha not allow them to start with a - or or a period yes I suspect that\u0027s kind of that would trip up again in a number of implementations and those places where you you dump these things into environment variables that\u0027s gonna cause some surprises for instance yeah I\u0027m yeah pretty comfortable this because by and large people just stick to digit alpha and - so yeah you\u0027re gonna say start with digit alpha or start with alpha one of those - I\u0027m not sure which yeah and what about end me there are a "
  },
  {
    "startTime": "01:06:39",
    "text": "bunch of rules in in languages that that these things are gonna get mapped to that suggest that the end also matters think about it are we adding too much complexity here I\u0027m not sure just pick a set of rules and write it down tell us yeah yeah okay all right that\u0027s good guidance thank you it\u0027s freaking cold in here so hmm no yes [Music] apart from the actual set of characters that you want to allow or disallow what is the plan about what we do with that restriction do we change the a a B and F do we just add what advice not to produce them I\u0027m not here about what the normative changed I thought we were just talking about the registry other than okay thank you so another thing we need to do the whole obsolete whitespace thing that we had previously with the BNF where we have sort of the the Blessed BNF and the sort of please don\u0027t look at this pmf I think that\u0027s just simply registry rules yeah I think if we just changed the BNF and the registry rules and then implementations can decide whether they\u0027re comfortable rejecting messages with those characters or not I know that some laughs will be out there and grab onto it immediately so to be clear we\u0027re talking about changing the BNF changing the registry rules but not but but probably putting some pros in next to the BNF that says that there\u0027s a wider range of characters you you know like anything you can choose to consume you know or what arrange characters if you want to that make sense actually now I\u0027m no I\u0027m more confused Julian just take a deep breath kasa five and do it again three that\u0027s better so is this purely about registration or is that about what we can put on the wire because I just have a issue the issue is clearly about registration we can talk about something more than that but the issue is clearly scope demonstration well the issues does have the word syntax yeah so so that\u0027s why I\u0027m confused I think it would be confusing if we constrain the registry but didn\u0027t have reflected in the BNF I think that a lot of the value of doing this would be lost because people would not clearly understand you know what the guide rails for the syntax we\u0027re putting down are I think that when we use a B and F in our "
  },
  {
    "startTime": "01:09:39",
    "text": "documents that is what we are documenting as something that is safe to generate and that people who generate other things won\u0027t be interoperable potentially it does not mean that you can\u0027t consumer wider range of input and still interoperate I think that\u0027s asking for trouble aren\u0027t ya lentils and the the concern here is that if someone rejects the entire message based on the presence of a header field that has one that say it has a plus character in it they reject the entire message as a result that\u0027s that\u0027s likely going to cause some surprises and interoperability concerns or worse for adapting the one header hurry so removing that header from from that particular message is not necessarily a problem because if you weren\u0027t expecting to handle that anyway it\u0027s that\u0027s just normal I\u0027m more concerned about the sort of collateral effects sure but we\u0027re not we\u0027re not saying that they have to reject them you know that you must reject a message that doesn\u0027t meet the PMF right right hey having having some understanding of what what what the expectations are around dealing with this would be would be good yep because currently if if someone puts then octet zero in the head of field name that might have the effect of causing the message to go away entirely well a lot of people right now on the Internet if you send something with you know I know an old character in the header that\u0027ll you know very happily shut down the connection right yeah but this is suggestion that plus perhaps could result in shutting down of connections which you know maybe and wider used in the people in this room you know are aware I mean I\u0027m firmly in favor that you know the the registry should reflect best practices here it seems concerning to overreach that hi I guess I\u0027m I\u0027m thinking back to the previous issue about the location header you know we define the syntax people produce the syntax they\u0027re safe if they go outside that while there\u0027s error handling we don\u0027t define that error handling in great detail what\u0027s the difference here the difference that you want to make a change yes is that in this case you want to change the spec one and the other case you didn\u0027t want is change suspect so I think that\u0027s a very huge difference yeah and I think this may be a much bigger segment of the population than you know double hashes and location letters right so if this is the approach we\u0027re gonna take what is the a B and F really mean well I don\u0027t mean the same "
  },
  {
    "startTime": "01:12:39",
    "text": "thing let\u0027s describe performance if we want to disallow selfie characters and header Fiat names we can split the a B and F into something and the obsolete part and clarify that\u0027s why the option B part was bad to use but I think changing what\u0027s allowed in the a B and F for header field names was a really big change that I\u0027d like to understand why we are doing that so we\u0027ve gone to we think this is a good idea to wait a minute what are we doing yeah I mean I think this may cause collateral damage in like existing compliant implementations right just not what we\u0027re trying to do and for the spec and in the section for what to do how to register a field name restrict it further that you\u0027re only allowed to register the following games with Mesnick names that fit this following grammar it for the following reasons so what comes what happens when someone comes up with some great application with a header that that violates that registration constraint and it interrupt rights but they can\u0027t physically register the header yeah that seems like an invitation to have an experimental space and headers Oh exactly so let\u0027s not do that just explain it in the a beam app as well that that well there are a couple different ways you can do it you have ever Cindy baby now that\u0027s different from the setting may be enough but that\u0027s not really very satisfying you\u0027re generally speaking you don\u0027t have any control over what you receive so what you really want is a a an a B enough to just specify what\u0027s the correct thing to send and then on the receive side how do you deal with errors and in this case in most cases most software should already be removing certain characters from the header fields received before they go out to a gateway but when what may not be occurring is the header fields that are handled by is for example custom HTTP servers or modules that don\u0027t have a need to go out to a gateway you can be processed directly yeah effectively they don\u0027t really need any of these requirements these requirements are aren\u0027t necessary for them you know I\u0027m "
  },
  {
    "startTime": "01:15:43",
    "text": "wondering if we can get some information that might help us make this decision kind of flailing around a little bit here first of all what do implementations do in the presence of characters outside of the norm that they lose the message to they lose the that particular line or what and then what characters are actually used in practice and some of us may have the ability to measure those sorts of things I don\u0027t know is it worth it I think the information we would get would be all over the map I think you know we can look at Apache and you know some CD ends and some browsers and stuff and get one answer but then you look at websites that Pro F in front of it and you\u0027ll get very different answers after some recent experiences of graphs I\u0027m very interested in that little world I\u0027m wondering and again with traffic you know we can look at traces for a bunch of web traffic and then suddenly you look at traces for you know people doing API stuff in the backend and spawned some corporate firewall and you\u0027re gonna see something very different I\u0027m wondering if we can maybe just change the a B and F to deprecated some range of characters and then say that you know implementation handling those characters is its implementation specific they can make choices about but but don\u0027t generate it if don\u0027t generate them if you want to be interoperable Android points out in in jabber since none of the standard field to use bad characters things like modsecurity usually just delete the bad field yeah yet Sakura for the record nginx rejects the requests with mother\u0027s name and I\u0027m relieved most of the other proxies resign like if request comes it will get 400 by the request right yeah to do any filtering on responses I don\u0027t know yeah I I am concerned with the laughs industry and related things that if we change this index to you know should not generate that that will result in some second-order effects right for responses I believe it\u0027s gonna be 502 but some gateway but I not gonna wanna see that well it should not generate if they\u0027re actually reading our specs you know they\u0027re not generating the response right they\u0027re handling it and we probably need to communicate that but they\u0027re more clear how it suggests their point of view would be they\u0027re trying to enforce cleanliness on the wire and someone violated this should not "
  },
  {
    "startTime": "01:18:43",
    "text": "generate and therefore you know needs to be reset and if and if someone is phone the advice and not putting weird characters in there header names they won\u0027t have any problems but if the application predates yes HTTP core yes they were following the advice of I I would like the effort of hte core to clarify and increase operability right interoperability and I\u0027m concerned this may have only one of those two impacts right yeah so I guess does the change in degree because if we look at eventually the current set of characters that are allowed field name equals token and token includes dollar sign percents ampersands single quotes star tilde type I mean it\u0027s a pretty broad set of characters do we really want to let you know it\u0027s any V care except the limiters basically right if we were meeting this syntax like of course not you have the question is what do we do now and this gets more to the philosophical level of you know how daring are we going to be in maintaining this protocol along yeah and how does this what level of pain has this cause right now be fixing that so maybe the question is what\u0027s the the minimal thing we can do to improve things here without endangering inner upper ability yeah that\u0027s my take and that\u0027s you know header certainly they had a registry right I think it\u0027s pretty clear that you can do that i I\u0027m concerned about the longer-term effects there that you\u0027re gonna create a situation where headers you can\u0027t get registered even if they are they should be I\u0027m not sure that\u0027s right mechanism and so if they work fine and practice should we be discouraging them well I may be some more research would help if a bunch of apps which for better or worse they\u0027re getting more common out there reject headers that are legal by the a B and F they\u0027re already not interoperable right so the usual had our problem right is this smuggling of through to one gateway or another right mm-hm and so you know like on shell characters you can make a pretty obvious case right of why you would break compatibility because you\u0027re concerned about that maybe we need to sort of find justifications for things to remove from the syntax specifically a character by character all right maybe a little data "
  },
  {
    "startTime": "01:21:56",
    "text": "would help I think maybe not the not uh you know what is the set of things that is done by all implementations but if we can find examples of characters that cause interoperability problems that might help move things forward John phonetics on the registry point you mentioned yesterday in dispatch that it was a expert review so sound that sounds to me like a situation where somebody\u0027s registering something the expert can say do you really need to have this grid character if the answer is yes because we\u0027re using it that\u0027s okay but the expert can say maybe you should try to you know if you\u0027re not already using it you\u0027ll have a pain point here so much you might try something else all right it sounds like you know the advantage of expert review is a lets you play human judgment in case the case basis right and I guess I\u0027m not as interested in the registry approach here because from me the goal the reason this is interesting to talk about is that if we can give a target to things like laughs and other bits of software that you know can reject or or strip headers based upon knowing that you know characters that would be I think a good thing but maybe it\u0027s it\u0027s it\u0027s not something we can do so leave it open take it down the road a little bit okay no consensus not yet 22 there should be fun clarify rules are on half closed TCP connections so so as Brad says in the issue the HTTP RFC is say nothing about the expectations are in half closed TCP connections in practice HP clients don\u0027t shut down there they\u0027re half of things after sending a request but it would be nice to infer some semantics from that wise media Sogeti okay and so I think the suggestion here if you scroll down [Music] Joseph made a case before trying to infer some semantics from you know incoming Finn as an indication of clients loss of interests because then the server can free up resources earlier and the savings are more pronounced when done with responses at trickle information down slowly for example long polling and then talking about you know so advantages for firewalls doing net and stuff or rather interactions with them I think Roy pushed back on that so "
  },
  {
    "startTime": "01:25:01",
    "text": "let\u0027s have this discussion Roy you don\u0027t think that that we can clarify this for it for TCP can you talk a little bit more about what your reasoning is I mean the problem with clarifying we\u0027re not actually defining to TCP as it deals with and TCP may exist the underlying layer or it may be under to your less or or we may be running on top of a different protocol entirely it\u0027s a notion of what half tho so it\u0027s very difficult to describe it in a way that makes sense but it\u0027s also true in general one Thompson one of the recent changes in TLS was that we recognized that half-closed was thing and tell us one 3includes text on this and I think implementations of implement but important that having implemented that implemented across all versions of TLS so we have we can say similar things about TCP and TLS if we do that and I\u0027m not sure it used to be the case so the problem there is that it used to be the case that in TLO so if you closed one half you lost the other half right actually required by the spec practice that was unevenly implemented but now it\u0027s we have different different colors so that\u0027s why you know it\u0027s that down regret convince them text that everything makes sense now I I\u0027m not opposed to putting it in the spec I just don\u0027t know how to do I noticed the comment at the top of the screen here which is basically saying that half cause doesn\u0027t mean anything is that is that a problem so this is this is like a real operational issue I mean the half-closed semantics I agree should be perfectly fine it should be one you should continue to generate the response like it doesn\u0027t mean that the client can\u0027t consume it the problem is in practice what has usually happened is the client has sent a fin and dropped out of the NAT table and now you send a response and you sit there for a very long time timing out on the TCP thing and that is by far and practices what is happening much much more than an actual half-closed which as far as I can tell no one actually does so it creates an operational problem to support this half-closed semantics that no one\u0027s really trying to use that\u0027s kind of the issue Mike Bishop kind of "
  },
  {
    "startTime": "01:28:02",
    "text": "going to Roy\u0027s question of layering I just want to share where I have encountered this issue before which is that and Microsoft\u0027s server-side implementation there was a bug that was incorrectly considering the client to have gone away when the incoming connection was half closed and then aged to layer you was looking at a stream instead of a TCP connection and at the end of the request the stream was half closed and so there was an application that was actually checking is the client still there and the answer was no it\u0027s half closed so and when we fixed that but the fix was to say no actually half closed does not mean the clients not still there so all that to say I think half closed means nothing is probably the right outcome here clarifying question to you Patrick the operational issue you described seems to indicate you might get different behavior for TCP running over v4 and v6 because there\u0027s no NAT table and one of them are you actually seeing that distinction in the data use huh yeah so that isn\u0027t the only case right but it\u0027s gonna be you know if your application just went away will normally generate a reset if everything it\u0027s like fully and then connected but it turns out like a lot of times when you go away you\u0027re not fully and and connected anymore so I\u0027m not sure if there\u0027s a v4 v6 distinction or not in the data but okay thank you suppose anger I\u0027m kind of curious about the use case for this and since that it seems like this could be done with if you wanted to actually close the connection you could do it with connection close as well if you really wanted to like get rid of the connection after the first request was finished processing and modern clients were like we use connections and stuff so why would have close be useful proper you to have such that the client would say hey I\u0027m not interested I\u0027m done my request and I want to close the connection after receiving the response from the server I mean yeah I mean if you have a lot of evidence of that placate of clients like intentionally trying to use half clothes for the you know for for the case that like makes logical sense to us but like haven\u0027t really seen in the field that would be interesting to know like you\u0027ve got an application that does a lot of half-clothed David\u0027s Ganassi Google I think so I don\u0027t think there are any applications that try to do this today because of the operational concerns you mentioned and because there are many servers that yeah they Reno F they just freak out that said I think it would make sense to have guidance there "
  },
  {
    "startTime": "01:31:02",
    "text": "because conceptually you can save resources with this like if your connections sent their request and they know they\u0027re gonna say anymore you can like feel your receive buffers on the server and stuff like that so telling servers you should do the right thing simply hurt right I mean I think like 75 40 tries to make this a better world right with go away and all that kind of thing Eric Kinnear Apple I want a second what Mike is saying is like this makes some sense for HP one but now as we start talking about the later versions where you have the ability to say stop I\u0027m not interested in the response anymore and things are intentionally half-closed a lot of the time it\u0027s worrisome to conflate those issues for people because you don\u0027t always know what this is running over and that could have some really painful and intended consequences so I think having half clothes mean nothing maybe the safer answer even if it\u0027s not as much fun Mike Bishop again I want to kind of build on the comment about the servers being able to reclaim some resources because I I think there\u0027s a distinction there as to what is the right thing to do after a half closed if you see the client has half closed after the request and you say that\u0027s equivalent to sending connection close and the server should not expect to receive any more data and should close the connection after it sends the response that\u0027s entirely consistent and that\u0027s good what the server should not do and what I think this issue was originally raised is assume the client does not want the response and either terminate partway through the response or just not send a response that I think is actively harmful to some plans which plans well I know that there are clients that have closed but I don\u0027t have a list of them so I\u0027m interested in that so I mean I think I agree I mean I think the basis of this issue is that pretend or not pretending but acting with no impact of receiving the half-closed in reality is more indicative of the client having gone away than the client just not intending to send any more data right despite I mean I agree that\u0027s not like the literal interpretation of what it should mean and so I would like to close this issue with you no citations of clients who you know use have closed to mean the other thing yeah in practice they just seem like badly outnumbered so be good to sort of investigate like what they are yeah and it is an ecosystem problem right right and in the interview spec the discussion of connect says even and "
  },
  {
    "startTime": "01:34:03",
    "text": "this is how you have clothes but most servers don\u0027t deal with that well so please don\u0027t do that yeah I think this is strictly an H any action I would want to take would be an h1 TCP specific it would be in the messaging to the h-11 document not the semantics yeah yeah I can ping some people my former employer and see if they know which clients that work all those work that\u0027d be good information next up is issue trailers trailer 16 and I think we have a proposal for this I made a comment proposal in a comment and then Roy you came back and I don\u0027t mind restating that Roy but my head hurts when I read what you wrote so as long as we can make it this on the screen let\u0027s see yeah there we go so as long as we can wordsmith this I\u0027m fine is that okay by you Roy are you still happy with this general direction for this issue that\u0027s just rephrasing to be targeted just at the first sentence I couldn\u0027t get past it maybe because that is the word filled in at too many times I\u0027m not sure okay next up is number 10 onion names so RFC 67 61 noted that applications of which HTTP is one should treat onion names in certain ways when using the DNS and so the question here is whether we need to note that in our documents Android pushed back on this and there\u0027s been a bit of discussion on the issue so be clear when because I also want to reduce clarified and I put the right changes right before me one anything sure as a good editor should see the applicable requirement in sixty seven sixty one is applications "
  },
  {
    "startTime": "01:37:03",
    "text": "that do not implement torch protocol should generate an error on the use of onion onion but should not perform a DNS lookup and that\u0027s to preserve the privacy characteristics of people people using onion don\u0027t want those DNS requests escaping out to the resolver do we need to note this in our documents Pete\u0027s making his way to Mike Paul people speak do you make any mention of special dealing with localhost or any of the other magical special names no then why would you make an exception for this one but I actually think that\u0027s a pretty good suggestion so you know if you want to expand the issue - we should have a pointer in a discussion about reserved names peachy but just onion doesn\u0027t seem like a good choice David\u0027s can ask Google I think in general this like all these reserved names belong in the DNS specs not necessarily here however a short paragraph at security considerations saying double-check this DNS document because if you don\u0027t you could leak privacy could be a sweet spot I guess that makes sense to me the only thing in the back of my mind is onion is for better or worse very special I don\u0027t think they\u0027re gonna mint many more though in this thin the reserved DNS especially use registry so as someone who currently has a draft to add something does a special you mean a mystery okay not necessarily Authority and I\u0027ll point out that the IAB invited people who were considering such things to put them under DARPA so whether they might not be in the top-level domains anymore similar things might be minted under DARPA after that invitation was extended so I actually think that that Pete\u0027s suggestion that making this advice about checking to see what special use names are currently registered and treating them so that they are not presented to the DNS does seem to me like a reasonable sweet spot okay and and and is that what a reference to 67 61 do that trick jeopardy I would really suggest that you write it without reference to sixty seven sixty one because DNS app has tried in multiple times to open and reframe that document they\u0027re not in love with its current framing so referencing it I think will not necessarily get you out of having to describe the current state of play is there anything else we could reference let me think about it but I think you\u0027re gonna have to write the text "
  },
  {
    "startTime": "01:40:05",
    "text": "it\u0027s Ganassi just thinking on the way back to going sit it down I\u0027m gonna completely contradict what I just said sorry sixty seven sixty one puts requirements on like DNS clients and technically HTTP isn\u0027t your most HTTP clients today call into some DNS function maybe it could be implemented in the browser or someone else do but it\u0027s kind of a separate sub module and it\u0027s up to that component to check this so if your HTTP engine makes a query for dot onion it\u0027s up to your DNS component to say hey I don\u0027t have an IP address for this it\u0027s not up to the DNS to the HTTP stack to not make the query of DNS necessarily but so 67 61 you know one of the considerations they have for domain name reservations is number two application software are writers the application software expected to make itself or recognize your names is special so haven\u0027t so oh you\u0027re right my bad so I think you know bright mentions a security consideration I think we might be able to say that there are some application requirements that apply to HTTP those are defined you know by DNS such as sixty seven sixty one right to get you aware of things like the locals things I mean the the data onions back was written thinking of HTTP pH and so it seems a little odd to you know not consider it as a security consideration all right well let\u0027s rough in some text and see how we go with it list that\u0027s all the ones we identified for discussion I have just one or two more I wanted to sink on Roy if you look at number 132 upgrading wiki tags I had oh okay I had a question there someone asked me a question in a private channel that reminded me of a very shady memory that one of the use cases for icky tags was to be able to upgrade them to strongiy tags from the server in a 304 am I miss remembering that do you have anything here that I tried I tried to think of that what I couldn\u0027t figure out whether it was one way or the other I can\u0027t remember I can\u0027t remember whether we you know it explicitly disallowed them or right it\u0027s a long time ago but I remember people have this use case but it reading the current specs you can\u0027t do it so I don\u0027t know if that\u0027s a little bit I "
  },
  {
    "startTime": "01:43:06",
    "text": "think a second resolution time stamp for each generation returns that as a week in tech until that second has elapsed and then upgrades that was wrong attack because then yeah that\u0027s right yeah from gondwana this is this is something that came up just a few weeks ago Cal connects that we ran into issue where you would put a record and you might say either this is the value of it right now but it\u0027s just about to change because the server needs to make some changes to it or the server might not make the changes so we had to reply with a wiki tag because we don\u0027t know immediately whether it\u0027s going to schedule straight away I\u0027m something we\u0027re interested in knowing what gets done here we don\u0027t have any particular opinions on it other than it was really hard for everyone working unit to understand that a strong e tag says the bytes must be absolutely identical and if the server changed the resource without changing the ear tag then intermediate Katia\u0027s would do horrible things and as a user of ice JEP that\u0027s that\u0027s weird so at least for what I talk about in the issue here I think to do something here we need to create an implicit relationship between the strong and weak version of one attack so that they wouldn\u0027t be considered two completely independent things but you know you could upgrade from one of the other is there interest in trying to do that and we need to think through the implications about you know what happens with an implanted implementation that doesn\u0027t support that encounters one of these and so forth and so on from it sounded like that was interested from from bran yeah th egg we use in our server is a sha-1 of the content so that\u0027s that\u0027s going to be the same if the contents to say I\u0027m going to be different if it\u0027s different it\u0027s more that why bother using strongly tags at all hmm was Lister question there and for us it\u0027s it\u0027s the same content or it\u0027s not but strongly tags have that weird confusing property to to people that intermediate cases will do bite range queries and cache bite Rangers and and break in horrible ways so what\u0027s the strong attack by you by train caching yes it went in our case generally it\u0027s it\u0027s private information so we don\u0027t care all right I\u0027m like any other "
  },
  {
    "startTime": "01:46:11",
    "text": "schmuck no um you know I don\u0027t bring something here\u0027s the current term has always been a body that is being written on what I might exerted everything for the week II eat eggs was that you didn\u0027t want to get stuck with a half half correct body forever because if you received it and it changed within the same sex whatever that you received it that you might get stuck with a bad body and but honestly the reality is that that folks have just ignored that over time and would rather deal with the one-in-a-million chance of getting a an override error like that then not have decent magic so that I\u0027m gonna conclude the issues I think so I have two small things about core I\u0027m coral well once correlated one is not that it\u0027s that\u0027s start with a core yeah so I\u0027ve been looking now for a little while at how three oh four is handled in terms of updating cached headers and it looks like there are bugs in many many implementations about this and I\u0027ve been talking with Roy that one an Apache I\u0027ve been looking at CD ends and reverse proxies and how they handle it and this has been one of the longest outstanding bugs for some cash implementations squid I think bug number seven is is this and boy that\u0027s a fun one and in browsers there\u0027s an especially interesting situation where browsers will update a cached response if you get a three or four with the new headers but for strange historical reasons they exempt some headers from that and in particular they exempt a header starting with content dash and X content Dash and X WebKit - and especially the content - one is really interesting because there\u0027s a header called content security policy yay so there\u0027s a case where a customer generates content security policy headers using for example the Apache HDX s mod headers and Apache would not send that header because it ops it out were fixing that and reverse proxies would not update it on the 304 and so they\u0027d serve the old content security policy header trying to get that fixed and browsers would ignore the content security policy header if it ever made it in a 304 to the browser we can do "
  },
  {
    "startTime": "01:49:13",
    "text": "better so I think the the interesting parts for the working group here are I would love to have a chat with browser vendors about this because I\u0027ve got individual bugs opened in the browsers and they\u0027re being very conservative which fair enough but saying that what we did it this way because that browser did it that way and you look at why that browser did it that way and it was cargo bolted from somewhere else so be great to get everybody together and agree on how we\u0027re gonna handle these things as one and if we\u0027re going to exempt certain headers we should document that in the specs for proxies is a lot harder because they really don\u0027t want to update headers on disk for performance reasons I don\u0027t know how to fix that and I don\u0027t know if we need to start advising people not to use three or fours or something else but it seems like it\u0027s a concerning situation so if folks are interested in this please come talk to me I\u0027m gonna top some browser folks about it and try and figure out where I need to go with it but I did I considered a security issue mostly because of content security policy is there a core issue open github is you know coming up just as a place to um actually no I\u0027ll get one open I think at the very least we need to talk about what headers get exempted from a update in 3 or 4 and I think it\u0027s you know h1 connection headers like you know connection and keep alive and stuff but then the question of if brow if proxies aren\u0027t going to update headers on disk where do we go from there they\u0027ve had years and years and years to do it they still don\u0027t do it a lot of them I don\u0027t know how to help that issue and the other thing is Marie do you want to get up and talk for one minute before mirga\u0027s that i just want to close sort of the loop on core and specifically I want to thank mark Julian and Roy for the tremendous amount of work we devoted a whole session to this today and I know it\u0027s not as exciting as Thursday\u0027s agenda of you know shiny new new things but this is important work we\u0027re going to be left with this document for a long time because I for one have no interest in reopening it again so they put out a new set of drafts for this meeting if you haven\u0027t like read the drafts yours file on github it would be great to take you know a read-through of these of the state the hope is by the time we meet again in Prague that we were you know really talking about just a very few things at the end so this is really the right window where you should pay attention if you haven\u0027t done a clean read through knowing that these will be the definitive citations of the semantic layer hgp for the rest of your career you know with that being said and you know no pressure to the editors right and with that being said you know thank you for all the perfidious getting done Murray good morning my name is "
  },
  {
    "startTime": "01:52:14",
    "text": "Murray COO Charlie and I\u0027m working on with some folks at Facebook and indirectly elsewhere to collect some of the security considerations that have to do with compression dictionaries which is a topic that keeps coming up coming up each time it\u0027s been approached I guess we get we go through some spasms about a way we have to make sure we do this safely and securely and make sure that when this comes through all of these potential security issues have been addressed and whoever proposes the work eventually backs off and so I\u0027d rather collect all that information into one place so we can run it as a checklist essentially so that when someone has a dictionary the compression dictionary thing to bring forward they\u0027ve gone through this so they can see this collected wisdom and applied it appropriately so I volunteered to do an informational document collects all of that and do it for the working group I spoke to Nick Sullivan on during the hackathon and he said he would be happy to contribute the folks back at Facebook are willing to contribute so if anybody has something wanna make sure they see in this document please let me know and I guess I can post a draft that\u0027s marked for this working group and you can do a call ideally to just send it how how would you like me to do it a usual way usually so that\u0027s it thank you was that being said I guess we returned a couple minutes early we\u0027ll see you on Thursday "
  }
]