[
  {
    "startTime": "00:00:04",
    "text": "but Matt\u0027s opinion the union is basically memories I\u0027d rather have a new room decision and confirmed on various sub from spectrum variance it\u0027s really hard winning this past summer gets all anything it\u0027s a nice - so are we in the end well and in a time crunch work institution this is a keyboard with one end yeah "
  },
  {
    "startTime": "00:03:06",
    "text": "[Music] okay welcome to the second meeting of the career Oprah and this week and also the last session in this week yeah I think most people have seen all these note words and so on but if you are new to this please read it the objective of today\u0027s meeting was essentially to pick up items that happened this week and that\u0027s why it will be a little bit less organized and a little bit more chaotic then in other parts of the meeting because during an ITF big of course nobody has time to actually create tons of slides and so on so this is the agenda that is on the agenda sheet and we actually have two items we want to add to that which is a really quick discussion hi question a really quick discussion of where we are with resource directory the main resource directory document is in a DV evaluation as we said Wednesday but there is this other resource directory document and we should briefly talk about that so I think we can do that first and the other thing we want to do is pick up the discussion about the Sena mer unit thing but we will only do that when alexei is back from the presentation years to give right now in the Acne working group anything else we shall be doing today we probably do have time at the end so if you have a favorite topic that you always wanted to present or discuss now is the time now I\u0027m not going to give an impromptu presentation about the new SI system that was introduced in May this year okay yeah we\u0027re going to skip that reset surgery "
  },
  {
    "startTime": "00:06:07",
    "text": "just young these are your side\u0027s Wyatt we can see you very well much better what time is it where you are oh five thirty year I can\u0027t quite suppress the comment that you look that way okay so on resourcedirectory next slide please as you mentioned there has been an area we are in AVM generation after working group last call we\u0027ve published three new draft versions during the working group last call period which we are mainly addressing things like clarify this add a bit more detail here or there now Alexa has been as kind as to finish or to do an ad review with that there is next slide please a lot of editorial things that we need to fix and one large question that is the question of the normativity of our ddns st to summarize the what we are saying about in SSD is that it is something that is being worked on and it is one of the ways that you can use to find your resource directory so if you\u0027re in a managed net then you should well it is recommended that you use the Rd AdWords option of neighbor discovery or would use any cast and there is also one of one of the or recommended mechanism is our DTN SSD and the commonwealth at this looks like a normative reference and it should be because right now it is an informative reference so what shall we do about it the status of our DTN SSD is that is being worked on so and Peter Peter refreshed it with all the outcome of the previous discussions but it\u0027s not still not in a state where we can expect to have it published in the next one or two I guess probably longer so having this as a normative reference would slow down the are the TNS of the Rd process quite a bit now the waste the possible ways to go forward here are to set it out which I don\u0027t think we should do to basically "
  },
  {
    "startTime": "00:09:09",
    "text": "convinced Alexey that we don\u0027t want to that that this is really not something that is of normative relevance even though we say there\u0027s one from the recommended options or to remove the recommendation that to use this and just say that there may be other ones that other up other discovery options that will be provided with new documents that could become important as well so that\u0027s that\u0027s the big question for discussion and also the thing where I\u0027d like to ask you for your input on what could we do about this yeah so input please custom woman without a chair head because I require on this document so I missed the chair for this normative references are really bad we made the mistake in our C seven to five true which had a normative reference for what we came RFC seven two five zero which is interesting it has our C number three three numbers below coop so why why was that a problem the problem was that some some random coral in the security area that that was completely without effect on the rearward delayed this document for a year and these things happen so normative reference the significant yes a second let me cut you there for a second we don\u0027t have many takers cause nobody volunteered the beginning won\u0027t one for this I\u0027m taking some yes I want to take it alone sorry so please those of you who are plop tops you could raise your hand your head for a second and and then think about whether you want to take minutes and then raise your hand please Thanks okay so both of you please take minutes this is important because we want to have this is going to the list later so right yeah so now that reference really is a big liability and we should ensure that in situations where we actually need it now these documents were meant to to run synchronously and turned out after wire that person power reasons we couldn\u0027t keep this up so I think it is really useful to maintain that forward reference because yes once the "
  },
  {
    "startTime": "00:12:12",
    "text": "the other document is out it\u0027s probably a good idea to use it but we need to find a way to describe this in such a way that it does not become a normative reference and one way is to say that that there are other ways to do discovery such as and then we do with the environment of reference to the draft and these also should be considered when finding a resource directory so just just to is a reminder we are not talking about service discovery or resource discovery at the mall we are talking about resource directory discovery which is pretty fluffy thing anyway we are not giving very very precise guidance here anyway but we are mostly listing ways this can be done and whether a particular resource directory that is discovered is actually useful in for a node that\u0027s a completely different question and there will be implementation specific considerations that play a role here so I think just pointing to the thing and using language that says this is one way to to configure things I think is the way forward or akarin and two data points um I can second Carsten that normative references can be an issue I have one quarter of a draft in L which has been for years waiting for RP to finish that was maybe a mistake to put I normally reference which was not strictly needed it was nice but it wasn\u0027t strictly needed so would have made sense informative and then on discovery us at large as you mentioned there\u0027s some probably other documents coming on discovery I think you\u0027re spot on on that there\u0027s a lot of discovery discussions ongoing on this pace right now I mean in the web of things on under discovering theories and hackathons many discovery discussions etc so most likely we will have more discovery related documents coming into space in a near future and that\u0027s something maybe take into account here now I\u0027m Stewart Churchill from Apple Carsten you said something that confused me and maybe you can explain you said this reference to our DD n SSD is not "
  },
  {
    "startTime": "00:15:12",
    "text": "about discovering the resources it\u0027s about discovering the directory but that\u0027s not remotely what that document says if you want to discover the directory that is a five minute task we can design that right here you pick a service type pick a unique string red suit with Ayane and then called the API on your platform to say I have a thing it\u0027s called the resource directory and I\u0027m either offering one or I\u0027m looking for one done I\u0027ve just explained everything you need to know to advertise the service and there are a thousand other services that advertise that way but there\u0027s really no if if there\u0027s an internet draft for this it\u0027s not even one page long it says here\u0027s the surface type publish it and search for it what that draft talks about is how you map the resources that would be in a resource directory into their equivalents using TNS service discovery so that you don\u0027t have a resource directory at all so it\u0027s not about discovering the resource directory it\u0027s about making the resource directory unnecessary so I\u0027m not standing here expressing an opinion on either side of that I\u0027m just confused because what you said doesn\u0027t reflect what\u0027s being discussed here I think I can clarify this from here on what we what we had in the resource directory draft are so far was to say that for the link to the resource directory that we are expressing in the discovery as for the resource directory if we the way to express that in our dgn SST is just as if that link were put into a resource directory and that means that all the ways of how is the path encoded in the text record etc we didn\u0027t want to spell out again and in fact we had spelled out wrongly by using and outdated by using by referring to the old way that our DK an SSD did that so yes we could do that but then we would probably pin down the flexibility of our d TN SSD because that is still in the process of deciding a are there subtypes involved or not and how does protocol negotiation fit into that and that is not fully done yet ok so thanks for that explanation that makes sense now my suggestion would be it seems that discovering the resource directory doesn\u0027t need all the full full generality of the subtypes and the text record path and all the other things you are talking about maybe there\u0027s a way forward where you define the subset that\u0027s needed to discover a resource directory and that might be the empty set it might be just here\u0027s a service type registered with Ayana done and and then let the DNS SD "
  },
  {
    "startTime": "00:18:12",
    "text": "resource directory establish the full generality of how other things are encoding because I think if you want to if you want to publish this RFC and have implementations that are discoverable on the network by clients that are looking for one then not saying how to do that leaves people guessing so specify the subset that you need to specify to have a workable solution that would be my recommendation so I gather we\u0027re talking about this paragraph in four good morning yeah a bit further down so here it says that this is described there and if you go to the end of that section a bit up yeah here so those are the three points that are recommended because they were added rather Lake in then there was the question about how how shoot application authors just do this as give some guidance on what to do and not only list options and this is the guidance that was added yeah so what Stewart has proposed would be to take the relevant progress from re DNS St and put them in yes does that make sense procedurally doesn\u0027t make sense from what would actually be in there I\u0027m I\u0027m still I\u0027m not sure whether this will cover all the aspects of protocol negotiation that will that kind of follow from the ARD DNS st mapping so this is there hasn\u0027t been published update to or DG a necessity so what you\u0027re looking at is is not the the very latest version Peter has already removed some of the the old parts in there that are that that we found at EF we\u0027re not really relevant anymore but the way basically the the remaining question that would need to be solved for this to be copy able into Rd is how do we express the the protocol part do we just register a teen SST service type that says and this always unconditionally goes to coop colon slash slash and not qu+ TCP or anything else to build the beautiful here I will the will would that be better than with subtypes of what I take from the discussion we had with figured last time was that subtypes are not not designed "
  },
  {
    "startTime": "00:21:14",
    "text": "for protocol negotiation and we shouldn\u0027t we shouldn\u0027t use it for that and just have an have a service type for each individual protocol this is bound to so if that\u0027s what we would go for and it looks like that but our DD + SSD isn\u0027t under direct way to publication yet so it\u0027s not set in stone then that would be the way I think I can offer you a suggestion about that I\u0027ll start with a simple example if we take a very familiar service like SSH and you ask how do you advertise that and the answer is its unique I on a service type is underscore Association underscore TCP you put that in the API when you offer it you put that in the API when you look for it done that\u0027s how you discover SSH so here that you\u0027re talking about something that isn\u0027t an issue with SSH because SSH runs over TCP it doesn\u0027t run over UDP or SCTP or quick so if I\u0027ve got an ssh client and you\u0027ve got an ssh server we know they can connect as long as they\u0027re on a platform that has tcp my the way i look at what you\u0027re describing here is i would fill out the Ayana form have a string assigned record in this RFC what the string is so that implementers know what it is and that string means resource directory over co-op over UDP now if in the future something is implemented there is co-op over TCP that is a different server types drink in the eye on a registry because it\u0027s a different implementation and the reason I say that is if you have a resource directory that only supports karpova TCP and I have a client that only support scope of UDP they can\u0027t talk to each other so for me to discover you is of zero benefit to the user the user wants to find things that they can talk to so if in the future you have co-op over quick if I don\u0027t support care over quick discovering that is useless as well so so it\u0027s common to think that you can have one application protocol running over three different transports and that\u0027s the same thing the way I look at it that\u0027s not the same thing that\u0027s three different things and the client can indicate which of those three or all of them it\u0027s interested in and the server can indicate which ones it offers so that that is my recommendation when "
  },
  {
    "startTime": "00:24:15",
    "text": "when questions like this come up for NFS can run over TCP or UDP in the rare case is that that question comes up that that\u0027s the guidance I give people and it means in this document you you specify one or or if you\u0027re supporting TCP as well you specify - I\u0027m guessing Rd / quick is not yet a thing okay so you don\u0027t need to specify that that could be a future RFC if and when that becomes real but for the ones that are real today specify those in concrete terms yeah yeah and I think that this is where Rd Genesis T is going I\u0027m just saying if we say if we say that here then we are making that decision for RDG a necessity it look looks like me now that like this is this is a way we can go forward I\u0027d like to have bit more on this about this on the mailing list maybe but yeah it changed me from what I\u0027m hearing that there are some details to be sorted out and in that case this text we\u0027re looking at on the screen is in fact a normative forward reference to something that\u0027s not yet decided so if it\u0027s possible and I know you don\u0027t to slow down the document if it\u0027s possible don\u0027t try to boil the ocean if there are open issues in our ddns SD then those can take that time being discussed but if you can figure out the subset that is necessary to find in our D server and and I\u0027ll come back to this example again I just told you how to find an ssh server and it didn\u0027t require a working group and lots of discussions it\u0027s here\u0027s the string ask the network for that string if there\u0027s some reason that it is not that simple then then then we need to resolve that because it shouldn\u0027t be that complicated so the reason why I think it\u0027s not that simple and it\u0027s not exactly like the various this over DNS overall NFS is that unlike those protocols in coop the applications can rely on the core protocol to have to have the same usable semantics over all those on transport and they can rely on proxies so even if if a resource directory client discovers a co-op plus TC could if if we if we used subtypes whatsoever to do protocol negotiation in over again SSD and I\u0027m not saying we should I\u0027m just saying that this would be an option we should still consider is that if the client has come as the coop plus TCP URI but has a proxy it can use "
  },
  {
    "startTime": "00:27:17",
    "text": "it could just go to the proxy and say hey please come please come please to my RT registration for my for my coop your ID over that proxy and that would still work with Cabot\u0027s but those caveats are generic to what is the pride discovered coop over quick and its proxy doesn\u0027t support quick this I think bit of a magic wand waving and then a miracle happened step here which they can\u0027t talk to be but I assumes that something else on their network can and that seems like certainly you could set up a demo where you can construct it that way but as a vendor shipping a product can you assume that every customer has these magic gateways that know everything no um but it can still then fail as later step I just I just want to make sure that we don\u0027t we don\u0027t overlook this possibility but it looks to me more and more like we just do as you suggest so I just typed into the node tab what I think the substance is we\u0027re talking about so yeah you\u0027re asking about Alice Lloyd UDP and underscore TCP and those will not be sufficient to cover the requirements of co-op because it can use more transports than UDP and TCP and in DNS SP the underscore UDP and underscore t CP is generally as I understand considered something that was designed with the mindset of the time when it was decided designed and underscored UDP is what more honest quit UDP and underscore TCP is what most applications use because that\u0027s what available but if there is anything more like co-op over WebSockets we still need to disambiguate between WebSockets and tcp plain TCP for example what Carsten is suggesting that would work for the case that we\u0027re talking about what what christian is talking about it is true but I don\u0027t to confuse the discussion here the if we could go back in time 20 years then I would not have inherited the underscore TCP and UDP from the SIV spec Oh just had a single label underscore srv4 service and that that label would just be a placeholder to give a delegation point in the DNS hierarchy and it would have no semantic meaning so we have this little historical footnote that you point out it\u0027s not actually a problem for what we\u0027re talking we\u0027re right now right now Christian you\u0027re talking about "
  },
  {
    "startTime": "00:30:18",
    "text": "all the different transports that kerb can use can you list all those transports that are currently specified and implemented how big is the set that we\u0027re talking about it\u0027s 2 times 3 it\u0027s UDP TCP and WebSockets all in their secured and secured versions so it\u0027s co-op over UDP Plus D TLS that\u0027s co-op s Cove over UDP and TCP TLS and WebSockets possibly with TLS okay so six is getting to be kind of a long list of six independent services to list so I agree that\u0027s that does make this more complicated than SSH which really doesn\u0027t have six different ways of connecting to it the so I\u0027ll offer this as an example of how other things have been done when your client does DNS update it needs to find the server for the hostname you\u0027re using that handles DNS update and that can be done in clear-text or it can be done over TCP or it can put in over TLS over TCP to prevent eavesdropping so there are three different service types because even though to a human being DNS update is just a thing I want to update my host name in secure secure I don\u0027t care maybe you should care at a protocol level if you\u0027ve got a client that only uses DNS over TLS for updates and the server doesn\u0027t support that then they can\u0027t talk to each other so the server is the client is specifically looking for and I think the service type is DNS - update - TLS so so we have three service types we have DNS update UDP DNS update or TCP and DNS update - TLS TCP and the client looks typically only for the TLS one if it wants to protect against eavesdropping so so that is a model for you to think about I\u0027m not saying you blindly apply it here but I\u0027m giving that as one data point of what has been done for DNS push notifications we actually only define that to use TLS it doesn\u0027t have an insecure option so but it so I\u0027m again I\u0027m mentioning that as a data point to consider I know in core ID you have different constraints and having the insecure version available it makes sense anyway I think the the "
  },
  {
    "startTime": "00:33:21",
    "text": "problem here would be that we tend to use the resource type and the - TLS we have in my example here that would impinge on that resource type I think we\u0027ve moved forward in RDG and SSD on explicitly noting the service type that that your eye is usable for in the export and not trying to come up with a service type from the resource form in the research tab because those just don\u0027t match so well that we can have a one on one mapping and even if they did it would be very hard to mechanically convert them and through sync to registries so it would not be another tribute maybe another way to look at this is pretend the core Rd DN SSD documents never existed or suppose it does exist but it doesn\u0027t get published take that off the table what do you want to write in this document about how a client would discover the Rd on the network so it can then talk to it to do further discovery so at least figure that bit out and and I understand the details you\u0027re talking about they make it more complicated than the IPP or the SSH case but whatever those complications are put aside the full generality of RDD n SSD which which tries to map all of these other attributes just forget all that just ask the simple question I have a computer on the network I\u0027ve got a Raspberry Pi or something I\u0027ve got my home gateway running in our D how do I find it and maybe the question is scope down that way it won\u0027t take quite so long to come to agreement on the answer yeah I think that\u0027s useful and I think unless there\u0027s another opinion I think we can take the details to the list and I think that this is should be manageable that the children delay resource for a tree a lot yes okay so it seems that was a useful discussion to have yes thank you okay should I go back to your slides or are we done [Music] okay good yeah so we want you to do the same more units discussion but I think Alexei "
  },
  {
    "startTime": "00:36:22",
    "text": "hasn\u0027t returned from acne yet so what we do is we\u0027re going to do the core applications discussion now and we use a format for that that we actually have been using in interims but has not yet been using face to face meetings which as we will just look at the notepad where Klaus has already written up the complete results of the discussion and we were yeah but why did you have a press a button - oh you you you ah you move the table that never moves the table whether particular yeah good so go ahead oh maybe given it Alex I expect you do the other thing first so we have the full rest of the time so send me more units okay so this is to continue the discussion we had in the previous course session about more units and how and if and should we indicate the fact that there are different kind of units that we are now proposing in there in the Sentinel units for history so basically we do have two options here we indicate the fact that we are using them that was referred to as u2 and and asterisk options in the previous session or we use units from the second registry as such and maybe one thing good to not note here is done I also sent an email on the other mailing list about a hour ago to give up every one bit of background on this will involve previous discussion they wanting to note here is that so we are not we are planning to register the unit identifiers themselves as such now the question is how do you indicate when you serialize the senemo using the u field how do you indicate that you are potentially using different kind of units than were originally proposed in them or it\u0027s no RFC but that of course backs you a question so why do you even need to indicate in the first place what\u0027s point here so can briefly mentioned about the the use case he had in mind in the previous session so I had a chat with him after session to get a bit more details on that so pretty much the use case here is that there are some cinema systems like they\u0027ve been building in Cisco that they use the "
  },
  {
    "startTime": "00:39:23",
    "text": "cinema unit field for routing cinema records so if your system such that you have say millions of sensors they\u0027re all sending notes in ml you\u0027re trying to push it all in in your college system and in the intermediate steps you want to do filtering you want to do routing of the information dispatching etc and because the units if they are consistent that always when you talk about speed it\u0027s meters per second period it\u0027s always only one unit for that kind of measurement you know that if you see meters per second it\u0027s something about speed and if you have for example engine replicates and only cares about speed you can conveniently put those records and that direction or vice versa you can filter out information that if you only care about speed and not for example radiation you see a radiation unit or something unit you don\u0027t recognize you can just drop those records from from your pipeline and go forward of course you can also use the name field for such as a routing but what this enables that you don\u0027t have to know those names a priori or even any information about the names that you can for example dynamically discover new temperature sensors just by looking at the fact that ok someone is now sending temperature information so this was pretty much the assumption in testing an RFC when we define the origin registry that would have one unit for for one kind of measurement as discussed in the previous session I mean that assumption didn\u0027t hold very well in the end but we were seeing more and more use for having richer kind of units and pretty much accurate okay we need a way to support also the richer kind of units another question is like how do we accommodate these two kind of conflicting requirements so one way to accommodate that is to have some kind of an indication that hey here is a unit where the original assumption doesn\u0027t hold anymore what you can do with that information for example you can erase an error that hey there\u0027s something happening I may need to understand but I don\u0027t or perhaps you can reroute that piece of data to someone that might be more capable of understanding so if you want to cover this use case we did go I think about different options for for doing that considered half a dozen different options going from new versions of sin ml the u2 field etc all of those turned out to be like way too much complexity given like what a simple thing we\u0027re trying to achieve here so pretty much the smallest impact solution that we came up with was actually the one that Carson briefly proposed in the in the end of the previous session I don\u0027t know if maybe half joking about but still I so putting putting an asterisk in the field and basically that would be a flag in "
  },
  {
    "startTime": "00:42:26",
    "text": "the unit that hey this unit has different kind of characteristics than the units that used to be in the RFC so there is he an example at say km/h you\u0027d put an frank character before after a special character that is not used you can easily determine that it\u0027s not one of the unit characters here we using Asterix for that because it seems to be a safe bet and then you all the units that come from the second registry yield prefix or suffix 10 with that flag of course this is not doesn\u0027t come for free that\u0027s an extra byte of overhead every time you use it that\u0027s not probably a really a big issue you if you really care about the last fight you probably has some form of compression to get deal with that anyway maybe the bigger issue there is that this does break the principle of lease at least and astonishment so when a developer C\u0027s unit able like hmmm why there\u0027s an asterisk and yeah they would have to go on into the upcoming RFC and see like oh that\u0027s the reason and yeah it\u0027s discussing this between the meet between the previous sessions yeah multiple people voice okay that\u0027s not very elegant it kind of smells funny but out of all the options this seems to be the best book best one we get so I guess that\u0027s the yes that\u0027s the last slide here and questions and comments Alexei Melnikov so in the current registry there are some units which are derivative correct are they going to be so that\u0027s a problem if we were designing that the registry now yes they would absolutely be is it worth moving them read retrospectively and potentially Prague existing code maybe not okay so they\u0027re sort of grandfather tents exactly and that\u0027s kind of an extra clutch there I mean we could I can see it work in both ways but whether the words of doing the right thing is worth breaking existing code potentially maybe not Justin when I was young and there was their books in in Germany books have a set price you cannot sell a book for less than it\u0027s set at but of course there are books that you want to sell off because you have too much inventory and so on so what you will do is you take a text marker and scribble on the sides of the book and then say oh this this is not the normal book it\u0027s a book with a quality problem and we can tell that to say that cheaper and the asterisk sounds a little bit like "
  },
  {
    "startTime": "00:45:26",
    "text": "swimming with the text marker and saying oh this is not that real SI base unit yeah so from that point of view it\u0027s almost something that that I might want to start liking but of course the problem remains that those people who want to use these units always will see the black text marker on their applications and this is a little bit of a cognitive problem I mean it\u0027s not a technical problem but it\u0027s it\u0027s like they are not taking us seriously here so we have to use the the s for us to say we are the second-class citizens which they are but you may not may not want to rub it in with every usage so that\u0027s one way to look at the thing can I quickly so quick comment on the usage correct about this much multiple use for senemo units this would only apply to when you use the you field of the serialization yes Wrexham the OMA use in schema that would not be impacted is great so the other thing the objective was to distinguish units from table one from units from Table two which is pretty much what the Astros does now with the assumption that the units from Table one are really moving very slowly I mean we are not going to it we\u0027re just a lot of units there and this the SI system changed again or something like that the that leads to the simpler implementation strategy to look up the name and if it\u0027s not in in Tier one apparently isn\u0027t able to and so you can derive the the essentially the same information by doing that and actually if there ever is a new registration into everyone the the application that they\u0027re restoring the routing based on units probably would have to react the same way because it doesn\u0027t really know whether the newly registered unit and tear one concerns it or not sure from first principles it probably maybe shouldn\u0027t yeah so that actually depends so there are some two things in table one as you said like yeah it\u0027s very very stable and Sam Soon is that doesn\u0027t change much except for that half a dozen units you are now adding there but in the longer term in a few years it\u0027s gonna be rather stable the second thing is that I think is more important for this use case that like one unit for one kind of measurement so there will never be another meter per second let\u0027s say kilometres per hour or yes anything new for speed I\u0027m just I\u0027m just talking about the detection of the use of caber "
  },
  {
    "startTime": "00:48:27",
    "text": "- yes download with that would look for an asterisk in the code I would write what look into everyone and say if it\u0027s not into everyone it\u0027s a favor to John yep and I think that that that\u0027s a fair way to do it of course it\u0027s a I guess Collins argument for that would be roughly Asterix is one line of code that I can easily fold into the system that would be a generalized go look up they may be 5-1 alrighty I okay don\u0027t come in a long line of code [Laughter] so I was like as a reviewer of this draft also I mean to me I was one of these astonished people to me it looks really bad as a solution I mean even the author seems to disagree on the actual choice I mean you propose it about you\u0027re not a person sure about this the target for sentimental is not just routing entities at the processing center mail is also consumers of this any any consumer of the sentimental data it might be that you parse it in different ways but having that asterisk there means like anytime you print it just like when you print chase and you will have that too maybe unless you do it some special string operation it means also that the view your product has km/h for some reason because not everybody has to use m/s or you\u0027ll also have to process that in a different way and I think it\u0027s kind of weird to embed these kind of ITF registry decisions into this NML unit itself like whether you have one reduced here to that for most people don\u0027t care about that I think so personally I think it\u0027s a bad idea I mean from the floor yeah I can let me try it if I remember all those points try to address them maybe in reverse chronological order it\u0027s not actually only about table 1 table 2 it\u0027s about semantics of that unit registry that were in indicating and it\u0027s really the key thing is that is it only one unit per kind of measurement and now we are breaking that and also as Colin pointed out in the previous session cinema was never meant to be human readable just turned out to be because we use Chasen so a normal human being you know developer society is never supposed to see sentiment as such of course in practice um it happens and yet the asterisks you would never saw that to a user you would always strip that a weight way in your code so maybe then what it looks like on the wire is mostly for neurological developers who will be astonished given but maybe it\u0027s a rather small stuff users and then finally yeah in one of them miss animal can be used in various different ways and it\u0027s been used in various different ways one of the core principles are also "
  },
  {
    "startTime": "00:51:29",
    "text": "stayed in the RFC was that it\u0027s highly highly capable I mean very useful for this kind of environments where you have a lot of sensor nodes sending data to that to the cloud systems and there this kind of routing capabilities are are very useful of course now the question is is is that useful is that use case important enough to justify their ugliness and I\u0027m personally I\u0027m kind of here on defense I was originally quite a bit against at doing anything it\u0027s just like okay let\u0027s put everything as such after a long discussion with Colin I was kind of starting to okay I understand I understand his use case I think it\u0027s a relevant use case I\u0027d like to cover that then the question is is like the pain of it pain of doing it worth it and that\u0027s kind of I\u0027m on the fence here myself I\u0027d be fine either way actually as long as we get it ya know maybe just to get a sense of the room does anyone have has anyone read the draft that\u0027s the first thing all right of those who have read the draft do you have a strong opinion one direction or another now you would like to voice out I must you mean not if you don\u0027t say anything hi my name is Matt Gilmore is the asterik needed I mean it\u0027s got to be expected that cinema in general will have additional units added over time yeah argument that there won\u0027t be a secondary table or additional units in Table one there\u0027s no version II non that to understand if that changed or not anyway so to the key difference is the asterik tells you this might be about a measurement that you should care about but you don\u0027t know that\u0027s really the information aster it gives you so cuz nope so that shouldn\u0027t happen because in table one you would never have new unit for speed where\u0027s the table to you may have multiple units for speed yes but um so you\u0027re gonna have new units for new kinds of measurements but as long as your system only cares about a single or let\u0027s say a subset of kinds of measurements that are in table one then it actually does bring you value that\u0027s one way you can use the asterisk probably more openly which is like hey oh you know raising a flag uh I might be doing something stupid here by ignoring these records that\u0027s kind of the simplest use case for it yeah but then you\u0027re right I mean you could also use okay you look up in table "
  },
  {
    "startTime": "00:54:29",
    "text": "to forward your data to someone who can look at table 2 but really the key thing is like avoiding the fact that someone thinks I\u0027m getting all about speed but then actually missing kilometres per hour and I was a summer I\u0027m thinking oh you know analytics system data dispatching etc yeah we have to wrap this up so we\u0027ve enough time for for the applications part my proposal would be that we generate a new version of the draft that explains this implementation strategy explains how it is broken by Table two and also explains how doing a lookup integral one is almost giving you the same function back and I think with that we should consider this done and then should we in order to facilitate that proactively register more stuff in table one that we know is highly likely landing there because now we\u0027re gonna do it by request what we saw being used so now in order for that strategy to work efficiently they table one should be as stable as possible okay that\u0027s maybe a worthwhile thing I wouldn\u0027t couple it timewise because that will take some time but I think you\u0027re simply leafing through iso/iec 80000 and and seeing which other combinations I actually defined as quantities and units there might be a good basis and and doing this per actively also really makes their life easier of people who want particular counts per square meter whatever stuff that we don\u0027t do yet events per hour per square meter that sounds good I mean if others you send an email before the meeting right and if others have opinions they can also just push it on a mailing list as well so let\u0027s cut it there I guess because they everything has been said about this issue already so I picked that as an action item it\u0027s certainly not something that we as the highest priority but I think it should be done yeah sounds good Thanks so least you actually don\u0027t have so much time so Klaus please "
  },
  {
    "startTime": "00:57:31",
    "text": "[Music] okay I have a number of items in this segment one item is report on the qualification site meeting that happened on Tuesday then I have somewhere a quick update on the career reality drafts which are working group documents here in core and then related to that quickly an overview of all the choreo based applications that we are currently having in different working groups so let\u0027s start with the site meeting on the rillette on Tuesday in the site meeting we looked at three topics the first one was problem details for co-op api\u0027s that\u0027s a proposal by Thomas Rosati he finally brought up what has been discussed quite often already in various hallway meetings and that is when you build the coop based application and you return some error to the client then you might want to include some problem details in that error description and for HTTP there\u0027s our c7 807 which defines a JSON based format and Thomas converted this to a C bar but also did some changes by making the format less specific to HTTP and more generally applicable so it also works in constrained environments this graph wasn\u0027t published before did ID cut off that\u0027s why it\u0027s not on the agenda of the core meeting but was on the agenda of this site meeting but now that the submission is open again Thomas has published his draft and I think you would welcome any kind of feedback on his proposal I think it\u0027s a quite useful addition to have in our repository of core data formats so please take and tell us on the mailing list what do you think if it\u0027s useful and if yes how you might use it in your application for example then of course my favorite question is always can you do it with coral and so we spend a few minutes in the side meeting to take a look how problem details might be done with coral and it turns out as long as the problem details are simply a list of key value pairs which is the case in most examples that we could find and then yes you can easily use coral for this and the current choreographed Dasha one also has a new section on what does it mean when "
  },
  {
    "startTime": "01:00:33",
    "text": "you return a coral document in an error response so normally a Cora document describes is a representation of a resource but if it\u0027s not a representation of a resource because it\u0027s part of an error response then what does it mean and that\u0027s what this new section defines then the next part in the it\u0027s not very general thank you the next part of the site meeting was about the extensibility and code points so of course when you would define your problem details you might want to have some kind of compact error codes for the different error conditions that can happen in your application and you might also want to include some application specific error details in the error message and then we have the typical problem of how do we do extensibility in this data format and it\u0027s becoming more and more apparent that this is basically the common theme of almost everything we do here in the core working group we need to define assign small compact unique identifiers to the semantic elements of our data formats so if we have these error types and error attributes in problem details and Thomas has a proposal and is draft how to allocate unique identifiers for that using IANA registries but of course we also have already sits for Kumai or corinth which uses this three level approach based on mega ranges that are assigned by iana then ranges which can be delegated by anna to someone else like an sto and then with that range there are the units as allocated and of course also in coral we want to have linked relation types in operation types and form fields and those need to have unique identifiers and we want to have them compact and so Corrie has a another completely different approach to this it uses your eyes primarily to identify the semantic identifiers and but then defines a static dictionary compression scheme to make it very compact on the wire so this segment of the site medium was mostly about this observation aha we have this pattern or this problem coming up all the time again and again and sometimes a registry is exactly what we need for that in particular if it\u0027s conservative protocol extensions that get reviewed a lot and so on but if we get into areas for example like application specific error codes then it becomes quickly infeasible to register every possible "
  },
  {
    "startTime": "01:03:33",
    "text": "error condition in any application that might exist somewhere and then ini registry so we have to look into these multi-level allocation schemes and I think we can learn from each other in some way so there was what that part of the site meeting was about and we always say and there are two hard problems in computer science cache in relation in naming and I think the naming part is often misunderstood many people think it\u0027s about buying a good name for your new open source project but I think the naming problem is exactly this how do we assign good points did a small compact and globally unique without requiring everyone to go through a single bottleneck somewhere the last part of this ad meeting was again about arrows and this time about co-op response codes and so we have defined this bunch of response codes and five five dot X X and 4 dot X X which are largely inspired by HTTP and the lag in HTTP those response codes are almost exclusively intended for describing protocol level errors so there\u0027s something wrong with the coop message format you would return a 4.04 sponsz for example if there\u0027s something wrong with an option you\u0027ll return return the bet option response and so on but there are very few if at all response codes if something goes wrong at their vacation later so the client might send a request that is perfectly fine from the point of view of coop but their payload if it\u0027s a post for example might not be acceptable from the application point of view because it\u0027s malformed C bar or it contains some key value pairs that are not recognized by the application so we discussed a bit if we maybe should have some kind of new and response codes which are dedicated to application level arrows rather than the protocol level errors and there were some arguments against and for that so maybe we can continue this discussion on the mailing list you know the part that you\u0027re living out here is that in the fetch fetch document RFC 81 32 we already have register two of these which are 409 for doing something that would leave the data in an inconsistent state called conflict in in HTTP and for 22 which is unprocessed entity which is which means something has been sent to you in the request that you cannot process so that\u0027s certainly not the whole picture but we have already started doing that "
  },
  {
    "startTime": "01:06:36",
    "text": "and the other should decide that we immediately should stop doing that or that this is a good thing and we probably will continue this until all 32 records are gone another observation related to error responses is that in any of our drafts when we define interfaces we often say this is the success case so you might get two or one created for example in for some API call and these are the error cases so many documents then say well if the resource cannot be found then return to 404 if the client is not authorized to be 2403 if there\u0027s a bad option return over 402 and so on and I\u0027m wondering if we need to repeat that all the time in every single API documentation so we discussed a bit if it could if we could have a central place somewhere where we describe all these conditions when you are supposed to return what and then in particular age documents I think like to do this maybe those can just reference this single document instead of having all the boilerplate text explaining that if the resource doesn\u0027t exist then you for 324 for so that was the report on the site meeting on to those who were there any additions no then let\u0027s move on to the so I published - or one of both the career draft and the H ref draft before the ITF meeting and there are not big updates this time because I spent more time on updating the drafts that describe correlate based applications so that\u0027s the next part so the only change to the Korra Draft has been this new power in section that I mentioned about what does it mean if you include career documents in non 205 responses in coop for arrow responses and and the other success cases and there have been no changes at all to date ref draft so em just as a quick reminder and coral is describes the links and forms of a resource and H ref then defines the Seaboard format that you can use to compactly express your your eyes so it\u0027s an alternative sterilization for your eyes any questions or comments on coral then let\u0027s move on to the coral based applications Francesca so nothing coral but on the previous topic I was just "
  },
  {
    "startTime": "01:09:37",
    "text": "checking what we do in ace just to make sure and we actually we just specify that when to send for one and authorized message because that is like in coop what unauthorized means or where it comes from is outer scope of coop so the application has to define that but we don\u0027t actually define like we don\u0027t actually use all the other like we kind of say okay if it\u0027s if it\u0027s for one if it\u0027s a note if the token doesn\u0027t validate then use for one and authorized so you for that specify you know like API specification specification feel often very repetitive and maybe make something that everybody can reference I\u0027m not sure that our draft would would use that I think maybe cos core could have used that but now it\u0027s it\u0027s an RFC so maybe it\u0027s more on the side of implementation guidance or something like that and we will figure something out but it\u0027s good that you\u0027re not having lots available oh yes yeah and we need to debate on the meaning of 401 because means the client is not authenticated the client is not authorized to perform the requested action that\u0027s that\u0027s and that\u0027s all right 3 4 + 4 1 4 3 is forbidden and reading 7250 - it\u0027s confusing are you saying this is not what it should say because then then it\u0027s different so apparently we inherited some terminology confusion from HTTP where they often put the word authorization when they mean authentication I think this is one of those cases so they have this www oh yeah second so that was the first sentence the second sentence says the client should not repeat the request without first improving its authentication status to the server so it says authorized on the first sentence actually right because in some cases of course you are authorized to do something without being authenticated in that case you don\u0027t get a fara one but you get a successful but if there there is authentication that is a prerequisite to being authorized then fara one actually is the who are you and four or three means I know who you are but you you still cannot do that ok and I think it makes sense to to differentiate these two Elvis okay so maybe like the "
  },
  {
    "startTime": "01:12:38",
    "text": "terminology in 72-52 wasn\u0027t very clear and maybe yeah that we should have had this discussion before vanishing Oscar so that\u0027s maybe great input for the Corrections and clarifications document okay done quick updates on coral based applications these are currently not working group documents anywhere but they are subject of discussion and t2 TRG and in core mostly in hallway meetings and I\u0027m currently aware of for applications that use Korea in some way three I\u0027m author or co-author of and there\u0027s a new fourth one that exists since yesterday and that I will talk at the end about the most interesting one probably is the overhaul of the pub/sub interface you\u0027re probably all familiar with the core up some draft that hasn\u0027t been updated for a while and the reason for that is I think it Prague or maybe even the ITF meeting before that we discussed splitting the configuration of pop subtopics and actual publication and subscription of to those publics and to separate resources and it took us a while to create a proposal for that and they discussed that proposal in Montreal and in much detail and now there\u0027s also an draft that puts that proposal into a text form I\u0027m unfortunately we couldn\u0027t get this draft to have future parity with the current - or nine of the pub/sub broker draft so the authors of pops-up need to iterate on this draft a few times until we get that feature parity and we can simply replace the contents of the current and pops our draft with that updated proposal yeah there are some hopefully helpful figures in the draft which show the structure that we have now we have a typical collection resource that contains all the different topic configurations and clients can create new topics by submitting a new initiatory configuration the server will then or the broker which is the server then creates a new item in its collection which stores the configuration and you have their usual operations of create read update delete to change and maintain the the configuration of topics and then there\u0027s a second separate resource that the broker also creates and that is then used for the publications and "
  },
  {
    "startTime": "01:15:38",
    "text": "subscriptions so you can use in this very simple scheme that - online defines a put or a post to publish your information to the topic and use observe to get the notifications when the state of that resource changes the nice thing about this split is now that we can also have other types of publish subscribe mechanisms so for example you could create your topic and then specify oh it\u0027s not using this simple but observe mechanism but instead it uses some other protocol like amputee for example or some other optimized form of coop up sup so for example NT - DRG we have this serious transfer pattern draft which reliably gets you all the information that gets published while for example if you use observe you know we only have this best effort approach where you get the latest information so you might want to configure a STP series transfer instead of this simple publish/subscribe can just go down a bit one implication of this change is that we have now something called a half created topic we always have the problem that if a topic is created but nothing has been published yet what\u0027s that state of their topic because somehow it exists but at the same time somehow it doesn\u0027t and I think we have now found a good answer to this problem after you submit your topic configuration the broker creates the topic but subscribers cannot subscribe yet until something has been published so we have this little state machine after creation the topic is called half created in this state you can change it to configuration or delete the topic again but you cannot subscribe you can only publish and once something has been published for the first time the topic is fully created and subscribers can subscribe next did I miss anything I don\u0027t think so any questions or comments or remarks on pubsub well one one comment with my chat would be we really want to ship this thing at some point so we have to make sure that we have the furniture that\u0027s in place to do this and where we can come back to that later we have about 12 minutes left I think Jessica wanted five minutes to "
  },
  {
    "startTime": "01:18:38",
    "text": "talk about Oscar and at work I need about five minutes okay good there have been small updates to the coral reef draft mostly to bring it in line in the same with this and to the same style that is used in the pub stop draft that I submitted and this choreograph describes how you can do well-known core and resourcedirectory with the coral interface and then there\u0027s also the data updraft in t2 DRG which designs a coral interface that you can use to store files on a server so for example a firmware update or a suit manifest or a much file or whatever you need and then you can have the typical lookup interface similar to resource directory there you can filter there the list of stored files for something that is interesting to you so it\u0027s a bit like a resource directory but the store actual files on the server instead of just links that point to other servers and then last but not least we have a fourth application now after the figure and that is draft tilaka a source code group manager at man - zero one that - zero one has not been published yet it exists an HEC indeed that we created yesterday and what we did is we take we took the - zero zero version of that draft and restructure did a bit so it matches the same structure that this pops up proposal draft has so first it describes all the representations and concepts that are rated to a score group management and then this group this describes the injections with the group manager and it turns out that this draft is basically identical to the pops up draft of course it doesn\u0027t do pops up but it does it has the same pattern of configuration so there\u0027s a collection resource you can post a new configuration to that and then the group manager will create a new resource that stores that configuration for the ausco group and you can create read update delete so essentially exactly the same interface so now we are wondering can we refactor this in some way and write another draft that describes the overall pattern and then the pops up broke for example which fill in his configuration parameters in status parameters and group management would simply define a different set of configuration parameters and so we can you reuse the same pattern in both drafts Colinas question how often the us-backed is "
  },
  {
    "startTime": "01:21:39",
    "text": "pattern to emerge in concrete applications twice so far I\u0027m aware of an Ericsson application does that does it - it\u0027s huge and so it\u0027s a pattern that is very frequent I think it\u0027s very useful to have as Janell general pattern that we can use for different applications any questions or comments on that marketed authorized not exactly on this on the previous part on coral for responses and even error code maybe we have yet another draft in core and describing multicast responses for a group of salvations where individual clients are signal about that with a response message which is an error response in fact so probably coracle be helpful for those kinds of responses to and about error codes maybe we can find something even better to indicate exactly that other than 5:03 yeah so and what you call error really is more like a redirect and we said we don\u0027t want to have a redirect at the protocol level because it\u0027s something that really an application should be doing and to do this the application needs some data so I think that that fits together very very well anything else on general on Coral Yes No maybe I have one thing I would like to [Music] okay yeah to get this thing shipped I think we need to have an idea when we want to ship it I mean we can work for five more years on this it\u0027s going to get better every year but maybe we need to ship something at some point to get better feedback from people and my hunch is that we need approximately one IDF to close all these issues that are currently in the repository maybe doing this using an issue of the day process and then when we say ok our issues are closed we have something like an implementation draft that we can recommend people to implement we take another IGF a period "
  },
  {
    "startTime": "01:24:40",
    "text": "to get these implementations get the feedback and improve the document based on that feedback maybe also get a few reviews from outside the web the thing web community into the big web community so with this timeline we would shoot for working a blast call in mid 2020 and the question is of course we have the resources to pull this off but the question of course is also do people see a big problem with this should we be faster but I don\u0027t know we can be should we we take some more time because things are may be a bit rougher and then I perceive at the moment so that that\u0027s where I would love to get some input for instance from Jim who was played a lot with her he\u0027s saying in the chat um that HRF needs to happen also in parallel so when I say Kowal I always mean these two draft draft overly intrusive call it wish I can report that while there weren\u0027t many draft updates in the last months since Montreal on Coral there has been a ton of validation of coral it has been applied to a larger use case internally and I think the concepts are now rock solid we are not going to change anything about that but we have this list of issues that might lead to some tweaks so Jim from Jabbar the basics work well trying to solve dictionaries is still an issue and also do you want to solve the json coral on the same time schedule that\u0027s an interesting question yes I\u0027m not sure we have enough data to to answer that question but we could try to you don\u0027t know what kinds of problems we run into when we\u0027re doing this we have two proposals for Jason serialization I think it\u0027s just a matter of taking one of those okay and that\u0027s difficult because both ugly okay you you wanted to use the last three minutes yes thank you casting hi I\u0027m Francesca and I "
  },
  {
    "startTime": "01:27:42",
    "text": "have no prepared slides or any presentation for this so this is just talking so in for the Oscar plus a doc scenario we are wondering about something we like feedback from employee implementers and also people who have ideas about constrained implementations I have started talking about this way several people Klaus militia Jim and I would like to hear if more people have opinions so the issue or the problem statement is for the aid of protocol we have three messages protocol or exchange and this third message so that goes from the client to the server could be combined with the first Oscar request that comes after the ED of protocol so the question is how can we combine this third addict message with a no score request and of course transport all of it in coop so we have identified possible three possible solutions and I\u0027ve heard several different opinions on this so militia from six dish he he said that his preferred option would be to actually transport the evoke message in a no score protected co-op request so that would mean adding the a doc data or the message three or whatever you want to call that into the payload together with the cipher text and signal it in in a way to to the to the server so this signaling could be done in two different ways Klauss supported the way where this england instant directly into the oscar option value so this would mean that server would have to parse the option value to to be able to realize that in the payload of the co-op message it\u0027s not on the oscar ciphertext but also the ADAC message three and militia initially was as it turned about this and after checking that it\u0027s the code he said that it\u0027s fine because he first done he first does parsing of the option then afterward he does processing of the option so that would be fine for him but Jim had a very strong reaction against this because his code makes this very difficult so his preferred option would be to send the Oscar message inside an "
  },
  {
    "startTime": "01:30:46",
    "text": "addict message ok what is an addict message that just the co-op message with a doc in the payload so there is a doc message three in the payload and what he proposed and Jim please correct me if I\u0027m mistaken or misunderstanding is that together with the a doc message three in the coop payload there will be something signaling that also the Oscar option value and the Oscar ciphertext will be contained in that same payload so what the server would have to do is to take the message process a doc and the other processing would also start or would also parse this payload and remove the ciphertext and Oscar option and put them at the right place so that when the coop message is processed the Oscar option will be added to the message and then Oscar can be processed so the if in the first case the processing would have been okay co-op parsing Oscar parsing than a doc then Oscar processing then co-op in the second case it would be co-op parsing a doc parsing a doc processing Oscar Oscar parsing Oscar processing so okay so this is recorded so you can go back and listen to it after but this makes sense so I actually I am doing this fast because we don\u0027t have time but I think that people who have I\u0027ve talked to have an idea what I\u0027m talking about I hope re quick a flowchart yeah we can you can sketch this out but okay so I have a last option which I would like to hear from that militia brought up and he said that this would be his preferred option for him and so this and I haven\u0027t talked to Jim or Klaus about this and I would like to hear everybody else comment that would be to create a new option called a doc this option is sent empty the only reason for having this option is to say signal that the ADAC message 3 is included in the payload also this option will be defined so that like in the specification it would say process this option before processing or score so would that would be an unprotected Oscar option so Oscar would leave it as is and by processing first before Oscar what the server would do would be just to parse the payload take out the doc and start the other processing which is what Jim didn\u0027t like "
  },
  {
    "startTime": "01:33:46",
    "text": "but yes so I I would like to hear opinions about this and I think that we have on one side implement implementation that are constrained and more have co-op more integrated with all score and on the other side implementation who are more general and have libraries and so switching from one library to the other is hard but yeah so what I what I think we should keep in mind with either code and for me either of those three would kind of work is that what we are doing on a semantic level is sending two dead two separate rest requests that one is the first process this attack message 3 which is usually opposed to a particular resource and then process whatever is in the the message and that we are doing this here and we may short-circuit through this process but we should be aware that this is what we\u0027re doing yes this is exactly what we\u0027re doing yes and we\u0027re trying to do it in a way that implementations can do it without too much pain so the question is what\u0027s the best option that we degrade coop it to a simple message forwarding protocol and run or score on top of that and since then everything is going downhill I don\u0027t think there\u0027s a good option here yeah they\u0027re only really bad and really really bad options ok something I haven\u0027t ok something I haven\u0027t said I think it\u0027s important is that this will be an optimization so we still have the option or the default option of running a doc first which runs on top of like transported on coop in coop and then so it\u0027s 2 passes and then start running as Oscar that\u0027s that\u0027s the default well here we\u0027re trying to think since it\u0027s important for 6 dish to have us little round trips as possible as few round trips as possible how can we optimize them so yeah this is this is an optimization thing already filling up the blocks anyway so you need multiple datagrams I don\u0027t think so I think I talked message 3 you mentioned was 2022 bite something like that so I don\u0027t think that plus your score request whatever that is but Oscar overhead is like 10 bytes so I don\u0027t think so we can "
  },
  {
    "startTime": "01:36:49",
    "text": "do ipv6 next year so we can look at that but okay but we can take interim on this if you think it\u0027s it\u0027s okay maybe it\u0027s worth thinking about piggybacking in a motion yeah since I\u0027m not sure that will lead us anywhere but maybe it does and then we can use that but maybe we do something very specific very ad hoc great thank you [Music] okay as I said we are on the hallway for seven minutes already thank you for your patience and see you all in in the interims and in vancouver maybe i should say that the the hallway sentiment was that having an interim meeting every two weeks might be a bit too often so we probably will come up with an interim schedule that\u0027s a bit lighter but we can do that on the mailing list every trip home "
  }
]