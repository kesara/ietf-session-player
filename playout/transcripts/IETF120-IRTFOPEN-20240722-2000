[
  {
    "startTime": "00:02:41",
    "text": "So you can even sit up the desk and use them to the best way. Oh, excuse me, or you can start Test, test I think if I need to look at notes, I need to hold it Sorry, I have a lot of things test"
  },
  {
    "startTime": "00:04:47",
    "text": "I mean, if you were just Thank you very much There has to be a purpose to the meeting"
  },
  {
    "startTime": "00:06:35",
    "text": "Thank you very much you So then you have to be really curious All right, we're just figuring out the technology here"
  },
  {
    "startTime": "00:08:17",
    "text": "ADI But if you, it, you know, And the extreme sound, the extreme line Thank you very much Thank you This one here All right, let's get started Welcome everybody. This is the IRTF Open meeting"
  },
  {
    "startTime": "00:10:00",
    "text": "at IETF 20 in Vancouver Can I just do a sound check? Is everything working? Can the remote people hear us? Call in the gain on your mic is to, and the gain on all the mics are is to be I don't see anything in the chat I'll assume the remote people can hear us Okay, the volume is a little high load Okay, so I will get started well me take over and fix the volume here So I'm saying, welcome, this is the IRTF open meeting I'm colin perkins, the IETF chair. This is an IETF one in Vancouver I start with the usual room reminders. The IRTF follows the IETF intellectual property rights disclosure rules by participating in the IRTF and participating in this meeting, you agree to follow the IRF processes and policies If you're aware of any contribution, so if you're giving the talk or you're commenting at the microphone, and you're aware that your contribution is covered by patents or patent applications, then you need to disclose that fact by the usual IPR, disclose your process I may expect you to do so in a timely manner"
  },
  {
    "startTime": "00:12:00",
    "text": "If you need several information in that, there are links on the slide for the copyrights patent and perfect patient policies, and these all apply to the IATIA as well as to the IETF We also make recordings of these meetings and in particular this meeting is being recorded. The recording will go on new YouTube after the meeting and it's also being screened online you participate and you're not wearing a red, do not photograph, like lanyard then you risk being photographed although I do not believe there is a photographer at this meeting but certainly if you give a presentation or if you speak at the microphones, you will be recorded and the recording will be made available Thank you the question to the IETF's privacy policy and by participating in the IRF you agree to work respectfully with the other attendees and we police at the in the IETF, you agree to work respectfully with the other attendees. We place a great importance on the Code of Conduct, so please do make yourself aware of that, make yourself aware of the anti- anti-harassment policies and procedures and so on And if you have any questions or concerns please do either talk to me or talk to you Ombuds team as you feel is appropriate If you are participating in this meeting in person, in the room, you need to sign in to the meeting using Meetecho, using the on-site tool either by clicking on the on-site tool link in the agenda page in the Datatracker or by scanning QR code on the screen If you're in the room and you want to ask questions, please do so using the Meitego tools We have a common cue for the local and remote participants so sign, don't just go to the microphone"
  },
  {
    "startTime": "00:14:00",
    "text": "join the queue in METECO if you have questions Remote participants well, if you can see this, you've already joined using the full client. Please turn your audio and video off unless you're actively wanting to ask If you have any technical issues, may all support the IETF or go to the URL on the slide slide Okay, so the IRF is a parallel or organization to the IETF whose goal is to focus on the longer-term research issues relating to the internet what the IETF does the engineering standards make The IETF is a research organization It's not a standards development organization. That's the role of the IEF and while the IRF can and does publish documents, in the RFC series, which is informational, RFCs, that's not the main for of the work here, the main focus of the research groups is expected to be understanding and papers, essentially. Research results get published in the usual academic literature literature IRF is organized as a number of research groups There's currently 15 research groups The Gaia global access to the internet for all research group met this morning Those other groups, which are shown in dark blue on the slide are meeting later this week. I think we have network management later this afternoon and then the privacy enhanced and assessments group in the last session today And then the others listed in dark blue are meeting later this week The Quantum Internet Group, the information centric network, group, the thing to thing research group, and the computation in the network group are not meeting this week but the other group are"
  },
  {
    "startTime": "00:16:00",
    "text": "are As I say, the main focus of the IRCF is in research papers and publications rather than RFCs but we do occasionally publish RFCs and the three RFCs published since the last IETF IETF RFCs, and there have been free RFCs published since the last idea. These are an RFC on the Internet of Things, edge challenges and function from the things thing research group An RFC talking about application scenarios for the quantum internet, and the Frost protocol from the crypto forum research I'm also very pleased that we have been able to offer a number of travel grants to support early career academics and PhD students, especially those from underrepresent groups, to come to the meeting today The slide okay, it's a little small, hopefully it's readable, shows the breakdown of who received the travel grants. We are, as you see, mostly female, non-binary, or trans participants, and about two-thirds of them from Africa, South America, India So I think we're doing a reasonable job on diversity, obviously we could do better Obviously, we would like to award more travel grants, but I'm very grateful for the travel grant sponsors you see listed on this slide for their support If anyone works from an organization which wishes to fund, further travel grants in future, then please become talking We're very grateful for the travel grant sponsors for the awards we've been able to meet We have also in the IRSG, the internet research Steering Group, we've been discussing the developments of an IRTF code of conduct"
  },
  {
    "startTime": "00:18:00",
    "text": "Now, the IETF has had a code of conduct for many years it's in RFC-7154, but if you read that, it's focused primarily on effective conduct conduct We believe we need a code of conduct for the IRTF to consider the effective conduct of research and to bring the references to the anti-harassment policy, the anti-hassment policy language policy, the Ombuds team and similar, into a common place, so it's accessible and readily available for the IRTI participants I've mentioned this in the last couple of IRF open meetings We sent it to the IRTF announced list the pointers to it as well. The document is currently draft Perkins IETF Code of Conduct and it is a document which we believe is now essentially done. So I would encourage you all to read draft Perkins's IRF code conduct send feedback to the IRSG and or to the IRSG discuss list We expect to be issuing a last call for comments on the document relatively soon in the next few weeks If you have comments before that, please do let us know and please do read it and comment when we issue the last call We would like to get this approved over the summer in place before the next meeting Also on the Minister Trivia, I am stepping down from the IRF chair role at the end of my time which will be in March 2025 So the IAB is seeking nominations from my replacements The URL on the slide is"
  },
  {
    "startTime": "00:20:00",
    "text": "for the call for nominations. There's also a couple of links there, RFC 7827, which is a document lars eggert wrote when he was IRTF chair talks about what the role of the IRTF chair is, both in terms of day-to-day practice and in terms of the strategic role of the IRTF chair. I also wrote a page on the IAB's wiki which is linked there, which, it went through what I said been doing in this job for the last five or six years and tried to summarize all the tasks I've done to give a perhaps a less reflective, but perhaps more complete summary of what the role involves If you're interested in taking over when I step down, please do consider nominating yourself. Please do come talk to me I'm very happy to talk about what's involved here and to give people a feel for work is needed and we do need some good candidates and please do consider volunteering This is something which would consider, perhaps, would perhaps especially suit a mid-career faculty member someone who was established just got to tenure, got a bit of time and a bit of funding and wants to make a difference and have some impact. So if you're interested in that, please do come back to me Okay, the other thing we do in addition to the research groups is we run the ACM IRF applied networking research workshop This is taking place tomorrow We have, I think, 12 full papers this time six lightning papers and what promises to be a great keynote talk So thank you to the organizers. Josie Simone, and Ignacio for putting together a fantastic program. I see it Ignacio there. Do you want to say anything?"
  },
  {
    "startTime": "00:22:00",
    "text": "anything? Okay. So thank you. And as I say, that will be happening tomorrow, and I forget which route I suspect, this one. But do have a look at the adjourn and have a look at the papers which are all online And the final thing I want to talk about is the Applied Networking Research Projects The ANRP is awarded to recognize some of the best recent research in applied networking research. It's awarded to recognize interesting new research ideas, which are potentially of relevance and importance to the standards community. And it's awarded to recognize upcoming people who would believe are likely to have an impact on Internet standards and technologies going forward we're very pleased to have three fantastic talks three fantastic A&P prize-winning talks today Zed Jang Zoo and apologies, I'm sure I pronounced that wrongly but Zijang will be talking about his work on improving test coverage for network configurations Yehemia, I'm sure it's done that wrong as well. Apologies, we'll be talking about his work on understanding the root causes of DNS resolution failures. And Jasmine will be talking about her work on key transparency for encrypted messaging As I say, I'm expecting three fantastic talks coming up, the papers and the copies of the slides are also on the website But yeah, we have three great talks coming up and congratulations to all three for their fantastic paper And that's all I have. The agenda for the rest of this meeting, Zeyang, is coming up next talking about network configurations, then you have near and Jasley"
  },
  {
    "startTime": "00:24:23",
    "text": "Okay, so the first talk is by C. Chen Su Zhu, who recently obtained his PhD from the university of Washington. His research aims to remedy the reliability risks in the day-to-day operation of network infrastructure, and his dissertation pioneers the use of coverage metrics in network testing and develops the relational abstraction to follow describe network changes, such as the correctness of network operations can be checked effectively and efficiently. He graduated recently from the University of Washington and is now working at Macon AI infrastructure networks Thank you very much, colleague. Thank you hello folks from the IRTF and IETF community. My award talk today will be about NetCOF. It is the first tool of it kind to compute the test coverage for network configurations. And this is a joint work with my fellow student, Wiesington, and our advisors, Ryan Beckett Ratu Mahajan, and David Walker All right It's a bit lag here, but I will see. Yeah here we go. Everyone in this room probably have witnessed a lot of network outages caused by configuration errors And the consequence was massive as a small time could have cascaded into a global scale incident Right. And this leads to the adoption of automated testing to find bugs and gain confidence"
  },
  {
    "startTime": "00:26:00",
    "text": "in the correctness of configurations Research papers have searched and there are significant engineering efforts going on as well However, despite that, all major cloud providers have adopted testing in their network CICD pipelines, outages are still happening. Of course, many other things could have made networks wrong, such as hardware failures, power outages, but even in the part of what we think our tests should have caught back networks wrong, such as hardware failures, power outages, but even in the part of what we think our tests should have caught them. There are still bugs that made it to the production One example is the Notorious 2021 Facebook outage where automated testing tools were in place but failed to identify the bug Now we have a problem Why would these network tests miss the bug? in the day-to-day operations? One may think that the testing tools could be buggy or the tools were just probably not capable enough to check all different kinds of network properties. These are all true, however There is one point that the networking community was paying less attention to That is the completeness of user-provided test weeks Configurations today are large and complex and a single test only covers a few aspects of them. Imagine if a part of network configuration is not being covered by any test tickets at all, then bugs in this place won't just be ideal identified, right? Regardless of how capable of the testing tools are. So in principle, I believe everyone should be with me that the completeness is better than incompleteness than how are we doing today and how can we achieve completeness? These questions are not easy to answer"
  },
  {
    "startTime": "00:28:00",
    "text": "today. Let me try to give you some sense of it via a very simple demo network Suppose we have two routers One connects to the internet service provider and it connects to the other router R2 as well Now a critical part of this network course is the configuration of both routers. For those of you, who may not be familiar with router configurations, they are basically commands and parameters that can control router behaviors in many ways. For example, a router config usually has a section specifying what routing protocols are running on the left. In this case, we use BGP protocol and the configuration also shows who are the neighbors of the router. On the left, two neighbors of R1 are declared, and for the second neighbor, and import policy is also declared, which are will explain next So the routing policies are another very important section of router configurations. They are used to customize the behaviors to process the routing information. For example, on the left, we have the policy checks the prefix of incoming routing messages from the neighbor ISP. And if they match a pre- predefined list called internal, then it will be permitted Otherwise, it will fall through to the next, which is default branch, which will add a tag to the message before permit. And this tag is used by another router to selectively admit routes. If you look at the policy on the right, it matches the tag for permission and then deny all others Hopefully, this is complex and hopefully you haven't been lost there And given the configurations, routers will produce the routing tables, which is then used for the actual package"
  },
  {
    "startTime": "00:30:00",
    "text": "folding right okay now how do we write? tests for this network? We write it based on our understandings of what this network is supposed to do For example, we want to check that R1 is paired with both neighbors via BGP, and this can be done by checking the company configuration contents And we may also want to check that any packets in print 20 slash 8 is reachable from R2 to ISP and this type of analysis is readily available today, which is not as data plane verification Now, this test wheat has ensured that the BGP period is configured and the connectivity to the internet is good However, this seemingly good test suite did miss a bug and because this routing policy, as highlighted in right here, on R1 is supposed to deny any route that overlap with the internal IP addresses but it is doing the opposite due to a typo And this bug is serious because these IP addresses corresponds to hosts that attached to a our routers, and we should already have internal routers paths to them which is not shown in this figure, however permitting an external route may override these internal forwarding paths, which will make our hosts with these IPs be unreachable To be able to find this bug via automated testing, we must realize that this routing policy term is not being tested and then we can add a proper test for it An example test would be evaluating this policy term with inputs that have the internal prefixes and make sure that they are rejected at the output of this routing policy Now, going back to our questions"
  },
  {
    "startTime": "00:32:00",
    "text": "how difficult it is to know how well an existing test rate is doing for a network and how difficult it is to write complete tests, right? For this time, network, it may need paying more pay more a network and how difficult it is to write complete tests, right? For this toy network, it may need paying more attention to the configuration details and it is still doable, but we are need to think beyond this toy example Our network engineer's daily job is to ensure that the reliability of networks that are of global scale. These are hyperscalers these are super complicated, and the configurations of them are maintained by a lot of different people and they evolve at a really fast pace. So creating and maintaining a complete test suite for these tests is just too difficult to be done by our engineers alone, and we need better tools to make this process easier In this work, we propose to help engineers write more complete network tests with configuration coverage. Given the network state and a test with our goal is to compute which configuration lines are covered and which ones are not And this feedback can help network engineers identify if there are testing gaps and once they know the gap, they know what is required new tests to fix the gap In this way, we can effectively improve the completeness of next tests, which in turn will improve the reliability of our network infrastructure Next I'll introduce how we define configuration coverage So network tests comes in two main flavors The first type directly analyze"
  },
  {
    "startTime": "00:34:00",
    "text": "configurations as the test one is doing here It examines the BGP peer configuration on R1, which corresponds to the line 1 and line 2 as highlighted in blue here. So we can easily define lines directly analyzed as covered no problem The real challenge comes from the second type of test or data plane test Instead of directly analyzing configuration, they test the data plane states in other words, the output of configurations If you check rich a bit you are not reading the configurations, but the wrong tables produced by the configurations So data plane tests are used a lot in that network testing. So when defining configuration coverage, we want to have them supported And our proposal is that by testing a data plane state, we are indirectly testing the configuration lines that contribute to the production of this routing table entry. We define the contributing lines at the coverage Now we need to define who are the contributors to a data plan state As we know, in a district control plane, a piece of routing information is shaped by each and every hop along its propagation In this example, a route is propagated from left to right, and Route 1, Route 2 shaped by each and every hop along its propagation. In this example, a route is propagated from left to right, and route 1, 2, and 3 have policy terms that add a community text to the route, which are used by the Route 4 to admin routes. If this route is tested, on Route 4, the local policy term is of course a contributor line because it admits the route But beyond that, we find the policy terms on the previous hubs just as important"
  },
  {
    "startTime": "00:36:00",
    "text": "as the local one. Because if the haven't added tags along the way, the tested route won't be derived at R4 So we define a contributor as lines who are critical to the existence of a data plan state, regardless of its local on non non-local routers Therefore, the key problem that we are solving in this work is to efficiently map any given data plan state back to its contributor configuration lines. And this is effective a provenance tracking problem To motivate our approach, we describe two strongman solutions. The first is to do a full data plane simulation and record the contributions at each step This will do a lot of unnecessary computation. Ideally, we want to compute contribution on demand and only for those who have been tested. And this only demand provenance tracking has been done in the field of deductive databases. However, it is hard to achieve both fidelity and performance if we encode the whole control plane simulation as deductive clauses So, our solution is based on an insight that the network state often hints the contributors themselves As you, we have attested rib entry from the previous example and we don't know anything about its contributors yet but this entry has a protocol field indicating that it is from the BGP protocol, right? There is a solid protocol field in the RIP that tells us that Because, but from the BGP protocol, right? There is a source protocol field in the rib that tells us that. Because based on control plane semantics, this route then must"
  },
  {
    "startTime": "00:38:00",
    "text": "have been derived from a BGP announcement sent by its neighbor. And it also hints that which neighbor it is, because the next hop is up route then must have been derived from a BGP announcement sent by its neighbor. And it also hints that which neighbor it is, because the next hop is R1, so we can guess that this BGP announcement is sent from R1 to our out art. Besides, a BGP route must depend on the BGP session between R1 and R2 being established, right? And moreover, we should also count the import policy that is used to admit this route And further, we can keep walking back and found the contributors of this first level concept contributors. In other words, the grand contributors For example, the BGP announcement must come from a BGP route owned by the neighbor and the BGP session must come from the BGP peer configurations at both end of the session, right? In this way, we can infer the contributors on demand which means that we walk backwards from a tested data playing state and step by step by contributors on demand, which means that we walk backwards from a tested data playing state and step by step and ultimately discover all contributors As you may have noticed, this forms a graph structure. The edges are contribution relations, and the vertices are the entities in a network, including data planes states, configuration elements, and some auxiliary concepts that help bridge the contributions contributions So this is the core idea of our approach. We system systematically model network contributions use a graph core idea of our approach. We systematically model network contributions use a graph-based model, and we also propose an efficient algorithm to infer contribution on demand If you would like to know more about it, our papers talk more and our implementation is open source. Please feel free to check them"
  },
  {
    "startTime": "00:40:00",
    "text": "Next, let's talk about the design So we designed our tool to take Confident Please feel free to check them. Next, let's talk about the design. So we designed our tool to take configurations, data plane states, and test traces as input. And we have implemented a net our tool to take configurations, data plane states, and test traces as input. And we have implemented a netcove to work with the open source configuration testing tool Batfish, which produces these data plane states via simulation. In concept, Netkov could also support tests in live networks or NBFARC emulating networks, as long as we have configurations and routing tables Now I'm going to do a live demo of the coverage results produced by Netcoff This visualization is based on open source code coverage tool called LCOF As you can see here, we show total lines versus testing lines in the overall project on the top right corner of this report, as well as the computed coverage rate of 26.1 26.1% And then I'm going to click the button and it asked us to browse into the directory and show the coverage of individual router configurations As you can see, we have 10 different routers in this folder and we show the breakdown coverage of each of them And what's coolest is the next if we navigate into the source file, we can view coverage results as colored annotations on sources. It is very cool convenient then to view and figure out whether there are lines you care about which is tested or not and you will be able to find any surprising testing gaps gaps All right Let's go to the next Okay in the remaining several minutes, let's take a look at"
  },
  {
    "startTime": "00:42:00",
    "text": "how we can use Netkoff to help ride better test weeks. The network will be looking at is Internet 2, a national backbone network in the U.S. It has 10 BGP routers and over 19,000 lines of configurations We adapt from the Route Views project data set to know the route announcement received from more than 200 external peers. So how would you test this network? A prior word called bagpipe proposed three verification properties for this network. We adapt them in tests using the BetFesh APIs So the first test, log to external, checks that if a BGP route has a specific community text called block to external, then these routes must, may not be announced to any external peers Then the no martian test tracks that if I received the BGP announcement had a specific prefix, within a range called the Martians, they may not be accepted. And the third, route for preference checks that if multiple routes to the same, destination were accepted from multiple external peers the Internet 2 must not select the one from a less preferred peer So these three tests consider the B multiple external peers. The Internet tool must, may not select the one from a less preferred peer. So these three tests consider the BGP routing behavior from three different aspects So how well are they checking different aspects of the configuration? Let's see what Netkov tells us The three tests collectively covered only 26% of the lines that are supported by our tool and these three individual tests covered dot 6%, 0.9% and 24% respectively, which means that the majority of the configurations are being completely untested So, um"
  },
  {
    "startTime": "00:44:00",
    "text": "this is surprising to us at first, and if this is surprising to you as well, you're welcome to try NetCorp on your own network to see you what's happening, and you will potentially join us in an effort to start an IETF workgroup to standardize configuration and put it to more usage All right the existing tests may have low coverage, but no worries We can use NetCob to make it more complete Here's an example So the No Martian test we just viewed from the previous slides is about the import policies of Internet 2 So when we look at the import policy, to find the testing gaps, we can, by viewing this like colored annotation on source, we can immediately figure out that there are five, if you can, sorry, I think it's a little bit blurred, but basically this is a routing point that has five terms. And out of these five terms, they are only one that has been tested, which is market green here. And this term is called block Martians. And there are four other terms that are marked as red which means that they are not covered by viewing at this result, we can immediately figure out that, okay, probably we need to add tests to track that these four other classes of freedom traffic are being rejected as well, right? So based on this knowledge, we add this test and the test test to check that these four other classes of freedom in traffic are being rejected as well, right? So based on this knowledge, we add this test and test it again and the result will show that all these lines will be marked as green So in our study, we made three similar tests to this which improved coverage from 26% to 43% It is far from perfect but for a network with 90,000 lines of configuration, we can't expect"
  },
  {
    "startTime": "00:46:00",
    "text": "a complete test with just six tests With Netkoff, we now have the visibility to our progress for the first time and a viable path toward 100% of coverage All right to conclude, complete enough testing is hard by users alone and it is impairing the reliability of the network. To this end, we define a network testing is hard by users alone and it is impairing the reliability of the network. To this end, we define and compute configuration coverage A key problem here is to efficiently map data plane states back to contributor lines and our approach is via a graph-based model and an efficient algorithm to infer contributions on demand And finally, we show that the feedback provided by that Netcoff can effectively make net graph-based model and an efficient algorithm to infer contributions on demand. And finally, we show that the feedback provided by Netkov can effectively make network tests more complete Okay, now I'm going to take one minute to talk about the next steps So over the last decade, network testing and verification have evolved significantly All large cloud providers have built such tools in internally and many companies have over this capability commercially So these testing and verification tools are built on different technologies, and we lack standard metrics to guide engineers in choosing the most effective tool or technique. And on the side, the extent of production provided by them. So during this IETF meeting, we are proposing to initialize and workgroup effort to bring configuration coverage to standardization. If you feel interested, please join us as an informal discussion during the BRIC session later, just outside of this meeting room. And you are also welcome to contact us offline I'll stop here. Thank you for listening, and please feel free to ask you questions. Thank you All right. Thank you"
  },
  {
    "startTime": "00:48:02",
    "text": "Fantastic talk. Are there any questions? And uh Jenna, first of all and then we'll go into the queue Thank you so much Jenna, Ingar, Fastly. Thank you for this talk. It was a lot of fun fun As you are describing how you have the data plan similarly, and then you'll use that as a way as the premise, I would say, to test what part of the configurations are being used It occurred to me that you could extend this to generate configurations Have you thought about that? Yes, that is a great question So Carriage, are you talking about it? coverage guided test generation? Basically, yes Yes, indeed. And we have, think about that, yes And we find that it can do part of the job, yes. But what it cannot do is to generate the assertions, which is the intents of what should be tested, right? and that should be filled by engineers like by hand. So yes, it can do job, but it can only do a part of them. Isn't your data plan itself the assertion? So we can generate tests by looking at what exactly this data plane does, but it can be used to find bugs inside itself right? That's true. Yeah, yeah so that's our view on it yes thank you thank Jonathan hoyland Cloudflare so I I wanted to know why you're not using oh sorry, not why. This seems like the kind of thing you would use formal methods for and get perfect answers rather than trying to do test coverage, right? And Bagfish, I know already is a"
  },
  {
    "startTime": "00:50:00",
    "text": "formal methods tool. So yes, it doesn't check the lines that can't possibly cause problems, but why is it useful to check the lines it knows can't cause problems? You are talking about why we need 100% coverage? I mean, well, it's why is tests a good choice here at all, right? What I want is not tests, it's mathematical proof that there's no problems, right? Like tests it's like, eh, well, you hit that line, but you didn't hit it in the right way, so it doesn't count. I see So if you're talking about coming up with complete verification or proof, that Nath will be doing correct, I think you are basically falling into the same trap that your formal properties that describe the network intent may not be complete And that's same trap that your formal properties that describe the network intern may not be complete. Sure, yeah. But your tests also are incomplete yeah even if you hit every line that doesn't mean you caught every logic bug indeed indeed So that's what, that's our positioning So basically, we are initially in these slides this effort to help both the completeness of tests as well as formal properties, which it doesn't support a lot of verification right now, but we are hoping that, you know, in the future it will be extended. And we are very aware that as similar to the philosophy of software testing, 100% coverage doesn't mean that it is bug-free, but it is least that if the coverage is low, then you must are in trouble, right? so it's it's it's our position yeah um yeah because i i just thought it was a little bit unfair to say uh bagfish doesn't cover all the lines because like parts of the formal methods things it doesn't come the lines that it knows can't cause problems so like it's not useful to cover those lines yeah"
  },
  {
    "startTime": "00:52:00",
    "text": "yeah yeah thank you And I guess come to jonathan hui usable formal methods research. Oh, yeah, and comes to my research group, it's fun uh lauren yeah thanks a lot for the talk. Very good work. Actually, my question especially covered, address, Janus point and the previous guy I mean, because at one point you mentioned that you are building kind of a graph based on the contribute because my question is about you address a lot about the syntax of the bugs or non-coverage. Are you also looking into the cement? I mean addressing the what we were called intent about the logic. But having a graph can be also a way if you can run some inference, or could be a also a tool that you can use to actually detect some of the logic that you want to test So are you using that? I mean, or is it part of what's coming next? So I am not, I have a full picture of a good answer to your question So basically what we are doing here is indeed just checking like syntax, I mean, the lines but we have not yet got a full understanding of what should be the semantics of a network So we have another work that you may want to check out that attracts what are the forwarding paths, what are the network interfaces that have been checked that have been covered by a network test suite I'm not sure if it's answers part of your question that what about it what is the cement of the network that have been covered but can't talk more about what are the semantics that you are? if I can reformulate I mean if you write a reconfiguration you have an instant for something to happen in the network you put a rule or something. When you do your test coverage, you say, okay, I check that this configuration, I looked at it. But you cannot say, if it's right or wrong. I mean, so is the configuration"
  },
  {
    "startTime": "00:54:00",
    "text": "right or wrong? And can you attach that to your test? coverage to kind of? Got it. I checked the syntax syntax but now I need also to check if the intent of the configuration is not creating issues. Yeah let me rephrase that So by talking about the semantics of network, you are talking about a list of network intents that is written as the semantics of network or as the how the network is supposed to do, right? And the year, I think hopefully this work can that is written as the semantics of the network or as the how the network is supposed to do right and yes i think hopefully this work uh can be extended to compute coverage for that but actually our question is how does that written specification be created? you know, at the first place? We haven't seen that actually. So I know some of the hyperscale are doing that probably internally which is, you know, aligned with the entire interim-driven network, the paradigm But it is not something that is none to our research committee yet, and we haven't been able to put our hands on that Happy to follow up later. Yeah, thank you for question All right. One last question quickly, please Yeah, Alesson Mane. Have you thought philosophically? about whether you think this is actually a good thing to be doing? in the sense that you're probably find a lot more problems, but you'll then lull test engineers into a false sense of security so it will have more crowd strike type events where everybody thinks everything's going to go well. You don't have enough people in the upsend centers because things are going well and when they're excrement does hit the fan, then things are just going to be really bad because you don't have enough people to fix it Have you thought about that? So is this question about like pursuing a high coverage would make we consume more like our engineer's time?"
  },
  {
    "startTime": "00:56:00",
    "text": "and make things slow? No, because if you make it better then management will say oh I can save people in operations because I don't need so many people so that when something does happen, they actually needed a lot more people because the disaster or the blast radius is a lot larger than it is You might be better off with lots of small so this is the chaos monkey principle. You actually, want noise in networks so that people are fixing it as opposed to going for perfection and then a big problem taking you out of the knees So I just think it's an interesting philosophical thing to think about. Thanks for the great question I think the assumption of this work is always to try to reduce the outages, but we really haven't thought about what comes after we reduced the possibilities of outages And I think that's a good discussion, but I haven't been thought about that yet I think that's welcome to take it off things. And I think that's a good discussion, but I haven't been thought about that yet. I think that's welcome to take it offline and have a more fun discussion. Thank you Thank you. And thank you for a great time All right, I'll just set up for that PTA All right, so a second post talk today is you have Gnostic I'm sure you can tell me how to pronounce that properly in a second"
  },
  {
    "startTime": "00:58:00",
    "text": "Yerhenya is a finally a PhD student at the University of Grenoble Alp in France, and she works on DNS and network security from large-scale internet measurement point of view Her talk today is on extending DNA errors, which was from what IMC must do Thank you for the introduction calling So, yes, the paper I'm going to present today was originally published last year at the Internet Measurement Conference with the the measurements done in early 2023 But things have slightly changed over things year at the Internet Measurement Conference with all the measurements done in early 2023. But things have slightly changed there were things. So in this talk I'm going to give you the updated numbers from this month But what hasn't changed since last year is that DNS is still one of the main components of the Internet, because essentially we have so many services that rely on translating human-readable domain names to IP addresses or the other way around So this figure here is of course a very simplified view of how it looks like but it does show some of the main components So usually what's going to happen is that we have some clients on the left that would like to get the API address of example.com domain name So the first thing it does is that it contacts a recursive result and if the answer is not already in the cache then the resolver will issue a bunch of query to different name servers until it reaches the nameserver of Example.com And then if everything goes well, the final answer is sent back to the client client now as I said if everything goes well because even in the very simplest scenario, pretty much everything can break. So one thing we can imagine, for example, there is some typo in the zone file and because of that, the software does not, did not matter to load it correctly and serves the zone to"
  },
  {
    "startTime": "01:00:00",
    "text": "end clients. Or maybe the zone file has some expired DNS sex signature So validating resolvers would return the surf veil another thing can happen is that the software refuses to process our requests due to some internal policy. Let's say if we reach a closed resolver but we're not on the ACL, then in that case we're getting the refused response codes. And then even if for once it is not DNS, maybe there is some underlying connectivity problems. And in that case, we will not be able to communicate with, any DNS server over there So of course, it's not that unusual that things break on the internet but the important question here is how does the end client know whether something happens and whether the resolution? failed? so since the very first day of the DNS there is this mechanism called arc codes or response codes. Essentially, it's a 4-bit field in the packet header with six values that were different in the original DNS 4-bit field in the packet header with six values that were defined in the original DNSRFC, such as form, error, serve, fail no error, and the remaining six were reserved for future use Now, at some point, we needed to grow beyond this 16 values, so response codes would start appearing in OPT, TSEC, TK resource records But that's also when things started getting slightly more complicated So for example, this response code 9 is has two different meanings. It's either not authoritative or not authorized And this response code 16 was assigned twice by mistake But in any case, if you're used to dealing with DNS failures,"
  },
  {
    "startTime": "01:02:00",
    "text": "on a daily basis, most probably you see quite a lot of surfails. This is a very generic response code that can be behind unresponsive name servers, lane delegations, DNS validation failures So in this case, how does the client know why exactly this resolution failed? And it turns out that the answer can be provided with extended DNS errors errors So what I'm referring to here is this proposed standard that appears four years ago. So originalization idea was to provide the mechanism to give more background as to why DNS resolution fail. But more generally it's a generic mechanism to provide some more context to DNS messages even if they do not necessarily fail And also to make it clear, extend the DNS error exist independently from response codes and no combination of the two is prohibited So we're not on the packet header anymore because extended DNS errors rely on EDNS zero And this is how the option looks like It's option 15. And the two main contributions of this RFC are the info code and extra text field So if you go to this previous example with the surf fail, now thanks to extended errors, we can actually see what happened. So first of all, we have this info code 7, which says that DNSX signatures have expired But then we also have some extra text between parentheses, which provides us even more details as to what happens. So in this case, Cloudflare tells us, it gives us the idea"
  },
  {
    "startTime": "01:04:00",
    "text": "of the DNS key that caused the problem, and even the expiration timestamp of signatures This extra text field is implementation dependent. So some implementations will give you very detailed in This extra text field is implementation dependent. So some implementations will give you very detailed info, others slightly less detailed and some software can leave it completely empty Then as for the info codes, there is a this register maintained by IANA with 30 entries as of now. 25 of them were defined in the original RFC and 5 were added later on. So there error codes are not really subdivided into groups, but looking at those, we can say that we can see that some of them deal with genoc validation failures others with response policies on caching, software operation, and other aspects of the DNS DNS These are also considered one of the best practices these days to run, for those who run public resolvers and it's, for example, one of the recommendations published in DNS Resolver recommendations that recently appeared at right right So one thing I wanted to analyze in our paper is how is the standard actually implemented these days by public resolve operators and open source software vendors So to do so, we have chosen nine different systems There are five big public DNS resolvers and four open source software vendors So speaking about the changes from last year this time include Google DNS to our test because at the beginning of last year it did not yet support extended DNS errors"
  },
  {
    "startTime": "01:06:00",
    "text": "Then for the test cases what we did was to create 60 different subdomains under extended DNS errors.com So those subdomains are either completely misconfigured or represent some of the corner cases. Now's the great majority of them would be dealing with DNS tech failures because after all we have quite a few extended DNS errors that represent those but we also have a bunch of link delegations there And then as for the methodology, it's very simple. We just sent the DNS error request to every tested system and then we analyze the response and check if there is an easy code inside and which one one So having done this test a couple of weeks ago, there seems to be something weird with Open DNS because apparently all my query is resulted in the ED code 16 which means censored If you look at the definition of this XEN DNS error, from the RFC directly, what it says is that, my domain name seems to be on a block list due to some external requirements So what we can do as well to see what happens here is issue a simple test with the DIG on Commons line And now looking at this TXC resource records in the additional section we can actually see what happened so apparently open DNS does not serve customers in France anymore due to some court order And that's because where that's where I'm based together with my measurement name server And that's the reason why I got refused and ED is extended censored in response to all of my requests. So this is just"
  },
  {
    "startTime": "01:08:00",
    "text": "one of the examples of how EDES are used today Also, in this particular case, we saw that the exact reason for blocking was provided in the TXT resource record but there is also this draft in the DNS operations working group, which tries to structure the extra text field for those cases when there is field in place to explain what exactly happened. So maybe in future there will be no need for that TXT records But anyways, after having repeats all the tests from a different vantage point in a different country Overall with our subdomates, we managed to trigger 18 unique extended DNS errors from all the 90s country. Overall with our subdomates we managed to trigger 18 unique extended DNS errors from all the nine tested systems. So the natural question here is to what extent those results? are consistent So what we saw that on the three tests cases resulted in the various same result, which was no ED at all. Those are so three subdomains, valid one, which is a our control subdomain, no DS which is assigned to a subdomain without the DS record published as a parent, and the unsigned domain which is not DNSX signed at all So for those three, we did not receive any EDE code at all. So what we can do to make such a comparison more fair is for each subdomain, we will compare EDs between themselves and ignore those cases where nothing was returned So we see more consistency with this approach. So if we want an analyze those systems that actually returned to extended DNS errors, they agreed in 14 test cases out of 63"
  },
  {
    "startTime": "01:10:00",
    "text": "So those test cases were mostly lane delegations but also three subdomains, which represents some DNSSEC, misconfigure So the natural question here is why do we see so many inconsistencies? And we identified three reasons for those. So the first reason is that not all the 30 ED scores are implemented by all the software we tested. So for example, with our test cases, we did not manage to trigger any EDs at is supported by Bindon9, for example The second reason is that some of the extended DNS error codes tend to be very specific, but others are mauch more generic. For example, talking about DNSF failures, we have this ED6, DNS bogus, which was returned by at least one system for the great majority of DNS-misconfigured subdomain So while some tested systems would be very precise and say, for example, signature misses, or signature expired, others would return a more generic DNSAC box And the second, the second, the second, is that some of the EDs, they do not signal errors but rather resolve their capabilities So we had three subdomains assigned with two very old and one of the newest DNSIC algorithms. And in those three cases, Cloudflare returned to ED1 which was unsupported DNS key algorithm So in this case, Cloudflare did not signal any misconfiguration on our side, but rather it provided more context to the resolution by saying that it does not support those algorithms And the reason why it's important to talk about those inconsistence"
  },
  {
    "startTime": "01:12:00",
    "text": "is this recent proposed standards that appeared a couple of months ago So the idea of the standard is that if we have a resolver that is ED compliant, it may choose to send reports to some monitoring agent that was specified by the name server operator So if the name server operator receives a set resolver that is ED compliant, it may choose to send reports to some monitoring agent that was specified by the name server operator. So if the name server operator receives several reports from, from the to some monitoring agent that was specified by the name server operator. So if the name server operator receives several reports from different pieces of software with different extended DNS errors that still points to the various same problem, then the nameser operator need to carefully interpret those reports So the biggest advantage of those extended DNS errors is that we can get all that additional info without having to send any additional packet at all So the next thing we were wondering about is whether we can use EDS to look for misconfigurations at scale So the methodology will be quite similar here in the sense that we still send the NSA requests and analyze the responses, but this time what we're testing is not just six to three subdomains, but almost three million registered domain names and we're using Cloudflare because Cloudflare is over because it provides a very detailed descriptions of what exactly went wrong in those extra text fields. And they returned us the highest number of unique ED codes during the previous experiments experiments So having done all those tests, overall almost 20 million domain names in the wild trigger, at least one ED We have 19 unique IDs in total, but as many as 215 companies of different extended DNA"
  },
  {
    "startTime": "01:14:00",
    "text": "errors per domain So looking at those that appeared most often this ED22, no return errors per domain. So looking at those that appeared most often, this ED22, no reachable authority, essentially what it means is that the recursive resolver could not reach any of the name servers for particular domain. So in this case, if you receive a surf fail, now that we know that none of the names servers of example.com were reachable by the resolver The second most common extended DNS error was a network error. So this error means that there was some problem in communicating with name servers And here in case of Cloudflare, it provides a very detailed explanation as to what exactly went wrong So we literally have the IP address of names servers inside the extra text field and the response codes that the Cloudflare saw on its side. So this is usually something we would not see as an endline Actually, these two error codes 2222 they mostly came together and in fact it was the most common combination of extended air codes. So what it really means in this example is that ED22 says none of the name service were reachable because ED23 precisely that the query to the name servers timed out out Now this extended DNS error codes is usually supposed to be returned by name servers if they receive a request for domain name that they're not assertive for but we received it from Cloudflare, which was a bit unexpected in this context But long story short is that if we send the request,"
  },
  {
    "startTime": "01:16:00",
    "text": "not a recursive resolver, but directly to the name servers of this example domain name, it's actually that name server that returns this ED20, not authoritative And what Cloudflare did was that it forwarded this error to the end line to us So in this example, we see that extended errors are not only generated by DNS systems, but they can also be forwarded from one system to the other And these three most common ideas that we have seen so far, they all refer to lame delegation Essentially, these are the situations when some name server is delegating to provide name service for a particular domain name for a particular zone, but it fails to do so And looking at the extended DNS error codes returned in the wild, this was the most common problem that we encountered Looking at the most extreme example, as I said, sometimes we get multiple extended DNS error code for a single domain name and we saw up to five of them So looking at this first error code EDA, it looks like there is some problem with DNS set, because we see DNS chemistry missing. But then if we look down the list, what we actually realize is that the name servers are not reachable because they are not authoritative for this particular domain And there is all where it's not able to retrieve the DNSQ records That's why it reports DNS key missing missing Now, this was an interesting case because we saw a couple of millions of domain names that triggered"
  },
  {
    "startTime": "01:18:00",
    "text": "R6 missing, missing DNA signatures, but for some reason, the resolution did not result in DNSIC validation failure, because we still got no error in those cases. So look at this extra text fields, it tells that the is some problem with the key with ID evaluation the dot 80 looking at this extra text fields, it tells that there is some problem with the key with ID 153 at the dot the AT zone file at the TLD So if we look at this very same domain with DNSV, what we can see is that there are actually two key signing keys but only one of them is active used to sign the zone and to establish a chain of trust So we did contact this TLD operator and they confirmed us that this second key with ID 153 it's a so-called standby key and it will only be used in case some emergency key rollover is needed So in this case, it makes perfect sense that Cloudflare reports to us that no signatures for generated with this key, but this thing is that it was not supposed to generate any signatures So we also are Cloudflare whether it was expected behavior or not They told us yes, and they also extended their documentation saying that if we received this extended DNS error, without the surfail response code, then most probably there is some key roles in progress or there was some standby key in the zone file So I will not be detailed in all the errors we received for those 20 million domain names We saw pretty much everything that could have been reported for example, expired signatures, Bogos Dianasek"
  },
  {
    "startTime": "01:20:00",
    "text": "domain names. We saw pretty much everything that could have been reported, for example, expired signatures, bogus dana sec, dnski is missing, but still we can clearly see that one of the most prominent problems that we see is lame delegations So four years after the SRFSI appeared, we can conclude that it is supported by major public result providers and software vendors and they all manage to identify the root code of DNS failures, but with different levels of specificity. Some of them return us a very detailed description as to want when thrown, others go more generic. So we also saw that it's very efficient to look for misconfigurations at scale, and we believe it's a very promising technique for DNS troubleshooting Thank you very much and I'm happy to take any questions Thank you So does anyone have any questions? While people are thinking about that question obviously, when you did the in the wild study, you found a wide range of types of failures and I was wondering, I mean, you know, it seemed like a lot of them were sort of the transient failures that you might expect. Do you have some feel for what fraction are sort of transient? failures which don't really indicate a problem with the DNS? just the network failed in a transient way, versus what? fraction indicate more of systemic configuration issues? with the DNS. So actually to really answer this question, what we would need to do is to run at least two"
  },
  {
    "startTime": "01:22:00",
    "text": "scons some time apart, maybe the negative day or even one hour later the results will be different for sure. So yeah, speaking of those lame delegations, and unreachable name servers, I assume that some of those are transit network failures but also the slain delegations are a very well-known problem that has been there for a while. So, uh, also expect affection of those to be a constantly present there. Okay so further measurements needed. Yeah. Okay, Matt Yes, I'm wondering if there's any pushback from people who might have been using obscure as an additional interference for hackers in not being too specific about it error messages, particularly about various types of authentications failure. I mean, for instance, telling which ciphers are not supported, potentially open Windows So speaking about the security aspect of those errors, that's are two things to keep in mind at least. The first one is for those systems who generate extra text fields, they need to ensure that there are not saying too much Then about the fact of the fact of and extended DNS error itself can also reveal some information for example if you're a resolve operator and you have a domain name on some block list you may or you may not want to disclose it to your end clients So in this case, you may choose to return one of those response policy zones extended DNS errors or you may choose not to do it I guess I have one other question I mean, you're at an IETF meeting and you've been there spending a lot of time digging into extended DNA"
  },
  {
    "startTime": "01:24:00",
    "text": "errors, RFCs and a bunch of other DNS RFCs Is there anything you think the IETF should? be doing, which they're not doing in this space? or any glaring things you would want to see difference in these types of standards? But what can we do better? Speaking about this particular standard, I have found it's very clear. It was approachable for me to read it to understand it and then to measure it in the wild So, regarding this particular standard, I do not have any comments really Good. It's good that we write some RFCs, which are clear. Glad to hear that All right, do we have any other questions? Okay, anyone remote with questions? All right, in that case, thank you very much"
  },
  {
    "startTime": "01:26:14",
    "text": "figuring out the technology yeah technology. Is that everything? Yep all right so the final talk today is by jessly and malvey Justine is a PhD candidate to EOAC, working on applied cryptography The various tools she works with have broad uses, but the advocate she's most interested in related to security and private identity on the internet One direction of her work has to do with bootstrapping identity credentials in a legacy compatible manner. The other deals with individuals identifying each other in encrypted messaging apps At that end, she's collaborated with researchers at Meta and worked on an open source key transparency implementation for WhatsApp, which is based on her work, Parakeet, which will be presented today So over to you. Thanks so much, Colin So I'm presenting Parakeet, which is a sort of contrived shorthand for practical key transparency for end-to-end encrypted message And this is joint work with Leff in Alberta, both of them at Mistin Labs, Isha Grosha at MSR, Air General Sir Kevin Louis and Sean Lala, all of whom are at Meta So, by the way, there is our already a key transparency working group. They're meeting on Friday after a new I know what a drag Friday afternoon, but if this talk interests you, that we're group. They're meeting on Friday afternoon. I know what a drag Friday afternoon, but if this talk interests you, that working group might be an interesting place to go. And in case you are not familiar with that working group at all, then maybe you also don't know what key transparency is, but I'm sure everybody"
  },
  {
    "startTime": "01:28:00",
    "text": "here knows how end-to-end encrypted messaging, for example, the signal protocol works And there's a messaging service to users Alice and Bob want to look each other up on this service to get public keys for each other and start communicating. So in order to get these public keys, they actually have to query the server, which also has a database that matches for example, phone numbers to public keys By the way, we'll just use username phone number interchangeably So hopefully that's not confusing And in a sense, what this makes the messaging service is not just a messaging service. It's not just running the signal protocol, but it's also an identity provider provider So now if Alice and Bob want to talk to each other, the first thing they need to do is get each other's public keys. So they look it up on the server. The server could respond with proper keys or it could respond with a malicious public key to which it knows the secret key and even though Alice and Bob think that their community in a way that only the other person can beat their messages really the so server is able to mount a meddler in the middle attack. And this is by the way assuming that the signal protocol is completely securely implemented and there's no bugs and it works perfectly encryption works perfectly. And what's even worse is that this actually can go undetected So the solution to this, at least what I believe, very strongly is the solution to this, is this transparent dictionaries model with some privacy So identity provider holds a dictionary with username public key pairs. That is the case today but and you users might join, and these users may then for their username update the public key, what they want and this by the way is the guarantee that they supposedly get today is that the server restricts queries to their username. So if I block somebody, they shouldn't be able to"
  },
  {
    "startTime": "01:30:00",
    "text": "query my username and see if I got a new phone because my public key changed or something like that. The thing that we do the server restricts queries to their username, so if I block somebody, they shouldn't be able to query my username and see if I got a new phone because my public key changed or something like that. The thing that we don't trust the identity provider for is that if the same username is queried at the same time, the server might actually give diverging values And by the way, this is an example of a more general problem and there are other applications that can find use for this type of solution. So one example is a centralized financial ledger, cough cough So there's a set central server that's trusted for privacy and for ordering So they're not going to just leak their entire database but, and they're trusted for ordering transactions making sure that they maintain accounts and stuff but they're not trusted for serving correct state, Kafka cough FTX but they're not trusted for serving correct state, cough cough, FTCS. And some of you might even have heard of this type of setting and the solutions therein are may sound relevant to certificate transparency or test evident logging, but for various reasons this setting has its unique challenges that are not just the same as certificate transparency so you can't just defer us to the CT various reasons, this setting has its unique challenges that are not just the same as certificate transparency, so you can't just defer us to the CTRFC and call it a day So let's go back to Key Transp transparency. Remember, we have in this model, and now, identity provider who holds a dictionary, as I've said, as ad nausea This identity provider may cheat by showing diverging views to different parties So what's a solution? Ideally, we want to prevent this identity provider from cheating altogether But then this ends up actually needing assumptions on clients specifically that they're good at storing long-term cryptographic secrets which we all know is a big problem And this also, by the way, is not an assumption that current systems make at all So this would require a whole other kind of UI and thinking about those kinds of problems as well So what can we do? What kind of security guarantee can we get?"
  },
  {
    "startTime": "01:32:00",
    "text": "that is closer in terms of user experience to what we already have? The security guarantee we go with is what we call anti- we do, what kind of security guarantee can we get that is closer in terms of user experience to what we already have? The security guarantee we go with is what we call anti-active vocivocation or non-acivocation Basically, the server should not be able to show different keys to different clients without getting caught at some point. So at any given time, if Alice thinks her key is PK Alice, show different keys to different clients without getting caught at some point. So at any given time, if Alice thinks her key is PKK, the server cannot get away with telling Bob that Alice's key is PK bad. One of these two parties is going to do detect it sooner or later And so given all of these requirements, let me just go through the model By the way, this is going to be a very dense slide. Please bear with me and we'll go over the most important points real quick at the end. So the first party is the identity provider, which stores this database and is trusted for privacy and authentic So for example, if you log into WhatsApp using your phone number or into signal using a password or something like that. And we want to eliminate trust for serving public keys And by the way, all of the updates that are being made by users or users joining, all of this takes effect in discrete time steps called epochs. Just it's much more efficient to deal with it this way. And then there's users join the system, then they might up update their key. They might want to look up each other public key if permitted, so you could go with a white list blacklist, whatever type of model you want. That's doesn't matter. They want to check their own keys history up until the present time steps So like whatever changes were made to my key, I should be able to know So which brings us to a guarantee that the users want, which is no changes are made to their key without their finding out. And correspondingly, their friends should receive matching keys for them. So again, what I said before, if Alice thinks her key is P.K. Alice, that's what everybody else should believe her key is as well. Now, there's a big one"
  },
  {
    "startTime": "01:34:00",
    "text": "what I said before, if Alice thinks her key is P.K. Alice, that's what everybody else should believe her key is as well. Now, there's a big white space there, and these are the two parties I've talked about So now I'm going to introduce a third party, which we'll call the auditors And these parties are basically just there to share some of the computational burden so that the users don't have to do very, very expensive computation or the server doesn't have to do very expensive computation that has latency for everybody involved So these parties just check some global predicates, meaning that the server is making its updates in some sort of kosher way. So they could say between Epic Start and Epic End, the server didn't delete any records And this could be anybody, user, smart contracts designated machines, TEs, SG whatever you want, some unrelated do-gooders, if you will And since it can be anybody, they actually should not learn data about particular users. Remember, we wanted the requirement that users want privacy. They don't want random people learning, whether their public key is changing or even what it is, right? So given this model, I know this is a dense slide, just focus on the bolded text. We want to eliminate trust in the server for serving public keys correctly And users want that all changes to their key are happening only with their knowledge and everybody else sees what they're supposed to see according to that user And auditors check some global predicates but are, basically completely untrusted otherwise so at the at these with these high level details some components fall out so that we need a mechanism for committing to a mutating database and a mechanism to allow users to monitor their own public keys and some source of ground truths Like if you commit something and you want two people to have the same view at minimum you want them to have some small stream that's"
  },
  {
    "startTime": "01:36:00",
    "text": "they know is going to be identical And also what we'd like and this by the way, fell out of my collaboration at META wanting to actually deploy this We'd like to support billions of users That's billions with a B, not an M And not only that, we also want to serve users with computationally limited devices just because you cannot afford the newest iPhone 15 doesn't mean you shouldn't get the best security guarantees So just again recap of the motto, server, server has a database. They need to commit to this database It's changing. There's a state that's mutating and we need a way for users to access this commitment so this is in other words this is the breakdown of the problem into two parts. And we'll talk for about committing and verifying a mutating data database So if you want to diagram, that's what I'm talking about So there's actually been some work on this before, parakeet, and by the way, since a well. And the solutions are usually based on Mercotrees or some kind of vector commitment And in our work, we use Marco trees and that's what we complete with as well. And the reason being that these require the least assumptions and as a standard spotting, you know that nobody who's running a really large system would want to deploy things without standardized components So to that end, that's what we use And then they reduce user workload by either using third-party auditors, like I said, or they use cryptographic tools such as NARCs or proof systems or something like that And then for allowing users to monitor the history of their own keys, there are a few ways to do this. You could either use a bend-only authenticated data structures to prevent the server from cheating"
  },
  {
    "startTime": "01:38:00",
    "text": "and then just erasing the evidence and being done with it The problem with this is that no state changes are ever deleted. That's literally what a pen-only means So that's one option Or users must do linear work in the number of server epochs to monitor their own key Essentially, it's kind of like assuming the user is all or users must do linear work in the number of server epochs to monitor their own key. Essentially, it's kind of like assuming the user is always online because if they don't check certain epochs, the server might have cheated, and they just get away with it Or the server generates some sort of expensive zero-knowledge proofs so might have cheated and they just get away with it. Or the server generates some sort of expensive zero knowledge proofs. So, OK, so I mean, it seems like all of these various components have kind of been solved, and this is a solved problem so what are we doing here? It turns, yes, in theory, we've solved this problem, but a lot of practical issues show up, and we've discussed several of these in the paper but I will limit myself to three of them here So the first problem I want to talk about a statement machine replication. A lot of existing work just abstracts this away and the experiments they just used a single machine. And I know because I ran some of them. And that's obvious bad, because at a global scale system, you're not going to have a whole bunch of servers a whole bunch of servers that are basically represented by a single machine that stores a data structure locally you just don't do that right so our work actually has a flexible storage layer if yet, which just allows you to plug in any existing database and just implement the interfaces the requisite interfaces that are relatively simple So that's, that's all I want to say about that. The other thing so the data structure for the state commitments, people had dealt with this before and at the scale that we were looking at this would grow to hundreds of terabytes over"
  },
  {
    "startTime": "01:40:00",
    "text": "the course of even half a decade and obviously this this means that it's going to be too expensive to deploy, so it's harder and harder to convince anybody to do this work. So what we did is we replaced the underlying data structure to the following effect So the orange line at the bottom, if you can even see it from the back, is the storage costs of work over five years with 10 million updates, so that's users joining or updating their keys Over five years, it's under 5 terabytes and for a work that gets pretty much the same guarantees called seamless and use the same assumptions and everything, they ended up with 110 over five years. And this, this that gets pretty much the same guarantees called seamless and uses the same assumptions and everything, they ended up with 110 over five years and this would just keep growing, right? So that's all I want to say about that. I want to go in a little bit more detail on users checking their own keys so i mentioned earlier, there are three ways people do this You either use your knowledge proofs You assume that users are always online or doing the equivalent amount of work to always being online, or you use a pen node data structures. Each of these has its own pIETFalls so ZKP is impractical for the server always online is impractical for the client and append-only data structures. Well, they have ever-growing storage costs. And even with our optimized data structure, and all that and if somebody worked on it further and got it to be even better i mean that's all well and good but try can convincing somebody at a corporation to deploy something where you have completely uncapped storage costs with no way of doing any sort of garbage collection So we basically come up with a middle ground, which we call secure compaction So you basically say maybe users don't have to be always online, but users that are actually using the system will come online at some point, intermittent and given that that's the case maybe we can find, do append only"
  },
  {
    "startTime": "01:42:00",
    "text": "but to only an extent and how do we do this? Let's go into a little bit more detail here here So think about this. So this is server epochs. So remember I mentioned the server is running in epochs and it's introduced batches of updates at every epoch. And say the server has had hundreds of thousands of epics so several years of five so everything that happened before epoch one thousand so five years ago or something might be possible for deletion. It's just so old So maybe you could just say, let's just delete anything that came before Epic 1000 Auditors just check that anything that's being deleted is old enough. However, that is defined But the problem is some of this old data may still be relevant, and not all of it may be obsolete So, for example, if Bob didn't update his key in a long time. His most recent key was before the app acquired it's considered old enough, but it's still Bob's latest key, right? So it shouldn't be deleted So maybe auditors check that only old enough entry are deleted and that for any deleted entry, there is some superseding entry that basically overrides it. So it's actually obviously, not just old the point is now this leaks data metadata for a particular users to the auditors, which we don't want to do as well, right? right? So instead what we say, let's involve both users and auditors and have some well-defined sparse epochs that only deal with deletion-related options operations and what we say is let's mark anything that is ready for deletion is tombstone and give a gray spirit to everybody to make noise to say if something tombstone is bad"
  },
  {
    "startTime": "01:44:00",
    "text": "give them a grace period or a checking period to whistlebl about that And auditors check that everything that is tombstone is old enough and correspondingly, users check that only expired values for them might be marked for deletion. So anything that is marked for deletion for them is obsolete for sure. And then at the end of this checking period, so, you know, you make this period long enough so hopefully the user comes online at least once in this in this interim and then checks and then after this gray spirit is over, you garbage correct And, yeah, and so that's how this model works. I won't go into detail for how this is all implemented, obviously And I actually want to conclude my discussion about this commitment and verification for mutating databases part here, and go on to disseminating small commitments so just as a reminder you have this database that's committed and users need a way to get this most up to date commitment as quickly as possible Now, previous work on key transparency specifically places this problem just out of bounds And then there's other work that seems pretty applicable so for example what if we use just existing gossip protocols that might work, right? Users have some out of bounds communication mechanism and they gossip whatever commitment they get and share their views. The thing is that this is a problem for a global scale system where you might actually end up with partitions. Besides, users, remember, we want to support users who have very computationally limited devices as well, right? We want to be able to make sure that also if their internet is bad or they come online and just keep playing phone tag with their friends, they're still able to get, these commitments and these cryptographic corresponding cryptographic guarantees so ultimately the dissemination might be too slow Even if the dissemination is in"
  },
  {
    "startTime": "01:46:00",
    "text": "pretty good and the gossip protocol works pretty well. All guarantees in this are retroactive So what is not retroactive? Blockchains Blockchains are technically supposed to upfront check everything that's coming in, right? So you could post a commitment to a smart contract or in the op-return field of a bunch of Bitcoin transactions that are predetermined somehow But now you have to trust as a company that's deploying this, you have to trust the blockchain and its code and as a user too. And by the way, even if you trust the blockchain and its code, the light plan solutions for this blockchain might be already too heavyweight so you're letting go of the guarantee of trying to support very low-powered users as well And actually prior work has shown that for any of the bigger blockchains, billions, again billions with a B users query, you could end up flooding the network with just queries for key transparency and not let it do anything else That does not seem like a good thing to do. So okay that is existing blockchain. So what if you just made our own blockchain and block means consensus. So let's just do deploy our own BFT consensus protocol. So let's ask the question, do we actually even need everything that can consensus provides? And before we even think about that, let's just see if we need to ask that question So are there any pIETFalls to consensus? Well, you have the n squared communication cost. So if you have n nodes in the consensus protocol, you have n squared communication you end up with delays as a result of that And by the way, this is notoriously complex to implement right as a slew of formal very verification work on consensus verification has shown So instead, we go back to the question is consensus really necessary? So remember, the server is already"
  },
  {
    "startTime": "01:48:00",
    "text": "trusted for compiling the updates and for finalizing the underlying database. The server already has infrastructure for compiling and serving messages from some sort of witnesses or quote-unquote consensus notes. So why don't we just use independent witnesses and deployed using TEs or industry consortiums or something like that? And these witnesses just need to store the latest commitment and check the the new commitment builds on it. So something like checking for a hash chain or something and so how does this work? This is very, very simple The identity provider creates a new commitment and just tells all of the witnesses, oh, I created this new up-to-date commitment that builds on the previous one you have. The witnesses check and if it just tells all of the witnesses, oh, I created this new up-to-date commitment that builds on the previous one you have. The witnesses check and if this check passes, they just sign the commitment that they have now, the newest commitment, and return it to the identity provider who just collects these signatures, maybe thresholdizes them or something or the other, but in any case, the, the identity provider collects these signatures and next to or something or the other. But in any case, the identity provider collects these signatures and next time a user makes a query, this goes together with the commitment. And a user basically just accepts if a threshold number of witnesses have signed this commitment And by the way, let's look at the communication here, right? That was our big problem with consensus protocols. So now the identity provider communicates with the witnesses. This identity provider by the way, is a big, powerful company that are maybe semi-powerful, who already has servers to serve users. They also communicate with witnesses and users but now the witnesses don't need to communicate with each other which speeds things up considerably and neither do they need to stand up the infrastructure to serve users because users are not communicating directly with these witnesses at all And besides, all of these communication benefits, actually we get all of the same guarantees as BFT"
  },
  {
    "startTime": "01:50:00",
    "text": "So this is basically Byzantine Folk tolerant, but you don't have liveness And we depend on the server for liveness in the first place, so that doesn't matter Giving that up is not bad in this setting and it can be used in addition to other mechanisms It's a simple protocol, easy to implement I literally just explained all of it to you. It's pretty much modular, so you probably get fewer bugs this way. And you can just use existing infrastructure and get certified commitments together with proofs and query resources so everything, every guarantee that you get is basically simultaneous and actually doing this in terms of consensus, you know that as the number of nodes increases, the latency is going to increase and as our graph here shows, that is not the case for this very simple, reliable broadcast type protocol And you can even have 80 milliseconds epochs now if you want. So very quick updates. Well, at least this wouldn't be the bottleneck. The bottleneck would be the data structure site which I talked about before. Yeah and that is all I have I think I'm out of time also. Thank you All right, thank you All right, does anyone have any questions? John after hoyland, Cloudflare Could you go back a slide, please? please? Yeah, yeah No, the one before that Thank you. You say that the witnesses don't need to talk to each other but if step two is a threshold signature, don't the witness need to communicate to produce the threshold signature?"
  },
  {
    "startTime": "01:52:00",
    "text": "I mean as long as enough it's basically like voting, so enough of them vote by sign off on the commitment it's fine and you can threshold any signature, any regular signature as well, right? You can just like, show shows your knowledge proof that all of these signatures fair that, like, five, uh, okay it's multi-sick rather than threshold sick Yeah, except, yeah, except you have, it's not that you, right like five... Ah, okay, it's multi-sick rather than threshold sick. Yeah, except, yeah, except you have, it's not that you require everybody to sign off as long as the majority signs off you're done Okay, very interesting. Thank you I guess my question is, obviously, the identity provider is someone like Facebook or who I presume we are witnesses? Yeah, so this would be something like T's could be one example of using witnesses You could use, for example, an industry consort assuming they don't collude with each other, or there's incentive not to collude with each other or there's regular or there's regulation that prevents colluding with each other right they'd have to be someone, independence of the agency. Yeah density provider. Yeah, indeed, yeah all right does anyone else have any questions We've got a couple of minutes Thank you Chirvan in the text in the chance posted link to the key transcript So if people are interested, further in the work, I guess that would be a good place to go One on Monday and one on Friday, so we're making anyone interested in that topic stick around all week All right, last call for questions If not, thank you I thank Jess Lee again That is the end of this session. I think there's a three fantastic talks today. I've got all of them"
  },
  {
    "startTime": "01:54:03",
    "text": "demonstrate the sort of very applied nature of the work and how we can have some really interesting protocol design work and measurement studies and so on, which translates into very practical results which are useful for the internet and hopefully applicable to the standards community and improve the Internet as well So three great talks there We have a couple more of these talks in the meeting in Dublin So if you're in the Dublin meeting in November, look out for those After that, we will be opening the nominations for the next year's prize So start thinking about any great applied networking research you've seen to nominate for next year's awards Please do come to the rest of the IAT sessions later this week to the applied networking research Workshop tomorrow. And thank you again to all the speakers Thank you, everybody"
  }
]
