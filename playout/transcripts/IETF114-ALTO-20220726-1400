[
  {
    "startTime": "00:00:05",
    "text": "thank you [Music] hello so this is a chingu and the CDP sign is Mohammed we are outer co-chair and so this is also Auto working with setting welcome to Philadelphia and for people in a room actually if you don't speak actually please keep your mask and if you uh you make a comments and make a presentation you can take a mask off not aware probably you already know this if you're not familiar please contact with Coach our connected with the chair and our ad F conduct guidelines and please focus on techno discussion with show your respect to your colleaguers IPR disk career if you have any IPR please follow ITF goals at a minute trivia so note that this session will be recorded and we will use midi Echo for queue control if you are remote participant please join the queue by Race by press wrist and abandon and leave the queue by a double click and uh when you make a comment please speak your name and for Blue Shield we have electrical blue sheet and it will automatically record your attendance and"
  },
  {
    "startTime": "00:02:01",
    "text": "and for chapter and Note Taker and we already have Jody and Richard to volunteer yeah so thanks for your taking notes and so the slides we already uploaded this take a look at that so working remotely so just remind actually all our discussion actually you know most work has been done on amenities please make a good user maniness we also can schedule some interview meeting if needed and we we actually have Auto working in meeting and uh you you use ITI working group WebEx resource so this is our meeting agenda we propose for today's discussion the first is session introduction and working group status update and uh and then we are focused on Charter item we have two uh important China items the first one is all the OM support and the second is auto over new transport for Auto uh om supporter will focus on the status update and resolve the pending issue and we receive a lot of comments before this meeting actually hopefully we can have good discussion on this topic second Auto over new transport we actually as a chair we request the review from our other area and we got a lot of quite good quality comments so we will you know take more iteration we hope Also may pay more attention to this Auto new transport actually engage with the expert from the art area and to get this worker because our Mindstorm actually"
  },
  {
    "startTime": "00:04:02",
    "text": "September uh we also will discuss the department experience of data actually uh we actually continued our hexon this is our second hackson made by Jody and also we have some other people like and and also Louis actually gave some update for what they are doing and so we'll have joined the presentation for this deployment experience update if we have time we will you know discuss no chatter item uh both Works actually relate to the computer aware networking and the the first one is considered Auto as the network exposure function actually we have three relevant chapter the first two actually are existing jump the chance to get updated before the meeting the last chapter uh discuss Auto Service function this is the new chapter so Luis will give the update for the kernel status in addition we have another draft architecture of computing Hardware Optical networker and also this chapter related to the Lewis worker maybe we can have someone discussion on this so since we represent this topic and uh so any agenda bash for this I see now so we move forward so uh document update actually uh so first a new app say and we since last it meeting actually we make a lot of progress actually we have three obviously get it delivered the first two actually are existing working group documents and unified property and a CDI"
  },
  {
    "startTime": "00:06:02",
    "text": "requested routing the last one actually the RC will coming and which is uh just before this before last 19 meeting is still individually but after uh after last itm meeting actually we can make a huge progress actually we already move this individual chapter to working good jobs and also now move to the rcq and get published so this shows 3D progress on this work and uh second actually after edited we still have two uh working groups after actually waiting for be delivered actually I hope the author can you know engage with outside Editor to address editorial comments and move these two worker forward and working Google draft and since not the IEP meeting we adopted two draft and om and a new transport so this will be focused on today's discussion and we rather actually this has been discussed in last night meeting already get it verified so this is the current Milestone status update uh you can see actually we uh already delivered the one of our Milestone coaster mode to for public application so we get this Milestone conclude and we still have three uh you know ongoing Milestone actually so please bear in mind in the the time frame for this issue work especially pay more attention to the auto new chance for this we need to engage more with experts from the other area okay [Music] um gems uh gems you can speak"
  },
  {
    "startTime": "00:08:04",
    "text": "we have gems in the queue can you speak no okay yeah that's a continue uh for external review actually just we mentioned actually we already received our early review and get some comments from hdb working group like Mike and so thanks to uh Mike and Martin and also Spence actually give a very valuable review so please focus on this external review and so I also want to mention actually we have Auto working meeting to discuss cellular information exposure actually two relevant workers why his movie the second is the pbecc and not only uh testing people are interested in this kind of topic we also see actually Alibaba and Princeton uh actually they published a lot of relevant paper and so we schedule meeting to discuss with this experts and research actually for example uh actually also Professor Jennifer and to uh energy also developed some of uh open source tools so these are very helpful to you know um adjust some of issue in cellular information exposure and also um actually also share some experience on cellular information aggregation and so the before this meeting they actually post a new version and and adjust some comments"
  },
  {
    "startTime": "00:10:02",
    "text": "based on some discussion in the interim weekly meeting and also monthly from Tess from Alibaba actually share his paper this paper already get adopted by its sitcom and which is focused on inter AP solution and so we actually agree actually we should you know for the next step which will come up with the framework to investigate water setting information to connect how to transport connect information to the application how to react to that information hopefully we can more make more progress after this meeting on this topic last one actually we do actually do a lot of effort to sort of socialize the author actually in this meeting and Luis will you know give a presentation in many office to introduce their Syrian practice integration with Auto and also actually I will discuss the auto introduction in obst working group and we already get a time slot on this and in addition actually we share and work with auto design team member problems actually to work on some paper which targeted iepf book and IP Journal and we will you know keep on to cooking this idea to hopefully we can make more progress so that's it and uh I think we can go to the poster presenter uh yes Auto om yeah so Jason is not here and we will ask Maddie actually to give a presentation so maybe come to the mic"
  },
  {
    "startTime": "00:12:10",
    "text": "hello everybody I'm Matty I'm here on behalf of the authors of onm module for also uh they shouldn't be here they couldn't be here uh in person so I'm doing the presentation on behalf of them but the discussion will be guided by Jensen uh which is in the uh virtual room and the the reason that I'm actually focusing on this point because it's it's the this uh presentation is uh intended to be to start a large part of discussions on onm uh because uh we intend to uh decrease uh increase the range of the range that it actually covers in uh into different in different parts that they will talk about uh so oi name stands for operation administs well I name stands for operation Administration maintenance and management of also protocol uh so in this slide you can see the latest link to the latest version in data tracker and also in GitHub uh which is good because a lot of discussions are going on uh in in iitfwgi uh uh also WG GitHub and also the definition of yank module yeah uh so after it 113 the group has received uh many reviews and addressed a lot of them uh so we have received five reviews from working in working group mailing list and we have an ongoing discussion with uh net mode working group and also we had five discussions on GitHub and we achieved two milestones for rnm and this the first one is a"
  },
  {
    "startTime": "00:14:00",
    "text": "document adaptation and uh the second one is that in hackathon of 114 uh we have implemented the concepts that are parts of onm uh for also which are given in the GitHub link okay so in this slide you can see a data model overview of the gang modules that we have uh included in the draft and also in the Implement implementation so we have the server management uh information resource manager performance Monitor and logging and fault manager and we have also data sources inside yet uh we have color code that uh the parts that are outside the scope of 1M but inside the scope of Auto and also the parts that are even outside the school of also which is like the data sources that are interacting with Source board sourcebond apis with data source listeners uh so uh so in uh this presentation uh we mainly want to all discuss six main questions and ask our comments about them and to further uh improve one and for the next ITF meeting so the first three one I have raised within the working group mailing list uh question four and five have been discussed internally in uh Auto working group and the last question uh is not have been discussed yet was it but it is an important question that Jensen himself will talk about and we will divide a large portion of this meeting to decide over that uh certainly uh so the first question is how to uh deploy data types in Auto related uh Ina Registries and we have two proposed model for that each with uh its own pros and cons the first one is to Define enumeration uh in Ina also types and it has a pro"
  },
  {
    "startTime": "00:16:02",
    "text": "because it's guarantee consistency between uh different types but it it has a con uh as a major consideration for us and uh because it's hard to extend to uh new data types for experimental drafts and also it requires I need to have younger skulls to be uh to interpret these data types so uh the second uh proposition is to use identities in ITF also Yang module and it has a pro because it's easily sensible to a new extendable to new data types but the con is uh it has it lacks the control uh for consistency and may results in uh challenging interoperability between uh variables uh so we are considering which one uh should we go go on with uh between these two the first one uh was to use enumeration and second one is to use identities in uh the image the second question uh is uh um the server the server level management by inspired by rescamp uh we added uh several lists and accomplished servant listed uh listen stack uh which is configurable in the data Yang module uh but the the remaining question here is that uh whether we should include configuration parameters of lower level underlying protocols in that two or not for example a lower level HTTP configurations like uh cache control or retry after Etc uh so that's the main question uh for this uh second subject server level management whether or not to include a lower level configurations uh the third question that we try to"
  },
  {
    "startTime": "00:18:01",
    "text": "answer is logging and fault management So currently in Yang module uh we have defined uh success failure cons for requests and responses uh but the reviewers have proposed uh three more uh lagging criteria that we will add uh in the uh in the revision of the draft uh the second one is Success failure records for the configuration updates themselves uh the second one is uh records for which configuration types is the dying module uh of supporting and we were wondering if kanyang module uh model provide this parameter itself or not and um this the last one is the census update of the connections to data sources that also server is supporting and we're looking forward to getting to get more Stacks uh more suggested useful metrics in the comments discussions or in the experience and of real in the experiments experiments of real deployments uh the question for uh is that so far we only have worked for server-side onm uh but the client side also needs and a module to be comfortable configurable for example in these two domain uh the first one is that uh how to uh how to configure uh uh the way that it also client is accessing auto services for example the URI uh their resource IDs and the parameters that of the alto client should use to be able to query out a server and uh the second one is uh data model for transport mechanism control with that to which we will uh come back later but there are the three main uh ways data"
  },
  {
    "startTime": "00:20:01",
    "text": "polling uh pops up or on-demand query which are very different from each other and uh so for this one the main question that we want to ask comments for uh is that whether we should add a new top level container for also a client uh or list or add a or whether to add a new data source type for auto server and consider also client as an also data source listener uh so is there very different and oh we just wanted to ask comments like if anybody in the queue has a suggestion or in the room we'll be happy to discuss in this session okay uh uh the uh the uh the next major question that we want to answer is a server to server communication so we have introduced multi-dominant settings for Auto in two major drafts the first one is for use cases and the second bar for uh second one is for analytics uh the link of these two drafts are given this slide that you can refer to uh but we have face uh in in the in um in the work for uh through the work for this uh ITF meeting we have phase two main uh question uh the first one is that auto server needs sometimes need to be a data source for another Auto server to provide it for uh Network information so we have two design options here the first one is to collect data uh using Auto directly for in which an auto server can act like autoclient for another Auto server uh and that may need extensions to also and the second design option is to use other software Source spawn protocols to expose databases of Auto servers between uh multiple Auto servers and for which we have no standards so far and need to decide for"
  },
  {
    "startTime": "00:22:02",
    "text": "that to better be a standard or not a standard or not and the second main question here in server to several multi-dom incoming Communications between Auto server is cross custom in past discovery which is a question that we have reached to uh in the hackathon and in the deployment so it's a real question and uh is that not no no none of the existing Auto Services can provide information for across domain pass Discovery and we actually require some mechanisms to look up to increase and increase sport of interdominals and in different administrative damage to track back the roads between multiple uh administrative domains so these are the two questions that we see can seek answers for can you go through uh uh the question uh the last question that we are cons that we're seeking answer to Is like uh the one that we have not uh we don't have an answer for yet and we want to ask for like most of the comments on this part uh so is like how to unify the the different data sources uh in Yang data model and configuration so we we need a different data uh models for different uh means actually the first one is for example for Source One protocol stack parameters like URLs or protocol versioning or authentication settings that that I previously talked about uh the second one is to set the query parameters the query expressions and the last one which is like the most conflicting one is the data collection mechanism parameters uh when when uh the clients have the ability to particularly pulling the auto server or use pop sub mechanisms or on demand uh querying so for this one uh Jensen will continue the discussion so Jensen if you are in the room go ahead"
  },
  {
    "startTime": "00:24:02",
    "text": "please you can go ahead hello thank Clarity to uh yeah so for this question actually uh you're saying in the current document uh we do introduce these three uh panel parameters for each data.platformer configured uh uh by the current uh data model in the in the document on a different two maximum to track the data why is that it can do the periodical polling and otherwise the captcha but in our uh a current in the real development so so with some information resource may need to do the on-demand query for the data scientists so once the data translation to uh automatically update the data broker so the algorithm plugin and they want to have some direct upside to the data cell so uh whether it's supposed to add a new uh parameter selecting type because they are demand that means the algorithms likely don't need to exactly uh the internal data broker in the Auto server inside but just to translate the completioner to the direct query to the data cell but this Russian uh complexity about how to do the night in between the uh data programming and data structure and the the raw data collected from the the sub distance so this is still open"
  },
  {
    "startTime": "00:26:02",
    "text": "cutting we want to reset some feedback from some other members may have some uh their own requirements on the real department for how to handle this yes all right thank you so any comments from the people in the queue or in the room you can go from uh so the next steps uh for also oingm uh would be that uh authors will make decisions about question one to question three uh that we discussed about as soon as possible and we'll submit a new new version of the NM document uh you can call so I think like okay so uh and also uh we will continue to collect feedbacks uh for questions four to question six uh and also we will test uh the Yang model in real implementation so to give you like mallow Stones uh the first one is that we will reach agreements on question one to question six and we'll completely revise the document before next iitf meeting and the second one is that we want to push also or a m Yang model uh deployment in the current deployment of Alto that we have in Opel also GitHub uh page and before March 23. thank you uh Martin Duke Google uh can you go back to slide five or question five pardon me so um why would you not just use the existing altar protocol design like why not do what are the"
  },
  {
    "startTime": "00:28:01",
    "text": "drawbacks using design option one oh so Jensen can you go on like to answer your description uh are you online actually we don't have any uh documents uh specify how to handle the um you're fading out there well I mean so like logically if you have an auto server and you want to get the configuration of that Alpha server you ought to be able to use Alto and it has the advantage of not having like more extensions um like I I don't see why you would need an extension to do that necessarily but um like I would without looking details like architecturally that would be way way cleaner than like doing a whole nother design in my opinion thanks okay so uh yeah yeah I think that's I I think the comments made by marketing is very very good uh the only uh small case which may be the question to Jensen because you guys uncut you guys did the hacker sound uh just like a few days ago and it was multi-domain so therefore if you do multi uh domain discover using Auto I think you are missing the egress point which may I may not be interesting to the client would that really be an example where you might be one way is like marketing side which is just extend the auto product a lot itself a little bit which is very clean by itself or maybe you're really invaded some other cases maybe there's it's easier uh for auto servers to reach agreement because they are essentially Enterprise uh essentially to Enterprise agreement and then a consumer to Enterprise and even for that case maybe the issue can be"
  },
  {
    "startTime": "00:30:00",
    "text": "solved by some kind of authentication or authorization hmm uh so I think recharge Richard brought up a good point uh dangerous point is uh the point that we have reached on uh the when we were implementing the uh code base for the hackathon uh so that's that's the point that clients might not be interested to find out about so uh but Martin's Point also makes sense to me because uh if we we should uh we should consider some extensions in also itself that enables uh the transfers of this kind of information uh but also recharge haven't had another point that I have not answer to your answer for that yet uh that might be like some sort of communications that between Enterprises make sense uh between some sort of uh specific uh authentication or handshake or something like that and client does not have access to that level of information so I think that's what would be or the main difference between these two uh interfaces but if we if we realize that we can handle that we can handle this concern uh without adding another level of complexity to the protocol we definitely will go with design option one with some extensions well I'm sorry I'm you know I'm starting to fully process this slide so this whole discussion is this like relevant only if I like there's also and it's currently do the currently adopted documents in Alto allow us to do the multi-domain use case okay so this doesn't this doesn't assume that these other documents um go anywhere I'm sorry Danny these two multi-domain dot drafts okay yeah yeah all right well I mean so so if we support the multi-domain use"
  },
  {
    "startTime": "00:32:01",
    "text": "case today then there must be some sort of service Discovery mechanism right across domains so like presumably that would solve the problem okay thanks any other comments about questions six specifically because one of the most complex complex question that we are seeking answer to search yeah so these are this one no the previous one uh so this uh this question is one of the major concerns of doubters so I'm bringing that that around on their behalf so so I'm sorry like I I I was reading the slide and you maybe you said it but like what is the actual question on this slide so Jason can you clarify that yeah we want to uh say some uh experiment about how to handle the uh the the connection between the algorithm uh plugin uh so which is generally the also information and the data circulation uh so far have two approaches why is that the auto server can build the internal data broker to sell the network information from the uh the data collected from the data file and the auto the algorithm plugin will use the information stored in the internal data broker to compute the information results and another approach is that the the"
  },
  {
    "startTime": "00:34:00",
    "text": "auto plugin comes directly curated the data service and not to use any data broker so that's the two approach you can can happen uh in different cases but in the same system actually it's hard to find the current approach to Define what should be the model to handle this yeah Richard so my overall reaction would be this looks like a very complex issue right there are so many different data sources are you really sure you want to attack this issue uh or maybe for to really make a progress this one can be next round because that's also an option so so that they can mention that it's not in the school about this argument but in the real Department that that is yeah for example you're really talking about quite Advanced uh data sources and just like a few days ago maybe three or four days ago and Marty and I we were talking to qingok and who is architect of esnet we were asking diploma how to deploy an auto actually his suggestion will be can I just send you a file every few minutes and then you just read it from a file and format we can agree on then you lock you load into your own server would that be simple so there are a lot of different data sources do you really want to visit my question is you mentioned uh servers I think uh for the hackathon you really have all kinds of issues I think also for the uh 113 hacksaw and I think we're using G2 Mini net that's a different format and now you talk about all different so it's quite large so that's my main concern so I think refrigerator's comments is like quite uh relevant here sorry but for 20 seconds"
  },
  {
    "startTime": "00:36:01",
    "text": "uh so we can decide to delegate uh discussing this question for further Improvement after IDF like 115 and uh consent uh focus on like addressing question one two five before uh tackling this problem so that might be a question but I don't know if you have realized uh Jensen's comments or not I think he thinks that in deployments it would be relevant yeah Martin Duke again um like this this data source thing um I mean we don't Define any of the data source apis right okay yeah and like I don't know this idea of data Brokers and I mean Alto is supposed to be a data source like a server itself right and there's just this proprietary thing where you're just Gathering stuff from around the network and like proposing like a broker that is collecting the data then Distributing it to Alto it's like that's the that's the alto server so you're like inventing a new Alto to speed Alto which just to zoom out and again I'm not you know a practitioner that seems like very I think you're creating abstraction to make this problem practical tractable that is not um does not sound very um realistic I guess and like maybe there may be interesting work in like defining like apis for data collection but um you would have to get a lot of devices to subscribe to that and I don't that seems like a big scope increase that we shouldn't get into thanks foreign yeah I I fully agree with someone here I think I think that uh going through the uh southbound interfaces is something that's I mean Alto is about exposing data not about collecting data so what"
  },
  {
    "startTime": "00:38:02",
    "text": "do you how do you collect data I mean it's quite important for the implementation and making decisions on the implementation on the design for sure but making it part of Standards probably will be a little bit over standardizing and this is something that's give me the you know so if you don't have any more questions I can wrap up the comments that were very useful interesting comments made by Diego and Martin I also Richard uh so I think Jensen answer to this question for you is that uh Martin and Martin Diego said that in terms of his standardization it's out of the scope of Auto as data aggregation protocol uh but in terms of implementation we can decide later so all in all after Richard Martin and Diego's comments I think like we should focus on question one to question five for this standardization and Tackle question six only in the implementation afterward thank you everybody for listening I think like we are reaching uh the end of time for this presentation so if you have any more comments we would be happy to have you in the queue for the last minute and also we will appreciate discussions going on the working group mailing list so please attend the mailing base and please write your comments for us in the mailing list is that possible thank you okay thank you Martin thank you Madi and thank you Jason actually we can keep on discussion question on the list and properties some of the questions yes thank you next is about the auto new transport richer okay so I'm going to go over the output transport next slide please okay so here is outline about things"
  },
  {
    "startTime": "00:40:01",
    "text": "which I want to cover and first one is I really want to show some connectivities what we are doing and so therefore people get a sense about where the modifications come from and where it should come from and then for people who are new we do have a bunch of new people who are who are not familiar with transport protocol so I'm going to give a very high level very quick like 12-3 minutes overview about what's going on about new transport because that's imported on your protocol and I'll highlight a little bit like like a meter changes from last ietf and then to the current version and then I want to spend all the majority of the time in real time to really talk about discussions and very many issues to to be decided to really focus on engineering side to really make all the decisions and so on next slide please so first a bunch of all this happened and slightly initially it's a little bit slow and and now we're we're moving quite like uh active or not hopefully we'll really try to maintain our momentum and so on so initially the document was adopted as a working group document on June 22nd and then we we did a bunch of reviews thank you so much for a lot of reviewers and Luis Sabine and Jordy and a lot of reviewers and from all the group so give a lot of reviews and we finalize our submit a new version on July 10th ultralight events elabores basically between uh right before the uh deadline and now the major issue as you'll see shortly which that's why I want to give you a little pointer would be there are some very excellent accent uh HTTP expert reviews so they are from Martin Thompson and they're from uh Spencer and also from Martin Nottingham they're very nice reviews and if you're interested in reading some of some of the discussions or reviews and here are the links and there are also some ongoing discussions slightly because hackathon delay a little bit and now we're resuming hopefully we can have all the discussions involved so next slide please okay so the religious review a little bit what we're doing in terms of all the requirements so therefore we can all refresh our memory because we are we're not designing a new transport protocol or new other protocol really but not possible it's a design is let's really"
  },
  {
    "startTime": "00:42:00",
    "text": "make sure that's impossible follow all existing designs and by now using essentially a new transform mechanism HTTP 203 so therefore here is bunch of requirements with Central that's a constraining our design space and we're not supposed to really inventing any any new things whenever possible so basically number one is like really follow the base protocol possible so therefore r0 is request all of the resources possible I can see that that wouldn't have some kind of fundamental constraint on the way with designers in your neurotransport or Auto product code and then I call the media base obvious one is auto SSE which is somehow old technology and Service Center event which we borrowed initially started from Windy room which is a wonderful designer and then with Central there's SSC protocol therefore for uh required inherited from over there because we're going to replace SSE because quite a few people Mission assets is very important so therefore this protocol is certainly trying to replace the functions of SSE so therefore you must be able to request an increment updates you must be able to stop income updates and you must really the server can tell the client okay I'm starting or I'm stopping so if I keep the signaling and then the server can all have all kind of Freedom really choosing uh the content type which you can say later or the major implication and also why I will read the design we're not going to revisit this point and they're already determined in the early design with obviously 88.95 and then we want essentially record as a major decision and people can discuss after that would be I want to refresh memory a little bit for people and the decision is we're still following the HTTP request for API actually that's a somehow this requirement actually really bites why because you can really use HTTP 2 2 to do a lot of things but if you really want to follow the rest for API philosophy and activities will come in really bites and you know says that with the concerned the way we design things I want a little bit with these costs that of course allow flexibility of deployment next slide please to refresh the memory a little bit so here is the new design in the protocol and you have not read the document it is becoming a little bit longer now so let me just summarize very quickly and structure and then we can go through the discussions and so on so the basic design is very simple you have Auto"
  },
  {
    "startTime": "00:44:00",
    "text": "server over there and you have all the auto information resources quite a lot to know and without like all kind of information resources cost map Network map and endpoint properties and pass factors how start will be used at one way another way I know what we do is we introduce a concept called a transport Cube you can see over there and the transporter queue is Central to have two components and one is called increment rblq and the one called receiver set RS and Q uq and then essentially user will be connected to the update queue and also if you want to receive update you become part of receiver set and for single user for example over here is column 2 and you use a single HTTP 2 of 3 Connection and to really get updates from multiple update queues so therefore that's really the overall design architecture borrowed a lot from early design so for that's the basic structure and the design is Clan can pull items from rbiet queue and also the server can push into it at least in terms of latency or equivalent opportunity you can see there's some like things one finalized next slide please so here is a set of all the major changes I'm not going to bore you with all the details probably they don't make much sense at all and I need a lot of things but overall you can see that there are a lot of changes and basically left hand side is early before the ietf 113 right about 13 and here's 100 changes so therefore really separate into different sections and make everything as concrete as detailed as possible so a lot of very detailed updates and so on so so those are a lot of suspect details just basically that's a major progress especially all the details according to the discussion of itf13 and so on next slide please so now that's really the design issues which one engage because that's the purpose of face-to-face meeting and that's really make all the media decisions so the decision isn't triggered by very excellent comments and discussions from actuality Experts of course because a working group of reviews already also addressed and then we got the three excellent reviews sort of one front address there are issues and discussion and so on so the main"
  },
  {
    "startTime": "00:46:00",
    "text": "point I want to get people to talk about is the phone and if you worry about oh all your discussion would involve a major uh restructure of the whole document oh no actually we're not the main thing actually is the main women issues from Jesus Culture which is excellent essentially two issues one is concurrency control unwind semantics of the transport the good thing actually the good news is they may represent generic concept for HTTP 3D design actually which suddenly realize if for people who follow the email it's not likely Auto specific somehow it really represents some kind of genetic concept but we want to really get engineering done as fast as possible and like I mentioned is ripping issues does not look like really about meter changes and mostly actually very minor changes but very important so therefore we want the working group to have very careful decision and discussion and then we can finalize a lot of things and then we can make a very good progress next slide please so now let's really talk about the first thing we want a working group to make a decision and to really present the issues clearly that's a very quickly reveal a basic concept so therefore very quickly let's review it then we can really discuss so what are the basic issues here remember the main thing about Neutron to our protocol our main thing about actually using interview 203 or SSE is to do very low latency and very low overhead push of Information Network information to the client like current design in the current document essentially has two mechanisms so let me review very quickly so look what we can discuss one is client pool I know one is a server push the clan pool actor model is a very simple card mechanism so basically the client just sent a request for example and if you look at your right hand side and that's essentially the transport q r q standards and for you to update you give a second number and with the media type and will also give you a tag about what information really is another clan and you use the same HTTP 2 or 3 Connection can issue a get request for example see get and specify the the secret number and then we'll get the content very simple one so that's a decline pool next slide please just refresh your memory and then here is the ability of server"
  },
  {
    "startTime": "00:48:00",
    "text": "push which is also well designed and so let's say what it really is and then what it will encounter so here is approach is very simple for people who are familiar with gdp2 it's using server approach promise so basically for example if I'm a server and I want to put a new content for example I'll send a push promise uh stream for example a prime stream number four you can see on your right hand side and I pretended because the semantics hdv2 really is that's why we want to follow is you send again request and pretend you send a virtual uh request you want to get the client and supposed to want to do it get and then for the second number or 101 and a silver direct list and the content from a server to the client so that's a server portion instead of conceptual agent like representing a potentially uh Clan pool so those are the basic concepts we're doing next slides please now that's the interesting part so now it turns out after the very very increasing discussion in the discussion from Market Nottingham and is from review is the question is if that's what you really want in terms of Clan pool and given that for hb2 for example the load the the client overhead may not be as a big why don't you introduce Clan long pool as a way to solve the issue that's a very interesting discussion and very quickly in the comments so therefore basically here is one proposal and what exactly how to get to work of course the email discussion did not go to technical details and here's the engineer let's see how it really works so the discussion point is very simple uh on your on your right hand side essentially it's transported q and student number 10112103 but what if you want to get a long pole use HTTP 2 and how to really get do that is very simple is the client can issue a gather request from the client to the server and what one request essentially the next secret number which we're building already so therefore you say hey I'm going to get 104. basically you always have a hanging or essential outstanding request for next one so therefore this can be sent without all the TCP handshake and overhead understand using the single connection itself then you implement the whole uh Clan pool so therefore that's one"
  },
  {
    "startTime": "00:50:01",
    "text": "feature which we're discussing and we liked it a lot during our internal weekly meetings basically the only change is very small we probably add a paragraph say okay and for clan pull and use a card use for the current Clan per model and that's really allowed currently you only can request which is a single number already in the transport queue and now we should allow you can allow the current one with second number plus one then that becomes essentially they they allow on tool so that's the design Decision One any support should I stop here to discuss or actually just mobile inside back so that's the one proposal we want to adopt it but we want to get feedback from working group very simple technology change very elegant but let's say if we were missing and something or somewhere next slide please next one which is also very interesting and also came out essentially from HTTP review which we really liked and but this one is slightly more conceptual and actually the change is very interesting but actually we need a really working group and also all our expert to discuss so here is the basic proposal about how to do it so the proposal is very simple and very elegant and English follows it for example remember early part we talked about the club The Promise approach promise approach of using a server push one very simple way is reverse the thinking the process for example the client around the push for example 101 and the client right now the current model is This Server will send a project promise approach stream 4 and and using the get method and for second number of 101 101 on the right hand side one possibility is sweetly conceptual model said okay I'm not really server pretending unless you send me a request why don't I just really put a content to you so therefore you get rid of the promise and essentially you make a frame into a put frame and put a method you turn the method into put and now you give a second number you just write into it so therefore that's one way of because"
  },
  {
    "startTime": "00:52:01",
    "text": "why I think there's some like basically there are some discussions at least from the HTTP review is there's some pushbacks to think about like a server push which actually interestingly Implement themselves in HTTP 203 and as approach Prime is but somehow considered as like anti-patent and so therefore there's some pushback about the like push but this one with more standard there's no push promise everything just become a standard HTTP methods verbs and put and so therefore it's very nice and what additional benefit is it with this one and actually can get rid of one awkward which we have in the current for example if people read the document very carefully we have one place specific value and for the current implementation design and the server the client must not cancel the promise because why if you push a promise and then because all the dependencies there's all the dependencies if we cancel it's very hard to really synchronize the state but if we allow the server to put you look the the clan cannot really like a cancel put sorry for what about about awkwardness of course semantics now really is suddenly the concept becomes somehow used to be like a server where the lotto server would have all the network State and essentially like pushing the information into the clan as a cache but now if you do put conceptually it's now client conceptual becomes essentially a stateful machine I mean in other states so for people who are like a purely you know stateful design and HTTP may be resentful so far we like this one but we won't have a lot of discussion on this one so that's the second issue next slide excuse so opportunity we're just finish all issues next one which also actually came out from review and from all three reviewers and Mark and Martin Thompson and Spencer talking so basically that's the third issue basically is day one is discussion is can you environment what are we interpreted is can you just make a late GP to spec as little as possible idea will be specified nothing but here is a concept issue which we encounter and that's actually also a genetic issue let me clarify the issue very clearly and we want to see which one so we'll give three proposals and we'll see which one are the working group likes so we can make a decision so what exactly the issue oh why even"
  },
  {
    "startTime": "00:54:00",
    "text": "generic issue or a specific issue here is look at the auto on on your right hand side upper right corner and R1 is a network map you send an abstraction of network and then you give your equipment the push update for example Network map one you send a patch one sort of for a darker patch a Json pad for example change the map a little bit and then you have a customer one which is a user Network map one as reference because as we designed the topology and the customer defining our cars and essentially depends on R1 and then you have R4 and which is a essentially is a new custom map and which is based on a new updated Network map you might move one IP address from location one location two and now you're also therefore change the average you change also the the the cards for example in the custom map one so therefore become such a dependent graph so overall accurate is a DAC what do we call Direct e600 graph of dependency of all the resources or pushing or sending from from the server to the cloud you know pushing or supposedly so you know most ideal case and if the requirement is hey if you want this Auto you guys I should specify nothing so therefore you just just send all the informations ask a server to send from from a server to the client that's easy to specify nothing approach engineer approach so conceptually to send all of our resources and put it into HTTP 2 servers uh cache or using socket API or whatever and then they just send all of so that's design number one basically Auto specifies nothing and you map each RI into independent stream and HTTP just out of scheduling the main issue is we might potentially lose a little substantial performance gain or using hp2 why we gave all of our resources to the HTTP layer as the server and because the server doesn't understand about anything about application semantics so for the server Management schedule let me send rfo first because they're all in the buffers in your own like objects and let me send our phone first then R3 R2 R1 then essentially the application cannot process anything in the buffer all R4 R2 R3 R1 onto everything you received and then process so therefore you lose"
  },
  {
    "startTime": "00:56:00",
    "text": "essential to gain of this essentially a dependency so that's the issue number one we did not like that one early design therefore we went down to design two but of course the issue is we're not specifying nothing we might introduce a maybe over specification and so on so let's discuss a little bit in current design 2 is a form it also has an issue it's not perfect but we are talking about engineer we're not trying to get everything perfect we want to get a working version so in design two is the current drops specify that server submissive HP is transport or the server in a dag order so for example if you're the server and auto server you're sending the information ask HTTP 2 to transport for you and you first really should submit anyone which has no dependency R1 for example you just specify send to it is finished so now on the one without dependencies R2 and A3 R3 you can send R2 and R3 and then you wait until the analyst said okay it's transported and now you send R4 so therefore essentially you would really be allowed somehow they're transport in the given order of course if by the way we mentioned this one even in this one even now you send in a given order or actually receiver's item I might also have a semantics maybe the HTTP client uh buffer size that might still buffer R1 R2 R3 and not delivering Apple layer you know right away they might be still actually delay but we think this is slightly better of course the issue about this one is also potential issue remember this long-running connections and the TCP window size that might be big I have a sliding window of transform might be large enough to understand R1 R2 R3 R4 in a single shot because they're so big you sound like a big buffer but now we're sending essential we introduce round trip delay there's no perfect solution okay these are R3 design three is I could indicate dependencies oh those resources are really dependent but that one probably involves modification of HTTP 3 semantics or two cement sort of or not targeting this one but we want to work and make decision one or two we recommended two but we'll see what the recommendation really is next slide excuse maybe how how am I doing timing am I too slow or you know you have the timer oh oh good great yeah I do have time great wonderful wonderful"
  },
  {
    "startTime": "00:58:02",
    "text": "so three and is how to well to specify the settings that's also an issue which we encountered and then a wonderful the Ponder by uh by Samantha which is very good uh Point as well so that's the issue we encounter so let's see if there's any suggestion or feedback from working group essentially so we want to control a little bit of crack essentially the specifications for example right now in a current draft we specify that the the client Mass being about the server to say hey the server Porsche is Singapore so reported to be self-consistent we also want to allow This Server and client really like a limited concurrencies because therefore you're not you're not going to overwhelm a very slow Auto client but unfortunately we realize and also a very nicely nicely upon out by Spencer and is that actually this specification scheme is changed in http 3. so basically what happens is a second year of approach now essentially it's kind of now is removed if you specify actually it's an even error so therefore you really should use like a Mac Max push ID frame with complete information and maximum currency and also change and so therefore there's essentially two and three are found on two design so how to handle this issue why yes which is remodeling we don't even specify anymore we just say okay let's operational and you guys should handle the when you when you configure your own servers and make sure you compute them all properly so therefore outstanding the right away store for independent of uh gp2 or GB3 the second one which is best about requirement UMass the center of sending about push and you must sample for example control this one but how to really do it will become generic and then essentially they deploy that's why relative with OEM when you're going and really send those information relevant let me uh you know in the crack away sort of foreign working group so that's the next one next slide please so last one and next one I can might be tricky or maybe hard or maybe easy so here is what the question really is so initially we use the other examples were written in ATP 1.1 format very"
  },
  {
    "startTime": "01:00:02",
    "text": "standard ever so familiar with it then we got the feedback that okay actually I really do e32 can you guys now in random format in hpv2 for example that's the right hand side format in the middle I think for some versions actually we have both 1.1 1.2 then every example would have two formats to become very messy eventually will end up with a two basically we wrote all of them with two sort of four we give some kind of comment said okay send this stream using prime stream number four and for example with your ready settings examples and also like some like pseudo instructions to really see how the information should be set as example but it's a wonderful sky guide from Mark is actually recommended written using 1.1 so therefore should we just roll back the all examples using 1.1 but adding some kind of pseudo like annotation to indicate what kind of information or not so therefore we really need some kind of guidance and therefore we don't want to go back and forth we just won't finalize next slice peace so the last one is the media type and we really need finalize the media type I think so at this point it's possible this also will point out by by Spencer so therefore we can finalize this uh media type which actually we have an internal version already but we want to wait a little bit until everything is final our email attempt is format input which should be relatively quick and but if people have any comments and we're more than happy to really go back or otherwise we're going to use traditional RFC at 7 to 85 format last slice please next slide okay okay so here is a list of all the questions and now our listening to all the comments and all the feedback from all accounts hopefully we put all there and we won't get people to tell us what you feel strongly to go ahead okay okay uh Martin Duke Google um so one minor thing can you go to discuss three please sorry must be three so like I'm in favor of you know saying what you mean in documents and not yeah so I don't know how long it takes you to find a slide but whether like to say something I say yes say something don't"
  },
  {
    "startTime": "01:02:01",
    "text": "just like ignore it assume people do the right thing discuss three get over shot right next one right uh no no okay anyway forget it so write something down like you could just write for hp2 and hp3 or you could have a generic requirement I would have a requirement that you know I would not just say configure your thing properly because that doesn't mean anything to implementers so it is an option too essentially yes okay and but without go to details of HTTP 2 do this way through to another which is a asset requirement yeah I mean I would just say like make sure you can send enough pushes and make sure you can send push assuming you're using push and and uh you know make sure you have um enough streams okay whatever the requirement is okay sounds good so like to zoom out well okay actually there's one clarifying question so are you now considering not using push at all uh that's not a discussion so can you go to discussion maybe go to yeah there was a bunch okay so they're in very so so there were like five they were like four design Ops four designers for how to do SOC yeah okay and one of them is push and none of them are sorry one second just one second okay make it easy uh oh next slide okay so basically it is Clan pool already who can support it right and silver push we can replace with sober pot okay I'll keep both of course that's a problem these two are mutually so you can say if you don't keep this one uh move so okay it has mine and uh so basically if we change into server put and get rid of so push completely okay so server put exists in one one right server put already existing in one point okay all right essentially get rid of uh push promise right okay so this is this is interesting um you got you got the best possible reviewers from the HTTP group so that was exciting to me exactly exactly um"
  },
  {
    "startTime": "01:04:00",
    "text": "so um like I want to zoom out on this draft like um so first of all okay so number one um the naive way I think as Martin Thompson put in his review the naive way to do Alto or HTTP 2 is just take the requests sure and put them in streams like that all the like 7285 also put them in streams and you're done right including SSC all that there's nothing there's nothing wrong with that correct so that's related three right basically oh no two I think some kind of like a uh yeah to basic ordering construct right so about these type things so I mean I don't want like we have a deliverable I don't want to like get Tunnel Vision on deliverable if the answer is that just like not having an HTTP 2 document is the right answer because you you just you just take like any almost any of many other HP applications you just take one one you rip it out you put it in two and it works and it works better because it work you might because performance in some cases yes you're right um and I I think I think it's always important to Benchmark whatever we're doing against doing that sure what I am and this this is a terrible thing to say because it's potentially like really changing Liverpool but what I feel like happened uh if I'm understanding correctly is the HTTP experts essentially redesigned SSC for us yes um in a in a version agnostic way that maybe was better um okay and foreign if that is the case um I I like I you know I've been thinking about this for 10 minutes so this is this is maybe a crazy idea but it's like the right answer to do 88.95 this and not have an H2 and 3 document um"
  },
  {
    "startTime": "01:06:04",
    "text": "because it sounds to me like if we just do the well I don't know I mean I don't know if you've implemented anything or you're still like struggling with the design here we we current implement it I think I mentioned a little bit actually it was on a server approach because as it was the key feature of a push and now of course we got a footage back which is very soon very only a few days ago yeah well not approach basically suggestion which is a wonderful suggestion we never thought that was possibility to reverse it of course there's conceptual issues yes some people you know always they can get like a philosophy code no that's not the right philosophy even though syntax is simple it's equivalent about philosophy is different so therefore uh well but where do engineering as long as we and like and you know if if any of the suggestions I have turn out to make sense like I'm happy to push back the Milestone deadline sure um but uh I mean like caramels don't actually still approach it's easier because that's already awesome switch to like a silver Puck because that's philosophically different concepts so I guess what I'm saying is like some data would be useful here I mean I I think we have like you could take vanilla 7285 plus SSE and just put it in hp2 implementation with no like special anything sure and like you're gonna get some performance yeah less serialization basically performance will be a horrible potentially for example you can see that well the most streams you have and I can control cases that make it look really bad okay serialize okay fair enough all right um like conversely you could do push which I guess you have code for and see that there's an improvement versus just just using HTTP 2 by itself right sure yeah um Clan pool only right um because basically essentially we have model is Clan pool only so the push only and uh long po definitely long Implement I think that's a very very elegant very"
  },
  {
    "startTime": "01:08:01",
    "text": "minor change the major concept uh debate is do we really switch the model from the server pushing and the essential virtually putting uh for the clan or so just putting the content into the client would you would you consider 88.95 to be client pull is that inaccurate 835 and then I'm sorry 88.95 the SSC dot is that client poll it's super push it's server but using sscu which is a method of all kinds of Transport because that's the only mechanism available so actually conceptual it is super push not a client not it's it's a silver push not a server put okay so I mean this I whoever's the note taker is you're gonna kill me so I'm gonna I'm gonna like think about stop diving into this but I would like you to think about um I would like to Free Yourself of what you're to do for a minute sure think about like what what are we trying to solve like is it is it best positioned in terms of HTTP versions or a new mode that like replaces 88.95 or supplements 88.95 um and and like so that's like through some thinking and two like given that you have some code and I know there's not infinite um software resources but but certainly like some experimentation yeah that's possible we do have several push yeah and but sort of put it conceptually but the good thing if it doesn't stand there to client software like a library it'll be slightly harder because typically clients are not really ready to to be written into a typically read the cache they're not like a writable cache mostly just write it only once but now put some conceptually it's more like a more like a data store so okay so so I like that's my advice um to do those two things um and uh like I'm my thoughts are fragmented so I'm not going to continue to shade up here but if you'd like to"
  },
  {
    "startTime": "01:10:00",
    "text": "huddle offline uh right after this maybe we can yeah we should talk about talk through a little bit more okay thank you and of course also discussion too which is no discussion sorry uh I'm sorry yeah 1.2 here too yeah it's also relevant about how much to specify if you look at all the discussions or discussion about don't stress anything or maybe there's you can say the case because generally were solving a case which actually generic HTTP 203 case which is how to handle multiple dependency and how to give instructions from the to the transport leader [Music] if we have any suggestions even to that piece of work because he can see that essentially there's a common common like abstract behind it yeah yeah so I mean I think you 've really hit the jackpot with who you're talking to about this yeah yeah and I I would never dream of second guessing Mark Nottingham about HTTP or Martin Thompson sure yeah but um yeah let's let's talk after and see what the right thing to do with this is uh like I said if we need to change the charter we could change a charter sure um because I think we've got a lot of great Insight we didn't have when we charted at this yeah well thank you and thanks for working quickly on this thank you so I'll just uh thank you Richard please go to discussion let's move to the next topic Jody okay okay take the floor so hi I'm Jordy Rogers welcome and I'm going to be talking about auto code bases and deployment uh this is actually a presentation actually several of us that we're going to be talking about this um so I'm going to be calling out for more people I guess to join me um next yeah"
  },
  {
    "startTime": "01:12:00",
    "text": "yeah I'm gonna just uh at a very high level just recap on the on the code base architecture uh just very fast on project management and approach when and then jump into deployments um and then probably we're probably going to skip the hackathon because that was presented actually Sunday uh so you have the the YouTube video if you want to look at that but yeah going next yeah so next yeah so uh yeah this is uh summary of the charter you all know about it the history of Alto starting from peer-to-peer then cdns and recently and sort of uh going into this new uh applications uh a lot of discussions is this is not in real in the charter but there are a lot of discussions about you know uh using Alto right Computing 5G uh seller and others uh and um you know participation from multiple vendors and and so on so next yeah so this is 70 7285 the traditional architecture and that you actually want to go next here next next couple more so yeah that's how we map it basically uh so there's a note one API Southern API the standard focuses uh on the Northbound API primarily there was just a discussion about the software API and not over standardized in that part um but yeah that's how we use Envision um the deployment of the code base uh on the Northbound you have applications across the board um from traditional cdns but also science traffic moving global data sets large-scale data sets globally with the science networks and and then the edge Cloud applications I mean the reality in iot The Meta versus one and then the southbound again uh the um across the board you know going from data centers so all the way to the edge as well and"
  },
  {
    "startTime": "01:14:00",
    "text": "the back hall um so moving on next hmm yeah just next uh you know this is uh pretty much what we discussed in the last ATF so I'm going to just uh cruise through these I guess very fast but we have um an approach whereby we are leveraging the hackathons as checkpoints and Muslims to progress so uh you saw that over the weekend um uh the team delivered a demo of um integration of Alto with um uh science networks uh FPS Russian um and also uh multipath quick and and ptcp uh by Z Yang as well um yeah so moving on next if you're interested uh we you know we use um scrum to manage the project and uh you know we have the dashboards available everything is under GitHub uh it's openly available so anyone can check anytime so there's a dashboard for the hackathon 114th and in general dashboard for the overall progress progress of um open Alton moving on next yeah that's just the dashboard next and just uh jumping into the topic of this conversation as well so the auto deployments uh if you want to go next yeah the the first part is uh what was uh this uh what's been discussed in the past the current implementations there's a Wiki available uh there's the Comcast bannocks and telefonica previous deployments um and then we have a bunch of new deployments uh work in progress that we're going to be discussing right now I guess in this conversation and and ongoing um so the Pacific Pacific research platform um in in California uh then CERN in Europe are really a global network uh UCSD the 5G deployment and the quick mptcp and then the edge cloud and science networks in general so moving on"
  },
  {
    "startTime": "01:16:02",
    "text": "to next um can you go back what's what do you mean there's an MP quick mptcp deployment well I'm gonna have ziang discuss that again okay yeah all right yes um now it's a good question some of these uh yeah that yeah let's answer the question some of these are just the work in progress they may not actually be deployments it was um so that it might be abusing a little bit the term terminology but yeah yeah so um yeah next one so um so Richard actually you want to take this one I think there's yeah double switch okay yeah so this is a basic basically a deployment or essential implementation that we're working with the uh quite a lot of people I think some people saw okay yeah so for people who uh follow Auto mini list and so this is really is a collaboration between this Auto working group and also a central discern team a certain team includes uh several two teams actually is quite a lot of him it's rather complex so one team CERN is uh a certain team is a high I think probably you guys saw the email Auto billion list has a project lead of the FPS project which is essentially all the data in certainly submitted to API system FPS will do all the scheduling and also see Murray also part of system improv stock his email as well and this case the operating manager so therefore that's one part of so the question and of course the other part I think involving in terms of people would be the rules is on top of FTS so"
  },
  {
    "startTime": "01:18:01",
    "text": "basically will select which sources to really transmit and FTS will collect all the transmission I requests and then try to schedule an email right away so for this one in particular uh basically is the main feature is a major missing part about FTS of all Lucerne is you cannot really control the the bandwidth usage on every single link so therefore the main main new use case of Auto here your typical Auto will really consider with like a source selection or peer selection and so on actually here for this particular use case which they found to be very exciting uh for the CERN is you basically insert the data transfer as you have Source you have destination and you send it you send the data so here is we use Auto really map The Source destination basically to for example dtn's data transfer node I'm mapping into the freezer codings using Auto using its own cost map and pass Vector for mapping in the physical links you use then application in the stock we are running app layer you can really click on usage all the transfers of all like upper layer links and then you compute a total user every protocol they do the app the optimization control of every 30 seconds or one minute then Auto will tell you how much you're using on every single physical link and then essentially you can really convert into uh for example you say hey I want to make sure I'm not using this link and model for example 10 gig or for example the two links or for this organization for these two experiments CMS or for example whatever experiment and resource should be one over two sort of for basically that's FTS a specified resource control go and then we implemented this or the algorithm essentially using Auto information is mapping as a as a constraint and then we Implement four zero other gradient algorithm which is actually quite exciting and I think we did a demo over there then also a composition framework to go from now not only is there other but also first order and the first order actually is the uh is is uh George's work or bottleneck of course right now it's a moment and the opponent structure is now in in the scope of Charter so we're most we're focusing on first is really getting the information control which is quite a new interesting case we're hoping to you"
  },
  {
    "startTime": "01:20:01",
    "text": "guys probably saw the email on auto meaning list so the goal is really get the production and I think meeting is from from both me high and also from Mario so it's really getting the the production data and and see how far we can push so um is this a is this informing a network management tool that's in repositioning the network based on this data or is this a client oriented uh service so they uh I don't know what means a clan also basically the workflow is falling uh ft has to actually centralize control logical centralized of course uh if you want to read a separate you might be about separately so basically there's a synchronized controller running a holster basically you might be a multiple and each one actually would have huge database to get all the transfer requests from across all the data okay and this guy would essentially become Auto Clan to really get the data from yes net from all the networks to really map from for example I'm sending data from MIT to contact I'm sending data from a Stanford to Sir sort of for your map into the physical links and then this query by a query of a client and then this is server Central dialogical server we'll do the optimization and do the constraint itself so I don't know if that's it probably that's problem that's a silver based approach a lot of color centralized of course they're all kind of make a scalables separate into different like partitions and so on but overall this is like a logical as server control but only using Auto client okay so the the network management the optimizer is acting as an auto client to extract the information okay and optimize every 30 seconds or one minute that's a production code okay all right so it so so the the user of Alto is like the network manager itself it is not the it is not like some person trying to download data uh for initially"
  },
  {
    "startTime": "01:22:00",
    "text": "right now we're really using some like a data and uh we had a discussion with Qing and I think we're also going to have a very quick meeting with India manga who is the director of the esnet which is the US part of this infrastructure and initially that's why I asked a question that initial the actor teen suggestion from last week is can I just give you a file and then that's your data source you just load the auto server and then send to it yeah okay thanks okay uh thanks Richard uh moving on to next one yeah we can actually move on to the next one so um and yeah we're gonna move to the next one so there's a a paper that's uh going to be published at sitcom Knight on on this deployment as well um and uh we'll put another demo in the next hackathon 114 that will continue to progress in that deployment um yeah the next one is actually now the California deployment service hello this is another Circle what will be presented on Friday in the media operations working group so it's the the integration of the uh Alto in the telephonica network in order to expose the capabilities to the telephonic acid again so it would be the client of the information that will be provided by by the auto server in essentially collecting the information from the telephonica network so what we you can see here a very basic example this was some some tests in the lab so we are now in the in the process of uh moving this into the production Network I will show later so essentially here what we identify is we are assigned pids for the streamer the cdns streamers and also we have pids for um identity final connecting let's say the preferences of the customers of telephonica networks in the different Central offices in the different pops right so the request routing logic of the telephonica CDN takes into account a number of of inputs you know the streamer State Tools the load level and so always from the perspective of the"
  },
  {
    "startTime": "01:24:00",
    "text": "CDN so this is the idea is to complement this with the perspective of the network the where the the customers are in principle so in such a way that we can determine what would be the number of hops right now with the capabilities of telephonic of Alto that we are playing with right now simply the number of hops from the streamers the idea would be to enrich that information with performance metrics and all the capabilities that are being developed in Alto in general right so essentially the point is with this information the telephonic acidien will consume the the topological information identifying where what are the practices of the customer and then taking decisions not only based on the uh servers of the CDN stream and information but also on the network information itself for taking the best decision at the time of delivering the content next please so this is the process that we are following we have started with uh some uh I mean really playing with Alto in the in the technology lab so essentially very basic setups I will detail later on as well so very simplistic Network just for understanding the capabilities and the feasibility and viability of this approach then we move to the pre-production lab facing a real configuration of the network and the complexities that I will detail and the point where we are now is just previously to introducing into the production Network so we are fighting with all the rules about security hardening the server and so on so far so the idea or the expectation that we have is to during this summer to go into production and I hope to be able to report in in next ATF the results that we can collect it's important to uh I mean in in all the pre-production lab and so we are playing with the real configurations but we don't have the the good insight about the scalability and so so once we move to into the production level we will get more starts and more information that we would like to share with all of you just to I mean to see what is a a real deployment just for you to to understand what we we are"
  },
  {
    "startTime": "01:26:01",
    "text": "talking about the real deployment this would be maybe the idea will be for for alto to handle around 3000 routers or something like that simple production we are talking about 40 routers something like this so the the the the next step is basically to understand the scalability and and all this stuff and next please so this has the very last slide I would like just to comment where what was somehow the the technical problems that we faced and somehow they yeah the the different engineering fights that we have with the with this deployment in the technology lab test essentially we started with a Ultra module in open daylight we need to adapt that because open daylight module was based on nldp so there was some transition to start collecting information from from bgp we in the technology lab we Face a mono vendor router scenario with virtualized routers so something somehow a lab environment for sure simplistic network configuration with just single IDP ospf in this case single autonomous system and simple metrics like the hop count right and uh Alto was connected essentially to one to some of the routers acting as rock reflectors so very um constrained environment then we moved to the production environment we migrated from the a bdp module from odl to the xrpgp we started finding issues in in xvp we write a number of tickets that have been already solved especially for bepls so I mentioned later okay in this pre-production environment we started playing with multivendor environments multivender our routers physical routers you know so moving from the vehicle to the physical dedicated Alto server and also facing the complexity of the real Network for the particular affiliate of telefonica where we are doing this this test there is a this is a network that"
  },
  {
    "startTime": "01:28:00",
    "text": "has a multiple private autonomous systems and also for sure public thermal system they also is a network that is not a Contin IP continuous and mpls Continuum so facing different issues in this respect also combining ospf and Isis and and we just have to also to take into account most of the sophisticated metrics in igp so not only the a number of hops but essentially the metric that has been defined in the igp for taking for building the cost map and the Lego map and then also connecting to different reflectors one for bgp sessions in order to collect the IP prefixes of the different customers in the different pops of telefonica and another reflector for a bgpls in order to retrieve the topology and be able to build the network map okay so the the very last steps is the integration with the production Network so we are now in in the process of being adapted to the production processes and rules the security the addressing the internal routing of the network all this stuff that you can imagine so hard and in all the environment in order to protect from external attacks the point now in the production Network in the in the routing part is that the activation of bepls is limited so we will start with a region of the network and then we will start progressively activating the apls in the rest of the network in such a way that we can incorporate all the information step by step and then also helping us to understand the scalability aspects and so and well we will coexist with many other services for sure and the expected deployment is the completed the department for Q3 so we're trying to to get the to bring here in idf115 the results for all of you that's all from this I think just one location for you for the what you have presented so far so yes thank you for sharing this interesting data which is really showing that there's something which is really concrete and really happening with the with the protocol so I really invite the others who has experience with the the protocol to share with that so I understand that"
  },
  {
    "startTime": "01:30:02",
    "text": "you have I would say some of the issues for the integration and so on which is just I would say as expected so if we just focus on the pure Alto I would say specification and so on did you encounter so far I would say animation part or something that needs to be clarified in the specification itself that need to be more input from the working group or it's just business as usual business as usual so the most problematic thing was to to parse the information from the products of SPF Isis and and so so no special issue with the the the fact of building an hour map and the Cosmetics was more or less a straightforward it was basically the passing of the protocols and trying to to expose they'll say the information of the network to be digested by Alto once this was solved the process of Alto was straightforward yeah and for the performance perspective for example how Alto is behaving how the request and there's is there any I would say shortcoming the way the operation of the protocol is currently designed is there something for example enhancement that we can consider in the future I think actually it's important this is for me the the key part that we need to focus on and if you have input that will really appreciate it by now not in anything special so take into account that we or we are in pre-production we are leaving the production from moving to production I'm sure that in the production we will face more complexities because the network will be huge by now we are dealing with uh four 30 40 routers is something visible regarding stations or considerations for alto yeah I think that the next step would be to include performance metrics on top of the picture so not only taking into account the Hops not only taking into account the ADP metrics but also taking the account the the situation of the network in such a way that the selection of the streamer could be richer in the sense of not only considering the path I mean the length of the path but also the characteristics of the path so this is the next step we have a number of use cases here on mine probably is soon for for this talking uh yeah so we are"
  },
  {
    "startTime": "01:32:01",
    "text": "concentrating on the deployment but the idea will be to enrich the decisions at the end okay and one last one last question on this one um about the the bootstrap in a different regression I would say how you are automating the way the the various engines are currently running do you have but now it's something manual is I mean we need to somehow we are in in a phase of uh how to say uh being sure that this is we are sure that this is the way to follow but the next step will be to integrate this with the logic of the CDN so automatic automating all of this from the CDM perspective so essentially that we can um retrieve the automatically and frequently and so the the information for that so for rental to the network no we don't expect special things it would be more from the client for the the tcd and the refrigerant towards to automate all the process to select the streamers and so on okay thank you thank you Luis thank you okay I think we need to yeah I know we hit the timeline right for this one so for next one actually do you want to see young or you want it so um I was going to talk a little bit about the the BRP uh deployment okay so um just real quick uh so the next one um yeah just to put things a little bit in perspective so I really should talk about um your CERN which is the problem of the large-scale data transfers from from CERN to Global globally uh to scientists are uh and research labs uh run the around the world um now we're also looking at another deployment at the Pacific research platform um um right here but in general the idea is that um there is a interest in in expanding through science networks so um we're also collaborating with esnet um also in the PRP deployment and as"
  },
  {
    "startTime": "01:34:01",
    "text": "Richard mentioned uh we're meeting with uh indoor manga um executive director of the esnet uh to discuss discuss these deployments this is a family of um of science networks that um their architecture is shared so if we deploy I'll turn and show value then it can be deployed um in in the rest of the networks as well so that's an approach and the potential um upside here um so next one just real quick on this um the prps what this networks are doing also they are extending to the edge so they actually extending the networks onto the 5G domain and building the edge Cloud as well whether it's the department of energy es9 Network you know building sensors and collecting that through Wireless and then building the the 5G Edge Cloud um and an example is a PRP that's um building a 5G uh Edge Cloud I do CSD and other other universities and NYU and other universities in the US as well and so they're looking at applications like the Holodeck um vehicle networks and um and um in general you know the metaverse or augmented reality um and so in this project uh you know there's an ecosystem of collaborators coming in this Caltech um esnet and and PRP and others and and quagmas actually involved here as well and so moving on the next one um yeah and this is about closing the loop here building what we call sort of the edge Loop so from a network you have first visibility then you apply intelligence and then control back to the network and this orchestration as well we believe that Alto is um uh you know suitable for for visibility and that's um the the deployment here the PRP and basically it's building this architecture and has Alto as the element to enable this visibility here in the intelligence uh we're looking at um"
  },
  {
    "startTime": "01:36:00",
    "text": "putting bottlenecker structure analysis basically to be able to make optimize uh decisions whether it's routing or rate limiting or service placement and then controllability could include Technologies like segment routing in order to help steer the flows so moving on to the next one um yeah and so that's just then the next one I don't know if we have uh yeah for ZN to make some yeah maybe we can just a note on the PRP we're going to be putting a demo in the next hackathon that's the goal for for that deployment and also at SC 22 also in November in Dallas available yeah all right so young are you online do you want to present have a quick maybe two minutes okay I will I will introduce my project uh we know in the defunter mode uh SDA controller only select one path every time for MP quick at the MP TCP uh there are lots of past uh not working in the SDA so my idea is the people or the past working uh by uh by algo so my uh serve is correct Network detours and the eo2 climate is the controller in SDA and I allocated mptcp and or MP quicker package to suitable paths so I"
  },
  {
    "startTime": "01:38:00",
    "text": "[Music] next page yeah so the result is is that the root is our mptcp and MP3 is higher uh that without eo2 it especially in per um Network we can see from the picture uh lost right higher uh to the throughput is defined now thank you okay thank you and then you have the idea we can take this offline I guess this is YouTube recording you can access and uh the slide decks from yesterday actually from Sunday so I think this concludes this um yeah talk thanks thank you so next we will have Luis to give representation thank you foreign yes this presentation is I will cover three drafts the idea the overall idea the working idea is to consider Alto as a network special function for for ATF Technologies and we will cover the data that you can then see listed there and I will do on behalf of my co-authors Danny Christian Serene and anshu Fang next please so in order to present a relationship among these routes uh the the working one will be the the one which is entitled IDF and our special function so the idea is to to consider Alto as"
  },
  {
    "startTime": "01:40:00",
    "text": "playing this role or the the special function that is able to expose capabilities to the network 2 applications external or internal applications such a way that can consume what the uh what the network can provide what kind of information can provide the network here we have the two examples that are the other two drafts involved that will be many others right one example could be for instance to determine the more convenient compute environment for instantiating any kind of application functions or whatever this is covered by the service edge the draft so essentially thinking on exposing compute capabilities CPU RAM storage and so on so far the other draft and the one entitles every functions follow the same approach but with the idea of exposing where service functions are and also the characteristics to reach those service functions here we can consider isolated service functions or we could consider even service function chains so it's such a way the idea would be the objective again would be to to characterize the path to reach these functions or to compose let's say the service chain among those functions in the others there are uh what I recommend specifically on on the net side so we will start with an F the working document then following by the service edge these two have been already presented in the past and I will focus later on a little bit more on the on the latest one the service function which is the new for for to be presented here so in the IDF number expression function the current version is zero one this is a the intention again is to align this with the current industrial trend of Network application integration and there are initiative similar initiatives in other seos and here we can consider for instance the three Epp Network expansion function that's on how is the inspiration of this work also that the Mec apis the all-runner rig the Linux camera initiative that is very recent with the idea also of offering apis to request and consume capabilities of the network and so on so far so again"
  },
  {
    "startTime": "01:42:01",
    "text": "the problem statement is very easy you know the networks are becoming consumable about application and services so let's consider Alto as the entry point for that there's exposure capabilities in which respect to IDF Network Technologies so the final objective is that the applications can make informed decisions taking into account the the network information so no blind decisions has to be asked today so as the applications are inferring or are guessing characteristics of the algorithm so the idea will be okay let's ask the network and the network will provide this information in such a way that I can and informed decision and then improve the quality of experience and so on so far so uh in this route this is a as I said before it's a kind of overarching draft so trying to expose what would be the different kind of capabilities to be exposed we are considering by now existing capabilities for sure the topology and the cost the cost map and so this is somehow the the the the initial capabilities of Alto but also the performance metrics the semantic view that can be provided by the path better and so on so far and also we include in this proposed uh also some other proposals as the service edge the service functions the abstraction of underlay for the overlay and this will work for the cellular for the CDN for sd1 and so and some other situations that will emerge are emerging in the in the in the industry like the the emergence or the appearance of the dynamic IP pools because of the fat of separating the control plane and the user plane both in the mobile part but also in the fixed part with the BNG the segregation the coops approach so the updated updates in version zero one for this specifically has been the content about service functions this detail in the draft that I will comment later and also security aspects that were not present in the previous version so next one please so this is the the draft of the whole service edge the current version is zero five and this activity or this this draft so how is"
  },
  {
    "startTime": "01:44:02",
    "text": "related with the computer World networking discussion that is happening in in the routine working group area but from the in the case of Alto Alto can provide here is an anov path solution so a direct working group area is working in an on-pass solution here we are addressing the same program space but with a different perspective with a different approach is also clear there are multiple and heterogeneous data centers being deployed across the networks so there are compute capabilities in terms of CPU storage pan with memory and so in different points of the network so the the objective here would be to expose all of this together with the topological information of the network and in the future with the performance metrics and so on and so forth uh the the purpose of this will be that the applications that can consume this information can instantiate the applications of the or of the service with informed information about the resources that are available but also the characteristics of the path to reach those compute capabilities across the network right so um the solution is to Liberation Alto for aggregating all that information and for exposing this information to the external applications again once more time in such a way that the application can do an informed decision no guessing about the characteristics of the of the network but just collecting the real information from the network the updates that have been provided in version zero five uh we described potential stations for Pat battery unified and unified properties so the idea is to leverage on the existing work and and maintain that existing work to cover uh what could be the information related to the Computing uh environments okay and we also provide example queries provided for a filter entity property map we've also providing some examples and so on so moving to the and I will detail a little bit more this last draft this is about service functions so the problem statement essentially is that nowadays the services are formed by a concatenation of service function so"
  },
  {
    "startTime": "01:46:01",
    "text": "this service function changes right so we have a connected graph of service functions but by now we don't have a combined information between the functions the this service chain plus the characteristics that uh that connect these different service functions so the characteristics of the of the chain so there is typically more than one instance of a service function in the network so there is a problem about what service service function instance to select individually or to form a chain to form a graph so at the end the purpose of all of this is to help on the service realization by selecting the most suitable service instance or instances depending if we are addressing just one single function or a chain or service functions so at the end the the purpose of this is to characterize the path to reach a particular service function instance or a type of service function so we could have several instances of the same type so we can try to determine what would be the better characteristics in the network for reaching the one of the instances and also to characterize the path among a sequence of service functions again I mean the characterize the path in a service function chain next please so the kind of information of interest that a client could consume would be the the well here at least I will comment some of them I mean from an endpoint to an instance of a service function type the same but characteristics for an endpoint to a specific instance of a service function type all about characteristics with for a given chain or for a bit or at the time of composing a service from one service function to another function and so on so far I will not uh waste more time on this so there are several cases that could be favored let's say for a com complementing the information with the network information in place next please so the the kind of solution will be similar the the picture is similar to the to the case of This research essentially to combine and to complement"
  },
  {
    "startTime": "01:48:01",
    "text": "to use the alto server to integrate the information of the service functions and integrate all of this with the political information retrieved by bgp via PLS and and so on as we saw before so um we are proposing here in in this draft a number of extensions extensions to enable the alto clients to request information of the inter of Interest the the kind of information that we show in the previous slide and also extensions to collect and combine both the service function and the network information all together for enriching the the decision of the sales function chain there are extensions uh or we do foresee extensions that could involve augmentations of the path vector and the unified property draft so we will leverage on existing work for this and just to remark that there is a clear link with related activities in ATF like the service function chain activity the service programming with semen routing in a spring working group or the service functionality topology on this so um we see clearly this link with this work in ATF but also there is a clear link with activities outside ITF as would be the only about virtual Network function graphs in Etsy NFP and next please so just just for finishing the next steps so clearly this is a our idea is to work on these different aspects for the future Authority Sheltering so we we have cleared this this is for future chartering so we want to provide all uh all this work for directing let's say the future and it is in in this direction so our idea is to complement uh also this other work in other working groups from ITF so helping on the automation of the service functions so that the sensation of the of the instance of the satisfactions and so on so far so we see this as a complement of uh which is already another in other working groups and our idea is to prepare updated versions of"
  },
  {
    "startTime": "01:50:01",
    "text": "the all the documents for its 115 and for sure comment some feedback is more than welcome so hunting all right Martin Duke Google again I'm not going to bother with the queue because yeah that's nobody um uh I was very excited to see on like one of those slides that um like you think there's something worth doing without any extensions um I think that was actually going to be my question having reviewed this Draft before the meeting um because uh to me like I think the hump is just to get adoption of this thing um of of Alto and out you know deployed and servers real servicing clients out there and then we can talk about extensions um you know at this point like doing extensions is the hope that somebody will adopt the use case is is where we've failed a bunch of times and I think this is this is very promising in that respect so um I I uh good luck to you to get this this out there and I think if this does get out there and deployed then any extensions that that use case might need would in my mind move very close to the front of the line for re-chattering thanks thank you that from my memories of what the guys in CERN and in general in the academic networks are doing this sfc case will be of interest to them as well because precisely they one of the things that they were interested in to do some kind of messaging of the data before it arrived the final so so probably this could be something that we should offer to them as well not only for the uh it's simply anything that came to my mind nothing but do a thing okay thank you okay thanks Luis so we have time so let's"
  },
  {
    "startTime": "01:52:01",
    "text": "move to the next one actually we only have five minutes and so who okay who will take over the last stop okay so loosen do you want to present this a hello everyone okay okay I will quickly uh hello everyone next I will introduce the jobs called the architecture of computing power Optical Network motivation with the rapid popularity and application of cloud computing artificial intelligence and other technologies will cause the total amount of data has increased its possibly and the demand for data storage Computing and transmission has increased significantly therefore the processing of this computing power to support therefore with the advantage of ultra large capacity capacity or Ultra long distance low latency and flexible scheduling of the optical network of products are what provide a weather coverage for example and efficiency"
  },
  {
    "startTime": "01:54:03",
    "text": "Super Capacity guarantee for computing resource this this Computing related network with the optical Network to release the calcability linkage between the next one use use case one network resource requirement the age the age Network management lawyer receive information from the client obtains currently a commit user information and provides it to the cloud management platform for Network resource the cloud management platform obtains regular information about applications and the networks uh the act the architecture of computing power Optical network is shown in the following falling feature it equals Cloud management platform or computing power okay orchestration Computing resource computing power scheduling called the network management Age Management platform age computing power orchestrian Computing resource computing power routine and forwarding each Network management next I will introduce the functions of"
  },
  {
    "startTime": "01:56:01",
    "text": "each component module the act the architecture uh uh Age Management platform receive application a requirements from Euler's very well in the units for what the promise it was about the management plan from age Network management reports Network information and the community computing power scheduling information Cloud management platform its function includes report the network information to the computing power scheduling lawyer inform the computing power serves and perceives the community empowers statements through the computing power scaling lawyer generates the computing power route and more enter the route in real time since the the generation computing power Arrangement information to Cloud Network management Cloud Network management distribute the receive the computing power Arrangement information to each Network management thank you foreign [Music] for this topic so so let's uh actually we wrap up for today's discussion uh"
  },
  {
    "startTime": "01:58:00",
    "text": "actually uh this time and we both attend in person so it's a yeah it's good good time actually we get together hopeful everybody uh you know we can have more people to attend in person in London media so so in say you in London meeting so and and uh Martin do you have anything to happen okay thank you thank you"
  }
]
