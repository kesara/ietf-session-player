[
  {
    "startTime": "00:00:10",
    "text": "okay it has just gone five o'clock here in the UK it's time to start the Seymour working group at ietf 115. I'm Barry lieba and my co-chair Christian I'm soos is here remote and thanks for taking notes Marco as always and Christian is also taking notes I encourage everyone else to also get on The Ether pad and help out with note-taking if you can so let's get started note the note well well it's um tells you what you need to know for legal participation in the ietf you've seen it many times already if you have any questions contact or go look at the BCPS and contact your lawyers if you need to if you're on site and you're not up here speaking on the microphone please wear your mask I see everybody is so thank you and um if even if you're in the room please get on the meet Echo client uh you can use the light client which you get by scanning that lovely barcode up there or sorry that lovely QR code up there um that's what takes the blue sheets now and that's it yes and use use that to get in the mic queue whether you're remote or local here's our agenda I have switched since the previous version that was posted the first two items in order in order to keep Carstens together so we don't have to switch slides back and forth um does anybody have anything they want to add to or change on the agenda"
  },
  {
    "startTime": "00:02:03",
    "text": "and yes Brendan um Brendan Warren I'm just proxying for Hank here he asked if it would be possible to move time tag and cddl to the start okay we can do that so although the fact that he's not here makes that questionable yeah well but so that that that thing that says a there pretend that's C point one and here's Hank oh there he is foreign so we do we'll do the order b c a d any other comments on the agenda okay so anything else uh that we want to adjust on the agenda hearing none that's all of my slides so I'm going to switch to Carson star do you want to do your own slides Carson nope I will switch the slides for you karsten's slides foreign take it away okay I actually have sneaked in a little additional item here we had a meeting of the user usable former methods proposed research group during the lunch break there were some 40 plus people in the room pretty active 40 plus people and it really looks like this research group will happen and that means we have a research group to talk to on all things formal methods so we are going to ask them to do studies about the best way to do cddl or something like that that could be interesting"
  },
  {
    "startTime": "00:04:00",
    "text": "okay but today I want to talk about time tank and City the evolution that we will skip that one slide that machine has made but much better slides for next slide please so just to remind everyone about time tag that document is from 2017. we registered the tanks in 2018 and they are being actively used in some programming language communities um so we should not really change this document a lot anymore this was adopted as a working group item and 2021 and yeah there's no rush to complete this but recently we mostly have been waiting for uh working with uh sedate so sidage is a working group that is doing the green stuff on on the slide um on light blue depending on your eyes where you can add hints to an RFC 339 timestamp and we are going to be able to transport these uh in uh time tag um as well so this is how it looks like and for the last half years so we mostly have been waiting for today to converge that has uh happened next slide please but uh yeah there is a problem here because uh while sedate was extending the time take with the RC 3339 timestamp with new information and implementation survey was done by one of the contributors and he found a little problem people are not using RFC 359 the way"
  },
  {
    "startTime": "00:06:00",
    "text": "it's saying you should use it and the reason is that 339 was based on ISO 8601 1988 for good reasons because that was a version of id6 8601 that actually had been published by nist I don't know if they did this intentionally or unintentionally but the document was out there in the wild so people could look at this without paying money so they weren't actually using the 2000 version of 8601 but that had made a little change by outlawing minus in front of zero zero colon zero zero for a local time offset and suddenly something that's being used in RC 559 no longer was allowed anyway we try to get some discussion going how to handle this of course when you find a bug the best thing is to acknowledge because it's not going to slow down your work but that's not what we decided to do incident uh so we decided to actually write up a fix that explains how local offsets are actually used and that goes beyond the the charter of the working group so what we are now doing is finding out whether the isg will be happy with doing that um so sudate has finished the working blast call of their document and I think the content is stable there's really not much reason to to change it and other groups like ecma tc39 temporal um are in sync with that so what we really should be doing is synchronous synchronize our isg"
  },
  {
    "startTime": "00:08:01",
    "text": "submission um of time tag with that of sedate that will take a couple of months I don't know but we should be doing our uh working plus call uh soon next slide so my original plan was to have a dash or three ready before iatf115 uh live intervened um so one question that came up was whether we would manage to add a third time scale we have UTC and atomic time as time scales uh India and we wanted to add ut1 um there is a theme here sibo in space it was used in a lot of space applications these days so it fits to have a ut1 an astronomical time definition in there but we didn't manage to do this it's a really complicated subject so it will require some extra effort so this will not go into this um document um also the distinction between planned and actual times will not go into this document we have a registry so we can always add stuff later but we we're not waiting for this and there is one inconsistency that requires a PR before we can submit the dash or three so expect that to happen early uh next week and my recommendation would be to do the Working World Class call that was time check questions okay let's talk about CDL 2.0 so uh that's a actually a pretty bad name because it sounds like we are changing everything you know we are not changing everything"
  },
  {
    "startTime": "00:10:02",
    "text": "um so in particular we are trying to make sure that uh every city 1.0 document remains a valid City area 2.0 document and surprisingly almost all ctd and 2.0 documents will be valid 1.0 documents we get to that but there are four uh things that are on the priority list here we have a I should have put that on the slide we have a freezer document um ctda-vis Frieza or something um that contains further items that we could pick up here but but haven't considered prioritized and we have a cddl2 draft document that contains rough sketches for all these items so let's go through through these sketches but if you find something in your work with cddl that is not covered by these four items and that you would like to see fixed within the next month it would be good to say that okay so this is one thing that we really got wrong in cddl tag numbers only can be literal in CDA 1.0 and that that was just plain not so bright so that's one thing we need to fix we probably should discuss the processing model and we have an item called annotations there and Brendan is going to say what he's doing with annotations then we have the module structure multiple cddl modules working together to get a model this requires some linguistic precision to separate and finally we want to"
  },
  {
    "startTime": "00:12:02",
    "text": "automate the whole issue of referencing stuff out of other documents rfcs internet drafts probably three gpp documents because there are enough that we want to cover that but I don't have a plan for that yet and I Anna references so you can say this video can be one of the various registered at INR registry X okay so let's next slide let's go into the non-literal tag number so the the first line is the current syntax where you actually have to have a literal uh tag number in there and uh The Proposal is to change this into backwards compatible literal tag number of course and something that looks like a generic argument so it uses the the generic argument uh angle brackets so you can write a spec like this um so well this number six syntax such as yeah and then you can put in the tag number here and uh well yeah just write normal CDT and just to remind people how we are using angular brackets I actually used an example here that uses angle brackets and it's generic semantics as well so this looks uh seems to be a very small patch and my main issue here is that I'm not quite sure yet how we are going to package this is this going to be a separate document which we just move independently or everything else or do we package this with other"
  },
  {
    "startTime": "00:14:00",
    "text": "stuff it's the first time we have seen a need to actually change the syntax since rc8610 Brendan just from a consistency perspective if we're looking at changing the uh the thing following the dot to a uh a non-literal it just feels very strange to me that we're exposing the major type of the tag to the left of the dot I would think there'd be a cleaner way to represent that I mean sixth the only reason six says tag to me is because I know the major type I shouldn't need to know that right well yeah the the this reflects another mistake that we have made that we probably cannot fix which is that only for number six this is the actual argument and for the for all the other cases it's the additional information so when you say 7.25 that doesn't mean that you have an argument of 25 it means you're using additional information 25 with seven so you have a half Precision floating point number this is yeah I I don't see a way to to fix this without actually opening that wound further so I would propose we do this just for yeah this this whole business of actually putting uh cddl on on the tweet touching the ground is pretty adult it's not extensible if we wanted to do"
  },
  {
    "startTime": "00:16:02",
    "text": "something that goes beyond Json and sibo we probably would have to add something to this so that that is not the most beautiful part of CDA but it's usually covered by the Prelude so you should write it and not 0 or H1 uh except in this place where it actually shines through I mean we could invent a new syntax uh but then the next question would be what what do we use to identify tanks as such and yeah it's also something where I uh get confused all the time when I write hash six in sibo diagnostic notation or leave out the the hashtags and cddl so this is not beautiful I agree with that but we need something that that kind of switches the parser into a different mode before we get these angle brackets or we will have all kinds of syntactic problems so hash six it is okay yeah so if anybody has an idea of how we would package this as a one paragraph RFC or whether we package this with anything else I think there are people who want this pretty uh quickly okay so that would say one paragraph RFC unless we find anything else there that needs to be changed in the day syntax of of the language but I'm not currently aware of anything okay next slide so the one thing that is pretty fundamental"
  },
  {
    "startTime": "00:18:00",
    "text": "but that we have already started to extend in one or the other way is the processing model so most people who do schema languages actually want to use these schema languages for validation and RFC 8610 essentially tells you when does a sibo instance match our Json instance uh match cddl specification so this is the validation model you essentially apply the model to the data and you get yes or no and that's a Boolean value in RC 9165 we already extended this by adding the concept of features so now you get yes or no plus a list of features that have been used in the match so there are some uh how to put this it's not necessarily entirely clear whether there's always a deterministic answer to this question but unless you you try to be adversarial when you write your model uh this this pretty much works so uh other schema languages have something called a post schema validation instance or psbi that actually changes the data that have been validated for instance by adding default values so CDA does have a DOT default but that does something slightly different so that would be one thing we could do but we could also do more uh changes to the the input that are kind of orthogonal and"
  },
  {
    "startTime": "00:20:02",
    "text": "what the cddl tool for instance does internally is to annotate the instance with the rules that actually were used in in matching so when the CDL the original one that I wrote there are other truths by now of course uh but the tool that is called lowercase cddl when that has validated an instance and you know which rules were applied and that's actually useful for for an annotated output which the tool can generate but it turns out there is a lot of noise in such a an instance because well you have things like some something equals text string and then something else equals this or something else so you get a lot of rules that are annotated on top of an item and the the mechanism that is used in a CDH tool to select one of those rules for the actual annotation is not very smart so it would be nice if the model actually had a way to say well the fact that this rule was used is really important and the fact that that this in the end was mapped to text string that was not that is not so important so that would be the kind of annotation that we would add in the model to have the validation process Edge data that go beyond the generic data model of sibo that allow you to do something with the validated instance and annotations we don't have to reinvent them because relax Ng"
  },
  {
    "startTime": "00:22:02",
    "text": "provides them so we probably will do something that is quite similar to what relax and G does and then we have an instance that is still the original instance that came in so there are no changes to the actual c bar or the Json but there are additional there's additional information in terms of annotations that can be used by the implementation that is using a past instance to to do something and of course the next step then is to think about transformation so uh for instance if you have something in a structure that that's only there to distinguish different cases you might want to remove that from the uh validated instance because you had you now have The annotation what it is you no longer need this the syntactical noise for instance when uh well I'm going occasionally going to switch to a b and F and then through cddl because they are so similar similar I have an ABN f tool that has that that is being used in particular for implementing cddl because it's a language and typical item where this is being used is when you have a string you want to get rid of the codes because the quotes are not part of the string but you also want to transform all the escaped stuff in the string to what is actually meant by that so that's a typical thing you might want to do in the transformation and that's something that that we could include in the processing model I would certainly want to have that in ambient efforts a bit less necessary in sibo because there are so many ways in sibo to express things"
  },
  {
    "startTime": "00:24:02",
    "text": "more semantic level anyway let's talk about annotations next slide and I'll give the microphone hello um I'm Brendan um so at the hackathon I uh continued some work I started quite some time ago on generating a c pull parser definition directly from cddl so what I have essentially is a combination code plus schema ish if you squint at it hard enough data structure and it uh it doesn't parse the whole block of Seaboard directly into a data structure instead it just consumes the values it needs when it needs them so it kind of iterates through the core structure as it needs the bits that are in it and this is specifically designed for suit but could be applied elsewhere um so it it has a few things that it does that make it quite convenient in that kind of use case it evaluates keys and types to make sure that it's uh getting what it expects to have it also has some guidance elements that it extracts from the cddl now those guidance flags are essentially what's used to control my parser so I can repeat elements mark them as optional unwrap some seaboor inside a byte string pass whatever I found to a Handler function or handle key value pairs which essentially nests down to another level um it's quite efficient for what it is but it's a bit of a pain to generate it from cddl as it is today and the the key things that I see as missing are first off entry points and I'll I've got another slide that gives a bit more of an example about that but essentially what entry points are are suppose that"
  },
  {
    "startTime": "00:26:01",
    "text": "you have multiple sub components of a cddl structure that you might want to handle individually you've got one choice for that today and that is to put them all in a top level type choice and that's okay except that in my scenario I may know already which one I'm going to encounter and putting them in that top level type choice in my scenario at least would require each of these elements to be tagged to be able to differentiate between them so I would very much prefer to have a concept that I've called entry points which is where I can tell maybe it's something that doesn't belong in cddl itself I'm willing to accept that but I definitely need to be able to tell my generator which things I might want to pull out and so from that perspective if everyone has to do that it looks to me like it belongs in cddl um I would like to have annotations for my parser to to tell it when something is going to need to be handled directly maybe in a slightly different way instead of just continuing to extract into a data structure so for that essentially what I'm saying is a Handler function name I've also said that I might want to extract a variable that might just be specific to to my use case it might not be generic so maybe it doesn't belong here I don't know that's for the working group um and then there's a question of entry point dependent handling suits got one specific use case which is interesting in this where I need to extract the sequence number of a manifest before I do any validation on it because if it's too late or if it's an old one there's no point in even validating its signature it's too old I won't touch it if it is valid then yes I'll go through and validate its signature but if it's too old I don't even want to look at it so um in that scenario I treat a whole bunch of things as opaque objects that I"
  },
  {
    "startTime": "00:28:01",
    "text": "would otherwise unpack and so there it would be convenient to essentially have two variations where either I unwrap white strings or I don't um ordered multi-maps are a really big deal for me because I'm encoding key value pairs in an array because I need to repeat them and not have them reordered on me and that's the only way that I can do that in in seabor and there's no way to represent that in cddl as it stands today what this means is that I have a separate data structure that lives in parallel to the cddl which says these are the names of the types which contain ordered multi-maps so that my code generator can identify them correctly um and of course as Carston mentioned Imports Imports are a really big deal because I don't have Imports today what I have to do is fetch copies of the cddl which for cozy let me tell you is not straightforward especially because of these trailing characters that exploded in there somehow um and then I have to concatenate all the cddl together and because of the way I'm doing it I can't even strip out the the elements of cozy that I don't want and so they get sucked into my code generator as well which I would really prefer if I didn't have if I could have fine-grained Imports I could get rid of a lot of that uh next slide please um so an example for where annotations might make sense imagine a challenge response protocol where the challenge and the response are different messages that responder knows that it receives challenges it doesn't receive responses it does not need to choose which of these types it's parsing against so in when I talk about entry points you can think of the responder receiving challenges as its entry point into there"
  },
  {
    "startTime": "00:30:02",
    "text": "it will only need to parse a challenge it does not need to parse a response so from that perspective having an entry point to the challenge simplifies the responder um I mentioned that there's suit not using every structure in cozy um and annotations could be used to strip that yes uh I think that's all I have so there you go Whirlwind tour uh any questions no yeah I have a question in five minutes which is whether the things that are on the slide actually solve your problem um yeah so uh let's talk about Solutions uh uh briefly we did that at the last interim um as well but I hadn't made slides for those so maybe it's a good idea to run through these again um so as Brandon said in today 1.0 we built our larger models by concatenaging uh little modules um in an intelligent way and which fires need to go into the the whole model real is information that lifts into externally and make file or something like that and in CDA 2.0 we want to have explicit references but we also want to be able to just feed some CVA 2.0 fire to a cd-day 1.0 processor and have that do something useful so people can continue to use their code generators and so on until these are also updated so here's the kind of syntax that I'm proposing to add these module superstructure components so as you can see this is a conventional comment it's a semicolon it's a common character in cddl that's it from ABN F which was"
  },
  {
    "startTime": "00:32:02",
    "text": "designed in 1977. and if you were wrong in 1977 then semicolon may be a very familiar common character to you right now most people think the hash mark is a common character and well just combined so this is this would be an export statement which is pretty much well I don't know if it's the same but it's related to what you call entry points so the uh module exported from RFC 1990 would say there are three entry points object ID relative object ID and private Enterprise number and these are the three ones that you are supposed to use you can get at near this so this is not trying to be data encapsulation or something like that but these are the three ones that are supposed to uh be used more often next slide so yeah uh one kind of reference oh should I put this slide later but it's okay one kind of reference that we often have to do is look into an Ina registry so I didn't use the conventional comment here because that that doesn't work you have to uh go right into the CDA here so let's say that the the Cozy algorithm is an intern integer for which Ina has an entry in the Cosi registry in the algorithm sub-registry and there in the column video I just spent half an hour talking with INR people on How likely this is going to be supported in the future I mean it works today because I just have to throw"
  },
  {
    "startTime": "00:34:01",
    "text": "this XPath at the registry but yeah this this uses um internal interfaces that I'm not supposed to to use so uh we need to find them to do this we need to find time to actually work with Ayanna on doing this and we actually have to finish the reference or identifier draft that explains that you are not doing this each time you uh switch on the ledge there is something that may be helpful here that doesn't reach inside the internal things that you're not supposed to access there's also a CSV file for each of these registries yes not sure everything is in there but yeah that that's useful input has somebody invented XPath from csvs yet you know that there is actually a draft about cddl for csvs so if you ever have to specify a CSV you know how to sit in here anyway so anyway so this is the direction here this will take some time because we have to talk with Ayana develop common ideas about what the interfaces are they will have to implement these interfaces so we're probably talking about a year or so until this actually uh works so maybe we should push this out again to a separate document but I think this is really useful in particular also when you don't want to hard code in your file that minus 27 means this particular variant of using AES uh then I think you'll win with this"
  },
  {
    "startTime": "00:36:01",
    "text": "yeah and you you are probably already guessed that I want to do the same thing for ABN F at some point uh so that's again something like that we need to understand next slide so here's the really minimal way to do an RFC reference so uh if you say I want the integer from RFC 8610 this is the Syntax for this when we Define cddl we kept quite a few special characters in The identifier syntax so we could use more characters here but I think that that actually works and of course the the implementation would be that if something is not defined uh in the CDA file you don't throw an error right away but you look at it whether it's a valid referencing syntax and by the way one nice thing would be that we actually can put the preload into a namespace and uh yeah we have to think about this what this actually means but we have had clashes between the preload and things that people wanted to write uh in specs and would be nice too separate this a little bit asked even if the preload is not supposed to change anymore so you know there are like six 36 reserved identifies uh you cannot use it would be nice if this would be a smaller number okay so this is uh I think a construct with high usability next slide uh now if we ever write something that like I don't see 1990 again then we will have this export line there"
  },
  {
    "startTime": "00:38:02",
    "text": "so this is a slightly simplified version of what is in RFC 1990 um and uh this would actually be clear that these are the three entries that you are supposed to use and until that is available yeah we can just do this unadorned import mechanism or next slide we can do an export an explicit import so this is one of the conventional comments again we say we actually want to import ID from RFC 1990 and then we can use that without the prefix okay this should work for rfcs that's easy it should work for internet drafts but there of course we run into this problem versions are stupid and uh yeah so we will have to spend some some mental energy on doing something here that balances convenience and the potential for errors uh but this should work maybe without the dot text I don't know and you should be able to take something out of out of a draft yeah and for the Arabs for the old rfcs there would be an implicit assumption that everything is exported from this RFC because we don't have the explicit entry point a statement and one thing we could also do is provide references into the document that are more detailed"
  },
  {
    "startTime": "00:40:00",
    "text": "because many documents have a an expositional part where you have chunks of cbda and then you have Consolidated CDL intersection you really want to pull the CDA from that section CDs this little trick where if you you find something twice exactly the same way that's okay foreign but we can't really rely that all drafts get this right so this is this would be a way to be more specific about uh using NXT fnxd okay so these are the important export uh syntaxis oh yeah so this thing is called include I don't know if include is smart we can find names for these things uh and essentially says we are going to use the the term time tag to reference things out of this draft I forgot to say that okay next slide so what are the operations we have the export mechanism that essentially adds a prefix to a local rule name and makes that namespace available to other specs we have the import which takes things out of namespace maybe use as is maybe on prefix uh details to be defined and we have the use for include thing that allows you to say where you actually can find that namespace and there is a problem"
  },
  {
    "startTime": "00:42:01",
    "text": "because references out from a document always age very badly so you really should not not ever have references from a document to something that is behind the URI or has a specific version number and so on uh you really should be doing this in terms of namespaces but then it's it's pretty convenient to be able to do this so yeah we again we probably have to balance convenience with correctness again here okay I think that's the main content there's another slide I think yeah so uh yeah what I just said so how do we find the document that exports a namespace I would like to be able to talk to about TS 25 point something and then uh the sister have the system know that it has to go to some 3gbp repository and extract the word document convert that to markdown extract the city data from that and so on so this this would be convenience but the the model spec should just talk about ts25 points three four five uh the inverse of course also can happen if you have a namespace and then the document gets split uh yeah then you have several documents and exporting into the same namespace and we get all the problems with updates revision versions semantic versioning uh there probably will be a Twitter in our lives at some point where you can say I want to have at least version 2.2 of IDs but not version three because that"
  },
  {
    "startTime": "00:44:03",
    "text": "might be too new for me so 2.6 is fine but 2.1 is not and 3 is not either okay last slide I think yeah um I just wanted to remind people abnf is a lot like cgdl so if we invent something here that works for CDL it's quite likely that this will work for ABN f as well well certainly not the Syntax for Anna references but ABN if there's other ways of doing that so that would be a slight Divergence but anything else we probably want to offer for a b and F Well at least the a b and f that goes into our cddl uh but maybe also uh for freestanding a b and F so uh yeah we no longer end the situation that people have to extract uh parts of a b and F of some random RFC to get their ABN F statements uh compile okay what are we missing Chris Chung go ahead Christian we don't hear you yeah not not getting any audio from do you do you hear me now yes there you go okay um what are we missing looking at the at the annotations we had before um I think this might be missing uh something on whether something is mandatory mandatory to understand or not"
  },
  {
    "startTime": "00:46:00",
    "text": "because looking at Brandon's requirement list on describing things that then go into into particular data structures um if I were to take a cddl document and map that to my data structure that would be an piece of information I would otherwise have to add manually so the data structure can say and this is potentially ignoring all say positive integer keys but not negative integer keys and if that information could somehow be part of the annotations I think this would be valuable although it could of course be feature dependent on whether something is mandatory to understand or not right now my assumption would be that anything that is in a city it's big is mandatory to understand uh so are you looking for something to say this is not mandatory to understand this mandatory to understand would be something of doubtish but if the CDL explicitly said there is this and that say extension point and this is marked as not mandatory to understand then something building a parser from the cdtl into a particular data structure would know from all the metadata in the cddl that it can ignore particular branches whereas regularly unlike some JavaScript conventions things that are not known are a pausing error okay I would like to to marry this with the dot feature mechanism in some way yes so maybe we can find some semantics that actually work with this together um Carson I'm gonna have to I I can't agree with you on the mandatory to understand Point uh if I have a parser that understands cozy sign and doesn't understand cozy Mac that's totally legitimate and that was Brendan Morin"
  },
  {
    "startTime": "00:48:01",
    "text": "this is henkery um switched order here no sequence um So my answer to question questions is I don't know and if anybody remembers the question so um look up the minutes and um but there's something that would be uh in in strong relationship to what Brent was but wants to do and that's an ideal so if we do The annotation and uh the code generation points that help us to do that we could further annotate them and and get that thing going I know yeah in the mood of breaking things apart into multiple uh documents I think that's the theme of this presentation here right now there could be something that then Builds on the first step of annotation and I think that a lot of people would like to do work on that today but they do not know where to start and that's Brandon's work uh input sorry from the from the uh first experience during the uh suit manifest purpose I think and uh generating and making that easier his life easier everybody's life easier and and then maybe we can break off from that uh something that would uh be annotation for that I think that is my only request that they plan for that when we break that out yeah I think there is some something interesting going on here um so putting all this information into one CDA specification it doesn't quite work because we we want to have a city address reaction that actually we actually agree on in a standard now we don't have to agree on the variable name for for something to extract um so uh we need to find a way to actually add to some cddl in a way"
  },
  {
    "startTime": "00:50:01",
    "text": "that it survives if that CDL evolves in some form um and yeah this is not a new subject at all we have that everywhere I mean CSS was designed to add to HTML so we know how to do that in principle uh we just have to make sure this is actually this works in in our specific uh context but I think that that's a pretty important observation I will throw a time check in here that we uh we do need a few minutes to handle the DNS um I'll I'll just say that that is effectively the solution that I've taken I'm doing exactly what you've described it's just not in the context of cddl directly so um I guess I agree in which case you know that there is a mating list and you actually can use that and throw ideas there and uh yeah I'm sure we will have a lot of nice interims in the next few months that actually look at specific parts of this and uh we can develop it from them and now I can give the microphone to my team don't see the slides here yet so okay I guess I just let you control it um okay yeah uh hi I'm Martin uh I talk about DNS message representation in sibo um most of the stock I already gave in on Monday and also a little bit during the interim uh yeah so maybe we can skip over some of the slides for time reasons okay the motivation mainly is that uh with uh for example 800 to 154 but also"
  },
  {
    "startTime": "00:52:02",
    "text": "with uh the lp1 networks we run quickly into fragmentation depending on the name size even for very short names within what a record if we use DNS of a co-op uh we run into fragmentation you can see this in this graphs where on the x-axis we see the queries and the responses and on the y-axis we see the packet size and the dashed lines marking the fragmentation borders so we need some way of compressing DNS messages which is basically what we're trying to do here next slide please yeah okay next slide um uh sorry yeah so the objective is to reduce the packet size of DNS queries and replace and uh yeah we want to encode this in sibo and omit the Redundant DNS fields and in the DNS queries and responses and also want to use address and name compression using packed sibo which we decided to make it optional so even parsers that don't support packed sibo can work with that next slide please um we already got from our discussions in core some feedback from DNS up um that the concise format might hamper a future DNS extensions but there are possible ways we're ready to address this um one way uh at least on the record uh with a resource record label uh level is to have unstructured resources records just as a byte string um I will go into this in at a later point and uh also with contact negotiations we can always for example fall back to the wire format uh which is still not off the table if you have any more thoughts on that how to uh improve that uh please give feedback there"
  },
  {
    "startTime": "00:54:03",
    "text": "um next slide please so we go straight into the DNS query this is basically at the moment still the same that as I presented at the interim um so the DNS name is just a text string and you can add optional IDs and record types next slide please resulting from the core discussions um this there's a problem that this currently doesn't support edns 0 because we can't have a additional section with this at the moment so a new way to add the Zulu RS for the edn s0 options and then it's also the question if we want to support it there is no way to express DNS stateful operations but since it no up code is present and the sections counts aren't the thing in our format and DNS save for operations with this R expressed as tlvs so how to express this here next slip is and yeah for the resource records again going back to that um basically this is also again like in the interim a seabo array which is minimum contains a TTL and the resource data and an optional name and record type specification which then would be just taken from the question if they are not present next slide please again from the discussions that already happened the question is here maybe what I said before uh also provides a possibility to provide the research record just as a byte string where we would just use a wire format of that record next slide please and lastly to represent a response that would be an array of arrays where each array would be an array of DNS resource records representing a section again we generally assume that the"
  },
  {
    "startTime": "00:56:03",
    "text": "transport can map the queries to the response which is both the case for Doc and Doh but if there if that's not the case the original question and ID may be amended optional next slide please and here again from the discussions uh the estate for operations are also here missing somehow and um there are also a few fields that are completely ignored because for Doc we didn't need them really but maybe it still makes sense to include some like the opcodes our code and flex next slide please and so just to give an example how well the compression works at this old format which probably will change a little bit um but not that much byte it's added then hopefully we can compress a query by 400 and response by 283 next slide please um for a more complex example uh where I gave this a dnsst example next side please we have the problem that uh the concise format is a little bit larger than the original format so we need some we had the idea to add some address and name compression and for that we use the sibo pack format next set please exactly and uh that uh then we we can use by adding to the media type the parameter packed one this is not the case in draft 0 0 1 at the moment where it's its own media type but it will be in zero two um and uh then also make the shared I value and argument table one list because we only need the prefix and suffix"
  },
  {
    "startTime": "00:58:01",
    "text": "compression from sibo packed so uh I don't we don't see a problem to uh make them one list and um yeah Earth then we basically have this cddl maybe also something for the cddl2 thing I wasn't sure if this is possible to express this in cddl uh how to our compressed response would work um yeah and uh the response then becomes just another sibo array of two arrays with the packing table which is the combined shared value and argument table and to compress DNS response which basically follows the same structure as before but just let every values are then there's a very certain compressed according to sibo pact next slide please and if you look then at the example I had before instead of 200 bytes we then have 119 bytes which is a compression rate of 146 there's 64. um percent yeah last slide should not come oh no okay this is some overlay yeah um we can add some uh implied DNS specific table entries for example tlds so that you can um have them maybe compressed but not mentioned in the packing table so that you can even save even some more bytes for common values such as for example tlds um now the last slide um so the question is especially regarding the query if we might need to get back to the board with drawing both if we want to support for example dsos but also the edns0 or do we keep it as is and just say if you want to use these features use application DNS message format as a fallback um which uh given that message is that use options or DNS stateful operations"
  },
  {
    "startTime": "01:00:01",
    "text": "might become more complex anyways might be a viable way to handle this and yeah uh for the next version we also need some more work on the backseat board uh specifically uh how the packing table is to be constructed and um also uh yeah this idea was a global compression context where you might use a TLD or something like that uh implicitly um we also need some to put some work into that are there any questions or comments on your site foreign contributed to was about compression that I have worked on various forms of compression since occasionally there is always this this urge to get that other one percent and I think we have to be very careful that we don't fall victim to that and do the things that actually are meaningful and can be implemented with with limited effort and not try to be that last one percent uh better afterwards so that would be my recommendation and further developing this if something falls out with without a lot of effort because it's yeah no complexity let's do it let's not try to do things that come to mind but then turn out to be really complicated and to sign this uh I agree with this basically also so yeah"
  },
  {
    "startTime": "01:02:01",
    "text": "um but especially with edms0 maybe this is still something to consider for DSO it leads for Doc there is already something that we proposed how to avoid them so uh yeah um any further comments okay okay great thanks yeah thank you um all right is uh I I guess we uh do not have time to discuss the remaining thing on the agenda we can save that for the first for the first um interim uh we I discussed with Marco um uh the interim schedule to coordinate with this with the core group we're going to keep the same Cadence that we had we just need to figure out when we want to restart should we have one in December or just wait until January to restart does anyone have a preference on that I see no preferences I'll just take it to the mailing list then so with that I guess we will call it a meeting thank you everybody have a good trip home thank you bye"
  },
  {
    "startTime": "01:04:02",
    "text": "it's a um you know"
  }
]
