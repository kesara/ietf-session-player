[
  {
    "startTime": "00:00:22",
    "text": "[Music] [Music] [Music] [Music] "
  },
  {
    "startTime": "00:04:23",
    "text": "it\u0027s the coming [Music] [Music] would you do the introductions yes I do that Oh shall we start okay okay is that so this is TCP mmm fucking of meeting TCP maintenance and my night station barking Lou please make sure you are in the right room and this is user load well and I think you already aware of this one but just in case by participating in the idea you agree to follow IETF process and policies and if you have any concerns about it please hello check is not well very carefree and you can find the same content on IETF website go beyond and we have no pay cuts do it okay could anyone point you\u0027re not peeking Thank you very and can anyone take care of Java okay thank you so much and this is just a usual reminder when you join in the meeting when you speak up the microphone please state your name so that\u0027s not nothing I can track your name and then when you submit your internet draft to this working group please make sure included eCPM in your draft name so that cheers can track the status of your draft okay so this is a today\u0027s agenda we are starting from working group status from chairs and then we have true working group items presentation first a you tuned we\u0027ll talk about rock draft update and after this Bob will talk about accurate issue and draft a plate and after this one we had two individual presentations Yoshi will talk about his new internet draft and then we have another individual presentation making TCP faster and cheaper application and this talk will be done by soy and you chilli and after this we have other draws two presentations TCP constrained "
  },
  {
    "startTime": "00:07:24",
    "text": "and no network and axure destructs is a working group i am in my working group but no this draft it\u0027s related to TCP so a key CPM chair and Arabic working group chair agreed to run working group rustical on both TCP M and a week working group so this Prudential patient gives some kind of heads up before this traffic go to working with rascal so this rough is not running or working rastko right now but beforehand we want to give you guys a heads up so if you are interested in this rough if you want to say something on this earth please read this off and the property of feedback on this rough that\u0027s why we have this presentation today any question to the agenda any comment questions okay moving on okay let\u0027s start from status of document and since rust ITF we have finished one draft and we have submitted alternative back of alternative back of draft alternative back of each intro to the idea investment and thanks so much for your cooperation and then we have six working with active active working group items and accurate EEG and draft um this drug has been updated recently and then this is one of the today\u0027s agenda and next one is a TCM rock drop this drop has been updated and then this is also one of the day\u0027s agenda and 795 is wrapped this draft has been updated unfortunately that was I cannot come to this meeting but we have received a slide from the AUSA\u0027s so we will talk about it on behalf of the authors and oh no no no yeah and then T CPM converter to draft and this nurse has been updated recently but according to the author it\u0027s a minor update and then eto draft there is no update software according to the author they are doing some ongoing experiment on this drug and restaurant needs generalized Asian and unfortunately this raft has been expired for now so we expect also to update traffic very soon that\u0027s the status of the working group item any question comment about octave documents okay maybe on okay so this is a slide for 793 be status so I will stick about it on behalf of the AUSA so thank you and two "
  },
  {
    "startTime": "00:10:25",
    "text": "weeks ago division ten has been submitted and this is updated related to tiff syrup and security consideration and then thanks for very good feedback from you change Joe Cory thank you so much and then so limiting remaining item leads updates some conformance checklist at the end of the document just like RFC 1122 that\u0027s a prong and this will be done in dry and okay go Jana Jana anger question on the previous slide you said on the active documents okay I just I was looking at this document do consider and I just realized yesterday that it\u0027s actually it\u0027s expired but it\u0027s not on this list so I want to ask what the okay well the choice of the status of the document was okay good question and so we have talked about this setup in the last ITF and then this drug has been expired and then one from maybe you know we can find some kind of editor but uh some editor food flavor will be editor it will be very you know tough job and we have to come exchange also email to other than that you have to hello leads to the conclusion so it needs stronger power so if someone want to brunt here for the editor they\u0027ll be very quick so agenda you want the frontier so I spoke with mark yesterday and he\u0027s cook singing and trying to convince him to get an update out okay if I it\u0027s a four page document you can finish this up but if ya know she has tried a lot sorry but for some reason no he doesn\u0027t respond to chairs so if you can help us that would be really great happy to do what okay so you want to be a editor you mean if you\u0027re necessary if necessary I don\u0027t think it\u0027s required at this moment okay I\u0027m happy to do okay excellent so seeing one of the one of the issues is that what\u0027s in the document has to reflect the working group consensus yes and this is what has what was hard to get in the past not making any future statements but if would be willing to talk to him and I\u0027m happy to present and I\u0027m happy to do the things necessary to move this job I think it\u0027s a useful duct we think that\u0027s you know ever yeah things are like things are yep me a cool event as far as I remember it was a while ago I think like there was a lot of back-and-forth awfulest with mark and I think we actually got to some kinda "
  },
  {
    "startTime": "00:13:26",
    "text": "greement so if you want to help we need to pick out those emails figure out what the agreement was and then we can involve you in yep I mean like Microsoft was like many involved in that sir right thanks Jenna okay and and there any question about it 793 based status um so I\u0027ve okay if this is in the middle so I hadn\u0027t finished it yet and so this is 793 is very important document for this working group as you know this is 793 B\u0027s so I could be more important for any idea or any time this is 793 piece again and I know this is very very wrong job 100 pages right but uh and then we already get some nice review from the people from time to time all right it\u0027s small subset of people but if it would be really good if we can get brown the rebels no I know this is long draught but if you can just read one section and the provide feedback that would be really really great and then I cannot say exact time schedule but I think this document is step by step approach to me the working group rastko so before we start running walking abreast Co we would like to make sure there is nothing red so if you have any concerns about the current uh status of the draft and if you think something should be done before the Viking rustical Y you have some serious concern some part of the draft please speak up please and and speak up or send a message on the mailing list that will be very helpful for us any comments some questions okay just if you have time please take a look at the draft and they provided a bit to us again this is important drop horse thank you so much any questions if not then it\u0027s ragtime hi everyone I\u0027m sure to give an update of the new rack draft my name is yu Chun and this is a work Jony with my colleague Neil Nandita and Priya at Google thanks like least so I think most people here FM always wrap just in case your first time you hear about it rock in the simple way is its is trying to detect loss efficiently while tolerating a small degree of reordering and very conceptually you can "
  },
  {
    "startTime": "00:16:27",
    "text": "think of every packet you send you on the timer with it and when the timer fires you we transmit the packet so how long do you arm the timer that\u0027s the tricky that the parlor rat does is that it uses the mostly recent match or the RTT and you can imagine every act comes back you update all the timers that\u0027s for all the pending packet that have been said but not acknowledged that\u0027s the very super high level offered and then so you don\u0027t need to count the number of the backs or anything up because it\u0027s all timer base and if you think I\u0027ll fast recovery this read you back rule it\u0027s similar to what Rack is doing which is okay when you get redo back line is sort of you get three RTT measurement and then you just send the add packets by the way and it\u0027s kind of like are you trying to repair that within a round-trip which is what Rack is trying to do except he waits for a not the timer is on so that it\u0027s the time now is an RTT plus a snow we are doing window to tolerate the reordering next slide please so in the last meeting the meant excursion is that there eats lack of design rationale of the rack reordering window because the autre is just as okay a quarter of a TT empirically tested seem to work fine but the concern is that well how do you detect the order and now how do you really handle reordered are you is are we going to make TCP so tolerant to reordering that now the network gears will start with auditing packets to help or send one packet over the moon and the other over your local area network so first thing first is that we need to define how we ordering can be detected because the previous wrap doesn\u0027t really talk about it he just sites uh you can implement some out ways and here is the algorithm in the new draft in a nutshell it\u0027s very simple if you want to detect me although you just look for out of order delivery right and with TCP sac base will you introduce a new state variable that you remember the highest sac sequence you have seen and now when you get another sack then you check with this higher sac sequence if it\u0027s below the sacs higher sacs sequence which we call the FAQ for ACK then this sequence has never been we transmitted and then this is clearly that some reordering has happened because the packets were delivered out of sequence order and then you simply remember that okay I have seen some reordering we don\u0027t measure the reordering de we simply remember this incident in a variable called RAC we Ord "
  },
  {
    "startTime": "00:19:28",
    "text": "in addition to that if the connections support T sac then you can further use that to detect reordering because if the packet has been spurious to me we transmitted the previous technique wouldn\u0027t work because you weren\u0027t sure if the sack is sacking the original one or the retransmitted sequence but a DISA clearly indicates that hey if you have retransmitted packet and also I got a de sac that\u0027s acting this sequence that means this retransmission is spurious and you wouldn\u0027t have done that the original one has been delivered and we start you can say okay that\u0027s also reordering so these are covered the case were you they say you\u0027re reordering window is small and then you spoolie fire a retransmission and so the sack sequence doesn\u0027t give you much a clear picture of whether this reordering or not but if the connection is support a sack you can detect that and the good news is that the major stacks or support a sack Windows iOS and Linux or support de sac um next slide please so now we can detect reordering we put this design rationale for rack wielding tolerance and first thing first is that today if you just reorder packets us however you like it you know our sending over and different paths between source and the sink then the actually caused a lot of problem despite if you whether you use rack or not first the biggest problem is on the whole stack that is a very high CPU cost because now the trro that receive receiver flow wouldn\u0027t work because typically the receiver all flow at the host week was receiving continuous sequence of packets of continuous sequence and on top of that now since you don\u0027t send these big jumbo frames to the receiver TCP stack and these are all out of order packet the TCP star requires you to send immediate act for every one of them so they say you send n packets they are all completely permutated and reordered then you end up sending an X instead of one in the typical case so this also adds pressure to the sender because now the number of a see need to process is a lot higher and in our test if you do this in and say you know they ask with extremely short et and very high penguins over 1 Gbps you see this very significant CPU increase so that\u0027s the "
  },
  {
    "startTime": "00:22:28",
    "text": "first problem with you know highly we ordered Network the other one is congestion control right if you send packet over very disjoint pass and most TCP congestion control assumes that the feedback you get is from the same bottleneck and in this case it is from two different bottlenecks you say so a TCP congestion control just won\u0027t work very well and and there a problem - server I\u0027m just saying that if you just run it without any change to congestion control on a highly distant past it won\u0027t work well and the last one is the last recovery you can always wait longer to tow it very high reordering if you know that the network I marry we order is their loss but the consequence is that you know if you do have packet loss then you will wait longer to recover the packets and it\u0027s always sort of a dilemma for how long do you set the reordering window you can never get the best we all being tolerant and the best loss recovery latency so with all that issues one rack is trying to do is to tolerate small degree of reordering and slightly diverse paths and the most common sin is the router parallelism that within a hub between the ingress and the egress poor there are multiple hubs to traverse this is not necessarily like a router router it could be a load balancer or even just you know any kind of intermediate node that trying to forward between A to B and the packet may Traverse slightly diverse paths and typically the traditional approach is you put a reordering buffer at the egress but a lot of time on it wielding buffer always cost memory and you have to a lot of logic in the know to deal with this so some sometimes people hate to do that I mean a lot of her designer hate to deal with DTP reordering and so they might trying to do something about it to a limited degree that you\u0027re trying to keep reordering to a certain extent but out of that day they would just let packet reorders the other common scene is the l2 retransmission for a wireless or you know the wireless trying to punch up in TCP packet they send it over and maybe three of them out of n because of channel noise couldn\u0027t get delivered so the link layer will retransmit on this three packets and if the receiver NIC or driver doesn\u0027t handle this reordering buffer well then they would try to upload the N minus three frames up to the TCP stack and there that\u0027s why we observe weilding but the sort of the thing is that this weilding are usually "
  },
  {
    "startTime": "00:25:29",
    "text": "very small in terms of the actual RTT and that\u0027s what Rack is saying okay we just need to wait a fraction of RTT but you know up to the maximun of the art the the pass that\u0027s the rack wielding window he cannot handle anything beyond that um next slide please so this is what\u0027s written in the traffic so people can take a look at what exactly do we put on the Monday of the reordering window Allison um initially when you start the rack we order in window the extra time beyond the RTT you want to wait before you you know we transmit a packet should be set to a fraction of the round-trip time and by round-trip time here I don\u0027t mean you know the past one or past two because I can not distinguish how many pass he actually travel it really just means okay the overall average round-trip time of this pass so you can imagine if the round trip times are highly disjoint and highly diverse between different paths then it won\u0027t work well but again as I said it\u0027s not designed to work well in those environments so initially we start with a small fraction in the track we just make it a quarter but this could be it\u0027s always bound to change as you know technology evolves and until the wielding odd has been observed using our wielding or detection we will continue to honor this classic Street you back rule for two reasons one is that because of you need to wait a little bit longer and that means if in Tennis Center or setting when the RTT is very small say 20 microsecond when there is not very there is no good ways today to have two months say five micro second timer with a lot of flows so simply counting still offer a great advantage in this this environment and the other key reason is that for compatibility reasons that firewalls who knows like intrusion detection system could still be using these rules and if just for safety we say will continue to honor this redo back and it\u0027s very simple to implement and it\u0027s every implementation has them anyways one simple way to do that is to in rack you can just set the wielding window to zero when you cease we do back I press code from co.labs I wonder whether you could say that initial reordering window I mean you\u0027ve said this is good to start with but maybe you "
  },
  {
    "startTime": "00:28:29",
    "text": "could suggest it should be three do pick the maximum of three duplex or or a certain fraction of the RT T\u0027s so that in the future when it is possible to time precisely you know you haven\u0027t stuck this stuff essentially you\u0027re losing a lot of the benefit of using something that\u0027s purely time-based if you say actually we we start by counting you know for when things get really a lot faster in the future see yeah that\u0027s a good point I think maybe we can add sort of no saying that you know in the case were you know time Americans friend is no longer an issue then the street you back rule may be overwritten over read it you know I was thinking like Artie T divided by six day you know something the max of Artie T V by by 16 and three new path has the okay yeah that work and the sir war is that we don\u0027t want to just have a star with a fraction and then you know statically set this window so we would recommend that the implementation should also use this act you know as a indicator of the spookiest retransmit that okay you\u0027re reordering window is too small so we have spirit retransmit are too pathetically increase the reordering window we don\u0027t Mende like exactly how you should adjust or adapt to this reorient window but just saying that you know you should take this feedback off okay you made it you made the window too small and then you should increase it and the last one is probably very important that the reordering window must have an upper bound and it should be set to one round trip and again this round table is intentionally made a bit vague of what exactly is the round trip or in our implementation what we use is the smooth round for time average but you can use the most recent one or a window max filter of the most recent RTT we don\u0027t put like exactly how you should do that Christoph Bosch I actually have a question about the boundary ordering window because like for example with you have layer to marry transmissions you could have a bigger reordering when I then the RTG itself then do you have any thoughts on that yeah so they say the the RTT is actually going to increase for those we transmitted packets right assume that you measure the those packets the runt of town of those sort of retransmitted packets and it could be a lot longer than the say propagation delay and in this case I think if you "
  },
  {
    "startTime": "00:31:29",
    "text": "use some kind like our smooth average which take account of all these packets then you should still work to certain extent because the smooth tongue the SRT T is always sort of biased towards the the longer same post yeah yeah but I think in this case we just want to keep it sort of loose so that you know the implementations can sort of improvised based on the particular situations he needs to fix next likely so with all that said how do we really compute the reordering window this is the exact formula we use in our Linux implementation so our style is do we detect we\u0027re ordering or not if we have a simply ordering and we\u0027re already in loss recovery since we already lost recovery that means we feel like this in this situation we are going to optimize to speed the recovery we believe that we have made the right decision this is a loss not reordering so we\u0027re going to set the wielding widow to zero and really fire up the retransmissions very quickly other than that we\u0027ll use again like I said the three you back rule which is R active batch registry so if more than three packets often act out of order that you are going to launch the loss recovery process to repair the packets and if we have seen we are doing so none of that now the those cases match and we have similar auditing we are going to set the reloading window to a quarter of the minority and we have this multiplier call reordering window increase which we linearly increase and this wielding window increased a variable will be adjusted based on have you seen these acts in the last round trip or not because every round trip you have seen a detail you are going to increase this multiplier yeah yes but Google this is a clarifying comment and it\u0027s not a complaint after slides but um I I just recently got some fairly decent data that kind of indicates that maybe min RTT over 8 yeah I\u0027d be a better starting multiplier especially since you\u0027re doing an adaptive back off and I\u0027ll be presenting those at map RG and they should already uploaded off online if you want to take a look yeah so I think three meetings ago we actually had ran an experiment to compare a corner on an eight we don\u0027t really see any difference for TCP data and again I think it\u0027s fine I\u0027m fine changing it to a II just we don\u0027t see any data so you can say one way or the other and we specifically leave out in "
  },
  {
    "startTime": "00:34:30",
    "text": "the like Rath does not meant that you had to be a quarter ah TT so that you know the implementation can always choose the best value that you they believe is right so and then the last line is simply the reordering window is unconditionally bounded to the SRT T value Michael Jackson so just a suggestion on replace for by a named constant like YouTube Thresh and say you may say to set it to four or whatever then it\u0027s clear why what this it\u0027s a variable okay yeah sure can do that it\u0027s a good point on next slide please okay so this I\u0027ve talked about all the traps I pay and links 4.18 today fully implement what I just talked about in the draft and it\u0027s on by default so the odhh rc6 675 the sack based recovery which family used to pack special is actually now a disabled so the latest linux as you use rock as the sort of the one and only fast recovery mechanism and overall we have reduced labor heuristic in linux about loss recovery from ten to two it\u0027s rocky or PMF RTO on an F RTO includes see the basic RTO of course and the over the algorithm are development in an implementation as has been concluded we don\u0027t plan any major development work maybe bug fixes and so I think that the at least we have an indentation fully implement the draft I believe that Praveen told me yesterday that Microsoft is still trying to catch up it\u0027s implementing the - do two draft but they are going to sort of implement that zero for very soon and that\u0027s that\u0027s it that\u0027s my I talked you know any questions comments general this perhaps a question for the chairs is this very poor Losco I think this law has been updated just tweaked so all right yes then and also problem tried to implement this draft and then she might come back with some feedback so maybe we can wait a little bit but I think this Russell is now getting good shape so it\u0027s I think working with Roscoe is "
  },
  {
    "startTime": "00:37:32",
    "text": "close but I would like to wait a little bit more okay okay sounds reasonable it\u0027s a secretary call for implementers to look at this document implemented arm and provide feedback thank you thank you [Music] this is high as it goes excuse me don\u0027t do it okay right this is accurate ecn just recently updated this draft can you move on Thanks a quick recap explicit congestion notification in the IP header and that table there has feedback defined in RFC 3168 for TCP it\u0027s not only intended for TCP or EC n is not only infinite for TTB but it was defined in the at the same time as IP and the problems with that feedback were that you could only get one feedback the round-trip time and then that was because the receiver repeated this echo can just an experience flag for a liability until it got a acknowledgement called congestion window reduced from the other end that so did TCP at the time when it had one with congestion response per RT which its standard TCP still does but there are other forms of TCP around so where this is all about updating the feedback so we get all the feedback information which is reflected in the title which says the problem was congestion exists existence not extent and if you move to the next slide the solution is congestion extent not just existence right so accuracy any is a change to the TCP wire protocol but current proposal is it repeats account of C packets or the data receiver repeats account of the see packets for that half connection in this counter called ace that you see there in green in the main TCP header which is made up of three flags overloads the use of three flags that we use during the and shake but it also adds an optional option which counts the "
  },
  {
    "startTime": "00:40:34",
    "text": "seee bytes and effectively what\u0027s happening here is there\u0027s counters for all the bytes of all the different code points on the receiver this counters for the mama sender the protocol is essentially sending the least significant bits of those counters across to synchronize the two counters with a round-trip time and a bit of delay right so sort of very simple conceptually the reason for the duplication of the fields is that if the option is stripped you\u0027ve still got a sufficiently useful protocol in the main header with the ace field which already burns the headers to do the negotiation and though sort of the bits to do the negotiation and the overriding requirement if you like of a number of use cases for this is to try to reduce um queuing delay by having more information more feedback information during a round-trip time and there you know there\u0027s existent case of ones that give you 500 microseconds can\u0027t delay over the public Internet instead of current state of the art which is 5 to 15 milliseconds something like that so the change is in the last cycle IETF cycle I\u0027m now gonna go through and the main one has been in response to a request from Michael Schaff to give justification for why we\u0027ve designed the protocol like we have you know why we\u0027ve used the bits we have and particularly why we\u0027ve used the head of bits so there\u0027s three slides on this that reflect three new sections in a new appendix Appendix B but in the head of their and the first the first subsection talks about the justification for the using them on the sin and the primary one is that this is how I received 3168 ecn did its feedback using two of those bits the ECE and the CW are and the idea is to be able to fall back with in other words it\u0027s backwards compatible so that a server uses the latest fair into feedback that it recognizes so if the server doesn\u0027t understand ecn it\u0027s an old server it will see it won\u0027t even look at those flags whatever they are it will just be a no ezn server and then the response it gives in the cynic will show the client that it doesn\u0027t understand them if it\u0027s an easier 3168 ACN server it will look at the last two bits which do it the easy end capability negotiation it one look at the third one "
  },
  {
    "startTime": "00:43:34",
    "text": "we\u0027re tested this is how they work and so it will then respond as if it\u0027s an ECCN server and the client will fall back from echo easy entry CN and if it\u0027s a full accurate ecn server it will look at all three bits and and so you\u0027ve got the back of malakut ability and three bits the need for the third bit or why why we use a third bit other than this back of compatibility thing firstly it was already allocated to the easier nonce which is now historic through a process we went through in here in this working group and by combining that flag with the other flags both in the handshake and during the counting phase once the connections established you\u0027re actually getting eight states whereas if you use that flag as a binary flag you only get two states so you know it makes sense to not burn somewhere else and use that flag because you\u0027re making efficient use of something that\u0027s all being used around ecn and you\u0027re not burning far too much date in a very sparsely or headed with very little space the original code point that the nonce used we don\u0027t use in accuracy n there there are sort of I got an email back from Anna who did the measurement studies who was looking at the data to tell us tell me how many servers there were but sorry I haven\u0027t read it because I was dealing with another email but it was something like five out of twenty six million servers responded with that nonce flag well either the server responded with it or something on the path changed it and and so it\u0027s sort of in the noise but they do still exist so we figure I\u0027m not sure working a bit longer will help if it is just random stuff because you just get more random stuff but very very fast and it could also just be a broken an implementation in a particular system has got particular front-end and you\u0027re never going to get rid of this it\u0027s just going to exist as a small percentage yep yep so just to ram home me the point I made earlier if instead of using that third third bit we\u0027d have done some other thing like use a TCP option to do this negotiation and reserve that for a bit for some future protocol as I said it would only be able to use that bit separately from the other two bits so you wouldn\u0027t have got that benefit of "
  },
  {
    "startTime": "00:46:34",
    "text": "the eight extra states or the eight states and also would have had to put an option on a syn we have avoided that obviously there\u0027s very little space for options on a syn and you\u0027ve got the right reliability problem of losing them sometimes because of Miller boxes and finally would have had a protocol which had all this fought fall back in the oldc n in the header and what about an option we\u0027ll have to check for all the inconsistencies between things that might be changing one differently to the others who had a more complicated negotiation so overall it was just much simpler much more efficient to put the third use that third bit for the negotiation given 3168 had already started using bits in the header it\u0027s it\u0027s unorthodox to use bits in the header for this you know tcp options would have been more orthodox but it sort of makes sense I think this was why Michael was asking what was the rationale behind this and I don\u0027t actually know I don\u0027t know where their own does I was involved in 3168 standardization but I don\u0027t know the rationale for why things are done in the header rather than those options I mean I also want to say that like there was a proposal to use an option a long time ago and I think the working group agreed to not go for that that\u0027s it yep okay I\u0027ll move on so the second section of this appendix explains why we use these three bits in the syn/ack these same three bits I was just talking about and this has been since draft Oh for we\u0027re now on Oh seven actually oh wait if you count my local copy the the idea here that this table shows the sin from A to B always set as one man one we\u0027re assuming the accurate Sen client starts that off then all the possible cases or late cases of how those flags might be sent back and we\u0027re ended up since draft oh four using four of the states to reflect back what was in the IP header I just finished explaining the table yeah the the second block of states their servers that do not support accuracy and this fallback mechanism I was talking about earlier that\u0027s that\u0027s how the client recognizes those and the last state is a broken state that we still found there\u0027s a reasonable number of these about where the server reflects back whatever the client says in the reserved flags and you know that that\u0027s a broken implementation that\u0027s been "
  },
  {
    "startTime": "00:49:34",
    "text": "around for some time and there\u0027s less and less of them but you know they\u0027re still we\u0027re okay so going to a little more detail on why we\u0027ve used all four of those states at the top there because you know in earlier versions of accuracy n we didn\u0027t use those two shown in red to feedback EC T 1 and E C 0 we only had a state to feedback whether there was not ec n or whether there was another state to feedback whether there was congestion experienced on the scene and this was due to finding there was quite a bit of bleaching which is why this slows got what blobs all over it bleaching means wiping of the ECT code point in packets usually going into the internet and we believe this is a sign of bugged diffserv wiping which is wiping the e CN field as well because this stuff thinks it\u0027s a all still part of the toss bite because people who write this code must be more than 50 years old right and so all their reading books that are more than 50 are off so we\u0027ve had to feed back the lease value of the ecn field in the IP header coming in so the server feeds that back in the TCP header and then similarly a number to the little sort of white number two we do the same thing on the ACK to feed back what came on the sin x IP header in the TCP header going back just to check both ways there\u0027s not this bleaching right because if there is this bleaching it\u0027s quite serious it you\u0027re sending ECN you think the other ends negotiated with you at the TCP layer and then you start using ECM but it\u0027s getting bleached and and then the other end doesn\u0027t hear any congestion experienced that might have happened before it was bleached for instance in your a case would be a mobile broadband router in your home then going over a mobile network that bleaches it and you\u0027re getting congestion in your access link up to that so we thought it\u0027s very important to make sure that both ends can detect this bleaching and then turn off ECM right so that consumes the last two combinations of all possible eight states in the syn ACK and again like I was asking do we have to do that white what\u0027s the reason for doing that so we\u0027ve written that in the appendix I think Michaels said well he certainly said he\u0027s happy with the appendix I "
  },
  {
    "startTime": "00:52:34",
    "text": "don\u0027t know whether he\u0027s happy with us doing it but the other point about this is that that state in column B marked nonce and the other one not broken although we\u0027ve used up all eight states the nonce is potentially usable in the future if we want to have a variant of this protocol and the broken state might eventually be usable as well so we haven\u0027t really used up all late it\u0027s it\u0027s crappy middle boxes that have used up two of the eight well a curvy middle boxes or or an old standard that never got used and also in old experimentals RFC so they may become available later next slide and that leads well into the this slide which is about what space there is for the future and this was what Michael was particularly concerned about if we\u0027re introducing a new protocol and then we find it\u0027s an experimental protocol so if we find that it doesn\u0027t work or we need to change it slightly how do we do a variant of it when we\u0027ve run out of space for doing any statement that it\u0027s a variant right you know only any version negotiation so we\u0027ve written down what what space you\u0027ve got you\u0027ve got those two code points I just mentioned on the syn/ack the the one that was used by the nonce and the broken one I think the nonce one would be usable pretty much now given there\u0027s such such a small amount of it about the other one will take longer then there are five unused code points on the final act of the three-way hand check this this part two of the previous one that can\u0027t really be used or I\u0027m sorry I\u0027ll finish the point there are also seven unused code points because there\u0027s a the negotiation continues on the first day tobacco or at least the checking continues so there are seven unused there but by the time you\u0027re getting to the last a core the first day to packet you\u0027re not really negotiating anymore you\u0027re just declaring you get you don\u0027t got any more cycles or phases of the handshake to to agree both ends what you\u0027re doing you\u0027re just saying what you are so you get a limited ability to do version negotiation apart from those first two code points on the cynic and particularly with TFO if you know it\u0027s far too late to have done anything if you\u0027ve already started sending data or it becomes very complicated to unwind it all right but you know with we\u0027ve stated what the states are there in the I\u0027ve seen out also the draft now and so in future if someone wants to make a variant it\u0027s clear what they can use then that first main bullet bullet is "
  },
  {
    "startTime": "00:55:35",
    "text": "about variants of acura ECA if in the other version of the perrolli parallel universities in the future he see an accurate ECM and everything doesn\u0027t come to anything how can you reuse these bits we\u0027ve got five out of the eight code points on the scene are still unused could mean something else are listed there they would preclude any use of ecn at the same time certainly any fullback use you might go to sort that out with us tcp option or something and all the weight of the code points in response to that are available actually that sentence doesn\u0027t makes it since all eight except one that means seven doesn\u0027t it yeah except yeah so six of them except the zero zero zero which means I don\u0027t understand ACN at all and reflection right and then of course we\u0027ve got three more TCP flags as well in the reserved area okay so that\u0027s I think satisfied Michael and hopefully everyone else I\u0027ll pause in case you know what\u0027s that come up for a question Jen I younger so given that we have Gordon the in the internet that is fifty years old and still treats you know ACN bits as part of the toss byte what guarantee do we have that those two code points will come back to us but can you explain what you got back um well what I\u0027m asking is I mean I certainly don\u0027t I don\u0027t know what the deployment thought what what the plan will look like in the future but I I\u0027m not convinced that we\u0027re gonna get the broken bits back what is suggesting is that you I think I don\u0027ts ones are already in the noise I mean they\u0027re sure yeah all right so we got one right so I suppose it\u0027ll be useful if he are specifying these two equipments as potentially coming back as what should happen to bring them back in this in the spec that\u0027s what I\u0027m asking for whether you write an R say so hi Brian Trammell um done some measurement on this it\u0027s not like a really good longitudinal study but we\u0027ve done it at like several points in time so along the time that we\u0027ve seen ECN uptake going up and we started seeing seee markings the things that break ecn seem to be correlated with the things that break the SCP so there\u0027s a lot of toss then I "
  },
  {
    "startTime": "00:58:36",
    "text": "said I\u0027m a bit he\u0027s only the IP bits which bits are you talking about I thought you\u0027re talking about that the bitch in the IP header not the bitch that he\u0027s beer oh I got confused by yochelson sorry I was talking about the bits that that TCP and the TCP header these two the two code points that it doesn\u0027t want us in on yeah the the nonce the notes on the broken one you could even so if you want to use those bits you have to implement additional safety measures to make sure that like you actually understand each other right but that\u0027s like a different protocol I don\u0027t think we need to think about it right now you chew on chain here I have recently explored a lot of comments about this proposal so but to me is evaluating this proposal with compare that with the DCT CP e CN which today if it cannot work for Y area because DCT CPEC every course you blindly trust the other and will do that oh you\u0027re gonna slide on this next okay so this is a poor attempt to summarize all the discussion we\u0027ve been having that you don\u0027t just mentioned and I think the core of it is generic receive offload and the the problem that you churn was about to describe is that DCT CP has has this sum step function in the network and it generally gives you runs of ce4 quite a long two of congesting experience for quite a long time and then runs of nothing for quite a long time it sort of toggles on off and so that the the way data center TCP does its feedback it has a state machine on each end rather than counters that says and and every time there\u0027s a transition from a run of one type of you know the marking on or the marking off it changes the flag in the TCP header to the other and tells the other end so you\u0027re you\u0027re trying to keep two state machines in in sync by parsing the transitions between them and the RFC 7560 which was a requirements document for accurate Sen had a appendix that showed that because this is a long a lot of this can be on pure acts which you can never know whether they\u0027re lost you\u0027re trying to keep two state machines in sync with an unreliable channel between them that you "
  },
  {
    "startTime": "01:01:37",
    "text": "never know whether the transitions have been missed and so you can you can get the state machines out of sync because of a your act loss and they do eventually get back into sync but you can you you can misunderstand the amount of congestion in the meantime so that was one of the motivations for designing a TC n however you Chung has been pointing out that with generic receive offload Hardware with these long runs of CE Marking with data center TCP you don\u0027t get a state transition because there\u0027s a long run of it and so the gyro Hardware sees this long run and it will allow it all to coalesce and then at the end of the run when C he stops it will pass it up to the network or you know once the cache is full it will pass it up where\u0027s with this counter every packet is one more see mark so the counter changes so it it flushes the ero cache every time every packet right so you Cheung wanted to use DC TCP feedback in the head of lights but otherwise use accuracy in the same user is all the negotiation the same but or at least have the option of using DC TCP feedback and we\u0027ve been discussing this off list as we being autonomy authors and Neil and we haven\u0027t quite come to a conclusion yet the the arrows show where we\u0027ve got to we\u0027ve got various suggestions to resolve a dilemma one I want I sent this morning to that small group of people and I it it needs quite a bit of thinking about because you know it I don\u0027t want to really think about it during the IETF because it needs really working it all out whether what implications are and otherwise if if we can\u0027t find a solution it\u0027s because I really don\u0027t like the idea of having two versions of a protocol depending on what sort of pattern of the package you\u0027ve got in the network you know it just seems wrong right so we really do need to try and solve this problem with one protocol rather than two but otherwise we came up with Mia proposed these three ways to accommodate the problem of GR Oh hardware one would be to parallel drafts which is the one that we all prefer out of out of three but none of them are ideal you know it\u0027s yet the the other two would be to have both mechanisms in the one draft and because it\u0027s an experimental thing we can we can try them both out using these initial counter values to find to find out which one you\u0027re using and the other one would be t2 users "
  },
  {
    "startTime": "01:04:37",
    "text": "DC TCP mechanism within a curry TN and get rid of the counters but certainly we don\u0027t want to do that because one of the that was one of the main goals of the protocol was to get away from that you know so we are all committed to finding a resolution but we\u0027re in progress you chunk did you want to add anything to that yeah thanks that\u0027s a great summary um and I just want to add sort of my point of view is that it\u0027s always oh if I need to implement something or add more complexity to a stack its what\u0027s the benefit and very practically and and I think actually Zn would despite the GR o issue with endo under heavy act losses if far more accurate than DC TCP but the question I don\u0027t know is how critical is it is it to handle heavy a Colossus and when I think of DC TCP it\u0027s like it\u0027s a congestion control feedback that you know at least Microsoft Linux and I believe FreeBSD all have so is rather quick transition if we just need to use options or headers to negotiate that and it does not have GR o issue at least in the death and her right now so this is sort of I I\u0027m committed to do more kind of data comparison work you know if I can get an implementation of the ACE or if I can come on my own and you know that you know this this look at some data and you know so we can get a better sense of the trade-offs yeah if I just before Corey comes to the mic if I can just explain that normally it\u0027d be fine to just do this by experimentation and you know just bring out a new version otherwise but because we\u0027re so limited on space and they\u0027re so limited ability to do versioning of the protocol where we\u0027re sort of having to do sort of either private network studies or their studies or something to try and work out a solution based on what we think is going to be the problem because we can\u0027t really do it on the internet that\u0027s right that\u0027s why I because I\u0027m burned badly because of the middleboxes issue on open deployment anything that has the least middle box concerns always looks very appealing but unbiased yeah but I\u0027ll use you cannot test every single necro and then you know or you know make the protocol so complicated that it\u0027s just very hard to to implement and deployed but you are not suggesting "
  },
  {
    "startTime": "01:07:37",
    "text": "having to version one is one you prefer the otherwise oh so right now I have a slight preference of the two pair of draft because that would just make each of the proposals simpler instead of like trying to really glue the two together but right now I really have very good data to make you know to justify my preference it\u0027s just I\u0027m always weighing towards simplicity and and you know middle box friendly I think some people here may not like me be you know a favoring me no boss friendly there well as they say middle boxes are for and they should fix it but the truth is they don\u0027t oh yeah Gouri first I think I have to confess I\u0027m no confused and I we spent a lot of time working on the Ocoee cien proposal and understanding it and we data it\u0027s NT to be appeared in the meantime I really feel very uncomfortable about the idea of having two different versions of this floating around that word ender trying to build new mechanisms on top of so I don\u0027t know how we get out of this but I I\u0027m interested in the discussion and I think it would be good to make sure that everybody else who was interested previously understands that discussion as we go forward but just to maybe something like he\u0027s on the slide by didn\u0027t radio out but the idea would be that you change version would have us also have the accuracy an option on the scene which would tell you that it was a different version than the other one yeah yeah still have two different protocol machines going through the network dealing of middleboxes in two different ways one of which was trying to work in a controlled constrained environment one of which was targeting something slightly different both of which will operate really across the internet in reality when we get there another point but your chones point is that he think he wants his to also work on the right area as well you know it\u0027s not just for data centers but doesn\u0027t matter whether he wants if that will happen I think okay any further otherwise our of nails clip Neal card welcome well I was wondering if one if someone could comment on a possible approach of waiting until we have a specific congestion control proposal that needs this that is far enough along that it has performance results demonstrating that this is definitely needed before we "
  },
  {
    "startTime": "01:10:38",
    "text": "sort of try to finalize this proposal I guess sort of going along with Yoochun\u0027s comment I have a similar concern about making sure that we if we\u0027re gonna undertake something with this level of complexity and possible metal box issues that we are pretty sure that there\u0027s a congestion control that really needs it before we go too far down the road and and also you know if we if we deploy accurate ecn and then three years later in the development of l4s we realized oh actually we needed something slightly different for all for us that would be ashamed to so wondering if maybe we should just have this proceed in parallel with l4s development or if that\u0027s not a good solution so I mean obviously DC TCP already made it video you\u0027re thinking something on the internet that needs it yeah miracle even so for me I think the best use case at the moment is actually easy n plus plus and like in deploying this together is an incentive to actually apply accurate easy n and I think it makes much more sense to try to get accurate easy and employed now because then you can actually eventually use your new conditional troll on the internet because accurately CNX requires the other end to change right while your congestion control is usually just sit aside so you\u0027d first need the feedback and then you can change your congestion control so it\u0027s a deployment issue and if we actually have a chance to get some deployment out there right now that better than nothing okay so we have chickens and eggs I was going back to the diploid 9yo night oh my Mane yes so going back I said my name is - see they will I work at Inter but going back to the deployment issue do you see accurate EC and being more robust than DC TCP or is there a comparison of robustness between the two you mean robust middleboxes or loss or okay if it\u0027s lost in the data center then a curation would be more robust the if there isn\u0027t well actually I wanted to I wanted to add something to what you Chan said that if you\u0027re getting some loss but not not a lot if say you get a long run of stretcher coming back saying the state machine hasn\u0027t changed you don\u0027t actually know whether there was one in the middle of that stretch at that did change cuz it may have got lost and then you wouldn\u0027t know about it you said I "
  },
  {
    "startTime": "01:13:38",
    "text": "mean if it\u0027s not just whether there\u0027s loss it\u0027s because you don\u0027t know about loss and you\u0027re using delay backs and stretch acts so you don\u0027t actually know in other words it\u0027s a non-deterministic protocol because you can\u0027t tell whether there was a message in the middle that changed things so so yeah accurate ecn is more robust generally but it has this gr OS you know certain is gr oh that interesting like does it buy you any performance improvement that it must be solved well I can only go I can believe what you Chang says and no reason not to believing of course but and maybe you want to you can chain for fast and networks like you know we\u0027re talking about say over 1 Gbps geo is definitely critical to have for things like you know 10 megabits per second how links probably not but the trend is that the Penguins is going up very very quickly right and so I assume that you all will become more and more important until there is a better solution like basically the offloading mechanism is getting becoming more more critical it might be anything and and I would add that it is likely that you know if his protocol is deployed and it becomes used the G ro Hardware will be adapted to make it efficient but it\u0027s just that again chicken and egg problem of what you doing that in the meantime do you just have to throw server resources at the thing because you cannot use Hardware optimization you know it\u0027s about deployment you know not just within the data center but outside or across the entire network because in my understanding all that traffic that you have on the wire would be tunnelled and therefore you would need a middle box not just to look at the outer header but outer and inner header to be able to do accurate ECN is that something that\u0027s a concern for you it is concerned but it\u0027s not a concern for a crazy sandwich and then to any protocol but that\u0027s concerned with the marking marking the outer tunnel and there\u0027s there\u0027s a whole lot of working that TSV working group that I\u0027m doing actually on on you know that they\u0027ve been specification for how ACN is dealt with by tunnel decapsulation since 2001 and they\u0027re generally deployed but you know there\u0027s those cases where they\u0027re not and so "
  },
  {
    "startTime": "01:16:38",
    "text": "yeah that\u0027s a that\u0027s a that\u0027s a different question but it\u0027s it\u0027s it\u0027s not an end to any question because then to end you\u0027re out of the tunnels again so one thing I just wanted to discuss a little more would be just sort of thinking out loud about this jirô issue so the one possible strategy would be to say if you want to use a corona say on you can you can use software G ro which is definitely you know it\u0027s something we use at Google and I\u0027m not sure you know industry-wide how much people are you relying on hardware for this versus software but we could just say you know if you want the latest and greatest stuff then you need use software gyro which is can presumably be I\u0027m imagining we could tweak it to be aware of the accuracy and counting scheme and basically continue aggregation and just have a simple state machine to sort of make sure that it doesn\u0027t lose the information that\u0027s being fed back from the other side but we\u0027ll still still continuing to do aggregation and then when it\u0027s got a full sized aggregate it can pass it up the stack with whatever I cure DCM bits attached to make sure that the full signal is passed on with aggregation that would be one strategy and now that should be very simple because you just begin to run a counter in the software stack and post possibly result to that counter including all the wraps so great back to Neela how easy is it to look at that and tell us what is feasible after thinking through after bigger than Ike because that sounds a very interesting thing to look at and understand I\u0027m definitely not the expert on the GRL code in the Linux stack I think Eric Doom is a is but I think it would be it\u0027s a function that does the aggregation is fairly small and simple I think someone could do a quick experiment to see you know what what see how feasible it would it be you know how complicated and it would be to get it to be high-performance because it\u0027s definitely a very hot cook path and you have to look at the cash effects of you know that whatever extra state was was carried along but as a bob said that my intuition says you could probably do it pretty efficiently because it\u0027s just sort of addition and some number of extra bytes for this date yeah okay should we move on to that last slide which is next steps so attempt to resolve the gyro issue you can see that\u0027s working progress I think it\u0027s we\u0027re not at the stage yet "
  },
  {
    "startTime": "01:19:38",
    "text": "where we have to choose between those three options I think we\u0027re still working out whether zero has a solution I\u0027m having to do two protocols I realize we haven\u0027t acknowledged each other\u0027s contributions in the draft which we will do and I checked the recent contributions from Michael and pavane they\u0027re already acknowledged from previous countries over so thanks very much there\u0027s a next step which actually I did this morning to address the outstanding issues from Michael but then Michael\u0027s raised a further point which I I guess I need to bring up here unless Michael\u0027s going to do on my college ever or whatever anyway of channel for him Michael is concerned that because this is a change to the wire protocol the any passive monitoring going on of ACN if it\u0027s not looking at the start of the flow then we\u0027re changing the meaning of the bits in the flow and that passive monitoring may be connected to systems that are doing I don\u0027t know load balancing whatever and they\u0027re our may confuse those peasant monitoring devices now I responded on the list that I don\u0027t think we can say that\u0027s a problem for a protocol specification to say that you can\u0027t change the wire protocol ever because there might be passive monitoring devices that don\u0027t work very well that aren\u0027t looking at the start of the flow to see what what what this stuff means and certainly talking to people who do passive monitoring not particularly vcn they always look at this in anyway you know that that\u0027s part of what you do to measure the round-trip time and so on so personally I don\u0027t think it\u0027s a concern Michaels I said that\u0027s Mike Lee came back and said he still stands by what he says and that\u0027s the state it\u0027s got to have any evidence that anyone other than me has written software that does and of course it does it doesn\u0027t right thing and it\u0027s completely perfect but but I\u0027m not sure I\u0027m not sure I\u0027m not sure you know Pat Michaels point is they might be good I mean it would be I would be happier I feel less lonely if I knew that other people are doing it but yeah it just seems like kind of a approaching doom I\u0027m hearing like oh my word that\u0027s same unlikely can there\u0027s not much there\u0027s much seem ok ok so Brian Brian if your software isn\u0027t a problem because it\u0027s already broken so we\u0027re not breaking like if you count how if you counter often those bits appear that\u0027s "
  },
  {
    "startTime": "01:22:39",
    "text": "like useless information and the information will change no but it\u0027s still useless so I think actually passive monitoring would be easier was equities in but like what I would put in the draft is a recommendation to like is it a recommendation a warning to say that this is inter and you should do many more monitoring right that\u0027s what I would like yeah and we have a section I was thinking we should do that this morning we have a section on recommendations for middleboxes and so on and that would be where we put it denying that I don\u0027t want to beat this done but what what recommendation are we giving what person ordering to be aware that the protocol might change and you know tip to actually look at the sin and see what\u0027s been negotiated before you measure the packet and therefore it might change so they should basically keep up with the drafts yeah the recommendation is to read the draft if you\u0027re going to be passive monitoring you\u0027ve got to read the drafts to know that there\u0027s a recommendation in it I mean there is very little that a past monitoring device could do in this situation that would be a problem in a reaction to this signal that would be a problem for Indian connectivity where that middle box is already causing a problem for Indian connectivity I mean I might as a change in the I made this point to Michael if if this thing is running some critical system it\u0027s already broken and it\u0027s not really checking the lights at all but it\u0027s already broken and it\u0027s already broken in a way but you probably notice and you fixed it so you don\u0027t really need the recommendation you shouldn\u0027t need to read the draft right I mean yeah if you reference works for the recommendation the draft be to read the draft and slowly circular you just crash the world but I think that actually what should appear there is like you know a paragraph or two you showing thoughts on white like exactly that reply it\u0027s like why this is not a problem right like that I think would be useful sorry that is you to look at when there\u0027s no actually I didn\u0027t channel Michael correctly because Michael solution is we shouldn\u0027t change the wire protocol we should change our ACN so that it doesn\u0027t change the wire protocol can you minute my silence at the my home page okay yeah "
  },
  {
    "startTime": "01:25:42",
    "text": "so gari first and I\u0027m trying to the minutes in a second and but this whole idea of monitoring in the network you can you can look at this stuff in the network if you want to look to see if accurate ecn is being used and that tells you it and it tells you that this feedback going on etc I\u0027m not sure we should tell people not to do this if you weren\u0027t deploying a network that relies on ACN you should be able to do these track what\u0027s going on here the the issue I\u0027ve seen appearing in some EU discussion with operators was should people look at this signalling to watch engage what the net was broken so there\u0027s a difference between Cantonese en Mart\u0027s rockeo TCN and the whole thing with where the machinery works and that I think is a more important recommendation please don\u0027t think an easier mark maseeh e means your networks broken right and that\u0027s that\u0027s the thing you shouldn\u0027t start assuming so the feedback of this does not signal a problem not change the way of protocol not suggesting not to change it or not suggesting okay sorry sorry Michael yeah I just wanted to say I don\u0027t but my name\u0027s Tim Shepherd I don\u0027t think we can if it is the case that we can\u0027t change the semantics of the bits in protocol headers because passive apparently Michael says with he didn\u0027t say that okay but right but I just I should we can\u0027t those if you\u0027re doing passive monitoring you have to keep up with what people are doing and a deal with it you can\u0027t I don\u0027t think we should change what we do to try to not I don\u0027t think we should change what we\u0027re trying to do here or make any decisions because it might make it more difficult for systems that are doing passive monitoring to keep working you should just move on and the best thing we can do is just document what we\u0027re doing and be completely transparent about what the new thing is by having published internet drafts in RFC\u0027s and that\u0027s it meuk you live in so I think it actually would not even break passive monitoring but I don\u0027t think that\u0027s worth explaining in the traffic but so if you do it correctly not the way Brian implemented you would actually look you would actually look at like when does a bit change and then figure out that there must be must have been congestion so if you actually implement that then every time this bit change there\u0027s still this congestion you get like more congestion feedback because it\u0027s accurate easy and gives you more congestion feedback and you still don\u0027t get the the real accurate you see "
  },
  {
    "startTime": "01:28:43",
    "text": "encounter but it still it\u0027s a single of congestion so it would like if you if you do it it would actually work but generally anger again a small terminology net passive monitoring has a lot of connotations which we might want to avoid not that applies here but meaning called passive measurements we\u0027ve been talking about passive monitoring all this while and we talked about allowing it and encouraging it so I should be careful to clarify exactly what we\u0027re talking about it can be passive and pervasive okay so I think wait working our way towards the last below on this slide I\u0027m not even gonna ask about that because you know we\u0027ve always got to resolve this euro issue and things first so I think we end there I\u0027ve just got a couple of things to add one related to ACN plus plus which apologies for letting it expire we just ran out of time and we\u0027ve got a meeting later in the week to edit it and get it sorted out that\u0027s related to our Croatia and so I thought I\u0027d I\u0027d say it now because we\u0027re recommending in the accuracy and draft but it goes together with ASEAN plus plus in an implementation and the other one is that I\u0027ve got a presentation on the implications on rack on the of rack on the on links and reordering in links in TS vwg so they\u0027re you know it\u0027s a bit of a sort of heads up on that in TS vwg on Thursday thank you okay so this is your C and say I\u0027m trying to talk about my simple draft the title is disabling pulse when other protections up available this is my individual draft okay also let me start from the background of this idea so as we already know RFC 73 23 requires putting time stamp in all segments I mean all segments and then time stamp option consume tend to Train bite in optional space and then option space ranks is just limited to 40 bite that means if time stamp option has been negotiated time stamp option consume 25 to 30 percent of the entire option space so it\u0027s groups like it\u0027s kind of overhead to me and then in the "
  },
  {
    "startTime": "01:31:45",
    "text": "first place why we need to put time stamp in all segments and basically time stamp has been used for two purpose mainly one is round-trip time measurement but some research indicates that so we don\u0027t have to measure round-trip time with every single segment we just need several segments around return it\u0027s good enough to get nice RTD measurement however in case of a pulse in order to provide the protections we need to put time stamp in every single packet so that\u0027s it spouses that requires all segments with tungsten so in other word if we have protection other than pulse and then we don\u0027t need to put time stamp in all segments so that we can utilize option space for other purposes saying it can increase CCP\u0027s extensibility feasibility a lot more that\u0027s the basic idea of this talk move to the next right okay so as I said a can provide some kind of protection and then what\u0027s Campos protect so this it has tried to illustrate how the pulse protection works oh I forgot to raise the point let\u0027s say we have current and the point here and here and then establish TCP connection and they extend TCP packet this Brown rectangle indicate the segment connection to the current TCP connection and in some case some pocket which belongs to the current endpoint has been delayed significantly and so since TCP seek is number space is just a little bit if the delay is big you know sometimes this you know seekest number is delayed more than 32 bits bite and then go since then this packet goes to this current connection it might be really difficult to distinguish this packet at this top pocket and then that\u0027s why we need a pulse in this case that\u0027s the primary case for pulse and then second the cases previously this and the point connect established at this point and then but this point this previous endpoint now disappeared but still the packet belong to this connection still exists for some reason and then try to join the current you know connections in this case if seekest number some how much to this connection it\u0027s very difficult to distinguish this bucket and this pocket and that\u0027s another case of pulse needed protection and then third case is some there is "
  },
  {
    "startTime": "01:34:48",
    "text": "some malicious attacker somewhere and try to inject a packet and then try to do some you know attack to this connection so this is the third case you know pulse can provide the protection if it\u0027s possible that\u0027s the souther case okay move on to the next slide okay so let\u0027s take a look how pulse rocks and basically you know pulse use timestamp for protection and what pulse does is a compare the timestamp in the segment and then timestamp which received in most recently and then if timestamp in the segment is newer and then passing the segment is buried and then the decision of which pocket is in Nuala order it\u0027s very simple let\u0027s say if we have a to timestamp tear on the teacher and then if T 1 minus T 2 is smaller than 2 to the power of a 31 and then the timestamp T 1 is a new one eres T 1 think about its older so it\u0027s a kind of binary decision if we if that this is a you know if you t1 minus t2 this one 2 to the power of 31 it\u0027s newer by errors it\u0027s over and then this simple Roddick\u0027s works for the first case for all first case in a previous right for all duplicate Kate segment in the connection in this case it works because timestamp barrier monotonically increase in a single connection so this logic work properly in this case and therefore the second case in the previous slide for segments from previous connections sometimes this logic works if the timestamp barrier monotonically increase across or TCP connection however some improvement in some implementation chemist and value does not monotonically increase across or TCP connection so some in this case this protection doesn\u0027t work so in this case for second case pulse protection may work were main a lot and then subtle case the segment from attackers in this case this protection won\u0027t work because no as I said the pulse logic works and just in a binary decision número order so if the attacker uses random timestamp and then apical success rate will be 60% so if you attack ascend a multiple packets you know yeah probably one with the pocket can cheat a post protection so in the sense pulse cannot provide protection against attackers so if we think this way pulse can only be effective for the first case and for second decide the case it\u0027s not "
  },
  {
    "startTime": "01:37:48",
    "text": "very useful so it might be better we have better protection if possible that\u0027s another motivation hope this draft move on to the next ride and then what kind of technology can be used as a replacement of a pulse and I think we have actually several technologies already and so right now in TCP working group TCP Inc working group we are discussing the technology that can encrypt a packet and if we increase the pocket we can easily distinguish you know packet belong to previous connection and the packets belong to the current connection because it\u0027s encrypted so if we see older a connection from the oldest take over the connection pocket cannot be encrypted cannot be decrypted because you know it\u0027s gamefreak to waste define the key so it\u0027s very easy to distinguish all the packet and the new pocket so it can provide stronger protection and unpause much much better protection and then also in case of TCP MP TCP and participate maintains 64-bit cities number space and in the session and then it used data single signal options and the replacement and so this indicates us as seeking signals mapping and then by checking and then this information is sent to TCP option so by checking this option we can Despres we can use this option as a replacement of the pulse and and then data syncing signaling check is much much stricter than pulse because policy is just no binary check knew our order in case of data signaling check it\u0027s required exact match so it\u0027s more in a robust and strict that\u0027s why you know you can provide stronger protection than pulse and then third option is the TLS this is application protocol but it\u0027s encrypted packet and then we have seen lots of deployment in TLS these days and if the packet is encrypted just like TCP ink you know we we can easily identify the package belong to earth connection and packet belonging to current connection so it can provide better protection John Powell\u0027s so if these technologies available we can disable pulse and the switch opportunity this technology for protection that\u0027s the basic idea of this truck okay move on to the next slide and then also this kind of a new protection can\u0027t have another possible benefit so if you are running busy server you might see rows of you know connection in time way state and it looks like a kind of overhead but "
  },
  {
    "startTime": "01:40:48",
    "text": "this is necessary because time way state is required to avoid seeing the segment from the previous connection with same endpoint and then you have to wait to a missile time to be expired for this kind of connections but this is not you know great for the performance of the server but let\u0027s say we have new type of protection I have mentioned in the previous right and we might be able to recycle this connection in time way state because as I said the purpose of the time rate is to distinguish target from previous connection and the packet from current connection if the packet is encrypted for example or we can easily identify this is coming from all packet and this is coming from you know drawing it to the current connection it\u0027s very easy to identify and then some people say you know yahoo happy being used this kind of protection by using pulse Bera as far as I know these days you know this kind of protection is not used because um we know there a similar case this no pulse protection becomes unreliable for example if multiple client is behind the same net and it seems the same IP address and then because of this pulse logic can be confused very easily and then discarded target unnecessary and that\u0027s called the trouble so because of that you know some implementation record in acts to say with this feature so but if we have a new type of protection even if the multiple client behind a single nut we don\u0027t have to worry about its pocket to be encrypted so we can safely distinguish all the packet and a new packet so with this is this could be another kind of benefit to use new protection okay move on to the next slide and so what will be needed so since we as I mentioned the technology is already already there we have a direct and we have deployment with the technology or English with the MP TCP has been deployed TLS is already deployed very well and so what we will need is just to have a some kind of signaling mechanism to enable this feature and the disable pulse that\u0027s what we need here and if and then probably need signaling because if we just disable pulse without you know getting a permission from the other side then when a pocket might be discarded because RFC 73 23 requires to discuss segment without timestamp option so if one side all of a sudden stop using pulse and then stop putting the time stamp and then packet might be discarded but this is not what we want so by using "
  },
  {
    "startTime": "01:43:48",
    "text": "signaling because you have to make sure both sides agree to disable pulse and then after that we can stop putting time stamp in a TCP segment so that\u0027s why we need signaling mechanism okay move on to the next slide and so there a simpler way to implement signaling mechanism one way it\u0027s new you Smith define new TCP option and do negotiation during the something wrong okay good so one option is define a new TCP option and use it the future negotiations during shapes see exchange and this is straight what but no it\u0027s requires another option space in sixteen segment and then the other way it\u0027s extend timestamp option for future negotiations and Richard previously you know proposed this kind of idea so maybe we can utilize his idea to some extent that\u0027s another idea and then third option is extend protection mechanisms for example in case of TCP yeah we might be use one bit of you know global sub option in you know and then you know in case of TCP Inc you know we can use use it by using this one bit we can negotiate which we want to disable pass or not and in case of MP TCP we might be extend and be capable or other way we can use MP experimental option in order for shoots on negotiation and that\u0027s a plan and and move on to the next slide okay this is the rust right oh you want to waitress right what you want to speak tell me go okay so so this is the rough slide on my talk so as I as you know this is very pretty much idea but uh so at this moment I would like to you know get a feedback on the two point and does this look a promising idea to proceed or do you see some serious program or concern in this rough and if this idea looks promising must should be done to be adaptive that\u0027s to point I would like to get feedback at this moment okay that\u0027s my that\u0027s a my talk please okay the the previous slide seemed to assume that I that you\u0027ve got to switch it off after you start it but in all the three cases you gave MPT CPT\u0027s being canned and TLS then you know at the start that that you\u0027re using them so you don\u0027t have to start using pores and then stop because you can just never use it yeah "
  },
  {
    "startTime": "01:46:49",
    "text": "am I missing something or maybe one time James II but when would you turn them off during a connection making stuff I think that\u0027s what you propose because you\u0027re negotiating it at the same time and yet slave might work or it might not yes okay right okay okay I\u0027ve got another question which is actually related to a case where you might have to turn the on later in the connection going right back you said there\u0027s a 50% chance of an attacker beating this so it strikes me that if you if you discover a case where you detect an attack with 50% chance then you could turn it or was on let\u0027s protect yourself in future that\u0027s not it\u0027s 50% chances succeed right yeah so before they find it no they might succeed well yeah yeah but then yes they moves but can you succeed or does it is it worth trying to protect yourself after the event so since you brought it up first of the you playing the cackle detection there\u0027s other protections as well I mean you have to guess the right sequence number so it\u0027s not just the pause protection that\u0027s protecting you um I don\u0027t like this well I like timestamps and I\u0027ll tell you why okay time stamps can be used for a couple other things um if if you don\u0027t have any any loss you can actually use them has a unique identifier for extending lis cinco\u0027s sequence number if you will if we made one minor change the time stamp which you have the time to have often change there where you always when you respond with the sax and the latest timestamp then they would actually be an extension to the sequence space already and you wouldn\u0027t have to worry about it okay so that\u0027s what I would rather see that happen again this the other thing is what I\u0027ve been playing with with our BB r implementation is I can look at the time stamp the other person is sending me to a series of acts and if I can determine what timing value the person\u0027s you of the Epirus using I can actually more more more accurately figure out what the bandwidth is the peer is receiving my data so the time stamp option is very handy to me and I would not like to see it go away with a rendered busy if we use sin that put the time stamp only get transmitted budget and then you might distinguish literals mr. copy this is original pocket or this is coming from the transmitter it\u0027s "
  },
  {
    "startTime": "01:49:50",
    "text": "maybe that\u0027s what I\u0027m thinking right now do you think it\u0027s possible well you need it on the data you need every packet both ways right the dear going out and the acts coming back but you say if you have if you have store the old time transmission time in the rocker side you don\u0027t need timestamp is essa\u0027 you\u0027ve done a retransmission if you if we had unique time stamps coming back on every on every act yeah so so if I see I said you net didn\u0027t you said what was reflected back I can then use the time stamp that I sent on that packet with the sequence number to determine which transmission it was mm-hmm and it\u0027s it\u0027s a unique identifier right but it\u0027s it\u0027s not doesn\u0027t have to be time service at it kind of some kind of idea you could use something besides the time yet but we have it have it there it works so why not use it hmm Michael Jackson on the floor if I understand TCP time stamps correctly so if you if you receive a packet from this old connection then the TCP stack drops it it detects it\u0027s from an old connection and the ongoing connection is not disturbed if you use TLS on you will end up in a decryption failure and a thing when the TCP TLS gets a decryption failure it terminates the TLS connection so you don\u0027t get this protection if I\u0027m not wrong anyone fluent in TLS I think it\u0027s I mean if you decrypt you get yes Stuart sure sure I was thinking the exact same thing to make this work you would need some significant software changes that you give the segment to TLS TLS get a decryption failure hands it back says don\u0027t acknowledge this don\u0027t tear down the connection wait and see if another one arrives so it would be some fairly major surgery on boring SS boring SSL\u0027s be able to reject segments without killing the connection just saying you\u0027re basically correct you still get the protection of data getting injected into your connection you end up losing the TCP connection unless you are clever like Stuart and I was having some more thoughts as well so you\u0027re you\u0027re basically correct but you still get the protection you just don\u0027t get their own puzzles you get the protection and data you tranch in here is going to pretty much say the same thing but and then to me it\u0027s like pass already works it\u0027s not perfect and now you say it\u0027s this disabled and the other layer to it and or do some kind of cross layer work and that\u0027s we needs a lot of work and and a further "
  },
  {
    "startTime": "01:52:51",
    "text": "point is that even in your proposal of just no TCB times the amount they eat our original data he wouldn\u0027t work they\u0027ll just use it a simple case so when you send this original data I typically use the MSS without timestamp option right let\u0027s say 1460 now okay because of loss detection you need to retransmit this one you want to insert that 12 byte that won\u0027t work because your exceed the MTU or the MSS so you have to send the 14 48 bytes in the first packet and the remaining on the next packet or you need require somehow with packetization and this is going to really hurt the TCP stack performance - yeah but sounds like an implementation problem to me we are right here for an implementation problem is is a problem okay yeah I wanted to echo a few points and add a couple more so I I were dumb I\u0027m a big fan of timestamps as well I mean I think Randall raised some of these points earlier that timestamps can be super useful when you have retransmissions and they allow you to sort of quickly a deduce that a retransmission was spurious I take your point that there might be a clever way to not do the timestamps until you are doing a retransmission but you know others have pointed out that could be problematic another thing that I haven\u0027t heard pointed out yet is that receivers actually make use of timestamps to do a receiver side RTT estimation in order to do receive buffer tuning auto tuning and there\u0027s not really an another alternative that I\u0027m aware of for receivers to get a good RTT estimate and receive buffer Auto tuning in in my opinion is a really important thing so I think so in my opinion timestamps are really useful another so another point would be that even though I I do encourage folks to keep timestamps I do see a potential value in either negotiating disabling pause or adding some bits that sort of allow each side to specify what they want the semantics of those time zones to be so for example I guess previously had ITF we discussed that our team is a big fan of being able to use microsecond granularity timestamps and with those really the the biggest blocker is the fact that the other side might interpret those as millisecond granularity timestamps and apply pause semantics and then drop your microsecond tagged packets because they\u0027re they\u0027re wrapping "
  },
  {
    "startTime": "01:55:51",
    "text": "too fast essentially so I do support a way to either disable pause or indicate that the timestamps may be advancing at make or several gates and need to be the pause time scale needs to be adjusted accordingly so in my understand here you know you might okay with you it\u0027s new protection by you don\u0027t want to you know disable timestamp option yeah exactly I support either being able to negotiate pause off or negotiate some alternate semantics for the timestamps but I do you think timestamps are great and I at least personally I\u0027m not worried about the loss in the option space because they do have such a nice semantics for detecting transmissions spurious retransmissions and for doing receiver side RTT estimation okay yes hi Brian criminal I\u0027m just gonna take the other side of the argument for a moment I think timestamps are terrible um not really actually I quite like them they radiate an enormous amount of information about the internal operation of the transport which in a lot of cases is good and in some cases is bad and getting in points control over when they do that is a great idea I\u0027m a co-author on draft night of tea time stamp negotiation I\u0027d be happy to like basically dust that off and turn it into what we need for this because so it did like the it was a little bit at the time it was a little bit of a solution in search of a problem and now it seems like we have a it was a different problem but it was not quite the right solution for the different problem because well it was basically saying okay well let\u0027s expose the time stamp generation rate so that we can do passive measurement of that without having to do like it basically reduced the amount of effort you have to do to essentially phase lock on the on the time stamp rate turns out when you phase lock on the time stamp late you get the drift of the clock on the machine and making the drift go away so that you don\u0027t have like link authority across multipath is really hard so like me know more about potential so you know in a lot of your cases you don\u0027t care because you don\u0027t really you can already identify the Machine by the IP address but in some cases you might want to be able to turn that off I think yeah that that probably the right way to go about the TCP side of this is to look at ttpm claims gain negotiation figure out of facts if we want to tweak that approach or if we want to do something based on that approach sort of a generalized way to let the endpoint say yes or no in this case okay thanks thank you thank you "
  },
  {
    "startTime": "01:58:55",
    "text": "oh hi can you hear me yes hi I\u0027m so hail from Google today I\u0027m going to present recent developments and extensions we have added two tcp linux to make tcp faster and cheaper for applications this is a joint work with you John Neal and many others at Google I\u0027m just presenting it for as a cohesive story next slide please so when we want to deploy TCP on emerging platforms 100 Gig NICs lots of CPU cores the bottlenecks we see are usually inside application at the border of interaction with TCP namely we need to optimize buffer allocation applications but we can\u0027t really do that if we don\u0027t have proper signals from TCP we need to save copies on send and receive we need to get better notification of what is available in TCP we need to somehow coordinate with TCP threads to basically try to preserve core affinity between user space and the kernel I mean II to lower per packet overheads on both receiver and the sender so for example the G ro mechanism that was discussed today a few times we can\u0027t really get to 100 Gig without having GRL or TSO either in software or in hardware next slide please so today I\u0027m going to present the zero copy mechanisms that are added to TCP and Linux which you found very useful in increasing TCPS efficiency then I\u0027ll discuss a new feature called is being queue which helps user space to optimize buffer allocation and then I\u0027ll talk about user space threading and affinity and Cisco loggerheads bit meltdown and Specter mitigations syscalls are now way more expensive so I will also discuss some mitigations for those next slide please so TCP is transmitted zero copy was added by vilem in upstream Linux a few "
  },
  {
    "startTime": "02:01:55",
    "text": "months back it\u0027s a very simple mechanism everything works just like a normal UNIX is call you do a send message for sending your data the differences kernel would keep references to your data blocks and send those data without actually copying those that data block and because of that kernel would send user space notifications on when this block is not needed anymore by the kernel note that if it was just net fare for I curve we could just allocate something and then on map it and let the kernel D allocate the memory but in real world applications these blocks are often shared with the application for example we can imagine a database with the memory cache and these blocks are actual memory cache is given to the kernel so we need to need proper synchronization with between TCP and the application next slide please the notification mechanism in Linux is very simplistic for any successful Cisco which basically means that positive number returned from the send message we assign an sequential ID and then when the blocks even to the colonel on that like uh nemesis call is that can be released we just send a notification on the Eric you this is very specific to Linux the notification mechanism but we imagine it\u0027s easily extendable to other platforms it\u0027s just a control channel um Eric Hughes are basically for getting ICMP packets from the kernel and then it gradually is extended to four timestamps and all sorts of notification to user space it\u0027s more of a control channel right now we had a normal data channel for Cisco\u0027s and then Eric you at reacts for orchestration um because some there are so many caveats in the implementation but user space should not touch the data payload while the references hold is held in kernel for example you can\u0027t imagine a nick that doesn\u0027t actually have a checksum offload if you modify that it would if you modify the packets it would cause it can cause data corruption in the Linux implementation of zero copy we have mitigations for this for example as soon as we see the packet is going through a device that doesn\u0027t have checksum offload we immediately copy the payload and fake zero copy notification so user space see this as a as an actual zero copy but we are actually doing copy inside occur next like piece a zero copy "
  },
  {
    "startTime": "02:04:56",
    "text": "isn\u0027t really a magic it says one copy adds extra notification to the app so if you have just one bite to sin it\u0027s probably just cheaper to copy and unless you have large chunks to sent it\u0027s not really worth it but when you have like 500 kilobytes or one megabytes of data or two megabytes of data to send using zero copy improves TCP performance by large margin we see double digit percentage efficiency improvement by that I mean how many CPUs we burn how many CPU cycles we burn for sending the data and you also we also save 20% of memory bandwidth which can be a bottleneck on I got disconnected I think where can you hear me yes okay sorry oh I don\u0027t know what happened so on 100 gig with one our gig NIC memory bandwidth on the bus can actually be a huge bottleneck for TCP and the NIC so by using zero copy you can also save more than 20% of memory bandwidth in our measurements it\u0027s usually more than 30% but cons we never saw less than 20% of improvements can you go to the next slide please this is a sender that uses your coffee as you can see you basically do a send message with message zero copy and then you need to pull the error cue to read zero copy notifications and then you can just free the blocks I put it in the slides for reference if someone wanted to actually use this feature for the application this code has a it\u0027s very simplified it doesn\u0027t actually work for multi-threaded apps and I will explain why in in next slides so there are some caveats on how to handle handle zero copy signals but the idea is very simple you just do a send message you put the your blocks with a sequential ID and then you received those IDs on Eric you and release your blocks next like this so one caveat of TCP zero copy is we cannot release a data reference in a packet if you received a sack for that block you do cycling again so we need to make sure the data is fully act and even if the data is fully act the can not release the packet because the problem is the packet for example I may "
  },
  {
    "startTime": "02:07:58",
    "text": "have a response retransmission of a packet the packet may sit on the device transmit queue for a long time while I receive the ACK of that packet so a copy of that packet may sit somewhere on the end house and for that reason we basically need the signals are generated when we really don\u0027t need that packet meaning that they did carefully act and no copy of that packet is actually sitting on the end host anywhere as a result of this for zero copy they may receive Adil or their notifications which can complicate the release process in user space but this is a conscious that this is a decision that was made just to make sure the implementation in the kernel doesn\u0027t have too much overhead of handling to just coalescing these release signals next life so but the next extension to TCP in Linux we added is TCP in queue one of the problems we had on 100 Gig nix exchange in large amount of data was that the user space has to guess what is what how many bytes are available in TCP received queue there are there is a Cisco called fil ndred you can call this to get depending the readable bytes on a socket I think it is also available in bsd and but a problem is right now after Spector and meltdown decease calls are very expensive and when we do this we can actually hurt a small data exchanges on TCP sockets also we need to do that all Puri because while I\u0027m reading from a TCP socket there may be packets incoming onto that socket and there may be more data available right after the read returns so we added this to Linux any if you read some data kernel will tell you how many more bytes there are to read so for example you can call receive message on DFT it will with 1k it would return how many bytes have been read and then also tell you how many more bytes you can read and using this data we basically optimize the buffer allocation user space we allocate enough buffers and then give because kernel guarantees that that mean like that 65 K is actually available to read so we wouldn\u0027t over allocate the allocates are optimally and then read the data we see 33 percent to 5 percent more efficient reads and writes for small and large are "
  },
  {
    "startTime": "02:11:01",
    "text": "pcs with this mechanism it also lowers the latency to a very good extent teh latency goes down because memory allocation is can be a bottleneck when we have very fast NICs next like these another issue that we have is the emerging Nick\u0027s are so fast and efficient that they\u0027re just packets being received on TCP streams and if you wait over the event queue of a socket or a bunch of sockets you\u0027re constantly receiving events from the kernel once every 80 or so junk and the number of wake-ups we have to do for a 100 Gig NIC is actually very extensive and each spurious each wakeup reads a few bytes like 100 kilobytes and then has to wait for another event to come up until we have a full trying to read the problem with that model is that most applications cannot react until they reach they read the whole frame for example an inch T 2 B 2 server cannot actually do anything until it has the whole frame ready so that it can process that frame so but we did Google is basically using received low Watts so whenever we use a watermark to just basically silence the events until all the bytes we need for processing is available this way we can be lowered the way cops in userspace for TCP and while we don\u0027t receive those notifications we can actually handle more useful notifications from other TCP sockets and we can easily scale to thousands and millions of hundreds of thousands and millions of connections just because we don\u0027t wake up is furiously next slide please this issue is looks kind of clear and kind of obvious but it\u0027s a very difficult problem to address the problem is in except when we have user space CCP we have two threats one that two sets of threats one that actually does TCP processing and one that actually reads from the TCP socket and if the data are the socket is processed on another core by TCP threats and then read on another "
  },
  {
    "startTime": "02:14:03",
    "text": "core by a user space threat we see more than 50% of throughput regression just because of invalidating cache and having to coordinate these CPUs Linux uses very simple heuristics for example it used to set the cpuid of a socket whenever you send or receive or poll a socket that basically means i would expect the user space thread to read this FTE on this core so i would try to process a packet of this socket on that core and the problem with our model was that for example if you have a Google application there is only one polar and all the if these are pulled by one thread and Linux would send all of the packets of TCP sockets through the same core and then it would userspace threads would read it from other CPUs we removed this heuristic from Pole and saw immunity saw more than 50% through good improvement for those applications but even with that this like expecting that user space would read from a specific core know heuristic would actually worked because a scheduler moves threads around there is contention on these struts threads may get block on a on a CPU get rescheduled and we can\u0027t really pin all the threats for generic applications because there is a value to reschedule any threads by this scheduler so instead of this we actually changed our applications to orchestrate how they handle handle CPUs on course to to make sure TCP and userspace threads try to process sockets on the same CPU this is basically based on the heuristics we use for TCP and Linux and then user space trust to follow the same heuristic and it would basically converge to the same core there is more than 10% gain as soon as we do this in efficiency and latency and but what these mechanism is not perfect because there are constraints that may move threads around but this is a very product they\u0027re very difficult problem to to fix unless we actually know what is happening inside TCP so the next slide I think um so based on this is just a summary based on the the efforts that we had at Google to try to make sure TCP is as efficient as "
  },
  {
    "startTime": "02:17:05",
    "text": "it gets on emerging platforms we think optimizing TCP core like congestion control making it resilient to reordering the loss is necessary we can\u0027t really go to those emerging platforms without these developments but it\u0027s not really sufficient to get ultimate performance for users based applications the performance of TCP really depends on how TCP is used for example even how people DFT is how the events are managed how the allocate buffers so we think there\u0027s value in to in looking on how we can we can provide more signals to the applications to make better decisions and how to to to use TCP some of the for example sends you a copy the reason that we coffee is just historical decision in classics and we see large gains by revisiting those syscalls and and adding extensions so that so that we can avoid copies for example for this implementation specific but the heuristics that we used for linux on setting cores for example on poll was based on a very specific application and you really didn\u0027t look at a wide variety of applications that are actually using TCP and that heuristics heuristic was actually hurting performance of user space just because we were not preserving core affinity so we really two two make sure all these implementation heuristics are guided by how applications use TCPS at the moment in this work we use the old and new TCP metrics for example we have a new transmit and receive timestamps and Linux that we use for trying to demystify latency in different parts of TCP yugyeong added a very nice Cronos to TCP for Linux so that we can for example say out of the 100 seconds this connection is open how long we have been busy busy sending data how long have been we have been receiving the limited and we use all of those in our in our research other tools such as net nest at SS Linux barf flame drafts EBP fnf choices are very handy in debugging these issues and making sense of the latency problems this this is the last light thank you for your time and "
  },
  {
    "startTime": "02:20:05",
    "text": "if there\u0027s any questions thank you we have a short amount of time for questions I\u0027m generating a thank you for presentations all this is quite interesting and thank you for discussing something that\u0027s different from just drafts and bits so I want to ask so see you you talk about various things and on the slide I see the cooking large TS O\u0027s and so on but to some degree your writing here you\u0027re conflating workloads and I would like to see if you can please them apart a little bit and I specifically want to see if you can speak to which of these are critical for doing the web and video and internet facing workloads versus datacenter workloads in particularly I am interested in understanding and the doctor waters in the past but I would like to see if you if anybody\u0027s trying to quantify the value or lack of value of T so for example on on implement of public facing workloads in specifically because I know that Google uses FQ and how much you\u0027ll actually plays into performance for delivering content can you speak to that sure well you showing a nil are there you have deeper knowledge of that part of the infrastructure but for most of most of the things I talked about today are focused on 100 Nick Nick fabrics and Nick\u0027s on emerging platforms with like less than in order of tens of microseconds of RTT but except for zero copy which actually can save a single-digit CPU cycles when serving content to users base especially content that has to be processed and it\u0027s not a static file for T so chunks specifically for 100 Gig Nick\u0027s we can\u0027t really saturate the neck without tears oh but Dad can cause congestion zazz I think you have been referring to for interface interfacing traffic or connections with lower bandwidth so this is a double-edged sword but for 100 Gig Nick\u0027s having a full tier so sent out of the Nick without engaging software is a must we can\u0027t really reach 100 without resources "
  },
  {
    "startTime": "02:23:08",
    "text": "understood but just to have to deface my question how much of this applies to internment facing workloads except for zero copy and polling polling and zero copy are are important for just efficiency over many connections so without the polling for example you can\u0027t reach more than 100 connections on a single polar so you may have other polling strategies but without that RFS improvement you can\u0027t really go beyond 100 connections zero copy is just it\u0027s not a must but it\u0027s just efficiency saving that would apply to internet racing track yeah Neal card well Google yeah just to run to what sir hello was saying and to address Jonah\u0027s questions yeah I would agree with this or how about most of these things being able to benefit internet facing applications and particularly we definitely have experience with TCP zero copy hoping internet facing applications that send a lot of data it\u0027s a video for example and then as far as TSM oh yeah so definitely TSO helps internet facing stuff as well obviously to it it\u0027s to a lesser extent because for internet pacing workloads obviously the bad wits are not hundred gigabit obviously they\u0027re closer to 10 megabits 15 megabits that kind of thing but even if those lower bandwidths there\u0027s a significant benefit from TSO so for example the Linux team so auto-sizing logic tries to create TSO jumbo packets or bursts if you will that are basically what it thinks are 1 milliseconds worth of data so at 24 megabits that\u0027s too many packets if forty eight megabits that\u0027s four packets so between sort of that sort of 4k video rates and can at least cut your number of trips up and down the stack in half by using team so for internet-facing stuff for something we definitely see valley frontier so thank you cute so here we go to the last presentation charts okay hello everyone my name is Carlos Gomez and one of the authors of the draft entitled TCP usage guidance in the internet of things so basically this would be a quick presentation basically "
  },
  {
    "startTime": "02:26:08",
    "text": "heads up as the chair said before on the fact that the authors of this document think that it is getting ready to request a working group last call quite soon so maybe some of you may remember that I presented the very first version of this document in the CPM back in IDF 96 in Berlin and since then after them it was decided the home for the document would be the lightweight implementation guidance working group so the document has been presented several times there although Michael sharp whose culture here in TCP and also co-author of this document has been keeping the document sorry keeping this idiom in the loop through the mailing list so our plan is to submit the next version which will be 0 for possibly a minor editorial update around September October and then request a presentation in Bangkok in both TCP m and also a week and possibly around the time request working robles call so next please as a reminder the goal of the draft is not to define a new TCP version not to define new TCP mechanisms it is to describe how TCP can be used configured or implemented in constrained works which are quite typical in IOT scenarios and present which other related trade-offs next please so as a quick overview of the contents in this document this is the table of contents so after the introductory sections we have section 3 that provides the main characteristics of constrain node networks that may be relevant for TCP comprising node Network and link properties also uses scenarios and traffic patterns then section 4 provides the TCP implementation and configuration in CNN\u0027s recommendations and content so this is organized in three subsections the first one relates with mechanisms or parameters that are related with path properties such as MSS the ACN and so on then the second subsection provides guidance for devices that really constrain in terms of memory and can only afford very small window sizes such as a single MSS window size and the third subsection provides more general recommendations for devices that can afford larger window sizes but are still constrained then section 5 discusses how applications may use TCP connections and related aspects then we have security considerations which are quite specific to this topic and finally we have an annex which intends to survey "
  },
  {
    "startTime": "02:29:08",
    "text": "the characteristics of the main implementations of TCP for constrain devices next please so to illustrate this we have a summary table from the annex which intends to collect details on parameter settings and whether some mechanisms are supported or not and also memory requirements in terms of code size for eight different constraint well disappear plantations for constrain devices so of next please so again the plan is to submit a zero for around September October then possibly request a working group last call by that time and in preparation for that it would be great if we could get your feedback your comments on the document so thank you very much in advance I don\u0027t know if there may be questions or any question No okay so then please provide feedback thank you and see you at the next site here if everyone if anyone hasn\u0027t signed the blue sheets please do so and we are missing one I guess [Music] you "
  }
]