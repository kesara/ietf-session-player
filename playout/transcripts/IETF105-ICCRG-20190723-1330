[
  {
    "startTime": "00:02:06",
    "text": "all right people I know I really don\u0027t have a voice but I\u0027m gonna try and use whatever I\u0027ve got this is IC crg if you are here for anything else you might be pleasantly surprised cuz we have more fun than anybody answers can somebody give the doors in the back please okay I\u0027ll need well let\u0027s I\u0027m gonna start now because we are 132 can everybody understand the words I\u0027m speaking good thank you well I I almost Thank You Marvin I\u0027m sorry yes all right so not well note well important if you\u0027ve not seen this before please look it up Google IETF and not well and you\u0027ll find good information about IPR disclosures about the work that gets discussed here if you\u0027re not familiar with please familiarize yourself with this before talking about nothing sorry please bring this or what does the doctor go this the agenda is as follows but before we get into the rest of the agenda I need a jabber scribe somebody on jabber jabber scribe Chavis Kaiba Thank You Maria where\u0027s the JavaScript who\u0027s taking minutes then I\u0027m gonna name you in a second we need some rated minutes thank you sir thank you again okay so we will be talking about VBR v2 which is a brand new BB r if you not been paying attention so Neal zero you\u0027ll be talking about that and you have an exciting what do we call it let bad double presentation what\u0027s that double feature thank you that was the yeah my brains also not really functional at this point yeah double feature only batch we\u0027ve got Praveen from Microsoft talking about it that plus plus some of you may have seen "
  },
  {
    "startTime": "00:05:06",
    "text": "that before but it\u0027s it was popular so we\u0027re bringing it back and we have our LED back from Marcelo which will build on this to do receiver side congestion control so this is going to be interesting I hope and if time permits we might have some time for a presentation from ana Donny\u0027s group at Maui before we get into these wonderful presentations I just want to take a few minutes of your time to discuss a direction in which we are trying to go so this is just kicking off a discussion this is getting the conversation started ICC RG used to has published documents in the past and we would like to start doing that again there\u0027s the context is that there\u0027s new an important work coming through ICC RG now and this is something that we are seeing as consistent presentations coming through these are experimental algorithms they need continuous review they need feedback from the community they go through iterations and they come back this seems more and more like a process that should turn into something sort of an eruption some sort of publication eventually be BRM get back dismiss are strong candidates at this point the brand new high star plus plus and also based chirping our early candidates but we\u0027d like to see this sort of practice start to happen I\u0027m completely aware of the fact that this needs a few things and has implications this needs commitment from the authors to keep coming doing things that they might otherwise not do this needs us to agree on what it means to adopt something what it means for a research group toward out the document so to speak it also does mean that we need to agree on what it means to publish document what do we if I I see crg says that we it\u0027s going to get published as an ICC IG document what should that signal to the community we do need to figure this out but I think we can solve these problems this is not intractable so that\u0027s something I just like to kick off a discussion and if anybody has any thoughts on this I will leave a couple of minutes otherwise we can convey this homeless Michael well so no thoughts seriously hi I was closer to the microphone so I stood up Brian Trammell uh do it um so I Spencer here so I can borrow back my pan orgy chair at UM the like so soap an orgy basically has this like a more "
  },
  {
    "startTime": "00:08:07",
    "text": "focused set of research questions that it\u0027s looking at at least right now it might you know mutate into something a little bit broader and we\u0027ve um sort of kept cozy and internet drafts which were adopted internet rush the thing for the for the the research group and the process runs um a whole lot like a working group right like so you basically just put the put the process over runs fine one question that we have in terms of the types of documents that we have in the research group are are these things that we basically just want to keep the document as an internet draft and keep it alive within the research group where that you know draft I RTF Arg label at the front means this is something that the research group is thinking about not necessarily that it\u0027s ever going to be published as a document right licks or something that\u0027s talking about sort of frameworks for how you would consider research in congestion control algorithms we\u0027re not really sure that we\u0027re gonna publish any the documents out of pan or G as rfcs I think that clearly the experimental RFC\u0027s for um for some of the experimental algorithms that make sense to publish here but you might also want to consider that some of these documents you might want to just sort of keep them as research group IDs as sort of kind of like living documents for for what\u0027s going on thanks Mike Aversa yes I very much agree with it in my experience the issue the issue with doing this my experience with telling people that we can publish things directly in as ECoG was that their response usually was that they have this business in the other room and it\u0027s very interesting idea Bob I like something I don\u0027t know I I don\u0027t know probably it just smells too much of this is a useless i RTF document or I don\u0027t know I don\u0027t know I just never had people wanting to do it your affair has been tapped by the mic I\u0027m a TS vwg chair I think I want to try and understand what the differences between so be publishing something here I\u0027m taking one of these two TS vwg which you could do as well so there is a difference because these groups are different and the process is different and that doesn\u0027t mean you shouldn\u0027t do it here and be able to do it there but we need to be clear to the community that reads these what that difference is and I don\u0027t know yeah so this is deliberately not going into that yeah yeah absolutely and hundred wasn\u0027t aware of the fact that I think that the leadership and the community are all confused about where these documents ought to go at the moment okay - Westland I get to almost take on my former aide transporte here this actually goes back to when I was a "
  },
  {
    "startTime": "00:11:07",
    "text": "previous term because that\u0027s when me and Laura said it worked quite hard really I said could then set devices the odd years to establish this process of trying to bring in things into a society do incremental specification first and then when algorithms were proved we could move them on into the ITF that was the intention of the process back then ten years ago and I think there\u0027s definitely value publishing specs experimentals as a starting point and then see what reached when we get high maturity and deployment experience and all these things we can move them into ITF when they\u0027re suitable so David Barack the other cheater cheater who happens to be here in Montreal I mostly want a plus-one Magnus\u0027s view of how the world should work is very nice analogy between ICC RGS relations the transport area with a CFR G\u0027s relationship to the security area this is where the deep expertise exists on the congestion control algorithms including every last little detail that you have to get right or else and like Magnus I\u0027d be very comfortable looking to this group to nail the algorithms to the floor and then the rest the IETF TC GG and Beyond can figure out how to pilot protocols so just to be clear David for a moment and we\u0027ll be Magnus as well are you proposing that are you suggesting that we can keep experimental that we publish it so many documents here if you find that useful as part of maturing and nailing the alchemist the floor go for it I jumped up when Michael said you know there wasn\u0027t much interest in people wanting to write things in the ICC idea and I wondered whether going back to Magnus is so I\u0027m Bob Briscoe going back to may was this point that where where this process came from was where IETF group would ask the ICC RG to do expert review and that sort of broken apart because there\u0027s so many transport protocols now that would use the same congestion control and so it occurred to me that TSP WG might be the place that would ask ICC RG now for all the transport protocols and it would be a and then that might that that might give a bit more cachet to having a ICC RG RSC about your your congestion control because it it\u0027s something that is used for a number of transport protocols Samiha could have been as an as an individual my opinion is that we should "
  },
  {
    "startTime": "00:14:08",
    "text": "not talk about processes right now and like it doesn\u0027t really matter we I would be super excited to work on congestion controls in a like cooperative manner where we all talk about problems and finding solutions together write them down make sure that we have a description which is like readable and implementable and we all like and then we can figure out what to do with it so my name is Michael sharp speaking as TCP I\u0027m sorry I came late because this slide was not on the other gender so I haven\u0027t seen it there was another room I just want to point that I disagreed is this what is written here and it would rico require recharging tcp Mbita also disagree right now I just avoid a big minus one on this one here I don\u0027t know what has been said before but it disagree with what is written on the slide I disagree with the publication of experimental algorithms such as hi start in this year she because this is in charter of TCP M so if the authors want to come to T CBM the Charter allows that and I is a grievous changing that part of the Charter right now without having a bigger process discussion but it doesn\u0027t matter I mean this is Isis here G right if Isis here G wants to do it they can do it sure but if that implies that people will say it will come to tease you and say that we don\u0027t do things that are in shorter then this is a different story so just be clear the slide here does not talk about TCP M the slightly talks about what ICC RG is going to do if if this means that people start showing up to IC c RG more that\u0027s a good thing for IC c RG the last I think your point is right that there\u0027s a scoping that scoping overlap between the two for sure and maybe this is something that we need to go off and discuss what to do about but I would like to have the concession about publication do I see that\u0027s a fair that\u0027s a fair point but just as I said the last point here is a TCP individual draft so stresses to be and brightener so there is overlap and what we have here on this bag just to be clear also that\u0027s all being adopted by DCAM yet so Matt Mathis I think at the end of the day what we\u0027re arguing about is what you need to do in order to put - I CCR G - a document name and maybe that should just be a self selection process to help some of us find other documents easier and just recognizing that sort of the rules are anybody can put - ICC RG in a file name is sufficient to address the topics on this line calling you\u0027ll have the last word hi Colin Perkins um I mean I clearly think you know publishing "
  },
  {
    "startTime": "00:17:09",
    "text": "congestion control algorithms is this clearly in scope of ACC oh gee you know experimental algorithms potentially even in informational our grooms if we we believe something is mature enough I think it is something I see see a G could certainly do equally this is the IRT F and doesn\u0027t set standards so we need to be clear on boundaries in the scope of what we\u0027re doing and we need to very much understand the relation with the IETF groups and someone brought up the crypto forum group earlier and that\u0027s been enough that someone brought up the crypto forum research group earlier what one of the difficulties with that group has always been knowing precisely where its boundaries lie and what\u0027s what what\u0027s research and what what\u0027s the standards and I think I think they generally get it right but it\u0027s always something that they have to be very careful of so I think if you\u0027re going this way I think it\u0027s a good thing but be careful of the scope thank you so much for that discussion you\u0027ll have to continue this later in our list or in Singapore but they\u0027re going to move on next to Neil\u0027s presentation on bbr Oh Steen testing there we go okay hi I\u0027m Neil Cardwell I\u0027m gonna talk about VBR version two a model based congestion control give a quick update of some work that is going on in our group at Google this joint work with each on in sohail Priya Ranjan you suck Ian and Victor and bin and Matt and Van Jacobson just a quick outline wanted to talk about an open-source alpha or a preview release that we sent out last night we\u0027ll talk about the status of the code some quick lab test results to give a flavor of the behavior and and where we\u0027re trying to head and then talk about the deployment status at Google and wrap it up so we\u0027ve just yesterday released an open-source alpha or preview release of the TCP BB r v2 code and the quick release is coming very soon as well I "
  },
  {
    "startTime": "00:20:09",
    "text": "think probably later on today and the goal here of this particular release is to enable research collaborators to do some testing try out their ideas get more real-world test miles on PBR and we encourage researchers to dive in and evaluate the algorithm the code help improve the PBR in general and of course we welcome patches with solutions to issues that were aware of and issues that researchers find along the way the slides have the URL with a hyperlink that you can drill through to get to the TCP and quick versions of the code and in particular I would also note that the TCP source tree there also includes the scripts that we use to run these tests and generate the graphs for this particular slide deck so that people can see what the details are and use those as perhaps a starting point for experimentation and I would just remark that these tests are using network emulation using the Linux net m-q disk and for an algorithm for an overview of the algorithm itself I would point people to the slides in the video for the IETF 104 presentation as well as some discussion in the IETF 102 slides as well so what\u0027s new and and what\u0027s changed between BPR version 1 and you are version 2 we\u0027ve talked about this a little bit before but just to sort of recap the properties that we are maintaining between version 1 and version 2 are obtaining high throughput with a targeted level of random packet loss and also being able to bound the amount of queuing delay that a flow is is causing despite the fact that it might be traveling through a very buffer blooded path but then the improvements that we are looking at from version one to version two as we\u0027ve discussed at the previous IETF include first improved coexistence when BB rb2 shares a bottleneck with we know or cubic much lower loss rates for cases where the bottleneck buffer is on the smaller side on higher throughput for paths with high degrees of aggregation which is common with Wi-Fi bottlenecks DOCSIS cellular they all use a lot of aggregation v2 includes support for DC TCP or alpha s style ecn signals and we\u0027ve also reduced "
  },
  {
    "startTime": "00:23:10",
    "text": "the amount of throughput hit that the flows take for entering the probe RTT phase where the flows try to cooperate to expose the min RT t of the path and so in the following slides we\u0027ll run through a few tests just to sort of illustrate the the general flavor of the behavior and illustrate some of the core properties that we\u0027ve maintained or and in some cases added to v2 and throughout these the metrics that we\u0027re looking at include throughput cueing latency retransmit rate fairness that sort of thing so just a tour through some some lab test results so first if we think about surviving random loss v2 continues to maintain the property that v1 had that it\u0027s able to achieve high throughput even with a targeted level of random packet loss so here\u0027s an example of an experiment where we take either we take one flow and it\u0027s either cubic or bbr or BB our version two and we send it through an emulated path where the link bandwidth is one gigabit the min RTT is hundred milliseconds as the bdp of buffer and then we do a bulk transfer with a particular level of random packet loss spanning orders of magnitude to the x-axis is log scale here so we can see that you know cubic is achieving low throughputs as is well known it\u0027s very sensitive to packet loss whereas PBR version one is achieving a high throughput up to about fifteen percent loss rate we\u0027ll sort of see the the corollaries of this in some of the follow-on tests but with PBR version one that level of loss tolerance is sort of implicit in the magnitude of the bandwidth probing that it\u0027s doing by contrast PBR version two is an algorithm designed around including an explicit loss threshold of a level of packet loss that it\u0027s trying to target so for example here the sender was configured with a loss threshold of two percent which means that if the short-term or sort of instantaneous loss rate that its measured of the last round trip time is is two percent it takes that as an explicit hint that that\u0027s an operating point that is has too many packets in flight and so well and it\u0027s bandwidth probing and then try to leave some Headroom in the in the path for other flows to obtain so that\u0027s why the curve has this shape here so you can see at low at low random loss rates it\u0027s achieving high throughput but it\u0027s not quite as high as BPR version one "
  },
  {
    "startTime": "00:26:11",
    "text": "because it is trying to explicitly leave some Headroom in the path or other flows to discover available bandwidth and to keep queuing and losses low and then you can see that the VBR version to throughput sort of it\u0027s reduced right around the the 1% to 2% range there which is because of that explicit loss threshold of 2% why does it fall off at that point well the if you sort of configure 1% random loss then you know obviously the losses are gonna vary round-trip two round-trip time so you get this sort of falling off in this flavor so that\u0027s that\u0027s one example another here if we take a scenario where where we\u0027ve got a bottleneck with with deep buffers one thing one property that we\u0027ve carried over from b1 to b2 is that PBR is able to use its model of the network path and generate an estimate of the bdp of the path and then bound the in-flight data based on that estimate to keep latency queuing latency reasonably low so here\u0027s a test that\u0027s very similar to test that we showed way back in IETF 97 so this is showing either 2 cubic or two VBR or BB are two flows entering in staggered times the link bandwidth is 50 megabits minar tt\u0027s 30 milliseconds and then we run a ball test for a while at various buffer depths and here on the x-axis is the buffer size as a multiple of the BDP and then on the y-axis is the median smooth round trip time sample that we obtained and you can see you know as well not as is well-known cubic will sort of fill any buffer you give it quite quickly and sort of hang out at that buffer occupancy so as the buffers are bigger than your RT T\u0027s are always bigger whereas vvr version 1 and 2 no matter the buffer depth they will have their estimate of the bdp and they\u0027ll bound their in-flight based on that to keep the latency within a more reasonable range so something new in MPP our version 2 is support for DC TCP or l4 s style ecn signals so I have a couple slides here with an experiment with that kind of ecn so the emulated scenario here is a one gigabit path with the one millisecond round-trip time so a more of a data center style scenario their bottleneck here is has a essentially a FIFO with the maximum depth of 1,000 packets which is 12 milliseconds at this bandwidth but the interesting thing here is that it\u0027s doing DC TCP or l4 s style ecn marking it on packets that had more than a 242 microsecond sojourn time "
  },
  {
    "startTime": "00:29:13",
    "text": "which is basically saying once the queue gets to be 20 packets or more then there\u0027s a sort of step up and you get ecn marks on on packets for queues of that length or longer and so the behavior we can see here in this kind of scenario is that for BB our version 1 it doesn\u0027t use ecn and so as you add more flows on the x-axis you can see that the queues get quite long and in fact tend to hang out right around 12 milliseconds and that\u0027s largely because the this test is only 10 seconds and so the flows are unable to sort of loosely synchronize and coordinate to expose them in RTT of the path and so BB ours is unable to bound the in flight in a in a way that we\u0027d like and on a experiment this chart by contrast if we look at DC TCP and BB our version 2 they were able to use those ECM signals to keep the queue right around the EC n marking threshold for smaller numbers of flows and only had very large numbers of flows do you start to see it make excursions above that target range with BB r2 being slightly more aggressive in its probing and thus having slightly higher RT T\u0027s with larger numbers of flows if we look so that\u0027s the latency picture in this kind of experiment we look at the loss rate picture it\u0027s even more dramatic notice we\u0027ve switched to a log scale on the y-axis because the the VBR version 1 B because it is not doesn\u0027t have time to learn them in RT t of the path it allows the queue to be quite long and the in the retransmit rate is it\u0027s just about 10% at higher numbers of flows whereas of course the BB r2 and DC TCP flows are able to maintain very short queues most of the time and have retransmit rates below a tenth of a percent so in the next experiment we are illustrating another component of the BB are oh yeah of course like sure does the fact that those plots any stuff at the start at 10 mean it was 0 before 10 yeah because of the log scale I was unable to get the zeros to show up but yeah if with one flow of course you see TCP and BB are to have the zero zero drops oh they were I only tried what I do I did one for 10 40 and 100 so at 1 \u0026 4 flows they had zero drops so another property of BB our version two is it has an explicit strategy for coexisting with with Reno and cubic flows within a particular performance envelope and this slide is just to sort of illustrate the "
  },
  {
    "startTime": "00:32:14",
    "text": "flavor of that obviously if you\u0027re talking about is to do a complete evaluation is a very large and dimensional space lots of tests you need to run but this is just one to illustrate some of the key dynamics here so this is a bulk throughput test where there\u0027s one cubic flow and one flow that\u0027s either media or VBR version two it\u0027s sort of the 15 mil 50 megabit bottleneck with a 30 millisecond 30 millisecond mid RTT and it\u0027s a three second bulk throughput test with varying about far depths here on the x-axis and then we\u0027re showing the throughput of the bbr version 1 or version 2 flow and then basically cubic gets the rest so we can see here at at lower buffer depths bbr version 1 grabbed you know sort of 43 to 45 megabits it whereas bbr version 2 because it has an explicit strategy about how it\u0027s going to probe for bandwidth and bound it\u0027s in flight it\u0027s able to have a throughput that\u0027s much closer to the approximate fair share they\u0027re reasonably low buffer depths and of course as the buffers are deeper and deeper the cubic tends to build such an enormous queues that be be our throughput does tend to gradually fall off as the buffers are deeper and deeper but we expect in the in the common case the the buffers should tend to be around one BTP or to be DP and in well provisioned networks so we expect that the common case should be quite reasonable so another aspect that we wanted to highlight was that bbr version 2 because of it uses loss as a signal and uses that to dynamically adapt the amount of in-flight data it\u0027s willing to maintain it has considerably lower loss rates than v1 in shallow buffer situations so in this experiment we\u0027re looking at the retransmit rate for an ensemble of bulk close the here the link bandwidth has a gigabit min RTT is 100 milliseconds it\u0027s quite a big BDP and then it\u0027s a five-minute test and the buffer here is very tiny relative to the BGP it\u0027s about 2% of the bdp but that can be quite representative of the situation you have if you build a high speed when out of commodities which is with shia labeouf errs this is the kind of scenario that the flows will need to deal with and so here we can see that cubic by virtue of its design and sensitivity to loss keeps the loss rate quite low BB our version 1 "
  },
  {
    "startTime": "00:35:16",
    "text": "because it is agnostic to loss and because of a couple other factors tends to have tends toward a 15% loss rate if there are large numbers of flows and you can see that in the PPR version one line or by contrast PPR version two because of its model is more rich and includes loss as a signal to feed that model it\u0027s able to keep the loss rates bounded in the region that is below its targeted lost threshold did you was there a question that you wanted okay thank you so those are the labs lab tests that we wanted to sort of run through to convey a flavor obviously this is is algorithm and the code is still a work in progress and obviously more tests will need to be run but we wanted to sort of convey the the flavor of where we\u0027re at and where we would like to have it in the properties that we\u0027d like to maintain and to add so a quick note on the status of the the algorithm in the code so um there are some remaining issues that we are aware of in the PPR B 2 algorithm where we\u0027d like to improve things it can happen that flows that experience ecn or loss early on in their lifetime but never thereafter sometimes don\u0027t reach their full fair share we can have Q pressure that\u0027s higher than desired when there are large aggregates of the BRV 2 flows and we can and it\u0027s also case that the the ecn response is not really well tuned for both for very long our TTS in the hundreds of milliseconds and it\u0027s also not quite tuned for cases with more flows than slots in the bdp and I would note that both of those issues are sort of shared with DC TCP which is also so far intended and and deployed so far for cases within a data center so these are sort of not problems unique to PBR version two but sort of more general in the ecn ecosystem and I\u0027m glad that there are people doing work on in this area and the l4s community and of course we\u0027re continuing to refine the algorithm and we welcome ideas about how to handle all of these issues so where are we in our deployment with this code as I mentioned in March we do have a global experiment running on YouTube for a few percent of users and what we see so far is that it it\u0027s has much lower queuing delays than cubic and even slightly lower than PBR version one it reduces considerably the the packet loss rates versus V one and gets them closer to cubic then then V one we\u0027re also using this code internally in "
  },
  {
    "startTime": "00:38:16",
    "text": "experiments between and within some Google Data Centers and what we\u0027re seeing there is that bbr v2 has lower tail latency compared to the previous DC TCP style congestion control that was it\u0027s deployed for TCP within Google Data Centers and we also in our deployment and testing we found in really interesting performance issue with the linux AK implementation that turned out to be a surprisingly high impact issue for for data center performance which we can talk about offline but the basic flavor is kind of inch seeing where the the Linux acknowledgement code actually does not just check to see if you\u0027ve accumulated more than one MSS of unacknowledged data it also wants to be able to advertise a receive window that\u0027s as big as the previous receive window it advertised which essentially means that it very often ends up waiting for the application to read all the data out of the socket before it then sends an acknowledgement advertising the same and I can see Matt frowning over here and then it before it decides to send an acknowledgement which can sort of include the application in the RTT loop of the congestion control and cause some serious latency issues anyway that was an interesting issue and it\u0027s it\u0027s a common issue too in the core TCP stack but we happen to run into it during this testing of this transition we can talk about it offline a few queries anyway we\u0027re continuing to iterate using both production experiments as part of the gradual rollout and also control lab tests so in conclusion we\u0027ve open sourced a first sort of alpha alpha or preview release of PBR version two it\u0027s ready for folks to take it out for a spin in a research experiment context and we obviously invite researchers to share ideas for test cases or test Suites metrics that they think we shouldn\u0027t be looking at sharing their test results is great we\u0027re more than open to algorithm or code ideas or patches and we\u0027re always happy to look at packet traces if you\u0027re taking a first bin and run into a surprising issue and in conclusion work on PBR V 2 continues both at Google and we\u0027re also in communication with the FreeBSD TCP team at Netflix who\u0027s also working on bbr as well so yeah any any questions or comments thank you so Goering Fair has thanks for bringing "
  },
  {
    "startTime": "00:41:17",
    "text": "this here because it\u0027s significantly different to the previous bbr instances and it seems to be having a really good way how much ditch have you on different experimental results in your labs because it looks like your points didn\u0027t have a confidence intervals or anything so I\u0027m kind of wondering whether you to lots of different snares different delays different traffic mixes or whether it was really just a first cut yeah I think I would characterize this is the first cut to give a sense of the flavor of the behaviors that we\u0027re looking for the properties that we\u0027re looking for and I I agree and take your point that a congestion control needs a lot more experiments than the ones we showed on the slide before you say you know you\u0027re ready for yes to illustrate as I said I\u0027m pleased you brought this here I\u0027m curious about the high RTT thing because I\u0027m I have size later on in the ITF about high RTT and other things you think there\u0027s a way we could look at high RTT in this and figure out what to do you mean for the DCN in a high RTT question yeah yeah absolutely so the I think the direction that we so I actually haven\u0027t in I\u0027m working with an intern right now to actually do experiments in this direction the I think my hunch is that what makes sense would be to include a response to ecn that is in the rate space so that flows with different itt\u0027s as if they\u0027re responding in an in the rate dimension then everybody can respond in a similar way despite having different itt\u0027s the issue with long RT T\u0027s and C purely see you and based algorithm that sort of happens immediately is the the long RT t flows in the stream of ecn signals they they get will sort of see an oscillation between EC unmarked and clear and it can happen on the scale of milliseconds but if you\u0027re RT long you know if you\u0027re art 100 milliseconds you may see a whole saga of up and down and up and down but that means that every RTT of yours has ecn marks and so using a classical style algorithm you do multiplicative decrease every single RTT of your life until you converge down to a Sealand of two and if you\u0027re sharing with a flow that has an RTT of 50 microseconds and it has a Seawind of - it\u0027s quite happy it\u0027s got a nice high throughput if you\u0027re but obviously if you\u0027re RTD 100 milliseconds you\u0027re Sealand of - makes you very unhappy so but I think if if all the flows are responding in rate by reducing the rate that might allow us to have good solution here I think that\u0027s fun look to see more of them okay thank you thanks Neil Martin Duke first question are you planning to do a draft of v2 and if so how long you wait yes so we are "
  },
  {
    "startTime": "00:44:19",
    "text": "one of our next to do items now that the code is out there is to update the internet draft that currently is describing v1 and update it to cover v2 that is definitely something we agree is important and we know it\u0027s particularly important for folks that are part of the open-source ecosystem so we\u0027re yes that\u0027s on our to-do list we actually independent implementation we find it very useful to have 60 points like the drafts rather than just trying to track your code sure seven question could we return to the loss versus throughput graph which i think is the first graph yeah yes okay so I I\u0027m not sure I fully understood what you said here so the cliff at 2% is a purely there\u0027s a lot of configuration parameter that\u0027s right that\u0027s right okay so so that\u0027s fine so if you didn\u0027t care about loss rate you could just turn it up to I guess that\u0027s 20 and you would essentially match the BB r1 curve at least where the cliff is I believe so yes okay so but going all the way to the left edge of the graph you\u0027re sacrificing about 10% of your throughput and is that so what is the trade-off there is that you are friendlier to cubic in that regime the so the the basic flavor there is that PBR b2 is trying to leave some Headroom in the system either in free slots in the buffer or free slots in the wire so that newly entering flows can grab some bandwidth without causing massive packet loss and so that flows with lower throughput can increase can discover that more bandwidth is available again without causing massive packet loss so the the this is kind of similar to for example the the rapid convergence mechanism in cubic where if cubic thinks that its fair share is falling because somebody else is entered then the cubic curve actually sort of spends a lot of time at 85 percent of the previous W max instead of 100 percent in order to leave the headroom for other flows to sort of discover that there is more bandwidth available so mostly fairness but you\u0027re also gaining a some RTT benefit yeah exactly so this is primarily been motivated by fairness but also it reduces Q pressure and lean C impact loss it also to pointing in the [Music] yes okay so first question is why the traditional choices for buffer sizes I "
  },
  {
    "startTime": "00:47:19",
    "text": "noticed that you went from one time VDP to about 100 times B DP and for shallow buffers point two so the question is why didn\u0027t you sell in those sizes we came out the tits it was catch a question it\u0027s a going back in here um we lost but I mean if you can mute your mic when you\u0027re not speaking that would be helpful so if you come back on the meanwhile Jake okay yeah I J holin with regard to the l4 s style ACN marking that\u0027s referring to the the receiver response being 1c he bit her or ze mark or is that yeah it\u0027s her so it\u0027s referring to both the fact that it\u0027s expecting the ecn marks to happen at a low threshold of Q and the fact that we are expecting the receiver to reflect the EC on marks on a sort of per packet basis rather than echoing the see e marks as having been experienced for an entire round trip time and until that\u0027s acknowledged with the CW are a bit so it\u0027s the essentially DC TCP style or ecn yeah did you try the easy end with the with like the home routers that do the marketing person uh no we haven\u0027t tried that yet my men just standing is that most of the home routers that do easy on marking our RFC three one six eight style it\u0027s so and we don\u0027t really intend to have B BRV to use that style of EC on yeah okay thank you thank you yeah sorry Praveen is trying to get a headset so if you can do the Arlette but stuff first and then come back to proving data so we make that part of these work it\u0027d be better if we could do thanks again me the plan was to have that that because I like that sort of builds on that what do you think Marcelo it doesn\u0027t work for you right "
  },
  {
    "startTime": "00:50:29",
    "text": "well gates he said he would also be willing to give it a shot without an headset but I\u0027m not convinced that it was but then he won\u0027t hear anything from us if you want to stop if you want to give it a try you can give it a try I mean probably hearing this if you want to give it a try come on let\u0027s give it a shot because it might be better if Marcelo follows you can you hear us yes very need your mic first so if you can speak if you can move you Mike now try questions I think that\u0027s perfectly alright this is not a long talk no you audios freaking super badly okay so let me try to figure out that sub situation then and you can both Marshall first so you can you move back from the mic just a little bit can you hear me now okay let\u0027s do that and I\u0027ll be more than are like that and we\u0027ll see when yeah that\u0027s it okay yeah okay good afternoon I am Marcello Angelo and I\u0027m going to talk about receive based LED but mechanism this work that we have done with Alberto Ana Praveen Daniel and Gabi so I guess well more or less "
  },
  {
    "startTime": "00:53:33",
    "text": "so I guess everyone won\u0027t know here knows what LED but is right I\u0027ll let buddy is a congestion controller that provides less than my best effort essentially defines a queuing delay target team right and increases and decreases the congestion we know based on whether the measured queuing delay is above or below the target all right the queuing delay space the Qun will delays inferred from the one-way delay experienced by the packets so let but there has been a few shortcomings identified regarding LED but in particularly exhibits or internet but fairness properties and they have been reported difficulties measuring the one-way delay in particular in tcp even if you use the tcp time stop option right the reason for these are several including the fact that you don\u0027t know what the time the timestamps are expressed on and also that when you have clock drift it\u0027s very hard to measure because because you\u0027re using this you\u0027re using these measurements in order to try to determine how much you\u0027re sending it\u0027s hard to distinguish error from log right so actually yes thank you okay sorry well not so what we were proposing here is a receive driven version of late right so the idea that we are proposing here is we\u0027re going to make a congestion controller that runs on the receiver right that is less than best effort is inspiring LED but well it\u0027s very close to let but plus plus that\u0027s why it was interesting for Praveen to present LED but plus plus before him and I present this first but later but that\u0027s fine right so the idea here is a congestion control would run in the in the receiver and the receiver we contract will control the sender through the receiver wind okay one significant change is that we\u0027re going to measure the RTT instead of measuring the one-way delay so we\u0027re going to estimate the queuing delay using the RTT rather than the one-way delay so what are the motivations why we want to do this so so we have essentially three motivations to regarding deployment models one is this is widely use for distributing operating systems updates right some operating systems updates are being done through syrians and there have been observed that in many cases CDN surrogates do not support LED but and also it\u0027s hard to "
  },
  {
    "startTime": "00:56:35",
    "text": "convey well there is no signal in to convey if they did support that but which content must be distributed using TCP cubic and which one could be distributed using LED right so the situation is that the operating system gets uploaded to the CD to a CDN using LED but because the the source actually supports that but but the distribution from the CDN surrogate to the client is not benefiting from Lebanon right if we have a receive based version of LED but this could actually enable the transfer using LED but from the pseudo rate that is oblivious to led but to the client who is actually will be controlling using less advanced effort congestion control and a similar situation of course when you have something like a proxy or a firewall or stuff like that that terminates the TCP connection right so the leg between the source that is using LED butt to the proxy is protected by LED but in the sense that it is using LED but but the leg between the proxy and the final client is no longer using it right so if you have a receiver receiver driven version of this this would enable the use of LED but in the second leg right and the other one is regarding how mobile device for instance in this case right that is downloading content from multiple sources could actually enable some way of distinguishing priorities if you want or what type of what type of traffic is willing to devote more to most of his bandwidth right so let\u0027s suppose in this case that you are you have a mobile phone you\u0027re having you\u0027re watching a video and then you receive what\u0027s up call one thing that you may want to do is use humming in general when you\u0027re watching the video use TCP and then if downloading your files or whatever using TCP and then when you\u0027re when you\u0027re a phone call comes in you may want to start using less than best a for for and your background download all right so if you if you are able to if you enable the the the end the end the client to determine which flows are led but and which flows are a regular TCP then you will empower the the client to manage its incoming link capacity by a seer assigning different congestion controllers to different to different flows right so these are the three main use cases that we have in mind CDN distribution proxies and enabling the user to define its references by setting different congestion controllers okay "
  },
  {
    "startTime": "00:59:37",
    "text": "so this is in general about the algorithm piece probably falls more into a lead plus plus but the the goals for the design is basically essentially what I what I assumed the original lead bath designs goals word that is if you have some latency sensitive delay sensitive traffic like voice when you\u0027re using lead but it should not add I mean the delay that it adds should be bounded to some target right if you have several lead but flows they should be they should that should be fair between each other right they should equally split the traffic if you only have led but it should be able to use the full capacity of the link and if you have if LED but is competing with standard TCP by step or type of type of congestion control then basically let that should move away and give most of the capacity to the TCP flows so the algorithm that we\u0027re proposing is essentially we are using the the round tip time in order to estimate the queuing delay so we measure the base Rowntree time as the historical minimum and we measure the current round-trip time as a filter off of last few samples we estimate from that the current queuing delay we define a target for what should should be the queuing delay and we essentially build an ideal increase multiplicative decrease based on the on how much you are a above the target right so if you are above the target you you you do if you\u0027re below the target you doing a naive increase if you\u0027re below the target you do a multiplicative decrease okay so this this was most about like that plus plus that is the the congestion control itself then I\u0027m going to dive deeper into the details on how do you do it from the receive side all right so we\u0027re going to do this controlling the receive window so the first observation is a received window has already is being used for something right you use it for flow control the idea here is you will calculate a congestion window on the receiver you\u0027ll obtain a value you will obtain a value from the flow control right and you will convey the minimum value of the two so you one or both flow a flow control and the congestion control on the receiver the idea here is that usually the the flows are not limited by the flow control in general so the the limiting factor should be the congestion controller running on the receiver so essentially the receive window will in generally express the congestion control "
  },
  {
    "startTime": "01:02:39",
    "text": "wind right the interaction with the sender\u0027s congestion control again because the window actually used by the sender is the minimum of the congestion window and the receive window because the receive window is carrying the the the LED but the lab but calculated window n LED but will be more aggressive in reducing so it\u0027s likely to have a smaller window than normal congestion control what usually will happen is that the LED bad congestion control will take over and will be the one prevailing because it will be the one expects pressing a smaller window so the other thing that we need to take care if we try to do this is we should avoid shrinking the window right because we have this multiplicative decrease what may happen is that at some point we need to express our window that it\u0027s has previous value right this is likely to be in most cases more than the number of bytes the I mean the amount that you need to receive and to reduce the window is likely to be more than the amount of lights that you have we seen the packet that you will send the ACK for so if you actually reduce the window in hive right away you will end up shrinking the window which is not recommended so essentially what we\u0027re going to do is we\u0027re going to drain enough packets from the in flight in order to accumulate enough space in order to be able to reduce the window without shrinking right this this can be done because you don\u0027t do I\u0027m going to placate it decrease more than once per round trip time right so essentially because you only reduce it once at most once per round the time you have enough packets to drain in order to then be able to express whatever window you want smaller than it is so that that that should be feasible and then the other problem that actually media suggested when I was talking to her about this for a while ago is regarding windows scale-up ships right window scale is as you probably are aware of I change of the units on the that you express the receive window right so actually window scale values between zero and one result in units that are less than the usual maximum segment size all right so you see that that\u0027s not a big problem because usually you want to decrease your window size or increase your window size in one MSS I mean or more or less right if you have values that are larger than 12 12 foot basically will be twelve thirteen and fourteen that basically implies that one change in one units in the in the receive window will be more than one MSS right in that may generate problems in "
  },
  {
    "startTime": "01:05:39",
    "text": "the sense that your congestion control now is much more coarse because the units it can express itself are much larger than one MSS right so we have make a set of measurements we have observe that values between 12 and 14 are very very rarely used today right they exhibit a bunch of other problems regarding window shrinking and and and other things so I guess that\u0027s that\u0027s the reason why we are not very used today [Applause] we wouldn\u0027t I mean if we want to vote that down this path we will need to probably do a bit more experiments regarding the stability and and how expressive the the congestion control will be if you use these larger values in any case in any case the value of the window scale is set by the client so the client could actually set whatever I mean values between up to eleven right if he\u0027s trying to use lead but a roulette pot and that doesn\u0027t impose any conditions on the traffic in the other direction so that can be another way of working around this so as I said we\u0027re using there RT teens through the one-way delay [Applause] doing this has a fundamental problem that is you include the queuing delay on the reverse path there\u0027s nothing I mean I don\u0027t think there\u0027s much we can do about this oh I haven\u0027t come up with anything we can do about this this basically means that you will be overly conservative that you will react also to congestion in the reverse path that\u0027s that\u0027s it right and we need to deal with a few other issues in order to to make this work in particular a fairly common case I guess it will be peer receivers in the sense that you\u0027re only receiving packets and you\u0027re not so if you\u0027re only receiving packets if you want to measure the rounding time you cannot send it and match it with the ACK you will because you\u0027re only receiving packets and sending acts in order to do that we will use the the timestamp options to match acts that we have sent in packets that are coming back data packets that are coming back so that that should work the other situation that we may have because we are handling pure receivers is that because we are going to match an AK with a packet we may have an artificial increase RTT because the source is not sending packets right so there are we have identified two reasons why the source is not sending packet one is because it has no data to send well in this case either you don\u0027t care because you\u0027re not managing anything because there is no traffic or either this happen once in a while for instance you have blocks of the that you\u0027re sending right every time the block ends you have some times of period without data the way we deal with this is essentially we filter so instead of measuring the current mounted time you "
  },
  {
    "startTime": "01:08:39",
    "text": "do a filter of the last 10 packets so probably you get rid of that sample that is that is that it\u0027s outside that has this artificially increase RTT right so probably that that should work and the other case where you may the sender may not be able to receive later is because you are clamping down the the the the receive window so if you are artificially telling him that he can not send because you\u0027re reducing the the receive window he won\u0027t be able to send and at that point you the rtt will be increased because you\u0027re not allowing him to send it but that\u0027s fine because you actually know when you\u0027re doing that so you can simply avoid measuring while you\u0027re reducing the the receive window right so you can accommodate for this the other problem that we have encounter while doing this is regarding the real reality of the timestamp values right the timestamp values have depending on the clock but you use for that has a given the molarity you may end up with multiple packets going with the same time sample all right so that that makes harder too much because you don\u0027t know which one matches with which one because we don\u0027t really need to measure all that all the packets just what we simply do is we might we measure the first one right the first time stamp that we send we are you in value in the first one that that would receive with the same value and we drop all the other samples that we have right and that gives us an proper original measurement of the of the rtt so molar design choices internet what furnace has been addressed using multiplicative decrease that has been I mean this there is there is a paper that explains why this case I mean I guess is fairly well understood reacting to packet lost what we do is similar a slit but we do a multiplicative decrease the coefficients for multiplicative decrease regarding time and regarding loss don\u0027t know do not have to be same I mean we actually play with different values right so you have a multiplicative decrease a parameter for loss and for time right regarding bootstrapping what we do is instead of starting the problem here is how do you manage to to to ramp up right what we do here essentially we start with whatever flow control whatever window the flow control gives that is usually a large window right and that basically gives enough room to for the for the for the sender to to ramp up and then we take it from there and regarding path changes what we do is the same thing that led but does that is we keep a history of the last I don\u0027t know 10 minutes and in order to forget L I mean we only keep the history for 10 minutes so we forget measured values that are older than that so if we change path we only keep the old path for 10 "
  },
  {
    "startTime": "01:11:39",
    "text": "minutes so we have implemented this we have run a bunch of experiments the the experimental setup is is very simple as you can see we have two clients we have two servers the clients are running late but or or else this is there\u0027s a few results that we have so for instance in this case what we have is a voice call that is using you have a base delay of 50 milliseconds you see observe here at the beginning that the voice is experienced the 50 milliseconds plus a bit of delay in this case you see are led but kicking in we have a target of about 100 milliseconds with almost there most of the time right and essentially we keep we show that that it keeps the the delay bounded when a LED butt-kissing bigger than internet but fairness what we have here are two are led but flows we have one that is using most of the capacity when it\u0027s alone right the second one kicks in they somehow managed to agree in a regional liquid split between regarding solo performance when are led but is alone the capacity of actually using the whole capacity of the channel depends on the the different set of parameters that you choose we I mean all these experience have been done with a with a given set of parameters that we somehow analytically obtain and what we observe is that roughly if the if the if the ramping time is not very very high you manage to be somehow near full utilization of the link as the round-trip time increases it has harder time reaching to the full utilization again this is depending on the relationship between the multiplicative decrease parameters and has a relationship with the with the fairness issue right interferes with TCP so there are two modes of interference with TCP either you\u0027re working you\u0027re reacting to losses or you\u0027re reluctant to delay that really depends on the size of the buffer of the bottleneck right if you\u0027re reacting to delay right if there is enough buffer in the bottleneck so that you measure the the target T you observe here that essentially you have our LED but then TCP kits in unlit but goes way down it just basically stays with one are a congestion window one gives all the rest to TCP and then when TCP disappears or LED but kicks in again and if there is not enough buffer in the in "
  },
  {
    "startTime": "01:14:40",
    "text": "the bottleneck in order to observe the target delay then both of them will react to losses but because of the parameters that are led but is using are much more aggressive that the ones that TCP is using what we observe is that led by a LED but uses more than what it used when it has a relay base but overall it leaves most of the of the capacity to disobey so okay so the other thing that we have done is we have played with LED bad plus plus stuff that Praveen we will present and essentially when they are both competing they play nicely with each other more or less right when TCP enters both of them disappear most and then when TCP goes away they they they they share again the capacity equally between okay and then in order to wrap up I mean I was wondering if this is the type of stuff that I see TIG would be potentially interesting working on Thank You Marcelo I just change that question a little bit and see how that people here would like to be good be interesting working with Marcelo even important at least in my mind it would be cousin seeing something like this deployed but yes questions we have a just a few minutes J holin this is very cool work thank you I might be I\u0027m not sure I had time but I might be interested in like me that\u0027s the I guess that\u0027s all I want to say for now thank you Thank You Neal card well I think this is this seems like very interesting and generally useful work is this add a couple of questions is this work so far in a simulator or with no no this is this this has been done in and I mean we have a Linux implementation on this and we have a bunch of virtual machines and and I mean a little icing barked okay okay and then maybe you mentioned this but I missed it what what how do you imagine picking the delay target or delay budget I\u0027m sorry once again how do you what\u0027s the plan for picking the delay budget so what we have done is as lame-ass using the leg but one okay that it\u0027s a hundred milliseconds the praveen has been using 60 milliseconds in in in that in Inlet but plus plus so I mean "
  },
  {
    "startTime": "01:17:42",
    "text": "okay thank you I mean there is some rationale in the in in the receive all why hundred millisecond make sense and there is some rationale why I\u0027m just leveraging on on them to to do yes Johan actually I also like this work because some we have similar sorts but different quite differently my questions are is any plans you know like can work for you seen signals or something sorry I came up here you okay my questions and Rachel then the thoughts in the future that could you know also works together is easy and signals with ECM signals and so we easy Ennis if I understand it correctly it will essentially be the same as US law so the response to this will be the same as as loss right so I mean I understand that what led but does yeah sorry no I\u0027m asking media let but reacts to to ecn Marxist and same as losses okay let but is that you usually try to avoid losses and also try to avoid a situation where geteasy anything else but if you get easy and singers it\u0027s the same reaction and it\u0027s the same reaction as we knew right answer the other question about the delay target so this whole thing was was proposed by patron at some point and they also had a lower delay target at the very beginning and then they increased the 200 milliseconds at some point because their scenario was mainly to avoid a congestion in the basically in the home router where the buffers are usually very big while still having a reader like behavior in the core network where buffers are smaller and you can compete like equally and the right rational which is in the draft is that you want to stay below 150 milliseconds because that\u0027s the maximum you can cope with for like any kind of interactions between humans Thanks and thank you so much Marcelo please find them and talk to them if you\u0027re interested in more work and I\u0027m hoping that this actually gather some steam because I think this is a very different type of work in that it\u0027s receiver side and I do think that there\u0027s a lot of value on this motivational muscle dimension are very important so thank you again for the work and for presenting it you\u0027re gonna move on to the last presentation which is praveen probing can you come up with and hopefully we can do this the wrong trevean okay I\u0027m gonna try without the camera if you can hear me please say yes we\u0027ll just give it a "
  },
  {
    "startTime": "01:20:42",
    "text": "movements till you try to get protein yeah can you hear me yes yay sorry for the mishap there with the headset so could do this without video can we get easier so this is plus plus condition control for background traffic this was originally presented in IETF 100 that presentation included some test results and graphs today I\u0027m going to skip over them because of lack of time but this is not a recap the algorithm and then I\u0027m going to talk about next steps so let\u0027s go to the next slide so this is a quick recap of what led by RFC 68 17 said it\u0027s a less than best effort congestion control algorithm applied on the sender as opposed to the receive set presentation that muscle adjusted the goal is to compare it\u0027s a deal in this condition control algorithm so you measure the minimum observed either over an observation window if the currently observed delay is less than your target then you increase the condition if the delays higher than target then you decrease the condition window the original actually did not have any strict requirements of slow start there was a solution to avoid it and it also reacts for packet loss because the goal here is less than best effort so reactive packet loss and other condition signals just extended TCP next by P 3 so we found about your progress with led by both documented and existing research as well as powerful our own experimentation so some of the problems with TCP one of the problems is one big data measurements there is no standard clock frequency and there\u0027s also like a clock skew problem so we could come up with like custom schemes to solve this but those are very difficult to get right in practice the other problem that like that has is a late comer advantage so one flow starts early then like that enters the networking later there it measures a higher base degree and it will inject more nearly into the network it will not be able to detect that there\u0027s other traffic and back off there\u0027s also a well known interred like that fairness problem there\u0027s a paper there that you can refer to so if you have multiple that but close it because it results were stable q but there\u0027s no fair sharing and of course the problem with slow start you know what should be done for like background connections there\u0027s also latency tough problem which is very interesting favor very not running late bad connection which is possible with like you know large background transfers file uploads photo uploads and such the connection keeps measuring a higher base delay over a longer period of time this ratcheting effort effect is very easily reproducible in by even in that measurements and then that\u0027s the lower latency competition problem so if if the link is actually very good and the latency is very low then the target "
  },
  {
    "startTime": "01:23:42",
    "text": "either has never reached so let bat compete very aggressively with standard easy so away with let y plus plus first will solve all of these problems next five weeks so this is incremented currently as a condition control algorithm for TCP in the Windows operating system the enhancements over that bad are these from annex though instead of using one waiting the measurements means round-trip time measurements we do know slower than we know condition window increase so there is a adaptive factor that we introduced for ramping up much slower than standard PCP similarly when we get to last the decreases multiplicative but the the reduction factors are in adaptive and then the slowstar is modified in several ways to be slower than Breno as well as to incorporate mechanism that very similar to hi start we use DNA as a signal to exert slow start and the most interesting one is the initial and periodic slow down because the some of the problems mentioned require measuring a very accurate base daily for that you need to eat traffic so that you are able to measure the accurate base level this has been shipping as part of Windows for a while it\u0027s currently used by several scenarios pretty broadly deployed at this point next bit please so why don\u0027t time let\u0027s see it\u0027s pretty easily available is already implemented in TCP of course the disadvantage is that we would measure during both productions because but because this is a less than best effort algorithm it\u0027s okay to be more conservative than what you ideally like there\u0027s of course the other problem of receiver anyways and delayed action TCP which to be accounted for if you measuring round-trip time so some of the medications for these problems are to enable the TCP time stamp option by default and to filter the RTD samples this is actually a solution from the addition of lightweight RFC so pick the minimum of the most reason for RTD samples and use a target delay of 60 milliseconds this value is very deliberate I noticed there was a discussion about this in the analyte representation but this value is very deliberate so because of why they accept everything is 150 and if targaryen hundred milliseconds system is very little room for on the other delays a propagation delay is 0 degree so that\u0027s why we pick the value of 60 milliseconds and it\u0027s also larger than the typical TCP delay DAC timeout on both Linux and Windows now there are of course like legacy systems which use higher values but in practice this works out very well now next slide please so what is more than we know this is basically introducing the reduction factor f and that factor is not a constant it so it\u0027s an ongoing value based on the ratio "
  },
  {
    "startTime": "01:26:43",
    "text": "we target billion the measured based divide and we pick a maximum of 16 because it gives us a trade-off between responsiveness and performance of course implementations are free to experiment with that value but we find 16 to be every me sweetheart this saw is basically the agency competition problem so if you deploy Ledbetter on the low latency link it would still it will still be less than best effort it will not interfere with flows the next back please so this is to magnificus decreases to solve the internet bad fairness problem this was actually suggested in the paper again this introduces a additional factor view and we also specify the values that we experimental your iPad so using the constant value of 1 and the decrease coefficient could be 0.5 the other thing that needs to be ensured is that the condition window never drops below two packets so this is required so that middle boxes don\u0027t time the flow out so we don\u0027t want long period of silence so you maintain at least a minimum rate to the network next slide please you know so slope is exponential and that can cause like massive loss in it cost also has other flows to back off so what we do here is three things first we apply the reduction factor f to the condition window increase to live slow start that makes it slower than we know we also limit the initial condition will go to two packets versus the de facto standard of ten packets now and there is a high start like mechanism it\u0027s not exactly high start but very similar is the target if the to delay is measured to be at least 3/4 of the target than may exist will start immediately and move it to condition events but this this high straight leg algorithm is only applied during the initial slow start subsequent slow starts you know used to be recorded as Thresh right next week least initials Peter it\u0027s not on so periodically led by plus plus will enter to an office where me condition windows again frozen it to packets for at least two round-trip times and then it will look slow start again backward solution Alice\u0027s thrush value and the way here is to not have more than 10% drop in throughput because we are probing for activity so the way we calculated that is from the entry of the slowdown and the time taken to reach of crisis Thresh we might declare at that value in mine so it\u0027s effectively it\u0027s basically a round of like 10 this was the latest interest problem it also helps with solving the late common problem next slide please so the graph was submitted just yesterday I don\u0027t know if people have gotten a chance to link it but please go get it and give us feedback there is a Ramsey IPR disclosure that we just posted I think the numbers three "
  },
  {
    "startTime": "01:29:44",
    "text": "six by one I couldn\u0027t get it in time for these presentation but I make sure the slider operator later and then the next step would be should this document be adopted in ic CLG or some other working group from our point of view this is widely deployed at this point there are a few or research areas for future but this is production road questions I don\u0027t know if you have any time for questions well if anybody has a burning question to the mic like right now I going to opening I was just a little curious about the 16 millisecond threshold where their experiments with lower values it would be great if a lower value might work the main concern is the uniDAC time out in Spencer so even though we filter our kitty samples it\u0027s still possible that there would be problems which be used a lower value I think let\u0027s do that at time what is like 40 motivated so that\u0027s the reason we picked away the high up on that but again this value is certainly subject more experiments Jake and also on a choice at the target delay is there is there some reason not to use a dynamic value to discover it and try to hit like adjust to a difference ah it\u0027s it\u0027s certainly possible again maybe I think that when you certainly open to more experimentation but in practice this value really works well on a variety of networks thank you yes respect request which is is it possible that you can make the value configurable based on the Matt\u0027s actually because in new transports like quick we now explicitly communicate that that way now would make it more useful in cyclic well that\u0027s a great solution here for quick we can certainly do that nicholae informedness i have two points to make first CDG is an igneous kernel and has lower than best default mode it might be worse considering in the evaluations and also ATMs has shown to be a big problem for that but episodes in the past you\u0027re not always the best afford anymore in pick um it\u0027s the presentation and this one is worse evaluating all these works when you have an issue and on the past feedback Thank You blogging I hope that the feedback was useful about the question of adopting let\u0027s take that the list listen in the figure what that really means but I think that will resolve this along with the other question of I hope you had a lot of documents but I give you a presentation and thank you "
  },
  {
    "startTime": "01:32:46",
    "text": "everybody see you all in Singapore on the list before that I would like to ask a quick question of the room how many people think that 3168 is a barrier to progress find mat in the corridor and tell him "
  }
]