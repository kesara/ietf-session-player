[
  {
    "startTime": "00:00:01",
    "text": "to to Well, I know. I'm happy to. Where is the clicky thing gone? gone? But you can, I'm not doing that. That's crazy talk So you're just going to have people say next? Yeah, and you press the button? Okay, cool to click. Where is the clicky thing gone? Is there going to? But you can, I'm not doing that. That's crazy talk. So you're just going to have people say next? Yeah, and you can use this for the point events The laser No. We'll leave it over there if you want to so in that box we have the extra circuit now. And it's called IET external and IETF 120. And then I've written some Python which goes through and pull all the circuits that are marked external and puts those into the templated config and the BGP config so like we can when you put it thingy and you just add it to Netbox and it builds that we can Wow, apparently it's already recording what I know saying Is there not? on the display or does it like maybe it's the other side? There's no battery one. Yeah, it's busy like recording everything I see and transcribing it, which would have been good if I, you know known that before rambling on for a long time about picky things We're just like, no battery does it take?"
  },
  {
    "startTime": "00:02:01",
    "text": "Oh, wait tell me. I will tell me need another battery Okay, battery works out feel super old. I was expecting it to be like some USBC plug thing, whatever So you stole it from another microphone from the table. It's on table. Good morning This is the IABG at IETF 120 Somebody's going to complain that we have, I don't know, agenda slides or something But we do um so just before we get started you can just look forward Oh, you probably have to, I'll do it in a second. Anyway, before we get started, if you're up here presenting, please either use this stand and look at the people. Or if you don't want to do that, and you want to do this, you can walk around, I wouldn't do this That's bad. Definitely don't do this because no one can fucking hear you. So, speak into the mic. If you need guidance on how to do that, hold the mic like this. And then everyone will always hear you. Okay Thank you slide There we go So hey everybody, this is what the IABG is. It's an informal gathering that meets on the Sunday prior to the IETF meetings in the what the IABG is. It's an informal gathering that meets on the Sunday prior to the IETF meetings. In theory, it's all supposed to be operationally relevant content and I think this time most of it is And for once, our agenda is not filled with BGP and DNS DNS We think Chris stole it from the back so we just need a replacement for on the table, yeah"
  },
  {
    "startTime": "00:04:04",
    "text": "um, so Chris has now disappeared, so I can't actually show you what the agenda is, but it's very nice I can tell you what the agenda is. It is IPV6 over Bluetooth and then network and sustainability and ops perspective. Experience in post-quantum DNSSEC, migrating Lacknix RPKI, and then I in deep space I believe that that's everything that people had offered and so we will jump into it IPV-6-7 Bluetooth we're actually going to do first. So that is Nalini and Rakheth. Who's actually going to be presenting? Is that going to be remote? Rikshi, okay So that will be a remote presentation, I believe, because of visa or entertainment. Unfortunately, yes Is Greek yep he's on okay I'll do a quick introduction. Ready? Okay, so this is part of a larger grant that we are doing for Internet resilience and disaster recovery on a shoestring very low, you know so we can do it ideally under a 10 $10,000 kind of a budget, which makes it very in the reach for many people So, and this is one part of it Rick Shee, please go ahead am i audible and visible Yes, yes, we can hear you now. Yeah, thank you Yeah. So, hi, everyone. I'm Rakhshit and along with me, Srinidi Thais, under the mentorship of Nalini, I've been working under this We are from NITK, Suritkal. So the topic is IP over Bluetooth for power affluent devices Next slide, can I go to"
  },
  {
    "startTime": "00:06:01",
    "text": "the next slide myself for up to informant um next slide can I go to the next slide myself for a pin for me if you want to share the slides yourself you can do that I'll stop sharing and then you can try. How about that? Yes sure. That's fine good Yeah. Okay is this visible No, hold on visible? Yeah, I think it's coming We see it now, actually. Oh, thank you Yeah So an overview. So what is IPV6 over blue? now, actually. Oh, thank you. So an overview. So what is IPV6 over Bluetooth to those unfamiliar? It is basically an extension that allows you to use IPV6 over Bluetooth that is transmit IPV6 packets over Bluetooth And this started off and has been mostly confined to communication in IoT networks mostly due to the low energy consumption of Bluetooth and it is also known as IPV6 over Bluetooth low energy for that reason and in this presentation we propose to discuss its use for power affluent devices. That is, a technical way of saying not resource constraint. That is, you know, everyday devices such as phones and laptops and PCs and so on. And the object is to achieve connectivity during internet failure Yeah So this is a brief description, a pictorial description of how IPV6 over Bluetooth would work Is my audio clear? Yes, we can hear you Rikshy. Right, so suppose we have a sender and a receiver who are running some network application on IPV6. We have an IP over Bluetooth stack that can contain many comments So the idea is that once IPV6 packets are outgoing, they are inter-support"
  },
  {
    "startTime": "00:08:01",
    "text": "by this stack and they are passed to the Bluetooth stack, which then sends it over to the blue Bluetooth on the other device. So there is a Bluetooth link but IPV6 packets are being sent IPV6 packets in other words is the data of the Bluetooth packet and the receiver passes this packet to the IPV6 over Bluetooth stack and then that those IPV6 packets are then extracted and given to the network stack, TCP IP or UDP or Wode whatever and then pass known to the relevant network up application. So this is how two devices would communicate of course there can be intermediate devices in between right so that was a brief description So coming to the use cases so all use cases are for internet unavailability and one of the most common occurrences is during disasters. So disaster more often than not disrupt traditional means of communication. We won't have the internet phones cables, more often than not So in such times, establishing communication and coordination so that rescue teams can contact people and communicate with them is extremely important. And having an alternate technology to have a local network where you can communicate with each other is very important and IPV6 over Bluetooth can be used for exactly this reason and especially small and medium sized communities, for example, universities right or those who want to have a backup plan in case of frequently occurring design communities, for example, universities, right, or those who want to have a backup plan in case of frequently occurring disasters can make use of this technology right so there are two RFCs, RFC 9159 and I believe 7668 which discuss this for IoT devices that is Bluetooth low energy And so how would a network look like when you have"
  },
  {
    "startTime": "00:10:01",
    "text": "a disaster area and you are using IPV6 over blue Bluetooth? So there can be devices with different roles nodes routers or both and border routers And border routers in this technology are those routers which can give you access to the internet and connect the local network to the internet So, better explained with this picture, right? So you have devices maybe laptops with different ways yeah so they're acting as nodes. Nodes basically participate in the network routers, route packets to other devices and border routers connected to the internet. So if you don't have a border router, you can simply communicate with devices within the network. So that is the object objective Right. So yeah, continuing chat applications. So Bluetooth chat initially gained prominence through the bridge app during the Hong Kong protests There it was the case of internet shutdown So we have a similar idea that is use IPV6 over Bluetooth to send messages from one device to another across multiple hops in the network and then iot gateway so this is not a power affluent devices use case, but without mentioning it, suppose you have multiple IoT gateways that are communicating with each other or maybe communicating with the central router you can have this as a fallback mechanism in case Wi-Fi connection or cable connection or something of that sort fails File sharing. Again, Bluetooth has developed a lot since it's version one, both in range and speed I believe initially it was a few hundred kbps and now it is a few MbPS. It can go up to tens of MbPS"
  },
  {
    "startTime": "00:12:01",
    "text": "So IPV6 over Bluetooth can therefore be useful for file sharing in local networks Basically transfer files from one device to another Next, local network notification I believe this is the most important of all especially in a disaster area where you want the rescue teams to send updates to people right? For example, weather updates and not notifications about a particular event or a food direction a medicinal supply delivery or so on. So you can use this to broadcast information from the team to the people across multiple hops across the network so that it reaches everyone in that particular area And the last one is data backup so supposing you detect low signal strengths or internet unavailability during the early stages of disaster You can think of backing up your data and you can either use the actual internet through a border router and back it up on the internet itself or you can back it up on multi devices or designated devices in the network that are probably a little far off from the area where the disaster is going to happen or something like that. So this is another use case So overall, the focus is to use IP basics over Bluetooth for local connectivity during internet unavailability Yeah. So coming to a little about implementation so we have been testing an implementation on Windows 10 about the IPv6 over Bluetooth stack. So it consists of a few components and a few libraries. So this is a brief description of that. Firstly, the important task is to take IPV6 package that are outgoing and send it to Bluetooth. And then"
  },
  {
    "startTime": "00:14:01",
    "text": "the other task is to take IPV6 packets from Bluetooth packets and send it to the network staff So we need a driver or an OS level module to do this. That is one thing. And another other application that can be a central component that can interact with the driver, you know, obtain device address and find nearby devices connect to them and so on. That is what we are calling as a packet processing application. So these two are the main components. And these packet processing application makes use of different libraries. That is a driver interoperability library and a gap library and a six low panel library. The first is to interact with the driver a user space library to interact with the driver. The second one is, you know, to set up a gap service so basically how do Bluetooth devices, let other devices know that they support IPV6 over Bluetooth so the IT has developed a standard in the form of a profile for Bluetooth GAT servers and that is called the IPSP profile which says, yeah, so I support IPV6 over Bluetooth. You can send me IPV6 packets within blue Bluetooth and I understand that. So that is something Bluetooth you can send me IPV6 packets within Bluetooth and I understand that so that is that is something that is an essential thing and we also have a header compression and decompression This was designed for IoT networks, but we can have this as an optional thing if we are doing it for power up the end networks devices so this is a description of again, a pictorial description with the packet processing application, interacting with the library in the user space and in the kernel space with the internet stack, the Bluetooth stack and the driver So, yeah coming to the requirement for, you know, setting up an IP basics over Bluetooth network, what all would we need? Firstly, you need to have that stack in your device that is a drive"
  },
  {
    "startTime": "00:16:01",
    "text": "and an application to convert between IPV6 package and Bluetooth and a central component or something of that sort So this is on the device as described in the previous implementation. And the other thing is you will need to configure routers to forward back and then you'll need to configure maybe a border router if you want to access the internet right and then last but not the least the very important thing to address devices assign addresses to devices and in the RFC, I think it has been proposed to use the EUI 64 but again, it may or may not be used we can use some other addressing mechanism or stick with that Right. Yeah. In conclusion, the is a IPV6 over Bluetooth is a viable solution for internet unavailability And yes, there can be a few security and implementation issues, but we need to deal with that And we can maybe go about setting a common set of guidelines and implementation details that can be useful when we are developing this on different platforms So yeah, that's it for the presentation Are any questions? questions? Hi, thanks for a good presentation. My name is jeffrey haas So you mentioned the security stuff and that's one of my two questions. So the first question you'd mentioned, like example, Bridgeify, you know, that's an example of places where people want to have no good security How far have you looked at? security for this type of application? application? Okay, excellent. We haven't started with that, to be honest. We are just looking on"
  },
  {
    "startTime": "00:18:01",
    "text": "testing you know getting it to work between two devices and all. But yeah, I think there are some security concerns given in the RFC as well we will need to look at them yeah let me, I'm going to jump in there too Totally good point Jeff. Right now, we're trying to just make it work. And but yeah, I totally totally point taken because as you say, some of these situations are delicate and one wishes to have very good security yeah okay well in that case my second point also may be used in your wish list so one of the cheques you have whenever you're doing these sort of low- bandwidth applications is if you have a generic device that just says, I have IP reachability now having a prioritization schedule to control what can use that bandwidth can be very important. My favorite example of that is your laptops just got on through a modem and it decides no from your IT spyware to run your back right now, and you can't actually get your email through. Yeah yeah, really good. Rick Sheet, did you, did you guys, did your team hear that we need a good workload scheduler and prioritization. Yeah, yeah Yeah, yeah. Super good points Yeah. Another GIF Jeff. Thanks for the presentation. I was kind of interested to what extent this work. It's seems to be very much in parallel to the Manet work that's been going on in the IETF for almost 10 years To what extent does this intersect with the Manet work? and why isn't it, I suppose, using that? entire framework? To what extent and why? are you heading off in a different direction if that's what you're doing? Ricketts chill out me, let me grab that one too, and then you can do Yeah. Yeah. So, so yes, indeed. There's a number of different alternatives. You know, one of the things we went into is like, I'll give you just a little"
  },
  {
    "startTime": "00:20:01",
    "text": "example. I was talking about some of our folks in the military, and they have like 18 year olds you know they jump on the thing that I was talking to some of our folks in the military, and they have like 18-year-olds, you know, they jump on the thing, on a, you know, they go to the Philippines and a typhoon, whatever And they're just having a nightmare setting up the whole communication system What we want to, what we're aiming for is something that very, very, very little very shoe strength very little technical knowledge you know needs to be done. My Rotary Club can do it. You know what I mean? And some of these technologies, excellent as they are are you need a technician That's kind of where we were coming from it, yeah So you're saying Mene has a much higher configuration load? I think so. And that's what it definitely we need to look at that. But that's what we felt. And even setting up Wi-Fi and a, you know, wireless access point that kind of stuff you know but but really good point, Jeff. We'll go ahead. What we should do is do a computer You know what I mean? How long does it take us? to do this versus Manet? There's been a lot of work in Manet. I know. It's covered a huge amount of ground. So it's not a slight thing, but the reason why there's been a lot of work is that it is an interesting problem to solve this mobile ad network. No, totally. Exactly what you're doing here yeah just wondering why why a different path but okay, fair enough, thank you. No, no, totally get what you're saying And I know some of that work too Hi, bob hinden two comments. I find the title of this draft doesn't really match what I think you're trying to do, because I read it as sort of trying to do a protocol spec or something, which that work is already done. So you might consider I mean I think you're trying to use Bluetooth for simple ad hoc network so you know in certain environment So you should make the document, make it"
  },
  {
    "startTime": "00:22:01",
    "text": "clear that's what the document is about and then as I said this on list the section on shortwave radio shouldn't be in this document It's got nothing to do with Bluetooth. It's a whole different topic no no totally totally get that and you know this is, as I say, what we've done is we've kind of redone the whole thing for, as I see a larger grant in this area But the grant is for disaster recovery rather than, you know, a protocol spec the whole thing for, as I say, a larger grant in this area. But the grant is for disaster recovery rather than, you know, protocols to back yeah yeah no really good point really good point, Bob. Hi there tom hill from BT. Thank you, Rexchie. Lovely presentation Forgive me if this is quite a basic question I'm struggling to work out as to whether or not, and I don't know a lot of work with Bluetooth. You'd be very obvious to find out How much of this is actually new IP work and how much of it is implementing things that already work in IPV4? I didn't understand, I mean IPV6 over Bluetooth and IP over Bluetooth, something like that? You gave a use case about the mesh networking or message? that was done in Hong Kong during the internet shutdown Obviously that was working with something So how much of this is implementing an IPV6 stack and how much of it is implementing new capability in IP? does it all work in IP before today No, no, so this is not about you know, changing anything in IP. This is about building another stack that is an IPV6 over Bluetooth stack some more software that can help you give out IP packets through Bluetooth. So this won't require any change to the IP stack or the Bluetooth stack as far as You know what, let me, I'm sorry to interrupt. So, okay so where this kind of led from is like if you look at the at the interfaces on where"
  },
  {
    "startTime": "00:24:01",
    "text": "Windows, you'll see that the Bluetooth interface has an IPV6 link link address and it ends up being quite a bit more difficult to get an IPV4 local address you can but it's a it's a it's a different kind of address. So in this case, it's sort of it's we were kind of going from there that, that it seemed easier to do IPV6 first on that stack and that you see what I mean? No, that's great But given the use cases that were mentioned, I thought this was all working in IPV6 Yeah, that's a very, you know, you can, you can, see here, there's a bunch of gaps here. This is really early We need to, one of things, other things we really, haven't done is seen how much is working over IPV4 that that is definitely a to do because i'm not we need to put, we need to put up that bridge of fire is working over IPV4 that that is definitely a to do because I'm not we need to put we need to put up that bridgeify app seeing what exactly they're doing it It's totally true. Yeah. It was curiosity, so thank you Yep, yeah. No, curiosity for us, too This is, it ends up being a surprisingly large space Yeah, thank you very much for the presentation So given how you specifically said for non-energy constraint devices, so for energy constraint devices, I can see the immediate benefit of Bluetooth low energy, but for energy unconstrained devices, it is kind of competing with Wi-Fi devices which out access points. And so I was busy specifically wondering if you tried to make a comparison and see why Bluetooth is more interesting than Wi-Fi so the primary idea coming to mind was that the Wi-Fi may already be kind of in use for kind of trying up to uplink to the Internet that isn't working. So Bluetooth is available and not used or something like that. But I was looking at your perspective yeah yeah rich if you want to grab that one uh no you go on yeah yeah so we that is it"
  },
  {
    "startTime": "00:26:01",
    "text": "now, again, again, it we'd need to do a real comparison because it and I think, I think it was ease of use that we were going down, you know? is, it's more, it seemed like Wi-Fi to us required some kind of central point where this can be pretty much peer-to-peer Lorenzo Kalidi, can you go back? to the, can you go back a few slides to the sort of complicated diagram with lots of devices on it? it? Rickshed, can you go back? a few slides? Yeah, oh, that one, I think, yeah OK, so this looks very cool, right? But it's actually quite hard to do, I think So one of the things that are quite interesting here is like, you know, how do you sign IP addresses? How do you do mesh route? If you just do this, you basically end up with a routing loop, right? So I think that's, that maybe sort of is what, you know, maybe Jeff was alluding to. Like, how do you make this work, right? Do you do, are you? run Babel on all of these things? Are you going to you know, who's going to sign IP addresses and so on? Do you have any of this working or is it just? sort of aspirational at the moment? We have some of it working. We have some of it working between some devices. So have you done multi-harm? yet or? No, we have not done multi-hop yet okay yeah so that we have single yeah did the easy part Okay. Well, I mean, it was it was hard enough Yeah. Yeah, yeah, yeah. I'm sure it was fun So yeah, I think that would be quite interesting to, because I think multi-link subnet routing is kind of really an unsolved problem. And I think, you know, Sixth Man has also been sort of struggling with this as well. So, you know, if you, if you figure out how to make this work let us know um or if you think, you know, Six-Man can help You know what, I, it sounds like we've got a couple of things. First, we want to at least make it"
  },
  {
    "startTime": "00:28:01",
    "text": "we only have it working on windows. We wanted to at least make it work on Linux and then I think what we should probably do is, you know, get the Bridgify app going get the Manet business, and just see you know, where the gaps are Because to us, it seemed like it was a there's a bunch of gaps and the ease of use thing needs to be thought about, but we should, we need to actually go over to the man-aid people too and and these things they have to have explicit pairings with each other, Bluetooth pairings or you, because that's also sort of like high-type touch, you know, manual stuff where you actually have to go to each device and like talk to them to configure That's a very good point. You know what? Oh my God Yeah, I have another whole idea for explicit, I mean, yeah, I have a oh my God, now you're making me think about another whole approach to this. If I may, I may have an idea for this. I want to, I need to think this out But, but if you get, if you allow me to do explicit configuration it really simplifies the problem a lot The problem with explicit configurations is how do you, I mean, it solves the problem of like, you know, for example, in internet shutdown case, Mr. Policeman or, you know, Mr Gover, I don't know, I mean, I'm just babbling, but keeps that problem out. But it brings up other problems of who do you let in if it's an explicit confusion? Anyway, there's a lot of work in interesting stuff we're really at the edges of this and we'll keep you posted Sorry to talk so much. Thank you Thank you Rickshit, did you have something else? Thank you Oh, there's so many out Don't put on the stand, please You can tip it down"
  },
  {
    "startTime": "00:30:01",
    "text": "Or you can hand it to me and I'll just hand it to the next person who is Ali. Ali. There we go And you've got 20 minutes Ali there we go. And you've got 20 minutes. I had 20, it was 20 with questions Um first time here at the IAB meeting, so very glad to meet you all Today I want to talk about sustainability, environment sustainability from an operational perspective You probably recall that the E-Impact Program had started a while ago with the intention of investigating the environmental sustainability topics that could be relevant for the IET and this Wednesday we have a green boff looking at the mostly energy metrics of internet work Now I want to hear with you some further topics and hopefully collect your feedback. What would you prioritize from an operational perspective? because sustainability is a deployment and operation impact question because we develop our products, we manufacture our networks, but at the end, what impact do they have on the environment? is really out in the field So this is really crucial Next slide Can I control? No We're waiting for it to change It should be changing. There we go"
  },
  {
    "startTime": "00:32:01",
    "text": "Thank you. I want to first share with you some valuable reference One is from our colleagues from Erickson and one Nordic operator and the other is from a co-work from the World Bank and ITU and they frame quite well high-level terminology as well as global data that's important to understand the impact of ICT in general so the data is at high level and therefore it is something hard to trickle it down to what it means for certain protocols or network architectures, but overall it gives us an idea. And one of those ideas is that the ICT sector is responsible current in 2020 and it's roughly along the same lines 4% of global electricity consumption and 1.4% of GHG emissions. So I am assuming some level of terminology, greenhouse gas emissions and the rest. If not, please interrupt So what it means is that electricity consumption translates into some level of greenhouse gas emissions and that depends on a few things, which I will elaborate later on in the slides. But so far, our an ICT sector, I'll present what it means in the next slide, is responsible for 1.4% percent um sorry i didn't Sorry about that good. Sorry about that. Yeah, and what is important is that"
  },
  {
    "startTime": "00:34:01",
    "text": "our share of global emissions is not dropping that something to remember. It's not increasing but it's non-decreasing, unfortunately And all this is happening even though we have a good renewable energy use practice generally in telecommunication And what is also important, we hear a lot trying to establish a correlation between data transmitted and energy used or GHGs generated there the correlation is not straightforward Data rates grow much faster whereas GHG is and energy consumption grows or doesn't decrease, let's say So we need to make a distinction And what is important, which will make it difference, is that per subscriber energy, use is not increasing but the GHGs are somewhat decreasing because we are using more and more renewables. However, subscriber number are also increasing So we have to really balance. Thanks Next slide, please. Now, if you words about the ICT sector This picture is from an ITU, but it's generally accepted. What the user side means, what the network means, what the data center means and what is X excluded And what I want to draw your attention to is the mix of greenhouse gas emissions that occur based on the manufacturing of equipment versus its use So in the user devices side,"
  },
  {
    "startTime": "00:36:01",
    "text": "the balance is 50-50 or if you take mobile handsets, it's really even more on the manufacturing side. Whereas for networks the balance is really skewed our embedded emissions, that is manufacturing side. Whereas for networks, the balance is really skewed. Our embedded emissions that are caused during manufacturing is rather low as compared to the use phase So that's why we focus so much on reducing use phase energy consumption And data centers and enterprise networks are a group to together and there the picture is also similar next slide please So given this situation as compared to other big industries like electricity generation, transport or agriculture, buildings, manufacturers, our share of network, of other big industries like electricity generation, transport, or agriculture, buildings, manufacturing, our share of the GHG emissions is low Why should we still care about this? Next slide, please. There are plenty of good reasons, actually And one of them is that the Paris Agreement, we all know this 1.5 degree limit humanity is chasing and is about to unfortunately miss it looks like has set targets for India industries and United Nations organizations have calculated the let's say responsibility of each sector and for the ICT sector they set a target to reduce emissions by half, by 20 each sector. And for the ICT sector, they set a target to reduce emissions by half by 2030. And as I said, we are nowhere near that target because we are in a non-decreasing cycle. And also there is a more practical reason"
  },
  {
    "startTime": "00:38:01",
    "text": "Most of the companies, vendors or operators, have now net zero pledges that we are supposed to report and also in Europe, for example, soon we will be required to report and that depends also absolutely on the GHGs generated by the next networks. And so you will hear this a lot We are switching to renewables, so that will take care of things. Unfortunately now because energy consumption is rising and both renewable and non-renewable energy use is also rising so to reduce the emissions by 50% renewable uptake will not make up for the gap. And another very key in, 50% renewable uptake will not make up for the gap. And another very key note is that we said per subscribe energy use is stable, but subscribers are rising. So one third of the population is still not connected So their connection to the internet to ICT services must be done in a sustainable way if we increase the subscriber numbers, steadily, somewhat we have to decrease their GHG impact And also we have seen this disturbing trend in the ICT industry that new application or new technologies like AI, Metaverse or digital twins are increasing ICT impact, unfortunately. We have seen very prominent companies announcing that their net zero pledges are known longer valid because the AI impact is pushing them"
  },
  {
    "startTime": "00:40:01",
    "text": "to use more and more energy and resource So there is a good reason to care. Next slide now what's what's a and more energy and resources. So there is a good reason to care. Next slide. Now, what are we supposed to do? We are working on energy efficiency energy consumption, but is that enough? What else has to happen? so that this work translates into real? greenhouse gas emission reductions from our operations? Please Okay, so this is the bathtub method which is very often used and the idea is that everyone has to take care of their own bathtub. And we'll see what that means. Next slide means Next slide, as I said, we are working on energy efficiency but are we working on the right reason? with the right reason, let's say because as you will hear, quite often, networking industry is focused on costs when it comes to energy efficiency, energy reduction energy consumption reduction Now, this is necessary we understand when we will a, let's say, multi-dimensional sustainability perspective, you have to take care of the environment, but also the economy and the society. We have seen when we don't do that we cut subsidies abruptly or forbid gas furnaces in homes, etc households react, farmers react things don't move so cost is important, affordability is important or bottom lines are important. But"
  },
  {
    "startTime": "00:42:01",
    "text": "do they result? in the environmental impact in the case? We have to make sure, please So I would say that if you other things have to happen. The path from energy efficiency to greenhouse gas emissions reductions require a few additional considerations and actions. And of course, along with energy efficiency, energy consumption reduction energy proportionality is a huge topic that we said the data versus energy is not directly proportional or it's not correlated linear let's say. We have to get close to that. Some people advocate zero energy for zero bits, but this is largely, let's say, beyond reach. But nevertheless, that has to continue. So energy consumption has to come down. But we have to also take care of the carbon so the energy supply that is used to power our networks have to follow a low carbon trajectory. And energy supply decarbonization and making sure that users and suppliers of data are also carbon aware Everyone's pushing the only onto the user, saying, oh, you have to decide when you watch this famous cat video. But what about the sub- side? The content providers, content delivery networks their actions actually dictate"
  },
  {
    "startTime": "00:44:01",
    "text": "what the subscribers can do so there are things on both sides. Then a word about traffic We have heard this word on rebound effect When you make something affordable, it gets used more. So we make it energy efficiency, energy consumption we make networks very cost-effective from an energy perspective, but then they become they are no longer bottlenecks and they get used more And we have to take care of this This is, there are practical things we can do about that and infrastructure expansion as we let say, grow the network, then it has a embedded emission impact but also it is enabling more and more It's like building auto-bound everywhere and as you build more, they get even bigger traffic Thank you. So the rest I can let's say I gave a examples very quickly we can go I'm now going to go through them it's for perhaps further reading. But in every domain from energy to let's say, GHG and environmental image there are things we can do on the network side in architecture, multicast units infrastructure, sharing these are all levels we can play. But what's important is what is your priority as an operator that you can bring. And we can also prioritize beyond energy. Thank you you you"
  },
  {
    "startTime": "00:46:01",
    "text": "There's five minutes for questions. There's still five minutes if you want. There's still some time for questions if you want. Yes, you said it for 50. Yeah 50 Thank you. Thanks for an interesting talk I think one thing that jumped out at me was the amount of the large percentage from the user device side of that like if that kind of adds up to 28% of the users, the one's biggest chunks is from user device at use time. Is there something, things? we should be looking at protocol wise for k um of adds up to 28% of the users, the one's biggest chunks is from user devices at use time. Is there some things we should be looking at protocol wise for cases where some protocols may use more power than others? So for example, some cryptographic ciphers or using quick overage protocol wise for cases where some protocols may use more power than others. So for example, some cryptographic ciphers or using Quick over H2 might use more power and in some cases, you want them for performance. And right now a lot of our selection of which to use is based upon performance but it might be worth us looking at are there cases where we want to influence? want them for performance, and right now a lot of our selection of which to use is based upon performance, but it might be worth us looking at are there cases where we want to have the power consumption influence that So if someone is close enough that quick isn't going to add much value, but it's going to use more power. Maybe we should be looking at using all kind of using h2 instead yeah indeed that's uh we touch upon trade offs very often that performance versus sustained performance, energy, security energy. These are indeed showing that we have to include the energy and the environmental parameters in inside our equations or optimization And as you said, in many interfaces, perhaps the application of encryption might not be proportional to the risk, and that can be excluded or a lower level of protection can be selected favoring more energy savings indeed But we have to"
  },
  {
    "startTime": "00:48:01",
    "text": "understand that this is a, let's see use case or end user question as well We have to identify each case What's the security risk? What's the environmental? impact? And can we optimize? together? And indeed, colleagues are working on this One example I give is, for example, doubling the size of encryption keys, for example, for quantum readiness. And that when it's happens, it has an hardware impact as well. Because on the U.E side, you are probably forcing a chip changes on the mobile network, for example ue's and that is hitting the manufacturing embedded emissions from the UE side. And we have to ask ourselves, is that the right thing to do? and if so if there is a risk for quantum era then sure, but we have to all account for this Does it answer your question? Thank you Adrian found green boss later in the week, which I have the GB dubious pleasure of co-chairing A question that came up in relation to this, and maybe this room can help answer, is to what extent operators are willing to consider sacrifice SLA in return for power efficiency or power reduction? Mm-hmm, yep don't know if you've got opinions or if some of the operators here would like to throw rocks about that Yep, yeah, exactly. This is exactly in the traffic management domain"
  },
  {
    "startTime": "00:50:01",
    "text": "as well. In the past, people were okay with broadcast technology Then everyone is now using on-demand And that means Unicast and that's pushing video traffic to incredible amounts and what's the impact? let's say, if you were to say we are scheduling a transmission every 10 minutes and you can join the next let's say, session of a video you have to wait 10 minutes. That's quality of experience. Does that? hurt your business, your business? and if not because that has a direct impact on traffic, on energy on GHs so indeed this is a key question. And that's the business side of sustain on energy, on GHGs. So indeed, this is a key question. And that's the business side of sustainability. So it's not only environment it's also business That's one. Chief Houston, not really a question but a comment A much more pointed presentation was made at the North American Network Operators Group, Nanol, last month, by Ron Bonica, also with time Lee, that pointed out that most networks are a bit like road networks that is designed for about an hour a day of intent use. And the rest of the time you have an awful lot of resource unused What you actually find is a huge amount of bandwidth, a huge amount of line groups and lasers etc and that presentation pointed out very, very effective that if you're using multi-line groups, lag groups, if you simply turn off the excess capacity when you don't need it, the power savings are phenomenal. And so a lot of this is actually not about the bigger picture, but about the smaller picture. How do you actually design and cr- your power to match your usage?"
  },
  {
    "startTime": "00:52:01",
    "text": "across a full cycle of usage? rather than trying to sort of take the macro picture? and somehow reduce encryption, reduce this, reduce that? which I don't think is the way to go about it So I'd certainly encourage you to have a look at that presentation from Nano Nanolignity. Sure, sure. I follow that. Yeah, thanks very much but I couldn't present the last four slides, which included indeed some of the measures you mentioned. Yep, thank you Thank you very much the next presenter mark and I'll put 15 minutes for the chat and five for questions Good morning This is about the Internet Protocol Suite for deep space Most of the content is on the draft It was on the first slide. That's fine This talk is not about internet users and application so don't come to me and say, my browser application doesn't work for that use case It's for space applications. And this talk is not about near Earth, so Leo, Mio, Geo not what we're going to discuss this project is been benchmarking benchmarking with mars but will be implemented first on Moon, which is a quote, quote, simpler problem. Next slide slide You said 15 minutes, right? Yeah, the terms of the bottom. Okay, fantastic Thank you. Just a note to, um, for, of the bottom. Okay, fantastic. Thank you. Just a note to keep this in mind because it may have impacts on on, you know decisions or use cases Space agencies now are moving into buying services instead of, you know, doing by the- themselves, starting with moon, so, you know, co-co, you rent a rover for a year"
  },
  {
    "startTime": "00:54:01",
    "text": "there will be guns and networking providers and provides private sector will offering will be our with Moon. So, you know, Coco, you rent a rover for a year. There will be guns and networking providers and provides private sector will be offering services to non-space agencies We're moving from specialized equipment to rad tested commercial off the shelves or other grade component Therefore, given that we have multiple providers and to robability and governance, will become strategic paramount. Moon network plan was defined by the IOIG, the interagency operations advisory group, and also for March to use 802-11 defined by the IOUAG, the interagency operations advisory group, and also for Mars to use 802, 11, 802, whatever, and 3GP on surface and the orbit of the moon Therefore, we'll be using IP. Next slide So, what are the displacement communications long delays Earth to Mars, 5 to 20 minutes one-way delay, so 10, 45 minutes round-trip time, depending on the positions of the planet, then links are interrupted. Next slide Why are the interrupted? Because we're orbiting, the planets are orbiting and the orbiters are orbiting So, depending on the position, on each device, you may communicate, for example in the middle line of sight between all devices but if the orbiter is on behind the Mars, then you cannot talk to Earth, but it can talk to the room and the other way over So you have to plan with you know, long interruptions Too fast? Back, just a second The key point here is that relay or for orders or road to store frames or packets"
  },
  {
    "startTime": "00:56:01",
    "text": "The key point here is that relay or for orders or routers, routers need to store frames or packets until the next up becomes reachable So that's the key thing to do It could be done on layer two That's what currently MRO and the other orbit around Mars are doing, MRO, Mars, reconnaissance arbiter orbiter. MRO is 20 years old spacecraft as a 40 megahertz CPU, but large solid-state memory and is hoarding the packets that are coming from the rover and then for those cases it stores the packets, actually the frame for each of those scenarios. Next slide so let's let's calculate a deep space RTT For example, taking MRO again, MRO does essentially 15 minutes of communications every six hours you know, roughly speaking So the smallest RTT would be a line of sight between everybody and the planets are the nearest So it's a 10 minutes RTT A pretty large RTT would be where the planets are far away and that you are not lucky and you had to wait until an overpass to talk to the other guy and then you're putting this really in bad shape during that past you don't have time to you know reply so you take another overpass you know, I'm pushing the limit. So it becomes 13 hours RTT Worst case is solar Mars conjection. They are really in bad shape, so you have two weeks of no-com every two years So in that case, the RTT is two weeks"
  },
  {
    "startTime": "00:58:04",
    "text": "Interesting problem. Obviously, if you have a constellation of arbiters, you know, that could cover the whole planet, moon or Mars, then you're lucky, but that will take it some time. Next slide So Earth Moon is going, as I said, we're talking Mars as the benchmark, but Moon is the one that will be implemented. It's a few seconds delay not very long but long enough that typical internet application won't work as is when we kind of tweaking However, Moon for some time will have the problem of not enough for obiters to have, you know, full coverage like Starlink therefore you will have interruptions or conclusions. Therefore, you need to plan for the fact that sometimes you'll have to buffer data frames or packets until the next opportunity happens of conclusion Next slide Okay, so the key point is can we use the IP? protocol suite for deep space? The answer so from RC 40 4838, that was essentially written 25 years ago, published in 2007 concludes now, in the very short summary is, you know, TCP doesn't work in this context just protocols and applications are too chatty for delays and disruptions Therefore, it doesn't work. The consequence was the invention of the new networking stack called the bundle protocol based on a star and forward design You need them to do everything you know, from scratch, transport, routing, naming, security neighbor discovery, application API, network management Somewhat, you have to reinvent everything I was the co-chair of the working group for some time"
  },
  {
    "startTime": "01:00:01",
    "text": "A few years ago, I started to be concerned that we're not making enough progress, I guess say and it's difficult and we can go into a lot of debate and discussion about it So with a group of friends, veterans you know, people that you know, we look at why don't we reassess the Internet Protocol for deep space given where we are today and the essence of this work is documented in the draft and the subject of this presentation Let's go next slide so that's the IP stack deep space IP stack So you see TCP, no way In space space, way you see TCP, no way. In space, you will have CCS is the SDO for for space communications and you know, IT in general a constructive committee for space data system They have defined space links, which are essentially here two from the point of view of IP We will have 802 something and through systems. We have defined space links, which are essentially here two from the point of view of IP. We will have 802 something and 3 GPP on the surface and orbits So you will run IP, UDP UDP has no notion of time such as IP has no notion of time. And you could run the UDP applications protocols You could use co-op for IoT and then you may be able to use quick TLS and then that gives you the rest of it. Next slide in the scenarios that you can think of is like where when the spacecraft is actually cruising, when the spacecraft is actually connected to a surface network and then in the"
  },
  {
    "startTime": "01:02:01",
    "text": "context of relays or routers or floters they could be layer two relays or layer three relays where as essentially assuming this for some time because it makes the design of the space that relays way simpler. Next slide So IP has no notion of time you know, we did have TTL but it's actually used as an up count as confirmed by V6 Can be encapsulated in CCS space links. It's already defined Since IP, over space links are point to point, we can use other compressions which means that you can compress a lot. The IP, UDP headers and the almost a single byte And the key thing here for IP stack for four others actually, the ones that have interrupted links is you need to temporarily store the package that's a new behavior for four orders because in a normal IP folder if the destination becomes unreachable, you just drop the packet and send back the ICMPR message. In this case like if you do on, you know, for layer two, the MRO, you just store the packet until the link is back up and then you forward again. We did a prototype of this 200 line of SICO no big deal. TCP doesn't work UDP has no notion at times, so fine. Next slide so I'm gonna skip this in a sense that you should probably know quick but quick as even if it was not designed for deep space, actually, is a lot of different intro interesting properties that are useful for deep space you know one hand shake for establishing the communication"
  },
  {
    "startTime": "01:04:01",
    "text": "zero RTT user space a single connection is a pipe of stream and can be long live. So you can imagine setting up the connection while the spacecraft is on Earth then sending on space and then keep the same connection for the time of the mission you know, month or years, if you are Next slide So does quick works for D-space Well, actually, by default, no but if you set the you know a few various quick parameters, to appropriate values, which is essentially pretty large based on the, you know, expected largest, RTT, so use kind of set the initial RTT, max idle timeout window size, and you simplify the congestion control then Quick works fine in space We did multiple simile max idle timeout window size and you simplify the congestion control then quick works fine in space we we did multiple simulations on this you could use Quick with the proxies, for example, you could imagine a deployment scenario when you do proxies as space edge where the proxy itself would probably be more smarter in terms of access policies, buffering QOS, and those kinds of things while, you know, elsewhere will be kind of a unknown. So matthew quick clients and quick stuff on Mars may not know at all about deep space really but only the proxies at the space edge will be. Next slide So we did some simulations. So we did some simulations HTTP request to Voyager obviously in simulation. So 48 hours RTT we used a quick configured, as I previously said, and then you know, it worked. Next slide We tried 10 days are"
  },
  {
    "startTime": "01:06:01",
    "text": "and advanced know it worked next slide we tried 10 days RTT and at that time our submission environment was not doing any that was wall clock, so it was not doing time warping, so that simulation actually took a whole month to do so next slide So what do you need to do if you use HTTP? an application for deep space well HTTP itself doesn't have any notion of time, so you're fine. Unless you use cache control or expire headers so either you don't use them or you set proper values but HTTP itself doesn't have notion of time so the only thing that you need to care if you're using HP environment is that you take the timeouts, right? You make sure that the timeouts on the client and the server size are appropriately set for the RTT And you make your design asynchronous you know. And if you do, you have assets, you make sure that you use local references. Next slide slide I'm going to skip the few. Next slide So we did a few results. You have the slides on a lot of similar actually packet loss reordering all the transport semantics we tested. This one is packet loss of five percent delay of one packet loss, reordering all the transport semantics we tested. This one is packet loss of 5% delay of one-way delay of one day We repeat 10 times the HTTP requests so that a packet loss is kind of applied over the whole thing and you know obviously the total time was the same as without packet loss because the recovery was done while the other request was done when it was sent, so it worked next slide we're done we're done well your time's up but you about five minutes for questions and you have"
  },
  {
    "startTime": "01:08:01",
    "text": "three people in line okay so we did the our implementation of storing packages We did ping. Next slide Next slide Next slide. While you could do UDP so therefore you could do streaming over UDP or over quick or you could do Evan SIP so you can call you know, Mars, if you want Next slide And I think that's okay network services and Warren you want to need DNS. Well, you have something about DNA So network management, you could do it SNMP. We tested at work You just set the time out properly. Net count is using TCP and SSH so we need NetCount for very quick, which is being discussed this week, or rest conf I haven't talked about BGP or routing, but BGP over quick may be useful useful And DNS, well, VNS is kind of a isolated networks or mostly isolated networks so you need to be careful so kind of a pre-cash stuff. There's a draft about this and actually Warren helped me out in sketching the ideas around this and i think i'm all done in terms of slides and if not yet actually Warren helped me out in sketching the ideas around this and I think I'm all done in terms of slides. And if not, yeah, that's what it is. Next slide So, summary, store packets for the forwarding nodes that are facing links up and down but only those farders setting matthew quick parameters appropriately and design your application to be asynchronous with large times Next slide questions. Yeah, thank you very much. There's a sign- meeting Wednesday morning Torres. Two questions"
  },
  {
    "startTime": "01:10:01",
    "text": "Is something like quick the way you would design? it from ground up if you would have to, you know, do that? And the second question is design it from ground up, if you would have to, you know, do that? And the second question is... That's a good question. Yeah. Well, I mean, because I think that something like that should be explored, whether that's feasible in a practical world is a different question but it's always good to know how close you are to I was trying to reuse whatever we have in our tool and frankly you know you but it's always good to know how close you are to... I was trying to reuse whatever we have in our tool set. And frankly, you know, if you start having transport semantics, you know, taking care of reorder duplicates and packet loss you're probably going to reinvent and then user space and, you know, one end shake for establishing a connection. When you start all those things, you know, in abstract, you may end up pretty close to quick actually well maybe I mean I'm not sure how easy it is for quick to do, let's say, for what error correction so proactive you know for the channel being lousy for example okay good question FCC is that there's a draft of quick about using FEC. FEC is actually being used at the lower links already. And one of the users of this is that mission operations have to send commands to the spacecrafts and these are to be, you know, it's like a small string, like reboot These has to be pretty reliable You don't want errors there. So the signal error rate is not good but the frame error rate is very very low because they apply to codex in pipeline at the link layer. Therefore, the actual frame error rate is very low so you may not need that much additional FEC on the top of it. And then the maybe I overlooked it in your stack but don't you think that things like proxy converters, caches or so are going to play an"
  },
  {
    "startTime": "01:12:01",
    "text": "important role to hide as much as possible yes The novelties of these type of links from legacy endpoints. Yeah, yeah, yeah, completely. Well, can you add a little bit of it when I talk about proxies? So yeah, caching, pre caching of stuff yeah, completely. One second, Rick We need to make sure we use the hands-up thing in the app. Like, Nelani, just keep it super quick because you didn't use the... I know, sorry, sir, I need to get on the app Yeah, I'll do it. I'll keep it really quick. So I'd like to see we have a perform and extension header IPV6 extension header which might be helpful for you, performance and desk diagnostic metrics I'll talk to you after because we can help you measure some of this stuff much more lightweightly Sure Jeff has. Nice presentation, Mark Did you be over quick? No, not a thing about BGP. I think that signaling the snow routing in this stuff would be terrible So one observation, one question A lot of the protocols that you've had in prior slide are flavors of call and response protocols You know, pick net comp as an example, even as an MP Those things are going to work terrible in these sorts of environment What sort of work have you done to say? here's stacks that we do that is old school modems. We start something and we push as hard as we can can The way you're saying it we haven't looked at that perspective So I guess we need to you know, I haven't looked that way, so I'm not sure how to answer your question. Okay, maybe something to chat about whole way about. Yeah, yeah, yeah, so the second thing, so I haven't deeply read the entire quick, you know, RFC set because you guys keep a coming out, you know, tons of them is going along"
  },
  {
    "startTime": "01:14:01",
    "text": "What should I be looking at RFC wise that talks about this type of sending discipline where we're not having data? blocked actually causing usual flow control token issues? You're looking at which RFC? Yeah, which RFC should I be looking at? That's not the core, no, 9,000 well RC is nine thousand two is actually about recovery and congestion control, right? So it's like where everything kind of work christian huitema and I wrote a draft about Quick in Space, which is actually a bit outdated from the time we wrote it to now what we've been doing It's kind of due to be a new version so you'll explain so there's a for from our point of view where we haven't done documented everything fully in terms of what we're doing. It's kind of a sparse into presentations and destination things, but that's exactly what I'm seeing here is that for this sort of thing that you've had to work you have to be assuming that you're not going to be having flow control, you have to have some redundancy, you have to avoid flow control if you have a prior draft, please drop within the chat. Thanks Super quick, we're out of time There's two of you. Yeah, hi, this is peter thomassen So you showed some measurements of your simulations and from what I can tell, it's pretty much, I guess, what you would expect by scaling the time axes or time units to I don't know, millisecond corresponds to half a day or whatever and then... Okay I'll let you finish. And then adding some random stalling I'm more interested um with my question in comparisons between a communication concepts. So you, for example, said TCP doesn't work well and I understand and then you said quick however seems to work well. And quick has some retry stuff like TCP does. So I wondered, why is that? not a problem if it is for TCP and then more generally"
  },
  {
    "startTime": "01:16:01",
    "text": "you were looking at IP stuff and said okay cool we can do this experiment And we don't need to use the network bundle or whatever the other protocol was called but how do those actually compare? Why would we not just use the thing that was? designed for deep space communications? Why do we want to continue? using IP? Oh, okay, so there's multiple things about in your question. Quick um uh you cannot just expand the time because it won't work. You need to adjust is in general mechanics So that's what I was saying in terms of setting a few parameters and, you know, simplifying the congestion control mechanism to be just a flow control itself. So that's what I was saying If you don't do this, then it will be, it won't work you know, with long delays So, so there's, you know still within the RC, you know, specs but we're kind of a changing a bit, the few patterns transport config parameters of matthew quick implementation to achieve that. The other question about, shall we use banal protocol, well, it's a long debate And I think the next person and the queue will have maybe some other things to do. It's like any solution, you know there's pros and cons in each approach and I think the IP approach if you remember, we'll have IP on the surface and orbits of Moon and Mars and we have IP on Earth so if you enable IP in the deep space, then you have a single IP network, right? A single network layer everywhere makes things zillions easier"
  },
  {
    "startTime": "01:18:01",
    "text": "to do than having all kinds of gatewaying between multiple, you know, between bundle and that and stuff so. But, you know, we could have a long conversation about it Sorry, I know we are out of time. Just a quick comment and then a question. As Mark mentioned, there is a pretty big debate with BP and what is simpler and and bp to ip gateways might be simpler than thank you the assumptions of IP literally throughout the solar system But one of the things that BP does, is allow you to pick bundle by bundle when data is no longer needed when it has been stored for too long because of waiting at intermediate nodes and that was a important design decision because you don't necessarily want to keep data that has expired in systems, particularly in space systems where stored and the power associated with it is very much at a premium. In this approach, I how do we determine that there are packets? that should no longer be delivered and can be thrown away sooner or earlier? Um okay, well, um may start that debate again, but Yeah, I was just, this sounds like a mailing list conversation Yeah, yeah. And if it's already been covered, I apologize, but that No, no, no. I'm just saying we're, we are way out of time Yeah, so... Yeah, so... ...get into the end of the rest of the light. I think I was just, this sounds like a mailing list conversation. Yeah, yeah. And if it's already been covered, I apologize, but that, no, no, no. I'm just saying we're, we are way out of time. Yeah, so. I think overall, I would say super thanks for the presentation the mic. I think overall, I would say super thanks for the presentation. I think a lot of people were interested, me in particular I think there's a lot of stuff that could be done to, you know, to expand and move on but maybe now is not that, maybe right now is not the time That question, there's debate on between the two alternatives Yeah, sounds like, you know, work. Yeah. You understand Yeah, thank you very much. Is there a Carlos in the house? Yes. Is there Carlos over that? All right, Carlos"
  },
  {
    "startTime": "01:20:01",
    "text": "you have 15 minutes for the slides and five minutes for questions and hopefully we'll stay close to that Do you have click anything or? Just say next. Yeah, just say next So morning, this will see very boring after Mark's incredibly cool presentation but I will try to make it interesting. Next I'm why I'm here, I'm, well, Carlos, most of you know me perhaps some of you don't I work for lagging one of the five areas. And my goal in this presentation is to bring some lessons we learned while migrating our P-K-I-CA to a completely new architecture and a complete new set of software, basically sort of a brain transfer of the whole RPKI system Next. So I'm not going to explain what the RIRs are just there are these organizations that have little black books where we write who holds which IP address. And the most relevant part of this for my presentation is that Lagnick together with APNIC are the only two RIRs who have a part particularity of having national international international under the main registry right? We have the NIR in Mexico and the NIR in Brazil that will be significant for what comes after this Next So basically what we have, the services we provide for users are basically through a web port We also have a Rest API and we have also delegated RPKI or up down, depending on which you prefer to use prefer to use. This is how the members interact with the system basically for ROA creation Back in the day, we allow some control over the certificates the resource certificates themselves, but we basically try to hide much of that because actually there's"
  },
  {
    "startTime": "01:22:01",
    "text": "little pointing members operating over the certificates. For some reason, I would say 99% of all user interaction happens through the clicky thing on the web portal, which I sort of fail to understand but whatever. This is, it is what it is so there's the registered database which is the little blackbook with RP addresses are. There's the CA and then, and this is relevant again we have under our CA, the delegated Brazilian CA, which is very large it's actually larger than the male lightning one Next Why, I mean, some people may ask us why we decided to move to a completely clean slate design because of reasons. I could, I could hours about this, but to make it short the old system had been patched over and over again and features added over time and at some point we decided we need a completely new thing It was about two years ago. Next I'm not going to detail, but this is what we came up with basically we split the whole thing into different components, we modular the interface with the center pool, the registered database. We created this command cues and we split the CA in a couple of sub-CAs plus a publishing system So when we start, to consider how to implement different, the different components you just saw in the last slide at some point we had to be a bit, I would say try to learn our own limitations and decide if we really wanted to implement a whole new signing CA ourselves And if, even if we did that, if we could actually keep up with the work that is coming out of the"
  },
  {
    "startTime": "01:24:01",
    "text": "ETF. And the, I mean, decision we made is that there is something that we can use that does most of them It lacked some of the features we needed but uh with their help of NET labs, we could actually have them implement that for us. Next So we try to avoid the not invented here syndrome that sometimes, you know, permeates many of the organizations we work for. So we had some red lines during the migration we wanted to keep the same TAL file because hope hopefully, sorry, currently right now, there is no way of rotating the TAL. There is no equivalent of RFC 5011 for RPC rpkai hopefully hopefully there will be in right now, there is no way of rotating the tal. There is no equivalent of RFC 511 for RPKI. Hopefully there will be. And I hope of few weeks. The thing is even when the RFC comes up RPAI. Hopefully there will be in I hope a few weeks. The thing is even when the RFC comes out, it will take time for CA and relaying particles to implement that We wanted to avoid long-running instance of relaying party tools to have to reset their caches and we have a expectation of doing a zero-down time migration of this delegated Brazilian CA Next Some of the challenges we found RPKAI, especially RPCA development is notoriously hard to test because it's really hard to instantiate whole trees with damage data, for example Perhaps you can do that with grill, but doing that with the proprietary system can be very hard It's testing, doing good testing of our PGA tooling it's it's kind of hard We wanted to pre-testing the integration with the member portal and we would like to have the ability to have both the old and the new system running in parallel"
  },
  {
    "startTime": "01:26:01",
    "text": "And we wanted to be able to validate the strategy for migration we work thinking about. Next So things we learned So I would call them ideas that the things we learned. So I would call them ideas that paid off in a way When developing the interfaces with the member portal, we created the internal API that communicates the portal with the CAs into an internal API that actually can publish to multiple CAs at the same time We did actually the last code modification to the old systems so it understood this new API did actually the last code modification to the old system so it understood this new this new API and we and a year and a half ago more or less we started running both systems in parallel the grill base system and the air and the old system system the grill base system and the air and the old system. We could have many of those, and I have an idea for that, that may be this discussed with you during the week next So the high-level idea of the mind migration will be to have the old and the new running on the city times, publishing on different sets of servers and be able to switch between them using DNS, changing the DNS records, right? right? We started running the whole pipeline in parallel about October last year We found a few bags actually When there was a funny one that was found during the Lagnig event in Fortaleza in October and corrected during the week. Thanks, Tim, by the way So the idea is once we're comfortable with the outputs of the old system being consistent with the new system, it will be time to change DNS records next This was really interesting and this took a lot of discussion and backup"
  },
  {
    "startTime": "01:28:01",
    "text": "and forth between the different parties How to do the zero time migration of the delegated CA? for context register of ER have been running on grill for almost five years, if I remember correctly. And Krill support the idea of multiple parents Someone asked why just you know, changing the hanging point of the CA from the old to the new is not enough in the reason that it's not enough it's because the service that registered VR provides to its members is also delegated RPAI So during the time that the third level of CAs go back to the parent and resign the repository, they will basically decide time that the third level of CAs go back to the parent and resign the repository, they will basically disappear from the internet. And that would take days or even weeks And I will show you a graph. We actually got some numbers for that So the idea was to use this feature that Krill supports multiple parents. Add the new and the old at the same time. This is not why this feature was created but it's sort of it was welcome feature It doubles the repository size, but the thing is most of the repository are kind of small. So it's not a big deal Next. So the end I mean the final the final component of all this is is this going to work, right? Once liu chang DNS records, long-running instances for relaying partit tools are happy with just seeing a new RRDPC session and keep on chewing, happily or not And this proved a little bit hard to do because we always wanted to test different versions of relation party tools. So lesson learn here Docker is your friend. And then is my different versions of Relating Party tools. So lesson learned here, Docker is your friend, and DNS Mask is your friend. I don't know if many of you know what DNS mask is, but it's a really cool tool that I have"
  },
  {
    "startTime": "01:30:01",
    "text": "discovered during this Basically, it's a sort of smallish DNS server that you can use as a proxy DNS or a local reserver, caching resolver, or you can use it to insert records, arbitrary records that, whatever, sort of an ATC host as a service or something like that It can be controlled automatically from a script, so we wrote some scripts that allowed us to run Docker instances of whatever I had a Docker instance for. And actually, scripted the back and forth in the DNA between all the new, all the new We learned a few quirks about how Docker actually configures DNS resolving for the containers, but there are switches you can use to override that. And we actually tested these three Relating Party tools all the way back to the earliest Docker image that was available for them. And I don't have the numbers exactly here, but for example, for Routinator, we had like a four almost five years span of version that had Docker images available. Fourth, we had Docker images also going back almost to 1.0, an RPCA client there were like a good, a good two year and a half, almost three years of versions that had locked images. So it was worked. We were quite happy with the result We find a couple of things that were easily corrected during doing tricks on the server side like doing touch on the certificate, because some of the versions of these Relating Party tools will not reload the certificate because they thought it had not changed or something like that Next This is the timeline of what I described This is in the order of things happened. And this graph that I included down below is it shows the moment where the second"
  },
  {
    "startTime": "01:32:01",
    "text": "parent for register VR was added. And you can see, we start from the 16 south and something VR piece that they are like the period second parent for register VR was added. And you can see, we start from the 16 south and something VRPs that the Peer Lagnet repository has. And you see this run up while the the delegated CIs from register VR go back to their parent and resign the repositories And they become visible under the new tree It lasted for about a day and a half and there was a slower ramp-up that lasted for days Next so on the end the final part of all this was trying to keep all the parties the stakeholders, I would say, income on what we were doing, communicating with them And actually, I asked for help to many of you And thank you for that, actually. I don't think that I mean, we have and actually I asked for help to many of you, and thank you for that, actually. I don't think that would, I mean, we would have, you know, the nerve of doing this without having the back and forth with many of you. So thank you for that that In the end, when we did the migration, and it was a bit of a letdown because in the end, the whole migration lasted like for 30 minutes because it was just you know shutting the old system, changing the DNS records and waiting wait for it and just worked but um again, thank you for all your help And again, I brought this because I don't know maybe some of these ideas may be useful from our operational perspective for other people operating CIs So, I think that's the last one Thank you. Great. Thank you Any questions? There's five minutes for that Hi Sorry. Tim Gersels, uh, the ripens"
  },
  {
    "startTime": "01:34:01",
    "text": "our lab back in the day, but this was ongoing I wanted to just make an additional comment on the strategy to have both systems run and power know a lap back in the day, when this was ongoing. I wanted to just make an additional comment on the strategy to have both systems run in parallel and add an additional parent at the level of NICPR Another reason for doing this is that it would be much easier to revert as well in case of issues because otherwise the communication between these systems would be could become very confused when suddenly you think you're talking to your old parents but they're actually new parents. And you want to go back and then all kind of things can go out of sync so that's the thing to keep in mind for these things Thank you Good. Great Sorry, I have a sort of comment for you, a question Me, I do. Sorry, Chris I was not on the tool. Yeah, I'm sorry, Chris, I didn't put my myself in the queue, so I'll dig myself for that too. I work for Google and do security stuff. Anyway, uh, said in the early part of your talk, like, testing this is really hard. I don't really understand anymore why it's so hard. So like should the cider apps group or some be, you know, decompose this whole thing down? better and then try and work out how to get the parts tested? It's not just that RPI client and Fort might do different things they may and that's a problem that could I just pick two things by a happenstance. By the way, I don't actually have any idea what any of them do Like, it's this not a problem that could be decomposed and then? some framework for testing this could be built? Like, making certificates is a, I don't have a shell script that does that it's not hard right like I don't really under why it's so hard because there's no really good tooling for for example creating fake repositories"
  },
  {
    "startTime": "01:36:01",
    "text": "or introducing control failures I don't think it's a I mean, it could be a cider ops topic, but I'm not sure it's actually a protocol problem, is rather a software issue Sider-Ops is an operations group. It's not a protocol group, which somebody- in the, somebody in the group will be happy to tell me three times So yeah, I don't think that's I mean, we could discuss us inside drops I would say something along best practice for our pk software testing or something like that. Okay. Thank you Thank you Which one's this? This is DNS second test in post quantum. I think it's our last one Oh, it's our last one, or we've messed up the time The timer will be down at the bottom in a second Okay, hi, it's Peter I'll give you a quick presentation on our post-quantum DNSSEC experiment with various algorithms in the field. It was the right Atlas study, connected together with Jason, who's sitting there with a red cap to be recognized okay next slide or do you want me to no nope I got this sorry okay all right um so in 2022, we did another study with just Falcon implementation and PowerDNS. And we wanted to expand that and do a field study with an actual public department The PowerDNS-Falcon thing was just local Docker things and internal measurements And yeah, so we implemented in PowerDNS and in Bind, various post quantum signing schemes and put those on the public internet so that one could do one's own queries and see how it goes but also do queries from other vantage points from RAP Atlas and then do statistics on them"
  },
  {
    "startTime": "01:38:01",
    "text": "We implemented both signing and also validation So one can interoperate, for example, validate bind signatures with powerdiness and the other way around The measurements were parameterized along a number of dimensions. So for bind, we used a KSKZSK set up, which is essentially having two keys and one of them being kind of an intermediary to the other And for PowerDinas, we use just one key which is called a CSK scheme then we also looked at domain names, like we set up our test zones, and then we queried names in them that existed and also names in them that did not exist, which in DNSSEC causes a response that has a proof of non-existence and there's various ways of configuring that there is NSSEC and NSIC 3 And for NSEC 3, there is empowered DNS, the narrow mode and the conventional mode in both PowerDNS and bind so we use those two different parameters also because they impact response size Then we did queries through UDP and TCP and we also did set the D-O bit or did not set the D-O bit If the D-O-B is present, that means that the client is interesting in DNSSEC stuff So the Reserver will request it from the authoritative server again increasing the response size And then let's see how it goes. So next slide, please Here is an overview of candidates for post quantum signing It's taken from a paper by Moritz-Muller who did a study, I think, in 2020, about which algorithms might be useful. We focused on those that have public keys and signatures below 10 kilobytes which already is pretty large for the DNS. And we didn't look at things that have like, I don't know, picnic with like 34 kilobytes, which seems hopeless We also, for the sake of fans, included the stateful hash based scheme that does have larger signatures, but why not? So it's called XMSF Next one"
  },
  {
    "startTime": "01:40:01",
    "text": "We did implementations using LIPOQF which is kind of an open SSC thing for post quantum algorithms. We used Falcon 512. As before but also for Bind, not only for PowdianS And we added dilithium to the name server stuff, we added Sphinx plus and we added xMSs in two flavors once with Merkel trees and once without Merkel trees, and there is all kinds of parameter sets which depend on how many signatures you would like to be able to do before it gets insecure That's related to the XMSS state. We can talk about that later if you have questions. Then we went on to RIP Atlas and at RAP Atlas and use gets insecure. That's related to the XMSS state. We can talk about that later if you have questions. Then we went on to Ripe Atlas and used about 10,000 probes in May 24 to run all of these different combinations. It was roughly 2 million queries thank you for everybody who to everybody who donated RRIB Atlas credits in case anyone's here And we recorded the return code of the DNS response. We recorded whether the response was correct with correctness we mean that for non-existing names, actually an X domain status was returned and for existing ones that we did query A record that we actually did get the expected a record content and also the expected no error code that we did not require for example that validation was done in order to call the response correct we also recorded whether the AD bit was present in the response, which is present if the resolver wants to indicate that validation was done and we recorded response time for the sake of completeness, which I'm not going to present, though, because it's not very interesting We pre-selected results to make more sense of them. First of all there is some noise in wrap atlas Some probes are I don't know, in a weird setup environment so they don't even do unsight they don't even do insecurity and escrow in weird setup environments so they don't even do unsc they don't even do insecure DNS correctly so we excluded those we required"
  },
  {
    "startTime": "01:42:01",
    "text": "that any probe resolve a combination would have a correct response for algorithm 8 which is RSA RSA-H-R-256. If you don't have that, then you don't have let's say, old-school DNS in a proper way. And if we don't have that we don't need to talk about PQC DNS sec we also excluded resolvers from private IP ranges like 192, 168 and so on and so forth Those could be valid resolvers If they run the local network, that's fine But RAP Atlas can't query them over TCP because of some limitation in their stack and to make things comparable in terms of how the sample is selected, we applied the same restriction to udp we also didn't look into network errors like destination and reachable and that stuff we just ignored it in our results sample. Next slide Yeah, so this is kind of an example of the queries that we did or the Drive Atlas did So this is with the deobit set, the lithium query for power de-dios through the Google Public Resolver As you can see, the response flag in maybe line 7 or something don't include ad the lithium query for PowerDiase, through the Google Public Resolver. As you can see, the response flags in maybe line 7 or something don't include AD, so Google admits to not validating our dilithium implementation. And you can see in the RRIC record that we use algorithm number 80 which is not from the private range it's an unallocated non-private number and we use such numbers because we wanted to make sure that it looks like any algorithm that a reservoir might not support but we didn't want to risk getting special treatment because of private range next slide um so we'll show you eight diagrams in total this is one diagram not four um And I will tell you how they are organized, and I have some notes here, what I want to say about them. So the first, the upper row, is always a UDP queries, so it says TCP files and the lower row is is"
  },
  {
    "startTime": "01:44:01",
    "text": "did I say upper TCP, I want to say upper is UDP and lower is TCP. Left column is with a D-O-bit false and the right column is with the D-O-bit true And we're looking at the bind implementation here. You can see in the title vendor is bind and is an X is false So this is for an existing name. And you can see that the response code is no error in a hundred percent of cases of of rs a shah 256 which is our pre-selection so that's plausible. And overall, I'm surf-fail doesn't really occur for classical algorithms and it does occur for the PQC algorithms as response sizes get larger and it happens to be the case that as you go down in the algorithm dimension response sizes get larger so so fails go up roughly. You can see if you, for example, go from udp to TCP without the deobit set delivery rates increase so surfail goes down, if you look at XMSS, for example, about 30% in the top left quarter and only about 70% in the bottom left quarter Yeah quarter Yeah, okay, next time So this is the same thing for PowerDNS. The only difference really being that now it's a CSK setup, so there's one less key So a DNS key responses are smaller and overall delivery rates are better And especially for Falcon, you can see that the success rates are really high. It's 97 over UDP and even over 98% for TCP Next slide This is a big expansion of the algorithm space, it seems. So what it actually is is the same algorithms but there is one insect and one insect three for each of them, because now we're asking for non-existing name. And again, you can see it's fine for RSA 256 which is a pre-cellar"
  },
  {
    "startTime": "01:46:01",
    "text": "And if you compare NSEC and NSEC 3, hold on yeah especially for Delith lithium 2 let me see where that is yeah it's, I will walk here here here If you look here, you can see if you compare dilithium with insects the failure rate is 38%. And if you do NSIC 3 it's 43%. That's a small difference but the difference is larger than it is for other algorithms. And that seems like some boundaries crossed in terms of deliverability, reliability When you do that, there's all kinds of boundaries, MTUs, and and that seems like some boundaries crossed in terms of deliverability reliability when you do that there's all kinds of boundaries empty use and all kinds of things it seems like specifically for this setup with CSK, KSK set up with Bind, if you go to Anthethic 3, then some people start getting more problems So the bottom line of this is it depends on all kinds of parameters and you get to interesting explainable behavior yeah so next slide This is with PowerDNS dns with a different kind of NS3 setup which is the so-called narrow mode and they're the interest result is in the last algorithm, the XN XMSS. If you go from NSIC to NSC 3 there, you can see that failure rates actually go from 20 or 30% to over 50. That's because the message size then exceeds 64 kilobytes, which is not deliverable. So the only ones who do deliver it seem to not actually request it um yeah the next slide so in this diagram here we have with the response was correct. So the left bin in each of them is response was not correct, right bin is it was correct. And we can see that it's roughly"
  },
  {
    "startTime": "01:48:01",
    "text": "100% correct responses for conventional algorithms and 70 or 80% roughly for the PQC algorithms and if you go from you to TCP, generally things increase by or improve by around 10%. You can also see if you compare left and right that things go back or worse if you set the D-O bit with is because you're requesting DENessec records and then responses get larger. So most of the time, well, not most of the time but it happens you run into serve fails. So then the response code wasn't the one that it's expected and correctness is zero Next slide yeah this is the same thing with just a little better numbers because there's just one key again in the PowerDNS case and you can see again that this improves things by roughly 50 on average and notably again fact is doing pretty well And then finally, we have the AD bit, which is on the next slide This is really interesting. So if you use DO equals zero then nobody really sets the AD bit because you're not requesting validation unless the Resolver really wants to do it But if you set the O bit then validation is requested And for the classical algorithms, roughly 30, 40 actually do it. That's in line with statistics from APNIC, for example, they'll say how many resolvers to validation And for the PQC algorithms, validation obviously isn't done, except for Falcon, it seems which obviously must be wrong right I mean we we're pretty certain that not 8% of ripe atlas probe resolvers to actually validate our Falcon implementation and interestingly it goes away if you use tcp so it's it's not really clear what what kind of software that is that, that does that Next slide Yeah, same thing for PowerDNS no difference. Next slide"
  },
  {
    "startTime": "01:50:01",
    "text": "okay um so the the main takeaways of this are um takeaways of this are, I don't go through it really in case you want to look up the takeaway numbers Slide 14 is the one you want to look at um next one yeah this is a benchmark done with PowerDNS for the different algorithms, the classical one at the top and the PQC ones at the bottom. Left column is key gen time, then they're signing and validation And the takeaways are essentially that for Falcon, things are in key gen time, several orders of magnitude, better than, for example rs a is on par with algorithm 13 for example The scale is logarithmic. And signing and validation is fine in terms of time but for example if you look at Sphinx then signing is pretty long it's like 0.2 seconds per signature And specifically for XMSS, it's prohibitively expensive to generate keys. It takes several seconds So not only the message size is a problem, but it's all not suitable for generating keys at Huck Next one Yeah, so this is the same query as before, except we're not using a Google Public Resolver, but we're not using our bind validation implementation to validate the PowerDNS del lithium signature. And it's the same response as earlier, except that the AD bit is now set this runs on port 53 or 4 of our tests server if you use port 53 you will get to the authoritative server not to the resolver So we have a set up these things you can query all of that yourself in very 53 you will get to the authoritative server not to the resolver so we have set up these things you can query all of that yourself in various combinations there's a website that explains how it works i think it's on the next slide yes there it is it's PQ-DNSSEC.D9.I.O And you have like a nice form where you can select query thing DNS key or A or whatever you want. One of the algorithms, classically, or PQC, and you can select which vendor you want for authoritative or for Resolver. You can select whether the name you're querying is existing or not and if it doesn't NSEC or NSEC 3 then you hit query. It goes through a DOH prox"
  },
  {
    "startTime": "01:52:01",
    "text": "and you get a dig kind of output at the bottom where you can see how things actually behave. And you can also use your command line to do this. So this is the real deployment that was used by the WRIB Atlas study. I think that's it Next slide is the thanks slide I want to give a big shout out to Jason who did the hardlifting and happy to take it was used by the Riber Atlas study. I think that's it. Next slide is the thanks slide. I want to give a big shout out to Jason who did the hardlifting and happy to take any questions hello hello Robert Gischdke from RIPNCC providing Atlas for 14 years now Thank you for this, it's lovely. Not a defense, more like a justification, you cannot ask DENSQaeda is against resolvers on the private IP address not privacy 1918 and such like that, because it would let you evaluate the local network. And, you know, we can do that but you can use the probes on resolver and for some of these questions it may or may not be useful. But I'm happy to talk to you offline about this if you want yeah yeah we can talk about it so we only use the Probes on Resolver so because you wanted to do whatever the probe would do in a real setup. And from what we learned from talking, to folks was that over TCP, even if the probe's own resolve, is in a private range then it won't do the query But if it's the UDP query, it will So actually we had to exclude those measurements But we can take it offline, perhaps. And maybe I misunderstood that aspect Q is empty, everybody hungry or everybody distracted? from Biden's news here in Canada. Okay, thank you. All right, thanks in Canada. Okay, thank you. All right, thanks so thank you everyone this brings us to the end of the IABG meeting keep in mind"
  },
  {
    "startTime": "01:54:01",
    "text": "we will, as always, have another IABG meeting at the next IETF. So if you've got interesting operational stuff to talk about, please do so Also, if you've got any feedback on this, any of the presentations, come along and talk to chris box myself Thank you again, and I will send the slides to Jeff, who will kindly post them for us on IABG.org because thank you Thank you so. I think so. I think so whoa, whoa. Yes, they are. I believe so. I think so"
  }
]
