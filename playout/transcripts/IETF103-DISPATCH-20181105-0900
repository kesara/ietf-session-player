[
  {
    "startTime": "00:03:42",
    "text": "just thank you hello whoa sorry um hello all we will get going with our meeting here so I\u0027m going to let\u0027s see I guess we can start on the main things welcome to dispatch we have fact is Mary on Mary Mary one of our co-chairs Mary will be online remotely here so she is joining that way and Marie and I will be at the front this time but thank you for all the fish we\u0027re both stepping down after this meeting joy across the realm so we have blue sheets circulating somewhere yeah great and we have found a kind scribe thank you over there Shawn somebody wanted to do some jabber relay Ted\u0027s done that great this is the first meeting this is the note well statement you need to understand all the things you\u0027re agreeing to if you get up and speak in here or hang out in here in general you can find the references to them here and with that I want to jump into a little bit of agenda bash before we hit the other stuff so we let\u0027s see get over to the agenda here we mistakenly put this secret token URI scheme in the art area meeting which it should not be it should be at the dispatch meeting so we\u0027re going to move that up to sort of up to the front with the HTTP header registration so we\u0027ll do Mark\u0027s two drafts first and then move on to the the other part of the agenda they also have a little bit of open mic time at the end of the art area meeting just a few people want speak to any other agenda as we need to deal with your silence is stunning so with that see if there\u0027s anything okay I need to talk about deadlines so this is our proposed deadlines for the next IETF keep in mind we do these deadlines to try and help you so that we can you know better try and get things to the right place and make stuff actually happen before they\u0027re submitted at the very last minute like you always all do if you miss the deadlines because you always do well then you go to the back of the line because that\u0027s really all we can do if we could do worse things we would the mailing list we have two mailing lists one for dispatch okay "
  },
  {
    "startTime": "00:06:43",
    "text": "that\u0027s about documents need to go somewhere and there\u0027s also the art area lists it\u0027s often these confused but just be aware that there are the two mailing lists so with that let us jump into one of marks documents which one do you want to do first mark let\u0027s discuss patterns we\u0027ll click it\u0027s hard to use them I can be in the pink box okay can I move the box excellent good morning so right now we record our header fields for htdp in a common registry the permanent message header field names registry we also have a provisional message header fields names registry which I won\u0027t talk about right now but in that registry we have all the HTTP headers and a bunch of other stuff as well and that was defined in RFC 38 64 Graham kleine drove a lot of that I did some of the HTV stuff and Jeff Mogul helped out as well way back in 2004 way back and so in that registry we\u0027ve got HTTP headers we\u0027ve netnews which is n MTP we\u0027ve got mail and mime I\u0027m still a little shady about the distinction but okay and we do not have SYP SYP has its own separate message head of registry for reasons which escaped me but I\u0027d love to hear about so I raised an issue in the HTV working group a while back we\u0027re doing the HTTP core documents revising the HTTP core specifications yet again and I noticed this and it had been bugging me for a while that the HTTP headers were mixed up in this other registry which had a couple of bad effects which I\u0027ll talk about in a minute so I raised an issue and we discussed it in Montreal and the feedback in the room was yeah probably makes sense to pull this out into a separate registry but Alexi pointed out that we needed to talk to a greater community about that because that registry was not set up by the HTTP working group it was set up by another process if I remember correctly that was AD sponsored but I could be misremembering Dispatch didn\u0027t exist back then but dispatch is clearly a place to talk about this now so that\u0027s why I\u0027m here hello and so I put together a strongman draft which I haven\u0027t had a chance to submit yet this is not what\u0027s formally being proposed in the HTTP working group and it\u0027s not something for this group to discuss but it does talk a little bit about the motivation for why we want to pull the HTTP headers out of that common or registry into their own registry and it\u0027s beyond things like just making it easier for people who are using HTTP to look through this huge laundry list of header and field names and sort out which one\u0027s apply to HTTP there\u0027s also things like it\u0027s it\u0027s difficult to evolve the registration process we want "
  },
  {
    "startTime": "00:09:44",
    "text": "to modernize the registration process it\u0027s a lot harder to coordinate it between a lot of different communities than it isn\u0027t just one community user confusion like I mentioned the extra review process that\u0027d be nice to have an expert apply the HTTP criteria for headers and all the considerations that we\u0027ve come up with which are quite extensive in the HP documents consistently to the headers and to make sure that the HP community is a perfectly involved so that\u0027s my motivation Alexi asked us to bring it to dispatch there seemed to be supporting the HP community for doing this and the question is does this make sense to everyone else and I already see an area director at the mind I see an area director at the decoration okay so I was actually not here as an area director I\u0027m here as a civil war veteran I was gonna explain you asked twice if did this and then put up a slide that I\u0027m looking at right now that says why sip did this and yeah we ran through the same analysis and I think you\u0027re going to find at least the people that work through all that agree with the rationale here and I I think splitting it out is a good idea Thanks I just wanted to check what did you plan to leave the other registry in place or create several ones for each of the things that\u0027s currently sharing it that\u0027s not my problem we would leave the I think the idea here is is that the HTTP header registry would be split out and the current registry and registration procedures for the other where our protocols would remain the same if those communities choose to revise their procedures or they choose to get together and revise them on this that\u0027s totally up to them I just kind of related and then headers that are currently only apply to HTTP within that registry would you also kind of try update a registry to obsolete those with in there and save refer to new registry or they would be taken out of the registry and at the top you\u0027d probably have a little thing that says hey if you\u0027re looking for HTTPS go over here this is Barry liebe one of the reasons that they were let that they were put together in the first place was to make sure that header fields that had similar sense were commonly defined but they kind of are but do you have any sense that that going forward as the registries are split we would try to keep a coordination there so that they we don\u0027t wind up with a header field that has the same name in both registries but a vastly different function we already have that we are we\u0027re already there but no one in practice no one goes and checks to make sure that there\u0027s not a conflicting header name in the registry you know for another protocol before they come up with their own it just doesn\u0027t happen you know no let I think this is the core "
  },
  {
    "startTime": "00:12:46",
    "text": "of Alexie\u0027s concern is is that he likes that level of coordination I think we can certainly come up with tools to help you have a common view of all the registries to see where there\u0027s overlap or you know no sir I think you may be maybe I\u0027m not being clear okay in the current registry if let\u0027s say content type sure it\u0027s the same it\u0027s one registry it\u0027s one name and this has a definition no it\u0027s not it\u0027s not you can have four or five venture however many ah yeah it\u0027s it\u0027s it\u0027s a double keyed registry you look at the protocol field and the name okay thank you as Marie from the floor this is terms of how to dispatch this this sort of feels like a tiny never meets in person working group rather than ad sponsored thing well we\u0027re dispatching things right so so to be clear this is the HTP working group asking hey is this okay I I\u0027m sorry I thought you were asking for us where to do this oh no my mistake Pete Resnick I am completely okay with the idea of doing this and to go back to Barry\u0027s point about keeping coordination what I think you\u0027re doing is sort of reversing the priority the the current registry is make sure they\u0027re coordinated and then we\u0027re gonna have different semantics by labeling them HTTP or something else we\u0027re doing it the other way around I think that\u0027s fine but I do think at some point you do want to roll it back either here or somewhere else to make sure that that coordination function gets written down in some interesting way so that we continue to keep one big Grand View of these things so what Alexa and I have talked about in the background is having some sort of alternate view and we need to talk to Ann about this so that you can have a consolidated view of all the registries it but my observation is is the audience for people who want to view it just for one protocol is pretty massive the audience of people who want to view the consolidated views is quite small and most were in this room hello this job to me it seems that you\u0027re dealing with a two-level problem and should have a two-level solution as in it would make sense to simply put one paragraph in HTTP registry registration procedure say and by the way registry and the common headed commentary if you need to cut down the requirements of the common having added against year - yeah someone needs to be able to fill out the form doesn\u0027t that would be no big deal so you\u0027re saying that you should register everything twice now I\u0027m saying that part of the procedure of register registering it once includes writing it up in two phases I don\u0027t want to raise the bar for registering headers I would for HTTP "
  },
  {
    "startTime": "00:15:46",
    "text": "here this or other I I care about HTTP headers you don\u0027t want to raise the bar for a dragging HTTP headers no I\u0027d you know and do you think that it\u0027s already too high yes do you think do you think actually and loading them in the common registry will raise the world requiring people to do anything extra is raising the bar we\u0027re dealing with a lot of people who frankly don\u0027t really care if it\u0027s registered or not so we need to make it as easy as possible for them we went over what conflicts that could the dumb back in that I see I see or as here is you yeah John Levine I have a question in a comment the question is to what extent do people use the same code to parse web stuff that departs mail I think there is well I think there\u0027s common libraries two parts part outline parts if if the people are using mime library suppose HTTP they\u0027re probably doing it wrong okay I believe you and the other thing is sort of a meta comment and Dave Crocker is a door leaf thing we ran into a similar problem that the you are the names for the for URI record resource record types are indirectly defined through the enum services registry you know and and the URI URI expect says well they the the names are either a protocol name like for syrup or it\u0027s a service name from enum services you know and we\u0027ve been scratching out you know and it\u0027s sort of and since neither of them have added anything in the past decade the overlap problem is not urgent but I think this is now the fact I but that with sort of the same week I\u0027m running into two places where we have fewer industries that would be nice just to coordinate to the extent that we avoid gratuitous name collisions it\u0027s like I don\u0027t want to necessarily make more work for I Anna since they will cheerfully do whatever we ask them to do including you know standing on their heads and dancing but I\u0027m going to do I\u0027m gonna give it something we should sort of think about in general about having coordinated registries because it comes up or Newark at the line after Johnson so what is the registration look what is the what if we have the term the rule for actually this expert review ah believe so yes so the VEX pert review the expert view instructions could say make sure there isn\u0027t a conflicting header and one of the other things or at least figure out why I think that\u0027s reasonable thing for expert review because the expert is the one who would know this not the registered person would do the registration so to be clear we don\u0027t have that requirement now and with a combined registry it\u0027s it\u0027s literally just hey look there\u0027s some other ones with the same name and think about whether or not that\u0027s a good idea I mean I think the expert could be the one who says think about and again it\u0027s not must not it\u0027s the expert review is think about the other thing to push back against the the registering it twice thing we\u0027ve got in RTP we\u0027ve got a dead "
  },
  {
    "startTime": "00:18:50",
    "text": "registry of RTP payload type as well as the mime types registry and the inferior suppose registering things twice but nobody does so I would strongly push back against two registries because they will get out of sync really easily despite I Anna\u0027s best efforts ah so I have not actually heard a single person speak against doing this idea I think that we can dispatch this as this is the way the HTTP group should proceed any objections to that see lots of thumbs up okay so for the minutes we\u0027re going to proceed with the HTTP should check out at the roach motel and do whatever it is they do thank you hi so I have a draft that I asked to be dispatched this is just me so it is a very common problem out there and there\u0027s plenty of news articles I selected a fun one from the register about how people get their credentials somehow released into the wild often by checking them into a repository oops and in fact if you do a little searching around you see lots of evidence of people who have realized this in places like github and removing their authorization tokens it\u0027s actually quite a widespread problem there in fact it is so widespread that there are now tools that people have come up with to find tokens and repositories and remove them with prejudice prejudice and indeed github has product around this and this is really interesting they scan for tokens in repos and do things when they find them and they\u0027ve identified the format\u0027s of several common tokens those of AWS as your github Google Cloud slack and stripe of course that\u0027s not the only people on the planet who use authentication tokens and actually before that announcement came out I had a little bit of a brain fart on Twitter where I said what if we created a new URI scheme for access tokens and then github refused to check in textual content that contains it and I got a lot of interesting responses to that and I talked to a few people in history and they said hey we actually might use this so that being the bar for hey let\u0027s try and do this for me I brought a quick draft called the secret token your eye scheme it is very simply a URI scheme that I did some sort of token that you want to keep secret it has a very permissive syntax this happens to the user a UUID there are plenty of other things you can stuff into it and that\u0027s it that\u0027s the idea and so my question to dispatch is is this good enough to try I think this sort of thing is in the class that it\u0027s a bit chicken and egg there\u0027s interests from what I\u0027ve seen in "
  },
  {
    "startTime": "00:21:50",
    "text": "people adopting it I talked to the engineer behind the github token scanning he was like hi I hadn\u0027t seen that that looks interesting but people are a little worried of actually producing and using or scanning for tokens in this format until it\u0027s standardized and we don\u0027t want to standardize it without any evidence of use so that\u0027s the chicken in the egg and so I was wanting some feedback to see if people think this is good let\u0027s try and if so should it be ad sponsored or a working group for an independent submission do we do it permanently registering the Ornstein provisionally which as we know isn\u0027t very very easy what do people think this is a digression back to the previous john cleansin I know the decision was just made without provision for review on the mailing list they don\u0027t have a problem with this particular decision but it is important to note that an important IETF procedural principle was quietly ignored let\u0027s just take a second to go back that for John so John I I did think about that before I said that and if you think we should we will review these these minutes on the list as always and and go over that decision but my thinking was that where this decision is going to actually be made is in the draft that does that registry and that draft will be widely reviewed all we were really doing here was discussing which mailing list that draft was going to be discussed on which seems more of an administrative level thing than a choice of think so perhaps we made the wrong choice there and I\u0027m happy to correct that well we\u0027ll go we\u0027ll go make sure that\u0027s that\u0027s in the minutes and we in review of the mailing list but that that was what was going through my head when I said those words alright Paul Hoffman talking about this draft although actually only obliquely being able to search for things easily in github has a lot of value and I work at I can some of you know that we just rolled the root KSK it was pointed out to us a couple months before the role that there were a bunch of a bunch of repos that had the old KSK and not the new what KSK in them and so that indicated oh maybe they didn\u0027t know to update and we mechanically went through as many as we could and sent issues you know like like mechanically sent issues to a lot of people saying don\u0027t know if this matters or whatever we got a lot of very positive response back we got some a little bit of negative response we got a lot of positive response some of its saying don\u0027t worry about it no one\u0027s ever - you know no one has implemented but some people going oh wow shit you\u0027re right so something like this even if github doesn\u0027t prohibit it but just being able to mark something like this so that white hats or grey hats can find it our our we were surprised we thought we would just get flamed for like because we said we are spamming this issue you know like no human typed "
  },
  {
    "startTime": "00:24:50",
    "text": "this we still got a lot of very positive response back and fixes so I think that even if you can\u0027t get like github to prohibit this but if you get any uptake at all it will have a positive value on the world ten-thirty this seems like a classic case where making it provisional and upgrading it if we see see use would be exactly in line with the way that\u0027s described so unless you feel like people won\u0027t take it up because they don\u0027t believe in Provisionals and that\u0027s certainly not my experience I would say that would be the way to go I tend to agree as long as it\u0027s an RFC I think it\u0027ll be fine yeah Tosun that\u0027s a reasonable approach I know that the - has caused you a problem already I know it\u0027s a bike shed but I\u0027d just like to raise that point we\u0027re gonna ignore that comment so is there any does anyone have any advice about what path this should take look let me rephrase that slightly more pointed would any ad object to sponsoring this we suggested ad sponsored was the ideal path for this especially considering how many ship documents I have agreed to Shepard recently Wow now that was blatantly I love it yeah it\u0027s yeah I just spoke to Alexei and I just heard Ben this is Adam Roche we have no objection to ad sponsoring this no one\u0027s jumping up to do it but I\u0027m sure we can find a Stuckey okay so I I\u0027m gonna make our proposal the question I\u0027m going to ask in a minute is so we should adjust ad sponsorship so if anybody wants to say that\u0027s the wrong half now would be a great time to speak to that and we\u0027ll let Jonathan go to speak about whatever he plan to see yes so I was gonna ask this is a sort of amusing question somebody asked in the jammer but also suppose somebody asked are you planning to have this draft truck checked into github you know more generally and more generally presumably your code for scanning for the secret token should itself be checked into github so is there a way to say this you know this contains the string secret token because I\u0027m documenting how your name your secret tokens but it\u0027s not actually a token so that sounds like a user experience problem which we don\u0027t do it the idea what we\u0027ll use the - to control that right I think I if I remember correctly github doesn\u0027t you know preclude you from checking it and it just warns you although you can set it so that it can preclude it I\u0027m sure that they\u0027ve thought through these issues and have adjusted accordingly I hope we don\u0027t need to deal with that problem but then there\u0027s encoding we could just encode it and I guess my only other question would be is any preference about whether such an ad sponsored document would be informational or status tract fine by me "
  },
  {
    "startTime": "00:27:54",
    "text": "Ted said from the floor for provisional informational Thanks okay so remember so I\u0027m sorry watch this you may have to point this way there although perfect this is this is a topic that has come up before pretty much every web form ever written accepts an email address and it is pretty common to verify the email address using a regular expression and people I know and I can have actually hired somebody to go and look at look at web forms and like the electrical extra top a thousand or something and see how they verify and the email addresses and pretty much without exception they use some random regular expression that some guy wrote we didn\u0027t actually understand that understand mail syntax so since we\u0027re all about standards and interoperability Sean Leonard and some other people sort of including me brought up some actual correct regular expressions for for the match both convince key email addresses and eai email addresses you know which are actually fairly complicated with mail syntax is complicated but who cares you know you just plug in it so our goal is simple is simply to first get them reviewed to make sure they actually are correct and then publish them and say hey instead of inventing a regular expression use this one and assuming mark is still in the room I\u0027m also wondering how we might socialize this among the web community where it actually cares we\u0027re actually matters where people should care you know so I guess I\u0027m you know I mean I think this is you know give give or take you know verifying the regular Commission this is basically done you know so I\u0027m hoping you know I hope you can be dispatched directly or ad sponsored or whatever is whatever TV is um well I know you\u0027re the chair yeah so the question is about where where to dispatch this and one of the the issues is is like I think in my thinking about how to dispatch this I\u0027d be asking where is the expertise to review these regular expressions because they\u0027re not easy to get right that\u0027s why we\u0027re writing this draft but the guy standing there probably could be one of the reviewers maybe Neil Jenkins I first of all I think it\u0027s a great idea i I agree that we see all sorts of random rubbish working sent ah and I think publish it I think you will eventually get people into it and people will find it and start using more and more so I think it\u0027s great idea it\u0027s "
  },
  {
    "startTime": "00:30:55",
    "text": "just the one thing I would want to point out though is that just because it is valid according to the spec doesn\u0027t mean all software supports it and sometimes the regular expressions that people do use are don\u0027t match everything that is technically valid but might match things that they can actually process and also there\u0027s the other side of that of sometimes the rate expressions failed to match against things that would technically be valid but actually I\u0027m a mistake on the user and a common mistake and no one really is it in your life so there is a reason why people don\u0027t necessarily always like that it\u0027s not just because they they got it wrong sometimes it\u0027s they they have a reason why they didn\u0027t use an exact RFC combined kind of match oh I agree I mean I personally I wouldn\u0027t be opposed to having you know sort of a cut-down version that\u0027s supposed more likely more likely to work you know and you know with Outlook or wherever changes I think even a lot of case it is is this like it\u0027s like people have never seen a plus sign and an address or just doesn\u0027t accept that you know it\u0027s it\u0027s that level of mistake that we\u0027re trying to fix yeah so one of the other questions I wonder if you guys thought about is in some ways a an RFC is like the least useful way to deliver this to people all right I agree we sort of need one to give it the the compound of that but is that is this is this a possibility for some experimentation with tools and how we write stuff to be able to deliver this in a form that\u0027s more useful for developers than how we usually give stuff to I don\u0027t see those as exclusive you know it\u0027s very useful I can tell you in other communities it\u0027s very use you know like given the the misconception that all rfcs our standards engraved and concrete is is useful here right yeah that big gamble see they\u0027re hot today the we\u0027ve had a few other graphs come by where the nature of the draft is here is an implementation that we believe was correct of how to do a certain thing to meet it to meet the standard where the standard is something else in this case a standard would be the syntax for the for the addresses yeah and we flip those to the ISE I I don\u0027t mean that to mean it\u0027s not valuable or anything like that it\u0027s just it\u0027s been more of a well it\u0027s not really this is just something you can use it\u0027s not a we\u0027re trying to say this is the right thing to use everything like that but just something you can use I\u0027m not saying it needs to be that way but I\u0027m just bringing that up as a thought I mean technically you are absolutely correct like the week you know these addresses are spots that\u0027s justified at a B in a B and F and when they suitably brilliant compile it which you\u0027ll be able to translate the a B and F into your favorite regular expression lactic is just there okay we haven\u0027t and a B and F is I believe the a BN f is sufficiently ambiguous that the translation is kind of tricky Dave Crocker and I did what we call them I think this is what Ben\u0027s talking about an likability statement I\u0027m Krane listing and we did that through the ie I think we did that through the iesg as an informational or something like that "
  },
  {
    "startTime": "00:33:55",
    "text": "yeah yeah yeah and so tell I want to agree with John\u0027s statement that you know the the relative weight that being an RFC carries makes a big difference as somebody who frequently feels like he\u0027s shouting at the wind for wanting to use addresses with plus signs in them I think that this is extremely useful it\u0027s not the only approach you take but it\u0027s the fallback approach because when I point out to people there are internet standards that define A+ is being perfectly legitimate they\u0027re like okay but how do i code that and if they want to use regular expressions as well you know show an IETF sponsored way of this is how you go about and do it but then you use other website tools to you know get it out there and and get it in the hold and that also makes me wonder why not you know why did it have to be part of a working group why not just maybe sponsored team defensive submission you know without being in a working group I don\u0027t mean I don\u0027t just make it clear people are using regular expressions now but they\u0027re wrong yeah well I\u0027m speaking of regular courage you are you Kurt Kurt Anderson so it\u0027s one thing to match the left-hand side are you also proposing for this regular expression to validate the right-hand side the domain aspect of the email address because you by definition you can\u0027t all this and tactically it mean if you want it right if you want to allá dated by looking it up that\u0027s you know you can do so but that\u0027s different well and I think that goes back to the applicability statement space because people just don\u0027t understand that validating a syntax doesn\u0027t give you a valid domain yeah but just be clear people get that wrong too you know there are plenty where they get it really wrong and that\u0027s what I\u0027m pointing out is that we need to somehow have bold flashing letters around this the validating the syntax does not mean you have a valid demand I said but it goes in the other direction they still plenty of there\u0027s still plenty of regular expressions where never nobody ever saw a top-level domain longer than five letters I agree and that\u0027s it\u0027s equally broken there too so how did all this come and just add men where\u0027s the draft it\u0027s expired how\u0027s the feel of that okay Neil Jenkins just want to quickly clarify this regular expression is just meant to match the email address not like a full mailbox string in a you know mine header like you ever the name part or comment or anything like that yes this is just a team it\u0027s just like you know what\u0027s your name what\u0027s your email yeah check your check here to receive unlimited spam we\u0027re familiar with that form yeah okay well whatever you guys say this is also not a helpful comment that\u0027s what I mean would you say I\u0027m creating more problems or add more solutions it has also been commented that no to regular expression implementations work alike so how are you deciding which ones are most useful "
  },
  {
    "startTime": "00:36:56",
    "text": "to target oh we specifically targeting the one in JavaScript and the one in girl okay I believe it\u0027s been a while since I looked at it I think we had particular widely used ones in mind yeah we were just about to maybe say the words ISE unless you had some other advice for us what you wish to say there well yes guess who I see will ask to review this document any right so I think considering the expertise is somewhat in this room and some people on mine I probably think that ADA sponsors probably a better way so obviously it will be better if we make a mistake and they kill expression and then publish RFC but I think we\u0027ll probably get more views here so I was looking to see if this actually might fit an extra and it doesn\u0027t but that audience is also present in that room so maybe you could take a couple of minutes to mention it there I mean that\u0027s supposed to be about mail store is not about forms and things but that audience is there is what I\u0027m getting in mmm yeah I sort of mine it through chat extra but you know that that\u0027s one cause to do it\u0027s actually you know at this time of day i\u0027ll be--i\u0027ll blurb it yeah how about this is a proposed step path forward the people who comment on it here\u0027s a straw man is eighty sponsored but when the when the ITF last call is done we note we sinned we make sure that we call that out and maybe beforehand call it out in every working group that defined one of the specs that these regular that drove this regular expression right though like wherever the ABN f was defined in the specification that nailed these things you know in those places we commented out and I\u0027m not saying co-working group last call it across ten working groups but just at least call it out in every working group that would have the expertise who\u0027s whose impact device who has a standard impacted by this spec I think the working groups that did this things were disbanded are gone okay to go yeah well the mailing lists are still around so ITF des SMTP for example yeah and I\u0027m sure the relevant people are on on the phone so yeah okay okay so will propose to the mailing list that thickens its you know to move this forward as ad sponsored as forward um actually we don\u0027t do anything on that the ad just does it so I think we\u0027ll take that as as the call if that\u0027s the direction it\u0027s gonna go unless anyone wants to speak against that okay thank you okay so we "
  },
  {
    "startTime": "00:40:12",
    "text": "are ending the dispatch meeting and moving on to the art area meeting which we do not share but we will chair so starting with area directors updates cluster 2:38 tell us how it goes it goes fine Adam Roach so the web RTC documents the last ones that are actually dependencies for cluster 238 have all been publication requested I have my area directory review done for those and we\u0027re waiting for some relatively small updates to the two of them and some clarifications and a third one that we\u0027re going to be talking about in WebRTC in the RTC web working group on Thursday so if anyone\u0027s interested in how those final resolutions play out to sort of watch the setting of the Sun you can come do that and after that we only have two relatively small dependencies to come out of payload and I think it\u0027s a music or the doing the ice SDP and after that the whole cluster breaks free so we\u0027re going to have like this I think been called the cluster of damocles finally drop on to the RFC editor sometime probably this quarter or first quarter of next year and there\u0027s going to be an incredible delay and publication of everything else I think we\u0027re in have like 20 consecutive RFC numbers and that\u0027s I think all that I have from the art area that\u0027s that\u0027s kind of the big thing going on right now there was just this is Ben I was just going to add anyone involved in cluster 238 be prepared to oh there the editor of drinks of their choice don\u0027t everybody anybody in the room that wants to speak to rats or bug woof it rhymes with all of them if you were at the first woof would walk Boff you would know that we already made that joke so if you were at the first boss which was a year two years ago we we basically just wanted to say gee working groups are using github what does that mean to the IETF and there is lots of mic line and such like that the boss this week in specific is about a new draft that Elissa Cooper and I have written that says gee it seems like working groups who haven\u0027t started using github want a way to do that more easily and you know they\u0027ve asked three other working groups who are already doing github what they\u0027re doing and they\u0027re all doing radically different things and so they just sort of stopped so one of the ideas that we had in the draft is why don\u0027t we just say what the data tracker should do if everyone agrees that this is a good idea to create a repo make responsible "
  },
  {
    "startTime": "00:43:14",
    "text": "people in all of that so that\u0027s that\u0027s part of what the boss will be doing this week we will also go go back and revisit the issue of well what should working groups be doing or not I put out a call for people to because we have plenty of open mic time at the end to say what their working group is doing with github that is interesting like when they\u0027ve noticed that other people aren\u0027t doing it and such so it\u0027ll be a general discussion just to be clear there is as far as I know no chance that what\u0027s going to come out of this is a requirement to use github a prohibition on using github or even something saying if you\u0027re using github you have to do it like this other thing is and certainly in this room that\u0027s pretty relevant because the like the HTTP this working group and folks like that tend to be very aggressive in the way that they use github and lots of other working groups are actually very passive and partial and as far as we can tell that\u0027s all fine so the mic line will probably be the most interesting part of the boss and if you have opinions which most people do because most people have opinions about blockchain because it\u0027s blotching almost everyone has an opinion about github because it involves the word get so if you have opinions come what we would like the mic line to be is I have this opinion but I\u0027m certainly willing to listen to other people and then not have the person behind them agree or disagree but just to be putting out the idea that after a few years of usage we have working groups again HTTP this being really the prime example of people who are really into this and do they want other people to be doing it like them or are they like no work this is the way we\u0027re doing it but if you want to do it like us here\u0027s how we do it so it really is a buff in the sense that even though we have a draft we\u0027re not really aiming at a super specific result I\u0027m just gonna mention when you stepped away that it\u0027s Wednesday at 150 right so yeah we it\u0027s so funny to have 150 be immediately after lunch yeah so yeah please come by and if you and we have a mailing list already which is not that one but ask me afterwards but we we want to help working groups and we\u0027re not sure what that means so come on by so I searched the announce list and found no new working groups formed since 102 so that\u0027s the basis of that slide if I should be looking at a different source let me know and we think John had one more for you to both your get no.1 okay the cooker watch this okay "
  },
  {
    "startTime": "00:46:14",
    "text": "successful test yeah this is another draft which i think is still alive but the SPF and decompose invented either before they were before ei I existed or at least before I was all specified and D mark let me say make do with this any couldn\u0027t a coherent sentence although SPF the specification of SPF says nothing about how it works in the presence of EI IMail D Kim and D mark sort of waved our hands don\u0027t get it quite right so this is a short update for each of these each of these three things to say if you are doing an SPF check on a dependent ei iMessage do it this way if you are doing D Kim signing and verification on ei iMessages do it this way and if you\u0027re doing what D mark does on here I messages do it this way and I\u0027ve actually implemented the SPF and DKIM things there what pretty straightforward is it basically anywhere that you can have a normal FDA label you can now also have a you label and it clarifies things that like in the SP SPF records themselves and the deccan validation records since they live in the dns and can be used to validate anything they don\u0027t actually have any e aí stuff in them they just have a ski in them you know what it says things like that it shouldn\u0027t it shouldn\u0027t be controversial and at least for the SPF adikam parts i\u0027m pretty sure they works it\u0027s you know since the the code works so again I\u0027m hoping to move this ahead as as minor updates for these three things the one process issue is that SPF and DKIM are standards track whereas be mark is either information alert or experimental currently information it\u0027s barely anything informational so whatever you have to do to be able to document you know but like like I would rather not split this up I would rather just have one thing that does it updates all three of them you know and again and this is not intended to be contentious it\u0027s all supposed to be pretty straight this sort of writing down clearly what sort of the obvious way to do this I\u0027m Kurt Anderson we\u0027ve also got two specifications that are in process from the D mark working group that both reference this document in terms of 70601 Biss and the art protocol and so it\u0027d be nice to be able to refer to something that\u0027s not a draft that will expire every six months yeah and also it doesn\u0027t update arc because arc is new enough that we actually manage to get this stuff in this is the first time around right but our does point to this document to say this shows you how to do it right yeah and also arc the arc the arc guys depend on BPM so it\u0027s helpful to have this this is exactly oh yeah it depends on D command D mark as updated by this document yeah so our quotient refer to a dead document it would be held for publication for the this what you probably use also and that\u0027s something you want this is Barrett liebe I agree that it would be nice not to split this up the only thing that gives me a little pause is that it is possible that the D mark working group will take as a future step a near future step to "
  },
  {
    "startTime": "00:49:14",
    "text": "come up with a standards track version of D mark presumably that standards track version of D mark would incorporate this well it would be newer than this so yeah right and therefore you\u0027d have part of this it\u0027s possible that the standards track version would do it slightly differently perhaps if we put it together maybe not the point is having that broken out makes it easy for us to just obsolete that and put it into the base standards track D mark without affecting whatever you say about SPF and DKIM it\u0027s a minor thing is throwing it out yeah actually that gives me it\u0027s a reason not to break it out because I\u0027m pretty sure I did it right and if you did it any other way it would probably not be right I mean it\u0027s the right call I mean if you look if you look at what it says part of the problem is the D mark depends on SPF and Deacon right and it\u0027s all it\u0027s all sort of a tangled bit that I mean it there is a little bit bit of arrogance involved in saying I\u0027m sure I got it right and nobody\u0027s ever going to find an error in it and if I\u0027m not saying that I know I\u0027m gonna and I don\u0027t mean that in a negative way what I\u0027m saying though is I I I think I\u0027ve made myself clear I think it\u0027s a small point I don\u0027t really care let me put this around let me encourage anybody who cares about D mark to take a look at it and make sure we got it right Ted Hardy channeling John cleansin from the Java chat room the EEI working group actually reached out to deke him and if I recall SPF so Jory tried to get this sorted and was basically blown off I agreed that addressing this in a careful way is appropriate and overdue thank you should is this something that we should just sort of take incurred to Anderson again that we should take on again within the Demark working group and then just bring it forward that way that\u0027s he kind of a half shaking of a head by Murray I I had the same idea originally and then I went and read the Charter and it\u0027s it\u0027s outside that so the guy you need is convinced is now at the mic yeah well I reach out ringing is easy if you know what you\u0027re doing so I was about to say ask the same questions so thank you yeah and that\u0027s that\u0027s why I didn\u0027t sit down because this is Barry liebe that was my next statement was we should just pick this up in Demark and I say that as a current chair of the Demark working group fine with me and then that that may answers the dispatch question very quickly even though we\u0027re not in dispatch now okay for me so I think open mic i believe the summary of the non dispatch item was that we would dispatch it to d mark which would need to reach harder yeah Adam I look and say what I wanted to capture there was it it would involve recharter ngey mark to include this "
  },
  {
    "startTime": "00:52:14",
    "text": "specifically I would encourage interested d mark parties to send me updated text this week hi Aaron Falk my sting of taps working group chair sorry for being distracted my laptop just bricked and I\u0027m like looking at the my productivity for the rest of the week just punting but the reason I wanted to get to the microphone is because uh those of you who\u0027ve been around for more than a couple years may recall that I showed up here a while ago talking about the transport services working group which which is not suppressing the transport area and has been working on defining an abstract API that the the goal here is to have an API that would be present in operating systems applications could then bind to instead of calling specific transport protocols Express the capabilities that they want from the transport protocol whether they want you know reliability partial reliability with the different security parameters so the things that allow you that distinguish between different transport protocols not just TCP and UDP but also SCTP DCP quick and then and then the the thing on the other side of the API would probe what would work and end to the network things like MP TCP were available or using this the happy eyeballs approach that they used for doing things like racing for ipv4 and ipv6 so the goal here was to to make it easier for applications developers to take advantage of capabilities new protocols without having to build the mechanism in to binder those protocols determine if they were going to work failover to something else if it didn\u0027t and so the working group has been sort of chewing away at this for several years now and we\u0027ve got some vendor engagement apples actually got something that\u0027s very compatible with this and there\u0027s an architecture and the abstract API is starting to settle and so it\u0027s kind of a good time for folks who have an applications background to take a look at this and from your point of view because the transport guys are you know we\u0027re sort of bottoms up looking at this problem and I think that from the application down you\u0027ll probably have some different insights and so the working group is kind of heading into the home stages where we\u0027re starting to polish up the documents and so if there\u0027s any like major course corrections would be really helpful to get them in in this time frame so taps meets Wednesday afternoon I think at 3:00 something and so you can just tune "
  },
  {
    "startTime": "00:55:14",
    "text": "in to the meeting but I actually mostly encourage you to go look at the the workgroup documents there\u0027s one that is called the taps interface specification and and see if the abstractions in there actually kind of make sense from an application perspective so and send comments to the group thank you Anna wrote I just wanted to give a suggestion you might want to send a mail to the ice mailing list I don\u0027t know if we\u0027re gonna keep that open up the working group close has been is that probably staying open okay because you probably have some people there that have worked through solving some of the problems that you\u0027re like doing and going to encounter south of this API and the idea will provide right sorry yeah short version is we\u0027re aware that\u0027s an issue had we need to approach working groups oh that\u0027s a good suggestion thank you Thanks okay unless there\u0027s any other topics I think we will call at the end of the meeting thank you all if anyone did not sign the blue sheets please come up front they\u0027re both you "
  }
]