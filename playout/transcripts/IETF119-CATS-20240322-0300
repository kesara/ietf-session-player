[
  {
    "startTime": "00:00:07",
    "text": "Okay. It's time to, to start the meeting. And good afternoon, everyone. Welcome to the CAS, meeting and I'm only as a cochair on-site, and Aaron is on the remote. Our secretary is Chun Lee And, our 8 days, James, and Jira. Okay. And also good morning and good evening to the online a death event. So it is a The item not well, just to remind, that when you participants in the IT meeting, you are agreed to follow Mike? We are too. Okay. Okay. Thank you. You are agreed to follow the IETF process and the policies. And before about, patent IPR, please note that you can you you should do this disclosure, it's at any time, not only, before the the option call or the, last call. And, Okay. So and the personal information that you provided to item will be handled in the accordance with, privacy statement. More about the information, listed below in the PCP. And for the conduct, analyze, please remember that you should be respectful and, got to say to your colleagues and all the time. And, we have the in personal discussions to diverse solutions for the global internet and meet the needs of of of diverse technical and operational, varyam."
  },
  {
    "startTime": "00:02:00",
    "text": "Moments, And, individuals are prepared to contribute to the ongoing work of the group. So, as my voice, clear, clear, Okay. You. Thank you. So, we are using the meet echo queuing control. So, for the On-site participants, please also log in the, meet their call. And the notes is taken by, timely, but we hope that everyone could help to make the information crackly. And the the link was sent in the chat box So, for the in person participants, make make sure to sign into the session. And, it was a miracle to join the mic and, usually, the cape audio and the video off at all times. For the remote participant, just to to open your audio and video, we used to bake and replace the cape, close it, when you don't sleep, Don't speak. S f f f 3. And here are our milestones and, deliverables. Now we have, dubbed, problem statement, use case analysis and requirements document, and we just adopt the framework and the architecture documents before the, meeting. So we hope that everyone could contribute and review the documents to to promoted together, And, here's the agenda for this meeting, we will have the presentations of use case and requirements and their framework. And then we will have 2 presentations about the compute, modeling and the metrics."
  },
  {
    "startTime": "00:04:00",
    "text": "And also has, maybe use case for mid haul networks, and, also for the analysis of methods for distributing the compute, metric. Meanwhile, we also have 4 parentitions that that's just to flash the slides, maybe, those works may not be right in charter now, but we encourage people to contribute more Work. Work. And, show the interests, to the working group So, any comments on the agenda Okay. Let's start our presentation First one, Go ahead, please. Hello, guys. Thanks for for the chairs for introduction. So I will give you a quick update about the working group document. Use case is in the requirements of cats, representing the co authors. Next slide, please. So, after the meeting in Prague, we have made some, a modification and the merge of the, drops we have merged the use case from Alibaba Group and all we have merged a requirement from, contributors from DTE Next up, please. So about the use case, about a compute aware AI large model inference, SI has, already presented in Prague, So like, the this user is more, focused on highly interactive and the real time translation applications GPT. And also beyond, behind these application,"
  },
  {
    "startTime": "00:06:00",
    "text": "you you really use large language models. So training large language models I usually needs, like, tens of 1000 GPU costs, but most of the, providers deploy their training inside data centers. So like, AI training might not be within Cascope, but on the other side, like, distributed AI inference, which usually needs like, the compute instance for, like interactive, computing, the, to repeatedly deployed in, app size, different app size. So selecting different, edge inference like, instances and in real time, it's within caskcope. So next up, please. And about the requirements. So, we have added, we have newly added a requirement merged from the, as I said, from, contributor from DTE on the, matrix collection. So, like, you can see in in the words in blue, like collecting metrics from all the, service instances may incur, like, much overheads, for the they may So we add a requirement that, should provide mechanism to aggregate the matrix, and the cast components do not to be aware of the, how metrics are collected behind the aggregates because we think that, it's not within Cascope and should be determined within the the, like, compute or edge service providers. Thank you. And the next slide, please. And another, modification on the requirement is about, and, matrix definition and use of matrix. So you can see that in red, we have deleted, requirement according to some discussion from, Prague. That the previous requirement is a much include a default action for the interoperable intro operation network nodes, which may or may not support the specific metrics."
  },
  {
    "startTime": "00:08:02",
    "text": "But, according to this discussion in the last meeting that people might not don't agree that, the network knows need to, aware of the split subsequent matrix. So we have a deleting the, we have deleting this requirement, and then we add a comment that for metrics that cast components to not understand or support cats will ignore them. Next step, please And also we have summarized some discussions recently on the mailing list It's probably, there was a threat about on the topic that whether SFC should be a proper use case in cats. And, also, I have listed the the thread link, you can You can, go to the details about the link. So I have summarized some of the key points if I, miss something or, I misunderstand about something. Please let me know. So first, it's about the definition of service in SMC and cats. So I have referred to, a definition from to draw. And also I see that people, most of the comments are, have consensus on this. So service in CAS basically services here is referred to that they can be addressed by client applications. While service in SFC is mainly about operator based services that could improve client applications. So here we see the difference. And, about how to use them, And, the difference is, is, are reflected here that cassus by sending traffic, to a compute instance and this compute instance, will run a client applications And then we we will get, and the sender will get the response. While SFC is about sending traffic, through instances. While these instances may run like a operator, service functions along a predefined path that is service function path."
  },
  {
    "startTime": "00:10:01",
    "text": "And towards a destination. So, sometimes that, SFC may have a loop which that they will receive this response. But typically, in the euro case that, SFC may not need that response. So, I think these are the major differences. And also there are some similarities, like, construction at of SFC or SFP can be enhanced based on computing awareness, like like, a comment from, Chang Lee from Huawei. He said that he can be named as computing aware FMC, but this is not, currently not a use case in cas working group. So all types are a cas working group scope. So next up, please. So a quick summary and the for the next steps on this, on this draft. So should we, update the terms of computing service of the 2 working group, documents, the use case documents, and also the newly adopted framework document, to clarify that cats is more about the user traffic. I'm, here to solid state for comments. And also, since matrix definition and the matrix distribution are the primary work for the next step. Are there any reflections or comments on whether current requirements should be improved. So thank you. Any what any comments Daniel. Please please please please Tena Huang DTE about The first question, I I I believe it's it's quite important and necessary to update our devolution of the computing service. For Z 2 existing working group documents. Because, particularly when the when in this is, there's a discussion of amenities about the f SFC. I believe it's, much more important to clarify What does the computing service"
  },
  {
    "startTime": "00:12:01",
    "text": "under the cast architecture is. Because from my point of view, SFC action is The service function is networking service function rather than the the, computing service function under cats. So, I do a lot of belief that computing aware the functionality, of cast will be taking advantage of, in in SFC scenarios. So And I I think we need to to clarify the definition of the community service. Thank you. Okay. Thanks. Hello. Hello, Charlie from Huawei. So, yeah, I we received a a comment. So, I think we should update the service, computing service definition into draft. So we'll do it as soon as possible. Thank you. Thanks. Okay. It's good to really shows a discussion the mailing list, in the meeting, I think we should at the consensus about the re relationship of Casa and the SFSA. And for the, magic distribution, we have 2 and 3. Transition today. So, I think the authors could work together to revise, WG documents. Yeah. And I I would say that Yes. Don't leave it to the document editor to come up with a new definition of computing service If you've got opinions, please put them on the list. Yeah. Sure. Thank you. Okay. Okay. Thank you. Next, the framework Hello, guys. Charlie from Huawei."
  },
  {
    "startTime": "00:14:03",
    "text": "Okay. So let's let's begin. Today's topics about, the framework, drafts, update So, yes, I I hope all of you have not have have known that. We we have adopted this draft. Yes. As an, you know, working group document. So next, please. So, basically, the agenda today is about 2 parts The first one is about the changes since the thus IETF meeting. So we update 3 terms 33 revisions from 03 to 06 So we're gonna introduce the the basic information of the updates and then we will go we will go into you know, introduce the the pending issues and what is next steps. I'm gonna yep. Next. So, this page shows the update of the, you know, from, revision 3 to 4. And in this updates made, we we we address 13 address, issues and most of them are editorial, right, and the updates mainly include like, we update the definition of terms including, like, service request request and and cats for water, cats, past selectors, something like that. And also delete the, you know, description of the the c s ID does not need to be global unique though the this sentence, but the because we don't think it is, you know, corrects in in all cases, right, and we saw also we renamed the service request to be, you know, service access. And then we also have some, example of, service specific pack packets and related, references. Question Poe. Next, please. And, regarding the updates, from revision 4 to 5 we, fix some editorial comment from"
  },
  {
    "startTime": "00:16:02",
    "text": "and Kristen and Jack could not Sorry. I'm not really sure I'm pronouncing your name correctly. And, unfortunately, and others are yeah. We receive a lot of comments from the mailing list. Thank you for your comments. It's really helpful. Yep. And also clarify, the The cat's matric can be aggregated I think that is quite important. Yep. And we also, clarify the C Seed Magic may may be distributed by different parts in to, you know, increase cats for water. So we didn't, you know, specify that we have to do something. We have not to do something. We we don't specify that. Yep. And the last point is about the, we class we clarified the CTS and CP A CPS, Right? And, yes, next, and, the update from, revision 5 to 6 it's a major update of the draft because we merge the content from, draft, y'all cats, awareness architecture. Right? So first of all, we have to think the contribution from, the orders of this draft Thank you so much. Yeah. So, we merge a lot of content into the this draft, like, we add a new section 3.3. Right? As a framework overview to provide a high level overview of the cast from work, but it's in an initial version Right? We need to add more text to explain the details of the version of the, framework, and we, welcome Annie Coleman and contribution this part and then we added some test test. Yeah. In CPS, the definition to explain, this local, logical comp, component can be implemented"
  },
  {
    "startTime": "00:18:03",
    "text": "in on on controller. So we are going to introduce Another new terms called something like a central controller, right, because we we describe the, framework from another, you know, angle. Right. And we also add the and then we, yeah, we add 3 deployments models distributed, centralized, and hybrid. In the draft in the, you know, deployment section and we'll also add some related Text to and figures to show, to show what is the, you know, distributed or centralized or you know, hybrid, deploy mode. And as well yeah. Yeah. We still need more comments and contribution here. So Welcome. Yep, guys. And then, yeah, we we finally, we also have some examples of service access packet, in the, you know, service processing section. Yep. And some other editorial at adictions. Yep. Yeah. So this is the sample of the cast deployments. I won't go into the details. Please go to read the draft. We we do provide 3 models right now. Yep. Comments are welcome. Next. So, let's repeat again the the current state of draft. So first of all, we have adopted the draft as you know, a new working group document. So we passed the IDAC call with no IPR announcement, and then we, receive a lot of support in the working loss working group adoption adoption call. Right? Thank you so much again for the support. Let's go together to move it faster and make the draft better. And, yes, we also received some comments that should be, addressed in the future as soon as possible in the working group last call. From, you know, Joe Hopin, Dick, Georgeon and hamster, Huijan, and Alice. Yep. Next."
  },
  {
    "startTime": "00:20:04",
    "text": "Yeah. So, we also, record the, you know, the the pending issue in GitHub reports repository So this is a link. So if you want to add some new issues. So go ahead to right there, we can, you know, discuss and address them, step 1 by 1. Yep. Thank you. Next. Yeah. So the last page is about the next step. We plan to address the panic issues step by step. Hopefully, we can address 1 or 2 to to after the meeting, and then we do really see for more reviewers because, you know, at least only the 1 version right now, we still have a long journey to go. It definitely not the final version. Right? So we need a lots of contribution, a lots of discussion, a lots of you know, tall men, So welcome. Yep. Let's work on it. Get it. Thank you. Comment. Questions. K. Danielle, please. That is. Personally, occurs to me that, pain's the late piece, the version of, and cat's architecture. The nonstop of the traffic, you know, service traffic would be service contact instance. So I'm wondering, Where is the service instance? I will be positioned under the cat's architects because this is exclusivity, defined in the section, 2 or 600, is correct me if I remember. Wrongly. So My suggestion is to We lead to make, clarification about the service instance, in the cat's architecture because action from my point of view,"
  },
  {
    "startTime": "00:22:01",
    "text": "easier the control plan and data plan. We do not have to do with the the the the service instance We we from, from the, hopefully and typically, we we we only see service contact, the service contact distance, distance, distance, Thank you. Yep. So, I don't think I can provide a financer here, I was I would suggest you to, send an email regarding this question to the mailing list, unless I have more discussion on a list, right, and and at this moment, I would say, the design of service contact instance is for avoiding to expose too many, you know, details of service instance so that we can do some, like, aggregation of the matrix, something like that. So it would make the detector or a framework more clear more clear. Right? So but, anyway, we can have more discussion on on the list. Yep, Thank you. Okay. So, we may kindly decide where the service instance is, but we we just to do the traffic steering. Based on the location of the service instance. At the first. And, There are no more comes into queue. Thanks a lot for the authors to the hard work to to to merge the, draft. And I think there's still some comments during the election call. Yep. And so, please just provide and, Another is that, please be aware of other drops. Which is might be, valuable to your hands date, on what. Thank you. Yeah. We do. Thank you. Okay. Thank you. Next is, How's the metrics? Please. Hello? Can you me? hear Yes. Oh, okay. I'm from China Mobile. And, this value involves compute modeling and the metrics and the way"
  },
  {
    "startTime": "00:24:00",
    "text": "control some talking about the metrics in the middle east it is for this, I have 1:1:9 meeting. But Next page, please. Here is some background and motivations. The motivation of computer and the network converters is that some service with a local computing results involved are increasing in our network and an email. The users of this service, expect, lowland history access therefore, the operator, need to deploy this cloud, past I miss these. Service director in this lecture, multiple points in the network can provide the same service. So that the provider need a proper scheduling method for this for those user request So as to load balance both the network results and the computing results, However, current any cost Pakistan, we'll only consider the network distance without computing information, and the counter load balance mechanism will mainly happen in the DC and, a user request may be redirect to other places we are short, on path the balance is based on Our network, our network, and the image, the traffic engineering, we have been near to the users and the it is the knowledge of the computing information. Since, the decision policy in the network should be about 10 degree of computing information. Next page. Base this page page, we conclude, customer conclude about the usage for computing metrics in the mail list or cast, it it did talk about that computing net model and the metrics can revert to the work in this management plan. For example, the red base,"
  },
  {
    "startTime": "00:26:01",
    "text": "And the, the an anuke allocated project. However, it had many about computing results management. Which can be used for, for example, service deployment is it to say to find a place with enough computing results to establish a service. Our service department. Potentially, uniform metrics for billing also be makes sense. If we want to make the service, had her at a computing results suitable. However, in in cat group, we really care about the computing metrics that need to be announced into the network which will influence the route for the service ID. Normally, the service ID is a is a anticancer address. Even we think that, the past metrics can even be a subset of the metrics used for the management plan. Next page, please. And, in the future, we introduce some metrics examples or in terms of, refuse, we can see verification is a standard design for DVR simple and a secure management for, for this PC, and, is a human readable and a machine capable. We can't see the finger, on the left it has some Magic about computing Computers system. For example, the processor But this kinda a Nick, And the in the right, we saw some general metric for the measurement of a server. On example, we can see the data's about the trial CPU memory. Others and others next page, please. I didn't this is another, example I've mentioned before an okay"
  },
  {
    "startTime": "00:28:02",
    "text": "they drive a common model, a standardized reference infrastructure specifications. Formerly the virtualized and the cloud native network function. We also have something about it. You can see the the left finger, the it about virtual resources. Is include compute storage network and about computer, compiled results, we can see some least, the VCPU, the RAM disc, the next next phase. Ask page, please. Oh, I we in this side, we give some about the requirements as I mentioned before, we would mainly care about the cast traffic steering. For example, decision pond, o, The path is, ingress the mint top would have eased the ingress is to select a proper egress. Which we which connects you to a proper service site. And for us to select, egress the ingress would not need all the computing information on the management management plan. We have, in the media meeting, before under some strategy was get, you know, the the first line is that, the computing metric impact should be few and a simple so as to avoid avoid exploring too much information on the service point. Second is about the computing metric in case should be involve of future extensions. And the third is the update frequency or computing metrics need to be considered carefully. So to avoid too much pressure on the network node on the control plan. Generally speaking, we have a a the conglomerate that we should start with a simple cases. Next week, please."
  },
  {
    "startTime": "00:30:05",
    "text": "To start with simple cases, we have a lot of talk, from, the mil millions we have, 3 potential matching that are considered as start point. The the metrics, is considered to proceed to be announcing into the ingress and influence the selection of the ingress and all the service that The first one is predict the computing delay. About the minute is the the estimated or duration of my process or the request it it is a the metric that, can be paths with the network delay. So it's easy to use for if we want to get the minimum total delay for the service success. And the second one is the service capability. For example, Vanser will transport 100 sessions and on other kind of support, 2000. So that, we'll be able to prefer the second one. Because it had a right, much better service capability. The third one is the status indication example, an indication of please stop sending new sessions to instant other metric can also be considered in future, if it is a, it is considered to be valuable. Next, it increase And, we we also find some corresponding matrix and the the optimization objective. Which metrics to announce is relevant to the policy in the decision part for the because I'm in the ingress. And the the policy in the decision point is relevant to the optimization of capital cuts. We have 2 men, objective, optimize and objective. In past now. The first one is to minimum the total delay. The network domain and that Duh. Computing computing delay. Gomez."
  },
  {
    "startTime": "00:32:02",
    "text": "We just, add the predictive computing delay under the computer then the network delay So we we haven't got the minimum total delay. It will optimize the user experience The second one is to load the balance. Loveland supports the network kind of computing resources. The service capability metric is very valuable for this purpose. It follows, we can see that it can be worked as it, but you'll follow the balance. Operator will care about the 2nd optimization object mode. Because, is capability in the relative static the 3rd metric, the data's indication would be of all when the server is a heavy load. Firewall is a temp and a dynamic value. So it it it's kinda only work additionally. A either conclusion, we can choose default optimization, objective, commonly, we have 2 candidates the services in cars. And how, 1 or 2 related to the default magic for it, makes things happen for think it's all, thank thank you all, and welcome for comments Thank you. Okay. Sure. The one in the queue. So we may move to next presentation, and, maybe there will be some discussion together, Hello, everyone. This is Luis. Well, I will be the one present team the the laugh instead of Jodi."
  },
  {
    "startTime": "00:34:02",
    "text": "And I will do it on behalf of my call for someone Sabine and and Roland as well. So, yeah, continuing with the the topic about the metrics, So the motivation, I I think, more results was, covered by the campaign. So, essentially, we are in a situation where on how the the metrics related to, the network information are are more or less stable. And, there is a lot of work already been done and done and been done in hearing in in IETF. However, from the computing perspective, there is some in work to be done in that respect. So, There is the need of of defining these metrics in order to support new new use cases, we we we have, the customer use cases. Some of the use cases also could be could require of, this need of of, having the metrics of consuming the metrics. We will comment later on, in the, in the next slide. But just to anticipate that. There is some adult work already assisting in in ITS. For sure, the the the work in cats, That's clear. Have just seen the the presentation for something. With the the, let's say, the, the, the perspective of the angle of, serving the traffic is still in purpose. Then there is a previous workers as well in a working group, more oriented to the fact of exposing the computing, compute metric information. And then some other previous work given in in ops. So with the specification of Hamid for the management of the, the built that are, built on machines. So so how also related to to compute in the sense of the there is a certain specification of resources there. Apart from the work done in IETF, there is, some other external work. Done in in other venues. Also, some time mentioned that. Just a quick reference for the information on the the TMS. MTF. Sorry. It's CNB and so on so far. All this work covered also the different angles. So there's a span"
  },
  {
    "startTime": "00:36:01",
    "text": "different angles, the raw compute infrastructure metrics, metrics associated to the, a virtual network functions, to the service functions, finally. And, other metrics that somehow combine or or or relate com compute and network information, that could be, yeah, the, the, one of the, the network delay, service delay, and so And finally, scalability as well of the service functions, so the number of sessions, these kind of things. Next, please. So the, the broadness space that we try to to cover in the in the draft. We depart from the idea of her of satisfying the service life cycle. Here, we we have just listed the service deployment on the service selection. Probably we could consider it as part of the satellite cycles or another stages like the service assurance, the service optimization, and so, but trying to not over complicate the things we went by now are looking at the service deployment and the service selection. What we, can see from once we go through the service life cycle is that that will be actions to be taken different information to be consumed and also different actors as well too, but participate of that consumption. So we have, for instance, the service deployment, we need to take an action of service placement we need to understand resources, compute resources are, and also what are the the nequon information, the NeoMedics, let's say, associated to those resources in such a way that we can derive from that metrics useful for understanding what would be the impact of instantiating the function here or or there. On the other hand, for the service selection, we we we could have the different actions, like the the selection of the services itself, or the selection of the path to reach that service instance. Again, we could, here, take into account, compute, and, and, information, And we could also, see in different actors to consume that that metrics. So the problem space also was evident from the presentation from something is somehow, abroad. Next, please."
  },
  {
    "startTime": "00:38:00",
    "text": "So regarding this particular draft, we already the the the version 01 in in the previous IT meeting. From now on, we have produced, an update we are now in in certification. What we have done new we can well, we what we have added new in this draft a number of use cases in order to motivate and just find the the need for the different kind of, compute metrics. So somehow they need to illustrate the problem in space as well. I was referring before. Considerating in deployment and and, and and a student by now and cyber selection by now. We have added a new section on, the production and consumption scenarios of this compute related metrics. So in such a way to understand what could be these actors, what will be the the ones requiring, the the the computer information, but not reproducing. There is the compute information. We are providing references to our resources to resources. So there are different, needs, the same or the different automatically apply to different, aspects. Right? Also, we have added a new section on metrics selection on exposure. There we, On one hand, we provide a reference to how the metrics could could be exposed, and which kind of metrics this needs to be exposed. Again, this would be related to that the the kind of, part of the service life cycle that we're going to address. Also, we have some discussion on the dimensions for to cause when you're defining the compute metrics, what kind of angles to look at the metrics discussion about the obstruction required according to consumes the metrics. So probably we need to deal with different level of a section. So this goes in the direct in in the direction of the simplicity that was commented on spam before. So to train to, scope the mentally to who will consume the metric, right, and also reference to the distribution and exposure mechanisms. Finally, we added the program as well as as 12. Next, please. So the next steps, we would like to to collect feedback from from cats,"
  },
  {
    "startTime": "00:40:01",
    "text": "there are already some discussions in the mailing list. We would like to to have even more discussion understand the the dollar, let's say, common points for sure in in in which is our ambition with the what will be chart know what they say in in cats hope, we be understand that we need to do some some work together and on on that for sure. And our idea will be to prepare a new version for for next And for that person to incorporate the comments that we can receive today, from cats and also the presentation that you already performed in an MRG before. Today and and also the same meeting on a information exposure, for edge computing. So the idea is to, yeah, to to try to, let let's say define better and understand war is needed and and and with that, yeah, yeah, progressing and working together with cats on on the part that they could be applicable to cats. That's all for myself. Thank you. Daniel, please. Okay. Then no problem. We're actually when we're talking about service to computing metrics, what I am keeping in mind is that we have to make a z joined routing decision in terms of post on service and networking metrics. So as an engineer, I will do my best to make the metrics network particularly in the net, imputing the service metrics as as as compatible as we could with the existing network metrics. So we We have to be careful when we when we're talking about employing complex service metrics structure entity. Cass Architecture. So, I second the syncing, from zonepons per presentation, we have to make the computing metrics as simple as possible. Yep. Thanks, Daniel. Just just"
  },
  {
    "startTime": "00:42:01",
    "text": "to comment on, in the draft, we explicitly say this that the proposition remain the will, for sure, reduce as much as as it's already there. That that's clear. And, yeah, and and the the tricky point here is regarding the Yeah. The the simple metrics as we need for instance in in the presentation before, for example, He was referring to the the server load, but the server is something associated to the expansion or is facilitated to the resources So think that we don't have yet a a clear view what is associated to to to the steering purpose. So this is why somehow what we are claiming is to to take a look to All the service life cycle understand what could be what could be the kind of metrics that we can consume to that. And from that point on, then identify what could be useful for the traffic updating purpose maybe for other purposes of the service life cycle, probably we can use other metrics. But but somehow, the years is that not to do to see what is out there. And from that, let's start identifying what could be applicable to one part of the circulation cycle or 2 other parts of the This is more or less than the Johnny from Huawei. So first of all, thank you for the work. I'm really happy to see that, and I will try to participate more in in the discussion. And then the second part is I do already believe for the metric from from from computing to the network should be done in the ads. But regarding the metric from, you know, the the the network to the computer, a computing size, not really sure where should we go. To do that Yep. Thank you. Thanks, Terry. Yeah. We we agree that there is, So for sure, work to be done in in cats, and and there is a a Kumangang or the point is that the the the charter from cats is so specific that, how are are concern is that we could lose some some of the metrics as I was referring to the server road, for instance, So,"
  },
  {
    "startTime": "00:44:02",
    "text": "Our approach will be to to go to the metrics to understand all the metrics and for that probably narrow down the scope rather than starting from the smallest scope and then trying to, to make it wider. We can discuss in on the list. Thank you. Thank you. Thanks for your presentation. I got 2 brief comments. The first one is about the service deployments and service selection, 2 faces. At this point, we want to have some, maybe, universal contents to ask with some service model, we know that the service deployment and the service selection phase may be getting to just one phase that's when we look for an auto instance or auto resources, we can just steer traffic to there. And they will invoke a new instance or get, request to handle this kind of service request. And for a second, comments is about the joint exposure of network and computers matrix. Is my considerations that some of the matrix in the computing side and maybe have the the same dimensions as the network side and this kind of be calculated or considered or to be, an accumulated form, but some of the or the computing side matrix should be evaluated individually. And I think that it is important. Maybe we should disclassify this kind of matrix and to make it just simple concluded as some types so we can handle it to be more simpler. Thank you for your comment. Going to the second comment first, yeah, you you are totally right. There will be some of them that could be compostable. Some of that's not. So, yeah, we we need also in this process of of metrics to understand what could be, let's say, the base metrics. And for that, what could be the ones that we can derive maybe composing them, maybe doing some other processing, I don't know, some statistical processing for extracting quantiles or whatever, but it's true that there will be a kind of basic method and for that, we can elaborate from others, on top of that."
  },
  {
    "startTime": "00:46:00",
    "text": "Yeah. Definitely. I reckon the first comment that you you did, I didn't get very, very well. I I think that you were referring to the fact probably the the 2, stages in the service life cycle could be done at the same time. Certainly, even done at the same time, So how are different Processes. You need different things to to to go through them. So even though it can be executed together, let's say, Even in that case, you you have different needs, let's say, in each of the stages. I think this is my view. Yeah. I got 2 points. Thank you. Edwin, please. So I'm I'm really happy to see these two drafts getting some discussion and progressing because It's been a big hole in the cat's work I think ideally, we would have generic compute metrics that can be used by cats and other in other places, but I don't want cat to get bogged down discussing compute metrics that are not appropriate for cat. So we have to we have to be a bit delicate and careful about how we do this. So that we don't have cats Waiting for super generic, or other specialist use cases. I think we still lack understanding of What metrics can actually be exposed by the servers? And, we also don't clearly understand what the steering function really needs to in order to successfully steer. So we've got a long way to go. And as chair, I'm wondering how we should best handle this And I think this is gonna have to go to the list, but we could have an interim dedicated to discussing metrics."
  },
  {
    "startTime": "00:48:02",
    "text": "We could have a design team to go away and maybe meet weekly discussing them. Or we could just do the work on the mailing list. So not asking for opinions now, but start to think about this and we'll try to make a decision on the mailing list quite quickly because I think that If we just roll along saying if we well, we'll update the draft and come back at ITF120 and so on. That's that's going to be slower than we should be. Thank you. Yeah. Thank you. Next. Jeff. Please of questions. 1, with regards to past just answer a couple selection plus computation. Do you envision, the necessity where next element in the past would be dictated by the previous one rather than fully computed path like we do in PC, for example, my short answer would be no. I I need to think on that. Okay. I'm gonna put I'm gonna put in here, Jeff, because You're talking about the path, and we don't do paths. We do steering onto months. Sure. I understand, but the What if the past resolution is dynamic and based on previous computation? Okay. Yeah. I get your point. Question number 2, and I think someone mentioned that in firms, collective operations. So they're not only based on resources available, but on seemity, I'm Longer. Each element computing. Right? So they need to be pretty much a key distant. Otherwise, you'll be on the And the flawlessly, collective operation requires everybody to do the same thing to same time, Do you envision including proximity asymmetric."
  },
  {
    "startTime": "00:50:02",
    "text": "Be a one of the of the metric, maybe it could be represented in terms of, delay or latency, which is something that is, I think feeds on the on the framework because we will have this network agent, probably affinity. Ah, okay. I got the now you mean the between different instances of the service. Right? Yeah. Yep, probably could be one of the metrics to be considered, but we need to realize how this could be reflected maybe through the the latency between Yeah. the could be array of latency. Yep. And then question it to Adrian, our collective operations and scope of this working group. I mean, there's some, INC or in network compute or progress in all across the idea what part of it should be here, what part of it should be someplace else. Well, the partner should be here is the part that's in the charter, but I'm I'm perfectly happy for us to import that If it's done elsewhere, or to learn from what's done elsewhere. Or to discover that we're entirely different. Can you Do something for me. Can you, send Printers, to either to the chasm or to the list. The work that you think is happening elsewhere that we should be aware Yes. As a chair of routing working group, there are 2 drafts progressing in routing in groups that are related to in network computing. I assume out there, sir. Here. I don't see them, but Okay. We we will dig into that. I'll send it to the list. Our Yeah. Thank you. Thank you. Okay. Thank you for the discussion. We may find some way to really enhance this work And the next It's me as well. Yeah. Yeah. Yes. Yes. I know."
  },
  {
    "startTime": "00:52:07",
    "text": "Sukhaya, again, this is Luis from Telefonica. I will present this other draft about the the how to to leverage on on cuts for bit whole networks I will do on behalf of my call for Mark. Next, please. So the the the part in point, the part in idea motivated by the, trend in in the radio in the radio part about the disaggregation, right, So the the initial Sorry. Initial deployment of the in the in the radio networks, where to have all the processing capabilities, in the in the antennas Okay? So, basically, forming the the backhaul segment between antennas aggregation part of the view and the packet core to process doing the the final processing of the radio signal. The antenna is collecting the analog radio signal processing it. And then send into the, I mean, generating the packet, the IP packet transfer, generating to the back it was a a starting point. Did the segregation in the in the radio. The fact is the the the idea here is to to take the all the process in the stack of the, of the radio, and distribute that in different elements in the network. So in such a way that we can we can have essentially the, the processing, you know, the, yeah, the sampling of the analog radio signal yet in the antenna, then the real time processing of that signal in one element called EU, which is distributed unit, in, in some place in the, in the network, so having, you know, generating the front haul segment between the antenna and the DU. And then moving the rest of the processing capabilities, mostly non real time, aspects into another entity called CU that could be even further centralized in the network. So between the EU and the CU having the main call segment. And then from the CU, the packet core, and so they, yeah, yeah, having again the backhaul. So this is the starting point. So next, please."
  },
  {
    "startTime": "00:54:04",
    "text": "So the the motivation then or how to or why to to take for cultures, but basically, as you can see on on your left, the the way of, realizing this in, the point of view of connectivity, and a network will be typically having the are you, the EU, and the CU collected in the in the network, right, being attached to, which is calling an RN terminology TNE. That could have a bit, transport network element. Could be as homologate is homologated to the p in in that So taking the picture from the left and moving what could be a representation on on on the right applicable to cats, we could have the DU units and the CU units running as virtualized entities. Then for the, I represented you on top of a server, but could be also, data center and the CUs, running a different, functions on different data centers. So the segment within the DU and the is that meet whole segment as you can, see on the on the figure. And, essentially, we would have a number of compute elements servers or data centers interconnected through, a network. The so different eNotes and so on. We could have different instances of the CUs. We could have different, like, in data center 3, different instance of the CUNS in data center or different instances in different data centers. So the the point here is how to what extent we could use catch to solve this connectivity scenario. Next, please. So when thinking on how to apply the gap framework to, to the mid call segment. The idea will be to consider that you as a client of the CU instances So, essentially, yep, playing the role of client in in the accounts framework. Also considering that, with the the cuts, pass a letter, we can take the decision on which see you, lever the traffic of each, du,"
  },
  {
    "startTime": "00:56:00",
    "text": "So, yeah, basically taking the the decision according to the network metrics and the per and the compute metrics observe in the deployment of the difference that you instances. So the, network manager and agent on the and, service intelligence monitoring agent could do the job. Of, sporting the metrics of the different environments, the order can compute and then helping the decision from the accounts path selector. We have exemplify. We have added the, or we have considered as an example of this in terms of data plane, the network is licensed. So we are assuming that we are using network in between the you and CU, and this is somehow this simplifies, I mean, This is how I am not entering into the details, what could be the data plane. Because some have do you know that the network slicing approach in IPF is a technology agnostic? So we are doing an example with network slicing, but could be any other data plane underneath. Next, please. So the next steps for this will be to cover a number of open points that we already have identified in the in the draft. For instance, the the fact that in in in the CAS framework we assume that there will be some identification or particular flows for delivering to the service, functions. Here in in the case of the, you will be all the flows. So no not a particular flow. So we need to understand how fits the security cache framework and some of the aspects that, are they detailed in the draft We would like to collect feedback from the feedback from the working group. Sorry. To understand it is you this, scenario, it says dispute mean, of relevance for for cuts, prepare a new version, and also come back to the to, with this idea of leveraging cuts for solving lease this connectivity. And that's all from Our side. Thank you. Okay. Thank you. Nate. 10 g. Louis, thank you, for the work. I'm seeing what bug, here's the cost that you are trying to have the DU to select a one of the CU park."
  },
  {
    "startTime": "00:58:03",
    "text": "But, on that, the radio accessing, the DU has not opened the IP yet. Hi. I'm going to know your IP part. Yep. We we need to think on on those details for sure. There will be an now taking this to the order and stuff. Need to think how to what will be the interaction between the SMO And the transport management entity in in Durham for doing for sharing the information and doing such kind of decision. So this is something we need to to work on say, So your PD but your PTC IP stack is on the client, on the on the on the CU side. In the middle, I don't know how you are going to get that IP level. Here, we're talking about the cats, right? Yes. So well, okay. I I I think I got it now. So The point is that in the middle, we have fiber connectivity. You don't have, I I mean, you are tunneling all that, reprocess signal on top of of of tunnels. IP terminals. So you are basically delivering that in the CEO and the U. It's it's like, any other traffic is is not an IP traffic because you have I mean, you have not completed the processing of the signal. But you can deliver that traffic using IP networks. So the payload would not be IP. Will be Yep. The a pre process and or an and complete process radio signal. Okay. We can talk about offline here because, I'm really confused with how you're going do the nest and AS message here. Yeah. We can talk about offline mode. Okay. Thank you. Okay. Thank you. Please continue to discuss this work. Thank you, Ministries. And the next please. Hello, everyone. This is Harshal from I'm going to discuss about how to distribute the metric."
  },
  {
    "startTime": "01:00:00",
    "text": "There's some design choice involved here. Next time, please. Yeah. First, quick recap of the test framework There's a 2 concept. So firstly, the, SMA, service metric agent to collect the computing metric The second is a pest selector. And the the SMA need to distribute computing metric to the, pass person editor. And so there's some design choice or wrong how to collect and how to distribute this information. Next, please. Previously in this draft, I discussed several approach, regarding different kind of deployments. You can use the syscent centralize or the distributed, CPS or CSSMA. So this gives us a 2 by 2 metrics each have its own pros and cons. It's in the drop, you can check that out. Next page, please. Yeah. But regarding how you void the, these components, we still have other, from on you to address regarding the metric distribution. We need to analyze the metric distribution overhead. Actually, we can have some kind of very simple formula. To to, to compute the metric distribution over there are two sides of this metric distribution. The first is the producer. Sorry. Sorry. Please. The back lego. Oh. On the mic. Yeah. Okay. It's 2 lounge. Yeah. So the first is the perp producer of the metric and this, pass the metric choose, consumer. So this two side, The first component of this metric distribution is a scope, Not every consumer needs this kind of information. And, not not every producer can produce some meaningful updates. So there is a second part"
  },
  {
    "startTime": "01:02:01",
    "text": "the metric distribution frequency, if for similar test not needed, but we may not distributes the metric to them. And the 3rd one in the metric size metricize, you you did have a mean, the biometric model. What kind of computing metric is involved here Next side, please. Yeah. The first optimization you can do is to reduce the scope of metric distribution. Basically, you don't, tune to to not indeed, or to or, distribution of the computing metric. And, there is a drop the IDR proposal concept about the notification domain. Basically, it's kind of googled the ingress and the ingress. So they are only get to they are, meaningful updates to them. And that you achieve this notification domain. I is there are several proposal, to help you implement it. The first one is use some kind of, pops up mechanism. The idea is that the consumer indicates the in interest of this, computing metric of a specific service by sending a a some message and, uploads that it can get some kind of update of this computing metric. And the second one is kind of, submit the the request into different groups if a ingress on a, egress is too far away, is highly unlikely that the egress will be seen negative. So we don't want you to we don't need you test these computing metrics between them, No side, please. And the second part is, inside this, computing matric distribute, scope, we see a new utility terming how frequent we distribute the metric how"
  },
  {
    "startTime": "01:04:03",
    "text": "How frequent when do you do you? There are there are 2 modes of of this, of this metric distribution. We call it push or or pool. Basically, the push is, producers send the metric to the consumer. And the pool is a consumer fetch the metric from the from the producer. And, and we can do similar optimization to imitate the distribution frequency. For example, in the push mode, we may need to set us a set set a threshold for the metric updates. If a metric does not change that much, we don't need to update. And for the poor side, we can use some kind of a cache mechanism. Only only fetch when the cache expiled. But you can see here, each side has their own view So poor side of the the consumer of this metric is ingress. So it has the information about the command that you are in. And when the client need need a new metric and the push side that they have what So computing metric updates So see some kind of didn't give you a 9 together. Next side, please. The sales drop is kind of intent to summary the related work regarding the metric and to inform the discussion about this And, ultimately, it was intended for the protocol design. So comments suggestion welcome. are And Daniel Place. Okay. Then no harm. I've, two questions. The number one is why the consumer we'll be taking into consideration one way talking about the, service a a matric distribution overhead because,"
  },
  {
    "startTime": "01:06:02",
    "text": "in my view, the metric I will need to be propagated and distributed Weasindy, CAS Architecture, which will not, include the consumer side Notice consumer is the CPS. So you see in the north north than the user. Okay. Okay. Okay. Good. The second Matt, Matt, comments is about the service metric agent because, I would assume, and then that Cats to woe. GAT disease. Computing, original information exposed by the computing side. As the r. Rather than we we we will not assume that a computing side would make some kind of refinement and a calculation for cats. So, it's it's it's it would be the, job of cats forward. Or the service metric agent to make the kind of on calculation and, they refined me according to the act gas architecture. So I I I would agree, with Adrian's suggestions to the working group out set up the design team to and clarify and about the service metrics particularly the the, principled on of the, general, service serviced as well as a computing metric, and the relationship. Between the service metric agents and the computing side and the cats foreigners. Thank you. Yes. What you are talking about is a metric model, and it's between the CSMA and the computing side. I'm talking about is between CTS and CSMA"
  },
  {
    "startTime": "01:08:00",
    "text": "inside the cuts. Has, 4 forwarding area. Yeah. Now what I'm, I'm talking about is is, I would assume the computing site will not do anything. With regard to the original computing information. Would simply expose what do they have? So it's the job of cats, either the cast forward egress port load the war, the sophismatic agents. To do the job. So you are assuming, server side does not do any, a quotation or preprocessing of the cast, of the computing metric and they stand by the for example, this CSLMA, Yeah. I I personally doubt I would not assume that. Because this is going to be the 2 different admit administrative domains. Yeah. And I think that's, what's the metric model we'll care about, what kind of information and, how do you get this information? Is kind of pro pre processing in the computing side or you get the raw data Okay. It's about two things. I think you you care about, if the server can tell something forecast or catch us to get some computing information, from the server or server can, change and do more things to fade cast and comment. And this draft talk about how to distribute the information when the sick SMA That's the information. I think So, It's also about the agent's point. About today. Metrics, dropped that what cast can't get. From about the company metrics. Yeah. Yeah. We've we've got like"
  },
  {
    "startTime": "01:10:01",
    "text": "We've got a sort of feedback loop that we need between the this draft and the metrics draft. Because This this formula is is is spot on. It's it's good. But what we now need to know is some of the details of Well, for example, what what is the metric size? And and then we can put that back into this draft to say, because our metric size is this, it rules out some options and rules in some other options. Yes. Agree. Yeah. Okay. Okay. Thank you. We Okay. Next week, we'll have 4, quick presentations. Chump, please. Hello, Johnny from. So, this is a quick introduction of our drafts, which is about the, which about using segment routing as well as the data plan of cats So next, please, Yeah. So in a draft, basically, we describe how to use as, including as on peers and as on V Six, It's the tunnel encapsulation for, from the ingress cats forwarder to the egress test for water, but actually, you can use other them. Don't really care about that. In this draft, we we specify, a potent potential potential, implementation of cats. Like, we define that a we can use an anycast ipv4oripv6 address"
  },
  {
    "startTime": "01:12:01",
    "text": "as the cat service ID, which is the CSID, right, And for the, to ID, CIS ID, it can be a, like, you know, MPS label or SIV6 seed, such as help help An x seat. According to the, service instant selector, And for the cat, component, we we require them to support SMPairs or SMB Six. And we also describe how to realize the, cats work from workflow, by using the, you know, DNS technologies, and As far as the data plan, encapsulation regarding the, you know, match a distribution part. We think this is out of the scope of this draft. And that should be, described in, you know, idea or other working group jobs, other drops in in idea, IDR or PC, you run it, other working group. Yep. Yep. And, yes, that's it. Thank you. Please read or draft. The next, Yeah. State this drop is about a particular problem or particular deployment because sometimes you may need to deploy multiple, service contact instance or so several sites behind one cas egress I'm saying you need to distinguish between those side, how to route to the right side. And if they are connected choose a different, interface of the has router, CASEgress, then you can use some kind of interface ID in, in a salary sixties and the and the point to DX, say, say it. And if it's our contact, contact the to the same interface, and I think this figure is shown in"
  },
  {
    "startTime": "01:14:04",
    "text": "blocker 1 and then you need another kind of locator. To locate the right sites we call it a real locator. And, as there are 2 options to to recap so it's a real locator. The first, we call it turn on mode. Basically, you give a turn off from the egress router to site and the terminal, alter outside, turn terminal IP is a real locator and the in our, test destination IP, the service IP, And the the second is for forwarding mode. Basically, you can, you can capture the real locator the ipvacings, and the between the, the attentional pattern, author and the the you decide you need to read this. If you will fix the extension, you'll get is real, locator to do the forwarding. Next. Yeah. Next we recorded the application of our computing network. Basically this is a one way of implementing the CAS framework because we see many similarity between the concept of the has framework on this APN. There are several important IDs in the cas framework So a service ID and, SCI service contacts the instance ID and the flow ID. We see in the APM ID, we already application group ID and that's, u user group ID. We can use the application ID as as the service ID and the user user group ID. Plus the application group ID to replace the file to pull as is a flow ID. So it's kind of, direct match. And the, 2, 2 encapsulated, this a team ID until into the cas, cas framework, we actually have Q option."
  },
  {
    "startTime": "01:16:04",
    "text": "First option, if you can put the IP inside the address, So we can call we we call it the ATM segment. Basically, it's, as we succeed, and the function part is the 18 ID. And secondly, if the IP ID is too long. We just use the locator and put the blinking ID in the IQOS 6 extension header. This is one way of implementing the CAS framework Yeah. Yes. Okay. Thank you. Next to The last one is Carlos, please. Hello. I hope you you can hear me well. So this is, a solution draft proposal by myself and Alan Moran, basically, if you are covering 2 slides or 2, not 2 slides, right, 2 drafts, what is the main, kind of solution overview of how to use IPRS encoding for cuts. Then another one, the company document that is about how to do service mobility in a catch environment also using IPLS and call you next slide, please. So here, you can see a figure trying to summarize the weather idea, the the terminology has to be a bit updated according to the last developments from the the working group documents, but it is that, here, we use APIs and coding to support cuts by basically making the the cuts for word that that is connected to the service site allocate an an IP address block or an IP address to the the cuts forwarded that is connected to the or close to the to the terminal. And then by using this IP address and calling we support the the cuts for wording, and we can do updates on the on the cuts for wording by by kind of using IP mobility mechanisms, so extending IP mobility signal is for example, you will have mobility of,"
  },
  {
    "startTime": "01:18:01",
    "text": "even or we want to have mobility for given service systems or mobility and of the terminal, we can do that by following mobile APV 6, kind of signaling for cuts. And that's the other idea in in in summary. So, of course, we would like to welcome any comments that you may have on and send that, those 2 to the amenities, and we work how many potential, interested contributor to to join us on these efforts. Thanks. Oh, Adrian. Do you wanna see something? Yeah. I I just wanted to to say it's obviously a little bit early for us to be working on solutions. But the reason we did these flash talks was to just show that there's work going on. And, to bring it to everybody's attention I'm slightly amused that we're, All focused on how do we get the packets across the network and identify the the the compute service that's needed, but we're still some way off being able to actually make the steering decision, which is is an equally important piece. I think because we've got a little time, I want to do 2 process poles. Show of hands the first one, is do you like having these flash presentations? Is this a useful thing to do or or should people just read the mailing list and get on with it? So if you can find that and vote That would be really interested in We're starting the show hand. Please join."
  },
  {
    "startTime": "01:20:01",
    "text": "In the in the mid echo? Okay. That seems to sort of be stabilized Still voting. Okay. It looks like this is something that you think is useful and the chairs can look at that future meetings, If the agenda space allows, Okay. My I'll stop that. And my my second question is, about how we progress the metric discussion And, and the question is, would you like to be driven on this discussion by the shares scheduling some form of meeting. I suppose the the no means now we just want to work on the mailing list. Okay. Now is the second Custom, Please check-in the show hands. Okay. Thank you. That that's pretty helpful to me"
  },
  {
    "startTime": "01:22:00",
    "text": "as a chair, Paul and I will, will talk about this and try to work out how to drive the metric discussion forward. Okay. Back to you as resident chair. Hi. Yes. We still have 8 minutes and, maybe anyone has some questions for the WG or for the dropped present day of today. Can, can, join the queue. Okay. If no more questions, maybe we can close our meeting, even do you wanna see all things, no. That's good. Thank you for taking the plane of traveling this time. And maybe you'll see us both in Vancouver. Who knows? Okay. Thank you, everyone. We're closing our meeting. See you in Banco."
  }
]
