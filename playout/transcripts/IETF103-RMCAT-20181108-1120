[
  {
    "startTime": "00:00:04",
    "text": "oh thank you I will take take what many people here mmm a minute okay so I guess we should get started this is the our MCAT working group I\u0027m Colin Perkins I\u0027ll be chairing co-chairs and a Brunnstrom and mutton stealing me for whom I see we have we have several remote people can you confirm the audio is working we go cha-ching can you hear us or not one yes okay so I guess that\u0027s what yes I can show you okay thank you good all right so as usual we begin with the notes well I\u0027m sure you have seen this before please note it and read the text there\u0027s a nice big URL which you also can\u0027t read "
  },
  {
    "startTime": "00:03:04",
    "text": "it\u0027s cut off by the pop-up which says Monica which said mirroring the screen which has the URL for the remote well on it slides all the materials are on the data tracker we have meet echo we have Java Jonathan Lennox has kindly volunteered to to monitor the jabber room and also to be the big red button pusher for me tech oak so if remote questions they will let Jonathan press the button to let you in at the appropriate time we also have a mailing list please consider subscribing if you haven\u0027t done so already and I will be taking notes so our agenda today we\u0027ve got this brief introduction on status updates will then talk about the eval test draft from the head for ten minutes or so I suspect it will effectively take Western that cha-ching will then talk about the video traffic model draft and the updates on another implementation in I guess Firefox and then Julius will finish by talking about now their implementation experiences and then an issue with the couple of congestion control directors working group status we\u0027ve got a bunch of candidate congestion control algorithms and related drefs coupled conditional draft is with the RFC editor but we\u0027ll be talking about it later and we may have to pull that back briefly scream \u0026 sbd have been published as RFC some time ago neither the working group last call has been completed and that\u0027s waiting for the chairs to do the write-up and we applaud Joyce for the way and I will automatically is right up again and GCC has condiments the the offers have indicated that they\u0027re not planning on updating it at this time but if they change their minds we will happily be waiting and ready to take the breath back the bonus draft has been in the RFC editor queue for about the last four years and is blocked on cluster 238 along with many other things so hopefully that will appear relatively soon the evaluation drafts the about test we\u0027ve all criteria and video traffic model drafts we have had working group West\u0027s calls on all of those Ebell tests and a traffic model we\u0027re going to be discussing later today the eval criteria isn\u0027t on the agenda to discuss but it was updated earlier in this opening this week CEO guess that you know comment briefly on that the status of that draft yeah you\u0027re good so so essentially we have in we have an up an update of this one that addresses all comments except for strengthening the security consideration sections that that that requires a bit more thinking that watan wasn\u0027t easy to be done at the "
  },
  {
    "startTime": "00:06:07",
    "text": "quick shot that we gave it and the other one the other requirements seemed to be in an ok shape now so that this could move ahead and we\u0027ll hope that we\u0027ll be getting the security consideration sections updated also soonish an interesting question is on how much you would actually want to say there specifically and what\u0027s the this is this is about experimentation and so there are no specific security issues of experimenting base the implementations of it probably need to consider all right so but we wouldn\u0027t want to discuss of what people would need to consider what what what they might leak is side channel information from there congestion control mechanisms or their timing of packets and whatnot this is nothing this is not of influence right in itself that the draft seems to be pretty easy on that yeah I mean my guess would be that it probably wants to say that experimentation probably doesn\u0027t have any great security issues but pay attention to the security considerations of the perhaps you\u0027re implementing like when you think about okay that\u0027s probably something one can done where one one can do quickly the eval test draft I think but an update to the security considerations in this last version and you should probably do something grace and what\u0027s of that okay oh I\u0027ll send some text from there that\u0027s good okay okay thanks okay so it sounds like the sizes of that is that we\u0027re looking for an update to revise the security considerations at that point we will unless they\u0027re objections do a brief working working group last call to confirm forward and Justin you had Justin correction I think we were evil this 0-60 run yeah so well provel criteria we will wait for yo to do an update to revise the security considerations and then do a brief working your bicycle discuss the other two in a few minutes wireless tests we have previously decided that this was ready for working great last call once the other evaluation drafts are done I see no reason to change that decision so hopefully in a few weeks while everyone\u0027s out the way we can work working group let\u0027s call that first [Music] feedback message was discussed in abt core and we\u0027ll talk briefly about the hack fun stuff in a second the condition control feedback draft which which gives advice for how to use the feedback message draft has as I think currently expired but we will update that once the feedback message has been completed to reflect the final state of the feedback message the two "
  },
  {
    "startTime": "00:09:07",
    "text": "interfaces draft the the framework and critic interactions I think the current plan is to reconsider those once we\u0027ve moved the candidates forward to you just endless track and to leave them at this time we have set of milestones as usual they are out of date what I am proposing and what I\u0027ve discussed briefly with the co-chairs is that a milestone for submitting the requirements in evaluation drafts which was this which was August 2017 we moved to December 2018 and since those those are essentially ready to go so quickly we will actually then meet that milestone after having moved it for 18 months the the the interactions this is Cody contractions the framework will push forward a year or so so they go to after we have hopefully done the congestion control drafts the evaluation results and the proposal for this tenders track congestion control algorithm we are proposing to push forward to July next year I suspect that\u0027s aspirational and optimistic but we may as well be aspirational optimistic and we can always change it again and some are meeting if we don\u0027t make that condition child\u0027s proposed standard we\u0027re suggesting is push it forward a year and again it\u0027s likely that that will slip but we may as well be optimistic and try and encourage people to do it the other two milestones publishing draft of techniques to detect instruments for diagnose failing to meet at each edge ELLs I think no one is quite sure what that is so we\u0027re proposing to remove that milestone at this time any comments on these changes meuk ooh heaven so those milestones was meant to provide some kind of invent measurements so if you deploy your congestion control you want to capture certain metrics to figure out that the loss rate didn\u0027t go to like infinity or whatever and report that back but given there\u0027s no work ongoing on this Purdum okay to remove it and we have monitoring in with ICCT and all of that so so the reason monitoring infrastructure in place already all right last check now I have the those a small group so it was Niels and Jonathan and was it such a remotely yeah looking at implementing the condition control feedback draft in the hackathon and I think they made some good progress we had a discussion of that in a VT core earlier this week and we resolved most of the issues and they\u0027ll be seeing an update to that draft in the next week or so Jonathan anything to report so this "
  },
  {
    "startTime": "00:12:07",
    "text": "working group John yeah I think the one thing we that came up at ABT core where we felt like we needed more feedback from people actually employing congestion control algorithms is how should the feedback mechanism handle duplicated packets because the feedback is indexed by sequence number so obviously if it packet is duplicated you can only report on that once and the question is what would be the most useful report in that case it\u0027s report on the first arrival time the most recent arrival time should we I don\u0027t know maybe add some additional flag which would be a format change saying this you know packet got duplicated something strange happened or what I mean so I feel like we need you know what is going to call you know be the most useful for the congestion algorithms to get the information so if people who\u0027ve done suppression algorithms could get feedback and I would be helpful do I kneel you can kneel if you\u0027d prefer that looks better Glennis and I don\u0027t know if another congestion control feedback mechanism that reports duplicates at all okay I mean so so maybe we don\u0027t have to go to that complication of actually bothering with we need to specify something yeah we report on exactly like it\u0027s maybe maybe duplicated yeah you should choose one is what I\u0027m saying yeah Kulemin so arrival time I think you should choose the first one because that\u0027s when you actually process a packet and then you just throw away the duplicate right so that doesn\u0027t matter for you also have easy and feedback in there right you might want to like I mean it can also happen that you get the packet you send a report back and then you get the duplicate right then it\u0027s already too late but if you actually happen to receive the duplicates before you send out the report and one of them had a congestion marking I should think you should report on it because it\u0027s still a signal from the network okay so the suggestion world was reports the time of the first one and if you get multiple ones and one is ecn marks then report them up here okay we\u0027ll bring that abt core but I have no objection to that in principle and unless anybody else has any comments the other reason why this is an issue is not just the network duplicating packets but because certain implementations hem Firefox don\u0027t support the RT X payload format so use packet duplication for handling package you know retransmissions sure yeah okay "
  },
  {
    "startTime": "00:15:07",
    "text": "chattering does that seem like it would work okay okay so for handling duplicating packets I second what Mira has suggested okay thank you all right I guess we\u0027re done with that in my case so that we will now move on to I can work this laptop to the next presentation which is you\u0027ll be pleased to know that we slights and no longer 75 megabytes in size thank you what have you done with the slaves you have to rid of some non important bits okay so so this is about a status update of this evil test draft we went with vacuum last call for zero zero six question and yeah yeah so we got some comments and reviews actually I\u0027m very pleased to see like a detailed review from the reviewers and comments and we authors especially me and shouting actually work through the reviews and comments and updated that one so next slide and we have a zero zero seven passional addressing mostly all the comments we got and thanks for the review so next one so let\u0027s focus on what we have I mean there are typos there things that\u0027s quite trivial that is come up with review thorough review so I\u0027m just focusing here what was basically changed that I think you guys should be our of and obviously you can do the diff so so the thing is like I think one word is missing here so so the thing here like we had this fist Kappa City pot capacity and then we said like we\u0027ll use some other traffic to actually change like non-responsive EDB traffic to change the pot capacity and then me and Sergey kind of work through a new formula which basically is more I think more more like more what what is supposed to say we have a table with all the pot capacity at pad capacity ratio now if we apply the formula and then you will see like what kind of it will be traffic you will be throwing it so anybody has comment on that shushing you want to say something we "
  },
  {
    "startTime": "00:18:14",
    "text": "can see you but you are not talking no I\u0027m good here I don\u0027t know did I trigger some yeah I don\u0027t have comments sorry maybe there was a confusion all of a sudden you\u0027re Vic your video is showing up on the screen so we assumed maybe you want to say oh okay I\u0027ll I\u0027ll mute that if I\u0027m not talking then yeah I\u0027m gonna post the audio in the video sorry buddy that\u0027s just great um so anybody has any comment have we applied this to a current at the table and see like well this is the right thing we kind of did mutters yeah I think it\u0027s fine then the next one we kind of I don\u0027t like zero and we kind of missed expected behavior for two of our use cases so it was basically kind of hidden into the text but we didn\u0027t really wrote it as a separate section so that\u0027s what we did so test case five point seven this is about short clip TCP flows and basically they suspected behavior here is like when you have shortly TC flows you actually kind of media bitrate kind of go to the minimums it stays there when the live flows are gone it will be like into the steady state and obviously the show but it should show is like it is it\u0027s gone down into the lower minimum betrayed it doesn\u0027t stay there so it\u0027s actually ramp up ramp up to the steady state so that\u0027s like the behavior expected behavior we added on the test case five point eight that\u0027s like pause and resume this is basically I think everybody showed the results with the expected behavior so we just wrote wrote wrote that this is pretty simple like when you pause it and then basically the rest of the rest of the flows should go and corrupt the bandwidth almost equally they should converse and when you again kind of like start your Postmedia it should be able to find this way to a some economy level converges convergence where all the three flows are a steady state so I think we have some discussions about 5.7 within the among the outwards like what what it should do but 45.8 it was pretty obvious we have been showing actual results displaying this kind of behavior so we\u0027re fine any comments on that anybody doesn\u0027t like it no change it yeah okay fine to me as well next slide so security considerations there it used to say like security should have not "
  },
  {
    "startTime": "00:21:14",
    "text": "been discussed in this memo I personally thought that\u0027s like understatement so we kind of wrote a new security considerations so what does it says it stays like these constant control these Cheska\u0027s you\u0027re supposed to run you know simulators or in a control environment where you know what\u0027s what\u0027s happening it\u0027s a basically a lab environment or your simulators so we don\u0027t expect anything any anything that impacts the desired result so your you should which one okay there\u0027s something the copy quest thing like this not to say what it says but the idea is like well you should not have some traffic that impacts your results in a controlled environment and then we also refer to eval criteria if there is a security consideration there every condition control will have to write the security conscious concentration so when you are particular testing something you should be you should be considering that and then we get a solution like we should also mention like we should not let the test things make into the Internet which where our condition control algorithm has not been tested or something like you should not leak this lab thing into the internet and flood the internet and break the internet issues to do that so I think that\u0027s very valid comment so I we just incorporated that one but this is kind of like yeah pretty simple constitutes good reconsiders I don\u0027t like what else need to be covered so Cory Ferris did you really have last sentence as well but I agree with the last sentences intent hmm I suggest it should be a separate paragraph but when you actually write it because the congestion control things a little bit different and I think you probably need to be more explicit than avoid leaking because you just say this isn\u0027t to be used in the journal internet or something that\u0027s a little bit more concrete so that earn somebody who\u0027s silly enough to think that that might be the case is very clearly advised not because hopefully people in this room already know that last sentences down else reading this who isn\u0027t familiar with what\u0027s going on who has to be warned that in some way this is an experiment that has to be controlled and use nicly at all environment yeah I would I like the controlled environment text it appears in many drafts that we write around here if you have suggestions for what that sentence should say the more I talked the more I realized you were going to say that yes I will just leave now yeah so if you have some citations I send it to you and I we think we think "
  },
  {
    "startTime": "00:24:15",
    "text": "we also find a typo but I don\u0027t think like we need to update that one but this one if you if you think like this need to be updated a lot of centers centers then we should update it so that\u0027s it what\u0027s next from my question to the working movement the English is not working in the draft it\u0027s copy/paste it\u0027s the copy/paste thing okay so what this seems to me is we need a minor updates to basic security considerations yep which I\u0027m hoping can happen waited to be what I would then propose is that we do a very short to working group last call on one week or so to confirm everyone is happy with it and then move move this forward yeah and also like I think in the mailing miss you guys have seen like there is a confirmation from the comments reviewers that the current draft actually addresses their concern so to be super quick what was the draft new adult you know just yes and I\u0027m expecting some some input from Gauri on the last sentence of the track Thanks okay okay next up is touching something on chatter yes yes thank you hello i I just enabled post my video and audio you guys with people to hear me yeah we can do and we can see great yeah so I\u0027ll keep a very brief update on the video traffic model drop OH draft draft I don\u0027t know how it showed up twice next page next page please okay you\u0027ve got the second slide up it takes a little while great yes so basically we have an after the working group last call yeah sort of within that period was gathered a collection of reviews there were sort of two batches that\u0027s why we kind of updated the draft and twice first from 0 for 4 from 0 and Oh 204 205 to address a collection of comments and both from Colleen and from Jimmy foo so the I\u0027m listing out the main one here is in adding a set of security considerations by the way and J : later on in his we also pointed to the risk of that second and this is the text that we have added to the security considerations and I thought it would be convenient to post it up here for people to review and provide comments 22 I can read it out "
  },
  {
    "startTime": "00:27:18",
    "text": "briefly so basically we mentioned that it is important to evaluate our GP based congestion control schemes using realistic traffic patterns so as to ensure stable operations of the network therefore it is recommended that candidates and RTP based congestion control algorithms be tested under using the video traffic models presented in this draft before why deployment over the internet so sort of more not necessarily like a security consideration for the traffic models that that\u0027s been presented but rather more as a recommendation for people to try out their candidate scheme and using the more realistic traffic pattern if there\u0027s any other suggestions or comments I\u0027ll be happy to incorporate that as well and I\u0027ll just finish that that round of update and fixed a couple of other terminology you know sort of the issues mentioned by calling basically avoiding the use of Arts Ram Katra in our job as well as fixed a couple of issues we run it by the ID units checked so our past here just in case people have comments regarding the text on the security considerations okay I don\u0027t see anyone at the microphone so I think okay then moving forward we later also and get some additional comments from both Michael and Jake those are more sort of editorial in nature one is in ensuring you know more consistent use of third person narrative and the other one is that Jake pointed out some confusion in our use of the term transient so we we made a pass and try to make mention of either transient period or transient States throughout several pieces of the draft those can be easily identify if you click on the different of the draft another minor wording changes I don\u0027t think it\u0027s worse a year basically would be we have addressed all reviewer comments and by the way and for the more detailed review comments on the mailing list after we updated draft as I remember I\u0027ve also provided sort of PowerPoint responses to the reviewers and so it\u0027s just we\u0027re just posting up it here just to make sure that if there are additional comments or you know if you really yourself grow up comments so we can accommodate them as well so to that I think we are kind of ready yet you\u0027re basically ready for the working group last called reviewers to check for those comments and buying by the way thanks blood or or your input and feedback on the draft so far sure thank you checking for the updates from what I\u0027ve what I can tell something my comments have been addressed I think "
  },
  {
    "startTime": "00:30:18",
    "text": "I don\u0027t remember but I think we got confirmation on the list for most people if there\u0027s no comments in the room what I would suggest is that just after the meeting I will issue a one week working with group last call to make sure and then we\u0027ll move this forward okay that sounds great okay thank you next up I think it\u0027s churching again talking about the mother in the Mozilla browser yes thank you so this is update and related to the draft by the way maybe a brief mention of the draft update status as an calling has showed earlier and the NADA draft has has completed working group last call and a martin has provided his shepherd reviews of comments and i believe we have we have actually updated the draft to version oh nine to address the individual and sort of review comments from martin that was a fairly you know eggs I just want to mention it up here too to make sure that the status updates are in sync with what the chair has them in their mind and go so so so going after that we have been mostly focusing on the implementation your effort in perfect incorporating it inside Mozilla Firefox browser and next page yes I just confirmed that is my understanding of the status as well so we just waiting to confirm okay that\u0027s great okay next slide is that there\u0027s a slight delay by the way I\u0027m waiting for its show to show up on my side so just a brief review the way we have made Co changes is that most of the changes are in what\u0027s up for one of the subfolders and that\u0027s one of the modulars within the app web RTC code and in the firefox and code repo and we\u0027ve basically took the hack of replacing the default and send bandwidth estimation modular which is in charge of estimating the recommended bandwidth with an alternative and that\u0027s called nada bandwidth estimation and of course we made changes to a cup of other files to you know serve to enable that change to enable that switch between de and also for this version this is before the hackathon so we have kept the receiver side of behavior intact which means that we do not really have one way delay measurement as feedback and we also have not modified the the feedback interval provided from the other end so so we sort of have a ma different slightly "
  },
  {
    "startTime": "00:33:18",
    "text": "different version of neither running in our current implementation so instead of using one way delay relative one way delay as the congestion signal as specified in the draft in this what we consider an intermediate version we\u0027re using the relative RTG as the congestion signal and also right now we\u0027re ignore we have not observed when the petty losses in our tests so our code right now has not added those handling for petty losses so it\u0027s kind of a slightly simplified version of the de nada congestion control algorithm the main I also want to point out that the default behavior of the rtcp feedback the typical swings around and the default interval of one second I\u0027m going to show some data on that - I believe it\u0027s sort of plus minus fifty percent right of the target feedback in which means that were actually operating this congestion control modular kind of this feels like interval higher than what we have designed it for so we\u0027re also curious to see whether it breaks or whether it still works and finally just for convenience we added a bit of our logging using the existing web RTC login framework so that we can pull out the stats to facilitate the graphing and next page so these are all the code change an overview of the code changes and next leg and page please so the way we run our tests will basically and set it up to have one side of the client and so first off with all these tests at least one side the modified version runs on Mac and then runs on the modified you know Firefox and nightly Butte the collection of changes is summarized below basically for the center side we now use the NADA bandwidth estimation modular we have revised the maximum sending rate to be format between second and also to explicitly configure the default video height to 720p but in the default Firefox behavior the video height is at 360 P and that also automatically limits T the maximum rate that\u0027s allowed that\u0027s specified for sending and finally a sort of logging we enabled locking States only and outgoing clothes another modular and there\u0027s no because we don\u0027t require any change from the receiver side we actually gone / a true Chrome you know I modified for the receiver side we use a-f-dot RC that\u0027s an online you know web RTC tool to enable the cost so we don\u0027t do anything other than changing the congestion control modular so we run three sets of tests the first one is really a sanity test I have two laptops "
  },
  {
    "startTime": "00:36:18",
    "text": "in my home you know connected to the same Wi-Fi and I kind of have fairly unlimited than home Wi-Fi so this is really to measure you know whether things work and how fast the rate can Graham here I\u0027m showing the three set of graphs showing the the rate calculated by the NADA congestion control modular in the first the top graph graph is the the relative RTG and that you know they write from the rtcp feedback message of course here you know with putting a local environment the base RTP is around one minute second so that\u0027s almost just the you know the the actual article orders and the the bottom graph shows the feedback interval of the individual read you know so for each rtcp feedback message as I was mentioning before basically it swings 50 50 percent flat miners are drawn as the one assessment and targeting for I kind of looked into the code to confirm that behavior to this one basically shows that the nagas algorithm because of the accelerated ramp up design it can start from the minimum rate of 200k and ramp up to the you know the maximum format within 15 seconds or so so it does Prem up pretty quickly and then even though this is drawn within the home unlimited but it\u0027s Wi-Fi so occasionally we do see you know a spike in the rtt so now that kind of reacts to that but recovers back fairly quickly if we have only one or two individual RTP spikes because of the minimum filtering you\u0027re doing next page please and next page please yeah we did okay so that is all the delay appreciable yeah so then we are ramping up the game a little bit I have a colleague actually gem foo and he\u0027s sorry gentle foo he\u0027s also one of the co-authors on the draft he is based in San Jose California so we basically carry out the same exercise except that now the sender is from my side and based in Austin Texas and he\u0027s from San Jose so there is a little bit of a green boat you know kind of that mimics more of a typical remote car and I was sending out the corner from the Cisco office where he the receiving end is home Wi-Fi oh by the way all these tests are carried over with bi-directional audio video course and I\u0027m only reporting on the the statistics of the outgoing sample the other side is kind of unmodified behavior so with this one what we are seeing is that the base RTP is actually very high it\u0027s around 160 milliseconds "
  },
  {
    "startTime": "00:39:19",
    "text": "and then also as we can see that even after you subtract the base the residual the relative RTP is fairly spiky and sort of spikes up sometimes quite outrageously constants in the very beginning and you know towards the the second you know the towards the end of the car so in reaction to that the nada congestion control modular indeed sometimes jobs to fairly load rate and then after the RTP recovers a little bit and ramps up again so when were no longer seeing a very more flat line I think control black paths we do see these adaptations going back and forth you know sort of swinging back and forth but maybe on the other hand the good news is that it does not get starved throughout it does have the capability of ramping back again when there were never there is the opportunity whenever to really yell it\u0027s a bit and I see there\u0027s a question yes go ahead yeah - just why are you sending so feedback so seldom why is this yeah and this is just we have not much we want to try first with our modified receiver behavior we obviously are interested in testing house whether you know faster feedback helps in my opinion it will help because you know it reduces the the feedback loop right the delay in the feedback control loop yeah it\u0027s just that we want to show kind of an intermediate result generalize the impression I get is this is just the regular rtcp feedback it\u0027s the only feedback channel they have at this point because we had leaked the code we the code changes we made dad if we\u0027re done this past week in a packet on that you do the real feedback okay but I mean still even read normal as long as you don\u0027t have this if you scale the five seconds and use the other one it\u0027s a regular feedback if it\u0027s endolymph often if you have the and program the mom is catch the comment I think Magnus was commenting that it should be possible to chew that feedback to go faster but Jonathan said the notice does have to do that okay if it\u0027s more like tuning the feedback external to the processor or is itself inside I did try you know sort of I actually had him to do receiver to so if you want we can you know kind of hard code so yeah if if one would implement according to the specifications and do the scaling etc if you use our Norris families modifiers in your STP or similar confirmation interface you will should be able to set thirty-two bound it so that you get more frequent feedback i "
  },
  {
    "startTime": "00:42:20",
    "text": "Jonathan Alex I would be astonished if liberal parties implements our our NRS okay so it sounds like we possibly have a browser limitation it looks it looks to me from a non neither expert I to be behaving sensibly given the the feedback is getting yes oh yeah sure by the way I want to mention that from from our perspective we are interested in its you know experimenting with other forms of feedback or more frequent feedback actually our to-do list it\u0027s just that the results were showing here we want to were sort of making stage two changes so we want to for now keep the receiver assist right sort of you know this way I\u0027ll be able to make the code changes and call anyone I want without you know doing anything special on the other side but then going forward will be interested in exploring you know sort of understand a bit better what new forms of feedback helps and to what extent yeah next page next page is up and I\u0027m measuring the latency here so relaying for serchio he says it realized during the hackathon we were not aware of transport feedback when we could go I mean we\u0027re not where there was a flavor of transport feedback already implemented so John Fleck speaking for myself chrome implements the Google transport CC extensions I believe Firefox display needed to epic that it has live web RTC in there does not currently implement it does not really have that enabled so in theory if you were speaking the transport CC you could interoperate with an existing Chrome browser I believe chrome is using that to feed something presumably equivalent to a little perhaps not the exactly the same as at PCC I think Casey\u0027s Lee is dong it wasn\u0027t it have to document all right since we\u0027re running a little short time so if you could go quickly go through the rest of the presentation sure yeah so under the final set of results is between B and Sergio so two across Atlantic car from Austin and two and Switzerland and again one side is from the office the other side is from the home where I\u0027m reporting again the base our GT here you know 300 plus many second just to show kind of the challenge and then but then I guess this time got slightly lucky in that most of the time if we don\u0027t see outer reaches our Tiki nada actually is able to you know that reach the phone maker per second by the way the connectivity is right even if from the home etc are fairly high and but then occasionally we do see those you know one second two second RTP spikes and nada will react "
  },
  {
    "startTime": "00:45:20",
    "text": "back and then try to grab up again again yeah and we\u0027re also seeing their corresponding feedback intervals extra reports in the bottom so sort of similar results and for us this is the first set of at least the know sort of running in the water test compared to all previous controller pairs or simulations so we\u0027re actually happy enough that no things getting really a break or you know the congestion controller didn\u0027t either flood the network or keep starving all the time but then of course we are very much interested in making it more reactive and then trying to see how how well can you can go next page and as a summary of observations that may be two things to highlight is that in the um let\u0027s see India and um you know some unlimited scenario the accelerator and Grandpa feature nada allows us to grant up to next weights fairly quickly sorry it\u0027s not 15 minute second it\u0027s a 15 second that was the title of my slide and the century briefly due to occasional RTD spikes and then once we get on to and remote connect connections we you know the algorithm reacts to RTP spikes and because of the long feedback unity and fairly you know sort of infrequent and interval it does take you know sir it doesn\u0027t wider great dip but otherwise it sustains maximum streaming grades was you know in the in the presence of random fluctuations so overall we actually thought it\u0027s quite a robust high RT T\u0027s and sort of higher than designed feedback intervals at this point next Paige you got it I\u0027m waiting on my set yeah you have the next pager yes yeah right and basically that motivates us and you know looking sort of looking at what to do next or obviously this a hackathon and feedback messages are something we\u0027ll want to be able to the result of it we want to be able to incorporate and the mention about the existing transport feedback implementation that something were look into - but interested in moving it all the way to the implementation as described in the trap in the draft in the sense that we want to use the feedback message as defined as well as you know move to the all the calculations based on relative one regulate values we\u0027re also interested in truck you know testing the impact of the different feedback intervals because that intuitively is a very cheap no sir parameter and and then tackling handling lost expected losses to at least adding that statistics and adding our existing algorithm in how we handle it over the series and so that that\u0027s about that\u0027s "
  },
  {
    "startTime": "00:48:20",
    "text": "it for the update for this draft okay thank you touching it to see some implementation experience I you guys flown one quick question can you make this code available somehow or is it not done yet it\u0027s it\u0027s half done maybe we will be happy to share a half-baked in the sense that feature wise right it\u0027s not the complete implementation but yeah I think if we clean it up a little bit we\u0027ll be happy to share that portion thank you yeah okay great thank you very much touching happy thank you hey Julius thank you everybody who doesn\u0027t know me I\u0027m jealous floor I\u0027m a PhD student from the University of Duisburg Essen next slide please and as you might be aware we\u0027ve done an implementation of the anodic congestion control algorithm in the omnibus plus ion of discrete ventilation framework and we finally managed to update it to the latest version of the draft and so this talk is supposed to be a short independent validation of the ns3 model you already have up on github next slide please and since since the last version of the draft has had a focus on that√≠s competitiveness with lost base flows this I\u0027m focusing here on test case 5.6 where we\u0027re comparing how Natha behaves with long-lived TCP flows but in in this scenario we\u0027ve used SCTP instead of TCP because I don\u0027t know the TCP model in omlette very well and I know that the SDP model is quite good because she has lots of code with the FreeBSD kernel and CTP in this case also used in the arena congestion control there\u0027s only one thing I\u0027m not quite sure because so I don\u0027t know whether the extra energy the SCTP model uses is the same as TCP and no.3 because as you will see in in the following graphs the the frequency of the delay spikes you see induced by the loss based congestion control is higher for my plots I don\u0027t know where those come from I guess this is has something to do with TCP in na 3 I can just tell you that setp X on every other packet so in this test case we have a bottleneck with one megabit 16 milliseconds of propagation delay and the maximum cumulative 3 milliseconds this test case also specifies I think 30 milliseconds of jitter that we don\u0027t edit that to to our model and also we\u0027ve been using the perfect video encoder which means all its immediately always generates the perfect desired sending rate and also please "
  },
  {
    "startTime": "00:51:22",
    "text": "note that in this version of our algorithm there\u0027s currently no accelerated ramp up not this means it may take a while for for the algorithm to converge to the desired rate okay so on the left side you see just one question yeah when you say perfect you know in our test there are two kinds of perfect one is adjusting the interval the other is adjusting the you know the number of packets per / so we\u0027re adjusting packet sizes so we have a fixed okay fps and we\u0027re just adjusting the exercises thank you so on the left side we see the reference implementation of three and in the right side are the results generated with our implementation and as you can see they\u0027re basically the same with with the exception that our frequency of the delay spikes is higher as I mentioned and I don\u0027t know what is this but it\u0027s it\u0027s that converges to the same operating point yeah next next slide please this is just the same scenario but with a larger bottleneck of 10 megabit so again basically the results are the same this was the reasons I only got like you like these two cases because across the board our curves looks very similar so it\u0027s just not that interesting next slide please so this one I guess you haven\u0027t seen yet so this is the new implementation of Nara as it interacts with the synthetic video codec stress based codec by Cisco here again the results look good but for some reason RTP tends to converge to a lower sending rate maybe surge or cha-ching are able to to say something about this I don\u0027t know if their behavior is the same yeah but but that\u0027s basically it yeah again sorry the confusion is we have essentially evaluated a large parameter spectrum with bose implementations and the behavior we\u0027ve seen has been basically the same if you\u0027re interested in are in some special simulation scenario I\u0027d be happy to implement it and push the results to the mailing list I hide so I want to mention for the trace based results at least we have also tests but we\u0027ve also tested in NS 3 maybe we have not shared the slides I can look back on that information and maybe share it on the mailing list extensions - if you want to do that comparison they would be good yet thank you thank you ok great thank you very much it\u0027s really nice that we\u0027re getting "
  },
  {
    "startTime": "00:54:23",
    "text": "some independent testing of these and it\u0027s also really nice that it\u0027s getting very similar result yeah absolutely thank you very much all right so we\u0027ve also been playing with a couple of congestion control flow state exchange next slide please and so we\u0027ve implemented version 7 of the document and we\u0027ve come across an issue where we find that the document talks about application limited scenarios for the passive version of the algorithm but not for the active version of the onion with them I don\u0027t know what what the reason for this is so this can lead to two issues if we have multiple RTP flows which have different priorities and if one of these flows is application limited this can basically lead to situations where other flows don\u0027t get more bandwidth even though they could be getting this because we still have some bandwidth available at the bottleneck next slide please so as a short remind reminder or how how office works and in the active so what we have is the the congestion control of an RTP flow sends a new sending a desired sending rate to the FEC and computes a delta to what the f is iike muted in the last iteration of the algorithm and sums all of these deltas up for periodically so what we get is an estimate of the the bottleneck capacity and what you can do is you can use that estimate of the bottleneck capacity to share it according to two weights among all floats you have in your in your flow state your in one flow group next slide please but the problem here is what happens if you compute a sending rate for a flow which is bigger than what your congestion control can deliver or which is bigger than what your media source can deliver then in this case in the second step after algorithm nothing happens but you make an error basically for your estimate of the bottleneck because imagine you you can compute a share of two megabit flow flow but you have an hour max of 1 point 5 mega bit in the next step of the iteration you report from the congestion control that you would like to send with 1.5 megabit and actually you decrease your total capacity of half a megabit so next slide please this leads to situations like yeast so this is an example here we have 2 RTP flows with different priorities and the bottleneck capacity of 4 megabit and a maximum sending rate of 1.5 megabit each "
  },
  {
    "startTime": "00:57:24",
    "text": "and so I would be expecting that RTP in this case or the flows in this case would get 1 point 5 mega bit each but as you can you see the second flow is somewhere around half of that next slide please so one one way to fix this would be to employ an approach as similar as what you see in the passive se where you compute a total left over rate so basically a difference between what your flow can with your traffic sauce can generate max and what you wanted to get and then just add it to the next flow in the same flow group next slide please yes so this is like the same scenario again with that fix and as you can see both lungs no get the maximum amount of they correct possible next slide please so yeah question is this an issue we should address questions how do we get this our max into the flow state exchange maybe in the register message but also we have two distinct cases where we are not limited by what our congestion control could deliver but maybe what and immediate source deliver so imagine we have a very old webcam which only does like 640 by 480 or sir yes how should we proceed there microwaves first of all thanks a lot for playing with this I mean quite nice to see second so the reason we didn\u0027t have two left over eight in this version is just I mean I was now looking back at the history of the old presentations you know we had it in the passive version and we ended up simplifying it and making it active and then the whole simplification process we removed that just to address the feedback from the group not be very happy to have that back in so I think it is an issue that we should address I think there is a small a small issue with the our group but that could be fixed and is probably not not a big thing actually if you could go back a few slides right now I\u0027m not 100% sure what\u0027s what\u0027s wrong here but something seems wrong because it seems that if there is a leftover rate to be added to the FAC our calculation of the very first flow the very flush flow is always gonna get zero right so something here seems to be in the wrong place oh yeah it might be sorry yeah yeah so this is a it seems like a minor thing I mean it\u0027s definitely doing the right the right thing yeah you\u0027re right just adding that up it may be that the plaster yellow has to go below if block or something like it\u0027s just a minor detail and we can "
  },
  {
    "startTime": "01:00:25",
    "text": "think this is easy to fix yeah but in principle I mean I I like this a lot I think this should happen I remember that I believe I remember 100% sure but that may be a part of the discussions that led us to remove it was also the second question that was on the last slide now regarding the interface you know I think there was a wish to keep the interface simple and not to have so many interactions and things coming to us I\u0027m not sure I believe this may have happened I think if we see register is a good place to have it maybe if it\u0027s a people on it\u0027s still too complex maybe we could just make sure that it document its says specifically that this my to lead this lead to do and desired behavior and that you should implement the passive version of the algorithm if you want to have total control I don\u0027t know I mean we I think we don\u0027t want complex but we do want correct yeah I agree I mean I I never understood why that would be so terribly complex but I think we were a bit maybe all over cautious in in and you know trying to keep complexity out and really really simplifying yeah that\u0027s my view so so what I\u0027m hearing is that this seems like a real issue and we should address it and question is just how we go about addressing it makes sense to people okay so I\u0027m seeing a cup of people nodding okay so the stressed is is with the RFC editor so at this point we can either do this in off 48 or we can pull it back to the working group it\u0027s not in plus the 238 my belief is that this is probably too substantive a change to just making off 48 so if that area director is comfortable if that\u0027s what we probably want to do is try and pull this back to the working group make the change fairly quickly and then you know Ari last four words and send it back area there activates here hiding behind Jonathan so I guess this is meant more than just an oversight right yeah it\u0027s a it\u0027s a it\u0027s an oversight but if there\u0027s a technical change I mean see or we could add it and I could have proved it but let me think about it for a second the other option would be to have a small draft that updates this draft but that also doesn\u0027t seem to be right okay so it seems like the conclusion is we agree that this change should be made if you could get "
  },
  {
    "startTime": "01:03:27",
    "text": "together and propose a change and then we will discuss with the area director and the RFC of this on the right way getting incorporated okay Mary great thank you very much is there anything anyone else wishes to bring up before we finish yes I am trying Gouri Fairhurst I\u0027m I\u0027m trying to write some security considerations text I wonder if it perhaps applies to many of the trust from the working group so I will send comments specifically on this one but I think there is a number of security considerations that point to one another and maybe the chairs or the working group wants to have a quick look at the security considerations across the current set of drafts yeah maybe some of the other drafts III will I will send comments but I\u0027m just saying that hey they might benefit from copying some of this text into other drafts or citing this particular set of security considerations across the drafts don\u0027t bugs I was just wondering if I feel like the hackathon work was moderately successful with us what are people worried shouldn\u0027t trying this again in in progress if there\u0027s interest that sounds like a good thing yeah okay all right great thank you very much in that case we will see you all in Pratt and if you have a blue sheet please bring it to the front of them thank you you "
  }
]