[
  {
    "startTime": "00:00:20",
    "text": "Thank you You have a lot. You had a bit get away, right, you've got it Can we we begin to gather and? hello everyone? Hello! This is your chair speaking. Excuse me hey Go now. If we could go ahead and get started, that'd be great Would somebody in the back mind closing that back door? door? Just to cut down on some of the noise"
  },
  {
    "startTime": "00:02:08",
    "text": "Okay, perfect First thing before we get started we are going to need some minute takers. Do we have any volunteers? Minutes taker volunteers. There is a notepad. You can do it collaborative It's linked from the agenda. It's super easy Really? Nobody I see people studiously trying not to meet my eyes All right so we have to do minutes, so which means we need a note taker So is somebody willing to do some notes, please? It's not that hard This is David I'd be willing to take notes after I finish presenting Well, thank you Others who did not volunteer, please feel free to add to the note page. It's linked from the agenda Okay so with that we'll go ahead and get started. This is the Jose working Group. As a reminder, you agreed to this when you register to attend this meeting. This is the note well of the IETF. It has all of the policies"
  },
  {
    "startTime": "00:04:00",
    "text": "and processes that are to be followed followed If you have any questions about the note well, please feel free to ask either John or I or Deb is our area director. Just a couple quick things that are other reminders These meetings are for professional collaboration. We want to maintain it environment in which everybody can participate and we do not in any way condone harassment if you feel that there is any behavior that you are not happy with, please bring it up. Thank you you Some additional meeting tips Be sure that you've looks like we have a fair number of people I recognize here as experienced IETFers. Don't forget to use the QR code or sign in to Meetecho Please use that tool to join the mic Please always go to the microphone when you're speaking and we will be using the queue to be ensure that the remote participants also have a chance to speak And with this this is our draft agenda Do we have any agenda bashing? Nope. And I think, David, are you first? I am Want to drive your slides, or did you want us to? I don't have that many. I can let you drive them Okay Good, everyone. Nice to talk to you today after lunch. We'll see what the energy is like in the room Unfortunately, I couldn't make it to Vancouver, but I'm really happy"
  },
  {
    "startTime": "00:06:02",
    "text": "to join you and talk about some of the other you today after lunch. We'll see what the energy is like in the room. Unfortunately, I couldn't make it to Vancouver, but I'm really happy to join you and talk about some of the updates we've had to the Jason WebProves family of specifications since IDF one Next slide So since the last IETF, we've had a lot of normative and we've had a lot of editorial editions The draft that was published a few weeks ago right before the cutoff was primarily internal changes. So we had a number of examples that were very dated. They'd been hand edited since the initial draft was accepted by the work group weren't necessarily the prettiest things either, and of course hand-editing means they probably didn't cryptograph validate unless we did something majorly wrong with the cryptography So behind the scenes, we refracted things to create kind of a common basis of examples and to write a implementation that would go through the steps of JD of examples and to write a implementation that would go through the steps of jwp generating a lot of artifacts that we could pull in So we kind of refact the documents to move algorithmic samples all the a single appendix underneath JP and those are now all being generated programmatically The draft 4 didn't have the change for the Mac-based algorithm that was in draft five, which will be the next slide in a second We also move to BBS, which is currently on draft 6 six. It has had a couple of changes but it's starting to slow down greatly in terms of the core cryptography, so we felt comfortable"
  },
  {
    "startTime": "00:08:02",
    "text": "dropping the draft suffixes that we had on the two algorithms, PBS and BBS proof. So those are now just BBS and BBS proof. No draft three or draft five suffix There was a breaking change in draft 6 in terms of the actual output, but it was relatively small in terms of code change We also moved to the latest BLSQ representation, which uses the XY curve and properly capitalizes people's initials Next slide So draft five would was published last night or this morning, depending on your point of view, had a bit more substantial changes in it So way back in draft three, we changed the proof section from being a single octet stream similar to JDS and having a single binary signature to actually being multi-part. So basically it's now in order to ray rather than a single string and we have that there, none of the algorithms were using it, but in draft five, we've refactored the single use in MacL algorithms to actually use that This is mostly there to provide them a bit of structure without having to invent it themselves It's also there so that when we start doing other representations such as a C zebra representation, we don't have to worry about people inventing different kind of structured representations of this intro information. So if you're unfamiliar with that algorithms, well, single use in Mac, they wind up having at least one signature potentially multiple signatures, multiple Macs And before they were concatenated into a big buy use in Mac, they went up having at least one signature, potentially multiple signatures, multiple Macs, and before they were concatenated into a big binary message that the"
  },
  {
    "startTime": "00:10:02",
    "text": "algorithm had to pull apart And now through the wonderful, wonder, of tilde delimination in the compact form and raise in the adjacent serialization, these are now represented as individual binary parts. So this does slightly increase the size of the messages, but we get a big benefit in that the algorithms don't have to encourage people to do binary buffer manipulation That winds up being specific to the cryptography use and the size of the JD people to do binary buffer manipulation. That winds up being specific to the cryptography used and the size of the GDP, how many payloads are in it. So hopefully this makes it more challenging to have a unsafe implementation of these specs because these all now wind up being the input to the particular cryptographic algorithms that you don't need to kind of pull apart. If you had something more complex as an algorithm, it need a more structure, you would still need to invent something like a object structure with optional part So far, I don't know of any that are going to need that. But this did also greatly simplify the implementation in the text, not having to pull these apart manually. Another we've found out that we had some basics for your old encoding leak into the algorithm. So we had some value that were being composed of, say, the basic B-64-year-al encoded version of particular payload rather than the binary form So this got changed. This was a breaking if you have an implementation but also removes a bit of a foot gun. So now algorithms are meant to operate be binary safe, to operate on binary data in the realm of basics for your all encoding is for serializing into compact and JSON forms"
  },
  {
    "startTime": "00:12:03",
    "text": "and for representing things within like say a JW JWK Finally, a big change We were with the single use in Mac components things using JWS This was very clever, but I'm sure people were were with the single use and Mac composing things using JWS. This was very clever, but I'm sure people realize that the consequence of clever is you have to explain which part is the magic trick. It becomes a lot more difficult to explain and it wasn't necessarily bearing any weight in terms of its complete It wasn't necessarily easier to use say, a JWS ES-256 signature that we synthesize a header and then extract the signature from versus just saying use UCDSA with the correct curve on this binary data and then use the signature Another benefit this simplifies the construction. We don't have to explain the magic trick And it removes what could be perceived as a dependent on a JWS library to implement these algorithms. It also means that when we do a something like a C-BOR representation, that there isn't the confusion about why algorithms are doing basics for your old encoding and decoding and JSON there isn't this confusion about why algorithms are doing basics four-year-old encoding and decoding and JSON-like headers internally Finally, we registered a structured syntax plus JWP for use by Apple applications. Next slide So speaking a bit of things that are going there related at BPS like I said, has draft 6 This seems to be getting a lot closer to stable, and they're shifting their focus on"
  },
  {
    "startTime": "00:14:00",
    "text": "extensions. So one extension there is blinding for signatures. So how can I get data included? like a protection for payload, for instance? where the issuer doesn't actually know the payload contents. So this is very specific You're not going to have someone provide sensitive information without the issuer correctly knowing and being able to vouch for it. But it does mean that you can have secret value that the issuer doesn't know that the holder of the credential does that can be used for a bit more of proof of possession So this is very useful Basically, for those who don't know, the ability to do a BBS proof relies on you knowing all of the values, all of the data of the credential before redaction And so these blinded values mean that no one not even the issuer would be able to do the proof Only the holder who knows that blinded value Orthogonal, I'll say is synonymous identifiers. So based on the identity of the verifier, we can generate basically a point, which would wind up being unique value for that verifier pretty much based on any payload So this would allow us to say have go for driving licenses have a driving license number and not disclose that, but use it as in to say have, go for driving licenses, have a driving license number and not disclose that, but use it as input to generate a stable identifier for sharing with a verifier So this starts to leak from say, identity verification a little bit more towards authentication or at least simplifying the recovery process If you can know that the document is kind of, has the same identifiers, not necessarily disclosing them and having them being a linkable value This combines with blinding"
  },
  {
    "startTime": "00:16:00",
    "text": "and that the pseudonym can be based on a blinded value. So I can basically have an idea identifier that the issue wouldn't even be able to be regenerate. So whether or not you how you use pseudonyms, what you base it on, whether it's blinded or is an application level decision, but these are really useful extensions for safety people who want to use this work for credentials I mentioned the BLS key representation updated. Another parallel work would be over in the OOF working group on SD jobs. I believe they're getting very close to last call So a lot of great work happening over there too. Next slide So next steps, there's more work than it's just on this slide, but these are the areas that we're you know, somewhat focused on in terms of priority So first of up, we want to make sure we understand how to use these valuable BPS extensions within J2P GPT, the equivalent to JOTs, make it some refactoring to accommodate these but very useful for some of these cases that we see people wanting to use this work for another one is single use BPS and Mac. They all have ways to kind of confirm that who the holder is. So some sort of proof of possession for BBS this could be based on the blinded valve or just knowing all the attributes For single use and Mac, this is based on having embedded ephemeral key that the holder knows the secret for. So you could say that BPS, it's somewhat intrinsic in the proof on presentation, whereas the other two it's a bit more extrinsic that I'm"
  },
  {
    "startTime": "00:18:02",
    "text": "using, you know, a signature from a key that's included to do this proof. So we were looking at moving single use in Mac to actually use JWS for those extrinsic holder confirmation stamps So basically sign over the presentation in order to prove that it's actually coming from the correct holder This should mean a little bit more agility because right now the cryptography that a holder could use is going to be tightly bound to the algorithm of issuance So if I want to issue based on say, EDI-2519, but the holder is using a cell phone that has P-256 curve and it's HSM, I can't really do that today with the parameters we have So looking to move to that, we probably will have a special form for that just for compact representation but hoping that simplifies things. We're also sort of some of the cleanups in the current published draft have been trying to move towards alignment with having a super cozy base representation We're hoping that the algorithms are identical. The outputs are pretty much identical and the different points of being things like protected headers and, you know, binary versus basic four-year-old encoded representations of things So we're hoping that we can make because we're at an early stage, kind of design for a great amount of reuse for the representation there. Finally, we're continuing to scout for additional algorithms. There has been concern in the past about single- use in Mac and how they're"
  },
  {
    "startTime": "00:20:00",
    "text": "don't have the newer properties zero knowledge proofs of generating pseudonyms that something like BBS has and the challenge has been having enough algorithm that we can say, okay, we don't necessarily need them I think that they are useful for people to have more algorithms that work with off the shelf, like HSMs and stuff today But if that case is to be made, then we really need to have additional algorithms that we can represent that have the properties that we're looking for. And so far, the level of specificity that we really want that's pretty much just been BBS I think that's it for me What was the last slide? So yeah, we are looking for more feedback from implementers We know this is a bit early, especially considering how many immediate deployment needs that are coming out of VI test two. But what sort of use cases? people are looking for what they would like us to focus on next, and always looking for implementers and again, we're looking for people who might be able to try it a little bit more feedback inspiration pointers towards what we could do for additional algorithms especially if we could find something that was multi-use unlinkable, but also post- post-quantum secure, like say a Stark or a lattice base zero knowledge proof That's it for me Are there any questions? for Mike for David? Okay We would like to see some additional review and discussion of this on the mailing list. Also, um,"
  },
  {
    "startTime": "00:22:02",
    "text": "David, if you could get with your authors, we have set up our we've begun to set up the GitHub repo for the Jose Working Group, and I'd like to have these drafts moved over to there so okay um set up the GitHub repo for the Jose working group and I'd like to have these drafts moved over to there so okay and I tried to help with that administrative kind of had off So if they run into process, like maybe the repo that they would like is being taken by someone else, that someone else might Oh, so you're, I've prayed to reach out with people in the past in order to get that process started and haven't had much luck So if people want to do that now, then I'll help wherever I can. We have one set up by the secretariat now i couldn't figure out who owned the repos that I found that were related to Jose and GitHub. And I couldn't get anybody to answer me on who had set them up. So we set up a different one. Okay well I can free up the name and we can move it okay if that's what we'd like to do yeah I think there a fairly simple process for doing that so thank you Thank you, everyone. All right Next is my Mike And I'll let you drive my slides Hi, I'm Mike Jones I know many of you. Thank you for coming I'm here to talk about the fully specified algorithms work that we've been doing for"
  },
  {
    "startTime": "00:24:02",
    "text": "a year and so. Next So I am not going to take your time saying what we're doing or why we're doing it We've covered that a few times. There's plenty of material to understand that. But you can reference if you would like to catch up on the motivations and goals. Next So we've made a lot of progress since IETF 119 in Brisbane In Brisbane, we described the current working group draft and at the time that was one big outstanding open issue in the working group about how we wanted to handle things in particular, elliptic curve Diffy-Hilman encryption we eventually decided, look, let's just comprehensively describe what's solving that with fully specified algorithms will be look like on list which we did if you search for the mailing list for a subject line, fully specified EC algorithms in April There was a good bit of discussion on that Some people saying, well, we don't need all of that Other people saying, well, but it's an actual problem But we got the data on what we might want to do about the remaining open issue which was great We then held working group last call in May on 2002 and I will say there was a lot of actionable constructive feedback received. I was really gratified by the level of engagement with the working group and got some really nice comments like, I don't know why somebody didn't do this a long time ago"
  },
  {
    "startTime": "00:26:02",
    "text": "orie steele and I worked pretty diligently going through every piece of feedback we received and we published O3 before the cutoff incorporating the working group last call feedback in July next So this slide all those bullet points are the history entries for 03 So that's a comprehensive description of what we did in the latest working group draft There's now going to be about a half dozen slides where I drew into some of these things that we did to make them completely obvious to you Next So, one of the most popular working group pieces of feedback was for Cose, make the status of ED25519 and ED-448 on par with support for the NIST curves. Used to be recommended no now it's recommended yes it's a very simple change, but it was a very popular change and so we were happy to do that based on working group feedback Next in Cozay because of the polymorphic nature of ECDSA, you could either do ECDSA with kind of traditional algorithms or it was, I would argue ambiguous in the Cose spec in the standard, about whether you could also use"
  },
  {
    "startTime": "00:28:02",
    "text": "some of those algorithm identifiers with brain pool and other situations so we got specific feedback saying well look, some of the MDOC deployment in particular for mobile drivers licenses, particularly in Europe, are using brain pool curves for some of the signatures Please, let's not strand those Cozai implementations and not give them fully specified algorithms. So? we did again very simple to do do and that's again text straight out of the table of the spec. Next Do you want questions now? Just somebody philip Hi, Mike Hi, everyone. On that same note, I recall a couple of months, maybe a year ago there, I finally figured out who was trying to do brainpool curves in Hosei It was the German Health Institute something like that so I'm not advocating for it, but maybe I'll try to find out the agency who specified using brainpool curves with Jose pin you on them or ping you somehow and see if, you know, they would like us to do the same for Jose Obviously, if there is also, you know, why consensus that we should Thank you for speaking up about that, Alib Philipp. I will say that one of the kind of intentionally conservative positions that Ori and I took were this work was we did not"
  },
  {
    "startTime": "00:30:02",
    "text": "create algorithms to do things where there were not already registered algorithms to do them. So for instance, we could have all done Jose registrations for brain pool algorithms We did not because they did, so we did for Cozay, but because there's no Jose registrations for Brainpool we did not do it. Now, it would not be hard for a different spec or a future version of this spec to do so should, you know, the working group by pop be hard for a different spec or a future version of this spec to do so, should, you know, the working group by popular acclaims say, let's do that at the same time But we intentionally did not create new functioning Okay, thanks, Mike. That makes sense Two points. I can help confirm about brain bookers for Hose Second question, for the causal values you are assigning to these curves, where did you get the numbers from? minus 261 to minus 264 the right? There's a big table in the IANA Algorithms Registry and there's many allocations already. Those were chosen to be in the two-byte range They're one of the two two-byte range so that they're not using up the rare one-byte numbers which is why they're greater than an absolute value of 256 and there's a small number of already registered things starting at minus 256 now why they're minus um shod registered minus numbers for signature algorithms"
  },
  {
    "startTime": "00:32:03",
    "text": "That's probably lost in history. Some of you may know. I just follow So to follow up, there isn't a mask asking is because us for enzymes I'm aware where these curves are needed for Cozy is mobile driving license specification in ISO and that is an already published ISO draft and it has to find different COSI values for the same algorithms and curves no for the curves not for the algorithms they didn't publish algorithm identifiers. These are algorithm identities not curve identifiers. So you are aligned with that draft yeah okay thank you I mean and when we get to a later slide on depth deprecated, I'll talk about if you would like the fact that MDL could keep doing what it's done if it's already working, but Kathleen. kathleen moriarty, I can help with that question from the time frame The minus was that it was starting to move out of favor as a austin wright? So it's the terms you had mentioned previously that were just defined That's what the minus was representing Oh, interesting. I did not. Yeah. So for those that don't know, I was the AD at the time, which is why I remember. Yeah very good. Thank you Anything else on this slide, otherwise next? ECDS again, that was the open issue when we met in Brisbane. And this is where we ended up with an engineering compromise We wanted to capture all the good dialogue that had come in as a result of the mailing list discussion And Ori and I, who's leaving, created a appendix in the current draft which captures what you"
  },
  {
    "startTime": "00:34:02",
    "text": "could do to register fully specified EC algorithms for all the core corresponding Jose and Cozai algorithms that are polymorphic But people said, A, this is a problem but it's not as big a problem as we want to register 18 things. So we compromised We, for both Jose and Coz, defined one fully specified ECDH algorithm for each of the kinds of uses Those algorithms use the most popular cryptographic findings today for those things which are the P-256 curve and when you need key wrapping, AES 128 key wrap You could register more in another spec You could even tell us, register more in this spec but we register two for Jose, four for Cozay And that's, again, a compromise an engineering trade-off based on the best synthesis of the working group feedback that we could put together next. Oh, we have Brian. We have a cue brian campbell, I may have different interpretations of what took place on the mailing list and so forth but I was not aware of anyone actually asking for algorithms to register. There was varying degrees of not worth it to this is a terrible idea, please don't do it, but I don't think there was anybody that actually wanted it or if they were, they were a very small minority. I would say that registering a small set is maybe even it doesn't feel like a good engineering trade off to me"
  },
  {
    "startTime": "00:36:00",
    "text": "It feels more like the worst possible thing that could have come out of this. Sorry, that's overly. I would I'm very much opposed to registering anything here, especially a small set of, of algorithms for a problem that no one really seems to have in practice, and this would potentially create a significant number of interoperability issues and maintenance difficulties for maintainers of such libraries Okay. Philip Like Brian, I was surprised to see O3 with these registrations And just to kind of nail on the point there are two for Jose, but there's no X25519. I know he said, tell us to register more so i'm saying i guess what i'm saying is either don't register everything or we need x2 X-255-19 for Jose as well at least to have a modern alternative to P-256 But likewise, I would much rather that we don't do these registrations as a maintainer You would much rather what? I would much rather that we do not have these registration and I'm speaking at this point as a maintainer of a couple of libraries Okay, I mean, I could go back and find on list the person or persons that said that it's a problem in practice and we were trying to again, cater both to people who said it's a problem and not a problem. Is this the right? trade-off? That's up to the working group. That's what we did as a result of the feedback, as we understood it Hi, there's Hannes. I think it's good that you do it. I have worked in a suit framework"
  },
  {
    "startTime": "00:38:02",
    "text": "encryption with Kosi. And there all these different variations are really a problem. And some of them have certain features and that is our combinations of algorithms have certain features and others don't So I think it's a good idea. Also using B2 of them have certain features and that is our combinations of algorithms have certain features and others don't so I think it's it's a good idea also using B-256 our one is also also good choice instead of curve 24519, namely because in the environment we have been using this IOT devices, there's often a lot of some of the, the, the, the, the curves 24519 are not that frequently used because there's also hardware acceleration for the NIST curves available so there that's a that's a very good choice i'm sure that maybe there are other uses of cosy for other algorithms so presumably like for the four you have probably do the job, but I find this is a practical problem Can you write that on list? I doubt that the minute takers know all of that I haven't posted that on the list, but I can do that no problem. I would appreciate that. Thank you, Hanas Next These two are quick. This is what we actually registered in the, or proposed to register in the current draft. These are the two Jose algorithms Next these are the four cosay algorithm The reason there's twice as many is Cozai uses both ephemeral static and static-static modes whereas Jose only registered ephemeral static algorithms Next"
  },
  {
    "startTime": "00:40:02",
    "text": "The other interesting discussion that I appreciated was what does it mean for something to be deprecated and what does it mean for something to be deprecated and what does it prohibited? and one of the things that I'll at least take partial blame for when we were finishing Coz√©, is I thought about incis that the algorithm registration criteria, the recommendation criteria, be described the same between Jose and Cozay. I didn't I mean, Jim ended up with, yes no, deprecated and something else whereas we took advice from sean turner, who was our area director at the time for Jose and Sean had recommended both deprecate prohibited, required, recommended optional somewhat different vocabularies And we did not want to try to completely bite off unifying those vocabularies that ship is sailed but in terms of what it means for something to be deprecated, there were useful discussions on list where some people felt like deprecated meant what Jose meant by prohibited, which is you must not use it, whereas the Cozay version of deprecated is used for algorithms like AESCBC where you know be careful what you're doing but it's not prohibited And so in order to"
  },
  {
    "startTime": "00:42:02",
    "text": "put these discussions to bed for fear, registrations, we thought, let's at least define these terms neither of which was actually defined in either spec suite and used the same definition in both cases So to Christina's point about brain pool, we are just deprecating the algorithm identifier used by brain pool in MDL We are not prohibiting it. That means if you have an implementation that's already using the polymorphic identifier and it's using it with a brain pool curve, there's nothing saying you can't keep that working whereas deprecated means if you're doing a new thing try not to do this anymore. As a opposed to prohibited which says you know, stop doing this right now Prohibited is appropriate for things like when there's a security vulnerability found in an algorithm And so we tried to clear that up, at least for purposes of Jose and Cozay. Thank you Moriarty. So, deprecated for a draft means this is just not something you should do anymore, right? And absolutely something can be obsoleted. And you'd see not something you should do anymore, right? And obsolete, something can be obsoleted and you'd still do it, right? Because there is a subsequent version that technically replaces it. So if you look at T do anymore, right? And obsolete, something can be obsolete and you'd still do it, right? Because there is a subsequent version that technically replaces it. So if you look at TLS 1.2, it's obsoleted by 1.3 but it's not yet deprecated because"
  },
  {
    "startTime": "00:44:00",
    "text": "nothing's wrong with it. I think change this so that this deprecated means something different than that deprecated could be quite confusing and then adding a prohibited So I think what you're adding might be confusing at least you know if you're going across the IETF and thinking of the terms and John Mattson made that point that deprecated is used in some drafts like TLS1.1 die, die, die, or whatever it was to mean stop using it although in fact the term isn't defined in those drafts. I read them It's like the time level in the tracker information like when a draft is deprecated or obsoleted, I'm talking IET, a process level. The status of the drafts as opposed to things in the graphs I know, but do you want to introduce a different way to use the same term? They already are I mean, the point I didn't make yet on this slide is, and again, this came from sean turner who was our area director at the time, he suggested these uses of the terms in Jose, and they're already in the spec spec And if we use these definitions, we don't have to change any registrations for Jose and we don't have to change any registrations for Jose use these definitions, we don't have to change any registrations for Jose, and we don't have to change any registrations for Cozay. If we change the meaning of deprecated to mean what's currently prohibition we would have to change a bunch of registration which doesn't seem like sort of minimal invasive. But this is a good on list discussion. I don't so much care what terms we land with I did care that we land with terms that are well defined Thank you. Next slide"
  },
  {
    "startTime": "00:46:02",
    "text": "All right, so where are we? As I see it, and as already sees it. Draft 3 solves the existing problems we were chartered to solve The trade-offs are based on extensive working groups feedback and I'm really gratified how many people spoke up and cared about these issues This was not like barely participation. There was a lot of traffic and so it took us a month to produce traffic three because we wanted to do a thorough job of incorporating everything we could that people said So thank you It tries to make a trade-off between immediately solving the problems that people have identified as immediate pain points, while document how future specs can solve additional problems that people aren't yet jumping up and down and saying the world's on fire because of this And importantly, one of the main missions and this is in the Charter is to prevent the problem from getting worse, which it does And again, we appreciate the vigorous engagement that we've received. I believe the draft is substantially improved because of it Next Last slide we suspect it's time for additional working group last call, but we can have a discussion on that point, and it's the chair's decision Brian? I will"
  },
  {
    "startTime": "00:48:02",
    "text": "note that I haven't read the new draft yet I apologize for that I hate it when people stand up and say that but I haven't had a chance to yet I am um very much opposed to the introduction of a new algorithm that I don't believe was anywhere in the discussion of last call, so I think that was inappropriate to add That aside, I would note also that the only feedback in response to the update responding to the last call feedback that's been received on this was basically a broad strokes mentioned that this doesn't was a broad stroke statement that it didn't address any of the feedback there and received them speaking on behalf of someone else now but i'm pretty sure they're in european time and not present so I'll do that for them So I don't think we're ready for a second working group bus call and I actually think that some of the problems with the the the potential deployment problems around the particular curve and signature algorithms are pretty pressing I know there's people that are wanting to have a solution in place for that and I personally think it's unfortunate that this whole thing's gotten caught up in the discussion of an attention to address VCDH problems that are not anywhere between not as pressing a problem and not a problem at all whilst also introducing potentially new interoperability problems and holding up the work that is really pressing and people are asking for from progress So yeah, not very uplifting comment, but it's what I got I have a couple of responses to that You're right, the only person that responded to the working group last call, emails that Ori and I sent was Neil Madden And, you know, Neil's on"
  },
  {
    "startTime": "00:50:00",
    "text": "record as saying in so many words I don't think we should solve these problems So it is consistent that Neal responded saying, I don't think this did what I was asking you to do He actually did also acknowledge, though, at this point, he thinks it should just be written to solve the... Speak louder? He did also just acknowledge in that email that he thinks it should focus on solely the problem of the the EDF EDDS issues and the two various curves so in a way he was giving giving to what the original goal of the draft was and allowing for that to go ahead not allowing, suggesting it be that way and and asking that the ECDH stuff be taken out of scope but no No, I hear you The other thing is, you and I have both been through a lot of last calls Generally, if you respond to people's comments and they don't say any anything, that means they're okay with it. There was only jon peterson we sent a response to out of about 10, that disagreed with the response. And it's unsurprisingly because he disagreed with the work for the most part I mean, to your point about not being comfortable with introducing ECDH algorithms that are fully specified, that seems like a really good last call comment for you to make Well, I haven't had a chance I don't love the silence is considered consent approach. I understand why you have to take it sometimes, so consider this, I guess, last call comment that that stuff should be removed. But it also gets back into some of my prior comments which were misconstrued as support for introducing those algorithms when I was just toying around on list, considering what the various combinations could look like, and I listed out a list"
  },
  {
    "startTime": "00:52:03",
    "text": "that I was trying, I'm not even expert in this, that that seemed too long already trying to just play with the ideas and hinted at the end of it that that was probably not a good idea and that I was uncomfortable with the idea of introducing them at all You represented that on list as being supportive of and even suggesting that those algorithms be added. So I have a little pent up dissatisfaction with the way some of this has played out And I don't feel like the results of the draft well represent what I have seen on list both from myself and from others involved. And it is, in fact, a time-consuming process to review, provide feedback and get back to it so there is there's reasons sometimes where there's not response to things like the update And I don't think that should be considered as just being okay with it. Okay, and to the extent that you felt like I misconstrued your response, I'm sorry about that, I do want to say, you did the most comprehensive analysis of the potential solutions to anybody, which is what I appreciated. Thank you. That's a little terrifying though because I said and even said afterwards that I didn't feel like I was qualified to do the analysis other than to say, don't do this, and then things proceeded from it. For what it's worth thank you Lauren Jumping the line really quick Do Brian's comment that the signature algorithms are sort of more important than the encryption algorithms which is, in my opinion, totally understandable because based on where some of that work is used historically. So the encryption mechanisms are newer. So I'm newer in"
  },
  {
    "startTime": "00:54:00",
    "text": "terms of usage because of the JWT and science tokens and so on. So encryption there is less common. But they're also outside sort of the classical OOS JWT type of usage, there are also other use cases where people do use encryption. And so I think that's that's fine So not everyone sort of sees the same urgency but but I see a need, for example, in these IOT use cases specifically with COSI and need for using the encryption mechanisms. And specifically, the emphemer static diffiherment Just maybe to clarify a point there, to Hannah says, I do use and implement an implement over 10 years ago, the JW excuse me, the JWE, the Jose level encryption So it's certainly not, I know it's not used as much, but it's not for a, lack of use or lack of need. There's a lack of need in the way that the negotiation occurs and the way that data is usually exchanged for the fully specified versions of ECDH, ephemeral static not for the algorithms themselves They're being used in practice right now It's also, JWE doesn't imply some sort of ephemeral Diffelman either. So there are lots of different as we all know, like both cozy and hosier are full of algorithms of different ways through things And I know know so you can you can use encryption the JWE and also the COSI encrypt in many different, with many different key exchange mechanism And the ephemeral static is only one of them. So you can just go for something super simplistic"
  },
  {
    "startTime": "00:56:02",
    "text": "and not use any of those more complicated mechanisms that's my point So just because you don't see or you think you don't see problems in with elliptic curve Diffie-Hellman, with the algorithms combination doesn't actually mean that if they don't exist exist exist Lawrence. Lawrence. laurence lundblade so I'm kind of trying to come up to speed on this little quickly so but my understanding is that the proposed minus 254 that's ECDHES, is based 254 that's ECDHES is basically a fully specified version of minus 29 that exists today right? Not having memory the numbers, it's a fully specified version of something Yeah, so minus 29 is, you know, ECDH, ES with a AES 128 key wrap, and then minus 50 says it's fully specified to the NIST curve, P-556. Okay, so my comment here is that in Prague there was an attack presented in the LAMPS working group about, I've been calling it the LAMS attack, and we've been discussing this heavily on the COES mailing list The minus 129 and friends are vulnerable to that attack, and I think we have to do something about it. And I think the only way to do some to do something about it and I think the only way to do something about it is going to be it's going to be a new number. It can't be you can't fix it without a new algorithm ID so my my comment here is should be, should we be registering minus 54? which probably shouldn't register minus 50s until we figured out what we're doing about this attack"
  },
  {
    "startTime": "00:58:02",
    "text": "and the approach for that What's that? Yeah, okay But my comment for this group is, you know, don't register minus 54 until we figure that out, right? Which, you know, I don't know if that's imminent or not, but it doesn't seem like it to me Thank you Okay, we, oh, sorry Your next So it seems to me like there's a fair amount of consensus around moving forward with everything other than the ECDH, which seems to be more controversial controversial Is there some way to I mean, it's not unheard of to combine and or separate specs? do we want to consider perhaps moving the ECDA? stuff to a separate specification? where we can have more ongoing discussion and debate? while not blocking the other algorithm which people seem to be keen on doing so what do the authors feel about that? um i think the reason compromise along that line is to do something along of what Brian was suggesting, which is let's not register new ECDH algorithms in this draft But at the same time, the working group did a bunch of an analysis on what it would look like to do ECDH registration and that's in an appendix And I would propose to leave the appendix there but say that"
  },
  {
    "startTime": "01:00:02",
    "text": "there was a working group consensus to register any of these at this time, but future specific could do so. But I don't want to pull all the working group knowledge that we gained about debating ECDH out of the spec, preferably Hi, justin richer and I'm actually going to suggest something that might suggested to me about a decade ago when I was in a similar situation with a bit of a draft that was more controversial than the rest. And that's that I'm going to propose that the authors take and create individual drafts not working group drafts, but individual drafts that perform the separation surgery in a way that they think makes the most sense to sort of like show this is where the dividing line would be between this piece and that piece and bring those back to the work group to say this is how we could go with the next draft. Do we want? This is what it would actually look like as opposed to sort of you know sort of vague line around this section would be out, but the appendix would be in and stuff like that. I would propose that to the authors. It worked out pretty well when you suggested I do it I don't remember the details. We can have a whole can have a hallway conversation. I was dynamic registration. Okay With, yeah. In this case, how however, in Brisbane, we did something pretty equivalent to that. We decided in Brisbane that we would have the mailing list to discussion about ECDH trying to categorize what that solution was decided in Brisbane that we would have the mailing list discussion about ECDH trying to categorize what that solution would be. So as you said, it wasn't vague there's a big table in that email that's cited in the slides and people responded to that that was a draft it was a detailed email discussion"
  },
  {
    "startTime": "01:02:02",
    "text": "So I feel like we've already covered that ground in this case. And that's what the working group told us to do in Brisbane We've got one more person in the queue and we do need to move on. I do think the result of all of this is we're not quite ready for another working group last call. So I think we need to have some additional discussion on the mailing list to figure out what ways forward we're willing to go with And Philip, you have the last word. Thank you Mike, I, from my record recollection of the appendix and i wouldn't mind if the appendix stayed in a version of the document where there is no actual registration sounds the fact that there are actual identity mentioned in the tables and I would like those to be gone from that discussion because those identifiers being there will actually lead to people implementing them anyway Any, you're done, do you have any last? I'd like to understand what it's going to take to move forward Right now it seems like we're stymied based on your conclusion Well, I thought there was a couple different proposals of ways. Like, are the authors willing to pull some of it out? Are there what? Are the authors willing to pull some? of this out? You suggested that we do a direct version of this that didn't write We could turn that around tomorrow and maybe we do, maybe we proceed with that that Otherwise people will just reimagine that I could turn it into prose rather than apparent identifiers. Okay But I don't want to, I don't think it does"
  },
  {
    "startTime": "01:04:02",
    "text": "justice to what the working group did in the last four months if we just delete it so can we just ask that specific question on the mailing list? Would it be okay? if we did turn it into pros and left? the appendix in place okay and took the registration out that are problematic for now? That's fine. Okay I'd like to solve the court problems. We've tried it solve all the problems but they're just I mean, I'd like to solve the core problems. We've tried to solve all the problems, but there doesn't appear to be an appetite to do that Right. All right. Thank you Okay, I will walk you through the course HBK document So here's a short summary of what it is in case you haven't been, for example, in the COSI group, or listen to one of the earlier presentations So we are talking about following the discussion we just had about chase on web encryption and HPK is a variant of public key encryption which uses the, it's a chem-based implementation key in caps encapsulation mechanism which given a public key of a recipient encrypts a message or any payload to that public key for following these chem-based APIs It was initially designed to support a classical traditional public key-based algorithms, but then it has also been defined to also cover sort of the hybrid mode or even people are debating now post-quantum use in HPK"
  },
  {
    "startTime": "01:06:02",
    "text": "but that's ongoing work and who knows where that will go The draft itself specified two serializations following what is already done before the JSON web encryption and there are two modes in there which offer different features one mode is which is called integrated encryption mode, which is targeting a single- recipient only. It's kind of an option version of the second mode Brian, you are already in the queue and I have not even finished the first slide Okay. I don't want to be pandan. Well, maybe I do want to be pananaic. I don't know but you started the introduction here and said you were going to talk about Cozay, HP, Ke. Oh okay, I mean, sorry. It's kind of but maybe that mistake. It's maybe a relative mistake given the desire to have things all be the same and not the same and the differences and so forth But we are talking about Jose here, right? Yeah I meant that was meant if you, if you, if slide is to remind what the work is about in case you haven't seen the discussion in Cozy or the previous presentation this is a newer document so you may have missed the Brisbane presentation. Perhaps I missed misunderstood what you said here, though. I did see the Brisbane food, but thank you. That's clarifying. Yeah so there's also a cozy based version which differs, but I did go into the details on how it differs because it obviously related to details in cozy and cozy or Jose it's and most people probably don't care about those differences because like the use cases for the two are somewhat different I would argue. But anyway I digress. So the second"
  },
  {
    "startTime": "01:08:02",
    "text": "mode is the key encryption mode which offers the ability to encrypt the payload to one or multiple recipients So that makes it different to the former one and it's of course or not of course, but it is more sort of complicated because it has, it has different, an additional layer of encryption while in the integrated mode you can encryption but it is more sort of complicated because it has a different, an additional layer of encryption. While in the integrated mode, you can encrypt a payload directly in the key encryption, as the name already indicates you first encrypt a content encryption key, which is then used to encrypt a code content so there's a one in layoff in the interaction, so to speak. Okay, so that's the one slide summary of what you probably have heard already in earlier presentations. Next slide So since the document was adopted, there was another two versions published So we are version 01 here. There was some feedback on a mailing list. Actually, there was more feedback than I thought feeling a little bit like we are rehashing some of the debates we had in the in the cozy working group already has been working on some early prototypes and and of course as things change we need to update the prototypes next slide Um, I think this slide I think is useful to explain some of the discussions on the mailing list, which were also the same reasons why we had lots of discussions in the COSI list so there's some similarity there. So in so when you use HPK there's a possibility to include application data or context information in the key derivation or into the authenticate authenticated data and there are two ways"
  },
  {
    "startTime": "01:10:02",
    "text": "to do so in HBKE, which are shown on the slide HBKE info and HBKE AAD and they have slightly different properties go into the different API calls, the HBKE specification as you probably remember, has specifies different APIs and these APIs allow you to pass in various different parameters And so I briefly summarized the differences here. So the HPK info has a fixed lens field versus the AAD the AAD has no lens restrictions but the former one is used in for one shot AP versus the later one is available in all APIs okay so the important aspect here, in my opinion is the question at the bottom, namely what information, what context information, what application? layer context are you incorporating in the HBKE? key derivation Because and that is important because it allows you to bind the endpoints and also the algorithm information that was in reference to what Lawrence previously said on a mic microphone. So if you don't bind that con context, an attacker is able to manipulate some of that information and potentially depending on the usage environment, which only the application developer knows it can then perform some attacks. So you need to be able to flex include that information which of course push also some responsibility to the application design perform some attacks so you need to be able to flexibly include that information which of course pushes also some responsibility to the application. Sorry, I hate to interrupt but we only have 20 minutes left and we have two more topics after this Okay, then I'll... You've got about seven minutes to do the highlight OK, I do. OK, then I slide. Sorry. Thank you So here's an example for the key encryption"
  },
  {
    "startTime": "01:12:02",
    "text": "Please pay attention to the recipients field which is sort of the interesting one here so you have the encrypted key field, sort of the recipients field is sort of the place where we encrypt the content encryption key which is then used on the outermost layer to encrypt the payload, which is here called the cyphertext So that's, I think that's the important part here also the fields in bold indicate the important fields with regard to this the use of HBKE in this, in this that's the important part. Here, also the fields in bold indicate the important fields with regard to this, the use of HBKE in this example, namely the encapsulated key which is this CT field from the chem that is output of HBKE and yeah, of course the algorithm field which indicates like what combination of HBKE algorithms we are using so in this case the NIST B-256 curve with SHA-256 and the AS-120 G-CM, which is then used to encrypt the content encryption key Okay, so that's the key encryption one The other one, which turned out to be a little bit more controversial on a meaning list which is next slide This is the text for this. Next slide Which is this intercrypted ink encryption mode, which is sort of only for a single recipient so it there is no recipient structure here, as you can obviously see on the screen And that is kind of an optimized to the earlier mode And so there have been some sort of a side effect of this is that it would require an update to the JWERFC which I think was in my reading the controversial aspect here. Next time"
  },
  {
    "startTime": "01:14:02",
    "text": "There's also some text explaining this. This is also the note that it requires this update. So next steps steps It's, I don't know don't know, uh, I think because I took a look at these Do you think these are too detailed to answer? These are way too detailed for us to answer here. I think if we work this week with a few of us, we can come up with some consensus calls that we can put onto the mailing list. If that's okay with you Of course. Okay, if you don't mind But everybody in here and online, obviously please take a look at the last two slides They were, ORI also posted a message to the mailing list that had the same, roughly the same content in it And we're gonna do a couple consensus calls to figure out a way forward for pieces of this document okay that would be that would be great Yeah, there's obviously a lot of details and a lot of reading that needs to be done so it's um yeah probably not. Yeah, we're not going to be able to formulate those into consensus calls that we can do here. Yeah. This in five done so it's yeah probably not easy we're not going to be able to formulate those into consensus calls that we can do here yeah this in in five in 15 minutes would be good if you formulated two with separate questions to the list Okay, yeah, I didn't want to really do it myself. Right having a discussion here and then finding out together with the chair to what possible use for questions to the group would be I noticed just because many are there's a huge overlap between the people participating in COSI and Jose like I've been witnessing this david lawrence. I'm surely will agree with me, like we've been through like one and a half years of discussion in Cozy on this and we've been up and down the solution space and back and forth and that's why I started implementing some of that early on"
  },
  {
    "startTime": "01:16:02",
    "text": "in COSI to change it like five times because people change it. And I think we have closed on the list. OK Next. Next one next topic yes next top Oh, yeah, this yeah, and I apologize. We probably should have asked for a little bit more time, but we did not do that. So so I will speed that up really How much time do you have? We have 15 minutes 10 for you Again, I missed Brisbane, yeah, that was a copy and base mistake Hopefully. So if that's like that looks familiar, then I uploaded the wrong slide So you know this already, so I don't need to tell you anything about the need for post-quantum crypto algorithms. I also don't need to remind you about the competition that NIST is doing and what all the different algorithms are. There's a great document in the big key, be quick don't need to remind you about the competition that NIST is doing and what all the different algorithms are. There's a great document in the P-QIP-MAY or group which focuses on BQC for engineers which explains all this about chems and how the API calls look like with the keychain and anger encapsulate and decapsulate, which is very similar from a API point of view than what we just talked about in HB Key. So that's why I'm good to have these talks next to you like with the keychain and encapsulate and decapsulate, which is very similar from an API point of view than what we just talked about in HBKK, so that's why I'm good to have these talks next to each other so next slide, so look at it when you when you find time um so there's obviously this uh also this discussed in various different groups that transition paths between the traditional algorithms and then the post-quantum crypto-agorism and with hybrid schemes in between I just talked about that sort of ongoing working age HBKE, and this document is about the sort of like the end state where traditional algorithms have been entirely been replaced"
  },
  {
    "startTime": "01:18:02",
    "text": "by both quantum algorithms Next slide This is the API. Next slide Key encapsulation mechanism and the decapsulation also. If anyone cares about the details, I can explain them So wen lin the document, you've find a couple of Cyphosuite registers for again for these two modes that I explained earlier one mode where so this is modeled very similar to what I changed explained, the key encapsulated or the key encryption or key wrapping mechanism was this two layer approach versus the, and that's the lower table and the upper table is this and we keep changing names here it's called direct key agreement or the in integrated encryption mode where we have only one receipt and it's kind of the optimized version and bending a decision on the discussion in HBKE, we would change it either to have both modes or to have only one mode in COSI, we have the two modes because they are the efficiency is key because of use cases in COSI in general with the way how things are encoded there Okay, next slide Yeah, I just talked about the single and multiple recipients set up. Next slide So the single layer setup, I will skip that Talked about this uh talked about this yeah next one to show an example So this is, this is sort of the single resource mode and again here we have, like in the previous presentation, there's obviously a need to register"
  },
  {
    "startTime": "01:20:02",
    "text": "the algorithm, but in this case like obviously an easier task with the post-quantum crypto algorithm and the output of the encapsulation operation is then included in this newly defined field, the ChemCT CT for ciphertext and yeah, next slide is sort of the microprecipient mode before the recipient structure, which mimics what we have seen earlier here again the recipients, and there may be multiple of them, but then obviously it wouldn't fit on the slide, but it and it would encrypt the content encryption key here in one of the recipients structures and then the actual payload the one the application payload to be encrypted, would then stay outside and so you could for example encrypt a payload once and then have multi-recipients each get the content encryption key and can then encrypt the outermost payload. So there's, by doing this, just there's also an efficiency gain specifically if you have long payloads like like firmware or software or anything big okay next slide so you see a pattern here in the type of style, obviously taken from the discussion So on the question to the group is working group adoption or style, obviously taken from the discussion. So the questions to the group is working group adoption and of course feedback as well. If you have any, what? the the questions to the group is working group adoption or and of course feedback as well if you have any or if you're working on this already working in other groups in the IDF on post-bunding crypto like like John is with the work he has been doing in a group on the hackathon hackathon, so that obviously be any feature would be interesting okay we have about two minutes. Does anybody have any feedback?"
  },
  {
    "startTime": "01:22:02",
    "text": "on whether or not we should do a call for adoption on this document? Yes Okay, I see a thumbs up. I don't see any thumbs down. Another thumb up a couple more thumbs up. All right, we'll do a call for adoption on the matter list for this document So onus, is this? Come back You've left yourself eight minutes. But actually I kept it really short So this is a document I've been presenting twice already the first time in last November And next slide so Yaron joined us to this document. So I, and that's the sort of the submitted version after Yaron join So we had a call for adoption on the mailing list So I have we've been left hanging a little bit with that document there was a call for adoption there was quite some positive feedback. Mike spoke in favor so that Ori Giuseppe, even Ilari, spoke in favor which is like almost for me at least something very unusual but then Carson jumped in and said he wasn't quite sure the scope doesn't seem to be right and so I've actually used this meeting to find out like what could I possibly do to address this. So we collected the feedback. There was some some content wise feedback as well custom it actually a detailed review. So if he's online, thanks Thank you, Carson. Captured that in this in this GitHub repository. Next slide Oops, and I saw a typo in the status here uh so i'm this in this GitHub repository. Next slide. Oops, and I saw it typo in the status here. So, my, so initially the initial idea was oh, couldn't we have a more generic document like"
  },
  {
    "startTime": "01:24:02",
    "text": "as the titles such as guidance we want to capture some of the this attack, the lamps attacking there and so on and i think now we uh at the point we, I published the, uh, this lamps attack that, which would be covered in tomorrow's cozy session in a separate document so didn't include it in here, didn't quite fit, like look covered in tomorrow's cozy session in a separate document so didn't include it in here, didn't quite fit, looked a little bit awkward, a collection of random things And so my proposal here is to change the the title of the document to what's in the document sounds revolutionary, but which would be security aspects of key identifiers on code and Hozy, which was the main reason we started there work on the document i think that's quite uh sort of like, it's a very narrow focus, but on the other hand, it would be it would be a document that would soon be finished and i think it's a it's a pressing issue um that's my proposal on moving moving this forward I would appreciate feedback Oh, is there any feedback? Anybody in the room? seeing thumbs up? up So I think we have five minutes so can you just send a quick note to the list? Propos that and then depending on the feedback? we can do a short second call for adoption I can also resubmit that now to black heart period is over. Yeah I can resubmit the document with this new title and change the abstract and then would make it more meaningful if someone actually looks at the document again Yes. Well, since there are people doing thumbs up i'm assuming there are people willing to look at the document so"
  },
  {
    "startTime": "01:26:02",
    "text": "would make it more meaningful if someone actually looks at the document again. Yes. Well, since there are people doing thumbs up, I'm assuming there are people willing to look at the document. So, all right so yes if you could do that that would be wonderful yeah also for all of the working group documents documents since we do are in the process of moving everything to the IETI IETF-owned GitHub repo, if you all could, each of you, each of you authors could do the work to move in over, that would be fantastic And with that, I do apologize for rushing through the last few topics, but I think we got through them anyway So any other questions or comments, any other business? All right, so with that we end four minutes early Thank you Thank you away from all of them"
  }
]
