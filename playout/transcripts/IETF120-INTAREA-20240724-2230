[
  {
    "startTime": "00:00:04",
    "text": "Thank you. Thank you All right, so it's 3.30 And again, can someone help us with the note taking while we? Thank you. Thanks, Joe Thank you very much. Cool So... Rock and roll everyone my name is one carlos uniga hello everyone wassim haddad here. Welcome to interior session thanks so as usual this is a night IETF official meeting, so we have the IETF policies in effect for topics that as patents and code of conduct so if you participate in this meeting, you agree to follow our process and policies and you're aware that your contribution will be covered by patent application that are on or controlled by you you must disclose that You acknowledge that all written audio, video, photographic records and we may be made public And the personal information that you will provide will be handled in accordance with the IETF privacy statement So, very importantly, too, you agree to work respectfully with other participants, and if you have an issue please contact the Ombuds team at the address provided on the slide There is also information on the BCPs if you ever you have more questions and you feel free to reach out to the working group chairs or the area of the directors. Sorry? Okay. So we'll do like this this all right so uh next slide"
  },
  {
    "startTime": "00:02:01",
    "text": "for the note really well so all this is on professional collaboration so if ever you see any harassment or misbehavior please report it we add the IETFs try to create and maintain an environment for people with different backgrounds to collaborate and work together. So we please ask you to treat everyone with dignity decency and respect and again you should not engage in any harassment while in the meetings if you believe you have been harassed please let us know and contact the right people For the meeting tips, as usual, we're doing a meeting call. That's how we know and contact the right people. For the meeting tips, as usual, we're doing a meter code. That's how we're keeping track of who's attending. So please log on to the tool either with your mobile phone or your computer computer and that's how we are going to be keeping track of the queue in your participant these are the resources agenda mythical, and if you need assistance, please reach out Okay, so agenda, let's bash it out So we have the status updates as usual from us then we're gonna have Tommy and Cotter's Okay you're going to present on the proxy provisioning domains We have probe with Bill as well as extending ICMP, stateless reverse route, trace route from valentine savvy with Lynn, web proxy auto-discovery Josh, ICMP extensions from yen and EVN from Chong Feng Any questions or comments regarding the agenda? All right right"
  },
  {
    "startTime": "00:04:02",
    "text": "So the first working group item is the communicating proxy configurations in provisioning domains. We'll get an update on that from the author, so no need to discuss much right now about it The biggest update that we wanted to give you is about the expired drafts we have a big list of drafts that are expired And after discussing with our ID, we believe those should be declared dead so that they don't steal hang and stall there in our page. So we're going to be reaching out to each one of the individuals authors from those drafts before declaring them dead. And of course, they will be free to bring them back to life even after death. That's one of the superpowers of the IETF. So but for now we just think it's the best thing to do So if ever you are one of the authors and you want to mention something about them, that free to do it now or on the mailing list or reach out to us us I think that's about it for the working group status updates. Any questions or comments? No hearing none so we're moving to the first item communicating proxy configurations in provisioning domains Nagma Can you share from there? if you choose to share slides with just upload it"
  },
  {
    "startTime": "00:06:01",
    "text": "Yep He doesn't tell you you Let us come on control Hi, everybody I'm Dranga Miaojjj from Microsoft and I'm going to present the update on the draft communicating proxy configuration in provisioning domains I'm co-toring this draft with tommy pauly from Apple So this is going to be really short recap what the draft is about So it's used provision in domain JSON format from RFC 8801 and I add that supports for proxy configuration there is a couple of proxy configuration parameters here and one of them is for example is a proxy protocol supported by the proxy is it is very funny to say that so if the client is configured to use a proxy, for example, HTTP Connect proxy, it can ask for a provision domain for that proxy using the well-known your and can find out about other protocols protocol that protocol supports and can upgrade to the better version the more secure version, for example, max proxy proxy protocol supports and can upgrade to the better version, more secure version, for example, Max proxy. It can also, in the same way, find out about configuration the proxy has, for example, which domains are allowed and which domains are not allowed And also the draft shortly explained that proxy can be also the proxy configuration can be found out or learned from the network. But in this case, there is a security issue or security consideration attached to it because"
  },
  {
    "startTime": "00:08:02",
    "text": "clients should not blind this trust data that are coming from the network or information that are coming to the network. So there is some text about this in the draft explaining that there should be some kind of policy allowing to it are coming to the network. So there is some text about this in the draft explaining that there should be some kind of policy allowing to use this kind of process and not just blindly use them Thank you was a adopted since the last year was adopted since the last EATF, and we also have a short update that address some of the major issues that we had. And I'm going to go through the through the updates and we can discuss or have a big feedback from the group on them So this is the list of the updates and I'm going to go from through each of them one by one so the first one is we added to configuration information about the HTTP version supported by the product, by the proxation update, the client didn't know what version of HTTP proxy supports So it could only use the regular way of finding out the versions of the HTTP that is supported for example racing them or trying and falling back or using something like, Service B DNS records, which does work in all the cases, for example, if it's connected to the address. And also it can use out-service mechanism to learn about the HTTP versions. But this adds a round-trip time to find out So we added a new key. This is ALAPN key, which contains the list of LPNs that proxy support And in this way, the client knows in front which version the proxy support and can choose the one that best fits their needs"
  },
  {
    "startTime": "00:10:02",
    "text": "Any questions or feedback on this? Thanks, Dragana Ben. benjamin schwartz, Meta I'm not convinced that optimizing connection to HTTP endpoints that use an IP host name should be a priority here. I'll note that it is not a priority It was not a priority for the original service bindings draft, which does not attempt to cover that. It just says that's going to be slow, and that's how it is So I don't think it's really worth optimizing, but if you want to go down this road, I would encourage you to harmonize this with the well-known ECH draft in the TLS working group which also specifies a JSON encoding for those same information okay yeah I've will take a look on that, or dummy tommy pauly Apple, so just responding a little bit to that, like in the case of like SVCB, given that like on a DNS record, I totally understand why we would not try to address the IP literal case there I agree it's a low price in general but I think you could have some you could imagine some funky cases where you have a proxy, which is only available over H3 and it is only available by IP address in some weird case. And while we are already giving the configuration information, you may as well have a way to tell that since there isn't another mechanism This is just, I think we can change this syntax, absolutely. And if we have something better to look at, I'd love to do that Okay. Yeah, I something better to look at, I'd love to do that. Okay. Yeah, I'm not going to argue against this Yeah, it's, we already have"
  },
  {
    "startTime": "00:12:02",
    "text": "a configuration, it's just adding the new key to speed stuff up Yeah, I'll just, okay, sorry, I just want to add extensibility is going to be valuable here because you might want ECA Okay, I was like looking sorry, I just want to add, extensibility is going to be valuable here because you might want ECA. Okay, I will take a look at that. The next tissue the next update that you had is about the DNS. Let's put the N at that. The next issue, the next update that we had is about the DNS, the split DNS configuration. So previously we had DNA Zones keyword that was listing the domains that are allowed to the proxy But this doesn't work to, it's an easy, it's not easy to configure excluded domains in this way So now we have two lists. We have matching domain and excluded domain which contains the list of domains And clients wants to connect to their source through the proxy, so it's a domain, through the property it needs to check both of the to figure out if if not proxy could root this request benjamin schwartz. So DNS zones is the defined in RFC 801 The definition of it is completely opaque to me I would really like to see and this so now this is going to and up with three different DNA domain list The DNS zone is out, so there is just two of them There is just matching domain next matching domains, including domains. So I looked in the draft DNS zone is not mentioned, which means it's not deprecated and if the interaction it's a this is in the sub-diction of the proxy Okay. Proxy is a separate subdictionary and for the proxy subdiction there is just two. Okay, that's helpful, but I think you still need to address the interaction between them"
  },
  {
    "startTime": "00:14:02",
    "text": "maybe a sentence saying don't use dns zones in this pvd uh i don't know know So everything, no hat here. I just wonder what the key names are correct because you say match domain and exclude it domain should it be excluded the domain? Oh, we can change name yeah yeah name Yeah. Tommy Polyaple. One other point that I had heard discussed a question brought by someone else earlier this week was how do you hand match and exclude IP subnet? because that is something like a pack file can do so either that leads to more keys or we find a way to have the format of this key allow for matching and excluding both names and subnets. It's just something that needs to be taken care of. I think it is important. Yeah, I think there's also a clarification to be made that exclusions, you could have only exclusions and have the default be include everything to say, so there are no specific match domain but you only have a little carve out for things you don't want to practice And the last change, since the last year, is about marking key as mandatory optional Previously, we didn't have this identification for the keys and now this this should add a better way to support different use cases and different configurations so all the new keys that are that was mentioned before, like LPN and exclusive domain and matching domains are"
  },
  {
    "startTime": "00:16:02",
    "text": "optional and we updated TIA and our registry to add a column about mandate or other column mandatory so this is this is this sufficient for the long-term strategy to to be able to update and extend this configuration and the thoughts? Hi, josh cohen I think one of things that should happen is look at the different functions that are commonly used in PAC files And that may mean more keys or it may mean like time was saying, sort of rules for how to do it because I think like things like regular expressions are commonly used in pack files So stuff like that. So basically doing like a review of the different functions and seeing how, if possible, those can be added to PBD. Yeah. Thank you you you let's do that okay um sorry i'm having a hard time getting into the queue uh mine if having a hard time getting into the queue. Might I find you up? Ben, david schinazi, Google Just to answer Josh, I think the fact that pack scripts were touring complete was somewhat of a horrible mistake that's been a huge headache for decades at this point So if you do, you know, when you do this effort of looking at, that, don't go crazy, keep it simple This is what, this is what's great about this. Yeah, I know I know. We don't want to have the same thing. Like a the same security issues or similar ones or any any So, and the last slide is about the remaining issues that we currently have accepted what Tom was already mentioning on the on the this was a uh, uh, uh, slides were made before that"
  },
  {
    "startTime": "00:18:02",
    "text": "So, um, uh, the first one is about authentic to the proxy. Um, this question should the the configuration have also some information about what kind of authentication process expect? Not to perform an authentication, but kind of an authentication so that the client can maybe prefetch some tokens that it's needed or decide not to use the proxy because it's doesn't have a proper token for this kind of authentication to the proxy. The second one is about the character set to use for the JSON format The provision domain JSON format doesn't have doesn't restrict character sets to be used and the question is should be restricted for this sub dictionary for the keys and for the values to be able to easier parse them. Yeah the different programming language and the last one is, as I already mentioned, the proxy configuration can be learned from the network which should not be trusted completely, and there is already some text in the draft about that this should be considered carefully And I'm wondering if the working group can take a look and and and have a feedback of whether this should be extended or changed or yeah, any feedback Yes, Ben? Hi uh i really think that we have a lot of work to do on client dot that authentication to proxies I don't really see why it would go here. It seems to me that it would go in line with the normal HTTP authentication challenge response flows. We still have some work to do. The existing flows don't do it. But I it's not obvious to me why I would go here This will be just a hint. More than the hint, it's not we still have some work to do the existing flows don't don't do it but I it's not obvious to me why I would go here this this will be just a hint more than the hint it's nothing else anyway not that that's all i that's the only thought uh"
  },
  {
    "startTime": "00:20:02",
    "text": "go here. This will be just a hint. More than the hint, it's nothing else. Anyway, not that's all I, that's the only thought. On JSON, it happens that URI templates are defined as unicode strings and that is also what jason strings are so the most natural thing to me is to say nothing there. And all the other fields here, are containing defined content I think, you know, it so happens that that that all of the possible valid values are lower ASCII And so I think that's covered implicitly. Maybe the key values should be a string without space or something it's just lazy either parsing or something like that so you are defining a reg registry for the key names and you'll have to come up with some rules for what those key names are but i don't think that matters yeah thank you you but I don't think that matters. Yeah, thank you. So to Ben's comment about authenticating the project for most cases, I agree with you that you should just have a URL and when you try and hit the URL, you'll get challenged for authentication and handle that with a normal flow. I think the exception to that is possibly what David is now in Q to discuss. When you have a proxy that doesn't want anyone to know it's a proxy and you going to be presenting the unprompted or whatever we're calling it this IETF law scheme Luckily, I didn't get out of the queue So normal HTTP authentic challenges basically don't work for proxies proxies And it doesn't really work And it's effectively limited to your very most basic product situation So like, for example, you can't return a, uh, like a normal HTTP authentication You can return a 400, I guess"
  },
  {
    "startTime": "00:22:02",
    "text": "and like present the user with a page that, like, guides them through some kind of authentic flow. You can send them out to do single sign on somewhere else and come back there's like there's like stuff that you can do. But with a proxy, there's no user interface that you can display and so except except for the very narrowest like situations where you want to do basic authentication or like something dead simple where there's a defined Chrome that the that the user agent can present to you it doesn't work very well. So this is what I mean by we have work to do I wanted to be able to do single sign-on and pass keys and two-factor through HTTP authentication to proxies but I just don't see how that connects here that connects here yeah there is definite progress to be made in the field. I just, I don't think any of that leads to we need to stuff something of this JSON JSON David Skidavis, a, thank you schinazi, authentication enthusiast, I guess Person who filed the issue number 249 here So the motivation for me there is not, is that there are a bunch of authentic emissions methods that do work with proxies, I mean, basic sure, but mainly the ones like issues concealed off that I'm the author on that just went through, like finished working group last call, also all the privacy password ones. And so in product, like we have these in production And being able to know which of those your proxy supports as a hint, can be useful because you have this constellation of stuff, can be nice So that was the intent of this. It's not to define any authentication to the proxy, it's just to say which authentic schemes does this proxy support support Jim Taff from Broadcom. I will say that authentication methods are heavily used"
  },
  {
    "startTime": "00:24:02",
    "text": "in on-promise proxy deployment, Crobros and every large company I deal with Kroboros everywhere So it is heavily used 407 redirect to a a tommy pauly Apple Yeah, so to the question of off, I mean, like, I don't really care too much if it's in this JSON format, but overall I think for a lot of the process, mean, like, I don't really care too much if it's in this JSON format, but overall, I think for a lot of the proxy cases, if it's, you know, not in something where you're part of a browser, it's just like something the system's doing you need to have a case that's just like the machine is just automatically going to be able to present this for a lot of the mass style proxies We use privacy pass very heavily today. One of the benefits of having a hint here is that for some of these types of authentication, you need to do or it's useful for performance to do work ahead of time Like with Privacy Pass tokens, you can grab a whole batch of them ahead of time because you're going to do one-time spending on them. To the UI flow one thing that we may also want to consider is grab the PVD information is something that happens at the time of, you know, learning a about the configuration of a network or a proxy in deciding do you want to use it. And so that is potentially an opportunity for some system level or a other configuration level UI where you can say, okay I've learned that my proxy takes something like a credential that's derived off of another credential so I can grab a Privacy Pass token that is based on the fact that I signed in with single sign on. And so I can have some nice UI flow, which unlocks my ability to later authenticate automatically So just things to consider Okay Thank you"
  },
  {
    "startTime": "00:26:02",
    "text": "So we close the queue, but thanks, Dragana, for the presentation If you have any more feedback, please feel free to send it on the mailing list So, Bill, you have two presentations, five minutes each so so feel free to use your 10 minutes as you please okay Hey everyone, I'm bill fenner I'm here to talk about two completely different ICMP things So the first one, they're both actually but the first one is one that can up first in Brisbane and it's about the probe protocol, RFC 8335 also called ICMP Extended Echo So this is a protocol where it's a lot like ping in that you send a package to remote and you get an answer back, but it's not at all like ping in that you are asking the remote a question You're not just saying, can I, did this packet get to? you, but you're asking, is the interface of yours up? Does it have an IPV4? address? Does it have an IPV6 address? Or, is this entry in your ARPCA? cache or your neighbor discovery cache? So that's the back background of what the protocol is A reminder of why, what's the motivation for publishing a new document? I went to go implement it and I did a survey of existing implementations and how they behave. And I'm not going to go over the details, but the fact that each implementation had a different behavior made me come to the conclusion that the spec needed some clarifications Also at the bottom, if a question from a user like, is this successful or is it not successful in how do I know so um last meeting, I presented the document and a lot of the content The changes since the last meeting were very minor, got some good feedback"
  },
  {
    "startTime": "00:28:02",
    "text": "but just kind of said, oh, like, this this optional field is really optional and deleted the extra null in null really good stuff um so the authors think that it's a valuable update to ROC 8335 and that it's ready to move forward Some resources kind of for coming back to, I don't think move forward. Some resources kind of for coming back to, I don't expect you to copy stuff off of here live but there's some some that I built while I was doing this exploration that like sends using SCAPI some probe packets and my V4 pull request got merged into TCP dump V61 is still pending and a repository to do some work on the open source probe client and then a link to this document So what's next? There's still the author issue. We can resolve that i'm not worried about it um but um don't know if we are if if if we should do you know some in informal interop testing to see a but I don't know if we are if if if we should do, you know, some informal interop testing to see if my ideas about what this spec now says are right and then really the reason I'm here right now is, you know, like I said earlier, the authors think that it's ready to become an RFCBIS document, so I'm asking for a working group adoption Anyone have any comments? Jumping on the queue, no hat on For the interrupt testing, or are you foreseeing something like an hackathon or you have something in mind that? you want to the group, to propose to the group? I mean,"
  },
  {
    "startTime": "00:30:02",
    "text": "it could just be you know i have access to all of the implementation that i know about so i could just set them up in a lab one day and start pinging and publish that result either as a you know, web page or as an appendix in the document or something the question is I mean maybe there's a round of feedback to the with the implementation author before making the results public because of those red X's, you know Right Thank you. Okay Eric Vink as an injured contributor yes, go forward. That looks like an interesting idea Only saying when it's, if it's adopted and when it's adopted change the name in RSC 83 25, whatever beast, right? Yeah, I didn't want to presume when I first published the work, so I didn't want to say, I know this is going to be 833.35 BIS So when it becomes, if it becomes a work group document yes I agree change the name thank you yeah so I think make becomes a working group document, yes, I agree, change the name. Thank you. Yeah, so I think it makes sense, so we'll consider it, but for yeah yeah exactly so Okay great. Next ICMP thing perfect on time Okay, so this one is about the weird kind of deployments we're starting to see customers are starting to talk about, where in a world of IPv4 scarcity, you don't want to assign a unique IP address to every interface"
  },
  {
    "startTime": "00:32:02",
    "text": "IP4 address to every interface on your router that's just waste for But you might not even want to assign an IPV4 address to every router If all of your forwarding is done, over IPV6, all of your control plane, you barely need it. You kind of need it for trace route So let's fix that problem instead This is what I just said. So it's all about IP address, scarcity, and deployments that are moving to extreme reduction in the amount of IPV4 address is used the proposed solution is to be able to use the ICMP extension mechanism on which there are a number of different ways in which to use these RFC 4880 ICMP extensions to be able to add an information chunk to an ICMP error on its way through. So the response to the trace route, could now include this field that says, this is my address Don't really pay attention to the source address. That's not enough information to know who I am. This is who I am And also a node name So I, you know, call me route foo you don't have to you know, you don't have to do anything to learn more about it. That's who I am So this is an extreme example of the you know very scarce addresses, every node in the trace route has the same address because we just ran out. And in fact, that's a bogus fee know, very scarce addresses. Every node in the trace route has the same address, because we just ran out. And in fact, that's a bogus before address. Anyway, there's, that's from the reserved space But so this is just a format that could be used but this is, you know, each of these"
  },
  {
    "startTime": "00:34:02",
    "text": "hops has a different piece of information. It says, here's my known names here this one just says here's my IP address IP6 address this one says both and then the final one just, again, back to Justice says here's my node names here this one just says here's my IP address IPV6 address this one says both and then the final one just again back to just its node name So the current status, we have an implementation in ERISA EOS Cisco has an implementation in the lab that they're playing with Arista has patches ready to submit to open source TCP dump and trace route packages The ANIC code point has been assigned, but we're not using it yet. We're using the mechanism described in the experimental code points useful RFC that where you have to explicitly configure a private use code point in a test deployment and we're doing that to make sure that the working group has the ability to change this. You know, if we just ship something and use a code point like we got the code point because it's first come first serve. But if the working group decides that the document needs changes, then we just burned that code point unnecessarily. So uh but for this oh just I wanted to mention also that there there was some I sent a message last week to the mailing list, there was some good follow to that on the mail list. So I think there's to mention also that there was some, I sent a message last week to the mailing list. There were some good follow-ups to that on the mailing list. So I think there is interest out there in this So again, I say, you know, for this document too, I think we're pretty ready for working group adoption Thanks, Joe You can go back to the recording Yeah, joe clarke, Cisco, I've read the draft, I've provided some feedback, and I think this is"
  },
  {
    "startTime": "00:36:02",
    "text": "fantastic from a troubleshooting standpoint I mean, Bill showed an example, but you can imagine for operators, for anyone who's doing it trace route across the internet, this is useful metadata to see fills in gaps And if I was the operator running the network, it would help me like, oh yeah, that's this address here even if I didn't have it everything in my own internal DNA So I think this would be great. It feels like low hand fruit in the world of the internet to implement something like this Thanks Thanks for Ben. Thank you schwartz I'm definitely not an expert on this at all, but when I see trace routes, they usually have IP addresses and then they have names derived from pointer record in the reverse zone, and that's it And this seems to recapitulate that basis basically. And I wonder, is there, is this an option? have names derived from pointer records in the reverse zone and that's it and this seems to recapitulate that basically and I wonder is there is this an opportunity to provide more user, human readable information? beyond an IP address and a host name to be able to tell me something about this piece of hardware? that might be useful for me to know There's an example is RFC 5387, 5830 always get it backwards, but that gives you incoming interface information which is another piece of information that you could get if every interface had a different IP address. But again, we're moving away from that. And so in order to fill that in, that RFC gives you incoming interface, IF index, or and or name and or address and or MTEU. So it can give you any of these pieces of information information So that's an example of what already exists and you could deploy these things together these extensions are stackable so you can have this"
  },
  {
    "startTime": "00:38:02",
    "text": "one and that one at the same time. You don't have to worry about them conflicting Okay, that's interesting. I just, food for thought about whether you want this field to really be a host name or whether you want to to be a free text field I, right I want it to be a host name, I think, because i want i don't want okay let me turn it around I don't want a free text field I want if it's going to be more than just a host name I want to start structured text field. And I don't want to put JSON into ICO so you know there are other bit fields available if we have some ideas about what is, what more what further information is useful There's also privacy implications not personal privacy, but network design privacy and the more information you give out, the more you have to worry about the privacy implications of giving that information out. And so that's another reason that this is kind of focused and limited in scope however i'd encourage discussion on the list if anyone has a concrete suggestion about more information that would be useful to add add Okay. Robert Kishhtak, Hi, Robert Kerstak, I, PNCCC One of those could be geolocation, just, you know, passing comment more to the point in a different universe, we were looking at reverse names for router interfaces back in the day and notice that in many cases they are just off You know, the router was there, but now the same IP address is used somewhere else. So when you look at the reverse name in trace route, the X actually is lying, fine. So that leads me to the question. What is going to be the incentive? for the operator to keep this updated if they ever put it in it's being provided by the router itself, so it just says, what is my name?"
  },
  {
    "startTime": "00:40:04",
    "text": "then the name is meaningful to whom What's the name that you get? in a normal trace route from a pointer lookup is meaningful to some subset And that's exactly my point. That can diverge from reality So I don't know if that could be a problem here, but what I'm looking for is that what is the mechanism to keep that information true? Well, I mean, in my mind, the mechanism is that it is provided by the router itself as opposed to some to keep that information true? Well, I mean, in my mind, the mechanism is that it is provided by the router itself as opposed to something else. You know, the DNS is an indirect lookup, and so someone else has to update the data Right, but the router doesn't know its name. It's assigned by some human and that human needs to reassign that name, then the router change place or, you know, behavior or whatever it is So I'm still, I don't know if this is, if this can get out of sync with reality If it can't, that's fine. I mean, operationally, I feel like it kind of is very probable that people keep their router devices. I mean, in a world where you log into a router to fix a problem, you really want to know what you logged into. And so it's host name will tell you This is kind of the self-describing network model where the device knows everything about itself And so this is what it's telling you. It's saying, I am the router called Fu. Okay. Thank you. Thanks A lot of good feedback. So please take it on the mailing list, if you have any more discussion. Sorry, we're cutting the queue because we just want to make sure we keep on track so Ralph, all yours all right my name is ralph this is really stateless Reverse Trace Route, and that's collaborative work with Valentin And he was here during the Prague meeting, I believe and he presented reverse trace route. So the status was missing And the comment was made that"
  },
  {
    "startTime": "00:42:02",
    "text": "and it's fair and it's true that functions using ICMP typically don't keep state around And we had the stateless design basically already ready so we put it into draft format and uploaded it. So I'm basically presented a tweak on something that Valentin presented I think, two IETFs ago So before I show you how we do it, I'd like to read reiterate the why. So the problem is, when you do a trace route, we talked about trace a little bit, when you do a trace route, you get a bunch of routers from you towards that destination you see the forward path and in addition to the IP addresses, and if a point of record exists, the router names, you get round trip time measurements and when you look at this this path that is being traced, you might see that betraying route C&D, the latency goes up and it persists, so it's not just at that router, but it persists, so it seems to be a problem somewhere, and just given this output alone, you might assume that there's something wrong between routers, CND So at the handover point between network A and network B And that might be true. You don't really know, but it might be the case that there's a problem but you do doing round trip time measurements, so you also have the reverse path as a component in your round trip time estimate. So the time includes the forward direction and the backward direction but you don't see the backward path. So the return path is invisible to you. And if routed D, for example, decides not to route back through a network A, but decides it on a different network for routing policy reasons or something else, then a problem between those two routers at the bottom will give you the exact same output So from your perspective, during the trace route, you don't know if it's on the reverse path, if it's between routers C and D you just see that there's an increase in latency at some point And I presented this as Dnock, which is the German version of Nanak And two days before I gave my presentation, there was a"
  },
  {
    "startTime": "00:44:02",
    "text": "request on the mailing list for somebody from a certain prefix to reverse trace route manually back to him because he sees a problem and he's not sure if he's on the forward path, on the backward path. And so today, people fix this with personal contacts or mails and that's a sorry state of affair So we try to fix this and now I'm going to show you how we address the problem. So we define a new ICMP request and response. The ICMP request is to trigger a single Pro packet from the server back towards you. So you basically have to send one request for every package that goes out. You don't want to send one request and then have a whole trace rot going out because that's clearly next amplification attack vector and we don't want to have that Now, what the server then does is in your request you can specify what should be the teacher going out because that's clearly an amplification attack vector and we don't want to have that. Now, what the server then does is in your request you can specify what should be the TTL of that packet, what should be the protocol So you basically configure regular trace routes remotely, and the operation itself is just what trace route does today is exactly the same thing So you can pick UDP, ICMP, or TCP as a the layer just above IP and you can also control fields that are typically used by load balancing routers like port numbers or the checksum in ICA The server will send this, the server will get the ICMP time exceeded message back. And what's missing now is reporting this back to the actual requester on. And that's the second ICMP message that we define in the document, which contains the IP address or maybe at some point note names and the RTTS estimates. So it gives you the same information that trace what gives you low locally but from the remote host So I already said that we had the stateless version already at hand, but we"
  },
  {
    "startTime": "00:46:02",
    "text": "consciously decided to submit the state full version And there's a reason for it So stateless basically means we don't keep state locally We put everything that we need to calculate round trip time, for example We put it in the packet, in the pro packet we send out. And when we get the ICMP time exceeded message back, we hope there's enough information in there that survived so we can do all our calculations and I give you ICMP here's an example. So for IPV4, the standard says the only thing that's guaranteed to come back is the copy of the IP header that expires plus at least 64 bits after the IP header It might be more, but the same standard says it should be 64 bits. So when you look at an ICMP probe, the same applies to UDP for TCP it needs to be even more bits because the header is simply bigger An ICMP probe by send out by trace rod would be an ICMP echo, which is type 8 code zero. We can't do anything about that We use the checksum to adjust the behavior of load balancing routers to set the checksum, we need to add some payload at the bottom but that can be discarded. That's not a problem We put the identifier in there, so the requester says, here's an ID for my request and the response it expects the same ID so it can match request and response we need to put it in there as well. The probe I'm not going to go into a that much, but everything there is guaranteed to come back because that's the 64 bits that the standard guarantees you to come back. And then we also need to add a timestamp when we send the probe packet, because when a packet comes, back we look at the time and subtract them, and then we know how long the packet was inside of the network, so the RTT estimate that's not guaranteed to come back So what it means for the stainless version, RTT estimations are not guaranteed to work. The question is, will they work on the current internet, right?"
  },
  {
    "startTime": "00:48:02",
    "text": "So it might not be guaranteed, but the current internet might not behave like this So what we did, we looked at some data from RIP Atlas, so they, give you the archives of the data I think they give you metadata, basically And we went through roughly 200 gigabytes of compressed archives, looked at all the IPv4 ICMP time exceeded packets in there and then did some statistics, did first some filtering because there was bad data in there, and then this some statistics. So you see the in this table here so roughly a little bit less than 50 actually sticks to the 64 bits. So in those cases, we can give the request of the IP address of the router, but we cannot give the request of the round-trop time estimate. But that's really valuable as a troubleshooting utility you want to see that as well, right? So for 50% of the cases, you will not be able to calculate the RTT but for the other 50%, you will actually be able to do that So 50% returns 48% bytes or more in the actual response So it's not catastrophic, but it's not ideal if you really want to do troubleshooting deterministically So let's compare the two, right? So we have stateless on the one hand and stateful on the other hand. So in stateful, we for example, we record the time when we sent the packet locally and then if it's not being returned to us in the ICMP time exceeded message, we can just calculate it, right? So this is the state I'm talking about. It's not a lot of state It's not difficult to maintain, and it's easy to protect and remove, but it's there So for the stateless version, we can identify all the routers on the reverse path, the IP address of the route on the reverse path. Stateful can do that too And as I just showed you, we can't always estimate the RTT because sometimes the time exceeded message will be truncated too early and we will as I just showed you, we can't always estimate the RTT, because sometimes the time exceeded message will be truncated too early and we don't get enough information back. But in 50% of the cases, this will work. For stateful, this will always work because we can"
  },
  {
    "startTime": "00:50:02",
    "text": "the time exceeded message will be truncated too early and we don't get enough information back but in 50% of the cases this will work for stateful this will always work because we keep that information locally and in addition, there's a function that a couple of operators have asked for and they found that useful so what wen lin the stateless version can only do, we can trace back to the requester because the copy of the IP header will be in there, so we know where to respond A couple of operators asked, well, can we just ask somebody else to trace somewhere completely different? We could, but we need to remember this because this will clearly not be inside of that packet So a stateful version will give you extra information. It's a bit like this website. Is this blah run down for me or for everybody else? right? This would be a similar function just for trace routes. And there was interest in that. We can do that in stateless, but we could do that in stateful So that's why we submitted stateful before we submitted the state list variant for you to consider consider In all fairness, there's a little bit of amplification right? So we send a request the server is going to do a probe so it's going to send out a single probe. It's going to receive potentially a TTI expired bag And then it also sends reply back So there's a little bit more work than in a sense of a little bit more than the client is actually sending. So there's a little bit of amplification If you want to attack the internet, I would suggest DNS still but there's a little bit of amplification. What you can do against that is, and there's an extension in the draft you can make the client send way more bytes before you actually start the reverse tracer operation All right So I also ask for working group adoption. I think the document is in pretty good shape for an individual document No offense, but I think it's in pretty good shape. We have an implementation of it"
  },
  {
    "startTime": "00:52:02",
    "text": "So the server we have as an EBPF program the client we have as a Python script, you can download it as online. It's available. I can send you the links if you want to there in the presentation that Valentin did in Prague We also did a bunch of measurements to see which code points to use. We send it through a bunch of nuts to see how nuts are behaving. We looked at the right atlas data to estimate how well stateless would perform on today's internet So I think we have a good package to decide whether we want to adopt this as a working group item or not And I think we need to agree on two things. So the first thing we need to agree on is whether we think this is a function we want to give to the operational community on the public internet And the second thing, we need to decide if this is a good starting point as a solution if the document gets adopted I really have a plan for it So I personally would call it reverse race route, so remove the stateless and then I would leave it up to the server so that the server, the operator of the server made a conscious decision to give you the ability to use reverse trace route with his box. So when this person did that, we can actually leave this person the decision to whether to do it statefully or not statefully. So after it gets adopted I would suggest that we offer both as a solution because the signaling doesn't change right? So you just, you ask for it It's being done. You don't know how it is being done if it's statefully on not, the server can decide and then the worry about potential security issues of the state we have to address obviously the document we did in the stateful version"
  },
  {
    "startTime": "00:54:02",
    "text": "and it's up to the operator of the server to actually decide whether they want to offer it statefully or not This is what I would do Okay. Thank you very much. You have three people in the queue right now Nalini? Yeah, nalini elkins So one of the things, I mean, great idea because i've certainly wanted it myself you know having reverse trade route. The only problem, though, is like so many people so many routers block ICMP on the internet Yeah, they probably do, but we don't talk to routers via ICMP. So we talk to end hosts, and so we did some measurements So if we measure, we send, I think ping, a simple ICMP ping to I think, 10 million hosts on the internet or IP addresses on the internet and when they replied to the ping, so we know that ICMP goes there, we sent our messages there as well and most of them responded to that as well so there's a there's a they replied to the ping so we know that ICMP goes there we sent our messages there as well and most of them responded to that as well. So there's a big chunk of places on the internet where this works today. So I don't think we have to worry about that huh okay we have a paper about this too I can send you a link and then you can see the numbers yourself No, sure, sure. I mean, every time I I've done Trace Route, there's a ton of stuff that doesn't respond back to ICMP. Well it depends so um if you use the the the macroel Linux trace route version, it's not even ICMP packets I do send out, it's all UDP packets, right? And they don't respond for various reasons. It doesn't have to be because it's ICAMP It could be because they're rate limiting time exceeded messages and things like that. So it might not be related to ICMP david lamparter, from scrolling through the draft, it's not entirely clear to me whether this is intended to be deployed on a huge amount of routers"
  },
  {
    "startTime": "00:56:02",
    "text": "or end hosts everywhere or whether this is going to be a very targeted thing that gets deployed in a few places. And I do think that distinction matters at least for the security consideration section. So I think just needs a little bit of clarification. So I can please not control where it's going to be deployed but I would assume from for the security considerations let's just assume it's on every host on the internet just like a ping is. And a bit of it ICMP, right? So it's going to sit in the kernel And so let's go with that assumption and write the security considerations for that. So at the bare least, I think you need to answer whether this is a default on or default off feature if I have a box that is fresh out there. Yeah, I completely agree thank you eric so eric thanks you're pretty much like that David, right? So I think your explanation is much clearer than in the draft. So thank you so much for explanation here If you start a trace route from a server on the internet, you will install a stack because you need to correlate the reply or the absence of reply back to the host so it's not really stateless. This one is stateless because it's all in the packet so we send the prop out and when we get the the time exceeded back, all the information we need is in there okay it's not our understanding the trace round same because you need to remember I'm sending these two DPP probe to this from this port then when you are receiving back I need to now understand, oh, it was my decision nation UDP port. I need to remember it. Okay, whatever the other point I really wonder whether I see and the right protocol to be used rather than NetCon for something like that. I would say yes. It could give you authentication in the same shot. Right, but I would strongly argue for ICMP is the right thing to do Because, so I would like to have this as a utility for the public internet so the public internet we have two things right we have pink and trace route right now. There's nothing else you have. You don't have net components I would like to have this as a utility for the public internet. So on the public internet, we have two things, right? We have ping and trace route right now. There's nothing else you have. You don't have net comp on the public internet. You have that for your boxes. The same is true for SNP"
  },
  {
    "startTime": "00:58:02",
    "text": "and other management protocols it's for your boxes but I want this to work on the public internet. And then ISAMP is the right answer That's a point. Thank you Ben? hi so do i understand right that you can request the you can request the trace route server to emit to perform trace routes using udp and tcp all right server to to emit to perform trace outs using udp and tcp or ICMP yeah or ICMP yeah but one request only triggers a single packet. Right yeah. But I can only use ICMP to communicate with that server, right? The request will be ICMP and the response, reporting the results will also be ICMP, yes Right. So this strikes me as odd because the number one reason I would use UDP trace route is because of ICMP black holeing right? But this actually doesn't allow me to function in the face of ICMP black holeing because now it outer connection is limited to ICNP. Yeah, that's true So the motivation for that was you could also write an application that uses TCP or UDP to the signaling, right? Yeah. But that means somebody needs to install that application. And we wanted to have it in the kernel, so it's a facility that's just there that comes with the operator system. So I think there is precedent for kernel integration services that are listening on, for UDP and TCP in ancient history at least I think like the echo functionality on, I don't know, Port 7 or something so anyway, I would consider whether there's potentially a UDP endpoint that, you know, you could allocate an IANA port for this and that would help. Yeah, so one response to that is that there's a applicability draft for our for ICMP. So for what kind of functions can you use ICMP and for what you shouldn't use ICMP?"
  },
  {
    "startTime": "01:00:02",
    "text": "A network troubleshooting is the thing that you should use ICMP for. And this is basically it's fitting so nicely also for the applicability. I think ICMP should exist but I'm not sure it should be the only way yeah all right yeah point thank uh also for the applicability of i think ICMP should exist but i'm not sure it should be the only way yeah all right yeah point i also do wonder if you could get some RTT information by using a deeply truncated timestem to try to get that squeeze that information into the first eight lights thank you you thanks uh lynn Please Okay, hello, everyone My name is Aline from Qinghwa University Today, I'm going to introduce the app update of our draft Establish Solutions for wireless land First, let's take a recap of our draft Savvy W-LAN is a source address validation solution for wireless lines. It uses MAC address is secured by 802.11I or other security mechanisms as banding anchors. It performs and snooping or DATC CP snooping to bind and assigned IP address to a verified MAC address It specifies how to migrate sub-bendings in mobility scenarios. And also, it supports two deployment scenarios in centralized wireless lands both access points and access countries can filter the spoofed packets based on the savvy bandies. In autonomous wireless lens, only access points perform the filtering of spoof"
  },
  {
    "startTime": "01:02:02",
    "text": "packets based on the savvy bandings Okay, uh, uh, the last time in IETF119, we present this draft and there are many people who are not very clear with the problem and motivation of this draft and this time I will focus on explaining it First, let's talk about the problem There are two problems we think in the wireless lens. The first one is there is a lack of naturally available binding anchors in wireless lens. In wire the lens people use switch ports as banding anchors. However, they are secure, yeah, they are secure and but the difficult, more difficult to speak than in then I addresses. However, in wireless lines there are no switch ports this kind of naturally naturally of secure banding anchors So that's a that's a problem one. The second problem is that in wireless wireless lens there are wireless lands suffer from the problem of user roaming. Yeah, when a user moves to a new accept point, there are a lack of appropriate binding entries for social adjustment validation. So we need a solution for wireless lens In fact,"
  },
  {
    "startTime": "01:04:01",
    "text": "FCFS savvy, which is RFC 60s 60 RFC62620, considers user roaming a case, and the user roaming case discovery protocol to verify that the host is still reachable through the previous spending anchor. If not, the FCFS savvy assumes that the new location is valid and creates a new banding using a new banding anchor Otherwise, the package coming from the new banding anchor are dropped However, we find that this solution does not solve the source-addressed validation in wireless lands very well There are two limitations. The first one is ND probing against a previous access point Increases the waste of air interface resources because the host can no longer receive packets from the previous access points when the user roaming occurs. And the second one is the use of ND to confirm whether or host is still reachable under a previous access point prolongs a service up outages during a host roaming and negatively impacts user ROMA roaming experience. So we believe a little method is needed for fast migration of survey bandings on the valley negatively impacts user roaming experience. So we believe a new method is needed for fast migration of survey bandings under wireless lands And we have updated the document since IETF 119 and there are three major staff The first one is the consideration has been given to the validation of IPV6 address, prefixes obtained from, by host through DHCP allocation"
  },
  {
    "startTime": "01:06:02",
    "text": "We have updated the related to in version 0.03 three and there is not a much different in the way that is the prefix are handled The second one is we have made the modification to the CAPWAP message element format This message element was used to synchronize savvy bandings between access points and access controllers. More detail, the we simplified the fields in the message. We remove cinder ID and its lens and the description from the message This kind of a fields were originally designed to identify the message sender sender But since we can, the accessible, the message sender was access controllers Um, since, uh, access points and access controllers can direct process a message after receiving him, so this kind of a these fields are no longer available, necessary And we also provide support for migration to the of the prefix related savvy bandies in the bottle of the figure, we provide some fields Third, we add consideration of the impact of different random MAC address generation methods on Savi"
  },
  {
    "startTime": "01:08:02",
    "text": "wireless land. We believe random MAC addresses on not affect the functionality of Savvy Wireless land because how are not allowed because hosts are not allowed to change their macro addresses during transaction exchanges according to HVE 802 802.11I HVE802.11I There is another issue is your relationship with the existing service solutions for different address assignment scenarios the method of establishing binding entries still follows respective scenarios specific procedures. For example, RFC's 6620, RFC 7530 That's all Any comments? Thank you. Thank you very much Any comments? Okay, you don't have anyone in the queue, but if you have any comments, feel free to submit on the mail list or request more feedback Thank you Thank you you all right so yeah one you. All right. Can I just? Yeah, one Eric. My understanding is that your document extend capwap is that your document extend CAPWAP. Okay, did you consider presenting this document in OpsidUVG, which is basically the Opsaraya, because CAPP? was OPS before? The chair is over there just next to it me me me Okay. Next is Josh"
  },
  {
    "startTime": "01:10:05",
    "text": "Run the slides for me So I'm josh cohen I'm kind of with us. Is that okay? The perils of being short So I'm one of the original co-authors of WPAD, the Web Proxy Auto Discovery which I think everyone here is heard of. You know, or any if you've been on the Ontario list over the past couple of weeks there are a bunch of discussion on that. And so that was designed 25 years ago before D.H.C was even widely deployed so the choices that we made are probably very different than what we would today. And one of the choices I think, you know, if I've discussed this with number of people over the past couple months, and I think they're really two schools of thought. One is, it's over, basically just put it to bed, it's no longer something we should continue to do. And the other which is, I will admit, a minority view is to constrain it is to make it best bad, I guess, for those who think that network discovery or proxy is inherently bad, it's less bad But I think one of the questions that needs to be answered, like some operating systems have it disabled by default, but Windows does. And so I have let's see, is Dragana still here? Yeah, we've been talking, and one of the things that needs to be figured out is is that because IT admins are still enough of them are still using it and want it, or is it just kind of there because it's there. So I think one of the things that needs to be answered going forward is what is what is the situation? So for the moment what I've chosen to do is to try and slim down W. Pat and see"
  },
  {
    "startTime": "01:12:02",
    "text": "if that is an alternative solution and at least that way whatever we decide to do there's choices so next slide So the current draft, deprecates the few of the discovery mechanisms that we have back then. The most problematic, I think, is the DSA combination of using W Pat as a host name combined with the DNA domain devolution, which is where you start with, let's say, you know, sales.example.com and then go to example.com if you don't find it And that has led to probably the most extreme exploits that I've seen So getting rid of that is good. Back then, DNS techs was barely adopted as well And the answer, as we saw it, was server location was going to be the way to securely discover services on the next network. But that ended up not ending up the same way so what remains is dhcp and DNSSD. I've been talking to people about the different potential exploits for that. And from config file format PAC file is a problem That's where a lot of problems also happen. It's also very complicated and a lot of resources get used because it's clicked. It's run every time a browser link is clicked So it all turned up to that is PBD which Dragana presented on earlier And also, in one of the ways to deal with, rogue advertising of proxies is if an enterprise does not have a proxy it wants to make sure that rogue proxies don't interfere, add a URN to the answer that you can get, which just says none, which should stop discovery Looking forward, one of the things that I'm considering, and I would appreciate feedback, is to just get rid of the devil which should stop discovery. Looking forward, one of the things that I'm considering, and I would appreciate feedback, is to just get rid of the devolution thing altogether. I think one of things that"
  },
  {
    "startTime": "01:14:02",
    "text": "I'm curious about is, I mean, that's a DNS thing, because that would be a situation where you may have a sub-domain that were the DNSSD is responding to that and then be apparent DNSSD thing, because that would be a situation where you may have a sub domain, where the DNSD is responding to that, and then it would be a parent domain. But if we get rid of DNSD that answers that problem DHCP only is another way to go And another, which I think would be helpful is to require user consent. I mean, that was a that was kind of a choice back 25 years ago that was really more about we didn't have a good way to do it from an architectural standpoint because the HTTP engine was on a different thread and IE but you know nowadays when you get on a wire network, there's often the user sign-in screen so that might be possible and that would help alleviate things as well Any questions or questions? Okay, thanks. Chris? Yeah, it's not my area of expertise, but just have you considered mobile networks because they don't use DHCP? That's what mobile networks? cellular. They get allocated IP address via data connect pdp context create and they get given IP addresses for DNS but that's about it so as far as I know dhc DHCP is not part of that check, the setup check Do they have like an equivalent? Well, DNS. Like SD? i don't know that that would be an area to explore okay um can I talk to you about that later yeah Thank you. Ben benjamin schwartz. benjamin schwartz So the original WPAD was a draft that never reached RFC, was never approved by the IASG and it was stacked on top of the PAC file concept, which was also a proposal that was never actually standardized"
  },
  {
    "startTime": "01:16:02",
    "text": "And so I feel like we're, you know, this is a, we're trying to solve a, we're trying to like update a thing that actually never in IETF terminology was created created So, I don't, like, I don't think we need to modern it just because it's old when it was never a standard in our formal terms to begin with and I really feel like what I'm missing in all this conversation is the why Like, why does this even why are we even talking about this? Like, why would a network need to tell me? these things? And like, okay, maybe there's a good reason, but like we need to know the reason to design an appropriate mechanism so it just seems like we're working in a vacuum here and I can't make any of these choices without knowing a lot more The thing that I don't see, or at least not explicitly here, is the option to take classic WPAD and just restrict it in various ways essentially deprecate portions of it and leave whatever we believe is actually useful and then potentially elevate that to a proper RFC step okay so I'm gonna respond in reverse. Okay. So I think to your last point, I mean, that is what's here. This is the old W-pad draft with like cross this out, cross that out, and add a few things. As far as, you know, the question of what is the reason? you know, one of the things that we need to do an assessment of is, you know, then we had a set of reasons and now the question is are IT admin still really using this and why? And so that's a conversation that is coming. I mean, I can speak to the decisions we made back then"
  },
  {
    "startTime": "01:18:02",
    "text": "I mean, part of it was, you know, proxies were relatively new and they weren't, they weren't necessarily viewed in a positive way But in order to state the, you know, the lives of help desk people, having to constantly tell people, how to configure their browsers at a point when they were still figured out how to do browse, you know, use the browser on a piece with like windsock you know so it was just a, it was an obstacle to enterprises getting their employee on the web. But I first started thinking about when I worked at UPS, we were designing a proxy to allow browsing for a desktop and we have to integrate with the mainframe for single sign on because management wanted authentication logs. And that was yet in HTTP10. So that's why I ended up coming to the IT up. So the question is, okay, what is the world with us? and I think to your first point you know what there's been a series of vulnerability announcements and when I spoke to more nottingham, they should be a know, when there's been a series of vulnerability announcements and when I spoke to mark nottingham, the H.C. Chair, he was like, oh, this is the perennial question of what do we do about W-Pad? So whether or not it actually achieved standard status or not, it's like, okay well, let's answer that question yeah i i think that there's a real, like, opportunity here for an informational draft on architectures like network architectures involving proxies and it's not, it's far from just enterprises there's a bunch of performance enhancing proxy architectures that are in wide use there's a bunch of new multi-hot proxy architectures that are emerging I kind of want to see that all really thought through before we go try to make sense something yeah you're being played off yeah please take it off offline. Thank you very much for the feedback feedback feedback"
  },
  {
    "startTime": "01:20:01",
    "text": "Thank you voice interface please. Okay, prosa Yeah hello. This is like an illustration of great minds and alike collect, because it's very similar to what Bill presented I'll it's very similar, we might need to merge it, but let's me talk through it first so next slide, please, because I can do it from the phone for some reason yes so let me first talk why we doing this, why I'm here No, not this one Anyway, I'll talk meantime So I spent quite a lot of time recently on doing V6 only or V6 mostly networks, right? And I will, yeah, next slide please. So yeah, this is a quick only or V6 mostly networks, right? And I will, yeah, next slide please. Actually, next slide. So yeah, this is a quick refresher, how V6 only done. Normally, right? you have not six or somewhere in your network we which connects your V6 only a network to the dual strike of only internet. But the most interesting part here is to make it really deployable on a record client, you most likely would need CILAT customer site translation which will take you if only application traffic translated to V6 and send it on the wire and translate the return traffic back. Next slide, please So what's the problem here? Let's say I do trace route from my V only MacBook, which sits on IETF net slide, please. So what's the problem here? Let's say I do trace route from my V6 only MacBook which sits on an ATF network to some V4 only destination Let's say I do trace route 8, 8, 8, 8.8 Routers, which are in the Internet which are dual stack, will respond from the AV4 address destination. Let's say, do trace route 8888. Routers, which are in the internet, which are dual stack, will respond from their before addresses to some not before address"
  },
  {
    "startTime": "01:22:02",
    "text": "will be translated to V6 by not 6 PILA device, and that I see MP PV6 will be easily translatable back by CILA because the source address of that IECNP belongs to not 64 prefix. However, what about a trace route from the intermediate hopes which are between the client and not 64 device? Those hoars are actually V6 only, and those V6 addresses are untranslatable fundamentally because the real V6 addresses. They are not from not 64 prefix. So as far as a know, most implementations drop them. There are some exceptions Next slide, please So yeah, as I say, observed operational issues is that trace routes could not represent V6 only hope which confusing for users because they tell you or you have a packet loss in the network, which I actually don't And it's obviously complicated troubleshooting Another case is it means your packet too bigs are not translated. I will say, radically I had a lot of conversations this week So theoretically, maybe you are not supposed to have MTAU programs in your V6-only network. You should be thinking about that And if you have MTU problem, you're doing something wrong But, well, sometimes I guess your backup link might be like, might be through internet or some something. Anyway, I think it would be nice not to break part possible to you discovery even more it's already broken enough so next slide please and next slide so what we are proposing we'd like to define how to try translate untranslatable i mean v6 are addresses which are no do not belong to not 64 and also preserves the information about original V6 source. Next slide, please And now how? Next slide. First of all, let me define untranslatable because I don't want to repeat it every time. So when I'm saying about untranslatable, addresses, I'm talking about addresses not from not six"
  },
  {
    "startTime": "01:24:02",
    "text": "four prefix and for which translator doesn't have an explicit static entry next slide please So yeah, translated and translatable. Yes, there is a .8 address, which is done maybe for address allocated by an already It's kind of, I think it's kind of belongs to 4RD, so yeah, we might use it, or we might just request to one particular specific address just for this purpose And, yeah, suggestion is to use that address to translate the source IPV6 address if they are fundamentally untranslatable Android implementation, as far as I know, for trace route, you using 2550X for trace route and use TTL as X. So you're hope number two will be seen as 2-2 in trace route But obviously it would be nice to standardize the approach so especially because we are in the process of writing a draft for how Celad should operate on costs And this is actually important addition to CILAT implementations. Next slide, please so yeah so what we proposed at the same time as Bill wrote his draft is to introduce a IP original Saurus extension object. It's obvious much simpler that what Bill's draft's doing It's just a length class and 16 bytes of original source IP. Next slide, please Yes so obviously we want to add it. It should be added by translation I mean by Silat when translating V6 to V4 and obviously when only those conditions are met Packett to Big special case, I'll talk about it in a second. Next slide, please So I mostly want to hear the room feedback on should be before how. So that's why intentionally do not put details on the draft but in overall a draft has details about"
  },
  {
    "startTime": "01:26:02",
    "text": "when and how to add the extension structure by translator or how to add that structure to existing this extension option to existing structure Thank you Bill for feedback on missing points here And we'll also update an actual translation algorithm on how it should be done. Next slide please. So open issues actually um currently drafts are suggestions that extension object is added to V6 packet and then translated to V4 I guess it's kind of easier because then it's easier to check if the translation is actually if the extension option should be done. However, it means that we cannot add it to packet too big because extensions are not defined for IPV6 packet to big If you translate first to V4 and then add to that extensions, structure, it means packet to bigs can be proper translated and extension structure can be added, but I don't know how easy it for implement to remember all those V6 details, because this already should be done. Actually, I got some feedback in the lobby that maybe we are over specifying and maybe draft shouldn't be even talking about that. It should say what we should get as a result and do not talk about all details, like how to update check some, where to add or just maybe provide an example. So it's actually also feedback I'd like to hear. Next slide slide Oh, it's the wrong version Anyway, yeah, so basically I have a slide here. So there is this, we can merge it with build draft, right, maybe, and add details about how to translate As there is original RFC, which I also can't remember the number about uh source address extension whatever it's called which builds draft kind of using as a way However, that RFC is saying that we will"
  },
  {
    "startTime": "01:28:02",
    "text": "be violating it because it's saying that if original interface, if there is saying that we will be violating it because it's saying that if original interface, if the ICMP is IPV4, that structure must be IPV4 address, and if ICMP, if you're talking about ICMPV6, the extension object must be IPV6 address. So it will be violated of that RFC to adding IPV6 address as an extension structure into IPV packet So it's actually, I don't know, like again, I don't have opinion I'm happy to merge with Bill draft if Bill is happy or we can keep it simple and separate and this one. So this is all I have so feedback things unfortunately I think we're out of time, so we're going to allow one quick comment, but otherwise we need to move on to the last presentation so quick comment it's useful uh i would suggest that you use Bill draft and you continue on it so you suggested merging is I'm not sure whether you can really merge that You should like to use an extension? defined and bills draft and you use it, yeah. You have a normative reference to bill Yeah. To be decided, right? It's an individual vote contributor here okay um masanauv would you mind would you mind in your comment to you? I'm Masanobu from any Eniopi. Can you send your comment to the list because we have one more presenter. Okay, I'll talk about you. Later Please, sorry, sorry okay hear me? Yes yes. Okay, great. Give a brief introduction about this nice Yeah, this is about even six Next please Even since the layer two network model built on top that epivis annulate to provide connectivity"
  },
  {
    "startTime": "01:30:02",
    "text": "between these custom sites. So this draft is not new. It has proposed before IETF 180 so it discussed for many rounds Next please. Yes, this is architecture and the the focus model of even six, you adapt to NEP devices E adapted in capitalized its frame from the custom site into IPVCs packet and send them to the IPV model of even six EADAPE devices. EADAPTA encapsulate the E. From the customer site into IPVCs packet and send them to the IPVSI's only network. Then the EGRAP PE removed the header and restore the original layer two frames Evensets use 32 bits V to unify each instance And for each event six instances, you adapt to the IPV for each human six instances, E adapt to use the IPVC set prefix to identify each side. So different sides are different prefix. MacVears table is in P2 to store the MAC addresses of all the hosts and the corresponding way and the set prefix they belong to. Next please so near the hosts and the corresponding way and the set prefix they belong to next place. So for layer two frames to be transmitted, it is directly placing payload IPVC packet by the EW EADAPE and the field of NACHEAD is set as 143 in the exact is the payload of the U-Snet frame Next please so this about the address the generation by mapping and by the eager speech and there's three inputs the other about the dress generation by mapping and by the IGRES PE and the three inputs. They are the magadress of the host that is virtual network interfere set perfect. So whether it is south or so whether it is south or the mega dress of the host that is virtual network and the site periphery. So whether it is south or desolation, each major address will be mapped to one out IPVC's addresses for the incubation So they have been discussing in last eight in the meeting Next please So regarding to the control layer, they have been mentioned by Eric. So the companion, control near document will be sub subpoenaed"
  },
  {
    "startTime": "01:32:02",
    "text": "after IETF 120. Next please The following revision had been made since IETF Washington based on the suggestion of Eric Muttcott Kassi in USAX edits in section 5.1 and the section of broadcast is revised in Section 5.2, and G.B. Soon is added as one co-author. Next, please And the yeah, so based on the comments of it Eric, we also added to the section of justification and benefits analysis, since this appraud leveraged advantage of IPV6, so it is different from nexus approaches this advantage has been illustrated in last IETF meetings, so I don't want to read introduce again. Thank you. Next please We're running out over time We can close in the next one minute, please Okay, sure. Next please yes this we have employment system and set up test bag to test capability. Next please, yeah So within each, we test bed to test capability, next place. Yeah, so within each, even since, we can pin the host from one to a another, we can ping P1, 2, P3 to show the capability of even six next please. Yeah, we can even transfer the file from one host to another within the even six instances within the same over IPVCs, and next please Yeah, this is to fulfill transfer next please next please yeah this a slap shop um frame mapped IPVC packet. We can show that the IPVC packet by the approach proposed in this document including address generation and and the"
  },
  {
    "startTime": "01:34:01",
    "text": "frame into the payload, that's all Next please yeah even six the virtual network so it has the isolation capabilities so in this case each one is true belong to different cases. So belong to different instances so H1 cannot pin H6 So this shows the isolation capability of even 6. Next please yeah so we also wouldn't like to ask for working group adoption this document. And any comments suggestion are welcome That's my introduction Okay, thank you very much. Thank you very much we're out of time for questions but please to the working groups and your group like on the main link And I also encourage you to ask questions if you have any to the group on the mailing list okay thank you very much thank you very much thanks everyone thank you sorry about running on Yeah, thank you"
  }
]
